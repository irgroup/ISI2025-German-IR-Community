<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.03,115.96,327.29,12.62;1,135.30,133.89,344.77,12.62;1,269.63,151.82,76.10,12.62">IR-Cologne at TREC 2017 OpenSearch Track: Rerunning Popularity Ranking Experiments in a Living Lab</title>
				<funder ref="#_hcdBnfQ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.47,189.71,108.38,8.74"><forename type="first">Narges</forename><surname>Tavakolpoursaleh</surname></persName>
							<email>narges.tavakolpoursaleh@gesis.org</email>
							<affiliation key="aff1">
								<orgName type="institution">TH Köln (University of Applied Sciences)</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.40,189.71,75.56,8.74"><forename type="first">Mandy</forename><surname>Neumann</surname></persName>
							<email>mandy.neumann@th-koeln.de</email>
						</author>
						<author>
							<persName coords="1,385.88,189.71,63.54,8.74"><forename type="first">Philipp</forename><surname>Schaer</surname></persName>
							<email>philipp.schaer@th-koeln.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">GESIS -Leibniz Institute for the Social Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.03,115.96,327.29,12.62;1,135.30,133.89,344.77,12.62;1,269.63,151.82,76.10,12.62">IR-Cologne at TREC 2017 OpenSearch Track: Rerunning Popularity Ranking Experiments in a Living Lab</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6D60B9308D1A4D541D66633EAD6C8CF1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we will present our work on popularity-based relevance ranking within the SSOAR open access repository system where we reused a popularity data-driven ranking approach. We applied the same normalization method as last year, namely the Characteristic Scores and Scale Method (CSS). Our main focus was to test if we could reproduce the results of last year's track. We, therefore, see this work not as a sole engineering task to produce the best possible popularity ranking method for scientific literature but as a test bed for reproducibility experiments in the domain of living labs.</p><p>The TREC 2016 OpenSearch track was focused on ad-hoc search for scientific literature and three scientific search engines and document repositories were part of this living lab-centered evaluation campaign: (1) CiteSeerX, (2) Microsoft Academic Search, and (3) SSOAR -Social Science Open Access Repository. From these three only SSOAR remained in this year's OpenSearch track. The first author of this paper is responsible for the implementation of the living lab infrastructure and the LL4IR API that is necessary to include an online system into the OpenSearch evaluation campaign. This work is based on her Master's thesis at University of Bonn <ref type="bibr" coords="1,260.96,514.48,9.96,8.74" target="#b7">[8]</ref>. Details of the implementation are described in the two overview papers of the OpenSearch track <ref type="bibr" coords="1,353.00,526.44,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,363.51,526.44,7.01,8.74" target="#b2">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In previous LL4IR and OpenSearch campaigns <ref type="bibr" coords="1,343.98,584.39,10.95,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,354.93,584.39,7.30,8.74" target="#b6">7]</ref> we experimented with different kinds of popularity data as a reranking factor. For our ranking method, we consider the number of views and the number of downloads in SSOAR as a popularity factor. Table <ref type="table" coords="1,252.29,620.25,4.98,8.74" target="#tab_0">1</ref> represented a sample of these data for documents in our corpus with a different year of publication and date of availability in SSOAR. We discovered different biases in the data that introduced flaws into the ranking when using them in a straight-forward manner, like the biases raw data introduces into the ranking due to e.g. different publication years, dates of availability or the lack of a common scale to compare the different usage data with each other. We implemented a method to normalize the usage data to remove biases and to enable some kind of comparability. Our method was based on a procedure called the Characteristic Scores and Scales method (CSS) described by Glänzel <ref type="bibr" coords="2,134.77,323.58,9.96,8.74" target="#b1">[2]</ref>. The CSS method is used to find characteristic partitions for citation distributions. For more details about the method see our last year's paper <ref type="bibr" coords="2,454.39,335.53,9.96,8.74" target="#b5">[6]</ref>. In short: The method extracts classes of papers based on their citations interpreted as "poorly cited", "fairly cited", "remarkably cited", or "outstandingly cited". These partitions can then be used to normalize different kinds of usage data distributions. Plassmeier et al. <ref type="bibr" coords="2,274.51,383.35,10.52,8.74" target="#b3">[4]</ref> showed that these classes are applicable to other usage data sets like the number of record views or the number of loans at local libraries.</p><p>In this year we didn't change our ranking approach but reran the experiment with the new queries for OpenSearch 2017. Our aim was to get a direct comparison of two identical systems in the same living lab setting. We would like to compare the different usage patterns and see if the overall results of the two experiments are the same to check on the reproducibility of these kinds of experiments.</p><p>In table <ref type="table" coords="2,186.91,491.25,4.98,8.74" target="#tab_1">2</ref> we can see the results of our popularity data crawling for SSOAR compared to those from last year. We analyzed approx. 18 000 documents with an average of 287 downloads and 416 record views per document in SSOAR. Although the absolute number of candidate documents in our corpus is lower compared to last year, the per document popularity data is richer. Our 2017 corpus statistics listed in the table <ref type="table" coords="2,290.65,551.02,4.98,8.74" target="#tab_2">3</ref> shows small derivations after we dropped all documents that have null values for one of their attributes i.e. download numbers, view numbers, date of availability or year of publication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We applied the CSS normalization method on the usage data of our whole corpus. In figure <ref type="figure" coords="2,196.74,644.16,4.98,8.74" target="#fig_0">1</ref> we can see the unprocessed view and download counts for four different time slices in the data. The plots show the counts for the in-system publication dates for the year 2009, 2011, 2013, and 2015. We see the same skewed popularity data as in last year's experiment. In the CSS normalized data, these large differences in the counts are slightly decreased and therefore allow for a better integration of the ranking formula and a better comparison. We can still see the biases introduced by the different publication years that are present in the raw data distributions. In another approach, we applied the CSS normalization method on the usage data for each publication year individually. Figure <ref type="figure" coords="3,165.54,500.63,4.98,8.74" target="#fig_1">2</ref> confirms that in consequence the curves come together significantly and could possibly provide a better comparison. However, in our ranking approach, we applied the CSS normalization on the undivided collection since we want to compare the result with the result of the previous year. SSOAR shared 1165 search terms and a list of approx. 18 000 candidate documents for the Open Search track in TREC 2017. These numbers increased in comparison to TREC 2016 in its last round where 1127 search terms (including 118 terms naming browsing categories instead of ad-hoc search terms) were distributed to the participants of the Open Search track. During the experimental phases in 2016 and 2017, SSOAR reported 16 730 and 33 583 feedback records, respectively. The number of reported clicks on candidate documents were 329 for 2016 and 475 clicks for 2017.</p><p>Table <ref type="table" coords="3,177.10,644.16,4.98,8.74" target="#tab_3">4</ref> describes the result of our ranking method in OpenSearch 2017 and 2016. Last year the number of clicks in the result is not reported. We (Gesis)  won the competition by having just one win click more than the base system. In 2017, however, we had more wins and losses. Still, our system performed better than the other ranking systems, Webis with an outcome of 0.462 and ICTNET with an outcome of 0.400. Figure <ref type="figure" coords="4,182.38,572.43,4.98,8.74" target="#fig_2">3</ref> shows a comparison between our experimental ranking scores in TREC 2016 and TREC 2017 for one sample search term. While the retrieval system remained stable for the two years, the computed ranking score differ a lot. The figure shows only those documents that were included in both systems in 2016 and 2017. They values in the figure were sorted according to the 2017 ranking score to show the corresponding ranking score for each value. The documents on the top of the list in 2017 have much higher ranking score in comparison to 2016, but the items in the tail have almost the same ranking score in both years. The reason for this diversity of ranking scores in two years may lie in new documents in the candidate list and also in the sharp growth of the number of views and download for some documents in TREC 2017. The impact on the resulting ranking is huge as a Kendall's tau value of -0.239 was observed for these two rankings. This was an observation we already had during last year's TREC: The popularity values introduce a high fluctuation of the resulting rankings. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,368.49,345.83,8.74;4,134.77,380.45,306.01,8.74;4,136.69,236.90,169.46,120.07"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Plot of raw number of the view and download (left) and CSS normalization (right) rates for four different time slices in the usage data of SSOAR.</figDesc><graphic coords="4,136.69,236.90,169.46,120.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,368.49,345.83,8.74;5,134.77,380.45,310.73,8.74;5,136.69,236.90,169.46,120.07"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Plot of raw view and download (left) and individual CSS normalization (right) rates for three different time slices in the usage data of SSOAR.</figDesc><graphic coords="5,136.69,236.90,169.46,120.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,134.77,263.39,345.82,8.74;6,134.77,275.34,76.93,8.74"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Comparison plot of the experimental ranking scores for a sample query in 2016 and 2017.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,136.16,127.36,338.01,94.14"><head>Table 1 :</head><label>1</label><figDesc>Sample of usage data for document in SSOAR</figDesc><table coords="2,136.16,142.89,338.01,78.62"><row><cell>#downloads</cell><cell>#views</cell><cell cols="2">available-form publication-</cell><cell>site docid</cell></row><row><cell></cell><cell></cell><cell></cell><cell>year</cell><cell></cell></row><row><cell>372</cell><cell>1147</cell><cell>2012-08-29</cell><cell>1998</cell><cell>document449</cell></row><row><cell>42</cell><cell>131</cell><cell>2015-12-01</cell><cell>2009</cell><cell>document45488</cell></row><row><cell>687</cell><cell>481</cell><cell>2012-08-29</cell><cell>2011</cell><cell>document29377</cell></row><row><cell>25</cell><cell>138</cell><cell>2014-04-14</cell><cell>2004</cell><cell>document38204</cell></row><row><cell>465</cell><cell>557</cell><cell>2012-08-29</cell><cell>1998</cell><cell>document1909</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,134.77,127.36,345.83,106.10"><head>Table 2 :</head><label>2</label><figDesc>Comparison of corpus statistics on the popularity data gathered from SSOAR for the years 2016 and 2017.</figDesc><table coords="3,136.16,154.84,337.13,78.62"><row><cell></cell><cell>2016</cell><cell></cell><cell>2017</cell><cell></cell></row><row><cell></cell><cell>downloads</cell><cell>views</cell><cell>downloads</cell><cell>views</cell></row><row><cell>docs total</cell><cell>24 760</cell><cell>24 760</cell><cell>18 003</cell><cell>18 003</cell></row><row><cell>docs w. usage data</cell><cell>21 523</cell><cell>24 724</cell><cell>15 344</cell><cell>18 003</cell></row><row><cell>max</cell><cell>504 720</cell><cell>21 788</cell><cell>38 818</cell><cell>24 450</cell></row><row><cell>sum</cell><cell>6 549 674</cell><cell>9 822 049</cell><cell>5 175 322</cell><cell>7 492 304</cell></row><row><cell>avg</cell><cell>264.51</cell><cell>396.66</cell><cell>287.47</cell><cell>416.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,134.77,261.07,345.82,128.01"><head>Table 3 :</head><label>3</label><figDesc>Filtered statistics on the popularity data gathered from SSOAR collection for TREC 2017.</figDesc><table coords="3,205.32,288.55,170.23,100.54"><row><cell></cell><cell>downloads</cell><cell>views</cell></row><row><cell>docs total</cell><cell>17 732</cell><cell>17 732</cell></row><row><cell>avg</cell><cell>289.93</cell><cell>421.16</cell></row><row><cell>std</cell><cell>660.44</cell><cell>548.52</cell></row><row><cell>min</cell><cell>0</cell><cell>2</cell></row><row><cell>25%</cell><cell>37</cell><cell>170</cell></row><row><cell>50%</cell><cell>196</cell><cell>350</cell></row><row><cell>75%</cell><cell>340</cell><cell>517</cell></row><row><cell>max</cell><cell>38 818</cell><cell>24 450</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,134.77,417.19,345.82,73.22"><head>Table 4 :</head><label>4</label><figDesc>Result from TREC OpenSearch 2016 and 2017 for Team GESIS / IR-Cologne</figDesc><table coords="4,136.16,444.67,338.08,45.74"><row><cell></cell><cell>Win</cell><cell>Ties</cell><cell cols="4">Losses Outcome Impression Clicks</cell></row><row><cell>IR-Cologne 2017</cell><cell>9</cell><cell>2</cell><cell>6</cell><cell>0.60</cell><cell>3700</cell><cell>31</cell></row><row><cell>Gesis 2016 round#1</cell><cell>1</cell><cell>460</cell><cell>0</cell><cell>1.0</cell><cell>460</cell><cell>NG</cell></row><row><cell>Gesis 2016 round#2</cell><cell>1</cell><cell>96</cell><cell>0</cell><cell>1.0</cell><cell>97</cell><cell>NG</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>We would like to thank the whole SSOAR team that supported us to implement the <rs type="grantNumber">LL4IR</rs> API into the productive system and opening up the system for academic research.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hcdBnfQ">
					<idno type="grant-number">LL4IR</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,602.00,342.24,7.86;5,146.91,612.96,333.67,7.86;5,146.91,623.92,333.68,7.86;5,146.91,634.88,333.68,7.86;5,146.91,645.84,333.68,8.12;5,146.91,657.44,160.05,7.47" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,195.78,612.96,176.45,7.86">Overview of the trec 2016 open search track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">Y</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec25/trec2016.html" />
	</analytic>
	<monogr>
		<title level="m" coord="5,184.12,623.92,239.70,7.86;5,383.78,634.88,96.81,7.86;5,146.91,645.84,12.29,7.86">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. November 15-18, 2016. 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="6,138.35,310.28,342.24,7.86;6,146.91,321.24,333.68,7.86;6,146.91,332.20,73.85,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,202.95,310.28,277.64,7.86;6,146.91,321.24,215.04,7.86">Characteristic scores and scales: A bibliometric analysis of subject characteristics based on long-term citation observation</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Glänzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,368.28,321.24,91.08,7.86">Journal of Informetrics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="102" />
			<date type="published" when="2007-01">Jan 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,342.66,342.25,7.86;6,146.91,353.62,333.68,7.86;6,146.91,364.58,333.68,7.86;6,146.91,375.54,333.68,7.86;6,146.91,386.50,57.85,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,146.91,353.62,114.32,7.86">Overview of trec opensearch</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jagerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">S</forename><surname>Krisztian Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,432.51,353.62,48.08,7.86;6,146.91,364.58,191.03,7.86">Proceedings of The Twenty-Sixth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Sixth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-11-15">2017. 2017. November 15-17, 2017. 2017</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,396.97,342.24,7.86;6,146.91,407.93,333.68,7.86;6,146.91,418.88,333.68,7.86;6,146.91,429.84,333.68,8.11;6,146.91,441.45,169.46,7.47" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,390.98,396.97,89.61,7.86;6,146.91,407.93,234.47,7.86">Evaluating popularity data for relevance ranking in library information systems</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Plassmeier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Borst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Behnert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lewandowski</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2857195" />
	</analytic>
	<monogr>
		<title level="m" coord="6,404.45,407.93,76.14,7.86;6,146.91,418.88,333.68,7.86;6,146.91,429.84,73.42,7.86">Proceedings of the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community</title>
		<meeting>the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community</meeting>
		<imprint>
			<publisher>American Society for Information Science</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">125</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,451.27,342.24,7.86;6,146.91,462.23,333.68,7.86;6,146.91,473.19,333.68,7.86;6,146.91,484.15,333.68,7.86;6,146.91,495.10,239.93,8.12" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,284.10,451.27,196.49,7.86;6,146.91,462.23,15.89,7.86">Historical clicks for product search: Gesis at clef ll4ir</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1391/26-CR.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,446.53,462.23,34.06,7.86;6,146.91,473.19,286.86,7.86;6,276.49,484.15,121.92,7.86">Working Notes of CLEF 2015 -Conference and Labs of the Evaluation forum</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015. 2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="6,138.35,505.57,342.25,7.86;6,146.91,516.53,333.68,7.86;6,146.91,527.49,333.68,7.86;6,146.91,536.18,333.68,10.13;6,146.91,549.41,333.18,8.12;6,146.91,561.01,80.03,7.47" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,285.16,505.57,195.43,7.86;6,146.91,516.53,145.79,7.86">Ideas for a standard ll4ir extension -living labs from a system operator&apos;s perspective</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1609/16090591.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,222.98,527.49,257.62,7.86;6,146.91,538.45,69.56,7.86;6,387.81,538.45,92.79,7.86;6,146.91,549.41,31.91,7.86">Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09-08">5-8 September, 2016. 2016</date>
			<biblScope unit="volume">1609</biblScope>
			<biblScope unit="page" from="591" to="592" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="6,138.35,570.83,342.24,7.86;6,146.91,581.79,333.67,7.86;6,146.91,592.75,333.68,7.86;6,146.91,603.71,333.68,7.86;6,146.91,614.67,333.68,8.12;6,146.91,626.27,198.70,7.47" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,285.38,570.83,195.21,7.86;6,146.91,581.79,166.75,7.86">Popularity ranking for scientific literature using the characteristic scores and scale method</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec25/papers/THKoeln-GESIS-O.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,463.04,581.79,17.55,7.86;6,146.91,592.75,232.86,7.86;6,349.91,603.71,130.68,7.86;6,146.91,614.67,184.85,7.86">Special Publication 500-321. National Institute of Standards and Technology</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2016">November 15-18, 2016. 2016</date>
			<biblScope unit="volume">2016</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of The Twenty-Fifth Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="6,138.35,636.09,342.24,7.86;6,146.91,647.05,291.07,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,237.44,636.09,243.16,7.86;6,146.91,647.05,136.91,7.86">A Living Lab Evaluation Envirtonment for Academic Document Repositories. Master&apos;s thesis</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Bonn</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
