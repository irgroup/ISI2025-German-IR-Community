<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.58,115.90,312.19,12.68;1,276.32,133.83,62.72,12.68">Contextualized PACRR for Complex Answer Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.21,171.71,73.60,8.80"><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval Lab Georgetown University Washington DC</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.94,171.71,61.23,8.80"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
							<email>ayates@mpi-inf.mpg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,378.10,171.71,34.58,8.80"><forename type="first">Kai</forename><surname>Hui</surname></persName>
							<email>khui@mpi-inf.mpg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Max Planck Institute for Informat-ics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.58,115.90,312.19,12.68;1,276.32,133.83,62.72,12.68">Contextualized PACRR for Complex Answer Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">37BF2DD982F70B68C4221B41EFE3B2DB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we present our submission to the TREC Complex Answer Retrieval (CAR) task. Our approach uses a variation of the Position-Aware Convolutional Recurrent Relevance Matching (PACRR) <ref type="bibr" coords="1,163.11,334.40,9.72,7.92" target="#b1">[2]</ref> deep neural model to re-rank passages. Modifications include an expanded convolutional kernel size, and contextual vectors to capture heading type (e.g. title), heading frequency, and query term occurrence frequency. We submitted three runs for human relevance judgments by TREC varying which contextual vectors are included, and the number of negative samples used when training. Our approach yields a MAP of 0.241, R-Prec of 0.321, and MRR of 0.520 when using the term occurrence frequency run in the lenient evaluation environment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most existing research in question answering has focused on the retrieval of answers to questions that have a single answer. Complex Answer Retrieval (CAR) aims to answer questions that have varied, multi-faceted answers. For instance, somebody who searches for "What is the life cycle of a green sea turtle?" probably expects several paragraphs that describing the birth, maturity, migration, and death of the creature. A system that could pull the information for each facet from the best source would results in a complete answer to the user's question, and would save the user the time of searching through these sources themselves. The benefits are even more clear when controversial questions are asked. For instance, a question like "What effect will the new health care plan have on my premiums?" would ideally pull a variety of opinions from reputable sources, and let the user make judgments about the merits of each take.</p><p>The TREC CAR task aims to encourage research into this area by providing benchmarks and a common dataset. The task uses Wikipedia as both a collection of documents and a source of queries. Headings within an article are used as queries. For instance, the article titled "Green Sea Turtle" with the headings in Figure <ref type="figure" coords="2,167.11,340.94,4.98,8.80" target="#fig_0">1</ref> has queries of "Green Sea Turtle » Taxonomy", "Green Sea Turtle » Ecology and behavior » Life cycle", etc. Each paragraph in Wikipedia is treated as an independent document; they must be treated independently of their context to avoid overfitting approaches to Wikipedia itself. There is an implicit relevance between each heading and the paragraphs that appear under it, which serves as an enormous (albeit weak) source of training data. TREC CAR collects human relevance judgments for system comparisons.</p><p>Throughout the paper we use the following terminology. The heading chain refers to a single path in the heading hierarchy of a document. The task treats heading chains as queries. For simplicity, we refer to every element within the heading hierarchy as a heading, even though the first is the article title. Title is reserved for the first heading, and main heading describes the last heading in a given chain. Any headings between them are called intermediate headings. A heading chain will always have a title and main heading, but does not necessarily have any intermediate headings. Example queries are given in Table <ref type="table" coords="2,434.73,509.19,3.87,8.80">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Example queries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Title</head><p>Intermediate Heading(s) Main Heading q turtle "Green Sea Turtle"</p><p>["Ecology and behavior"] "Life cycle" q us-hist "History of the United States" ["20th Century"] "Imperialism" q disturb "Disturbance (ecology)" [] "Cyclic disturbance" q medical "Medical tourism"</p><p>["Destinations", "Europe"] "Finland"</p><p>We identify that a central challenge of the CAR task is addressing discourse context. Individual paragraphs of well-written articles will often omit what could otherwise be considered critical text. For instance, only the first of the four relevant paragraphs for q turtle use the phrase "Green sea turtle" in its entirety, with subsequent paragraphs simply using the head noun "turtle". Other examples use pronouns, or are otherwise able to express the ideas with no matching terms. Since the coreferent term appears in separate paragraphs and it is necessary to treat paragraphs in isolation, coreference resolution cannot be used to work around this problem. Headings can also introduce context themselves. For instance, relevant paragraphs for "History" are unlikely to use the word, but instead simply present historical events.</p><p>Related to the problem of discourse context is the problem of heading utility. We observe that headings can serve a variety of functions in an article. Intuition suggests that titles should appear in relevant paragraphs, but this breaks down due to discourse context. Furthermore, some titles will never appear in the text verbatim (aside from, perhaps, the lead paragraph) because they include structure. For instance, q us-hist and q eco provide specifiers from what would otherwise be the overly-general or ambiguous topics of "History" and "Disturbance", respectively.</p><p>The remainder of this paper is organized as follows. We first present related work and existing benchmarks. We then motivate and describe our methodology. Finally, we present and discuss our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Although Complex Answer Retrieval is a new task in TREC 2017, some work has already conducted on the CAR dataset. Some researchers presented a survey of prominent ranking and query expansion approaches, with the intent for the results to serve as a baseline for CAR participants <ref type="bibr" coords="3,388.04,462.70,9.96,8.80" target="#b3">[4]</ref>. They found that the deep neural model Duet <ref type="bibr" coords="3,257.88,474.65,10.51,8.80" target="#b2">[3]</ref> outperformed other approaches, including Okapi BM25, cosine similarity with TF-IDF and word embeddings, and a learning-torank approach. They also propose a 'safe environment' for training in which the set of candidate paragraphs is limited, allowing for faster experimentation. Others have successfully used the CAR dataset to evaluate a neural reinforcement query reformulation approach <ref type="bibr" coords="3,270.52,534.43,9.96,8.80" target="#b4">[5]</ref>. They found that recurrent neural networks marginally outperformed a version of their approach that used convolutional neural networks.</p><p>Recently, improvements have been observed for ad-hoc information retrieval using neural methods. DRMM uses term occurrence histograms and a dense deep neural architecture to predict document relevance <ref type="bibr" coords="3,377.94,596.28,9.96,8.80" target="#b0">[1]</ref>. Duet jointly models local and global document interactions using convolutional neural networks <ref type="bibr" coords="3,467.31,608.24,9.96,8.80" target="#b2">[3]</ref>. MatchPyramid uses a query-document similarity matrix and a convolutional hierarchy <ref type="bibr" coords="3,179.75,632.15,9.96,8.80" target="#b5">[6]</ref>. Most recently, the PACRR architecture was introduced, which uses convolutional filters and k-max pooling to achieve state-of-the-art ad-hoc neural retrieval results <ref type="bibr" coords="3,235.97,656.06,9.96,8.80" target="#b1">[2]</ref>. Due to the observed effectiveness of neural IR reranking techniques <ref type="bibr" coords="4,441.85,141.88,10.51,8.80" target="#b0">[1,</ref><ref type="bibr" coords="4,454.03,141.88,7.75,8.80" target="#b5">6,</ref><ref type="bibr" coords="4,463.44,141.88,7.75,8.80" target="#b2">3,</ref><ref type="bibr" coords="4,472.84,141.88,7.75,8.80" target="#b1">2]</ref> and the positive preliminary results for complex answer retrieval using neural IR techniques <ref type="bibr" coords="4,199.45,165.79,9.96,8.80" target="#b3">[4]</ref>, we present a technique technique that builds upon a stateof-the-art neural information retrieval architecture (namely, PACRR <ref type="bibr" coords="4,446.41,177.74,10.29,8.80" target="#b1">[2]</ref>). By operating on word embedding similarity scores instead of exact matches, the PACRR architecture partially addresses some discourse context problems. For example, both "green" and "sea" have a similarity score of 0.48 to "turtle", providing a weak signal in lieu of no signal. This, combined with partial n-gram matches, means that architecture is relatively effective at the CAR task with no modifications. Nevertheless, we present additional considerations and structural changes that are aimed to address the discourse context problem, the heading utility problem, and the CAR task in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query formulation</head><p>The trivial approach to formulating a query based on the heading chain is to simply concatenate all the headings. This, however, can lead to some very long queries. (The longest query observed in training data using this technique was 54 tokens long.) For some approaches, such as BM25, this is inconsequential. However, for neural IR approaches that process fixed-size query-document similarity matrices, this causes problems. Either the matrix size needs to be large enough to handle the longest query, or the query need to be reduced. Since such a large matrix size would contribute considerably to processing time, the only practical approach is to trim terms off the query.</p><p>Previous work has either taken the approach of truncating the query to a fixed size l or removing the terms with the lowest inverse document frequency (IDF), often being stopwords <ref type="bibr" coords="4,263.52,452.76,9.96,8.80" target="#b1">[2]</ref>. Neither approach is ideal here. Truncating can leave off critical details about the query. For instance, removing "Life cycle" from q turtle would over-generalize the query. Concatenating the headings in a different order could not be done in a reliable way because of the heading utility problem: it is unclear which headings are most important for a given query.</p><p>The approach we take is to remove terms by IDF. Terms in intermediate headings are removed before terms from the title and from the main heading. This is based on the intuition that the context that the middle headings brings is less significant, e.g. in q us-hist . It is worth noting that, although not ideal, only 0.6% of queries are affected by this procedure with a reasonable l = 18.</p><p>We leave further evaluation of this approach-as well as alternate approaches that challenge the concatenation assumption-to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Heading position</head><p>Under the concatenation assumption, there exists nothing structural about the model to inform about the position of each token within the heading chain. We consider this a deficiency because heading utility can certainly be influenced by the position of the heading. For instance, while not always true, titles often appear in full. Thus, we include three binary vectors as additional input to PACRR's dense layer. One indicates whether a given position corresponds to a term in the title, another if it corresponds to an term in an intermediate heading, and a third that indicates when a position belongs to the main heading. An example of these vectors for q turtle is given in Table <ref type="table" coords="5,363.99,178.71,3.87,8.80" target="#tab_0">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Heading usage frequency</head><p>One hypothesis is that headings exist on a spectrum from structural to contentdriven. In q turtle , we consider the "Ecology and behavior" and "Life cycle" headings structural because one would expect a similar pattern in other articles about organisms. "Cyclic disturbance" in q distrub would be considered content-driven because it relates to a detail exclusive to the topic of ecological disturbance. We suspect that structural headings are less likely to appear verbatim in relevant paragraphs, and instead use related language. For instance, this might include terms like "birth" or "maturity" in "Life cycle", while never using the words "life" or "cycle". On the other hand, it would be difficult to adequately describe the topic of content-driven headings without using exact terminology due to the specialized language.</p><p>To approximate this spectrum, we calculate heading usage frequency, defined as follows:</p><formula xml:id="formula_0" coords="5,253.00,530.45,108.15,22.97">f rq(h) = a∈C I(h ∈ a) |C|</formula><p>That is, the probability that a given article a in corpus C contains heading h, given the indicator function I. To include these values in the model, stratify them by fixed percentile ranges. We include a vector of length l where each value corresponds to the stratum index of the corresponding heading. (In this work, we use the following percentiles (1) 60th, (2) 90th, (3) 99th. A score of 0 indicates that the heading did not meet the 60th percentile threshold.) Values close to 0 include article titles and other content-specific headings like "Cyclic disturbance". On the other end, there are headings like "Life cycle" and "History", both of which are in the 99th percentile. Complete, case insensitive heading matches are used here, so all the terms in "History of the United States" belong to stratum 0, even though "History" belongs to the 99th percentile. Unknown headings are assumed to belong to the 0th percentile. An example of this vector for q turtle is given in Table <ref type="table" coords="6,162.16,154.80,3.87,8.80" target="#tab_0">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Term occurrence</head><p>Term occurrence takes a local perspective on estimating heading utility. For any given term t, this feature estimates how likely it is to occur in a relevant paragraph under a heading with that term. That is,</p><formula xml:id="formula_1" coords="6,218.20,244.54,177.76,26.60">occ(t) = h∈C p∈rel(h) I(t ∈ h ∧ t ∈ p) h∈C I(t ∈ h)</formula><p>where C is the training corpus, h is a heading, and rel(h) retrieves relevant paragraphs for a given heading. Here, term matches are is determined by Porter Stemmer, with numerals folded down to a single digit placeholder. The term occurrence estimation is included in the model as another contextual vector, where each value is the occ value for the corresponding term. Unknown values are assumed to have a value of 0. An example is shown as occ_prob in Table <ref type="table" coords="6,472.85,339.96,3.87,8.80" target="#tab_0">2</ref>.</p><p>Since the PACRR model "sees" values as word embedding similarity scores that allow for inexact term matches, we also an extension to term occurrence. As hypothesized with the heading usage frequency, structural headings are less likely to appear in relevant paragraphs than content-based headings. To account for these observations, we expand the definition of term matches for the purpose of the term occurrence score as follows. For any heading with a heading usage frequency greater than threshold t f rq , we also include matches for the top n exp query-expanded terms. Query expansion is accomplished by taking the 50 terms with the highest BM25 score from all relevant documents in the training corpus. An example is shown as occ_prob_exp in Table <ref type="table" coords="6,343.52,459.52,3.87,8.80" target="#tab_0">2</ref>. Notice how the value for "life" increases significantly when expansion is enabled. This indicates that paragraphs under "life" headings are not likely to contain the word itself, but are likely to contain words that are similar to it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We submitted three runs to TREC CAR 2017: nn6_pos, nn4_pos_hperc, and nn6_pos_tprob. All three include the heading position contextual vector (pos). One includes the heading usage frequency vector (hprec), and another includes the query-expanded term occurrence vector (tprob). We also varied the number of negative training samples per positive sample with values of 4 (nn4 ) and 6 (nn6 ). These configurations produced the best results in the 'safe environment' described in <ref type="bibr" coords="6,191.49,620.19,9.96,8.80" target="#b3">[4]</ref>. We report our system performance in terms of Mean Average Precision (MAP), R-Precision (R-Prec), and Mean Reciprocal Rank (MRR).</p><p>TREC provided system performance results for three environments. Automatic uses implicit paragraph relevance, based on paragraph containment under a given heading. Manual judgments grade results based on the following grades: must be mentioned (3); should be mentioned (2); can be mentioned (1); roughly on topic (0); non-relevant (-1); and trash (-2). The lenient variation of the manual evaluation treats paragraphs that are 'roughly on topic' as positive by shifting all the grades by 1, except trash which remains at -2.</p><p>We present our results for each run and environment in Table <ref type="table" coords="7,429.74,178.71,3.87,8.80" target="#tab_1">3</ref>. All three runs perform comparably in each environment; a paired t-test indicates that there is no statistically significant difference between any two pairs of runs within a given environment. However, we observe that nn4_pos_hperc performs marginally better than the others in the automatic and manual environments, while nn6_pos_tprob performs the best in the lenient environment by a larger margin. This could be attributed to the query expansion approach when calculating the term probabilities; the expansion includes terms that may be on topic, whereas the other approaches have no mechanism to capture terms that are roughly on topic. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we presented a deep neural approach for the TREC answer retrieval task. We showed that including a measure of term occurrence frequency yields improved results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,156.50,281.57,302.36,7.93;2,245.93,115.84,123.50,151.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example headings found in the Wikipedia article 'Green sea turtle'</figDesc><graphic coords="2,245.93,115.84,123.50,151.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,168.93,209.84,275.64,102.64"><head>Table 2 .</head><label>2</label><figDesc>Example contextual vectors for q turtle</figDesc><table coords="5,168.93,233.80,275.64,78.67"><row><cell></cell><cell></cell><cell cols="8">Green Sea Turtle Ecology and behavior Life cycle</cell></row><row><cell></cell><cell>pos_title</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>pos_inter</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell>.</cell><cell>pos_main</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>frq_strata</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell></cell><cell>occ_prob</cell><cell cols="3">0.6 0.5 0.6</cell><cell>0.1</cell><cell>0.8</cell><cell>0.2</cell><cell cols="2">0.1 0.3</cell></row><row><cell></cell><cell cols="4">occ_prob_exp 0.6 0.5 0.7</cell><cell>0.1</cell><cell>0.8</cell><cell>0.3</cell><cell cols="2">0.9 0.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,139.63,316.57,336.09,176.65"><head>Table 3 .</head><label>3</label><figDesc>Results for each of the three runs under various evaluation environments.</figDesc><table coords="7,214.91,338.80,185.55,154.43"><row><cell>Run</cell><cell>MAP</cell><cell>R-Prec</cell><cell>MRR</cell></row><row><cell>Automatic</cell><cell></cell><cell></cell><cell></cell></row><row><cell>nn6_pos</cell><cell>0.144</cell><cell>0.111</cell><cell>0.216</cell></row><row><cell>nn4_pos_hperc</cell><cell>0.148</cell><cell>0.116</cell><cell>0.224</cell></row><row><cell>nn6_pos_tprob</cell><cell>0.140</cell><cell>0.107</cell><cell>0.213</cell></row><row><cell>Manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>nn6_pos</cell><cell>0.197</cell><cell>0.209</cell><cell>0.417</cell></row><row><cell>nn4_pos_hperc</cell><cell>0.201</cell><cell>0.213</cell><cell>0.418</cell></row><row><cell>nn6_pos_tprob</cell><cell>0.198</cell><cell>0.206</cell><cell>0.419</cell></row><row><cell cols="2">Manual (lenient)</cell><cell></cell><cell></cell></row><row><cell>nn6_pos</cell><cell>0.235</cell><cell>0.311</cell><cell>0.499</cell></row><row><cell>nn4_pos_hperc</cell><cell>0.234</cell><cell>0.311</cell><cell>0.505</cell></row><row><cell>nn6_pos_tprob</cell><cell>0.241</cell><cell>0.321</cell><cell>0.520</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,634.83,342.24,7.92;7,146.91,645.79,333.68,7.92;7,146.91,656.74,267.72,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,309.49,634.83,171.10,7.92;7,146.91,645.79,50.60,7.92">A deep relevance matching model for adhoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,220.99,645.79,259.60,7.92;7,146.91,656.74,164.77,7.92">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,119.62,342.24,7.92;8,146.91,130.58,333.68,7.92" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Melo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03940</idno>
		<title level="m" coord="8,345.97,119.62,134.62,7.92;8,146.91,130.58,170.32,7.92">A position-aware deep model for relevance matching in information retrieval</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,138.35,141.54,342.25,7.92;8,146.91,152.50,333.68,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,289.02,141.54,191.57,7.92;8,146.91,152.50,147.86,7.92">Learning to match using local and distributed representations of text for web search</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,315.04,152.50,108.68,7.92">Proceedings of WWW 2017</title>
		<meeting>WWW 2017</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,163.46,342.24,7.92;8,146.91,174.42,294.24,7.92" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,351.05,163.46,129.54,7.92;8,146.91,174.42,32.06,7.92">Benchmark for complex answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
		<idno>CoRR abs/1705.04803</idno>
		<ptr target="http://arxiv.org/abs/1705.04803" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,185.37,342.24,7.92;8,146.91,196.33,94.30,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,239.66,185.37,240.93,7.92;8,146.91,196.33,11.13,7.92">Task-oriented query reformulation with reinforcement learning</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,178.90,196.33,33.65,7.92">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,207.29,342.24,7.92;8,146.91,218.25,187.18,7.92" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,333.69,207.29,146.90,7.92;8,146.91,218.25,62.00,7.92">A study of matchpyramid models on ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<idno>CoRR abs/1606.04648</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
