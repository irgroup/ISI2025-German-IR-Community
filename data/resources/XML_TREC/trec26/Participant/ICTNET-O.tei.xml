<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,174.00,109.67,247.78,11.90">ICTNET at TREC2017 OpenSearch Track</title>
				<funder ref="#_4y2Pzss">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
				<funder ref="#_HbKYCzj #_KsU2zVR">
					<orgName type="full">NSF Foundation of China</orgName>
				</funder>
				<funder ref="#_NcgeM4Q #_MvN6gFq">
					<orgName type="full">National Basic Research Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,110.16,141.67,28.21,8.61"><forename type="first">Peng</forename><surname>Xu</surname></persName>
							<email>xupeng@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,148.09,141.67,29.63,8.61"><forename type="first">Long</forename><surname>Bai</surname></persName>
							<email>bailong@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.20,141.67,47.67,8.61"><forename type="first">Suiyuan</forename><surname>Zhang</surname></persName>
							<email>zhangsuiyuan@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.32,141.67,34.22,8.61"><forename type="first">Fang</forename><surname>Yang</surname></persName>
							<email>yangfang@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.72,141.67,42.87,8.61"><forename type="first">Zhibin</forename><surname>Zhang</surname></persName>
							<email>zhangzhibin@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,340.66,141.67,44.45,8.61"><forename type="first">Xiaoming</forename><surname>Yu</surname></persName>
							<email>yuxiaoming@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.69,141.67,39.49,8.61"><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
							<email>jinxiaolong@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,439.44,141.67,42.40,8.61"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,174.00,109.67,247.78,11.90">ICTNET at TREC2017 OpenSearch Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">275EB515672005689B0D562082DE1C50</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The OpenSearch track explores The "Living Labs" evaluation paradigm for IR that involves real users of operational search engines. The task in the track will continue/expand upon the ad hoc Academic Search task of TREC 2016. It is difficult to define who is better in the ranking experimentation, because the real users in the natural environments search a key word with their own purpose. The best way to evaluate two ranks is let the real users make use of them. So TREC 2017 Open Search Track provides this platform which is a new form to assess the ranks good or bad.</p><p>The Open Search provide the training queries, testing queries and candidates documents, but it did not tell us which document is more relevant to a specific query which is necessary to train our model. So first we need to crawl the rank of all the documents on each query from an existing web search engine. Then we try a serial of features in order to find the relevance between the queries and the documents. And we also designed scoring rules to give each document a score. Finally, we used XGBoost to train models for each training query and then found a way to predict testing data based on the models.</p><p>Feedback data is the key to this track. We find a simple way to integrate the feedback into our model. Unfortunately, there is so little feedback that can hardly improve the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Crawl Training Data</head><p>Since we only know the candidate documents of each query, we should use external information to rank candidate documents. We crawl the top 100 documents for each query from real search engine SSOAR. If the number of returned documents is less than 100, we just retain all the documents.</p><p>We discover that the training data and SSOAR returned documents contain various languages, so we uniformly translate them into English by Google Translate. Then we try to match candidate documents with SSOAR returned documents in order to get a ranked document list.</p><p>We use the function below to measure the similarity of a candidate document and a returned document.</p><p>( , ) = # ℎ # Practically, we set a threshold at 0.6 to judge if two documents match, which we find all candidate documents match with a distinct returned document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">train the model</head><p>We use 3 types of features to train XGBoost models. topic model similarity, sentence embedding similarity and document meta-data features are used. In order to learn scoring functions, each ranked document is given a score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Topic Model</head><p>Topic Model is an effective way to gain semantic similarities of documents 2 . We considered several models and finally decided to use Latent Dirichlet Allocation (LDA) <ref type="bibr" coords="1,356.64,581.26,3.15,5.54" target="#b3">3</ref> . We use all the training documents to learn the model and infer the topic distributions of each document and query.</p><p>Then we can get the similarity just by calculating the cosine similarity of two topic distributions.</p><formula xml:id="formula_0" coords="1,87.60,617.54,292.54,33.86">( , ) = ( ) • ( ) || ( )|| • || ( )||<label>Where</label></formula><p>( ) refers to the topic distribution of document .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Document Embedding</head><p>We use pre-trained 300-dimensions vectors generated by word2vec 4 as word embedding. Then we use bag-of-words model to represent a document, which embedding is the average of all word embeddings occur in it. Again, we just use cosine similarity to measure the similarity of document-query pair.</p><formula xml:id="formula_1" coords="2,87.60,174.02,273.34,35.78">( , ) = • || || • || || 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Meta data</head><p>We use author, publish time and type and other five meta data as discrete features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Scoring Rules</head><p>We give each ranked document a score in order to learn a scoring function. The score of a candidate document is decided by its position in the returned document list given by SSOAR. This way is like last year's paper <ref type="bibr" coords="2,135.36,255.58,3.15,5.54" target="#b5">5</ref>  ranked position between 50 to 100  score = 0: document isn't in the returned document list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">predict testing queries</head><p>Since we just train models for each training query, how to predict document scores on a testing query becomes a problem. We find the top 5 training queries that is most similar to the testing query, and use their models to approximate the testing query model. The final score of a document on a testing query is the average of its scores given by the five training query models. Cosine similarity between query embeddings is used to determine the relevance of a testing query and a training query.</p><p>If a training query is less similar to the testing query, it is also less credible, so we set a threshold at 0.5 to select credible training query models for prediction. A training query model should be abandoned if its relevance to the testing query is less than the threshold, though it may already be the top 5 most similar to the testing query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">exploit feedback data</head><p>Generally speaking, feedback is essential to our system. If a document gets "win", we should increase its score. We will decrease its score if it gets "loss". The score should be maintained unchanged if it gets "tied". Then we will retrain our models to get a better performance. Unfortunately, we get too many "tied" that could hardly improve our system.  <ref type="figure" coords="2,199.03,599.11,21.65,8.61">above</ref>, training data results are too small, so the way to exploit feedback is hard to have an impact in train models. Maybe the data that we crawled is from SSAOR, so there are many ties in testing data results. If that is the case, we should use another authoritative web search engine ranks as training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion&amp; Acknowledgements</head><p>We use external information on the Internet to train models on training data, and use them to predict ranks on testing data. We also considered feedback to improve our system. We also find some shortcomings of our system. First, more external information could be used such as Google Scholar. Second, we train a model for each training query, which may not make full use of training data. If we separate queries into serval types, and learn a model for each type of queries, our system may be more robust. Finally, we did not make good use of feedback because of the lack of feedback.</p><p>In a word, we think we have done our best so far, and we expect to get a better result next time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,280.08,114.50,7.33,8.72;2,290.40,107.06,5.43,8.72;2,305.52,128.76,4.22,6.02;2,87.60,138.07,23.79,8.61;2,133.20,138.07,228.45,8.61;2,379.92,138.07,26.22,8.61;2,428.40,138.07,14.04,8.61;2,468.24,138.07,39.56,8.61;2,87.60,150.31,217.07,8.61"><head></head><label></label><figDesc>word in document d which consists words. and represents embeddings of the document and the word respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,138.24,256.87,131.62,8.61;2,87.60,267.32,146.25,9.74;2,271.68,268.39,119.65,8.61;2,87.60,278.60,146.25,9.74;2,271.68,279.67,124.46,8.61;2,87.60,290.12,146.25,9.74;2,271.68,291.19,129.24,8.61;2,87.60,301.64,164.49,9.74;2,271.68,302.71,129.49,8.61;2,87.60,313.16,146.25,9.74"><head></head><label></label><figDesc>. The scoring rules are as follows:  score = 5.0 -0.05 × position: ranked position between 1 to 5  score = 5.0 -0.10 × position: ranked position between 6 to 10  score = 4.5 -0.10 × position: ranked position between 11 to 20  score = 2.5 -(1.0/30) × position: ranked position between 21 to 50  score = 1.0 -0.01 × position:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,105.12,517.75,397.63,89.97"><head></head><label></label><figDesc>results are shown in tables below.</figDesc><table coords="2,105.12,529.03,397.63,78.69"><row><cell></cell><cell></cell><cell cols="2">Training Data Results for SSOAR</cell><cell></cell><cell></cell></row><row><cell>OUTCOME</cell><cell>WINS</cell><cell cols="2">LOSSES</cell><cell>TIES</cell><cell>IMPRESSIONS</cell></row><row><cell>0.36</cell><cell>3</cell><cell>4</cell><cell></cell><cell>22</cell><cell>29</cell></row><row><cell></cell><cell></cell><cell cols="2">Testing Data Results for SSOAR</cell><cell></cell><cell></cell></row><row><cell></cell><cell>OUTCOME</cell><cell>WINS</cell><cell>LOSSES</cell><cell>TIES</cell><cell>IMPRESSIONS</cell></row><row><cell>Round 1</cell><cell>0.43</cell><cell>5</cell><cell>9</cell><cell>2588</cell><cell>2602</cell></row><row><cell cols="2">As shown in the figure</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>We would like to thank all organizers and assessors of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is sponsored by the <rs type="funder">National Basic Research Program of China</rs> (the <rs type="programName">973 program</rs>) under grant numbers <rs type="grantNumber">2014CB340401</rs> and <rs type="grantNumber">2014CB340406</rs>, This work is also supported by <rs type="funder">National Key Research and Development Program of China</rs> under grant <rs type="grantNumber">2016YFB1000902</rs>, and <rs type="funder">NSF Foundation of China</rs> under grants <rs type="grantNumber">61572473</rs> and <rs type="grantNumber">61772501</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_NcgeM4Q">
					<idno type="grant-number">2014CB340401</idno>
					<orgName type="program" subtype="full">973 program</orgName>
				</org>
				<org type="funding" xml:id="_MvN6gFq">
					<idno type="grant-number">2014CB340406</idno>
				</org>
				<org type="funding" xml:id="_4y2Pzss">
					<idno type="grant-number">2016YFB1000902</idno>
				</org>
				<org type="funding" xml:id="_HbKYCzj">
					<idno type="grant-number">61572473</idno>
				</org>
				<org type="funding" xml:id="_KsU2zVR">
					<idno type="grant-number">61772501</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,100.07,166.10,248.17,6.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,198.01,166.10,136.32,6.77">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName coords=""><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,350.88,166.10,156.99,6.77;3,87.60,174.98,267.13,6.77" xml:id="b1">
	<monogr>
		<title level="m" coord="3,350.88,166.10,156.99,6.77;3,87.60,174.98,212.85,6.77">KDD &apos;16 Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,99.36,184.10,375.37,6.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,195.65,184.10,89.86,6.77">Latent dirichlet allocation[J]</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,290.74,184.10,121.04,6.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,98.88,192.98,408.98,6.77;3,87.60,201.86,184.10,6.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,200.90,192.98,145.99,6.77">Online learning for Latent Dirichlet Allocation</title>
		<author>
			<persName coords=""><forename type="first">M D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,358.38,192.98,149.48,6.77;3,87.60,201.86,59.35,6.77">International Conference on Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="856" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,100.07,210.74,407.60,6.77;3,87.60,219.62,334.81,6.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,220.33,210.74,287.34,6.77;3,87.60,219.62,61.45,6.77">Sensing spatial distribution of urban land use by integrating points-of-interest and Google Word2Vec model[C]</title>
		<author>
			<persName coords=""><forename type="first">Yao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liu</forename><surname>Penghua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,154.33,219.62,185.84,6.77">International Journal of Geographical Information Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,100.07,228.50,407.86,6.77;3,87.60,237.62,208.00,6.77" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lillis</surname></persName>
		</author>
		<title level="m" coord="3,214.55,228.50,293.37,6.77;3,87.60,237.62,123.46,6.77">BJUT at TREC 2016 OpenSearch Track: Search Ranking Based on Clickthrough Data. The Twenty-Fifth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
