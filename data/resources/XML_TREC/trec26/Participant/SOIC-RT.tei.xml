<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,75.84,55.87,468.38,20.73;1,192.58,83.77,234.89,20.73">Fast NLP-based Pattern Matching in Real Time Tweet Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,249.78,115.51,47.58,9.50"><forename type="first">Zheng</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics, Computing, and Engineering</orgName>
								<orgName type="institution">Indiana Unviersity Bloomington</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,306.45,115.51,63.84,9.50"><forename type="first">John</forename><surname>Wolohan</surname></persName>
							<email>jwolohan@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics, Computing, and Engineering</orgName>
								<orgName type="institution">Indiana Unviersity Bloomington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,75.84,55.87,468.38,20.73;1,192.58,83.77,234.89,20.73">Fast NLP-based Pattern Matching in Real Time Tweet Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B72663748B74FC5C0551C0E8ECEA0CD2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>real-time summarization</term>
					<term>social media recommendation</term>
					<term>ad-hoc information retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social media users are willing to obtain information from online social streaming services. Everyday people receive news notifications from mobile devices and figure out information which are new and interesting to them. Therefore, it is necessary to learn a recommendation mechanism to see how to attract users attention most by providing most useful news or information to them. This year, TREC (Text REtrieval Conference) offers a Real Time Summarization track to explore online user reading preference on Twitter, one of the largest social media platform so far, to figure out recommendation patterns best suitable for users.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>With the exploration of social media, everyday people are facing with numerous news from all kinds of online streaming services. It causes a huge problem for online users to extract the real needed news as they are drowned in huge amount of irrelevant noisy news. Therefore, it is necessary to come up with a model that can help to filter out useful news in a quickly and accurate manner. Moreover, as information updates so fast, time issue also needs to be considered. Yesterday's hot new may be no longer interested by users today, such as sports news; duplicate news are also not trigger users' interest because they have already got the information. Considering these, understanding how to make real time recommendations to users accurately has huge potentiality and still needs a long way to go.</p><p>In order to copy with this challenge, since 2016, TREC conference merged previous the Microblog (MB) track, which ran from 2010 to 2015, and the Temporal Summarization (TS) track, which ran from 2013 to 2015 together to form a new track named as 'Real Time Summarization' (RTS). The overall goal for this merged track is to find the most interesting tweets for users in a timely manner. In this year's RTS track, there are two scenarios in total including Scenario A (push notifications) and Scenario B (email digest) <ref type="bibr" coords="1,174.86,613.30,10.79,8.64" target="#b6">[7]</ref>:</p><p>• Scenario A (push notifications): Tweets which are regarded as relevant and novel to users' interest profile will be pushed to the user as notifications in a timely manner via TREC RTS evaluation broker via a REST API. Then these notifications will be immediately routed to the mobile device of a group of human assessors. The human assessors can therefore judge the notifications accuracy as well as time efficiency. As users are not willing to receive too many notifications everyday, there is a upper bound limitation of the number of notifications. • Scenario B (email digest)): In this scenario, given a user's interest profile, we need to generate a daily tweet recommendation list for him/ her. The list should be no more than 100 tweets per day and should be push to users in a short time after a day is over ideally. As the same as Scenario A, the accuracy of the generated daily tweet recommendation list is also based on the human assessors' judgment. We can consider previous tweets influence on users but can't involve in future tweets. i.e. when we generate recommendation tweet list, we can consider today's tweets but can never use statistics from tomorrow's tweets. The whole tasks started from July 29 2017, UTC 00:00 to August 5 2017, UTC 23:59:59. During this period, we 'listened ' to the Twitter sample stream using the Twitter streaming API to get sampled real time posted tweets. We are also offered a batch of topics represented as users' interest profile. all our models are built based on these two datasets.</p><p>Our contribution of this track is threefold: First of all, we build up a NLP-based model to match streaming tweets with user's interest profile and recommend tweets back to users in real time; second, by leveraging information retrieval language models, we generate a daily tweet ranking list based on user's interest profile as well and recommend a daily tweet digest to users; third, the model we build up can be generalized to other social media dataset and applied to other online platforms as well.</p><p>The rest of the paper are organized in following structures: Section 2 reviews previous work in the RTS track last year; Section 3 explains the details of our models for both scenarios; Section 4 shows the evaluation result from human assessors via a bunch of cutting edge evaluation metrics; Section 5 points out the limitation of our current work and future improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In order to construct better model for solving the track tasks, we look into previous work as well as combine our previous related work together to come up with novel strategies to cope with Tweet real time summarization.</p><p>As a tweet content is short and less than 140 words, one basic approach is tweet content expansion. <ref type="bibr" coords="1,503.82,682.27,11.62,8.64" target="#b0">[1]</ref> uses Google retrieved search pages as external resources to enrich tweet content, which turns out a positive result for tweet recommendation. <ref type="bibr" coords="2,79.60,79.53,11.62,8.64" target="#b2">[3]</ref> also uses Google Search Engine retrieved pages as an external resource for query expansion. Moreover, it also consider the web links embedded in tweet content and use their source page content to expand tweet content as weel. In previous work for solving RTS tasks, <ref type="bibr" coords="2,223.30,123.37,16.60,8.64" target="#b10">[11]</ref> considers text categorization as well as text clustering via classifiers such as SVM and non-negative matrix factorization to minimize the error classification rate. And <ref type="bibr" coords="2,166.01,156.24,37.64,8.64">[13; 8; 4]</ref> also consider clustering structures as an external latent support for tweet content pattern recognition.</p><p>Besides query expansion, <ref type="bibr" coords="2,163.97,189.23,11.62,8.64" target="#b1">[2]</ref> uses JS-divergence to estimate relevance and redundancy between tweets and topics. It also applies a hybrid TF-IDF strategy to compute the salience score for tweets towards topics. <ref type="bibr" coords="2,159.29,222.10,11.62,8.64" target="#b5">[6]</ref> divides the whole process into an offline part and an online part. In offline part, it trains a relevance measurement model and a redundancy detection model. And the online part calculates 11 different features to represent both tweets and topics as the input for the model built up in offline part. <ref type="bibr" coords="2,121.02,276.90,11.62,8.64" target="#b8">[9]</ref> defines a set of filtering functions to filter out the most relevant and salient tweets towards a given topic. <ref type="bibr" coords="2,48.96,298.82,16.60,8.64" target="#b11">[12]</ref> however uses a KL divergence language model with both Jelinek-Mercer Smoothing and Dirichlet Smoothing as similarity algorithms as well as parameter tuning process to finalize its language model. <ref type="bibr" coords="2,132.52,331.69,11.62,8.64" target="#b4">[5]</ref> also builds up a set of features based on bag-of-word model and semantic structure of sentences. Afterwards it applies a Time-adjusted Dynamic Thresholdbased model to generate recommendations for given topics.</p><p>[10] leverages an idf -based term weighting scheme as well as Jaccard similarity method to work on lexical level of tweet contents first. Based on a time dependent evaluation function, it therefore filters out the most relevant tweets towards topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODS A. Scenario A</head><p>In Scenario A, it requires everyday participants can push at most 10 tweets for users given a topic due to users are not willing to receive too many notifications everyday. Hence, there are three challenges existed. One challenge is timeliness. Users are not willing to receive tweets after it posted more than a certain time cause their interest towards tweets will decay with time even though the tweets are very relevant to their interest topics. Another challenge is relevance calculation. As tweets are short documents with no more than 140 words. Simply applying language models can cause huge error because the short-length text may contain hidden concepts or multiple semantic meanings. For example, if a tweet contains the content "Wow Apple, niceTech", it may have a positive attitude towards Apple Inc instead of the apple fruit. Therefore, how to tackle the short-length text challenge is also worthy to think about. The third challenge is novelty. As users can only receive limited amount of notifications each day, they are not willing to be bothered by notifications with similar content.</p><p>To solve all the challenges above, we come up with a fast-NLP based filtering model which can recognize tweet content pattern in real time and compute the similarity closeness with user interest profiles. We conclude our model into the following 4 steps. The details of the work flow is showed in Figure <ref type="figure" coords="2,348.50,373.02,3.74,8.64" target="#fig_0">1</ref>.</p><p>First step is query reconstruction. Based on the task, a topic (query) is formed with three fields including 'narrative', 'title', 'description'. Title is the main keywords of a topic, which only contains several words only such as 'HPV vaccine side effects'. Description extends the title a little bit to briefly introduce what a user is looking for towards the topic. For example, to the title above, its related description is 'Information concerning possible side effects of the HPV vaccine'. Narrative is a short paragraph to describe the purpose of the topic and why a user is interested in the topic. It contains one or several sentences to describe and its content length a little bit longer than the rest two fields.</p><p>Each field refers to different information, to best capture users' interest, we use a linear combination of these three fields to finalize the query for a given topic. We can tune all the weights or arbitrarily assign weights based on empirical experience.</p><formula xml:id="formula_0" coords="2,334.11,587.59,221.88,8.74">Q = αQ(title) + βQ(description) + γQ(narrative)</formula><p>Second, as both tweets and topics are short documents, it is necessary to expand their content to retrieve more semantic meaning and content information. There are multiple ways for content expansion. By comparing different techniques such as Google Search Result Page or using Word2vec on large existing corpus to retrieve synonyms, we decide to use WordNet as an external resource to extend our both tweet content and topic content.</p><p>Third step is NLP based entity filtering. As both tweets and topics are unstructured text information, in order to extract quantitative information out of them, NLP related methods are applied. Using POS tagger, given a piece of text, we can extract all nouns, adjectives and verbs from it which contain most of meaning of the text. Moreover, by leveraging bag-of-word model, besides 1-gram words, we also extract 2-gram words as these words contain structural relationship as well as more semantic meanings of the sentence. In the end, after NLP based entity filtering step, both tweets and topics are represented as a batch of 1-gram and 2-gram entities. In the end, we can project both topics and tweets into a high dimensional space where each dimension refers to an entity.</p><p>Therefore, the fourth step is to build up a similarity calculation function to quantify the timeliness, relevance, and novelty of each coming tweet. We define the function f as:</p><formula xml:id="formula_1" coords="3,48.96,245.87,268.54,47.93">f (tweet, topic) = (cos(tweet, topic)- N i=1 cos(tweet, C) N )D(t) D(t) = 1 -e -(t-t 0 ) γ</formula><p>where D(t) is a time decay function, cos() refers to the cosine similarity between two pieces of text and C is the existing tweet collection. By leveraging similarity function f, we can quantitatively evaluate each tweet and push it into a tweet temporary repository C.</p><p>In every time interval T, we push the tweets with highest similarity score of a topic to users and empty the tweet collection repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scenario B</head><p>In Scenario B, everyday we need to generate a tweet ranking list given a particular topic for users as an email digest. As users are not willing to read too many tweets at a time, the upper bound of tweet number is 100. Therefore, it is a pure information retrieval problem. We don't need to consider timeliness and novelty anymore, the only criteria is tweet relevance towards a topic.</p><p>Everyday during the 'Twitter Streaming listening' period, we stored the sampled tweets into local disk. In the end of each day, we generate a ranking list for each topic based on the stored daily tweet collection.</p><p>In Scenario B, the first several steps are the same as Scenario A, data pre-processing is also necessary in the begining. We The overall flow is showed in Figure <ref type="figure" coords="3,204.29,561.81,3.74,8.64" target="#fig_1">2</ref>.</p><p>In the beginning steps, we also need to calculate weighted queries, and extract entities from both tweets and topics (queries) and therefore project tweets and topics into the same high dimensional space.</p><p>After that, we create a language model ensemble in which there are five classic language models including TF-IDF model, Vector space model, BM25 model, language model with Dirichlet Smoothing and language model with Jelinek Mercer Smoothing. For each topic-tweet pair, we calculate the similarity score using all five models. We standardize each model similarity score so that similarity scores in each model are in the same range and comparable. Afterwards, for each tweet-topic pair, we sum up all five similarity scores together as a representation of final similarity score. In the end, for each topic, we rank the top 100 tweets with highest similarity scores and push the ranking list to users as a daily email digest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULT</head><p>In total, the RTS track offers 188 topics. Each day, all participants need to submit up to 10 tweets for each topic for Scenario A and a tweet ranking list up to 100 tweets for each topic to fulfill the requirement of Scenario B. We received the evaluation result based on both human assessors and NIST official pooling evaluation. In Scenario A, the result are judged from 2 independent resources. One is from NIST assessment and the other is from mobile assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Scenario A</head><p>NIST assessors judged 96 topics this year. Per official track guidelines, the metrics used include EG-p, EG-1, nCG-p and nCG-1.</p><p>Mobile assessors judged 188 topics (with uneven effort), and some tweets were judged by multiple assessors.</p><p>The whole result is showed in Table <ref type="table" coords="4,211.78,79.65,3.74,8.64">1</ref>. For Scenario B, the result is evaluated by NIST assessors. It judged 96 topics this year. Per official track guidelines, the official metrics are nDCG@10 and nDCG@10-p. And the detail is showed in Table <ref type="table" coords="4,155.00,218.30,3.74,8.64">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scenario B</head><p>V. CONCLUSION Even though this is the second year of the Real Time Summarization track in TREC, as it merges two former tracks, its tasks reflect real user need in real society. Due to this, we believe solving these tasks is a great help to explore more innovations in both information retrieval and recommendation domains. In our work, we develop a Fast NLP-based Pattern recognition model to calculate tweet similarity towards a given topic in relevance, timeliness and novelty aspects. The result shows we can retrieve considerably good results for users. In the future, we are planning to focus more on pattern analysis on text content by involving more NLP based models such as constituency-based parse tree to generate better features containing more semantic meaning of original contents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,319.00,321.16,185.30,6.91;2,319.00,53.13,255.11,255.13"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Tweet real time recommendation in Scenario A</figDesc><graphic coords="2,319.00,53.13,255.11,255.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,319.00,321.15,139.14,6.91;3,319.00,53.13,255.11,255.12"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Tweet email digest in Scenario B</figDesc><graphic coords="3,319.00,53.13,255.11,255.12" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,70.54,430.21,230.52,8.64;4,70.54,440.99,230.53,8.82;4,70.54,451.95,211.52,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,90.85,441.17,166.74,8.64">Query expansion for microblog retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,268.42,440.99,32.65,8.59;4,70.54,451.95,121.28,8.59">International Journal of Web Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="368" to="380" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,463.09,230.52,8.64;4,70.54,473.87,125.45,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,150.65,463.09,150.41,8.64;4,70.54,474.05,52.59,8.64">Ccnu at trec 2016 real-time summarization track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,143.24,473.87,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,485.01,230.52,8.64;4,70.54,495.97,66.85,8.64" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,150.80,485.01,150.27,8.64;4,70.54,495.97,63.11,8.64">University of pittsburgh at trec 2014 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,506.93,230.52,8.64;4,70.54,517.89,75.05,8.64" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,151.64,506.93,149.42,8.64;4,70.54,517.89,70.67,8.64">Personalized community detection in scholarly network</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,528.84,230.52,8.64;4,70.54,539.80,230.52,8.64;4,70.54,550.76,230.52,8.64;4,70.54,561.54,64.54,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,181.20,539.80,119.86,8.64;4,70.54,550.76,226.84,8.64">Assorted textual features and dynamic push strategies for real-time tweet notification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,82.32,561.54,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,572.68,230.52,8.64;4,70.54,583.64,61.71,8.64" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,174.31,572.68,126.75,8.64;4,70.54,583.64,57.30,8.64">Polyu at trec 2016 real-time summarization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T D L W</forename><surname>Li</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,594.60,230.52,8.64;4,70.54,605.56,230.52,8.64;4,70.54,616.34,230.53,8.82;4,70.54,627.30,194.83,8.82" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,139.51,605.56,161.55,8.64;4,70.54,616.52,82.69,8.64">Overview of the trec 2016 real-time summarization track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,178.84,616.34,122.23,8.59;4,70.54,627.30,85.11,8.59">Proceedings of the 25th Text REtrieval Conference</title>
		<meeting>the 25th Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.54,638.43,230.52,8.64;4,70.54,649.39,230.52,8.64;4,70.54,660.17,230.53,8.82;4,70.54,671.13,230.52,8.59;4,70.54,682.09,149.14,8.82" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,265.85,638.43,35.22,8.64;4,70.54,649.39,230.52,8.64;4,70.54,660.35,151.80,8.64">Comparing community-based information adoption and diffusion across different microblogging sites</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,251.71,660.17,49.35,8.59;4,70.54,671.13,230.52,8.59;4,70.54,682.09,23.29,8.59">Proceedings of the 27th ACM Conference on Hypertext and Social Media</title>
		<meeting>the 27th ACM Conference on Hypertext and Social Media</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,340.58,57.61,230.52,8.64;4,340.58,68.57,230.52,8.64;4,340.58,79.53,217.41,8.64" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="4,388.49,79.53,143.60,8.64">Irit at trec real time summarization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Moulahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">B</forename><surname>Jabeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tamine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hubert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,340.58,90.49,230.52,8.64;4,340.58,101.45,230.52,8.64;4,340.58,112.23,155.89,8.82" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,546.19,90.49,24.91,8.64;4,340.58,101.45,230.52,8.64;4,340.58,112.41,82.37,8.64">Lightweight, conservative, yet effective: Scalable real-time tweet summarization</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,443.72,112.23,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,340.58,123.37,230.52,8.64;4,340.58,134.14,154.23,8.82" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,449.43,123.37,121.67,8.64;4,340.58,134.32,81.38,8.64">Bjut at trec 2016: Real-time summarization track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,442.05,134.14,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,340.58,145.28,230.52,8.64;4,340.58,156.24,230.52,8.64;4,340.58,167.02,161.77,8.82" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="4,530.99,145.28,40.11,8.64;4,340.58,156.24,230.52,8.64;4,340.58,167.20,88.90,8.64">Pkuicst at trec 2016 real-time summarization track: Push notifications and email digest</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,449.60,167.02,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,340.58,178.16,230.52,8.64;4,340.58,189.12,230.52,8.64;4,340.58,200.08,230.52,8.64;4,340.58,210.86,153.52,8.82" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="4,475.19,178.16,95.91,8.64;4,340.58,189.12,230.52,8.64;4,340.58,200.08,227.03,8.64">How others affect your twitter# hashtag adoption? examination of communitybased and context-based information diffusion in twitter</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
