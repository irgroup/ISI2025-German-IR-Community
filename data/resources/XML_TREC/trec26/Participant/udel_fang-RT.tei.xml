<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,104.90,79.49,402.20,12.62">Silent Day Detection in Real-Time Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.05,117.16,41.79,8.74"><forename type="first">Kuang</forename><surname>Lu</surname></persName>
							<email>lukuang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.00,117.16,48.01,8.74"><forename type="first">Peilin</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.69,117.16,40.27,8.74"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,104.90,79.49,402.20,12.62">Silent Day Detection in Real-Time Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B381912A9434FEAF6569839A7A36D134</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In microblog retrieval, a system's ability to detect silent days and "shut up" during these days have an huge impact on its performance <ref type="bibr" coords="1,321.03,226.56,9.22,7.86" target="#b0">[1]</ref>. Therefore, in this year's Real-Time Summarization Track, we focus on detecting silent days. More specifically, we propose two silent day detectors phrase-based weighted information gain and local query term coherence, both of which focus on using query terms collectively instead of individually. Track results suggest that our methods can effectively detect silent days, which subsequently results in promising performances for both scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Real-Time Summarization Track aims to build systems to retrieve tweets for interest profiles in two scenarios: 1.tweets are posted to the evaluation broker as soon as detected relevant; 2. relevant tweets are identified at the end of each day, simulating an email digest summaries for interest profiles. In both scenarios, the retrieved tweets should be both relevant and novel.</p><p>According to a previous study about the evaluation of microblog retrieval <ref type="bibr" coords="1,422.29,379.68,9.96,8.74" target="#b0">[1]</ref>, as well as our experiments on last year's Real-Time Summarization Track, it is clear that a system's ability to detect silent days, meaning days that contain no relevant information, and "shut up" for these days are critical to the performance of the system. Therefore, in this year's RTS track, we focused on detecting silent days. It is important to note that both redundant and irrelevant tweets are treated as irrelevant tweets in the RTS track, but we chose to treat redundant tweets as relevant tweets in silent day detection phrase since finding silent days with only redundant tweets or silent days with no relevant tweets may require different techniques.</p><p>The problem of silent day detection is related to query performance prediction. However, we did not simply use the existing query performance prediction techniques since some core differences between these two tasks might significantly weaken the effectiveness of query performance predictors on silent day detection. First, the problem setting is fundamentally different because in query performance prediction, relevant documents are always assumed to be exist, which is clearly not always the case for silent day detection. Moreover, the majority of the predictors assign scores to individual terms and aggregate the scores to calculate the final score of a corpus or a result list. As a result, containing high inverse collection frequency terms would be enough for a silent day to receive a high score. Given these differences, new methods specifically for silent day detection might certainly be required.</p><p>In this year's Real-Time Summarization Track, we handled the silent day detection as a classification problem and proposed two silent day detectors phrase-based weighted information gain and local query term coherence, both of which focus on using query terms collectively instead of individually.</p><p>As shown in the final TREC results, the proposed predictors can effectively detect silent days, which subsequently results in promising performances for both scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Silent Day Detection</head><p>The problem of silent day detection is naturally addressed as a classification problem since a binary decision of whether a day is silent or not should be made. In this year's track we focused on proposing new features for silent day detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collectively Using Query Terms</head><p>Despite the high similarity between query performance prediction and silent day detection, the stateof-the-art query performance predictors could mistakenly assign high scores to silent days because of two reasons. First, in traditional performance prediction tasks, it is usually assumed, if not ensured<ref type="foot" coords="2,525.39,125.60,3.97,6.12" target="#foot_0">1</ref> , that there are at least some relevant documents in the corpus. The assumption leads to the fact that existing performance predictors aim to predict the performance in the realm of possible. When also taking impossible query-day pairs into account, the theoretical basis and intuitions of the existing predictors might not always hold. Some existing performance predictors are built based on this assumption <ref type="bibr" coords="2,509.93,174.99,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,522.11,174.99,7.01,8.74" target="#b3">4]</ref>. Even those that are not, the difference between a non-silent day and a silent day may not reflect on them. For instance, given some of the state-of-the-art predictors which are based on the standard deviation of the scores of the top ranked documents <ref type="bibr" coords="2,258.97,210.86,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="2,271.14,210.86,7.75,8.74" target="#b5">6,</ref><ref type="bibr" coords="2,280.55,210.86,7.01,8.74" target="#b1">2]</ref>, a retrieved list of all irrelevant documents could have very high variance as well, just as that of an easy query.</p><p>The other problem is that the majority of the query performance predictors assign scores to individual terms and aggregate the scores to calculate the final score of a corpus or a result list. The score of a term is usually related to its inverse collection frequency <ref type="bibr" coords="2,328.74,258.84,9.96,8.74" target="#b2">[3]</ref>. Therefore, only containing terms with high inverse collection frequencies is sufficient for a day to receive a high score that would likely result in the day being labeled as a non-silent day. For instance, for query MB254 : cancer and depression in last year's RTS track, since cancer and depression both have high high inverse collection frequencies values, a day containing only one of them could have a high score.</p><p>Therefore, we make no assumption about whether there are any relevant information, and hypothesize that using query terms collectively instead of individually might be more suitable and propose two sets of silent day predictors: phrase-based weighted information gain (PWIG), and local query term coherence (LQC), which we discuss below.</p><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phrase-Based Weighted Information Gain (PWIG)</head><p>. This predictor is inspired by the use of term proximity features, which are ordered or unordered groups of terms, in the query performance predictor weighted information gain (WIG) <ref type="bibr" coords="2,231.71,421.36,9.96,8.74" target="#b6">[7]</ref>. In WIG, both single term and term proximity features are used to predict the performance of a query over a collection, and the query term features would dominate the final scores of WIG, which is the second problem discussed above. Therefore, phrase-based weighted information gain (PWIG) is proposed so that single term features are removed and different weights for sequential dependence (considering order) and full dependence (without considering order) features are introduced.</p><p>More specifically, a query, its sequential dependence feature set as well as full dependence feature set are noted as Q, S(Q), and F (Q), respectively. R(Q) is the union of S(Q) and F (Q). Given a term proximity feature ξ, the probability that it appears in a document D or a day C are denoted as P (ξ|D) and P (ξ|C). Finally, given a query which has a retrieved list L K containing K documents D i ∈ {D 1 , D 2 , ..., D K }, we define PWIG as follow:</p><formula xml:id="formula_0" coords="2,186.59,562.15,346.04,27.42">P W IG = 1 K Di∈L K ξ∈R(Q) λ ξ log P (ξ|D i ) P (ξ|C) , if |R(Q)| &gt; 0<label>(1)</label></formula><p>where</p><formula xml:id="formula_1" coords="2,244.04,619.12,288.60,35.37">λ ξ =    λ √ |R(Q)| , ξ ∈ F (Q) 1-λ √ |R(Q)| , ξ ∈ S(Q)<label>(2)</label></formula><p>In PWIG, we estimate the relevance of the retrieved list only using query terms' collective occurrences. WIG is computed for single-term queries.</p><p>Local Query Term Coherence (LQC). Local query term coherence (LQC) is the other set of features we propose, which infers the difficulty of a query by estimating how coherent the query is. If, in a collection with respect to a day, the query terms are closely associated, the query is easy to the collection. Therefore, the day is not a silent day. The coherence between query terms are calculated as the coherences of groups of query terms with sizes range from 2 to the size of the original query, and the sub-coherences are aggregated to the final coherence of the query. This way of computing is chosen since the associations between query terms can vary significantly and it is not necessary for a query term to be closely related to all other terms. Moreover, we hope that by computing coherences for all possible query term groups, we cover all association conditions of a query. Another important computational detail about LQC is that these sub-coherences are computed locally. In other words, only top K tweets of the retrieved list are used instead of the whole collection. The reason behind it is that there can be more than one meaning of a query term, and the meaning of it in top ranked tweets are more likely to be the same as its original meaning in the query. The calculation details are as follow: the set of all possible multi-query-term groups of query Q is noted as F (Q). The occurrence of ξ where ξ ∈ F (Q) indicates a certain degree of coherence of terms in ξ. As a result, more tweets in top K contain ξ means higher degree of coherence between these terms:</p><formula xml:id="formula_2" coords="3,224.92,281.73,307.71,22.31">C(ξ) = # of documents containing ξ K<label>(3)</label></formula><p>Intuitively, longer multi-query-term groups tend to be more important. Therefore, ξ are grouped by their sizes i through function A():</p><formula xml:id="formula_3" coords="3,245.85,342.53,286.78,9.65">C i (Q) = A({C(ξ) : |ξ| = i})<label>(4)</label></formula><p>We employed three implementations of A(): Max, Average, and Binary. Binary means that if there is at least one occurrence of ξ, the final value would be 1. The function Binary is employed so that even in the extreme case where there is only one appearance of a multi-query-term group, LQC is still able to detect it. This scenario could be the result of only one relevant tweet of a day. C i (Q) are then aggregated further by using a weighted sum of them to calculate the raw LQC (rLQC):</p><formula xml:id="formula_4" coords="3,246.44,426.98,286.19,58.59">rLQC = |Q| i=2 log(i) × C i (Q) (5) LQC = rLQC iLQC<label>(6)</label></formula><p>The weight is implemented as the logarithm of the size. This weighting scheme is used to favor longer query-term collection while not overly penalizing the weight of short ones when the query is long. rLQC is then divided by the ideal LQC to obtain the final value of LQC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training the Silent Day Classifiers</head><p>The proposed two sets of predictors were then used as the features of Naive Bayes classifiers to detect silent days. We now discuss the details about how the classifiers were trained.</p><p>Training Data The data from 2015 Microblog Track and 2016 RTS Track were the obvious choices for the training data. In order to obtain more training data in the hope of improving the classifiers, we modified the data used in 2011 and 2012 Microblog Track by identifying silent days according to the timestamps of the tweets and queries so that they could be used to train the classifiers.</p><p>Parameter Settings We tuned the parameter settings of the proposed silent day detectors on the training data in order to obtain the optimal parameter settings for the submitted runs. For phrase-based weighted information gain, the number of tweets K was set to 5 and λ was set to 0.2. Whereas, for local query coherence we set the number of tweets as 5, 10, 100 for the aggregation functions Max, Average, and Binary, respectively. Different Labeling Strategies: Silent Day vs. Silent List. During the experiments of exploring silent day detection, an interesting phenomenon was discovered: given a query, it is possible that there are some relevant tweets in the day, but the retrieval method fails to retrieve any relevant documents in the top 10 results (10 is chosen here since it is the tweets-per-day limit). In other words, the retrieved list is "silent" but the day is not. When using the retrieval function F2EXP <ref type="bibr" coords="4,424.91,234.27,9.96,8.74" target="#b7">[8]</ref>, the number of silent lists in tracks of different years are shown in Table <ref type="table" coords="4,314.39,246.23,3.87,8.74" target="#tab_0">1</ref>. As it can be clearly seen, this phenomenon is frequent. Therefore, besides labeling silent days only based on the judgment information, there is another reasonable labeling strategy which labels days with silent lists as silent days. There are two reasons why this could be more desirable. First, since there are no relevant tweets in a silent list, in terms of performance, returning any tweets from the top of the list is the same as treating the day as a silent day and returning no tweets. More importantly, since the proposed detectors are post-retrieval and rely on the top retrieved tweets, they may receive similar values for silent days and silent lists. As a result, assigning them the same label could be more benefitial for the final classification performance than assigning them with different labels. Both labeling strategies were explored in our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submitted Runs</head><p>We use the same corpus we crawled using twitter "sample" end point of the twitter stream api<ref type="foot" coords="4,496.37,396.97,3.97,6.12" target="#foot_2">2</ref> during the evaluation for both scenarios. Non-English tweets were filtered out. For the downloaded tweets, only "id" and "text" fields were used. If a tweet was a retweet, the "text" field of the original tweet was used since retweets would be normalized to the underlying tweets for evaluation. For the interest profiles, we only used "title" field as initial queries for our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Scenario A</head><p>In scenario A, we tested the effectiveness of the proposed silent day detectors as well as explored how different silent day labeling strategies affect the performance. There are 4 steps for generating our scenario A runs: 1) Given a day and a query representing an interest profile, retrieve an initial result at the end of day using some ranking function; 2) Use a silent day classifier to detect whether a day is a silent day or not; 3) If the day is a silent day, do nothing, but if it is not, use the top 10 retrieved tweets as candidate tweets 4) Perform redundancy detection on the candidate tweets and return non-redundant tweets. We submitted three runs, which all used F2exp <ref type="bibr" coords="4,267.42,568.80,10.52,8.74" target="#b8">[9]</ref> as the ranking function and jaccrad distance and threshold 0.5 for the redundancy test. The differences among these runs are the queries for interest profiles, the labeling strategy for training silent day classifiers, and the number of returned tweets for non-silent days. The details of each runs are described below:</p><p>-U DInf oBL: In this run, "title" field of the interest profiles were used as queries. We trained the classifier without considering silent lists. For each non-silent day, only the top non-redundant tweet was returned. The decision of returning one tweet was based on our experiment results on the previous year's tracks. -U DInf oSDW R: Similar to the previous run, except that the classifier was trained by treating silent lists as silent days.</p><p>-U DInf oEXP : In this run, we searched the "title" field on commercial search engines such as Google and Bing before the evaluation period. The snippets of the search results were subsequently crawled and used to expand the "title" field <ref type="bibr" coords="5,255.97,106.44,9.96,8.74" target="#b7">[8]</ref>. The expanded queries were used to retrieve results for each day for each query. The classifier used in this run is the same as the one in U DInf oBL. For each non-silent day, all the non-redundant tweets of the candidate tweets (up to 10) were returned.</p><p>There are two things need to be noted for the submitted scenario A runs. First, in run U DInf oBL and U DInf oSDW R, we chose to return only 1 tweet for a non-silent day since when we conducted experiments on previous years' tracks about how the number of returned tweets would affect the performance, returning 1 tweet provided the best performance. Moreover, since we initially planed to use the relevance feedback provided from the broker, we decided to return the maximum number of tweets allowed for a non-silent day in run U DInf oEXP to maximize the amount of relevance feedbacks we could receive. However, because the relevance feedback containing conflicting judgments and we did not come up with a reasonable way of using them, we did not use the feedbacks for our scenario B runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scenario B</head><p>In scenario B, we wanted to investigate different redundancy detection methods. Therefore, we submitted three runs which were all based on U DInf oSDW R, which was expected to be the best run for our scenario A at that time. The only difference between these runs is how redundant tweets were detected. The detailed explanation of them are listed below:</p><p>-U DInf oJac: It is the same as U DInf oSDW R except returning 10 tweets per day instead of 1.</p><p>-U DInf oW 2P re: This run is similar to U DInf oJac except the fact that we changed the redundancy detection method to a word embedding based method. More specifically, we represent a tweet with a vector that is the averaged sum of the vectors of words in the tweet. The cosine distance between the vector representations of two tweets were used to decide whether they are redundant. The word vectors used were the pre-trained vectors trained on part of Google News dataset<ref type="foot" coords="5,455.56,420.90,3.97,6.12" target="#foot_3">3</ref> , which was provided by the authors of the toolkit word2vec <ref type="bibr" coords="5,298.08,434.43,14.61,8.74" target="#b9">[10]</ref>. The redundancy threshold was set to 0.9, which was tuned on previous years' data.</p><p>-U DInf oW 2V T W T : It is similar to U DInf oW 2V T W T . The difference is that, instead of using pretrained vectors, we trained the vectors on the tweets we crawled before the evaluation period for about a 7-day period. The redundancy threshold was 0.9, which was tuned on previous years' data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Analysis</head><p>The performances of submitted runs as well as the track medians for different scenarios are shown in Table <ref type="table" coords="5,107.21,565.90,3.87,8.74" target="#tab_1">2</ref>. Note that only primary metrics, which are EG-p for scenario A, and nDCG@10-p scenario B, are reported.</p><p>For scenario A, it can be clearly seen that UDInfoSDWR and UDInfoBL can outperform track median significantly, which shows that the silent day detection methods we used are very effective. However, UDInfoSDWR, which uses the classifier that employs the labeling strategy considering silent lists the same as silent days, performs worse than UDInfoBL, which uses the classifier that employs the labeling strategy without considering silent lists. It is inconsistent with our experiments on past years' data. We discovered through additionally analysis and experiments that it might be caused by the fact that there are less silent days in this year. In this year there are only 17.7% of days that are silent days, which are less than that of 2015 (24.7%) and 2016 (23.4%). As a result, in this year precision tends to be more impactful on the system's performance. However, the classifier trained by treating silent lists as silent days has advantageous performance in past years because it predicts silent days more aggressively, which leads to higher recall but lower precision. Thus, using it is less effective on this year's data. For scenario B, there seems to be no difference among the redundancy detection method in terms of performance, which might suggest that the word embedding based method does not prove to be superior over jaccard distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year's Real-Time Summarization Track, we directly address the problem of silent day detection. It was handled as a classification problem and two sets of silent day detectors using query terms collectively are introduced. Track results indicate that the proposed silent day detectors can indeed be effective for RTS tracks, and thus prove their usefulness to microblog retrieval tasks when silent days are somewhat frequently present.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,199.21,90.90,212.39,69.54"><head>Table 1 :</head><label>1</label><figDesc>Summary of Silent List Phenomenon</figDesc><table coords="4,199.21,102.07,212.39,58.37"><row><cell cols="3">Collection # of Silent Days # of Silent Lists *</cell></row><row><cell>2011&amp;2012</cell><cell>355</cell><cell>255</cell></row><row><cell>2015</cell><cell>126</cell><cell>121</cell></row><row><cell>2016</cell><cell>131</cell><cell>171</cell></row><row><cell cols="3">*  silent days are excluded for this number</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,123.02,90.90,376.15,92.73"><head>Table 2 :</head><label>2</label><figDesc>Performances of Submitted Runs(a) Performances of Scenario A</figDesc><table coords="6,123.02,112.80,376.15,70.83"><row><cell></cell><cell></cell><cell cols="2">(b) Performances of Scenario B</cell></row><row><cell>Run Name</cell><cell>EG-p</cell><cell>Run Name</cell><cell>nDCG@10-p</cell></row><row><cell>U DInf oBL</cell><cell>0.3226</cell><cell>U DInf oJac</cell><cell>0.2886</cell></row><row><cell>U DInf oSDW R</cell><cell>0.2907</cell><cell>U DInf oW 2P re</cell><cell>0.2933</cell></row><row><cell>U DInf oEXP</cell><cell>0.2025</cell><cell>U DInf oW 2V T W T</cell><cell>0.2906</cell></row><row><cell>Track Median</cell><cell>0.2194</cell><cell>Track Median</cell><cell>0.1865</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,89.33,695.55,443.30,7.86;2,89.33,706.51,59.66,7.86"><p>In fact for the track collection disk4&amp;5, the query 672, for which no relevant documents were found in the original TREC</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="2,152.07,706.51,329.72,7.86"><p>2004, is often excluded for performance predictor evaluation by previous work<ref type="bibr" coords="2,469.50,706.51,9.22,7.86" target="#b1">[2]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="4,89.33,706.51,265.62,7.86"><p>https://dev.twitter.com/streaming/reference/get/statuses/sample</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="5,89.33,706.51,186.72,7.86"><p>https://code.google.com/archive/p/word2vec/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,87.56,418.36,445.07,7.86;6,96.13,429.32,436.50,7.86;6,96.13,440.28,314.21,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,279.31,418.36,253.32,7.86;6,96.13,429.32,18.39,7.86">An exploration of evaluation metrics for mobile push notifications</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,138.52,429.32,394.10,7.86;6,96.13,440.28,132.19,7.86">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;16</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="741" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,451.24,445.07,7.86;6,96.13,462.17,258.56,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,353.43,451.24,179.20,7.86;6,96.13,462.20,40.54,7.86">Predicting query performance by query-drift estimation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Raiber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Markovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,144.80,462.20,89.97,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,473.16,445.07,7.86;6,96.13,484.12,436.50,7.86;6,96.13,495.08,192.76,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,289.44,473.16,119.79,7.86">Predicting query performance</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,434.86,473.16,97.78,7.86;6,96.13,484.12,436.50,7.86;6,96.13,495.08,10.75,7.86">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;02</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,506.04,445.07,7.86;6,96.13,516.97,190.58,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,158.60,506.04,342.47,7.86">Document score distribution models for query performance inference and prediction</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,510.88,506.04,21.75,7.86;6,96.13,516.99,65.14,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2014-01">January 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,527.95,445.07,7.86;6,96.13,538.91,436.50,7.86;6,96.13,549.87,126.52,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,223.71,527.95,205.76,7.86">Standard deviation as a query hardness estimator</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pérez-Iglesias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,456.01,527.95,76.62,7.86;6,96.13,538.91,353.89,7.86">Proceedings of the 17th International Conference on String Processing and Information Retrieval. SPIRE&apos;10</title>
		<meeting>the 17th International Conference on String Processing and Information Retrieval. SPIRE&apos;10<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,560.83,445.07,7.86;6,96.13,571.79,133.51,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,253.46,560.83,260.35,7.86">Improved query performance prediction using standard deviation</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cummins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>O'riordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,96.13,571.79,101.25,7.86">Proceedings of SIGIR &apos;11</title>
		<meeting>SIGIR &apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,582.75,445.07,7.86;6,96.13,593.71,43.00,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,191.16,582.75,232.40,7.86">Query performance prediction in web search environments</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,445.56,582.75,87.07,7.86;6,96.13,593.71,10.75,7.86">Proceedings of SIGIR &apos;07</title>
		<meeting>SIGIR &apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,604.67,445.06,7.86;6,96.13,615.62,436.51,7.86;6,96.13,626.58,263.50,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,173.23,604.67,291.08,7.86">Semantic term matching in axiomatic approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,484.56,604.67,48.07,7.86;6,96.13,615.62,436.51,7.86;6,96.13,626.58,81.49,7.86">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;06</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;06<address><addrLine>New York, NY, USA, ACM</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.56,637.54,445.07,7.86;6,96.13,648.50,86.71,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,173.20,637.54,252.93,7.86">An exploration of axiomatic approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,446.35,637.54,86.29,7.86;6,96.13,648.50,58.04,7.86">Proceedings of SIGIR &apos;05. SIGIR &apos;05</title>
		<meeting>SIGIR &apos;05. SIGIR &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.22,659.46,445.41,7.86;6,96.13,670.39,122.50,7.89" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,288.81,659.46,239.80,7.86">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
