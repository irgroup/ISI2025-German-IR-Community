<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.98,71.79,409.58,12.90;1,95.55,87.73,406.46,12.90">Open domain real-time question answering based on asynchronous multiperspective context-driven retrieval and neural paraphrasing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,130.92,127.07,57.93,10.75"><forename type="first">Vivek</forename><surname>Datla</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.99,127.07,58.33,10.75"><forename type="first">Tilak</forename><surname>Arora</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.97,127.07,41.75,10.75"><forename type="first">Joey</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.94,127.07,70.30,10.75;1,384.24,125.54,1.41,6.99"><forename type="first">Viraj</forename><surname>Adduru</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,390.22,127.07,76.46,10.75"><forename type="first">Sadid</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,114.13,141.13,50.88,10.75"><forename type="first">Kathy</forename><surname>Lee</surname></persName>
							<email>kathy.lee1@philips.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,173.39,141.13,71.88,10.75"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,253.67,141.13,51.32,10.75"><forename type="first">Yuan</forename><surname>Ling</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.36,141.13,86.02,10.75;1,399.37,139.60,1.88,6.99"><forename type="first">Aaditya</forename><surname>Prakash</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,405.35,141.13,81.06,10.75"><forename type="first">Oladimeji</forename><surname>Farri</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.98,71.79,409.58,12.90;1,95.55,87.73,406.46,12.90">Open domain real-time question answering based on asynchronous multiperspective context-driven retrieval and neural paraphrasing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DEFE26ECF9A057E8EBF07F37A5BB6339</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The live-QA task involves real user questions, extracted from the stream of most recent questions submitted to the Yahoo Answers (YA) site that has not yet been answered. There are two tracks in the live-QA task, general domain, and medical domain. In general domain, unanswered questions are taken from six categories of real-time yahoo question answering feed, and for the medical domain, they are taken from the consumer health questions asked in NLM forums. The answers given by the system for both general and medical tasks are evaluated by human experts looking into accuracy, readability, and preciseness. The features of our opendomain question answering include question decomposition, question focus identification, context identification, answer retrieval and summarization. The current system builds an asynchronous system which has a multi-perspective view of the question being asked by decomposing the question into multiple smaller questions and identifying answers to subquestions and summarizing the answers. Our system performed close to the median in the live-QA task and ranked second in the medical sub-task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open domain question answering is a challenging task and an open problem in the area of AI and NLP. Our approach to addressing this gap in the * The author is affiliated with Rochester Institute of Technology(vra2128@rit.edu)</p><p>† The author is also affiliated with Brandeis University (aprakash@brandeis.edu). community involves building an automated system that answers an open-domain question using multiple sources after understanding the question and the context in which the question is being asked helps to generate better answers. In the past, researchers have used domain-specific expert systems to answer factoid questions. The performance of the systems for such domain-specific factoid questions is close to that of human experts. The open-domain real-life questions amplify the challenge many folds as natural language is ambiguous, and constructing the answer requires an elaborate understanding of the question being asked, expert domain knowledge, as well as language generation models <ref type="bibr" coords="1,436.56,416.09,84.29,9.46">(Datla et al., 2016)</ref>. The questions asked are mostly soliciting feeling or opinions regarding a certain life event or task performed.</p><p>The open domain real-time question answering task increases the complexity even further as one has answered in less than 60 seconds. Additionally, the answers need to be concise as they are restricted to a limit of 1000 characters. The medical sub-task introduced this year focuses on consumer health question answering received by the U.S. National Library of Medicine (NLM). The questions are less noisy compared to the general domain questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">General Domain Question Answering Task Description</head><p>The Live-QA track first started in TREC 2015. This year a new sub-task wherein the questions from the medical domain are asked. The competition runs for 24 hrs, for the general track questions being posted on Yahoo Answers site (after some preliminary cleaning) by the real users are posted on to the participating team's servers registered for the competition. Both the general and medi- The questions in the general domain are selected from 7 distinct topics shown in Table <ref type="table" coords="2,266.26,273.11,4.09,9.46" target="#tab_0">1</ref>. As the table indicates, topics for the general domain questions have several sub-categories. The category of a question may overlap with other categories. For example "Why does Labor back this kind of behavior?" is identified by the user as in the topic category "Travel" and to the sub-topic category "Australia". However, from the question, we can understand that it belongs to the category "Politics and Government". Sometimes the questions belong to multiple categories, and the user based on his interest/convenience picks only one topic <ref type="bibr" coords="2,115.03,435.70,80.13,9.46">(Datla et al., 2016)</ref>.</p><p>The questions being asked on Yahoo Answers website are mostly subjective and describe a human experience which is often personal and relevant to the topic. The ability for a machine to replicate human understanding of the topic(s) and biases in a subjective question is challenging. Also, the fact that these questions can represent multiple events and potential causal relationships further complicate the Live-QA task. For example, the question "My fiance hates my dog. He ignores him and always complains. He started calling him names. Should I be worried?" posted in the Pets topic shows three parties (me, my fiance, and my dog) with a mix of interpersonal relationships represented as emotions and actions "hates my dog", "ignores him", "always complains", "started calling him names", and "should I be worried"). The answers given by people for this question include suggestions on personal relationships, pet behaviors, and further questions like "Do you want to stay with the person who is cruel to animals?" <ref type="bibr" coords="2,132.01,734.44,80.13,9.46">(Datla et al., 2016)</ref>.</p><p>1 Yahoo Answers -https://answers.yahoo.com/ As the answers given to the subjective questions indicate that there is no one correct answer and answers provided by users indicate the different focus picked while answering the question. To answer such questions, one needs not only to know about the sentiment and the focus of the question but also needs to know the interactions between various facets of the problem. Given these opendomain questions, the big challenge that we need to address is how to access huge domain knowledge to answer such questions <ref type="bibr" coords="2,441.24,202.16,79.61,9.46">(Datla et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Medical Domain sub-task</head><p>In addition to the main question answering task, a subtask for medical question answering is introduced this year. The questions for this medical subtask focuses on consumer health question answering. Consumer health questions received by the U.S. National Library of Medicine (NLM) are curated for the competition. The questions are complex and contain more than one sub-questions. Sub-questions are defined according to the focus and the question type. There are 23 question categories defined. They are diagnosed, information, complication, symptom, inheritance, prognosis, treatment, usage, cause, ingredient, contraindication, storage and disposal, genetic changes, association, susceptibility, interaction, tapering, indication, diagnosis, side effects, organization, dosage, and prevention. The question type is defined based on the information being asked by the user. We have organized the question types into a smaller set of categories such as information, medication, diagnosis, treatment, and complication.</p><p>For the medical sub-task, we used a slightly different strategy in answering the questions compared to the main task. We used Wikipedia as our knowledge base and used the structure inside Wikipedia to identify the page that most likely contains the answer based on the question asked.</p><p>The methodology followed is similar to the process followed in <ref type="bibr" coords="2,383.66,633.06,80.36,9.46" target="#b0">(Datla et al., 2017)</ref>. We used the structure of Wikipedia to identify the most appropriate section that answers the question based on the classification into 23 categories. For classification of the question into 23 categories, we used the feature extraction algorithm in <ref type="bibr" coords="2,448.68,700.81,71.26,9.46;2,307.28,714.35,51.34,9.46" target="#b5">(Sarker and Gonzalez, 2015)</ref>.</p><p>After identifying the type of the question, we use our in-house medical concept identification to extract the medical terms such as disease names, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TREC 2017 Competition</head><p>During the TREC competition, a question is pushed every minute by the track organizers onto the server registered with the competition. The question posted on our server is a JSON object with fields shown in Table <ref type="table" coords="3,193.60,404.70,4.09,9.46" target="#tab_1">2</ref>. The category, subcategory, and the question-title fields always have entries, while the other fields can sometimes be empty.</p><p>The questions from the topics shown in Table <ref type="table" coords="3,72.00,473.45,5.45,9.46" target="#tab_0">1</ref> sometimes relate to current events, and hence it becomes particularly challenging to address the questions on personal experiences related to current events, pandemics, or ongoing family issues like marriage, divorce, etc.</p><p>The time for answering the question is same for both general domain and medical sub-task. If, after 60 seconds there is no response provided by the server to the competition, then the response is assessed as negative and would be penalized. The systems are ranked on two metrics 1) success: a ratio of the aggregated scores of the answers to the total questions asked in the competition and 2) precision: a ratio of the aggregated scores of the answers to the total number of the questions answered by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">System for General Domain Question Answering</head><p>The components of our system used for general domain questions is shown in Figure <ref type="figure" coords="3,236.23,755.86,4.09,9.46">1</ref>. The main features of our system can be summarized as follows:</p><p>• NLP engine to parse question and context and normalize the data.</p><p>• Evidence curation engine, which identifies the related sources, metadata based on the user's interest. In the current work we have used Google<ref type="foot" coords="3,409.88,178.49,3.99,6.91" target="#foot_0">2</ref> and Yahoo<ref type="foot" coords="3,466.57,178.49,3.99,6.91" target="#foot_1">3</ref> as our data sources.</p><p>• Neural paraphrase identification <ref type="bibr" coords="3,494.65,217.14,30.89,9.46;3,329.09,230.69,63.13,9.46">(Hasan et al., 2016)</ref> to pick the most similar questions to the target question.</p><p>• Keyword extraction engine <ref type="bibr" coords="3,464.01,267.30,61.54,9.46;3,329.09,280.85,25.45,9.46" target="#b4">(Rose et al., 2010)</ref> that normalize the available information ranks the evidence and allows for querying to match the given context and evidence semantically.</p><p>• Asynchronous retrieval of candidates for answers for decomposed question and context pairs.</p><p>• Answer generation engine -Answer focus text identification.</p><p>-Answer focus word identification based on bi-directional attention model <ref type="bibr" coords="3,505.55,444.38,20.00,9.46;3,350.91,457.93,47.02,9.46" target="#b6">(Seo et al., 2016</ref>) -Answer phrase generation, by having the components of introduction, answer, and conclusion. -Answer alignment concerning the context and decomposed questions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Answer summarization</head><p>We had three different combinations of sources for three runs submitted for the competition. For the general domain task, we had Google as our source for Run-1, Yahoo as a source for Run-2 and Run-3 had no preference, used both Google and Yahoo and picked the best answer.</p><p>For medical sub-task, we followed a slightly different strategy for answering the questions compared to the general sub-task. As a knowledge source, we have used Wikipedia. For every question, we decomposed it into several sub-questions. The most appropriate wiki page is selected based Figure <ref type="figure" coords="4,177.26,347.97,4.24,9.46">1</ref>: System Architecture for general domain question answering on the graph structure of Wikipedia. For example, if the focus word is a drug name, then all the pages that have the drug name are retrieved, and the page that has the best fit concerning the description is taken as a candidate source of context from which the answer is extracted. We used an internal medical concept identification engine to capture the medical concepts. We also built a simple bag-of-words based logistic regression classifier to identify the type of the question and the focus of the question based on the description given.</p><p>For the feature extraction, we have used <ref type="bibr" coords="4,258.27,530.25,32.00,9.46;4,72.00,543.80,88.61,9.46" target="#b5">(Sarker and Gonzalez, 2015)</ref>.</p><p>After identifying the most appropriate page, we do a keyword overlap based windowing to identify the most relevant piece of text that most likely has the answer. This relevant text is used as input to bi-directional attention model <ref type="bibr" coords="4,240.38,620.37,49.89,9.46;4,72.00,633.92,25.45,9.46" target="#b6">(Seo et al., 2016)</ref> trained on SQUAD dataset <ref type="bibr" coords="4,217.28,633.92,72.99,9.46;4,72.00,647.47,23.48,9.46" target="#b3">(Rajpurkar et al., 2016)</ref>. Given a question and context (a body of text that contains the answer), the model picks the phrase that answers the question. We heuristically create the answer by padding the current sentence which has a word with the sentences above and below it. We also take the first sentence of the introduction of that disease as an introductory sentence and prefix the above-generated answer. We had only one system for the medical sub-task. If there was no answer obtained from using Wikipedia as our source, we defaulted to the sources which we have used in general domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>Results from our system were evaluated based on the scoring system shown below:</p><p>• avgScore(0-3): The average score over all questions. This is the main score used to rank the participating system runs.</p><p>• succ@i+: the number of questions with score i or above (i ∈ {2..4}) divided by the total number of questions. For example, succ@2+ measures the percent of questions with at least fair grade answered by the run.</p><p>• prec@i+: the number of questions with score i or above (i ∈ {2..4}) divided by the number of questions answered by the system. This measures the precision of the run, designed not to penalize non-answered questions.</p><p>Table <ref type="table" coords="4,345.46,688.12,5.45,9.46" target="#tab_2">3</ref> indicates the scores we obtained in the general domain question answering task. Our scores are close to the median. Yahoo seemed like a better knowledge source compared to Google for generating answers. One reason might be because questions are taken from Yahoo, and there is more overlap with the kind of topics discussed. The answer generation is dependent on the source of information and questions which are longer and have multiple sub-questions were hard to answer. Google<ref type="foot" coords="5,104.12,424.95,3.99,6.91" target="#foot_2">4</ref> search did not help much with the capture of candidate answers for the emotional and subjective questions. Table <ref type="table" coords="5,111.87,468.33,5.45,9.46">4</ref> indicates the scores obtained for the medical sub-task. We used Wikipedia as our knowledge source, and as results show, Wikipedia has excellent coverage of medical concepts and diseases. Even though we have used only one system for medical subtask, the variability of the results is because of the default sources of knowledge used to answer general domain were tapped when the answer is not present in Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The performance of our open domain real-time question answering system is close to the median score of all runs in the competition. Not surprisingly, Yahoo answers website as our knowledge source performed well for general domain compared to the other knowledge sources we have used for other runs. For the medical sub-task, our system performed second-best among the runs in the competition. All the runs for the medical</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="4,72.00,62.81,453.52,268.74"><head></head><label></label><figDesc></figDesc><graphic coords="4,72.00,62.81,453.52,268.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.00,73.11,218.27,191.32"><head>Table 1 :</head><label>1</label><figDesc>Topic categories and no. of sub categories</figDesc><table coords="2,72.00,86.35,218.27,178.08"><row><cell>Topic</cell><cell>#sub topics</cell></row><row><cell>Arts &amp; Humanities</cell><cell>10</cell></row><row><cell>Beauty &amp; Style</cell><cell>5</cell></row><row><cell>Health</cell><cell>10</cell></row><row><cell>Home &amp; Garden</cell><cell>6</cell></row><row><cell>Pets</cell><cell>8</cell></row><row><cell>Sports</cell><cell>30</cell></row><row><cell>Travel</cell><cell>27</cell></row><row><cell cols="2">cal tasks run parallel and are identified by header</cell></row><row><cell cols="2">information provided by the competition organiz-</cell></row><row><cell>ers.</cell><cell></cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,72.00,73.11,218.27,236.18"><head>Table 2</head><label>2</label><figDesc><ref type="bibr" coords="3,176.26,232.08,77.42,9.46" target="#b0">Datla et al., 2017)</ref>. Based on the question type we identify the most likely section in the Wikipedia that holds the answer. If the question has multiple sub-question types, then we answer each sub-question at a time in the same order as given by the user.</figDesc><table coords="3,72.00,73.11,218.27,168.43"><row><cell></cell><cell>: Question Fields</cell></row><row><cell>Category</cell><cell>Topic of the question</cell></row><row><cell>Sub-category</cell><cell>sub-topic of the question</cell></row><row><cell cols="2">Question body description of the question</cell></row><row><cell>Question title</cell><cell>actual question posted</cell></row><row><cell cols="2">medications, clinical symptoms, etc. mentioned in</cell></row><row><cell cols="2">the context and the question. We use the medi-</cell></row><row><cell cols="2">cal terms and demographic information extracted</cell></row><row><cell cols="2">using our tool as an input into the Knowledge</cell></row><row><cell cols="2">Graph-based clinical diagnosis inference engine</cell></row><row><cell cols="2">described in detail in (</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,77.98,73.11,459.28,273.80"><head>Table 3 :</head><label>3</label><figDesc>Overall Ranking in General Domain Question Answering</figDesc><table coords="5,77.98,86.35,459.28,260.55"><row><cell>Participant</cell><cell>avg</cell><cell cols="3">S@2 S@3 S@4 P@2 P@3 P@4</cell></row><row><cell>ECNU ICA-EastChinaNormalUniversity</cell><cell cols="4">2.001 0.833 0.695 0.48</cell><cell>0.838 0.7</cell><cell>0.483</cell></row><row><cell cols="5">ECNU ICA 2-EastChinaNormalUniversity 1.895 0.794 0.662 0.452 0.813 0.677 0.462</cell></row><row><cell>CMU-OAQA-CarnegieMellonUniversity</cell><cell cols="4">1.139 0.567 0.387 0.198 0.577 0.393 0.201</cell></row><row><cell>run2</cell><cell cols="3">0.777 0.421 0.25</cell><cell>0.126 0.482 0.286 0.144</cell></row><row><cell>run1</cell><cell cols="4">0.706 0.395 0.223 0.105 0.487 0.275 0.129</cell></row><row><cell>run3</cell><cell cols="3">0.613 0.357 0.19</cell><cell>0.084 0.434 0.231 0.102</cell></row><row><cell>ECNU-EastChinaNormalUniversity</cell><cell cols="2">0.206 0.14</cell><cell cols="2">0.059 0.016 0.141 0.059 0.016</cell></row><row><cell cols="5">Table 4: Over-ranking in medical sub task</cell></row><row><cell>Participant</cell><cell>avg</cell><cell cols="3">S@2 S@3 S@4 P@2 P@3 P@4</cell></row><row><cell>CMU-OAQA-CarnegieMellonUniversity</cell><cell cols="4">0.637 0.392 0.265 0.098 0.404 0.273 0.101</cell></row><row><cell>run1</cell><cell>0.49</cell><cell cols="3">0.265 0.157 0.069 0.429 0.254 0.111</cell></row><row><cell>run2</cell><cell cols="4">0.441 0.275 0.137 0.059 0.394 0.197 0.085</cell></row><row><cell>run3</cell><cell cols="4">0.431 0.284 0.147 0.059 0.397 0.205 0.082</cell></row><row><cell>ECNU ICA 2-EastChinaNormalUniversity</cell><cell cols="4">0.402 0.216 0.127 0.059 0.268 0.159 0.073</cell></row><row><cell cols="5">CMU-LiveMedQA-CarnegieMellonUniversity 0.353 0.216 0.137 0</cell><cell>0.218 0.139 0</cell></row><row><cell>ECNU ICA-EastChinaNormalUniversity</cell><cell cols="4">0.255 0.225 0.147 0.029 0.228 0.149 0.03</cell></row><row><cell>ECNU-EastChinaNormalUniversity</cell><cell cols="4">0.137 0.216 0.088 0.01</cell><cell>0.216 0.088 0.01</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,323.42,746.25,84.60,7.77"><p>http://www.google.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,323.42,757.13,98.13,7.77"><p>https://answers.yahoo.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="5,88.14,757.13,101.12,7.77;5,307.28,372.79,218.27,9.46;5,307.28,386.34,218.27,9.46;5,307.28,399.89,218.27,9.46;5,307.28,413.44,218.27,9.46;5,307.28,426.99,19.70,9.46"><p>Google-https://google.com/ sub-task had scores greater than the median score across all the runs in the competition. In the next steps, we would like to explore models for question understanding and emotional answer generation.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,307.28,487.38,218.27,8.64;5,318.19,498.34,207.36,8.64;5,318.19,509.30,207.36,8.64;5,318.19,520.26,207.36,8.64;5,318.19,531.05,207.36,8.81;5,318.19,542.01,207.35,8.81;5,318.19,553.14,22.42,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,349.41,509.30,176.14,8.64;5,318.19,520.26,202.72,8.64">Automated clinical diagnosis: The role of content in various sections of a clinical document</title>
		<author>
			<persName coords=""><surname>Vivek Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashequl</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kathy</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,328.67,531.05,196.87,8.58;5,318.19,542.01,124.98,8.58">2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1004" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.28,577.08,218.27,8.64;5,318.19,588.04,207.36,8.64;5,318.19,599.00,207.36,8.64;5,318.19,609.96,207.36,8.64;5,318.19,620.75,117.74,8.81" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,431.78,599.00,93.77,8.64;5,318.19,609.96,207.36,8.64;5,318.19,620.92,72.65,8.64">Open domain real-time question answering based on semantic and syntactic question similarity</title>
		<author>
			<persName coords=""><surname>Vivek V Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yassine</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kathy</forename><surname>Benajiba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashequl</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaditya</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,408.85,620.75,21.65,8.58">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.28,644.86,218.27,8.64;5,318.19,655.82,207.36,8.64;5,318.19,666.78,207.36,8.64;5,318.19,677.57,207.35,8.81;5,318.19,688.53,207.36,8.58;5,318.19,699.49,195.66,8.81" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,505.63,655.82,19.92,8.64;5,318.19,666.78,207.36,8.64;5,318.19,677.74,34.59,8.64">Neural paraphrase generation with stacked residual lstm networks</title>
		<author>
			<persName coords=""><forename type="first">Kathy</forename><surname>Sadid A Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashequl</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,379.37,677.57,146.17,8.58;5,318.19,688.53,207.36,8.58;5,318.19,699.49,116.42,8.58">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2923" to="2934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,307.28,723.60,218.27,8.64;5,318.19,734.56,207.36,8.64;5,318.19,745.35,207.36,8.81;5,318.19,756.31,77.76,8.81" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<title level="m" coord="5,409.62,734.56,115.92,8.64;5,318.19,745.52,140.80,8.64">Squad: 100,000+ questions for machine comprehension of text</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,72.00,67.28,218.27,8.64;6,82.91,78.24,207.36,8.64;6,82.91,89.03,163.51,8.81" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,108.93,78.24,181.34,8.64;6,82.91,89.20,57.75,8.64">Automatic Keyword Extraction from Individual Documents</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,149.03,89.03,47.31,8.58">Text Mining</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,109.12,218.27,8.64;6,82.91,120.08,207.36,8.64;6,82.91,130.87,207.36,8.81;6,82.91,141.83,144.74,8.81" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,257.07,109.12,33.21,8.64;6,82.91,120.08,207.36,8.64;6,82.91,131.04,156.91,8.64">Portable automatic text classification for adverse drug reaction detection via multi-corpus training</title>
		<author>
			<persName coords=""><forename type="first">Abeed</forename><surname>Sarker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Graciela</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,248.77,130.87,41.50,8.58;6,82.91,141.83,92.15,8.58">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="196" to="207" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,161.93,218.27,8.64;6,82.91,172.89,207.36,8.64;6,82.91,183.68,207.36,8.81;6,82.91,194.63,77.76,8.81" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,200.11,172.89,90.16,8.64;6,82.91,183.84,134.64,8.64">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName coords=""><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
