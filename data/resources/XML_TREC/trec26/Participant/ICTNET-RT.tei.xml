<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.04,83.51,345.35,12.22">ICTNET at TREC 2017 Real-Time Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.36,107.89,37.01,8.85"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
							<email>wangxiao@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,194.40,107.89,51.42,8.85"><forename type="first">Pengcheng</forename><surname>Fan</surname></persName>
							<email>fanpengcheng@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.08,107.89,41.80,8.85"><forename type="first">Liang</forename><surname>Cheng</surname></persName>
							<email>chengliang@software.ict.ac.cn</email>
						</author>
						<author>
							<persName coords="1,307.92,107.89,47.82,8.85"><forename type="first">Guoliang</forename><surname>Xing</surname></persName>
							<email>xingguopliang@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.76,107.89,31.53,8.85"><forename type="first">Zhihua</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.44,107.89,43.24,8.85"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Web Data Science and Technology</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Institute of Network Technology，ICT(YANTAI)，CAS</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.04,83.51,345.35,12.22">ICTNET at TREC 2017 Real-Time Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1CC61EB669FAE18F5ECF12F9119B1A35</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRADUCTION</head><p>Nowadays Twitter represents a successful social application and own billions of users, and there is a growing trend for recommending high quality message to users due to the business need. The Real-Time Summarization (RTS) track explores techniques for constructing real-time update summaries from social media streams in response to users' information needs.</p><p>Our task then can be reduced to a recommendation system, actually it is a recommendation system based on data stream which has continuous and enormous message data of various types. As indicated by the name of the track, the main goal of this track is to solve the problem of making the recommendation real-time, relative and novel, which is exactly the demands of scenario A. For scenario B, posting the mail digest is like a compromise to scenario A, in this scenario, we only need to post a batch of tweets to users through email at the end of the day, which means there is no real-time limitation of scenario A, and this problem then can be reduced to traditional ad-hoc search problem. In this paper we mainly focus on scenario A and then conduct the solution of scenario B based on scenario A. Substantially, Scenario A can be interpreted as following problem: given user profiles (also known as topics) which is the abstraction of a certain crowd of people's interests, by monitoring the twitter steam data, we need to make real-time (as soon as the tweet is posted), relative and novel tweet recommendation to the corresponding profile once detected. The problem mainly contains the following aspects: text processing (i.e. natural language processing), vectorization (feature selecting and extraction, vector similarity) and data storage (database management), the key part is the vectorization and similarity calculation. We need to combine these parts together to build an effective system.</p><p>Our approach mainly includes two different models, the word2vec model and TF-IDF model. In word2vec model, we simply train a word2vec language model based on wiki corpus, and then appliy the model to tweet and profile to gain vector, based on the similarity between tweet vector and profile vector we adopt corresponding pushing strategy. The TF-IDF is different in vectorization, it cached tweets a few days ahead, and apply TF-IDF model on the cached tweet corpus as well as profiles to gain the tweet vector and profile vector, details will be explored in the rest of the paper. According to the results of evaluation, our TF-IDF model achieved better performance than the naïve word2vec model, the best run was around 15% above the medium score of all automatic runs this year in Scenario A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SYSTEM DESIGN</head><p>This part elaborates the specific system design and details. As mention before, our system mainly focuses on scenario A (pushing notification) part, thus the following part is actually organized by the skeleton of scenario A. Scenario B is based on the design of scenario A, it will also be fully presented. Our system is a linear system, as showed in Figure <ref type="figure" coords="2,313.69,185.89,3.93,8.85">2</ref>-1, it is constructed of data loading module, preprocess module, feature extraction module and pushing strategy module in sequential order. The logic is clear to follow, first we load tweet data and profile data, then implement the preprocessing of the tweet text and profile text, next we present the tweet text and profile text in vector, calculate the similarity between them, and pushing the tweet according to the pushing strategy. The details of each module will described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Data loading</head><p>In pushing notification part (Scenario A), since we need to push tweets to users in real-time, we cannot afford too much time in the whole process. Therefore, the system must be able to achieve the tweet pushing fast enough. Intuitively, we load the tweet one by one. We first sample the twitter stream(1%) by twitter tools 1 and cache the sample data in database. Here we cache the data because of the need of constructing the TF-IDF model, besides, the cached data is necessary for email digest (Scenario B).</p><p>Once the tweet data is cached, we load the data from database and move into next system module, here we need to pay attention to control the speed of loading data, ensuring that the loading speed is slower then sampling speed otherwise we would encounter database error.</p><p>For user profiles, we can obtain the profiles through REST API officially provided by NIST. These profiles are JSON format file, they can be loaded directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Preprocess</head><p>For twitter data, the preprocess module is necessary for handling the text data since normally the original data always includes many noises, we take different strategies to clean the noises and keep the main information. Our principle is keep the text information to maximum because we believe the most valuable information is always presented by the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Non-ASCII Filtering:</head><p>Some tweets has a lot of emoticons and signals in text content. To keep the system more effective, we regard them as noises and filter them out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Non-English Filtering:</head><p>We just keep the English tweets in our system as required by the track, so we filter all non-English tweets from the raw data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Too-Short Filtering:</head><p>We believe that those too short tweets are too hard to get useful information.</p><p>If we kept them, the vectorization result would not be good. Thus we filter these too short tweets.</p><p>Basically, if a tweet is less than three words, it will be regarded as noises and will be cleaned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4.">URL Filtering:</head><p>If we want to calculate the similarity between a tweet and profile, we should pay more attention on text content. We filter the URLs in tweet text content by adding a URL filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5.">Hashtags-Retweet Filtering:</head><p>We remove all hashtags and retweet information in the raw tweet data. Keeping hashtags will result in bad performance in our system so we remove them, specifically, for retweet we only retain the original tweet text of all retweets.</p><p>For user profiles, the JSON file already has decent format so we just skip the preprocess procedure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pushing Strategy</head><p>• Threshold model However, we still need to do some expansion for these profiles, and it turns out that the "title" expansion has the best performance in our system, this will be discussed our feature extraction module next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature extraction</head><p>This module is the key module of our system since it defines the way of text vectorization, which is crucial for similarity calculation and message pushing. In our system, the vectorization for tweet and profile is the same, we mainly adopt two models, the word2vec model and TF-IDF model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Text refining</head><p>First we have to refine our preprocessed tweets and profiles. We mainly have three operations. 1) Stopwords filtering. We keep a stopword table in our system and then filter all the stopwords in the text (tweets and profiles). 2) Lemmatization. This is the common procedure in natural language processing, the purpose is to get the original form of the word, by means of this we can reduce the unnecessary dimension in vectorization. 3) Stemming. We only keep the necessary meaning part for words, this is the old trick like lemmatization which will help enhance the performance in vectorization. Then the refined text will be updated from the database for the next procedure of vectorization by the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Modeling</head><p>As mentioned above, we mainly take two different models to build our system, and they are implemented in our three submitted runs, we will compare and analyze the performance between them.</p><p>word2vec model: This model is naïve word2vec<ref type="foot" coords="3,288.48,340.91,3.24,5.69" target="#foot_0">2</ref> model. We use Wiki corpus we crawled to train the word2vec model, and then obtain the word vector of text by the trained model. For tweet, we simply take the average after sum the word vector to get tweet vector. For profiles, we only take "title" part of a profile to get the corresponding vector like tweet. In this model, the main work load is the training process of the model as well as the corpus crawling. Our first run (ICTNET-Run1) adopted this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TF-IDF model:</head><p>Strictly, TF-IDF is not a model, actually it is only a technique in VSM (vector space model), here we use TF-IDF is for the convenience to elaborate. In this model, first we used the cached tweet data and profiles from database as corpus to train the TF-IDF model, here we use third-part library to train it. <ref type="bibr" coords="3,129.12,465.47,3.24,5.69">3</ref> Particularly, for profile, we only use the "title" part, but we also need to do some expansion.</p><p>Here we mainly take two ways to expansion. One way is to use the "description" part of the original profile to expand it because the "description" part is the detail information of "title" part which may complement the information for the single "title" part. The other way is to use google search API the expand the "title". We observe that some "title" is abbreviation of some entry like people's name or some specific place, and we cannot have more information in even "description" part of the profile, thus we decide to use the google search API to gain the most relative text information to expand the "title" part.</p><p>In our run, we take the first 3 result by using the "title" as query.</p><p>Next, after we trained the TF-IDF model, we can get the tweet vector and profile vector of the same dimension, simply we take the average of the sum of the words in text like before. The rest part is the similarity calculation between tweet vector and profile vector. Our second and third run (ICTNET-Run2/ICTNET-Run3) used this model, with different parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Similarity</head><p>We calculate the similarity to decide whether they are relative, the higher similarity, the higher relativeness, this is the same between tweets. We use the standard cosine similarity to calculate the similarity score.</p><formula xml:id="formula_0" coords="4,185.76,75.09,218.73,57.24">  1 2 2 1 1 c o s n i i i n n i i i i A B A B s i m i l a r i t y A B A B             Formula 2-1</formula><p>Where i A and i B are the components of A and B respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Pushing strategy</head><p>For scenario A, our pushing strategy takes the philosophy of simple, basically it is a threshold model.</p><p>First we set a threshold of similarity score to judge whether a tweet is relative to a user profile, then after we calculated the similarity score, if the similarity score has exceeded the threshold, then we come into the novelty check. For novelty, we set another threshold, since we can push at most 10 tweets to one profile per day, so for each profile, we maintain a pushing queue. Once the tweet is qualified for the relativeness, we calculate the similarity between this tweet and each tweet in the pushing queue, if all the similarity score is under the novelty threshold (the higher similarity between tweets, the less novel of the new tweet), we push the tweet to the corresponding profile through the REST API. For scenario B, one thing to notice is that the email digest does not require novelty, as shown in Figure <ref type="figure" coords="4,90.00,544.69,3.99,8.85">2</ref>-2, our policy is to store all the similar tweet that pass the relativeness threshold in scenario A into database, at the end of the day, we sort all these tweets by the similarity score and choose the first 100 tweets as the email digest.</p><p>Here we list our parameter </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EVALUATION RESULTS</head><p>The evaluation period for TREC 2017 RTS is finally from July 25 00:00:00 UTC to August 3 23:59:59 UTC. In this period, all participated systems will perform their runs and submit the results after evaluation include ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relativeness Threshold</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Novelty threshold DB</head><p>For scenario A, the evaluation metrics include Expected Gain (EG) and Normalized Cumulative Gain (nCG), according to the final official email feedback, we list our overall performance in From Table <ref type="table" coords="5,142.57,441.49,4.48,8.85" target="#tab_1">3</ref>-2 we can see that our system has ordinary performance in scenario B, the best run (ICTNET-Run3) is only close to the medium score in nDCG@10-p. The reason is not hard to find because our system is mainly focused on scenario A, for scenario B, we just sort the similar tweet passed the relative threshold. Substantially, scenario A only consider the current similarity between tweet and profile due to the requirement of real-time, however in scenario B we have to consider the overall similarity between tweet and profile in a whole day, this is different with real-time scenario, so the simply sorting would not have good performance.</p><p>According to the two tables, we can tell that our TF-IDF model (used in ICTNET-Run2 and ICTNET-Run3) outperforms our word2vec model, we have concluded the reason mainly come from the fact that the word2vec model has not utilized the information of twitter data and profiles, only the Wiki corpus is not enough to present the real text vector.</p><p>We also list our "strict" and "lenient" precision of Scenario A below and compare them with TREC 2016 top 10 runs, our best run (ICTNET-Run2) has decent performance according to the rank.(last row) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSIONS&amp; Acknowledgements</head><p>In this paper, we have discussed system design of our RTS track in TREC 2017 from data loading to pushing strategy, the main work of our system is to use the pre-cached Twitter data along with the Google query expansion to train the TF-IDF model, our pushing strategy takes use of threshold model out of simplicity. According to the evaluation results, our system has a decent performance in Scenario A pushing notification whereas trivial in Scenario B of email digest. For future work, we will try to explore the enhancement of model accuracy as well as pushing strategy, the dynamic threshold model is worthy exploring, beside, the profile expansion is also a potential part to enhance.</p><p>We would like to thank all organizers and assessors of TREC and NIST. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,276.48,170.29,42.24,8.85"><head>Figure</head><label></label><figDesc>Figure 2-1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,90.00,760.75,144.66,9.06;2,116.88,104.53,31.62,5.29;2,116.88,113.29,30.27,4.45;2,116.88,119.77,22.35,4.45;2,210.00,104.53,26.81,5.29;2,210.00,113.29,27.68,4.45;2,210.00,119.77,26.97,4.45;2,303.12,104.53,44.10,5.29;2,303.12,113.29,28.22,4.45;2,303.12,119.77,31.35,4.45"><head></head><label></label><figDesc>1 https://github.com/lintool/twitter-tools</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,276.48,513.49,42.24,8.85"><head>Figure</head><label></label><figDesc>Figure 2-2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,157.92,591.49,263.03,89.25"><head></head><label></label><figDesc>table.</figDesc><table coords="4,157.92,607.57,263.03,73.17"><row><cell></cell><cell>Relativeness threshold</cell><cell>Novelty threshold</cell></row><row><cell>ICTNET-Run1</cell><cell>0.80</cell><cell>0.60</cell></row><row><cell>ICTNET-Run2</cell><cell>0.53</cell><cell>0.80</cell></row><row><cell>ICTNET-Run3</cell><cell>0.65</cell><cell>0.95</cell></row><row><cell></cell><cell>Table 2-1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,90.00,92.29,415.44,342.45"><head>Table 3</head><label>3</label><figDesc>As we can see from Table3-1, the medium score of all participated runs is in the first row, overall our best run (ICTNET-Run2) outperform the medium run at each metrics. Especially in EG-p and nCG-p, our second run have nearly 15% and 20% enhancement separately.</figDesc><table coords="5,468.22,92.29,36.88,8.85"><row><cell>-1 below.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,90.00,330.37,415.46,48.45"><head></head><label></label><figDesc>This work is sponsored by the National Basic Research Program of China (the 973 program) under grant numbers 2014CB340401 and 2014CB340406; Taishan Scholars Program of Shandong Province，China(No.ts201511082)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,96.72,751.48,167.63,8.01"><p>https://github.com/RaRe-Technologies/gensim</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,96.72,761.80,151.69,8.01"><p>https://github.com/scikit-learn/scikit-learn</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,94.50,392.46,93.93,10.54" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.12,410.04,295.49,6.95" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://trecrts.github.io/TREC2017-RTS-guidelines.html" />
		<title level="m" coord="6,133.20,410.04,89.98,6.95">TREC 2017 track guidelines</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.12,425.64,394.08,6.95;6,111.12,440.28,35.08,6.95" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,285.36,425.64,138.54,6.95">Overview of the trec-2014 microblog track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sherman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>DTIC Document</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="6,111.12,456.84,394.18,6.95;6,111.12,471.48,250.37,6.95" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,329.05,456.84,176.25,6.95;6,111.12,471.48,16.84,6.95">Overview of the TREC-2016 Real-Time Summarization Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,142.07,471.48,196.31,6.95">Proceedings of the 25th Text REtrieval Conference, TREC &apos;16</title>
		<meeting>the 25th Text REtrieval Conference, TREC &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.12,488.04,393.95,6.95;6,111.12,502.68,195.50,6.95" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,311.24,488.04,181.08,6.95">University of waterloo at TREC 2015 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles La</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,111.12,502.68,195.50,6.95">Proceedings of the Twenty-Fourth Text REtrieval Conference</title>
		<meeting>the Twenty-Fourth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.12,519.24,394.11,6.95;6,111.12,533.88,394.35,6.95;6,111.12,549.48,93.91,6.95" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,451.20,519.24,54.03,6.95;6,111.12,533.88,243.89,6.95">Assorted Textual Features and Dynamic Push Strategies for Real-time Tweet Notification</title>
		<author>
			<persName coords=""><forename type="first">Kathy</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaditya</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Prakashy</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,372.68,533.88,132.79,6.95;6,111.12,549.48,70.80,6.95">Proceedings of the 25th Text REtrieval Conference, TREC &apos;16</title>
		<meeting>the 25th Text REtrieval Conference, TREC &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.12,566.04,394.20,6.95;6,111.12,580.68,192.77,6.95" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,256.07,566.04,249.25,6.95;6,111.12,580.68,26.40,6.95">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,142.32,580.68,68.71,6.95">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004-04">2004. April 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
