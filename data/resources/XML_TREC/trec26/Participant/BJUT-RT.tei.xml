<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.51,98.99,338.99,12.90">BJUT at TREC 2017: Real-Time Summarization Track</title>
				<funder>
					<orgName type="full">Data Mining &amp; Security Lab</orgName>
				</funder>
				<funder>
					<orgName type="full">Beijing University of Technology</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.86,137.64,74.72,10.75"><forename type="first">Qingwei</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.29,137.64,51.37,10.75"><forename type="first">Kai</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,345.37,137.64,55.78,10.75"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
							<email>uyangzhen@bjut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.51,98.99,338.99,12.90">BJUT at TREC 2017: Real-Time Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BBD74EBE6BB95AC67912C0165164AEBD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our effort for the TREC Real-Time Summarization task in 2017, which is pushing notifications to the users mobile phone (Task A) and submitting periodic email digest according to tweets posted on the previous day (Task B). In essence, both of the tasks are about a process of extracting the relevant data from tweets stream with respect to the users' interest profiles. For each task we submitted three runs, in this paper, we presented the system framework and experimental results briefly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>We are in an era of information, that is filled with varieties of data every day. As one of the most popular social network platforms, Twitter has a total of more than 300,000,000 users, millions of tweets are posted on the web every day. In this case, its of great importance to help people find useful and non-redundant information the user wanted.</p><p>The TREC 2017 Real-Time Summarization (RTS) Track aims to explore techniques and systems that automatically monitor streams of social media posts such as Twitter to keep users up to date on topics of interest. We might think of these topics as "interest profiles", specifying the user's prospective information needs. There are two tasks about the Real-Time Summarization (RTS) Track this year:</p><p>• Track Scenario A: Push notifications. As soon as the system identifies a relevant post, it is immediately sent to the user's mobile device via a push notification. At a high level, push notifications should be relevant (on topic), novel (users should not be pushed multiple notifications that say the same thing), and timely (provide updates as soon after the actual event occurrence as possible).</p><p>• Track Scenario B: Email digests. Alternatively, a user might wish to receive a daily email digest that summarizes "what happened" that day with respect to the interest profiles. At a high level, these results should be relevant and novel; timeliness is not particularly important, provided that the tweets were all posted on the previous day.</p><p>Since the core tasks in A and B are the same, the similar approaches are used in task A and B. The paper is mainly organized as follows: in Section 2, we present our approach for Tweets message recommendation based on users interest profiles. In Section 3, we report our experimental results and in Section 4, the concluding remarks are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real-Time Summarization Framework Design</head><p>To address the two tasks mentioned above, we construct a system to catch the relevant tweets. Figure <ref type="figure" coords="1,491.42,280.87,4.98,8.64">1</ref> shows our system framework. It consists mostly of five parts: Query Expansion, Tweet Preprocess, Relevance Verification, Redundancy Detection, Ranking and Submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Expansion</head><p>For this year, 188 interest profiles are given in the same form of "topid" "title" "description" "narrative". The "title" contains a short description of the information need, similar to what users would type into a search engine. The "description" and "narrative" are sentence-and paragraph-long elaborations of the information need, respectively.</p><p>In order to find the synonyms and related keywords from the interest profiles to measure the relevance better, we do the query expansion. For every topic, we feed the topic title into the search engine (e.g. Bing News Search, Wikipedia) and get top 100 search results snippets as the expanded items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweet Preprocess</head><p>During the evaluation period (from July 29, 2017 00:00:00 UTC to August 5, 2017 23:59:59 UTC, 8 days in total), we listened to the tweet stream using the Twitter streaming API. We can receive a log file every minute, and in each log file it contains about 1000 tweets, that is to say more than 1,440,000 tweets every day.</p><p>In consideration of efficiency, it is necessary to preprocess a vast amount of tweets to filter out most of the trash or irrelevant tweets and transform each tweet into a standard and clean format.</p><p>First we discard date, time, tweetid, @, RT and URL to get pure tweet contents. Then we identify and filter out the crash tweets. If a tweet meets one or more these conditions below, we regard it as trash tweet and filter out it.</p><p>• All characters are capital (typical trash tweet)</p><p>• All characters are single letters instead of words (e.g. a b c d e f g) Figure <ref type="figure" coords="2,275.18,606.47,3.88,8.64">1</ref>: System Framework.</p><p>• The of text is less than 20 (too few words to provide enough information)</p><p>• The length of unique words is no more than 3 (e. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance Verification</head><p>According to the guideline 2017, we submitted 3 runs finally. The most difference among the 3 runs is about the part of Relevance Verification and Redundancy Detection.</p><p>For run1, we mainly use MATLAB and its toolbox -TMG <ref type="bibr" coords="2,319.50,695.51,143.33,8.64" target="#b3">(Zeimpekis and Gallopoulos 2007)</ref> to classify the prepro-cessed tweets into relevant topic. We use the Indexing Modin TMG toolbox to process A (the interest profiles together with the search results from query expansion) and B (the preprocessed tweets) to get the term document matrices (tdms) C (C 1 , C 2 , C 3 , ...) and D respectively. By matrix multiplication (C i D), we can get a score s(t j ) with respect to 188 different topics. We set threshold θ= 0.24 based on a previous work, if the calculated score s(t j )≤ θ,we regard it as a irrelevant tweet and discard it. According to The principle of Naive Bayesian classification, a tweet is classified into the topic in which it has the best score.</p><p>For run2 and run3 (Wang and Yang 2016), we train a classifier based on labelled Microblog Track (2015) and Real-Time Summarization Track (2016) past data. Label 1 presents relevant tweet and label 0 presents irrelevant tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Redundancy Detection</head><p>As we all know, users can retweet any tweets they interested in, or because of the occasionality, it is very likely to produce some similar or the same tweets. To avoid the simple copy and high similarity between the candidated tweets, it is necessary to take some measures to do Redundancy Detection.</p><p>For run1, our method assumes that the similarity between two tweets is merely determined by occurrences of their common vocabulary <ref type="bibr" coords="3,139.10,345.06,96.46,8.64" target="#b1">(Tan, Luo, and Li 2016)</ref>. The similarity for redundancy detection is defined in Equation <ref type="formula" coords="3,257.61,356.01,3.74,8.64">1</ref>. In this equation, t 1 and t 2 are the words in tweet t1 and t2 respectively, the numerator of the fraction represents the sum of word length of the intersection of two tweets, and the denominator of the fraction represents the sum of word length of the union of two tweets. We set threshold α= 0.6, if the calculated similarity between two candidated tweets t1 and t2 similarity(t1,t2)≥ α, we regard it as a redundancy tweet and discard it.</p><formula xml:id="formula_0" coords="3,63.97,461.74,228.53,22.31">similarity(t 1 , t 2 ) = union score(t 1, t 2) intersection score(t 1, t 2) (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking and Submission</head><p>According to the official guideline 2017, each system is allowed to push at most ten tweets per interest profile per day for task A. This per-day tweet delivery limit is to model user fatigue in mobile push notification. To address the problem, we design a counter in our system, for each topic if the number of the posted tweets reaches the limit, stop pushing notifications to the RTS evaluation broker. There is also a limit of 100 tweets per interest profile per day for task B. So we collect all the candidate tweets in a day, calculate their scores and classify them into the most likely topic, then arrange the scores of the same topic in a descending order and submit the results via Batch Upload to NIST.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Results</head><p>In this section, we introduce the evaluation methods <ref type="bibr" coords="3,265.43,684.56,27.08,8.64;3,54.00,695.51,30.77,8.64" target="#b0">(Lin et al. 2016</ref>) and our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Measures</head><p>For each tweet, the user makes one of three judgments: relevant, if the tweet contains relevant and novel information; redundant, if the tweet contains relevant information, but is substantively similar to another tweet that the assessor had already seen; not relevant, if the tweet does not contain relevant information. From these counts, we computed strict precision, defined as:</p><formula xml:id="formula_1" coords="3,357.72,153.13,200.28,22.31">relevant relevant + redundant + not relevant<label>(2)</label></formula><p>as well lenient precision, defined as:</p><formula xml:id="formula_2" coords="3,357.72,198.17,200.28,22.31">relevant + redundant relevant + redundant + not relevant<label>(3)</label></formula><p>Expected Gain (EG) for an interest profile on a particular day is defined as follows:</p><formula xml:id="formula_3" coords="3,400.04,253.56,157.96,22.31">EG = 1 N G(t)<label>(4)</label></formula><p>where N is the number of tweets returned and G(t) is the gain of each tweet: Not relevant tweets receive a gain of 0; Relevant tweets receive a gain of 0.5; Highly-relevant tweets receive a gain of 1.0. Normalized Cumulative Gain (nCG) for an interest profile on a particular day is defined as follows:</p><formula xml:id="formula_4" coords="3,397.89,352.62,160.11,22.31">nCG = 1 Z G(t)<label>(5)</label></formula><p>where Z is the maximum possible gain (given the ten tweet per day limit). The gain of each individual tweet is computed as above. Gain Minus Pain (GM P ) is defined as follows:</p><formula xml:id="formula_5" coords="3,370.95,432.75,187.05,8.96">GM P = α • G -(1 -α) • P (6)</formula><p>The G (gain) is computed in the same manner as above.</p><p>Pain P is the number of non-relevant tweets that the system pushed, and controls the balance between the two. Scenario B runs were evaluated in terms of nDCG as follows:</p><p>for each interest profile, the list of tweets returned per day is treated as a ranked list and from this nDCG@10 is computed. Note that in this scenario, the evaluation metric does include gain discounting because the email digests can be interpreted as ranked lists of tweets. Gain is computed in the same way as in scenario A with respect to the semantic clusters. Systems only receive credit for the first relevant tweet they report from a cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results Analysis</head><p>We got two results from the organizer lately. Results of task A and B are shown in Table <ref type="table" coords="3,435.25,618.80,4.98,8.64" target="#tab_0">1</ref> and<ref type="table" coords="3,460.32,618.80,28.47,8.64">Table 2</ref>. Columns represent 3 runs and the median scores, and rows represent some related evaluation measures mentioned in the previous chapter.</p><p>Results show that there is a great gap between our system performances and the median scores, especially the EG1 and nCG1 of BL1. Fortunately the latency of BL1 is satisfactory relatively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we present the implementation details of our runs for Real-Time Summarization Track. Results show that our method is effective to some degree, however there is still a great gap between our system performances and the median scores. In the future work, we will concentrate on how to improve the accuracy of the system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,260.02,673.60,32.48,8.64;2,63.96,684.56,228.53,8.64;2,63.96,695.51,86.01,8.64"><head></head><label></label><figDesc>g. I love you I love you I love you I love you I love you I love you I love you I love you)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,65.95,64.27,214.60,165.20"><head>Table 1 :</head><label>1</label><figDesc>Task A Performances. BL1-04 0.1692 0.1711 0.0793 BJUT-BL2-05 0.1837 0.1625 0.1809 0.1598 BJUT-BL3-03 0.1602 0.1225 0.1636 0.1258 median scores 0.2194 0.1951 0.2095 0.1826</figDesc><table coords="4,65.95,78.43,212.81,151.04"><row><cell>runtag</cell><cell>EGp</cell><cell>EG1</cell><cell>nCGp</cell><cell>nCG1</cell></row><row><cell cols="4">BJUT-Table 2: Task B Performances.</cell><cell></cell></row><row><cell></cell><cell>runtag</cell><cell cols="2">nDCGp nDCG1</cell><cell></cell></row><row><cell></cell><cell>bjut tmg</cell><cell>0.1796</cell><cell>0.1456</cell><cell></cell></row><row><cell></cell><cell>bjutgs</cell><cell>0.0746</cell><cell>0.0746</cell><cell></cell></row><row><cell></cell><cell>bjutg</cell><cell>0.1169</cell><cell>0.1169</cell><cell></cell></row><row><cell cols="3">median scores 0.2194</cell><cell>0.1865</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was supported by the <rs type="funder">Data Mining &amp; Security Lab</rs> and professor Yang from <rs type="funder">Beijing University of Technology</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,319.50,177.13,238.50,8.64;4,319.50,188.09,238.50,8.64;4,319.50,198.87,238.50,8.82;4,319.50,209.83,124.41,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,394.92,188.09,163.09,8.64;4,319.50,199.05,64.07,8.64">Overview of the trec 2016 real-time summarization track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,402.96,198.87,155.04,8.59;4,319.50,209.83,43.59,8.59">Proceedings of the 25th Text REtrieval Conference</title>
		<meeting>the 25th Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,319.50,223.84,238.50,8.64;4,319.50,234.62,123.14,8.82" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,463.73,223.84,94.28,8.64;4,319.50,234.80,77.50,8.64">Polyu at trec 2016 realtime summarization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="4,319.50,248.64,238.50,8.64;4,319.50,259.42,125.34,8.82" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,445.65,248.64,112.36,8.64;4,319.50,259.60,80.38,8.64">Bjut at trec 2016: Real-time summarization track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="4,319.50,273.44,238.50,8.64;4,319.50,284.22,238.50,8.82;4,319.50,295.18,199.20,8.59" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,499.92,273.44,58.08,8.64;4,319.50,284.40,84.79,8.64">Text to matrix generator users guide</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zeimpekis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gallopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Greece</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Engineering and Informatics, University of Patras</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
