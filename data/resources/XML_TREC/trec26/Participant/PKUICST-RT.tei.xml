<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,122.96,97.41,366.09,12.90;1,196.00,113.35,220.00,12.90">PKUICST at TREC 2017 Real-Time Summarization Track: Push Notifications and Email Digest</title>
				<funder ref="#_dyr4K6v">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.66,140.29,53.04,10.75"><forename type="first">Jizhi</forename><surname>Tang</surname></persName>
							<email>tangjizhi@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.65,140.29,44.17,10.75"><forename type="first">Chao</forename><surname>Lv</surname></persName>
							<email>lvchao@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,301.76,140.29,40.50,10.75"><forename type="first">Lili</forename><surname>Yao</surname></persName>
							<email>yaolili@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.21,140.29,75.40,10.75;1,432.61,138.76,1.41,6.99"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
							<email>zhaody@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,122.96,97.41,366.09,12.90;1,196.00,113.35,220.00,12.90">PKUICST at TREC 2017 Real-Time Summarization Track: Push Notifications and Email Digest</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">87AF3F6C41C04C6B69B14B26925C5ABC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our approaches and corresponding results in the Real-Time Summarization(RTS) track at the 2017 Text Retrieval Conference(TREC). The main idea is to build a two-stage filter system for both scenario A and B. In the first stage, tweets are filtered according to its relevance score to a particular topic, while in the second stage, they are filtered according to its novelty score to previous submitted tweets. We tried several approaches to model the text similarity, such as negative KL-divergence and cosine distance, as well as blending models. Especially, in scenario A, the push notification scenario, we designed a decoupled system that can maintain high availability in order to meet the real-time requirements. The experiment results show that our methods reach good performance with respect to several metrics such as EG-p and nDCG-p.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Microblog, such as Twitter and Weibo, has become one of the most important accesses for people to get information. However, finding out helpful information from massive microblogs by hand can be very difficult and exhausting. Building an automatic system that helps to pick out specific microblog is a good solution. The TREC 2017 Real-Time Summarization (RTS) Track aims to explore techniques that helps build such systems. There are two scenarios contained in the RTS Track:</p><p>• Scenario A (push notification): Content that is identified as relevant and novel by a system based on the user's interest profile should be sent to the user in a timely fashion. • Scenario B (email digest): Participating systems should identify tweets and aggregate them into an email digest. The email should be periodically sent to a user. Under that circumstances, users can read a longer story about the contents.</p><p>For both scenario A and B, we perform a two-stage filter system separately.</p><p>In push notification scenario, our system contains three function modules, Filter Module, Judge Module and Submit Module, and two tables, i.e. Pre-process Module listens to the tweet sample stream, roughly filter out tweets that obviously irrelevant to the interest profiles, and insert the remain tweets into the Pre-process Table . The Judge Module continuously detects new tweets from the Preprocess Table , and compute the relevance score between those tweets and the interest profiles. A tuned relevance threshold α is utilized to judge whether a specific tweet and an interest profile are relevant. Then, for every relevant profile, we compute the novelty score between current tweet and previous submitted tweets. Similarly, a novelty threshold β is used to determine whether a tweet is novel. Those tweets passed the two threshold will be inserted to the Submit Table . Finally, the Submit Module submit tweets in the Submit Table <ref type="table" coords="1,377.38,361.94,7.75,8.64">to</ref> the Evaluation Broker. The independence of the three module guarantees that the system can recover quickly and safely from system crash.</p><p>In email digest scenario, we directly precess the tweets from Pre-process Table . The whole procedure is basically the same as Judge Model in scenario A. Two threshold are performed to filter out those 'relevant but novel' tweets. the only difference is that after the filtering, we sort the tweets by the relevance score for every interest profile, and select the top 100 tweets per interest profile per day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In this section, we discuss our system design thoroughly. Fig. <ref type="figure" coords="1,336.11,512.13,4.15,8.64" target="#fig_0">1</ref> shows the architecture of our system. The Pre-process Module and the Pre-process Table are actually shared by both scenario A and B, we take these together as an independent part, Preliminaries. And then Scenario A and B will be discussed separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminaries</head><p>In this section, we mainly talk about how our system perform preliminary operation, to make the follow-up filtering easier and more precise.</p><p>Filter Module The preprocessing we adopt on interest profile and tweet stream follows <ref type="bibr" coords="1,453.01,645.41,63.60,8.64" target="#b1">(Yao et al. 2016</ref>) and <ref type="bibr" coords="1,541.78,645.41,16.23,8.64;1,319.50,656.37,68.31,8.64">(Lv, Yang, and Zhao )</ref>, which is described as follows:</p><p>• Non-English Filtering: Tweets written in a language other than English would be judged as not relevant based on guidelines of Real-Time Summarization Track. Thus,  we use the twitter's language detector to abandon the non-English tweets.</p><p>• Non-ASCII Words: Removing all NON-ASCII characters from the tweets will also helps remove non-English tweets.</p><p>• Redundant Retweet Elimination: All additional commentary in the tweets containing "RT @" will be ignored.</p><p>As the guideline mentioned, all retweets should be normalized to the underlying tweets.</p><p>• Porter Stemming and Stopword Filtering: We remove all stopwords and stem the tweet text using the Natural Language Toolkit.</p><p>• Word Overlap Filtering: We filter out tweets that have no overlap with all interest profile in word-level, because our methods don't consider semantic information. This can accelerate the he speed of identifying possible relevant tweets for each profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistics Information</head><p>In the language model, if any word in the query is not in the document, the relevant score between them will equal to zero, which is unreasonable. Smooth techniques could solve this problem by merging global word probability distribution with current document model. In our proposed approach, we obtain the global word probability distribution by computing word count information of tweet stream during the 10 days before the evaluation period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario A</head><p>In this section, we will introduce our method for Scenario A.</p><p>• Judge Module This module keeps 'listening' to the Preprocess Table . Every time a new inserted tweet is detected (actually we collect a bunch of tweets in every time interval T1 in practice), that tweet is sent to the next stage for filtering. In the first stage of filtering, for every interest profile, we compute a relevance score using a text similarity function f . If that relevance score is bigger than the relevance threshold α, this tweet-profile pair can go to the next stage. In the second stage of filtering, for every selected tweet-profile pair, The same as previous stage, we compute the similarities using f between the tweet and each of the pushed tweets of this profile, we select the biggest one as the novelty score and compared to the novelty threshold β. If that novelty score is smaller than β, we insert this tweet to the Submit </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity Algorithm</head><p>The key components of the Judge Module is the similarity function f . We use f to compute the similarity of (tweet, profile) pairs and (tweet, tweet) pairs. Note that we only use the 'title' of each interest profile for computing similarities.</p><p>We utilize two different methods to model similarity.</p><p>• negative KL-divergence language model One of the most powerful approach is language model. Each tweet D and each interest profile Q can be regard as a probability distribution. We use notation θ D and θ Q to represent the language model respectively. The negative KL-divergence between θ Q and θ D with the help of collection language model θ C can be calculated as below:</p><formula xml:id="formula_0" coords="3,73.66,250.05,209.14,66.76">DIR(Q,D, C) = w∈Q P (w| θ Q )• log (1 -λ) * P (w| θ D ) + λ * P (w| θ C ) , with λ = µ |D| + µ</formula><p>(1) • cosine distance Another method is using cosine distance model the similarity directly. We build the IDF(Inverse Document Frequency) vector for each tweet and interest profile. The IDF of each word is computed by the tweets collected before evaluation period, as we have talked in the Preliminaries section. The formula is shown below:</p><formula xml:id="formula_1" coords="3,131.17,412.52,161.33,24.02">COS(Q, D) = Q • D | Q|| D| (2)</formula><p>Query Expansion As microblog retrieval suffers severely from the vocabulary mismatch problem (i.e. term overlap between query and tweet is relatively small). Query Expansion <ref type="bibr" coords="3,73.40,477.89,99.97,8.64" target="#b2">(Zhai and Lafferty 2001)</ref> can play an important role in this situation. Moreover, more terms in the query makes retrieval more precise in general. We use Pseudo Relevance Feedback technique to expand the interest profile with IDF-cosine method in PKUIC-STRunA3 and PKUICSTRunB3. At the end of each day, we collect the submitted tweets of each interest profile, compute the word count, and sort by the word count. For each interest profile, we add the top K words that are not original in the profile to the profile. We set the expanded words a weight γ(γ &lt; 1) while the original words with a default weight 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter Selection</head><p>The parameters shown in Table .1 are tuned via grid search on TREC 2016 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario B</head><p>From Figure .1, we can see our approach of Scenario B is not much different from that of Scenario A. We remove the Submit Module and Submit Table, and add a sorting process at the end of Judge Module. Besides, we try to utilize model blending in this scenario. Model blending has been proved </p><formula xml:id="formula_2" coords="3,511.51,128.35,31.72,19.70">K = 2 γ = 0.2</formula><p>useful in many situation. We simply use the formula below to blend our two similarity models discussed before.</p><formula xml:id="formula_3" coords="3,333.03,209.71,224.97,22.68">BL(Q, D, C) =δ • DIR(Q, D, C)+ (1 -δ) • COS(Q, D), 0 &lt; δ &lt; 1<label>(3)</label></formula><p>Parameter Selection Like Scenario A, these parameters shown in Table .2 are tuned via grid search on TREC 2016 dataset.</p><p>Table <ref type="table" coords="3,353.20,292.28,3.88,8.64">2</ref>: Parameters of the Push Notifications Scenario.</p><formula xml:id="formula_4" coords="3,326.09,301.48,225.32,107.45">Run ID f α β Query Expansion PKUICSTRunB1 DIR µ = 50 0.72 0.72 - PKUICSTRunB2 BL µ = 50 δ = 0.5 0.78 0.78 - PKUICSTRunB3 BL µ = 50 δ = 0.5 0.78 0.78 K = 2 γ = 0.2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment</head><p>The evaluation of TREC 2017 Real-time Summarization track takes place from July 25, 2017 UTC to August 3, 2017 UTC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario A</head><p>For Scenario A, there are two main assessment approaches.</p><p>One is Mobile Assessment. Mobile assessors receive pushed tweets immediately, and judge whether that tweet is relevant, redundant or non-relevant. The strict precision is the proportion of relevant tweets pushed by a run, and the lenient precision is the proportion of relevant and redundant tweets pushed by a run. This time, assessors judged 188 topics(with uneven effort), and the results of Mobile Assessment are shown in Table .3.</p><p>Another assessment approach is NIST Assessment. This assessment has multiple metrics, including Expected Gain (EG) and Normalized Cumulative Gain (nCG). There two variants of EG, EG-1 and EG-p. In EG-1 metrics, on a silent day, the system receives a score of one (i.e., perfect score) if it does not push any tweets. While in EG-p, on a silent day, the score is one minus the fraction of the ten-tweet daily quota that is used. Similarly, we can define nCG-1 and nCGp. The results of NIST Assessment are shown in <ref type="bibr" coords="3,514.05,695.51,29.36,8.64">Table.4</ref> We can observe that different approaches of modelling similarity have different preferences. In PKUICSTRunA2 and PKUICSTRunA3, we select IDF-cosine algorithm and a relative high relevance threshold. That makes PKUIC-STRunA2 and PKUICSTRunA3 get higher score in precision. But higher threshold also means the system tends not to push the tweets, witch makes these systems perform bad in some macro-averaged metrics (because it's common for these systems to push nothing all day), like EG and nCG. Additionally, from the comparison of PKUICSTRunA2 and PKUICSTRunA3, we learn that a good query expansion method really helps a lot, and pseudo relevance feedback technique can be a choice. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario B</head><p>Table.5 reports our results for the email digest scenario. The main evaluation metric is nDCG-p and nDCG-1.</p><p>As we keep our parameter setting in Senario B similar to that in Senario A, the performance of our system in Scenario B have the same trend with that in Scenario A. It shows that our two-stage filtering approach also perform well in a nonreal-time task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we present our systems for TREC 2017 Real-Time Summarization Track. We design a two-stage filtering system for both Scenario A and B, and utilize two kinds of text similarity model, language model with negative KLdivergence and IDF with cosine distance. Pseudo relevance feedback technique is tried to do query expansion. Particularly, a decoupled real-time system are designed for Scenario A. Experimental results show our effectiveness and efficiency of our system in both tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,235.58,362.89,140.84,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The System Architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,54.00,668.60,238.50,35.33"><head></head><label></label><figDesc>Table and Submit Table, that transfer data between modules. The Filter</figDesc><table /><note coords="1,54.00,696.16,84.68,7.77"><p>*Corresponding author.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,87.97,82.18,441.05,217.10"><head>Table Submit Table</head><label>Submit</label><figDesc></figDesc><table coords="2,87.97,82.18,441.05,217.10"><row><cell>Twitter API</cell><cell></cell><cell></cell></row><row><cell>Non-English Filtering Filter Module</cell><cell>Judge Module</cell><cell></cell><cell>Scenario A</cell></row><row><cell cols="2">Non-ASCII Filtering Redundant Retweet Elimination Stopword Filtering Poter Stemming Pre-process Relevance Filtering Novelty Filtering Relevance Filtering Interest Profile Judge Module Word Overlap Filtering</cell><cell>Query Expansion Scenario B</cell><cell>Submission Log Submit Module Real-Time Evaluation Broker</cell></row><row><cell></cell><cell>Novelty Filtering</cell><cell></cell></row><row><cell></cell><cell>Sorting</cell><cell></cell><cell>Daily Summarization</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="2,319.50,591.91,238.51,112.24"><head>•</head><label></label><figDesc>Table, and remove it from the Pre-process Table. Submit Module Like the Judge Module, this module keeps 'listening' to the Submit Table. Every time a new inserted tweet is detected (actually we collect a bunch of tweets in every time interval T2 in practice), that tweet is sent to the Evaluation Broker. If the response tell us the submission is accepted successfully, we remove that tweet from the Submit Table and write it into the Submission Log. Otherwise that tweet will stay in the Submit Table until a successful submission.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,328.82,64.27,219.86,78.81"><head>Table 1 :</head><label>1</label><figDesc>Parameters of the Push Notifications Scenario.</figDesc><table coords="3,329.09,73.48,219.32,69.61"><row><cell>Run ID</cell><cell>f</cell><cell>α</cell><cell>β</cell><cell>Query Expansion</cell></row><row><cell>PKUICSTRunA1</cell><cell>DIR µ = 50</cell><cell cols="2">0.7 0.5</cell><cell>-</cell></row><row><cell>PKUICSTRunA2</cell><cell>COS</cell><cell cols="2">0.8 0.85</cell><cell>-</cell></row><row><cell>PKUICSTRunA3</cell><cell>COS</cell><cell cols="2">0.8 0.85</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,59.98,221.71,227.71,140.74"><head>Table 3 :</head><label>3</label><figDesc>Scenario A Mobile Assessment.</figDesc><table coords="4,59.98,230.91,227.71,131.53"><row><cell>Run ID</cell><cell cols="4">strict precision lenient precision</cell></row><row><cell>PKUICSTRunA1</cell><cell></cell><cell>0.3108</cell><cell></cell><cell>0.3642</cell></row><row><cell>PKUICSTRunA2</cell><cell></cell><cell>0.3673</cell><cell></cell><cell>0.4174</cell></row><row><cell>PKUICSTRunA3</cell><cell></cell><cell>0.3863</cell><cell></cell><cell>0.4340</cell></row><row><cell cols="4">Table 4: Scenario A NIST Assessment.</cell><cell></cell></row><row><cell>Run ID</cell><cell>EGp</cell><cell>EG1</cell><cell>nCGp</cell><cell>nCG1</cell></row><row><cell cols="5">PKUICSTRunA1 0.2869 0.2588 0.2864 0.2583</cell></row><row><cell cols="5">PKUICSTRunA2 0.1959 0.1866 0.1866 0.1774</cell></row><row><cell cols="5">PKUICSTRunA3 0.1997 0.1892 0.1908 0.1804</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,95.43,506.25,155.65,51.12"><head>Table 5 :</head><label>5</label><figDesc>Scenario B NIST Assessment.</figDesc><table coords="4,95.43,515.45,155.65,41.91"><row><cell>Run ID</cell><cell cols="2">nDCGp nDCG1</cell></row><row><cell>PKUICSTRunB1</cell><cell>0.3483</cell><cell>0.3003</cell></row><row><cell>PKUICSTRunB2</cell><cell>0.1968</cell><cell>0.1809</cell></row><row><cell>PKUICSTRunB3</cell><cell>0.2306</cell><cell>0.2024</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The work reported in this paper is supported by the <rs type="funder">National Natural Science Foundation of China</rs> Grant <rs type="grantNumber">61370116</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_dyr4K6v">
					<idno type="grant-number">61370116</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,319.50,119.25,238.50,8.64;4,319.50,130.20,238.50,8.64;4,319.50,141.16,121.19,8.64" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,518.05,119.25,39.95,8.64;4,319.50,130.20,238.50,8.64;4,319.50,141.16,117.04,8.64">Pkuicst at trec 2015 microblog track: Query-biased adaptive filtering in real-time microblog stream</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">F Y F C</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">Y J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,319.50,154.83,238.50,8.64;4,319.50,165.79,238.50,8.64;4,319.50,176.57,130.89,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,528.66,154.83,29.34,8.64;4,319.50,165.79,238.50,8.64;4,319.50,176.75,85.91,8.64">Pkuicst at trec 2016 real-time summarization track: Push notifications and email digest</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,423.54,176.57,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,319.50,190.42,238.50,8.64;4,319.50,201.38,238.50,8.64;4,319.50,212.16,67.25,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,457.52,190.42,100.48,8.64;4,319.50,201.38,223.26,8.64">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,319.50,212.16,21.92,8.59">CIKM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
