<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,200.59,98.99,210.83,12.90">BJUT at TREC 2017: Tasks Track</title>
				<funder>
					<orgName type="full">Beijing University of Technology</orgName>
				</funder>
				<funder>
					<orgName type="full">Data Mining &amp; Security Lab</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,191.80,137.64,42.20,10.75"><forename type="first">Lupu</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.71,137.64,96.01,10.75"><forename type="first">Guangyuan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,351.43,137.64,55.78,10.75"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
							<email>uyangzhen@bjut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,200.59,98.99,210.83,12.90">BJUT at TREC 2017: Tasks Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61E016EC2E8FD30A8DAD4FC1AB526972</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We generally evaluate the quality of task based information retrieval system from two aspects: task understanding and task completion. To evaluate the quality of task understanding, we need a list of sub-tasks that provide a complete coverage of tasks for each query. Finding a way to get a list like that for every query is our target. So, this paper explored the viable approach to achieve it and analyzed experimental results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Unlike traditional search engines only focused on serving the best results for a single query, the task based search engines try to understand the reasons that might have motivated the user to submit that query. The Tasks track is aimed at devising techniques to evaluate task based information retrieval systems ability to understand the tasks <ref type="bibr" coords="1,240.36,406.83,52.14,8.64;1,54.00,417.79,21.44,8.64" target="#b1">(Verma et al. 2016)</ref>. The Tasks track is divided into two parts: Task understanding and Task completion.</p><p>This paper focused on Task understanding, it ask for a ranked list of keyphrases that represent the set of all subtasks for a query, while avoiding redundancy. The quality of the ranked list of keyphrases is evaluated using diversityaware metrics. We mainly makes use of two keyphrase sources:</p><p>• Google suggestion API and Bing suggestion API</p><p>• Generated by combing the initial query and keywords extracted from documents.</p><p>The method details will be covered in Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking System Framework</head><p>The set of candidate keyphrases is ranked by scoring. The score of a keyphrase q was generated by the initial query is:</p><formula xml:id="formula_0" coords="1,127.66,621.36,164.84,9.65">S(q) = S s (q) + S k (q) (1)</formula><p>The score of keywords from web search engine suggestion marked as S s , and the score of keywords from keyword extraction marked as S k . We used the query suggestions from the Google and Bing suggestion API, and give them all 10.0 points as the highest score, because the web search engine suggestion is the most available source. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keyword extraction</head><p>The other major source of our candidate keywords is extracting keywords from documents. The source of documents in BJU T 1 (RUN ID) is the top 10 results from google search engines, and it in BJU T 2 is the top 10 results from Clueweb12 document collection.</p><p>Before extracting keywords, we removed the stop words and numbers, because they are meaningless in Generating keyphrases. We extracted keywords from each document using the ED keyword extraction algorithm <ref type="bibr" coords="1,485.19,618.80,68.52,8.64" target="#b2">(Yang et al. 2013)</ref>, this algorithm use difference between the intrinsic mode and extrinsic mode to extract the highly relevant keywords. and the score S2 is offered by this algorithm. The score of keyword means the relevance between keyword and document. The higher the score, the higher the relevance. We removed the keywords with a score less than 0, and if the documents were from web search engines, we would remove the HTML elements.</p><p>In the final, we get a set of keywords, we used two different ways of combing a keyword k and the initial query q: (i)adding k as a suffix to q; (ii) adding k as a suffix to the last entity in q. Such a removal strategy is motivated by the fact that in English most of the usual (non-adjectival) renements are syntactically performed as an addition to the right. <ref type="bibr" coords="2,76.05,135.08,113.00,8.64" target="#b0">(Garigliotti and Balog 2016)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scoring keyphrase</head><p>We ranked keyphrases by their scores. The score of a keyword k extracted from document d is generated by:</p><formula xml:id="formula_1" coords="2,117.61,207.75,111.28,30.32">S k (k) = n i=1 s(k|d i )s(d i |q)</formula><p>(2)</p><p>• s(k|d i ): expresses the score of keyword k extracted from document. it is gived by keyword extraction algorithm, The score of keyword means the relevance between keyword and document. The higher the score, the higher the relevance.</p><p>• s(d i |q): expresses the score of document d i generated by the initial query q. it was gived by Clueweb12 document collection. if the document was from web search engine, we set it to 1 points.</p><p>Combining Eq(1) and Eq(2), we will have the final score of keyphrases. So, the graphical representation of the model is depicted in Figure <ref type="figure" coords="2,138.12,380.45,3.74,8.64" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head><p>We submitted the following two runs: BJU T 1 and BJU T 2 , The results of our runs is shown in Figure <ref type="figure" coords="2,221.41,433.85,4.98,8.64">2</ref> and Table <ref type="table" coords="2,269.66,433.85,3.74,8.64" target="#tab_0">1</ref>. We don't have more statistics about other participators because of only have two teams submitted run this year. So we can't compare the results with other teams who participated this year. About the details of two runs is as follow:</p><p>• BJU T 1 : we used the web search engine suggestions with the highest priority in the ranking, and we chosen top-10 documents from results of web search engine as the source of keyword extraction. we only used keywords with S k (q) more than 0.</p><p>• BJU T 2 : This approach is essentially the same as BJU T 1 , but the source of documents is Clueweb12 document collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results Analysis</head><p>We compare the two runs to each other. We can see that the two results are generally similar, Because both of them used the web search engine suggestion API, and it contributed the majority of the score. Due to the BJU T 1 used documents from Web search engine ,and it have some interference from HTML elements, the scores of BJU T 1 is lower than the scores of BJU T 2 . But the differences of two scores is very small.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>We have described our participation in the TREC 2017 Tasks track, and it will be the last Task track because of the few participators. We explored the viable approach to generate phrases which represent sub-tasks of initial query, and we experimented the two sources of documents what be used to extract keywords.</p><p>In future work, we will find other sources of keywords, methods for combining keywords, and methods for generating phrases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,361.30,482.21,154.90,8.64;1,319.50,216.00,230.40,251.78"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Ranking System Framework.</figDesc><graphic coords="1,319.50,216.00,230.40,251.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,354.48,361.19,168.55,8.64;2,327.15,202.60,223.20,133.64"><head></head><label></label><figDesc>Figure 2: alpha-nDCG@20 Performances.</figDesc><graphic coords="2,327.15,202.60,223.20,133.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,346.75,393.83,184.00,47.85"><head>Table 1 :</head><label>1</label><figDesc>Experimental mean Performances.</figDesc><table coords="2,346.75,410.04,184.00,31.65"><row><cell>Run</cell><cell cols="2">nERR-IA@20 alpha-nDCG@20</cell></row><row><cell>BJU T 1</cell><cell>0.536024</cell><cell>0.627844</cell></row><row><cell>BJU T 2</cell><cell>0.561675</cell><cell>0.643954</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was supported by the <rs type="funder">Data Mining &amp; Security Lab</rs> and professor Yang from <rs type="funder">Beijing University of Technology</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="2,319.50,684.56,238.50,8.64;2,319.50,695.34,179.58,8.82" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="2,471.26,684.56,86.74,8.64;2,319.50,695.51,134.63,8.64">The university of stavanger at the trec 2016 tasks track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Garigliotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="3,54.00,57.48,238.50,8.64;3,54.00,68.44,238.50,8.64;3,54.00,79.22,151.34,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,253.62,68.44,38.88,8.64;3,54.00,79.39,105.63,8.64">Overview of the trec tasks track 2016</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,178.49,79.22,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,54.00,93.07,238.50,8.64;3,319.50,57.48,238.50,8.64;3,319.50,68.26,238.50,8.82;3,319.50,79.39,81.63,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,226.32,93.07,66.18,8.64;3,319.50,57.48,238.50,8.64;3,319.50,68.44,19.70,8.64">Keyword extrac-tion by entropy difference between the intrinsic and extrinsic mode</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,346.87,68.26,211.14,8.59">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">392</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="4523" to="4531" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
