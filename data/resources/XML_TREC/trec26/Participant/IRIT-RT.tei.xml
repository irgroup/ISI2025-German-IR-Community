<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.19,88.00,288.65,12.90">IRIT at TREC Real-Time Summarization 2017</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,211.10,126.05,80.53,8.64"><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
							<email>abdelhamid.chellal@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.99,126.05,83.85,8.64"><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
							<email>mohand.boughanem@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.19,88.00,288.65,12.90">IRIT at TREC Real-Time Summarization 2017</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4907AC1C2DAC2F8673B5C89E247ADCA7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the participation of the IRIT laboratory (University of Toulouse) to the Real-Time Summarization track of TREC RTS 2017. This track aims at exploring prospective information needs over document streams containing novel and evolving information and it consists of two scenarios ( A: push notification and B: Email digest). In this year the live mobile assessment was made available in real-time which provides the opportunity to propose an approach based on adaptive learning that leverages relevance feedback. We submitted two runs for scenarios A and three runs for scenarios B. In both scenarios, the identification of relevant tweets is based on a binary classifier that predicts the relevance of an incoming tweet with respect to an interest profile. We examine the impact of the use of the live relevance feedback to re-train the classier each time new relevance assessments are made available. For scenario B, the summary generation is modeled as an optimization problem using Integer Linear Programming.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media streams are valuable sources of information for a user who wishes to receive timely notification to keep up-to-date on the topic of interest. To fulfill this information need, notifications should be relevant (on topic), timely (provide updates as soon as the event occurs), and novel (avoid pushing multiple tweets that convey the same information). TREC Real-Time Summarization (RTS) track focus of these types of information needs. In this track, participant systems are required to monitor the live stream provided by Twitter streaming API over a period of eight days and to identify relevant tweets per day with respect to predefined user interest. Tweets identified as relevant to the users interest profile are pushed in two different scenarios:</p><p>1. Scenario A, called "Push notifications": In this scenario, tweet that is identified as relevant and novel is pushed in real-time to TREC RTS evaluation broker. Participating system are allowed to push up to 10 notifications per day per interest profile and pushed tweets are routed immediately to the mobile phones of assessors for relevance judgment. 2. Scenario B, called "Periodic email digest": This scenario is more like a top-100 retrieval task based on a one-day tweet collection. It consists of identifying a batch of up to 100 ranked tweets per day and per topic to be pushed as an email notification to the user after the day ends.</p><p>Comparing TREC RTS 2017 track with previous editions TREC RTF 2015 <ref type="bibr" coords="1,408.71,565.68,11.38,8.64" target="#b0">[1]</ref> and TREC RTS 2016 <ref type="bibr" coords="1,101.89,577.64,10.63,8.64" target="#b1">[2]</ref>, the major change consists in the deployment this year a mechanism whereby participant systems can fetch mobile assessor relevance judgments in real time for its pushed tweets. The availability of relevance feedback provides opportunities for techniques based on adaptive learning and relevance feedback.</p><p>For scenario A, we investigate a use of a supervised learning based approach aiming at identifying relevant tweets in a real-time fashion. Our approach consists of three filters that are adjusted sequentially namely quality and topicality, relevance and novelty filters. In our participation, we focus on the relevance filter which we consider as a binary classification task. Hence, we propose to build a binary classifier that determines whether the incoming tweet is relevant or not with respect to the topic of interest. We train the binary classifier using the labeled tweets of the TREC RTF 2015 track data-set.</p><p>Our classifier considers social signals as well as query dependent features to filter tweet stream. In order to explore the effect of the use of the live relevance feedback, we submitted two different runs. The main difference between our runs is that in the first is an adaptive learning strategy in which live relevance feedback is used to update periodically the classifier whereas in the second run the classifier is not re-trained.</p><p>For scenario B, we investigate the use of Integer Linear Programming (ILP) to generate a daily summary and we compare this approach to the traditional method that consists of selecting top weighted tweets iteratively and discarding those having their similarity with respect to the current summary above a certain threshold.</p><p>2 Adaptive learning strategy for push notification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System overview</head><p>In prospective information need, notifications should be relevant (on topic), timely (provide updates as soon as the event occurs), and novel (avoid pushing multiple tweets that convey the same information). The aforementioned requirements are fulfilled by our approach as follows: (i) To reduce the latency between notification time and publication time, the decision of selecting/ignoring an incoming tweet is taken immediately in real-time as soon as tweet occurs. (ii) To enhance the relevance and novelty of pushed tweets, the proposed method relies on three consecutive filters namely:</p><p>-Pre-processing and low-quality tweet filtering; -Relevance filter based on a binary classifier that takes advantage of the ongoing user relevance feedback; -Novelty filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Pre-processing and low-quality tweet filtering</head><p>The pre-processing step first filters out any non-English tweet using language attribute available in the tweet meta-data. After stop-words and URL removal and stemming, the text of the incoming tweet is tokenized with considering hash-tags (without # prefix). Finally, we apply a quality filter that discards any tweets containing less than five tokens or more than one URL or three hashtags. To boost filtering speed, we apply a boolean relevance filter that eliminates any tweet that does not match at least 3 terms of the title and the description of the interest profile. For the matching against tweet text, the title and the description of the interest profile were tokenized and stop-words were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Relevance filtering</head><p>The relevance filter is the main component in real-time tweet filtering system. To identify relevant tweet to push to the user, we consider the relevance filtering as binary classification problem in which the incoming tweet is classified as relevant or not relevant. We use a supervised learning approach to build a predictive binary classifier that produces tweet filtering predictions. The binary classifier is built using a Random Forest algorithm <ref type="bibr" coords="2,257.42,601.45,11.56,8.64" target="#b2">[3]</ref> that is trained on a TREC 2015 RTF dataset as follows: we extract for each topic tweets from the judgment pool of TREC 2015 RTF dataset. We obtain 94,068 tweets among them 8,164 tweets were labeled as relevant. We notice that the classes of these sets are unbalanced. To get a balanced training dataset, we filter out all tweets that do not contain at least two query's words. Thus, we obtain a training dataset that contains 6,663 tweets in which the distribution of relevant and irrelevant tweet is 50.18% and 49.81% respectively.</p><p>In the context of real-time tweet filtering, we are limited to utilize features that are already available in the meta-data of a tweet, and we are not able to use Twitter REST APIs to collect further features such as the profiles of followers. From the set of available features, we used feature selection algorithms to determine the best relevance-dependent signals that can be effectively exploited in a tweet filtering task. We use an information gain algorithm implemented in Weka tool <ref type="bibr" coords="3,381.59,115.33,10.47,8.64" target="#b3">[4]</ref>, which allows us to identify 21 features categorized into three classes: query dependent, tweet specific and user account features.</p><p>Query dependent features: In our approach, we assume that the user information need follows the standard TREC topic format which includes a title (Q t ) of the information need and a description (Q d ) that indicates what is and what is not relevant. We used six query dependent features: (1) the number of words overlap between the query's title |Q t | and hashtags in the tweet, <ref type="bibr" coords="3,436.24,175.10,11.68,8.64" target="#b1">(2,</ref><ref type="bibr" coords="3,447.92,175.10,7.79,8.64" target="#b2">3)</ref> the number of word overlaps between the text of the tweet and the query's title |Q t |, and the query's description |Q d | respectively, (4) the cosine similarity between the query title and the tweet's text vectors using word2vec <ref type="bibr" coords="3,142.19,210.97,11.38,8.64" target="#b4">[5]</ref> word embedding. The vectors of the title of the query and the tweet's text are obtained by summing up all vectors of their words. <ref type="bibr" coords="3,261.51,222.92,11.68,8.64" target="#b4">(5,</ref><ref type="bibr" coords="3,273.19,222.92,7.79,8.64" target="#b5">6)</ref> the relevance score of the incoming tweet with respect to the title Q t and the description of the query Q d . These scores are evaluated using an adaptation of Extended Boolean Model proposed by <ref type="bibr" coords="3,272.59,246.83,10.79,8.64" target="#b5">[6]</ref>, in which the word embedding is used to estimate the weight of query terms in order to cope with the shortness of tweets and word mismatch issues. In this adaptation denoted by Word Similarity Extended Boolean Model (WSEBM), the query title Q t represents "ANDed terms", and Q d represents "ORed terms". The relevance of the tweet T to "AND query" Q t and "OR query" Q d are estimated respectively as follows <ref type="bibr" coords="3,374.00,294.66,10.79,8.64" target="#b5">[6]</ref>:</p><formula xml:id="formula_0" coords="3,214.66,313.67,289.75,64.96">RSV (T, Q t and ) = 1 - ∑ q t i ∈Q t (1 -W T (q t i )) 2 |Q t | (1) RSV (T, Q d or ) = ∑ q d i ∈Q d (W T (q d i )) 2 |Q d |<label>(2)</label></formula><p>where W T (q) is the weight of the query term q in the tweet T , which is evaluated as follows:</p><formula xml:id="formula_1" coords="3,246.69,403.78,257.72,15.86">W T (q) = max t i ∈T [w2vsim(t i , q)]<label>(3)</label></formula><p>where w2vsim(t i , q) is the cosine similarity between vectors of tweet words t i and query words q.</p><p>Tweet specific features: We exploit five tweet-specific features: (1) URL&amp; Hashtag: Whether the tweet contains a URL or a hashtag; (2) Retweet count per day: The ratio of times this tweet has been retweeted and its age (in days); (3) the number of words that a tweet text contains; (4) the hour at which the tweet was published; (5) whether an entity (PERSON, ORGANIZATION, LOCATION) is mentioned in the tweet. For this, we use Stanford Named Entity Recognizer 1 .</p><p>User account features: We argue that the importance of tweet content is related to the authority of the user who posts the tweet. The authority of a user can be captured through social features that are available in the meta-data of tweets. These features are time-sensitive, the importance of a signal depends on the account age. An old account may have much more followers than a recent one. Therefore, in user account features, we implicitly consider the age of the account (in days) at the time of the tweet publication. The user account features are as follows:</p><p>-Follower: Number of followers of the author of the tweet; -Friend: Number of followees of the author of the tweet; -Verified: Whether the user account is verified; -Tweet/day: Ratio of the number of posted tweets and the age of the account; -List/day: Ratio of the number of lists a user appears in and the age of the account; -Fol/day: Ratio of the number of user followers and the age of the account; -Fr/day: Ratio of user friends and the age of the account; -Fol/Fr: Ratio of the numbers of followers and followees of user; -(List + Fol/Fr)/day: A combination of Fol/Fr and the number of lists the user appears in.</p><p>1 http://nlp.stanford.edu/software/CRF-NER.shtml</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Novelty filtering</head><p>For novelty filtering, a word overlap pairwise similarity is used to detect redundancy of the incoming tweet with respect to tweets previously pushed for a given topic over all days. The incoming tweet is pushed if it novelty score is greater than a predefined threshold. We set the novelty threshold to 0.7 for all topics and over the evaluation period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Adaptive learning strategy</head><p>To further improve the effectiveness of the binary classifier, we use relevance information feedback to update the binary classifier. The system fetches the relevance judgment of users every 10 minutes (rate fixed by track organizer) and used it to label the new instances that correspond to the features of the pushed tweets. The classifier is re-trained periodically once new relevance assessments are made available. We set this strategy in order to fit a real-world scenario in which the user may choose to judge the pushed tweet immediately or later (if it arrives at an inopportune time) or may choose to not do it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Runs</head><p>We submitted two runs based upon a binary classifier (IRIT-Run2 and IRIT-Run3) in which we use the same novelty threshold and the minimum word overlap between interest profile and tweet. The main difference between these two runs is that in IRIT-Run2 the binary classifier is re-training using live assessment whereas in IRIT-Run3 the classifier is not updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results for scenario A</head><p>The evaluation framework of scenario A (Push notification) follows the interleaved approach proposed by <ref type="bibr" coords="4,114.32,432.07,11.58,8.64" target="#b6">[7]</ref> in which runs are evaluated in two different ways namely live mobile user assessment and post hoc batch evaluation. In the former, tweets submitted by participating systems were immediately routed to the mobile phone of an assessor with the corresponding interest profile. The assessor may choose to judge the tweet immediately or later (if it arrives at an inopportune time) or may choose to not do it. As the assessor judges tweets, the results are relayed back to the evaluation broker and recorded. The post hoc batch evaluation relies on two stages: relevance assessment and semantic clustering. Tweets returned by participating systems were judged for relevance by NIST assessors via pooling based on both scenarios (A and B) after the end evaluation period. Tweets were assessed as not-relevant, relevant, or highly relevant. Then relevant tweets that convey similar information are clustered into the same cluster. Metrics for live mobile user assessment and post hoc batch evaluation are detailed in track guidelines 2 and in <ref type="bibr" coords="4,176.64,551.62,10.58,8.64" target="#b6">[7]</ref>. In the mobile live assessment, assessors judged 188 topics, and some tweets were judged by multiple assessors. As a result, the number of relevant tweets, the number of redundant tweets, and the number of non-relevant tweets may sum up to a value that is greater than the total number of pushed tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Results in terms of mobile live assessment</head><p>Table <ref type="table" coords="5,141.08,139.35,4.95,8.64" target="#tab_1">3</ref> reports the performance of our two runs based upon learning to filter approach in terms of the number of posts that were judged relevant (Rel), redundant (Red), and not relevant (Not Rel); the number of unjudged posts; the total length of each run (|R|), the strict and lenient precision (P S, P L) and the strict and lenient utility (U S, U L). The two last columns report mean latency and median latency. Form Table <ref type="table" coords="5,185.35,187.17,3.81,8.64" target="#tab_1">3</ref>, first we observe that the performance of our two runs in terms of utility and precision metrics are above the median scores of all participant systems. Second, the comparison of the performance of the two runs (IRIT-Run2 and IRIT-Run3) reveals that the use of relevance assessment feedback improves the performance overall metrics. However, we notice that the number of tweets pushed by our approaches is relatively low. The run IRIT-Run2 that use the live assessment feedback to re-train the classifier returned 607 tweets among them 48 tweets were un-judged which means that the classifier were re-trained by adding only 559 new instances to the initial training data-set. We think that the low number of pushed tweets is due to the fact that the novelty threshold (set to 0.7) and the tweet-query word overlap threshold (set to 3) were a little bit too tight. Table <ref type="table" coords="5,137.09,395.09,3.36,8.06">2</ref>. Performances of our submitted runs for scenario A evaluated by using post hoc batch evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Results in terms of post hoc batch evaluation</head><p>In the post hoc batch evaluation, NIST assessors judged 96 topics. Table <ref type="table" coords="5,403.21,428.56,4.91,8.64">4</ref> reports the performance of our two runs in terms of EG-p, EG-1, nCG-p, nCG-1 metrics as well as the median scores of the aforementioned metrics as reference. We also report the performance of our runs in terms of GMP metrics (with alpha = .33, .50, and .66) and the latency (mean and median) of tweets that contributed to system gain.</p><p>We note that the performance of our best run (IRIT-Run2) in terms of expected gain metrics (EGp and EG-1) overpasses the median scores overall participant systems whereas performances in terms of normalized cumulative gain metrics (nCGp and nCG-1) are slightly below the median. These results reveal that our approaches have a good precision but low recall for 96 topics. These results can be explained by the low number of tweets pushed by our approaches due to the tweet-query word overlap and novelty thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Runs for Scenario B</head><p>To generate runs for scenario B, the tweets stream is filtered using the low-quality tweet and relevance filters with ignoring the limit of ten tweets per day. At the end of each day, we obtained a set of candidates tweets for each topic. From this set we generate 3 different runs as follows:</p><p>1. The first run (IRIT-RunB1) takes as input tweets that passe the relevance filter based on adaptive learning strategy in which the relevance feedback of mobile assessor is used to retrain the binary classifier periodically. After filtering stage, tweets are clustered according to the content similarity.</p><p>Then form a set of candidates tweets, a subset of tweets is selected so as to maximize their overall relevance to the query subject to constraints related to, summary length, temporal diversity, coverage, and redundancy. In order to handle this selection, we formulate the tweet summary generation as integer linear problem (ILP) <ref type="bibr" coords="6,288.85,115.33,11.59,8.64" target="#b7">[8]</ref> in which unknowns variables are binaries and both the objective function (to be maximized) and constraints are linear in a set of integer variables.</p><p>Constraints ensure that at most one post per cluster from the two categories of clusters (topical and temporal) is selected with respect to the defined summary length limit. To solve the problem, we use the GNU Linear Programming kit footnotehttps://www.gnu.org/software/glpk/, which is a free optimization package. 2. The second run (IRIT-RunB2) is almost the same as the first run except that we use as input a set of tweets that were filtered without updating the binary relevance; 3. The third run (IRIT-RunB3) takes as input the same set of candidate tweet as the first run. In this run, candidate tweets are ordered by the relevance score computed according to the equation 4 and the top ten tweets are iteratively selected with the exclusion of those having word overlap above a static redundancy threshold set to 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tweets clustering</head><p>The tweet clustering is based on a pairwise similarity comparison between an incoming tweet and centroids of existing clusters. For an incoming tweet T the key problem is to decide whether to absorb it into an existing cluster or to upgrade it as a new cluster. We first find the cluster whose centroid is the nearest to T . The decision of whether T is added to the closest cluster is made if the similarity score is greater than a predefined threshold γ = 0.7; otherwise, T is upgraded to a new cluster with T as the centroid. Each time an incoming tweet is added to an existing cluster its centroid is updated. We choose as new centroid the tweet that has the highest value of the sum of similarity scores with all other tweets in the cluster. The tweet-tweet similarity is estimated using word overlap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summary generation</head><p>From M candidate tweets (those that pass the relevance filter) we select N tweets which receive the highest relevance score with respect to the interest profile subject to series of constraints related to coverage, redundancy, and length limit (maximum number of tweets allowed in the summary set to 10). Assume that there are clustered in A clusters (denoted C j ) among them there are s clusters that contain at least two tweets. In the same way, The tweet summarization problem can be formulated as the following ILP problem:</p><p>We include an indicator variable X i which is set to 1 when tweet T i is added to the summary and 0 otherwise. The goal of the ILP is to set these indicators variables to maximize the payoff subject to the set of constraints that guarantee the validity of the solution. Notice here that the first constraint states that the indicator variables are binary.</p><p>∀i ∈ [1, M], X i ∈ {0, 1}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Objective function</head><p>Top-ranked tweets are the most relevant tweets corresponding to the related aspects which we want to include in the final summary. Thus, the goal is to maximize the global relevance score of selected tweets that improve the overall coverage, temporal diversity and relevance of the final summary. The objective function is defined as follows:</p><formula xml:id="formula_2" coords="6,249.49,628.22,108.09,12.88">max(∑ M i=1 X i × RSV (T i , Q))</formula><p>The final relevance (RSV (T i , Q)) score of the tweet T i with respect to the query is given by combining linearly the relevance score of tweet T regarding the query title (equation 1) and the query description (equation 2) as follows:</p><formula xml:id="formula_3" coords="6,217.94,679.96,286.47,13.10">RSV (T, Q) = RSV (T, Q t and ) + RSV (T, Q d or )<label>(4)</label></formula><p>nDCG@10-p nDCG@10- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Coverage and redundancy constraints</head><p>These constraints fulfill both redundancy and coverage requirements. In order to avoid redundancy, we just choose at most one tweet from each topical cluster. Indeed, the limitation of the number of tweets from each cluster guarantees that a maximum of sup-topics (aspects) will be presented in the summary such that the summary can cover most information of the whole tweet set. These constraints are formulated as follows:</p><p>∀C j ∈ {C 1 , ...,C s } ∑ i;T i ∈C j X i 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Length Constraints</head><p>We add this constraint to ensure that the length of the final summary is limited to the minimum of either a predefined constant N (i.e. the maximum length) or M -1 where M is the number of candidates tweets.</p><p>∑ M i=1 X i min(N, M -1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results for scenario B</head><p>Table <ref type="table" coords="7,125.44,408.63,4.88,8.64">5</ref> reports our results for Scenario B, which aggregated the user's interest in a daily summary with a maximum of 10 tweets. We note that performances of our runs in terms of nDCG@10p are below the median. The difference between performances of runs based on ILP compared to run (IRIT-RunB3) that is based on the section of the top-10 tweets is not significant. These results can be explained by the low number of candidate tweets that passe the relevance filtering stage. In fact, if the number of candidate tweets (M) is less than the maximum length of the summary N (set to 10 in our experiments), the ILP component acts almost like top-K ranking methods since it selects all candidate tweets with discarding the redundant ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and future work</head><p>We presented in this paper three different approaches for real-time summerization of tweet stream. The proposed approached compute either a relevance score or filtering score which allow to determine if a new tweet should be pushed. For all these approaches, we underline that further experiments are needed, more particularly in the parameter tuning steps. However, we believe that results are quite promising and could give interesting insights in the future in terms of real-time tweet filtering, which are important components in the information access within data-streams.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,176.89,354.22,290.98,6.27;5,138.42,362.59,234.87,6.32;5,396.52,362.86,22.66,6.05;5,445.30,362.86,10.46,6.05;5,138.42,370.56,234.87,6.32;5,396.52,370.83,22.66,6.05;5,445.30,370.83,10.46,6.05;5,143.53,378.53,133.45,6.32;5,299.14,378.80,3.49,6.05;5,324.79,378.80,3.49,6.05;5,360.22,378.80,3.49,6.05;5,406.11,378.80,3.49,6.05;5,448.80,378.80,3.49,6.05"><head>EGp EG- 1</head><label>1</label><figDesc>nCGp nCG-1 GMP.33 GMP.5 GMP.66 mean latency median latency total length IRIT-Run2 0.2212 0.2041 0.1996 0.1825 -0.0942 -0.0557 -0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,105.62,624.93,367.22,68.73"><head>Table 1 .</head><label>1</label><figDesc>Performances of our submitted runs for scenario A evaluated by the mobile assessors.</figDesc><table coords="4,152.35,624.93,299.86,30.63"><row><cell></cell><cell cols="4">Rel Red Not Rel S U L U S P</cell><cell cols="5">L P unjudged |R| Mean latency Median latency</cell></row><row><cell cols="3">IRIT-Run2 404 75</cell><cell cols="3">551 -222 -72 0.3922 0.465</cell><cell>48</cell><cell>607</cell><cell>115.1</cell><cell>32.0</cell></row><row><cell cols="6">IRIT-Run3 554 113 812 -371 -145 0.3745 0.4509</cell><cell>62</cell><cell>875</cell><cell>131.2</cell><cell>29.0</cell></row><row><cell>Median</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">-805 -456 0.3403 0.4174</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note coords="4,105.62,683.93,204.85,9.73"><p>2 http://trecrts.github.io/TREC2016-RTS-guidelines.html</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,195.11,89.82,216.08,63.22"><head>Table 3 .</head><label>3</label><figDesc>Performances of our submitted runs for scenario B.</figDesc><table coords="7,374.60,89.82,5.52,8.06"><row><cell>1</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.25,663.96,399.16,7.77;7,113.59,674.76,391.93,7.93;7,113.59,685.88,20.17,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,459.82,663.96,44.59,7.77;7,113.59,674.92,107.79,7.77">Overview of the trec 2015 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yulu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Garrick</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,238.85,674.76,94.62,7.73">Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">November 17-20, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,92.07,399.48,7.77;8,113.59,102.86,390.81,7.93;8,112.92,113.82,45.58,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,469.91,92.07,34.82,7.77;8,113.59,103.02,140.96,7.77">Overview of the trec 2016 realtime summarization</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,271.40,102.86,91.68,7.73">Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">November 15-18, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,124.78,258.23,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,166.12,124.94,55.51,7.77">Random forests</title>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,228.13,124.78,64.70,7.73">Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,135.90,399.16,7.77;8,113.59,146.70,323.25,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,470.09,135.90,34.31,7.77;8,113.59,146.86,115.96,7.77">The weka data mining software: An update</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,236.51,146.70,85.52,7.73">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009-11">November 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,157.82,399.15,7.77;8,113.37,168.62,153.01,7.93" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,335.84,157.82,168.57,7.77;8,113.37,168.78,42.98,7.77">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR, abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,179.74,399.16,7.77;8,113.59,190.53,392.38,7.93;8,113.32,201.49,291.64,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,344.76,179.74,159.65,7.77;8,113.59,190.70,84.44,7.77">Word similarity based model for tweet stream prospective notification</title>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><surname>Dousset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,214.47,190.53,287.53,7.73">Advances in Information Retrieval -39th European Conference on IR Research</title>
		<meeting><address><addrLine>Aberdeen, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-08">2017. April 8-13, 2017. 2017</date>
			<biblScope unit="page" from="655" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,212.61,399.16,7.77;8,113.59,223.41,390.82,7.93;8,113.44,234.37,318.73,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,274.22,212.61,230.19,7.77;8,113.59,223.57,27.05,7.77">Online in-situ interleaved evaluation of real-time push notification systems</title>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,157.51,223.41,346.90,7.73;8,113.44,234.37,76.56,7.73">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">August 7-11, 2017. 2017</date>
			<biblScope unit="page" from="415" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.25,245.33,400.28,7.93;8,113.59,256.45,139.97,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,261.45,245.33,117.09,7.73">Algorithmics for Hard Problems</title>
		<author>
			<persName coords=""><forename type="first">Juraj</forename><surname>Hromkovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Waldyr</forename><forename type="middle">M</forename><surname>Oliva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, Inc., Secaucus, NJ, USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
