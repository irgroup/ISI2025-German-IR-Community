<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.04,116.90,299.28,12.68;1,145.51,134.83,324.33,12.68;1,281.47,152.76,52.42,12.68">Patient selection for clinical trials based on concept-based retrieval and result filtering and ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,267.95,191.70,79.46,8.80"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
							<email>joleveling@gmail.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>teckro The Bank Building 63 O&apos;Connell Street Limerick</addrLine>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.04,116.90,299.28,12.68;1,145.51,134.83,324.33,12.68;1,281.47,152.76,52.42,12.68">Patient selection for clinical trials based on concept-based retrieval and result filtering and ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">377066614454E209FFFCB71BCB1F66EE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For our participation at the clinical trials task in the TREC 2017 Precision Medicine track 2017, we investigated retrieving and matching clinical trial documents with patient information based on text and concept annotations of the text, filtering results for demographic information such as gender and age, and re-ranking results based on patient information. Experimental results show a competitive precision at high ranks for our least complex approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC evaluation campaign has run a number of tracks in the medical domain in previous years. Teckro<ref type="foot" coords="1,267.30,452.69,3.97,6.16" target="#foot_0">1</ref> participated in task 2 of the Precision Medicine track at TREC 2017 <ref type="foot" coords="1,225.00,464.65,3.97,6.16" target="#foot_1">2</ref> , where the participants were challenged with finding relevant clinical trials from ClinicalTrials.gov for which a patient is eligible. The task represents the process of selecting candidate patients for a study on experimental treatments, e.g. if prior treatments have been ineffective for a patient. A more detailed overview of the track and its tasks can be found in the track overview paper <ref type="bibr" coords="1,203.71,525.98,9.96,8.80" target="#b6">[7]</ref>.</p><p>The rest of this paper is organized as follows: Section 2 describes related work. Section 3 introduces the motivation and questions around the research described in this paper. Section 4 gives a brief overview of documents, topics, and relevance assessments for the task. Document and query processing for our experimental system are outlined in Sections 5 and 6, respectively, before the retrieval approach is described in Section 7. Section 8 details the official submissions and additional experiments and their results (see Table <ref type="table" coords="1,403.56,610.93,3.87,8.80" target="#tab_2">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The clinical trials task at TREC 2017 resembles the problem of identifying clinical studies for a patient. A patient can be characterized by his/her demographic group (e.g. gender, age, ethnicity), medical history and conditions, and other factors. To support the patient selection process, clinical trials usually define from several up to several hundred criteria for the inclusion and exclusion of patients. For example, a trial may be restricted by age, gender, or previous conditions (e.g. "pregnant women").</p><p>Previous tracks at TREC have focused on several different use cases from the medical domain. A similar track was concerned with searching for potential participants in trials based on electronic health records <ref type="bibr" coords="2,378.32,280.90,9.96,8.80" target="#b2">[3]</ref>.</p><p>Researchers have also previously tried to parse and analyze eligibility criteria for clinical trials to facilitate finding suitable clinical studies for patients. Much of the work has focused on documents from the ClinicalTrials.gov web site <ref type="bibr" coords="2,462.33,321.67,14.61,8.80" target="#b10">[11]</ref>, the same web site that provided documents for the TREC 2017 task. Ash et al. <ref type="bibr" coords="2,198.40,350.49,10.51,8.80" target="#b1">[2]</ref> describe a system to automatically encode and evaluate eligibility criteria to find appropriate clinical trials for patients. The system uses standard vocabularies to represent concepts and employs Bayesian networks to infer missing information. An evaluation using clinical trial protocols from NCI's Physician Data Query shows high agreement (0.84 kappa) between the proposed system and an independent physician in protocol selection. <ref type="bibr" coords="2,264.54,427.13,10.51,8.80" target="#b3">[4]</ref> aim for a more portable and standardized representation of eligibility criteria. They analyze a number of full-text protocols from Pfizer and documents from ClinicalTrials.gov to cluster criteria and find templates in language use. Similarly, Ross et al. <ref type="bibr" coords="2,241.13,479.86,10.51,8.80" target="#b8">[9]</ref> try to analyze the complexity of eligibility criteria in clinical trials. They classify criteria in trials from ClinicalTrials.gov with respect to complexity, semantic patterns, clinical content, and data sources. Their findings include that 85% criteria have significant complexity and 40% have temporal references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bhattacharya and Cantor</head><p>Samson et al. <ref type="bibr" coords="2,211.55,544.55,15.49,8.80" target="#b9">[10]</ref> propose the ERGO annotation as a formal representation for eligibility criteria to capture the semantics of eligibility criteria in documents from ClinicalTrials.gov. They test this approach to search for trials and screen patients for eligibility.</p><p>For the TREC 2017 clinical trials task, generating a standardized representation of eligibility criteria might have proved helpful as well. However, much of the standardization efforts aim at easier matching of numeric values or values with a fixed domain (e.g. "intraocular pressure &lt; 30 mmHg" or "cholesterol level = high (&gt; 350mg/dl)". In contrast, the TREC 2017 topics do not seem to include lab tests or references to numeric relationships as constraints.</p><p>We had initially planned to investigate the use of word embeddings and deep learning for this task. Due to the lack of adequate training data and due to time constraints, we abandoned this approach.</p><p>Our system for the participation at TREC 2017 was developed with the following considerations in mind:</p><p>-This track offers the traditional challenges related to natural language processing and information retrieval, i.e. how to deal with synonyms or related terms. A typical solution would be to annotate text with concepts from a standard vocabulary and exploit relationships between concepts from this vocabulary in an ontology-guided search. For example, including child concepts in a query can help improve recall as synonyms and subordinated concepts in documents would match and increase the result set size. -In the ClinicalTrials.gov documents, inclusion and exclusion criteria are merged in the criteria field in the XML documents. Parsing the criteria field and differentiating between inclusion and exclusion criteria would help improve precision by not matching concepts related to exclusion criteria. -Individual eligibility criteria can be seen as logical constraints, where exclusion criteria can be transformed into inclusion criteria by negation. For example, the exclusion criterion "age &gt; 60" can be transformed into an inclusion criterion "age &lt;= 60" by negating the relation. -Medical texts often contain negated concepts or negative findings, e.g. "no findings for tumor". For retrieval, negating concepts (i.e. concepts in a negative scope) might prevent mismatches and improve precision. For example, the concept for "tumor" should be represented as a negated concept, e.g. "not-tumor" if found within a negation scope. Our system for this task comprises a combination of approaches aiming to address the challenges mentioned above. The data flow and processing steps in the system are illustrated in Figure <ref type="figure" coords="4,297.99,119.93,3.87,8.80" target="#fig_0">1</ref>. We will briefly describe the individual approaches in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Documents, Topics, Relevance Assessments</head><p>The document collection for the TREC 2017 task consists of data from an April 2017 snapshot of ClinicalTrials.gov. <ref type="foot" coords="4,290.52,196.89,3.97,6.16" target="#foot_2">3</ref> The collection contains 241,007 trial documents. Sixteen training topics were provided, of which seven had one or two documents assessed as relevant. These topics were used to test our system's functionality and perform some plausibility checks. Thirty official topics were provided for the task. For each topic, a set of up to 1000 ranked documents was retrieved by the participants. Relevance of documents was assessed by experts at the Department of Medical Informatics of the Oregon Health and Science University (OHSU), judging relevance for a set of pooled documents for each topic, using simple depth-15 pools. More details can be found in the track overview paper <ref type="bibr" coords="4,163.50,306.04,9.96,8.80" target="#b6">[7]</ref>. We submitted the allowed maximum of five runs. Before describing the experiments, we provide an overview over the experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Document Processing</head><p>In our system, document processing comprises the following steps:</p><p>1. "parsing" document content into separate fields (e.g. inclusion and exclusion criteria from criteria), 2. annotating text with concepts from a medical ontology, and 3. detecting negation scope.</p><p>We briefly outline the document processing steps in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Parsing eligibility criteria</head><p>The clinical trial documents contain textual information in different fields, of which the criteria field lists both inclusion and exclusion criteria. In order to distinguish between positive and negative criteria for inclusion, we analyzed the criteria field in the documents. The main idea for the analysis is to support differentiating factors that make a patient eligible for a trial and ones that make him/her ineligible. For example, a patient with "breast cancer" would be eligible for cancer treatment trials, which will list "cancer" as an inclusion criterion, whereas other studies might explicitly exclude patients with cancer. Both criteria would be mentioned in the criteria field, and parsing the content of this field aims at distinguishing inclusion and exclusion criteria, so as not to mix matches and mismatches in the result set.</p><p>We found that while the original document XML does not differentiate between inclusion and exclusion criteria with XML markup, some text markers &lt;criteria&gt; &lt;textblock&gt; Inclusion Criteria:</p><p>1. Subjects must be healthy male nondependent recreational drug users 2. Subjects must be 18 to 55 years old, inclusive.</p><p>3. Subjects must have greater than or equal to 10 lifetime nontherapeutic experiences with central nervous system (CNS) stimulants (e.g., amphetamines, cocaine, methylphenidate), greater than or equal to 1 nontherapeutic use of prescription stimulants within the 12 months prior to Screening, and greater than or equal to 1 nontherapeutic use of a CNS stimulant within the 12 weeks prior to Screening.</p><p>Exclusion Criteria:</p><p>1. Subjects that are deemed medically unsuitable or unlikely to comply with the study protocol for any reason.</p><p>2. Subjects who do not pass Qualification Phase criteria to be eligible for the Treatment Phase. &lt;/textblock&gt; &lt;/criteria&gt; Fig. <ref type="figure" coords="5,211.73,523.54,4.13,7.93">2</ref>. Sample criteria field for document NCT02144415.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;inclusion_criteria&gt;</head><p>Inclusion Criteria:</p><p>1. Subjects must be healthy male nondependent recreational drug users 2. Subjects must be 18 to 55 years old, inclusive. 1. Subjects that are deemed medically unsuitable or unlikely to comply with the study protocol for any reason.</p><p>2. Subjects who do not pass Qualification Phase criteria to be eligible for the Treatment Phase. &lt;/exclusion_criteria&gt; Fig. <ref type="figure" coords="6,154.39,557.29,4.13,7.93">3</ref>. Sample inclusion_criteria, exclusion_criteria and concept annotations for document NCT02144415.</p><p>(usually lines) and formatting (line breaks) often indicates where a list of inclusion or exclusion criteria starts. Figure <ref type="figure" coords="7,308.28,131.89,4.98,8.80">2</ref> shows the content of the criteria field for a sample document. For example, most of the original formatting (i.e. line breaks) seems to have been retained in the XML, and a line such as "Eligibility criteria:" would indicate that a list of criteria follows in the text. We computed the frequency for all lines in the criteria field for all documents and manually assigned a category to lines occurring with a frequency of 10 or higher to indicate whether they start a list of inclusion (I) or exclusion criteria (E). Based on these categories, we built a simple parser, which iterates over the content of the criteria field line by line and assigns a category to each line based on the manually annotated data.</p><p>For example, lines marking the start of exclusion criteria in the criteria field include "Exclusion criteria:", "A person will be excluded from the study if he/she:", "Patients with any of the following conditions are excluded:", and "Subjects to whom any of the following applies will be excluded from the study:". Markers indicating the start of inclusion criteria include "Inclusion Criteria:", "A person is eligible for inclusion in the study if he/she:", "ELIGIBILITY CRITE-RIA:", and "Participants will be able to enroll if they:".</p><p>After assigning a category to each line, we concatenated the content for each category to form a field for inclusion_criteria and a field for exclusion_criteria. Figure <ref type="figure" coords="7,166.49,360.64,4.98,8.80">3</ref> shows the result of parsing content of the criteria field for the sample document from 2. There are, of course, documents, where the distinction between inclusion and exclusion criteria is less obvious or more complex. For example, the content might contain the sentence "Pregnant women are excluded from this study", which defines an exclusion criterion, but not as an item in a list of criteria. To deal with these cases, a more sophisticated parsing approach would be required.</p><p>Text in the following XML fields was concatenated into a single text field: brief_title, brief_summary, condition, condition_browse, criteria, description, detailed_description, intervention_browse, intervention_name, keyword, mesh_term, official_title, and other_name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Concept annotation</head><p>We selected the NCI thesaurus<ref type="foot" coords="7,274.14,537.27,3.97,6.16" target="#foot_3">4</ref> (version Thesaurus_17.04d) as the basis for annotating concepts in text from clinical trial documents. The NCI thesaurus comprises more than 120k concepts with information including preferred terms, synonyms, semantic types, child and parent concepts, and definitions. Table <ref type="table" coords="7,475.61,574.69,4.98,8.80" target="#tab_1">1</ref> shows a sample concept from the NCI thesaurus in a readable format.</p><p>To alleviate the potential problem of ambiguity and to remove annotations that were deemed not helpful for the task at hand, we filtered out some concepts from the ontology. We discarded concepts marked as "retired" concepts in the NCI thesaurus. Concepts were also removed based on their semantic type, i.e. excluding concepts with the semantic type "Quantitative Concept", "Qualitative Concept", "Idea or Concept", "Temporal Concept", "Research Activity", "Geographic Area", "Functional Concept", "Spatial Concept", "Molecular Biology Research Technique", "Professional Society", "Animal", "Mammal", "Fish", "Vertebrate", "Bird", "Amphibian", "Fungus", "Plant", "Language", etc.</p><p>In addition, we filtered out concepts referring to adverse events (based on the concept label), as these concepts would be more relevant in later stages of a clinical trial. For example, the NCI thesaurus contains concepts for both "Tremor" and "Tremor_Adverse_Event", which both have "Tremor" as a synonym and we keep only the first concept.</p><p>Concept annotation for a text is based on comparing all concept labels (i.e. for preferred and alternative concept labels) in their tokenized and stemmed form with the stemmed token sequence for the text. To maintain high precision for the concept annotation, we used the light "s"-stemmer <ref type="bibr" coords="8,397.97,451.57,9.96,8.80" target="#b5">[6]</ref>. Concept labels are matched from left to right, keeping the longest match only, without allowing overlapping matches.</p><p>Annotation information includes IDs for the matching concepts, and start and end offsets for the matching concept label in the text. The criteria, inclu-sion_criteria, exclusion_criteria, and text field are annotated with concepts, storing the corresponding concept IDs in a separate field (i.e. with a concept_ prefix for the field name). The main idea behind concept annotation is to allow easier matching with morphological variants of the concept labels and to alleviate the problem of synonyms or related concepts. For example, "heart attack" vs. "myocardial infarct" would be annotated with the same concept ID.</p><p>For each annotated concept, all of its child concept IDs in the NCI thesaurus were determined and aggregated -together with the original concept ID -in a separate document field (i.e. with concept_child_ prefix). The idea behind indexing child concepts is to allow matching between a more generic and a more specific (or subsumed) concept. For example, the topic might contain a more generic term such as "cancer", while the document mentions the more specific "breast cancer".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Negation detection</head><p>Negation has long been identified as a potential problem when analyzing text in the medical domain, see e.g. <ref type="bibr" coords="9,261.17,170.78,9.96,8.80" target="#b0">[1]</ref>. For example, "no findings for cancer" indicates that the presence of cancer cannot be confirmed, so an annotation of this text fragment with the concept for "cancer" would be incorrect. We employed the NegEx algorithm <ref type="bibr" coords="9,210.43,206.65,10.51,8.80" target="#b4">[5]</ref> to identify the scope of negations in the clinical trial content. Concepts found within a negative scope are negated, i.e. their concept ID is modified with a negation prefix so a search for the (un-negated) concept ID will not produce matches. Note that when a concept is negated, all its child concepts should be negated as well in the concept annotation step described in the previous subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Query Processing</head><p>Figure <ref type="figure" coords="9,165.15,360.16,4.98,8.80" target="#fig_1">4</ref> shows a sample topic with information in different fields: disease (disease under investigation), gene (genes of interest), demographic (patient's gender and age), and other (other criteria such as medical conditions and findings). For the generation of queries from topics, text from the disease, gene and other topic fields is annotated with concepts in the same way as for documents. Phrases such as "No relevant factors" are deleted from the topic text. Age and gender information are extracted from the topic's demographic field for filtering out trials where the patient does not fall in the age or gender group. This query processing step allows for easier transformation of topics into queries for the retrieval engine.</p><p>Our system is based on a Lucene core<ref type="foot" coords="10,300.86,142.52,3.97,6.16" target="#foot_4">5</ref> to facilitate retrieval of indexed clinical trial documents. Retrieving and matching documents for a given topic involves the following steps:</p><p>retrieving documents using the BM25 retrieval model, hard filtering of results with constrains such as gender and age, and re-ranking documents based on inclusion and exclusion criteria.</p><p>We briefly outline these steps in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Retrieval</head><p>The standard retrieval function for Lucene was, until recently, a variant of tf-idf which, compared to state-of-the-art retrieval models, achieved lower retrieval effectiveness. The underlying retrieval engine for our TREC 2017 experiments is Lucene (version 6.1.0), which in this version employs the BM25 retrieval model <ref type="bibr" coords="10,134.77,330.26,10.51,8.80" target="#b7">[8]</ref> as the default ranking model. BM25 still offers competitive retrieval effectiveness, even without parameter optimization. We used BM25 "out-of-the-box", i.e. without parameter optimization. Also note that Lucene's BM25 implementation still suffers a loss in effectiveness compared to a faithful BM25 implementation due to a lossy encoding of document length. <ref type="foot" coords="10,325.10,376.52,3.97,6.16" target="#foot_5">6</ref> We did not apply the proposed fix to the Lucene BM25 model, which would potentially improve performance as it increases accuracy for document length normalization.</p><p>The query generated from a topic contains n-grams for the textual fields (i.e. disease, gene, other), which are searched as phrases. Terms and phrases for each field are syntactically grouped together. Terms for the disease field are treated as mandatory search terms, i.e. a result document must have at least one match with terms in the disease group.</p><p>For all topics, a maximum of 1500 documents are initially retrieved, to allow retrieval of 1000 documents after filtering out non-matching documents. Documents in the retrieved set are then filtered by matching age restrictions (i.e. minimum and maximum age in years in minimum_age and minimum_age document field) and gender (i.e. male, female, or no restriction in gender document field) from the demographic field in the topic.</p><p>For cases where less than 1000 documents are retrieved in the initial retrieval step (i.e. with mandatory matching of disease terms), a second query is generated as a fallback, dropping the restriction that disease terms are mandatory. Results from the second retrieval are appended to the initial results, discarding documents that have already been retrieved in the initial retrieval step. Scores for the second retrieval step are re-normalized, starting with 99% of the score for the lowest ranked document from the initial retrieval step to merge both result sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Result filtering</head><p>Some demographic eligibility criteria for the trials are encoded in different document fields, e.g. gender, minimum_age, maximum_age. We parsed the content of these fields to facilitate matching with the same information from the demographic field in the topics. For example, the age fields contain the numeric value as well as the unit (e.g. year(s), month(s)). We separated out the unit into a separate field for the index (e.g. minimum_age_unit) and mapped the "All" value for gender to match both "male" and "female". These restrictions were used to filter out any documents that did not match the gender or age criteria provided in the topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Reranking results</head><p>In a final step, the retrieved set of documents was reranked as follows:</p><p>a document's score is increased by 1% if it contains i) a phrase in the inclusion text field, ii) a concept in the inclusion concept field, or iii) a negated concept in the exclusion concept field. a document's score is reduced by half if it contains i) a phrase in the exclusion text field, ii) a concept in the exclusion concept field, or iii) a negated concept in the inclusion concept field.</p><p>The motivation behind this step is to reduce the impact of terms from these fields -including the other field -from the original query, where the presence or absence of terms (or concepts) is not a meaningful indicator of relevance (or in the typical cases, of eligibility) for a clinical trial.</p><p>We submitted five runs, varying the parameter settings corresponding to which fields in the document index are searched. Parameters and results for the five official runs, re-runs, and additional experiments are shown in Table <ref type="table" coords="12,435.87,166.54,3.87,8.80" target="#tab_2">2</ref>.</p><p>The three runs teckro3-5 were configured incorrectly (i.e. teckro1 is the same as teckro3) and we had to re-run these experiments with the corrected configuration. Results for three additional runs are also included (teckro6, teckro7, and teckro8). Evaluation results include mean average precision (MAP), NDCG, and precision at 5, 10, and 20 as reported by trec_eval.</p><p>We achieved the best results with our least complex approach (teckro1). Restricting concept matching to the inclusion criteria yields slightly higher results for some metrics such as P@10 (teckro7). The use of child concepts did not help obtain higher performance for any experiment. Precision at 5 documents for all runs likely suffers due to suboptimal settings for the re-ranking of documents.</p><p>The relatively high performance can be attributed mostly to document preprocessing (i.e. parsing criteria) and overcoming some problems of the vocabulary mismatch with the NCI thesaurus. Only one gene name in the topics was not covered by the thesaurus. Overall, precision values are competitive with results from other top teams.</p><p>In conclusion, the clinical trials task is not a simple information retrieval task, where treating the query and documents represented as a bag of words would result in high precision. Our least complex approach achieved the best performance compared to approaches including structural information for concepts.</p><p>In the future, our current system might form a baseline system to support comparison with and optimization of more complex approaches, including ones based on current research topics such as deep learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,154.61,612.23,306.15,7.93"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Data flow and processing steps in the clinical trials retrieval system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,264.82,544.53,85.73,7.93"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Sample topic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,116.83,345.83,144.99"><head>Table 1 .</head><label>1</label><figDesc>Sample concept from the NCI thesaurus showing concept ID, parent IDs, synonyms, and semantic type for "Myocardial_Infarction". The parent concept is "My-ocardial_Disorder".</figDesc><table coords="8,136.16,166.23,342.98,95.59"><row><cell>Concept ID:</cell><cell>C27996</cell></row><row><cell cols="2">Concept name: Myocardial_Infarction</cell></row><row><cell>Parent IDs:</cell><cell>C35544</cell></row><row><cell>Synonyms:</cell><cell>Myocardial Infarction; Heart Attack; MI; Myocardial Infarct; Myocar-</cell></row><row><cell></cell><cell>dial Infarction, (MI)</cell></row><row><cell>Definition:</cell><cell>Gross necrosis of the myocardium, as a result of interruption of the</cell></row><row><cell></cell><cell>blood supply to the area, as in coronary thrombosis.</cell></row><row><cell cols="2">Concept status: -</cell></row><row><cell cols="2">Semantic types: Disease or Syndrome</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,134.77,116.83,364.30,192.14"><head>Table 2 .</head><label>2</label><figDesc>Parameter settings and results for official runs, re-runs" and additional experiments.</figDesc><table coords="11,136.16,154.75,362.90,154.23"><row><cell></cell><cell></cell><cell>Parameters</cell><cell>Results</cell></row><row><cell cols="3">Run Identifier Text Field Concept Field</cell><cell>MAP NDCG P@5 P@10 P@20</cell></row><row><cell>teckro1</cell><cell>text</cell><cell>concept_text</cell><cell>0.2430 0.5295 0.4276 0.4000 0.3207</cell></row><row><cell>teckro2</cell><cell>criteria</cell><cell>concept_incl_criteria</cell><cell>0.1653 0.4235 0.3172 0.3172 0.2508</cell></row><row><cell>teckro3</cell><cell>text</cell><cell>concept_child_text</cell><cell>0.2430 0.5295 0.4276 0.4000 0.3207</cell></row><row><cell cols="2">teckro3 re-run text</cell><cell>concept_child_text</cell><cell>0.1884 0.4898 0.3724 0.3103 0.2466</cell></row><row><cell>teckro4</cell><cell>criteria</cell><cell cols="2">concept_child_incl_criteria 0.1653 0.4235 0.3172 0.3172 0.2500</cell></row><row><cell cols="2">teckro4 re-run criteria</cell><cell cols="2">concept_child_incl_criteria 0.1054 0.3634 0.2000 0.1828 0.1397</cell></row><row><cell>teckro5</cell><cell>text</cell><cell cols="2">concept_child_incl_criteria 0.2435 0.5296 0.4276 0.4000 0.3224</cell></row><row><cell cols="2">teckro5 re-run text</cell><cell cols="2">concept_child_incl_criteria 0.1895 0.4899 0.3724 0.3103 0.2466</cell></row><row><cell>teckro6</cell><cell>text</cell><cell>concept_incl_criteria</cell><cell>0.2436 0.5301 0.4276 0.4138 0.3234</cell></row><row><cell>teckro7</cell><cell>text</cell><cell>concept_criteria</cell><cell>0.1905 0.4910 0.3862 0.3172 0.2603</cell></row><row><cell>teckro8</cell><cell>criteria</cell><cell>concept_criteria</cell><cell>0.1065 0.3638 0.2069 0.1793 0.1414</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,635.82,335.86,7.92;1,144.73,646.78,38.41,7.92"><p>The research described in this paper was conducted while Dr. Leveling was employed at teckro.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,658.44,174.63,7.47"><p>http://trec-cds.appspot.com/2017.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,658.44,127.07,7.47"><p>https://clinicaltrials.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,144.73,658.44,117.65,7.47"><p>https://ncit.nci.nih.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="10,144.73,647.48,145.89,7.47"><p>https://lucene.apache.org/core/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="10,144.73,658.44,288.57,7.47"><p>http://searchivarius.org/blog/accurate-bm25-similarity-lucene</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.95,494.27,337.64,7.92;12,151.52,505.22,329.07,7.92;12,151.52,516.18,87.01,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,291.48,494.27,189.12,7.92;12,151.52,505.22,87.47,7.92">Biomedical negation scope detection with conditional random fields</title>
		<author>
			<persName coords=""><forename type="first">Shashank</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,246.51,505.22,230.02,7.92">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="696" to="701" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,526.84,337.64,7.92;12,151.52,537.80,329.08,7.92;12,151.52,548.76,329.08,7.92;12,151.52,559.72,156.79,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,151.52,537.80,329.08,7.92;12,151.52,548.76,54.94,7.92">Finding appropriate clinical trials: evaluating encoded eligibility criteria with incomplete data</title>
		<author>
			<persName coords=""><forename type="first">Nachman</forename><surname>Ash</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omolola</forename><surname>Ogunyemi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucila</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ohno-Machado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,225.26,548.76,255.34,7.92;12,151.52,559.72,42.94,7.92">AMIA 2001, American Medical Informatics Association Annual Symposium</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="27" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,570.37,337.64,7.92;12,151.52,581.33,329.07,7.92;12,151.52,592.29,329.07,7.92;12,151.52,603.25,329.07,7.92;12,151.52,614.21,329.07,7.92;12,151.52,625.17,65.01,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,459.86,570.37,20.73,7.92;12,151.52,581.33,329.07,7.92;12,151.52,592.29,89.75,7.92">Identifying patients for clinical studies from electronic health records: TREC medical records track at OHSU</title>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyle</forename><forename type="middle">H</forename><surname>Ambert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,465.07,592.29,15.52,7.92;12,151.52,603.25,329.07,7.92;12,151.52,614.21,79.61,7.92">The Twentieth Text REtrieval Conference Proceedings (TREC 2011), volume Special Publication 500-296</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lori</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,635.82,337.64,7.92;12,151.52,646.78,329.07,7.92;12,151.52,657.74,122.50,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,359.69,635.82,120.90,7.92;12,151.52,646.78,230.68,7.92">Analysis of eligibility criteria representation in industry-standard clinical trial protocols</title>
		<author>
			<persName coords=""><forename type="first">Sanmitra</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">N</forename><surname>Cantor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,389.56,646.78,91.03,7.92;12,151.52,657.74,44.72,7.92">Journal of BiomedicaL Informatics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="805" to="813" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.95,120.62,337.64,7.92;13,151.52,131.58,329.07,7.92;13,151.52,142.54,329.07,7.92;13,151.52,153.49,20.99,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,238.15,131.58,242.44,7.92;13,151.52,142.54,114.14,7.92">A simple algorithm for identifying negated findings and diseases in discharge summaries</title>
		<author>
			<persName coords=""><forename type="first">Wendy</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Will</forename><surname>Bridewell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,273.89,142.54,135.73,7.92">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.95,164.45,337.64,7.92;13,151.52,175.41,143.48,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,222.33,164.45,101.53,7.92">How effective is suffixing</title>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,333.29,164.45,147.30,7.92;13,151.52,175.41,79.57,7.92">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.95,186.37,337.64,7.92;13,151.52,197.33,329.08,7.92;13,151.52,208.29,290.38,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,362.30,197.33,118.29,7.92;13,151.52,208.29,100.55,7.92">Overview of the TREC 2017 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Vorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shubham</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,272.02,208.29,114.24,7.92">TREC 2017 Notebook papers</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.95,219.25,337.64,7.92;13,151.52,230.21,263.45,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,321.99,219.25,158.61,7.92;13,151.52,230.21,72.15,7.92">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,232.25,230.21,98.04,7.92">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.95,241.17,337.64,7.92;13,151.52,252.12,329.08,7.92;13,151.52,263.08,20.99,7.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,366.91,241.17,113.69,7.92;13,151.52,252.12,107.81,7.92">Analysis of eligibility criteria complexity in clinical trials</title>
		<author>
			<persName coords=""><forename type="first">Jessica</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Samson</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simona</forename><surname>Carini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ida</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,266.28,252.12,160.79,7.92">Summit on Translational Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="46" to="50" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,274.04,337.98,7.92;13,151.52,285.00,329.07,7.92;13,151.52,295.96,329.08,7.92;13,151.52,306.92,40.43,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,247.04,285.00,233.55,7.92;13,151.52,295.96,129.37,7.92">A practical method for transforming free-text eligibility criteria into computable criteria</title>
		<author>
			<persName coords=""><forename type="first">Samson</forename><forename type="middle">W</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mor</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simona</forename><surname>Carini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bobak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jessica</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ida</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,289.89,295.96,141.10,7.92">Journal of BiomedicaL Informatics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="250" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,317.88,337.97,7.92;13,151.52,328.84,329.08,7.92;13,151.52,339.80,234.00,7.92" xml:id="b10">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Zarin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tony</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Califf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicholas</forename><forename type="middle">C</forename><surname>Ide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,220.19,328.84,256.80,7.92">The ClinicalTrials.gov results database -Update and key issues</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">364</biblScope>
			<biblScope unit="page" from="852" to="860" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
