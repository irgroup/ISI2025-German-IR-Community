<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.88,84.23,466.74,15.44">NOVASearch at TREC 2017 Real-Time Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,95.56,110.57,93.58,10.59"><forename type="first">Gustavo</forename><surname>Gonçalves</surname></persName>
							<email>gs.goncalves@campus.fct.unl.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Faculty of Science and Technology Universidade NOVA de Lisboa Caparica</orgName>
								<orgName type="institution">NOVA LINCS</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.07,110.57,70.86,10.59"><forename type="first">Flávio</forename><surname>Martins</surname></persName>
							<email>flaviomartins@acm.org</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science Faculty of Science and Technology Universidade NOVA de Lisboa Caparica</orgName>
								<orgName type="institution">NOVA LINCS</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,432.38,110.57,76.35,10.59"><forename type="first">João</forename><surname>Magalhães</surname></persName>
							<email>jm.magalhaes@fct.unl.pt</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science Faculty of Science and Technology Universidade NOVA de Lisboa Caparica</orgName>
								<orgName type="institution">NOVA LINCS</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.88,84.23,466.74,15.44">NOVASearch at TREC 2017 Real-Time Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C5A0794B2E47109209F619DCCE65FF5A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The rise of large data streams introduces new challenges regarding the delivery of relevant content towards an information need. This information need can be seen as a broad topic of information. One possible strategy to tackle the delivery of the most relevant documents regarding this broader topic is summarization. TREC 2017 Real-Time Summarization (RTS) provides a testbed for the development of stream based real-time summarization systems. Leveraging on the social media network, Twitter, the participants are challenged to deliver the most relevant and diverse information in two main scenarios.</p><p>The real-time push notifications scenario, or Scenario A, focuses on the identification and delivery of relevant information in near real-time. Whereas the daily-digest scenario, or scenario B, strives for the daily delivery of the most relevant and diverse documents.</p><p>This paper presents the participation of the NOVASearch group at TREC 2017 Real-Time Summarization (RTS). Our work was developed for tackling the scenario B, after an analysis of the proposed systems for the TREC RTS 2016. In our approach we explore document filtering methods; vocabulary expansions; and the identification of subtopics through the aggregation of documents based on their textual similarity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The continuous generation of content in social-media networks originates real-time data streams forming a deluge of data, that needs to be filtered and analyzed to identify information with significance towards end users. The TREC Real-Time Summarization (RTS) Track aims to tackle these issues through the delivery of the most relevant tweets in a near real-time push notifications scenario (A), or in a delayed digest in the daily summarization scenario (B). The two scenarios share the criteria of delivering relevant and diverse information. This track introduces new challenges, such as dealing with a dataset that is continuously expanding and prepare algorithms to face different relevance distributions over time, ultimately identifying the most relevant content and deliver it at just the right time. This ever-growing data volume might overwhelm users with duplicated or irrelevant information. This data volume introduces the need for algorithms that consider multiple features to estimate the relevance of a specific sub-branch of information and its change over time, to deliver relevant content at the right moment.</p><p>We developed a system aiming to participate in the daily summarization scenario, where significant occurrences towards a given topic are summarized at the end of the day. With our participation, we have studied the impact of different retrieval models, vocabulary expansion methods, and summarization approaches. Our architecture is presented in Section 3 of this paper, as well as the summarization technique explored, and finally, the achieved results are presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>To tackle this summarization challenge, we started by studying the participation notes of the TREC RTS 2016 track. From the fifteen participating teams of the 2016 TREC RTS track Lin et al. <ref type="bibr" coords="1,526.79,306.27,9.37,7.94" target="#b5">[6]</ref>, fourteen of them participated in the push notification scenario (A) and all of them in the daily summary scenario (B). As a starting point to develop our architecture we analyzed the approaches published in the participation papers that were submitted. The ten teams that submitted participation papers developed and evaluated systems for both scenarios A and B. We were able to identify the most common techniques that were used to tackle the different challenges posed by the track. Most works <ref type="bibr" coords="1,435.64,393.94,9.37,7.94" target="#b0">[1,</ref><ref type="bibr" coords="1,447.25,393.94,6.15,7.94" target="#b1">2,</ref><ref type="bibr" coords="1,455.64,393.94,6.15,7.94" target="#b3">4,</ref><ref type="bibr" coords="1,464.02,393.94,6.15,7.94" target="#b4">5,</ref><ref type="bibr" coords="1,472.41,393.94,8.28,7.94" target="#b10">[11]</ref><ref type="bibr" coords="1,480.69,393.94,4.14,7.94" target="#b11">[12]</ref><ref type="bibr" coords="1,480.69,393.94,4.14,7.94" target="#b12">[13]</ref><ref type="bibr" coords="1,480.69,393.94,4.14,7.94" target="#b13">[14]</ref><ref type="bibr" coords="1,480.69,393.94,4.14,7.94" target="#b14">[15]</ref><ref type="bibr" coords="1,484.83,393.94,12.42,7.94" target="#b15">[16]</ref> applied filtering and text cleaning techniques to the incoming tweets before further analysis and indexing. The employed filters and cleaning criteria were based on heuristics that varied in strictness across teams. The most aggressive filtering modules focused on discarding tweets that did not contain any query term, such as the ones applied in Lee et al. <ref type="bibr" coords="1,337.81,459.69,9.40,7.94" target="#b3">[4]</ref>, Li et al. <ref type="bibr" coords="1,381.89,459.69,9.40,7.94" target="#b4">[5]</ref>, Tan et al. <ref type="bibr" coords="1,432.73,459.69,13.36,7.94" target="#b13">[14]</ref>. Several works opt for a more permissive approach applying a filtering criterion that considers the text length, presence of URLs Bei and Hu <ref type="bibr" coords="1,481.46,481.61,9.37,7.94" target="#b1">[2]</ref>, Modha et al. <ref type="bibr" coords="1,542.92,481.61,13.33,7.94" target="#b10">[11]</ref>. In general, all works identified a need to strip special characters from the tweets, remove stop words and to stem the incoming text before further analysis and indexing.</p><p>The typical strategy used to achieve summarization was to define relevance and similarity thresholds as requirements for the submission of new information. Moreover, there are several approaches Moulahi et al. <ref type="bibr" coords="1,371.30,558.32,13.38,7.94" target="#b11">[12]</ref>, Suwaileh et al. <ref type="bibr" coords="1,446.69,558.32,13.38,7.94" target="#b12">[13]</ref>, Wang and Yang <ref type="bibr" coords="1,526.38,558.32,14.72,7.94" target="#b14">[15]</ref> that relied on query expansion to overcome the vocabulary mismatch problem brought forward by the characteristics of Twitter. Query expansions were based on external sources or the analysis of textual elements in the provided Interest Profiles. The external sources used ranged from Twitter itself to commercial search engines, such as Bing, as we can observe in the systems developed by Suwaileh et al. <ref type="bibr" coords="1,337.09,635.03,13.32,7.94" target="#b12">[13]</ref>, and Wang and Yang <ref type="bibr" coords="1,429.18,635.03,13.32,7.94" target="#b14">[15]</ref>, respectively. The identification and removal of duplicate information was a generalized concern tackled by all teams. Most teams defined a threshold based on a standard similarity measure, e.g., the Jaccard Similarity or designed their own as is the case of Moulahi et al. <ref type="bibr" coords="1,467.54,678.87,13.36,7.94" target="#b11">[12]</ref>. Some teams opted to use learning to rank methods in their systems, using features extracted from the available textual elements, with the objective of automatically tuning these thresholds for relevance and similarity; ultimately better preparing their systems for the track. Bagdouri and Oard <ref type="bibr" coords="2,165.83,394.07,10.55,7.94" target="#b0">[1]</ref> is an example of leveraging on these methods and external datasets to train their system. From this study we leveraged and adapted common techniques used across teams during the 2016 RTS track, emphasizing the work developed by the top three teams of the 2016 edition Moulahi et al. <ref type="bibr" coords="2,53.80,448.86,13.36,7.94" target="#b11">[12]</ref>, Suwaileh et al. <ref type="bibr" coords="2,128.27,448.86,13.36,7.94" target="#b12">[13]</ref>, Tan et al. <ref type="bibr" coords="2,183.08,448.86,13.36,7.94" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TOPIC SUMMARIZATION</head><p>To build our approach to the daily summarization problem, we surveyed the techniques used by the systems on the 2016 edition <ref type="bibr" coords="2,53.80,506.32,9.27,7.94" target="#b5">[6]</ref>. Our architecture is inspired by the best participants systems and applies a similar pipeline. The system can be split roughly into three stages: preprocessing, vocabulary expansion, and summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>To discern between noise and useful documents a couple of heuristics were used. These heuristics were employed to avoid indexing irrelevant documents as early as possible in the system's pipeline.</p><p>Firstly, incoming tweets are filtered according to the language of its textual content. We rely on the classification in the tweets' lang metadata field, included by Twitter. This field exposes the internal language classification made by Twitter. Only tweets written in English were considered, as defined in the track's guidelines.</p><p>To help with the removal of spam tweets, we filter tweets based on the URLs <ref type="bibr" coords="2,104.27,662.42,10.68,7.94" target="#b6">[7]</ref> linked in the text. The URLs are matched to a comprehensive URL blacklist <ref type="foot" coords="2,164.50,671.23,3.38,6.44" target="#foot_0">1</ref> and are discarded immediately, if the URL domain is contained in the blacklist. The list contains web Table <ref type="table" coords="2,342.14,85.73,3.45,7.70">2</ref>: Tweets containing URLS are expanded with title of the pointing URL Web page, creating the so called virtual document <ref type="bibr" coords="2,360.91,107.64,14.82,7.70" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweet text Expansion with URL page title</head><p>Russia's information war might be thought of as the biggest trolling operation in history Russian internet trolls were being hired to pose as pro-Trump Americans -Business Insider pages classified as fake news, gambling, and pornography; thus avoiding the exploration of tweets that contain URLs that lead to irrelevant content. The next step in our preprocessing pipeline consists in an adaptation of the work developed by the Qatar <ref type="bibr" coords="2,480.47,261.73,14.85,7.94" target="#b12">[13]</ref> and Hong-Kong <ref type="bibr" coords="2,317.96,272.69,14.85,7.94" target="#b13">[14]</ref> universities, in the 2016 edition of the track. We verify the tweets' quality by enforcing two criteria. First, a tweet must have more than twenty characters, and second, it must not be entirely capitalized. We used these criteria to guarantee that there were sufficient textual elements to be analyzed and to avoid the indexing of small trivial documents.</p><p>Finally, the last step of the module, before proceeding with the tweet's indexing, consists in cleaning the tweet's text. We clean the tweet's text by stripping it of special characters; splitting wellformed hashtags and adding the to the text; removing stopwords using Indri's stoplist<ref type="foot" coords="2,393.39,380.13,3.38,6.44" target="#foot_1">2</ref> ; applying a lower case filter; and stemming using the Porter stemming algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Vocabulary expansion</head><p>Twitter is a microblogging platform, and its documents are limited to 140 characters. Therefore, we apply query and document expansions to overcome the vocabulary limitations of the documents shared on this social media network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Query expansion.</head><p>For the query expansion, we experimented with two different models leveraging on Named Entity Recognition (NER) and Pseudo-Relevance Feedback (PRF) with external news sources. For the TREC RTS track, information needs were simulated through the creation of interest profiles that are composed by a title query, a description, and a narrative. The fields present in an interest profile differ regarding their extent, providing progressively more context and information about the user's information need.</p><p>For our query expansion based on NER, we identified entities in the narrative of the interest profile and added them to the title query, provided that they were not already present. The named entity recognition was achieved resorting to the CoreNLP software <ref type="bibr" coords="2,317.96,622.82,10.43,7.94" target="#b7">[8]</ref> developed by the Stanford NLP lab. We focused on the identification of locations, persons, organizations and miscellaneous entities in the narrative of the topics. This method aims to obtain more vocabulary related to the information need adding words that were not in the title query. However, due to stemming it will increase the weight of some words that might be under the same lexical root.</p><p>Moreover, this approach does not provide a generalized gain to all topics, since not all topics contain entities in their narratives.</p><p>For the PRF we leverage on the work of Martins et al. <ref type="bibr" coords="3,257.24,109.71,9.36,7.94" target="#b8">[9]</ref>, which have developed a framework, named Jitter API, that delivers expansion terms based on monitored Twitter endpoints. Martins et al. <ref type="bibr" coords="3,53.80,142.59,10.55,7.94" target="#b8">[9]</ref> employ time-aware ranking models to deliver expansion terms based on the content published on the monitored endpoints. We focused on the Pseudo-Relevance Vertical Feedback (PRVF) endpoint, that monitors the content published in Twitter news channels. From this endpoint we retrieved 20 expansion terms. Where the original query terms gathered a total weight of 50%. With this balance we aimed to avoid topic drifts, still leveraging on the recent topic terms that were detected by the Jitter API.</p><p>The NER expansion is combined with the title query using a weighted interpolation, expressed by</p><formula xml:id="formula_0" coords="3,190.83,240.35,104.60,9.81">Q = IP t + α N ERExp(IP {n } ).</formula><p>Where Q is the resulting query, IP t is the interest profile's title, α the determined interpolation factor, and N ERExp(IP {n } ) is the expansion of the interest profile's narrative. The PRF expansion terms provided by the Jitter API <ref type="bibr" coords="3,173.76,285.05,9.43,7.94" target="#b8">[9]</ref>, already consider the original query terms weighted accordingly.</p><p>The NER expansions were performed at the start of the competition, since they only depend on the interest profiles. Whereas the PRF expansions were made at the end of each day, before generating the summaries. <ref type="bibr" coords="3,115.39,383.98,14.72,7.94" target="#b9">[10]</ref> by using the virtual document model. We leverage on this idea, to expand the tweet's vocabulary. The tweet's vocabulary is expanded by adding the words in the titles of the linked web pages, to the tweet's original text. If the URL's domain shared in the tweet is not present in the URL blacklist, it will be followed. We will clean the text as in the preprocessing phase and index it jointly with the original tweet's text, provided that we can successfully extract the title of the resolved web page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Document expansion. The exploration of linked content via hyperlinks for microblog search was explored by McCreadie and Macdonald</head><p>Our premise is that trustworthy sources of information, such as news accounts, tend to use Twitter to share their news through short descriptions followed by a link for the full news. By extracting the web page title, we hope to expand the tweets vocabulary with words that were not initially present in the short news description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Retrieval</head><p>We leveraged on several retrieval models to obtain the ranking of the documents, such as Vector Space Model with cosine distance (VSM), Okapi-BM25, and query-likelihood language models with Jelinek-Mercer and Dirichlet smoothing retrieval models.</p><p>We tuned the parameters of BM25 on the TREC RTS 2016 dataset and found the best parameters to be k = 1.0, and b = 0.2. These values indicate that BM25 performs better is stronger when focusing on term frequency, and less to document length normalization, in a dataset composed of small documents.</p><p>We use language modeling with Jelinek-Mercer (LMJM) smoothing with the parameter λ = 0.9. The LMJM smoothing settled on a relatively high-value when compared with previous studies, where λ = 0.1 <ref type="bibr" coords="3,82.02,687.64,13.26,7.94" target="#b16">[17]</ref>. However, these experiments were done on larger documents. Thus we verified that when working with short documents LMJM performs better when relying on the relative weighting of terms, aiming to match most query terms.</p><p>We use language modeling with Dirichlet (LMD) smoothing with the parameter µ = 200. For LMD we found better results with a small value when compared with the usual value µ = 2000 <ref type="bibr" coords="3,542.72,131.63,13.49,7.94" target="#b16">[17]</ref>. Once again this is due to the short length of our documents. Using this parameterization makes LMD focus on term frequency for matching documents to queries.</p><p>The best parameters found by tuning on the TREC 2016 dataset are used for the experiments with the TREC 2017 dataset for better ranking results. We also leveraged on Reciprocal Rank Fusion (RRF) <ref type="bibr" coords="3,317.96,208.34,9.28,7.94" target="#b2">[3]</ref>, with the proposed value of 60 for web datasets, to combine the results of these tuned models: BM25, LMD, and VSM, to diversify our ranking and better approximate the optimal ranking. The usage of RRF was also influenced by the limitation of the number of submissions. Since each team is limited to submit three runs, in each scenario, we use RRF to fuse different rankings aiming to gather more relevant documents; and using the runs to evaluate other features of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Summarization</head><p>The final module of our system is the summarization module. This module strives to identify subtopics of interest that arise during the event, under the main topic. We aimed to summarize a topic by grouping documents and choosing the most representative ones to submit to the daily summary.</p><p>Our summarization strategy was developed to meet the evaluation procedure of the track. Where relevant documents were semantically clusters by NIST assessors, and only the first submitted tweet from each cluster would contribute for the final score. With this evaluation procedure in mind, we implemented a singlepass clustering and diversity algorithm, Algorithm 1.</p><p>Algorithm 1 iterates the document ranking, for every query, by the decrescent score of documents, as shown in lines 4 to 16. In lines 6 and 7 we can observe that the first document in the ranking will form the first cluster. Afterwards, every document will be compared with the first document of each cluster. Since the clusters are created following the ranking score, the comparison with the first document of each cluster guarantees that we are comparing each document with the most relevant document of each cluster. In lines 9 to 13, we add each document to the first cluster where the similarity comparison surpasses the pre-defined threshold. If a candidate document never surpasses the threshold, it will create a new cluster where the document will be the cluster representative, as shown in line 12. We leverage on the Jaccard similarity to assess the similarity among documents, where an experimental threshold of 0.22 was set for our submission. Finally, in lines 17 and 18 we iterate the set of all clusters, to retrieve the document with the highest score from each cluster, and return the synthesized ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>Each participant was limited to submit at most three runs for evaluation, in each scenario. For this edition of the track, relevance was measured with resort to the nDCGp@10 and nDCG1@10 variations of the nDCG@10 metric. These variations differ from nDCG@10, since they account for the submission of documents for uneventful Algorithm 1: Single-pass Jaccard diversity grouping input : A similarity threshold, jaccThresh, and a document ranking, R. output : An ordered list, L, of the representatives with the highest score.  <ref type="table" coords="4,170.02,580.77,4.17,7.94">3</ref> summarizes the features used in each of the submitted runs. Our first run consisted on a temporalaware learning to rank model named RMTS, developed by Martins et al. <ref type="bibr" coords="4,73.77,613.65,9.42,7.94" target="#b8">[9]</ref>, without the vocabulary expansions and clustering algorithm. Secondly, we submitted a run leveraging on the RRF document ranking with both query expansion based on PRF with NER title queries, and document expansions; and clustering of the document ranking. The third run also leveraged on the RRF document ranking, with both query expansion based on NER and document expansions; and clustering of the document ranking.</p><p>Observing Table <ref type="table" coords="4,126.38,690.36,4.20,7.94" target="#tab_1">4</ref> we can verify that both nDCGp and nDCG1 present the same value for Run 1. This is an expected result since  <ref type="table" coords="4,501.76,397.07,3.04,7.94">3</ref>. However, the results obtained by these two runs differ hugely, possibly indicating that the queries expansions provided by the Jitter API <ref type="bibr" coords="4,513.70,418.98,10.44,7.94" target="#b8">[9]</ref> were not properly tuned for this track, taking full advantage of the temporal ranking provided by the API. The overall performance of our runs was positive, staying above the nDCGp and nDCG1 median, that were 0.1868 and 0.1155 respectively, with our best run being Run 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Post-mortem experiments.</head><p>With the conclusion of the track and the publication of the relevance judgments, we made final experiments with our system, that assessed the impact of each of the components of our best run, and are presented in Table <ref type="table" coords="4,519.31,525.13,3.02,7.94" target="#tab_2">5</ref>. The first line of the table shows our best submitted run as a comparison reference towards the other lines.</p><p>Through this experiment we have identified that the best configuration (BC) of our system was obtained through the utilization of the LMD retrieval model, with the tuned parameters; document and query expansion based on NER; and clustering the document ranking. As we can observe in the third line of Table <ref type="table" coords="4,515.86,601.84,3.13,7.94" target="#tab_2">5</ref>, the document expansion with the title of webpages was our best investment, providing the greatest relevance loss when removed from the BC. The query expansion based on NER did provided a slight less loss, when removed from the BC. Indicating that it deserves further a more careful study on how can he be employed to enhance our results. Finally, and surprisingly, the clustering module was the one that had a trivial impact on the overall relevance. With this analysis we understood that there is still a lot of room for improvement in our subtopic detection strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Our approach to solve the daily-digest summarization problem was composed of many features. It ended up being a exploratory work of these features, that delivered satisfactory results being above the median. From the vocabulary expansions, the document expansion with the webpage titles was the approach with the biggest impact. The query expansions both with NER and PRF, need further development; The NER approach can be better explored with the identification of named entities also in the tweet text. For the PRF expansion, leveraging on the Jitter API, careful tuning is needed to extract better results. The document retrieval using RRF did not generate the expected results, what indicates that a more careful review and tuning is needed.</p><p>Ultimately, through our participation in this track we have obtained an excellent insight about the dynamics of subtopics across time. The detection of subtle changes in documents sharing the same topic, is a difficult task that needs further research. Moreover the detection of such changes in real-time can be crucial to deliver immediately the most relevant content towards end users; Thus showing the significance of this task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,56.21,148.90,60.72,8.83;4,56.21,160.85,53.77,8.83;4,56.21,172.81,92.87,8.83;4,56.21,184.76,116.30,8.83;4,56.21,198.69,3.07,5.13;4,77.52,195.72,67.32,8.83;4,56.21,210.65,3.07,5.13;4,77.61,208.49,97.80,8.02;4,56.21,221.61,3.07,5.13;4,90.92,218.64,73.69,8.83;4,56.21,233.56,3.07,5.13;4,77.61,231.69,15.51,7.70;4,56.21,244.52,3.07,5.13;4,91.46,241.55,63.84,8.97;4,95.72,252.51,183.21,8.83;4,95.94,264.56,18.67,7.70;4,53.13,277.40,6.15,5.13;4,104.90,274.43,45.06,8.97;4,53.13,289.35,6.15,5.13;4,91.46,287.48,15.51,7.70;4,53.13,300.31,6.15,5.13;4,104.77,297.34,114.50,8.83;4,53.13,312.27,6.15,5.13;4,91.46,310.39,14.94,7.70;4,53.13,324.22,6.15,5.13;4,77.61,322.35,14.94,7.70;4,53.13,336.18,6.15,5.13;4,77.21,333.21,84.19,8.97;4,53.13,346.26,25.57,7.70;4,53.13,357.12,168.30,8.97;4,53.13,369.94,64.49,7.94;4,53.80,566.08,136.39,9.37;4,63.76,580.71,104.03,8.04"><head>1 5 Doc ← R[counter ] 6 if isEmpty (Clusters) then 7 Clusters</head><label>567</label><figDesc>Clusters ← {} 2 counter ← 0 3 rankSize ←Length(R) 4 while counter &lt; rankSize do Clusters : L ← L + getFirstDoc(c1) 18 return sort(L) 4.1 Results and discussion 4.1.1 Submitted runs. Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,53.50,85.73,240.54,145.47"><head>Table 1 :</head><label>1</label><figDesc>Summary of the approaches used in TREC RTS 2016.</figDesc><table coords="2,129.87,108.64,114.03,122.55"><row><cell>Pre-</cell><cell></cell><cell cols="2">Summarization</cell></row><row><cell cols="2">processing</cell><cell cols="2">techniques</cell></row><row><cell>Filtering</cell><cell>Text cleaning</cell><cell>Threshold definition</cell><cell>Query or Doc. expansion</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,370.10,85.73,133.71,69.95"><head>Table 4 :</head><label>4</label><figDesc>Submitted runs results</figDesc><table coords="4,370.10,111.63,133.71,44.04"><row><cell cols="3">Run ID nDCGp@10 nDCG1@10</cell></row><row><cell>1</cell><cell>0.1896</cell><cell>0.1896</cell></row><row><cell>2</cell><cell>0.1440</cell><cell>0.1333</cell></row><row><cell>3</cell><cell>0.2710</cell><cell>0.2587</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,317.66,177.38,242.06,227.63"><head>Table 5 :</head><label>5</label><figDesc>The Best Configuration (BC) is composed of the LMD retrieval model, query expansion with NER, document expansion with URLs and results clustering. The impact of each component is illustrated in the different rows.</figDesc><table coords="4,357.04,236.16,159.83,78.50"><row><cell></cell><cell cols="2">Cumulative index 2017</cell></row><row><cell>Method</cell><cell>nDCGp</cell><cell>nDCG1</cell></row><row><cell>TREC</cell><cell>0.2710</cell><cell>0.2587</cell></row><row><cell>BC</cell><cell>0.2831</cell><cell>0.2697</cell></row><row><cell>BC -U RL</cell><cell>0.2675</cell><cell>0.2554</cell></row><row><cell>BC -N ER</cell><cell>0.2746</cell><cell>0.2601</cell></row><row><cell>BC -Clust er inд</cell><cell>0.2812</cell><cell>0.2682</cell></row></table><note coords="4,317.96,342.27,241.76,7.94;4,317.96,353.23,241.76,7.94;4,317.96,364.19,241.23,7.94;4,317.96,375.15,240.25,7.94;4,317.96,386.11,241.76,7.94;4,317.73,397.07,181.80,7.94"><p>the Run 1 system does not have a strategy for grouping or nonsubmitting documents; hence being fully penalized by always submitting tweets on silent days. Run 2 is our run with most features, combining all the modules that we have developed. Whereas Run 3 only differs from Run 2, by not making use of the expansions provided by the Jitter API, as we can observe in Table</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,56.72,702.46,106.59,6.18"><p>https://github.com/StevenBlack/hosts</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,321.00,702.06,146.82,6.18"><p>http://www.lemurproject.org/stopwords/stoplist.dft</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,111.11,465.04,6.30,7.67;4,174.67,465.04,6.30,7.67;4,220.85,465.04,6.30,7.67;4,53.80,501.73,240.24,7.94;4,53.80,512.69,240.25,7.94;4,53.80,523.65,241.76,7.94;4,53.80,534.60,240.25,7.94;4,53.80,545.56,224.88,7.94"><p>√ √ √days, for a given query. The nDCG1@10 metric is the strictest of the metrics, where the submission of one tweet during a uneventful day will result in a complete loss of the available bonus for not submitting during a silent day. Whereas for nDCGp@10 will produce a score loss based on a decay, with a limit to up to ten tweets.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,69.23,334.76,225.06,6.18;5,69.23,342.68,224.81,6.23;5,69.23,350.65,224.81,6.23;5,69.23,358.67,224.81,6.18;5,69.23,366.64,97.32,6.18" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,211.58,334.76,82.71,6.18;5,69.23,342.73,23.13,6.18">CLIP at TREC 2016: LiveQA and RTS</title>
		<author>
			<persName coords=""><forename type="first">Mossaab</forename><surname>Bagdouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,106.40,342.68,166.40,6.23;5,151.78,358.67,78.19,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,69.23,374.61,224.81,6.18;5,69.03,382.53,225.78,6.23;5,69.23,390.50,224.81,6.23;5,69.23,398.52,224.81,6.18;5,69.03,406.49,55.28,6.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,153.59,374.61,140.45,6.18;5,69.03,382.58,15.12,6.18">CCNU at TREC 2016 Real-Time Summarization Track</title>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Bei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Po</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,96.59,382.53,161.84,6.23;5,114.62,398.52,75.79,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,69.23,414.46,224.81,6.18;5,69.23,422.43,225.88,6.18;5,69.23,430.35,224.81,6.23;5,69.23,438.32,225.58,6.23;5,69.07,446.34,141.44,6.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,264.44,414.46,29.60,6.18;5,69.23,422.43,222.53,6.18">Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Buettcher</surname></persName>
		</author>
		<idno type="DOI">10.1145/1571941.1572114</idno>
		<ptr target="https://doi.org/10.1145/1571941.1572114" />
	</analytic>
	<monogr>
		<title level="m" coord="5,76.88,430.35,217.17,6.23;5,69.23,438.32,140.63,6.23">Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;09)</title>
		<meeting>the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;09)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,69.23,454.31,224.81,6.18;5,69.23,462.28,224.81,6.18;5,69.23,470.20,224.81,6.23;5,69.23,478.17,224.81,6.23;5,69.23,486.14,224.81,6.23;5,69.23,494.16,181.69,6.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,168.02,462.28,126.02,6.18;5,69.23,470.25,123.33,6.18">Assorted Textual Features and Dynamic Push Strategies for Real-Time Tweet Notification</title>
		<author>
			<persName coords=""><forename type="first">Kathy</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vivek</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaditya</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,204.70,470.20,89.34,6.23;5,69.23,478.17,70.75,6.23;5,239.03,486.19,55.01,6.18;5,69.23,494.16,20.43,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,69.23,502.13,225.88,6.18;5,69.23,510.10,224.81,6.18;5,69.23,518.02,224.81,6.23;5,69.23,525.99,225.57,6.23;5,69.23,533.96,225.89,6.23;5,69.23,541.98,156.60,6.18" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,69.23,510.10,224.81,6.18;5,69.23,518.07,104.77,6.18">HLJIT at TREC 2016: The Approaches Based on Document Language Model for Real-Time Summarization Track</title>
		<author>
			<persName coords=""><forename type="first">Song</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhenyuan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leilei</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haoliang</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,187.75,518.02,106.29,6.23;5,69.23,525.99,56.18,6.23;5,216.79,534.01,75.44,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,69.23,549.95,225.58,6.18;5,69.23,557.92,224.81,6.18;5,69.03,565.84,225.78,6.23;5,69.23,573.81,225.58,6.23;5,69.00,581.83,225.22,6.18;5,69.03,589.80,20.18,6.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,141.57,557.92,152.47,6.18;5,69.03,565.89,15.12,6.18">Overview of the TREC-2016 Real-Time Summarization Track</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,96.59,565.84,161.84,6.23;5,81.47,581.83,75.22,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,69.23,597.77,224.94,6.18;5,69.23,605.69,224.81,6.23;5,69.23,613.66,225.58,6.23;5,69.12,621.68,225.75,6.18;5,69.01,629.65,97.00,6.18" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,192.72,597.77,101.46,6.18;5,69.23,605.74,28.45,6.18">Observing Common Spam in Twitter and Email</title>
		<author>
			<persName coords=""><forename type="first">Cristian</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Feamster</surname></persName>
		</author>
		<idno type="DOI">10.1145/2398776.2398824</idno>
		<ptr target="https://doi.org/10.1145/2398776.2398824" />
	</analytic>
	<monogr>
		<title level="m" coord="5,111.84,605.69,182.20,6.23;5,69.23,613.66,56.76,6.23">Proceedings of the 12th ACM SIGCOMM Internet Measurement Conference, IMC &apos;12</title>
		<editor>
			<persName><forename type="first">Jim</forename><surname>Byers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ratul</forename><surname>Kurose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Mahajan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Snoeren</surname></persName>
		</editor>
		<meeting>the 12th ACM SIGCOMM Internet Measurement Conference, IMC &apos;12<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-11-14">2012. November 14-16, 2012</date>
			<biblScope unit="page" from="461" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,69.23,637.62,224.81,6.18;5,69.23,645.59,224.81,6.18;5,69.23,653.51,224.81,6.23;5,69.23,661.48,225.57,6.23;5,69.23,669.45,208.75,6.23" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,175.34,645.59,118.71,6.18;5,69.23,653.56,51.43,6.18">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,132.75,653.51,161.30,6.23;5,69.23,661.48,113.11,6.23;5,69.23,669.45,185.97,6.23">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06-22">2014. June 22-27, 2014</date>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
	<note>System Demonstrations. The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct coords="5,69.23,677.47,224.81,6.18;5,69.23,685.44,224.81,6.18;5,69.23,693.36,224.81,6.23;5,69.23,701.33,224.81,6.23;5,333.28,89.10,225.75,6.18;5,333.17,97.07,97.00,6.18" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,241.08,677.47,52.96,6.18;5,69.23,685.44,213.42,6.18">Barbara Made the News: Mining the Behavior of Crowds for Time-Aware Learning to Rank</title>
		<author>
			<persName coords=""><forename type="first">Flávio</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">João</forename><surname>Magalhães</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2835776.2835825</idno>
		<ptr target="https://doi.org/10.1145/2835776.2835825" />
	</analytic>
	<monogr>
		<title level="m" coord="5,69.23,693.36,224.81,6.23;5,69.23,701.33,18.83,6.23">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</title>
		<editor>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vanja</forename><surname>Josifovski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</editor>
		<meeting>the Ninth ACM International Conference on Web Search and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-02-22">2016. February 22-25, 2016</date>
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,105.04,225.99,6.18;5,333.39,112.96,224.81,6.23;5,333.39,120.93,225.58,6.23;5,333.28,128.95,160.79,6.18" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,474.47,105.04,84.91,6.18;5,333.39,113.01,155.45,6.18">Relevance in Microblogs: Enhancing Tweet Retrieval Using Hyperlinked Documents</title>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,501.45,112.96,56.75,6.23;5,333.39,120.93,91.16,6.23">Open Research Areas in Information Retrieval, OAIR &apos;13</title>
		<editor>
			<persName><forename type="first">João</forename><surname>Ferreira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">João</forename><surname>Magalhães</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pável</forename><surname>Calado</surname></persName>
		</editor>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-05-15">2013. May 15-17, 2013</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,136.92,224.99,6.18;5,333.39,144.89,224.81,6.18;5,333.39,152.81,225.57,6.23;5,333.39,160.78,224.81,6.23;5,333.39,168.80,224.81,6.18;5,333.18,176.77,55.28,6.18" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,381.31,144.89,176.89,6.18;5,333.39,152.86,17.06,6.18">DAIICT at TREC RTS 2016: Live Push Notification and Email Digest</title>
		<author>
			<persName coords=""><forename type="first">Sandip</forename><surname>Modha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krati</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deepali</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prasenjit</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chintak</forename><surname>Mandalia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,362.66,152.81,160.26,6.23;5,378.77,168.80,75.79,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,333.39,184.74,224.81,6.18;5,333.39,192.71,225.88,6.18;5,333.39,200.63,224.81,6.23;5,333.39,208.60,224.81,6.23;5,333.39,216.57,224.81,6.23;5,333.39,224.59,181.69,6.18" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,333.39,200.68,112.42,6.18">IRIT at TREC Real-Time Summarization</title>
		<author>
			<persName coords=""><forename type="first">Bilel</forename><surname>Moulahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lamjed</forename><surname>Ben Jabeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamine</forename><surname>Lynda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,471.04,200.63,87.16,6.23;5,333.39,208.60,70.75,6.23;5,503.19,216.62,55.01,6.18;5,333.39,224.59,20.43,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,333.39,232.56,225.99,6.18;5,333.39,240.48,224.81,6.23;5,333.39,248.45,225.57,6.23;5,333.39,256.42,224.81,6.23;5,333.39,264.44,215.64,6.18" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,505.04,232.56,54.34,6.18;5,333.39,240.53,180.80,6.18">Light-Weight, Conservative, yet Effective: Scalable Real-Time Tweet Summarization</title>
		<author>
			<persName coords=""><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,526.56,240.48,31.64,6.23;5,333.39,248.45,122.32,6.23;5,538.48,256.47,19.72,6.18;5,333.39,264.44,54.38,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,333.39,272.41,224.81,6.18;5,333.39,280.33,225.57,6.23;5,333.39,288.30,224.81,6.23;5,333.39,296.32,224.81,6.18;5,333.39,304.29,97.32,6.18" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="5,466.91,272.41,91.29,6.18;5,333.39,280.38,42.47,6.18">PolyU at TREC 2016 Real-Time Summarization</title>
		<author>
			<persName coords=""><forename type="first">Haihui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dajun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,389.75,280.33,166.25,6.23;5,415.94,296.32,78.19,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,333.39,312.26,224.81,6.18;5,333.18,320.18,225.78,6.23;5,333.39,328.15,224.81,6.23;5,333.39,336.17,224.81,6.18;5,333.18,344.14,55.28,6.18" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="5,425.63,312.26,132.57,6.18;5,333.18,320.23,15.12,6.18">BJUT at TREC 2016: Real-Time Summarization Track</title>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,360.74,320.18,161.84,6.23;5,378.77,336.17,75.79,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,333.39,352.11,225.02,6.18;5,333.39,360.08,224.81,6.18;5,333.39,368.00,225.57,6.23;5,333.39,375.97,224.81,6.23;5,333.39,383.99,224.81,6.18;5,333.18,391.96,55.28,6.18" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="5,531.35,352.11,27.06,6.18;5,333.39,360.08,224.81,6.18;5,333.39,368.05,17.06,6.18">PKUICST at TREC 2016 Real-Time Summarization Track: Push Notifications and Email Digest</title>
		<author>
			<persName coords=""><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Feifan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,362.66,368.00,160.26,6.23;5,378.77,383.99,75.79,6.18">Proceedings of The Twenty-Fifth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Fifth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-15">2016. 2016. November 15-18, 2016</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
	<note>Special Publication 500-321</note>
</biblStruct>

<biblStruct coords="5,333.39,399.93,224.94,6.18;5,333.39,407.85,224.81,6.23;5,333.18,415.87,154.39,6.18" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="5,460.53,399.93,97.81,6.18;5,333.39,407.90,145.30,6.18">A Study of Smoothing Methods for Language Models Applied to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<idno type="DOI">10.1145/984321.984322</idno>
		<ptr target="https://doi.org/10.1145/984321.984322" />
	</analytic>
	<monogr>
		<title level="j" coord="5,483.92,407.85,59.40,6.23">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
