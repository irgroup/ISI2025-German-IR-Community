<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,91.72,112.00,428.56,15.15;1,175.61,133.91,260.78,15.15">Experiments with the Negotiated Boolean Queries of the TREC 2009 Legal Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-02-02">February 2, 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,264.32,167.81,83.35,8.74"><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
							<email>stomlins@opentext.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Open Text Corporation</orgName>
								<address>
									<settlement>Ottawa</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,91.72,112.00,428.56,15.15;1,175.61,133.91,260.78,15.15">Experiments with the Negotiated Boolean Queries of the TREC 2009 Legal Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-02-02">February 2, 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">5AA12AD9675E05EF1740E65B28097F3D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For our participation in the Batch Task of the TREC 2009 Legal Track, we produced several retrieval sets to compare experimental Boolean, vector, fusion and relevance feedback techniques for e-Discovery requests. In this paper, we have reported not just the mean scores of the experimental approaches but also the largest per-topic impacts of the techniques for several measures. The experimental automatic relevance feedback technique was found to attain a statistically significant gain over the reference Boolean result in both the mean Precision@B and F 1 @K measures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open Text eDOCS SearchServer TM is a toolkit for developing enterprise search and retrieval applications. The eDOCS SearchServer kernel is also embedded in various components of the Open Text eDOCS Suite 1 .</p><p>The eDOCS SearchServer kernel works in Unicode internally <ref type="bibr" coords="1,354.11,436.98,10.52,8.74" target="#b6">[7]</ref> and supports most of the world's major character sets and languages. The major conferences in text retrieval experimentation (TREC <ref type="bibr" coords="1,479.08,448.94,14.61,8.74" target="#b11">[12]</ref>, CLEF <ref type="bibr" coords="1,529.48,448.94,10.52,8.74" target="#b4">[5]</ref> and NTCIR <ref type="bibr" coords="1,128.07,460.89,10.79,8.74" target="#b8">[9]</ref>) have provided judged test collections for objective experimentation with the SearchServer kernel in more than a dozen languages.</p><p>This paper describes experimental work with the eDOCS SearchServer kernel (experimental post-6.0 builds) conducted in part by participating in the Batch task of the TREC 2009 Legal Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Batch Task</head><p>The Batch task of the TREC 2009 Legal Track investigated the effectiveness of ad hoc and relevance feedback search techniques for e-Discovery.</p><p>The Batch task evolved from the Ad Hoc and Relevance Feedback tasks of past Legal Tracks. We have participated in the 4 years of the Legal Track to date. (We also have helped with coordinating the Legal Track for the past three years as described in <ref type="bibr" coords="1,273.00,593.37,14.61,8.74" target="#b17">[18]</ref>, <ref type="bibr" coords="1,294.58,593.37,15.50,8.74" target="#b9">[10]</ref> and <ref type="bibr" coords="1,332.78,593.37,10.30,8.74" target="#b5">[6]</ref>.)</p><p>As in the previous three years, the document collection to be searched was the IIT Complex Document Information Processing (IIT CDIP) test collection <ref type="bibr" coords="1,299.37,617.28,9.96,8.74" target="#b7">[8]</ref>. It contained 6,910,192 metadata records from US tobacco companies; 6,794,895 of the records included document text of varying quality from an optical character reader. Uncompressed, the collection was 61,251,357,065 bytes (57.0 GB). The average record size (including metadata markup and the ocr document) was 8864 bytes, though the records varied considerably in length.</p><p>In e-Discovery (also known as eDiscovery, electronic discovery or legal discovery), the goal is to return all documents responsive (relevant) to a production request, without returning any non-responsive documents.</p><p>For the Batch task of the TREC Legal Track, the organizers re-used 10 of the production requests from past years, herein called topics, numbered from 7 to 145. Each topic included a "request text" (a natural language description of the request, typically one-sentence), a "defendant query" (an initial Boolean query proposed by the defendant), a "plaintiff query" (a rejoinder Boolean query from the plaintiff) and a "final negotiated query" (the final Boolean query from the negotiations). (Examples of some of these appear below.) The final negotiated Boolean query is sometimes referred to as the "reference Boolean" query.</p><p>Furthermore, the relevance judgments from previous years for the topics were available for use as an input to the systems. On average, 2000 document assessments were available per topic (ranging from 499 for topic 145 to 6500 for topic 103). These input relevance judgments are sometimes referred to as "training judgments", "training examples" or "training qrels". This year's scoring was done with entirely new judgments, however, and if the sampling happened to select a document judged in past years, it was not guaranteed that this year's assessors would agree with the past assessment.</p><p>[19] and <ref type="bibr" coords="2,124.06,266.44,10.52,8.74" target="#b5">[6]</ref> have more details on the track and task, and <ref type="bibr" coords="2,331.50,266.44,10.52,8.74" target="#b0">[1]</ref> and <ref type="bibr" coords="2,363.63,266.44,10.52,8.74" target="#b1">[2]</ref> have more background on e-Discovery in general. Also, background on our past participations in the track are in <ref type="bibr" coords="2,399.71,278.40,14.61,8.74" target="#b14">[15]</ref>, <ref type="bibr" coords="2,421.31,278.40,14.61,8.74" target="#b15">[16]</ref>, <ref type="bibr" coords="2,442.89,278.40,14.61,8.74" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>Our index was the same as the past few years. Our index included both the metadata and the ocr document of each record. We indexed from the "&lt;/tid&gt;" tag to the "&lt;/record&gt;" tag, which meant both the metadata and the ocr document were in the FT TEXT column. Any tags themselves were indexed (we just didn't bother to discard them). Entities (e.g. "&amp;amp;") were converted to the character they represented (e.g. "&amp;").</p><p>We did not use a stopword list, and we also indexed most punctuation as 1-character words (exceptions were the hyphen and apostrophe, which were treated as 1-character stopwords). The contents of the "&lt;dd&gt;" section of the metadata were additionally indexed in a separate DOCDATE column, though this column was not used by the queries this year.</p><p>The index supported both searching on just the surface forms of the words and also searching on inflections from English lexical stemming. The documents were assumed to be in the Windows-1252 character set when converted to Unicode. Words were normalized to upper-case and any accents were dropped.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Searching</head><p>The techniques used for our 3 submitted Batch runs of August 2009 and 3 other diagnostic runs are described below. The relevance ranking approach was the same as past years. The relevance function dampened the term frequency and adjusted for document length in a manner similar to Okapi <ref type="bibr" coords="2,436.71,531.39,15.50,8.74" target="#b10">[11]</ref> and dampened the inverse document frequency using an approximation of the logarithm. For wildcard terms (e.g. "televis!"), all variants (e.g. "television", "televised", "televisions", etc.) were treated as occurrences of the same term for term frequency purposes, and inverse document frequency was based on the most common variant. For runs which used inflectional matching, these calculations were based on the stems of the terms. For terms in phrases or proximity contraints of Boolean queries, only occurrences of the term satisfying the phrase or proximity counted towards term frequency.</p><p>The 3 submitted Batch task runs (and 3 other diagnostic runs) were as follows: otL09fb (final Boolean run): (This run was not submitted). The otL09fb run used the final negotiated query, respecting the Boolean operators such as AND, phrase, proximity, NOT, etc. Full wildcard matching was supported. Relevance-ranking was still used to order the matching rows. For example, for topic 118 (which was not actually one of this year's topics), for which the final negotiated query was "(malfunction! OR breakdown! OR failure! OR fault! OR incident!) w/25 ((manufactur! OR assembl! OR fabricat! OR produc!) OR (test! OR trial! OR exam! OR validat! OR evaluat!))", the corresponding SearchSQL statement would be SELECT RELEVANCE('2:3') AS REL, DOCNO FROM LEGAL09FULL WHERE (FT_TEXT CONTAINS 'malfunction%', 'breakdown%', 'failure%', 'fault%', 'incident%' within 25 words of 'manufactur%', 'assembl%', 'fabricat%', 'produc%', 'test%', 'trial%', 'exam%', 'validat%', 'evaluat%') ORDER BY REL DESC; otL09fv (final vector run): (This run was not submitted). The otL09fv run was the same as otL09fb except that the Boolean operators such as AND, phrases and proximities were dropped (all operators became an OR), and punctuation was dropped. Full wildcarding was still respected. <ref type="bibr" coords="3,406.35,214.64,14.56,8.74">For</ref>  The submitted otL09rvl run was the same as otL09fv except that (1) the terms were taken from the request text field instead of the final negotiated query field, (2) linguistic expansion from English inflectional stemming was applied, and (3) common instruction words (e.g. "please", "produce", "documents") were manually removed. For example, for topic 118, for which the request text was "Please produce all reports, written memoranda, correspondence, and other documents related to past incidents involving the malfunction of machinery in connection with manufacturing or testing activities, or which occurred within manufacturing or testing facilities.", the WHERE clause of the corresponding SearchSQL statement would be otL09frw (baseline fusion run): (This run was not submitted). The otL09frw run was a weighted fusion of the final Boolean, request text vector and final vector runs: weight 3 on otL09fb, weight 2 on otL09rvl, and weight 1 on otL09fv. Each input run was retrieved to depth 1,500,000 (or however many documents it matched if it matched fewer than 1,500,000). This year we used the "Reciprocal Rank Fusion" (RRF) algorithm to combine the input runs. <ref type="bibr" coords="3,238.43,493.59,10.52,8.74" target="#b3">[4]</ref> otL09F (pure feedback run): The submitted otL09F run did not make any use of the topic fields. Instead, the run used a feedback technique based on the set of documents that were previously judged relevant (the "feedback set"). Documents of 10000 bytes or more (in the xml formatting of the collection) were excluded from the feedback set in hopes of reducing the percentage of input text that was not relevant. In some cases the feedback set was further restricted to a random sample to cap the number of input documents at approximately 200. The documents of the final feedback set were used as the input to the SearchServer IS ABOUT predicate which created a vector query from the highest weighted terms (based on a tf.idf calculation after appending the input documents together). English inflections were enabled, and stems in more than 5% of the collection's documents were omitted.</p><p>otL09frwF (feedback fusion run): The submitted otL09frwF run was a weighted fusion of the pure feedback, final Boolean, request text vector and final vector runs: weight 3 on otL09F, weight 3 on otL09fb, weight 2 on otL09rvl, and weight 1 on otL09fv (same fusion approach as otL09frw except for additionally including the feedback run as an input).</p><p>For each run, only 1,500,000 rows were allowed to be submitted for each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Avg. K R@K P@K F 1 @K Gray@K Avg. Num.   </p><formula xml:id="formula_0" coords="4,112.78,173.39,385.94,23.68">(high rel) Avg. K h R@K h P@K h F 1 @K h Gray@K h Avg. Num. Judged@K h otL09F<label>26582</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Thresholding</head><p>Like last year, the systems were required to specify a cutoff value "K" for each topic at which the track's main measure, F 1 @K, would be computed. F 1 is (2*Precision*Recall)/(Precision+Recall) and hence requires both high precision and high recall to produce a high score. If K is chosen too small, F 1 will be low from low recall. If K is chosen too large, F 1 will be low from low precision. Ideally, the retrieval set will have all of the relevant documents at the top, and K would be set to the number of relevant documents.</p><p>(Also, the systems were required to specify a cutoff value "K h " for each topic for when just counting "highly relevant" documents as relevant.)</p><p>For our runs this year, we thresholded the retrieval sets as follows:</p><p>For the 2 vector runs (otL09fv and otL09rvl), we set K so that just documents of relevance() score of 200 or higher were included. (And for highly relevant documents, we set K h so that just documents of relevance() score of 225 or higher were included.) This thresholding approach was the same as used for the Table <ref type="table" coords="5,152.50,82.08,3.87,8.74">3</ref>: Impact of Experimental Techniques on did not matter for our K values for the Boolean runs.) For the baseline fusion run (otL09frw), we just used the same K (and K h ) values as otL09fv this year.</p><formula xml:id="formula_1" coords="5,112.77,82.08,373.62,24.34">F 1 @K, F 1 @K h , F 1 @R and F 1 @R h Expt ∆F 1 @K 95% Conf</formula><p>For the feedback runs (otL09F and otL09frwF), the training qrels were a factor in choosing K (and K h ). One input was the "retrospective optimal K value" from using the retroK option of the l07 eval scoring utility to determine what value K would have produced the highest F 1 for the run when using the training qrels. Another input was the estimated number of relevant documents for the topic based on the training qrels (which was listed in the provided estRelL09.append file). The submitted K value was the greater of the retrospective optimal K value and estRelL09.append K value, plus 10 percent (in case the deeper runs this year led to greater numbers of relevant documents). (For K h , we just used the K h values from estRelL09.append, which for the 5 topics with past highly relevant judgments was the estimated number of highly relevant documents, and for the other 5 topics just used 14% of the estimated number of relevant documents.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Results</head><p>Tables 1 and 2 list several mean scores for the 6 experimental runs. The retrieval measures are defined in Section 3.1 of the Glossary at the end of the paper. The highest mean scores of each measure are in bold; however, see Tables <ref type="table" coords="6,161.10,654.25,4.43,8.74">3</ref><ref type="table" coords="6,165.53,654.25,4.43,8.74" target="#tab_4">4</ref><ref type="table" coords="6,165.53,654.25,4.43,8.74" target="#tab_5">5</ref><ref type="table" coords="6,169.96,654.25,4.43,8.74" target="#tab_6">6</ref>for which mean differences are statistically significant. (The columns of Tables <ref type="table" coords="6,526.71,654.25,4.43,8.74">3</ref><ref type="table" coords="6,531.14,654.25,4.43,8.74" target="#tab_4">4</ref><ref type="table" coords="6,531.14,654.25,4.43,8.74" target="#tab_5">5</ref><ref type="table" coords="6,535.57,654.25,4.43,8.74" target="#tab_6">6</ref>are explained in Section 3.2 of the Glossary.)</p><p>We see that the feedback runs outperformed the plain vector runs when comparing to the Boolean run. For example, in Table <ref type="table" coords="7,173.33,450.04,3.87,8.74" target="#tab_4">4</ref>, the "fv-fb" entries for Precision@B (where B is the depth to which the Boolean run retrieved) show that the final vector run outscored the final Boolean run on just half of the queries, whereas the "F-fb" entries indicate a statistically significant advantage for the pure feedback run over the final Boolean run in Precision@B using either All Relevant or just Highly Relevant documents.</p><p>The tables flag topic 105 as one for which feedback was particularly helpful. This topic's request text was "Please produce all reports, written memoranda, correspondence, and other documents related to building design compliance or noncompliance with structural standards, and compliance or noncompliance with structural regulations.", and its final Boolean query was "(build! OR structure!) AND (design! OR plan OR scheme OR blueprint) AND ((compliance OR comply OR complies OR obey! OR correspond! OR meet! OR adhere! OR conform) w/5 (regulat! OR code! OR law! OR ordinanc! OR rule! OR statut!))". In the feedback query, we see helpful looking terms that were not in the request text or final Boolean query such as "ASHRAE", "CONTAMINANTS", "HVAC", "IAQ", "OSHA", "SBSC" and "VENTILATION".</p><p>Last year, our pure feedback run (otRF08F) did not do well compared to the Boolean run. We suspect the decision this year to just use relevant documents of less than 10000 bytes improved the quality of the feedback run substantially this year. We have verified that Precision@B was higher with otL09F than otRF08F on the two topics in common (topic 80, 0.989 vs. 0.902; topic 89, 0.460 vs. 0.365). We suspect further improvements to the feedback run are possible by using a formula that favors terms that appear in multiple relevant documents (instead of appending all of the relevant documents together before picking the terms). The tables show that topic 138 was an exceptional case in which the Boolean query still outperformed both the plain vector and pure feedback approaches in various measures, including Precision@B and F 1 @K. This topic's request text was "All documents describing or detailing instances of government subsidies for competitive local products.", and its final Boolean query was "(China OR CN OR PRC OR "Hong Kong" OR HK OR Japan OR JP OR Taiwan OR TW OR ROC OR India OR Philippines OR PH OR Cambodia OR KH OR Vietnam OR VN OR "North Korea" OR "South Korea" OR KP OR Thailand OR Asia OR EMEA OR Government OR Market) AND (Subsidy OR subsidies)". We suspect that requiring 'subsidy' or 'subsidies' to be in the result was helpful for precision, whereas in the plain vector and pure feedback approaches these terms had relatively little weight. We should investigate further to see if alternate feedback-based formulations would perform better. In general though it may be advisable to manually supervise the feedback process. We found that fusion of the baseline runs with the pure feedback run did not, on average, improve upon the pure feedback run in most measures (i.e. the F run typically had a higher mean score than the frwF run). Note that we do not blame the new RRF fusion technique for this result; an (unreported) experiment comparing the frw-style run with the RRF technique and last year's fusion technique did not find much difference. The tables often flag topic 105 as one of the topics that declined with fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Glossary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Retrieval Measures</head><p>The retrieval measures of Tables <ref type="table" coords="9,216.98,483.99,4.98,8.74" target="#tab_2">1</ref> and<ref type="table" coords="9,244.66,483.99,4.98,8.74" target="#tab_3">2</ref> are defined as follows:</p><p>"Avg. K": The Average K value. "R@K", "P@K" and "F 1 @K": Estimated Recall, Precision and F 1 at Depth K (respectively). "Gray@K": Estimated percentage of the top-K that was "gray" documents (e.g. documents too long for the assessor to fully review).</p><p>"Avg. Num. Judged@K" is the actual number of judged documents in the top-K, followed in parentheses by the actual number of relevant (r), non-relevant (n) and gray (g) documents.</p><p>"Avg. Ret": The Average number of Retrieved documents per topic. "P@B" and "R@B": Estimated Precision and Recall at Depth B (where B is the number of documents matching the final negotiated Boolean query).</p><p>"F 1 @R": Estimated F 1 at Depth R (where R is the estimated number of relevant documents). "R@ret": Estimated Recall of the full retrieval set. "indAP": Induced Average Precision (the popular "average precision" after discarding unjudged documents; the sampling probabilities are not used for this measure, i.e. indAP is not infAP or statAP).</p><p>"GS10J": Generalized Success@10 on Judged Documents (1.08 1-r where r is the rank of the first relevant document, only counting judged documents, or zero if no relevant document is retrieved). GS10J is a robustness measure which exposes the downside of blind feedback techniques <ref type="bibr" coords="9,403.98,675.27,14.61,8.74" target="#b12">[13]</ref>. "Generalized Success@10" was originally introduced as "First Relevant Score" (FRS) in <ref type="bibr" coords="10,345.09,75.16,14.61,8.74" target="#b13">[14]</ref>. Intuitively, GS10J is a predictor of the percentage of topics for which a relevant document is returned in the first 10 rows.</p><p>"S1J": Success of the First Judged Document. "K h ": K value when just counting Highly relevant documents as relevant. "R h ": Estimated number of Highly relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Difference Tables</head><p>For the comparison tables (such as Table <ref type="table" coords="10,254.51,171.42,3.87,8.74">3</ref>), the columns are as follows:</p><p>• "Expt" specifies the experiment (the codes of the two runs being compared are listed, indicating first run minus second run).</p><p>• "∆" is the difference of the mean scores of the two runs being compared (the column heading says for which retrieval measure).</p><p>• "95% Conf" is an approximate 95% confidence interval for the mean difference (calculated from plus/minus twice the standard error of the mean difference; strictly speaking, for 10 topics, it would have been a little more accurate to have used a multiplier of 2.3 instead of 2.0, but we did not update our scripts for this paper). If zero is not in the interval, the result is "statistically significant" (at the 5% level), i.e. the feature is unlikely to be of neutral impact (on average), though if the average difference is small (e.g. &lt;0.020) it may still be too minor to be considered "significant" in the magnitude sense.</p><p>• "vs." is the number of topics on which the first run scored higher, lower and tied (respectively) compared to the second run. These numbers should always add to the number of topics.</p><p>• "3 Extreme Diffs (Topic)" lists 3 of the individual topic differences, each followed by the topic number in brackets. The first difference is the largest one of any topic (based on the absolute value). The third difference is the largest difference in the other direction (so the first and third differences give the range of differences observed in this experiment). The middle difference is the largest of the remaining differences (based on the absolute value).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>For our participation in the Batch Task of the TREC 2009 Legal Track, we produced several experimental runs to compare experimental Boolean, vector, fusion and relevance feedback techniques for e-Discovery requests. This paper reported not just the mean scores of the runs but also the largest per-topic impacts of the techniques for several measures. We found that the experimental automatic relevance feedback technique (which just used shorter relevant documents for feedback) produced a statistically significant gain over the reference Boolean result in both the mean Precision@B and F 1 @K measures. However, there were still cases (most notably topic 138) in which the reference Boolean query produced the higher score. Fusion of the Boolean result (and other baseline vector approaches) with the relevance feedback result further increased the scores for some individual topics, but not on average in most measures. While this paper focused on automated approaches (aside from the reference Boolean query), we suspect that for best results in practice one should manually supervise the approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,82.46,400.66,418.43,8.30;3,129.53,412.61,329.51,8.30;3,129.53,424.57,198.75,8.30"><head></head><label></label><figDesc>WHERE FT_TEXT CONTAINS 'past'|'incidents'|'involving'|'malfunction'|'machinery'| 'connection'|'manufacturing'|'testing'|'activities'|'occurred'| 'manufacturing'|'testing'|'facilities'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,112.78,188.30,381.48,297.18"><head>Table 1 :</head><label>1</label><figDesc>Mean Set-based Scores of Experimental Batch Task Runs</figDesc><table coords="4,112.78,188.30,381.48,297.18"><row><cell></cell><cell>0.167</cell><cell>0.266</cell><cell>0.132</cell><cell>0.000</cell><cell cols="3">260 (115r, 145n, 0g)</cell></row><row><cell>otL09frwF</cell><cell>26582 0.168</cell><cell>0.215</cell><cell>0.113</cell><cell>0.016</cell><cell cols="3">384 (134r, 248n, 1g)</cell></row><row><cell>otL09rvl</cell><cell>61608 0.239</cell><cell>0.119</cell><cell>0.105</cell><cell>0.007</cell><cell cols="3">465 (141r, 321n, 3g)</cell></row><row><cell>otL09frw</cell><cell>20756 0.226</cell><cell>0.180</cell><cell>0.114</cell><cell>0.004</cell><cell cols="3">412 (132r, 278n, 3g)</cell></row><row><cell>otL09fv</cell><cell>20756 0.160</cell><cell>0.165</cell><cell>0.105</cell><cell>0.007</cell><cell cols="3">353 (115r, 236n, 3g)</cell></row><row><cell>otL09fb</cell><cell>27462 0.143</cell><cell>0.149</cell><cell>0.063</cell><cell>0.016</cell><cell cols="3">277 (84r, 190n, 3g)</cell></row><row><cell>Run</cell><cell>Avg. Ret P@B</cell><cell>R@B</cell><cell cols="4">F 1 @R R@ret indAP GS10J</cell><cell>S1J</cell></row><row><cell>otL09F</cell><cell cols="3">1500000 0.558 0.055 0.251</cell><cell>0.582</cell><cell>0.653</cell><cell>0.957</cell><cell>6/10</cell></row><row><cell>otL09frwF</cell><cell>1500000 0.531</cell><cell>0.054</cell><cell>0.238</cell><cell>0.609</cell><cell>0.618</cell><cell>0.978</cell><cell>8/10</cell></row><row><cell>otL09rvl</cell><cell>1500000 0.476</cell><cell>0.041</cell><cell>0.194</cell><cell>0.535</cell><cell>0.591</cell><cell>0.909</cell><cell>9/10</cell></row><row><cell>otL09frw</cell><cell>1500000 0.460</cell><cell>0.046</cell><cell>0.204</cell><cell>0.542</cell><cell>0.583</cell><cell>0.993</cell><cell>9/10</cell></row><row><cell>otL09fv</cell><cell>1482237 0.447</cell><cell>0.037</cell><cell>0.194</cell><cell>0.575</cell><cell>0.550</cell><cell>0.940</cell><cell>7/10</cell></row><row><cell>otL09fb</cell><cell>27462 0.391</cell><cell>0.037</cell><cell>0.037</cell><cell>0.037</cell><cell>0.275</cell><cell cols="2">1.000 10/10</cell></row><row><cell>(high rel)</cell><cell>Avg. Ret P@B</cell><cell cols="5">R@B F 1 @R h R@ret indAP GS10J</cell><cell>S1J</cell></row><row><cell>otL09F</cell><cell cols="2">1500000 0.256 0.228</cell><cell>0.213</cell><cell cols="2">0.757 0.409</cell><cell>0.815</cell><cell>2/10</cell></row><row><cell>otL09frwF</cell><cell cols="2">1500000 0.221 0.230</cell><cell>0.193</cell><cell>0.719</cell><cell>0.366</cell><cell>0.868</cell><cell>5/10</cell></row><row><cell>otL09rvl</cell><cell>1500000 0.239</cell><cell>0.174</cell><cell>0.164</cell><cell>0.688</cell><cell>0.338</cell><cell>0.779</cell><cell>5/10</cell></row><row><cell>otL09frw</cell><cell>1500000 0.206</cell><cell>0.224</cell><cell>0.153</cell><cell>0.686</cell><cell>0.331</cell><cell>0.826</cell><cell>5/10</cell></row><row><cell>otL09fv</cell><cell>1482237 0.168</cell><cell>0.151</cell><cell>0.143</cell><cell>0.725</cell><cell>0.312</cell><cell>0.763</cell><cell>4/10</cell></row><row><cell>otL09fb</cell><cell>27462 0.149</cell><cell>0.143</cell><cell>0.069</cell><cell>0.143</cell><cell>0.167</cell><cell>0.828</cell><cell>5/10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,156.01,498.60,299.99,8.74"><head>Table 2 :</head><label>2</label><figDesc>Mean Rank-based Scores of Experimental Batch Task Runs</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,72.00,96.77,468.00,596.85"><head>Table 4 :</head><label>4</label><figDesc>Impact of Experimental Techniques on P@B</figDesc><table coords="5,307.50,96.77,165.06,8.74"><row><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row></table><note coords="5,72.00,672.01,156.10,8.74;5,86.94,683.96,453.06,9.65"><p><p>corresponding vector runs last year.</p>For the Boolean run (otL09fb), we set K (and K h ) to the number retrieved. (Hence relevance-ranking</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,114.15,82.08,383.70,332.87"><head>Table 5 :</head><label>5</label><figDesc>Impact of Experimental Techniques on R@B</figDesc><table coords="7,114.15,96.77,383.70,318.18"><row><cell>Expt</cell><cell>∆R@B</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>F-frwF</cell><cell>0.000</cell><cell>(-0.016, 0.017)</cell><cell>5-5-0</cell><cell>0.06 (105), -0.02 (138), -0.03 (102)</cell></row><row><cell>frwF-frw</cell><cell>0.008</cell><cell>(-0.008, 0.024)</cell><cell>6-4-0</cell><cell>0.08 (105), 0.01 (145), -0.01 (102)</cell></row><row><cell>frw-rvl</cell><cell>0.005</cell><cell>(-0.001, 0.011)</cell><cell>7-3-0</cell><cell>0.02 (102), 0.02 (138), -0.01 (103)</cell></row><row><cell>rvl-fv</cell><cell>0.004</cell><cell>(-0.005, 0.014)</cell><cell>6-4-0</cell><cell>0.03 (105), 0.02 (89), -0.01 (102)</cell></row><row><cell>F-frw</cell><cell>0.009</cell><cell>(-0.023, 0.040)</cell><cell>7-3-0</cell><cell>0.14 (105), -0.02 (138), -0.05 (102)</cell></row><row><cell>F-rvl</cell><cell>0.014</cell><cell>(-0.016, 0.043)</cell><cell>8-2-0</cell><cell>0.14 (105), 0.02 (145), -0.03 (102)</cell></row><row><cell>F-fv</cell><cell>0.018</cell><cell>(-0.018, 0.054)</cell><cell>8-2-0</cell><cell>0.17 (105), 0.02 (89), -0.04 (102)</cell></row><row><cell>F-fb</cell><cell>0.018</cell><cell>(-0.018, 0.054)</cell><cell>7-3-0</cell><cell>0.17 (105), 0.04 (89), -0.03 (102)</cell></row><row><cell>frwF-fb</cell><cell>0.018</cell><cell>(-0.004, 0.040)</cell><cell>9-1-0</cell><cell>0.10 (105), 0.05 (89), -0.01 (138)</cell></row><row><cell>frw-fb</cell><cell>0.009</cell><cell>(-0.001, 0.020)</cell><cell>8-2-0</cell><cell>0.04 (89), 0.03 (105), -0.00 (145)</cell></row><row><cell>rvl-fb</cell><cell>0.004</cell><cell>(-0.008, 0.017)</cell><cell>5-4-1</cell><cell>0.04 (89), 0.03 (105), -0.02 (138)</cell></row><row><cell>fv-fb</cell><cell>-0.000</cell><cell>(-0.010, 0.010)</cell><cell>7-3-0</cell><cell>-0.04 (138), 0.01 (102), 0.02 (89)</cell></row><row><cell></cell><cell>∆R@B</cell><cell></cell><cell></cell><cell>(high relevance)</cell></row><row><cell>F-frwF</cell><cell>-0.002</cell><cell>(-0.059, 0.054)</cell><cell>3-6-1</cell><cell>0.19 (105), -0.06 (89), -0.17 (51)</cell></row><row><cell>frwF-frw</cell><cell>0.006</cell><cell>(-0.015, 0.027)</cell><cell>7-2-1</cell><cell>0.07 (105), 0.02 (145), -0.06 (138)</cell></row><row><cell>frw-rvl</cell><cell>0.050</cell><cell>(-0.036, 0.135)</cell><cell>4-5-1</cell><cell>0.42 (51), 0.08 (138), -0.05 (103)</cell></row><row><cell>rvl-fv</cell><cell>0.022</cell><cell>(-0.036, 0.081)</cell><cell>8-2-0</cell><cell>0.20 (89), 0.10 (105), -0.17 (51)</cell></row><row><cell>F-frw</cell><cell>0.004</cell><cell>(-0.066, 0.074)</cell><cell>5-5-0</cell><cell>0.26 (105), -0.08 (138), -0.17 (51)</cell></row><row><cell>F-rvl</cell><cell>0.054</cell><cell>(-0.010, 0.118)</cell><cell>9-1-0</cell><cell>0.25 (51), 0.24 (105), -0.00 (104)</cell></row><row><cell>F-fv</cell><cell>0.076</cell><cell>( 0.007, 0.146)</cell><cell>9-1-0</cell><cell>0.33 (105), 0.21 (89), -0.00 (104)</cell></row><row><cell>F-fb</cell><cell>0.085</cell><cell>(-0.061, 0.231)</cell><cell>7-3-0</cell><cell>0.61 (89), 0.35 (105), -0.20 (51)</cell></row><row><cell>frwF-fb</cell><cell>0.087</cell><cell>(-0.048, 0.223)</cell><cell>7-3-0</cell><cell>0.67 (89), 0.16 (105), -0.06 (138)</cell></row><row><cell>frw-fb</cell><cell>0.081</cell><cell>(-0.050, 0.212)</cell><cell>9-1-0</cell><cell>0.66 (89), 0.09 (105), -0.03 (51)</cell></row><row><cell>rvl-fb</cell><cell>0.031</cell><cell>(-0.129, 0.191)</cell><cell>8-2-0</cell><cell>0.60 (89), 0.11 (105), -0.45 (51)</cell></row><row><cell>fv-fb</cell><cell>0.009</cell><cell>(-0.096, 0.113)</cell><cell>6-4-0</cell><cell>0.40 (89), -0.10 (138), -0.27 (51)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,114.15,82.08,383.70,458.39"><head>Table 6 :</head><label>6</label><figDesc>Impact of Experimental Techniques on R@ret and indAP</figDesc><table coords="8,114.15,96.77,383.70,443.71"><row><cell>Expt</cell><cell>∆R@ret</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>F-frwF</cell><cell>-0.027</cell><cell>(-0.059, 0.006)</cell><cell>2-7-1</cell><cell>-0.10 (145), -0.08 (80), 0.06 (138)</cell></row><row><cell>frwF-frw</cell><cell>0.067</cell><cell>(-0.010, 0.144)</cell><cell>7-3-0</cell><cell>0.30 (51), 0.16 (105), -0.13 (138)</cell></row><row><cell>frw-rvl</cell><cell>0.007</cell><cell>(-0.033, 0.048)</cell><cell>6-3-1</cell><cell>-0.13 (89), 0.05 (80), 0.12 (138)</cell></row><row><cell>rvl-fv</cell><cell>-0.040</cell><cell>(-0.120, 0.041)</cell><cell>3-7-0</cell><cell>-0.30 (51), -0.16 (80), 0.13 (89)</cell></row><row><cell>fv-fb</cell><cell>0.538</cell><cell>( 0.430, 0.645)</cell><cell>10-0-0</cell><cell>0.84 (89), 0.74 (105), 0.26 (104)</cell></row><row><cell>F-frw</cell><cell>0.040</cell><cell>(-0.030, 0.110)</cell><cell>7-3-0</cell><cell>0.30 (51), 0.12 (105), -0.07 (138)</cell></row><row><cell>F-rvl</cell><cell>0.047</cell><cell>(-0.028, 0.122)</cell><cell>7-3-0</cell><cell>0.30 (51), 0.13 (80), -0.13 (89)</cell></row><row><cell>F-fv</cell><cell>0.008</cell><cell>(-0.032, 0.047)</cell><cell>3-6-1</cell><cell>0.11 (138), 0.08 (105), -0.06 (103)</cell></row><row><cell></cell><cell>∆R@ret</cell><cell></cell><cell></cell><cell>(high relevance)</cell></row><row><cell>F-frwF</cell><cell>0.037</cell><cell>(-0.042, 0.117)</cell><cell>3-3-4</cell><cell>0.36 (138), 0.10 (80), -0.07 (102)</cell></row><row><cell>frwF-frw</cell><cell>0.033</cell><cell>(-0.070, 0.137)</cell><cell>4-2-4</cell><cell>0.41 (105), 0.13 (145), -0.21 (102)</cell></row><row><cell>frw-rvl</cell><cell>-0.001</cell><cell>(-0.024, 0.021)</cell><cell>3-2-5</cell><cell>-0.08 (80), 0.03 (7), 0.06 (103)</cell></row><row><cell>rvl-fv</cell><cell>-0.037</cell><cell>(-0.168, 0.094)</cell><cell>2-5-3</cell><cell>-0.40 (105), -0.26 (138), 0.29 (7)</cell></row><row><cell>fv-fb</cell><cell>0.582</cell><cell>( 0.470, 0.694)</cell><cell>10-0-0</cell><cell>0.96 (105), 0.76 (89), 0.39 (80)</cell></row><row><cell>F-frw</cell><cell>0.071</cell><cell>(-0.059, 0.200)</cell><cell>5-2-3</cell><cell>0.41 (105), 0.36 (138), -0.28 (102)</cell></row><row><cell>F-rvl</cell><cell>0.069</cell><cell>(-0.058, 0.197)</cell><cell>6-2-2</cell><cell>0.41 (105), 0.36 (138), -0.28 (102)</cell></row><row><cell>F-fv</cell><cell>0.032</cell><cell>(-0.062, 0.126)</cell><cell>6-2-2</cell><cell>0.32 (7), 0.11 (138), -0.27 (104)</cell></row><row><cell></cell><cell>∆indAP</cell><cell></cell><cell></cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>F-frwF</cell><cell>0.035</cell><cell>(-0.028, 0.098)</cell><cell>6-4-0</cell><cell>0.29 (105), 0.08 (7), -0.07 (51)</cell></row><row><cell>frwF-frw</cell><cell>0.035</cell><cell>( 0.006, 0.063)</cell><cell>7-3-0</cell><cell>0.13 (105), 0.08 (7), -0.01 (51)</cell></row><row><cell>frw-rvl</cell><cell>-0.007</cell><cell>(-0.044, 0.029)</cell><cell>4-6-0</cell><cell>0.11 (51), -0.06 (105), -0.07 (7)</cell></row><row><cell>rvl-fv</cell><cell>0.041</cell><cell>(-0.007, 0.088)</cell><cell>7-3-0</cell><cell>0.19 (138), 0.11 (80), -0.06 (51)</cell></row><row><cell>fv-fb</cell><cell>0.275</cell><cell>( 0.108, 0.442)</cell><cell>8-2-0</cell><cell>0.58 (89), 0.58 (7), -0.13 (51)</cell></row><row><cell>F-frw</cell><cell>0.070</cell><cell>(-0.020, 0.160)</cell><cell>6-4-0</cell><cell>0.42 (105), 0.16 (7), -0.08 (51)</cell></row><row><cell>F-rvl</cell><cell>0.063</cell><cell>(-0.007, 0.132)</cell><cell>8-2-0</cell><cell>0.36 (105), 0.09 (7), -0.02 (102)</cell></row><row><cell>F-fv</cell><cell>0.104</cell><cell>( 0.017, 0.190)</cell><cell>8-2-0</cell><cell>0.44 (105), 0.17 (138), -0.03 (51)</cell></row><row><cell></cell><cell>∆indAP</cell><cell></cell><cell></cell><cell>(high relevance)</cell></row><row><cell>F-frwF</cell><cell>0.043</cell><cell>( 0.009, 0.078)</cell><cell>7-3-0</cell><cell>0.13 (89), 0.13 (105), -0.03 (138)</cell></row><row><cell>frwF-frw</cell><cell>0.036</cell><cell>( 0.010, 0.061)</cell><cell>9-1-0</cell><cell>0.12 (89), 0.07 (138), -0.02 (104)</cell></row><row><cell>frw-rvl</cell><cell>-0.007</cell><cell>(-0.032, 0.018)</cell><cell>4-6-0</cell><cell>-0.08 (138), -0.05 (80), 0.05 (145)</cell></row><row><cell>rvl-fv</cell><cell>0.025</cell><cell>(-0.030, 0.081)</cell><cell>4-6-0</cell><cell>0.20 (138), 0.16 (80), -0.05 (7)</cell></row><row><cell>fv-fb</cell><cell>0.146</cell><cell>( 0.046, 0.246)</cell><cell>8-2-0</cell><cell>0.39 (80), 0.34 (89), -0.05 (138)</cell></row><row><cell>F-frw</cell><cell>0.079</cell><cell>( 0.026, 0.132)</cell><cell>8-2-0</cell><cell>0.25 (89), 0.17 (105), -0.04 (104)</cell></row><row><cell>F-rvl</cell><cell>0.072</cell><cell>( 0.008, 0.136)</cell><cell>7-3-0</cell><cell>0.29 (89), 0.16 (105), -0.04 (104)</cell></row><row><cell>F-fv</cell><cell>0.097</cell><cell>( 0.041, 0.153)</cell><cell>9-1-0</cell><cell>0.25 (89), 0.18 (80), -0.03 (104)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,114.15,82.08,383.70,236.43"><head>Table 7 :</head><label>7</label><figDesc>Impact of Experimental Techniques on GS10J</figDesc><table coords="9,114.15,96.77,383.70,221.74"><row><cell>Expt</cell><cell>∆GS10J</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>F-frwF</cell><cell>-0.022</cell><cell>(-0.044, 0.001)</cell><cell>0-3-7</cell><cell>-0.07 (138), -0.07 (145), 0.00 (103)</cell></row><row><cell>frwF-frw</cell><cell>-0.014</cell><cell>(-0.051, 0.022)</cell><cell>1-2-7</cell><cell>-0.14 (104), -0.07 (51), 0.07 (80)</cell></row><row><cell>frw-rvl</cell><cell>0.083</cell><cell>(-0.101, 0.268)</cell><cell>1-1-8</cell><cell>0.91 (51), 0.00 (103), -0.07 (80)</cell></row><row><cell>rvl-fv</cell><cell>-0.030</cell><cell>(-0.237, 0.177)</cell><cell>3-1-6</cell><cell>-0.91 (51), 0.14 (89), 0.32 (138)</cell></row><row><cell>fv-fb</cell><cell>-0.060</cell><cell>(-0.130, 0.009)</cell><cell>0-3-7</cell><cell>-0.32 (138), -0.14 (89), 0.00 (103)</cell></row><row><cell>F-frw</cell><cell>-0.036</cell><cell>(-0.081, 0.009)</cell><cell>1-4-5</cell><cell>-0.14 (51), -0.14 (104), 0.07 (80)</cell></row><row><cell>F-rvl</cell><cell>0.047</cell><cell>(-0.116, 0.210)</cell><cell>1-3-6</cell><cell>0.77 (51), -0.07 (145), -0.14 (104)</cell></row><row><cell>F-fv</cell><cell>0.017</cell><cell>(-0.063, 0.098)</cell><cell>3-3-4</cell><cell>0.25 (138), 0.14 (89), -0.14 (104)</cell></row><row><cell></cell><cell>∆GS10J</cell><cell></cell><cell></cell><cell>(high relevance)</cell></row><row><cell>F-frwF</cell><cell>-0.053</cell><cell>(-0.211, 0.105)</cell><cell>2-6-2</cell><cell>-0.56 (104), -0.25 (7), 0.39 (51)</cell></row><row><cell>frwF-frw</cell><cell>0.042</cell><cell>(-0.088, 0.172)</cell><cell>4-3-3</cell><cell>0.46 (51), 0.21 (80), -0.32 (104)</cell></row><row><cell>frw-rvl</cell><cell>0.047</cell><cell>(-0.061, 0.155)</cell><cell>5-2-3</cell><cell>0.37 (103), 0.21 (7), -0.21 (80)</cell></row><row><cell>rvl-fv</cell><cell>0.016</cell><cell>(-0.089, 0.120)</cell><cell>3-4-3</cell><cell>0.32 (138), 0.21 (102), -0.21 (7)</cell></row><row><cell>fv-fb</cell><cell>-0.064</cell><cell>(-0.203, 0.074)</cell><cell>2-5-3</cell><cell>-0.50 (103), -0.25 (138), 0.29 (105)</cell></row><row><cell>F-frw</cell><cell>-0.011</cell><cell>(-0.289, 0.267)</cell><cell>5-5-0</cell><cell>-0.88 (104), -0.32 (7), 0.86 (51)</cell></row><row><cell>F-rvl</cell><cell>0.036</cell><cell>(-0.244, 0.316)</cell><cell>4-5-1</cell><cell>-0.88 (104), 0.30 (103), 0.86 (51)</cell></row><row><cell>F-fv</cell><cell>0.051</cell><cell>(-0.236, 0.339)</cell><cell>6-3-1</cell><cell>-0.88 (104), 0.43 (103), 0.85 (51)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,86.71,637.68,453.29,7.86;10,82.52,648.64,457.48,7.86;10,82.52,659.60,20.99,7.86" xml:id="b0">
	<monogr>
		<title level="m" coord="10,228.71,637.68,311.30,7.86;10,82.52,648.64,342.19,7.86">The Sedona Conference R Best Practices Commentary on the Use of Search and Information Retrieval Methods in E-Discovery. The Sedona Conference Journal</title>
		<editor>
			<persName><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">VIII</biblScope>
			<biblScope unit="page" from="189" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.71,677.72,453.28,7.86;10,82.52,688.68,320.24,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
		<title level="m" coord="10,154.79,677.72,385.21,7.86;10,82.52,688.68,190.69,7.86">Toward A Federal Benchmarking Standard for Evaluating Information Retrieval Products Used in E-Discovery. The Sedona Conference Journal</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">VI</biblScope>
			<biblScope unit="page" from="237" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,86.71,75.84,453.29,7.86;11,82.52,86.80,20.99,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,310.10,75.84,135.81,7.86">TREC-2006 Legal Track Overview</title>
		<author>
			<persName coords=""><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,452.97,75.84,87.03,7.86">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,86.71,105.73,453.28,7.86;11,82.52,116.68,268.44,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="11,347.61,105.73,192.39,7.86;11,82.52,116.68,157.69,7.86">Reciprocal Rank Fusion outperforms Condorcet and Individual Rank Learning Methods</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Büttcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,86.71,135.61,307.28,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><surname>Cross-Language</surname></persName>
		</author>
		<ptr target="http://www.clef-campaign.org/" />
		<title level="m" coord="11,153.52,135.61,107.63,7.86">Evaluation Forum web site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,86.71,154.54,453.29,7.86;11,82.52,165.50,202.48,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="11,395.85,154.54,144.15,7.86;11,82.52,165.50,21.14,7.86">Overview of the TREC 2009 Legal Track</title>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Hedin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>To appear in) Proceedings of TREC</note>
</biblStruct>

<biblStruct coords="11,86.71,184.43,453.29,7.86;11,82.52,195.39,20.99,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,160.04,184.43,196.98,7.86">Converting the Fulcrum Search Engine to Unicode</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Hodgson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,363.63,184.43,172.11,7.86">Sixteenth International Unicode Conference</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,86.71,214.32,453.28,7.86;11,82.52,225.28,246.24,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="11,378.16,214.32,161.83,7.86;11,82.52,225.28,136.07,7.86">Building a Test Collection for Complex Document Information Processing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Agam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="665" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,86.71,244.21,397.59,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="11,124.30,244.21,154.83,7.86">NII-Test Collection for IR) Home Page</title>
		<author>
			<persName coords=""><surname>Ntcir</surname></persName>
		</author>
		<ptr target="http://research.nii.ac.jp/∼ntcadm/index-en.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,263.14,448.68,7.86;11,82.52,274.09,140.50,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,397.24,263.14,142.76,7.86;11,82.52,274.09,21.14,7.86">Overview of the TREC 2008 Legal Track</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Hedin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,110.95,274.09,88.01,7.86">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,293.02,448.67,7.86;11,82.52,303.98,60.66,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<title level="m" coord="11,402.18,293.02,137.82,7.86;11,82.52,303.98,31.38,7.86">Okapi at TREC-3. Proceedings of TREC-3</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,322.91,281.07,7.86" xml:id="b11">
	<monogr>
		<ptr target="http://trec.nist.gov/" />
		<title level="m" coord="11,91.32,322.91,190.87,7.86">Text REtrieval Conference (TREC) Home Page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,341.84,448.68,7.86;11,82.52,352.80,49.14,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,173.53,341.84,308.73,7.86">Early Precision Measures: Implications from the Downside of Blind Feedback</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="705" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,371.73,375.86,7.86;11,467.18,369.96,11.72,5.24;11,481.64,371.73,58.36,7.86;11,82.52,382.69,185.11,7.86" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<title level="m" coord="11,172.39,371.73,294.79,7.86;11,467.18,369.96,11.72,5.24;11,481.64,371.73,58.36,7.86;11,82.52,382.69,180.36,7.86">European Ad Hoc Retrieval Experiments with Hummingbird SearchServer TM at CLEF 2005. Working Notes for the CLEF 2005 Workshop</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,401.62,448.68,7.86;11,82.52,412.58,112.07,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,172.69,401.62,363.09,7.86">Experiments with the Negotiated Boolean Queries of the TREC 2006 Legal Discovery Track</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,82.52,412.58,88.01,7.86">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,431.50,448.68,7.86;11,82.52,442.46,112.07,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,172.69,431.50,363.09,7.86">Experiments with the Negotiated Boolean Queries of the TREC 2007 Legal Discovery Track</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,82.52,442.46,107.87,7.86">Proceedings of TREC 2007</title>
		<meeting>TREC 2007</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,461.39,448.68,7.86;11,82.52,472.35,79.92,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="11,173.21,461.39,366.79,7.86;11,82.52,472.35,55.85,7.86">Experiments with the Negotiated Boolean Queries of the TREC 2008 Legal Track. Proceedings of TREC</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,491.28,448.68,7.86;11,82.52,502.24,140.50,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,401.42,491.28,138.58,7.86;11,82.52,502.24,21.14,7.86">Overview of the TREC 2007 Legal Track</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,110.95,502.24,107.87,7.86">Proceedings of TREC 2007</title>
		<meeting>TREC 2007</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,91.32,521.17,397.05,7.86" xml:id="b18">
	<monogr>
		<ptr target="http://trec-legal.umiacs.umd.edu/batch09a.html" />
		<title level="m" coord="11,91.32,521.17,194.51,7.86">TREC 2009 Legal Track: Batch Task Guidelines</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
