<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,57.60,76.38,496.82,16.65">PARADISE Based Search Engine at TREC 2009 Web Track</title>
				<funder ref="#_9DDsgEN #_wZ7aVwC">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder ref="#_MGqCyns">
					<orgName type="full">China MOE</orgName>
				</funder>
				<funder ref="#_DEEBvWr #_AX3vDgT">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,169.46,123.52,68.94,9.94"><forename type="first">Dongdong</forename><surname>Shan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,246.13,123.52,73.03,9.94"><forename type="first">Dongsheng</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.98,123.52,31.63,9.94"><forename type="first">Jing</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.28,123.52,57.19,9.94"><forename type="first">Hongfei</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,57.60,76.38,496.82,16.65">PARADISE Based Search Engine at TREC 2009 Web Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2AB66FE8C6512625F2D13CE53ADEC8B5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Search and Retrieval]: Systems Issues</term>
					<term>Retrieval Models Performance</term>
					<term>Design</term>
					<term>Experimentation System Design</term>
					<term>Information Retrieval</term>
					<term>Term Proximity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we introduce the PARADISE search engine in TREC09 Web track. PARADISE is the abbreviation for Platform for Applying, Research and Developing Intelligent Search Engine, which is a search engine platform developed by SEWM group, Peking University. The system is designed to support both English and Chinese information retrieval. This system preprocessed and indexed the five hundred million web pages for this year's Web Track. In the preprocessing stage, the templates were removed, the encoding were identified and unified, and the anchor texts and InLink information are extracted with the mapreduce framework (using Hadoop in this system). In retrieval, our runs used an extension of BM25. This model distinguishes terms from different fields and integrated both term counts and position information. Furthermore, some web based features are also considered.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION PARADISE[1] was developed by Search Engine and</head><p>Web Mining group in Peking University. It aims to provide a search engine platform for processing large volume of data. The Web track requires retrieving documents on a very large document collection, so it becomes a challenge for both effectiveness and efficiency.</p><p>PARADISE system contains several important components: store, preprocessing, indexing and retrieval. We would introduce both the architecture and algorithms in detail. Furthermore, we would analyze our performance in Web track this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task</head><p>This year's Web Track uses a new collection named ClueWeb09. It contains one billion web pages in different languages. The total size of this new collection is 25TB, and the compressed size is 5TB, which is significantly larger than earlier collections. This year's task focuses on the English corpus in the test collection，which involves a total of 504 million English web pages with a size of 1.94TB after compression.</p><p>In this task we used 24 machines. 23 machines are used to process the data, such as content extraction, data indexing, information retrieval. The rest is used as a frontend service machine. It interacts with the 23 machines when they run queries. It submits queries and collects the results returned by those machines. Each of the machines has two 2.8 GHz Intel Pentium CPUs, 4GB memory, and 1.6TB of local SATA disk.</p><p>In addition, we have a cluster of 30-machine running Hadoop distributed computing environment. We use it to merge anchor texts, compute PageRank, and find duplicate pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Document Representation</head><p>In our system, we have two kinds of documents. The first kind of document is a normal document, such as HTML, PDF, and MP3. The second one is the document that has been preprocessed by preprocessing system. This kind of document has a certain format. The index system only reads this kind of document. We will take HTML page as an example to introduce the second kind of document contains.</p><p>As we know, a HTML page contains much information, such as URL, title, body, description and anchor texts. There is also some specific information, such as importance and duplicate degree of this document. The preprocessing system is mainly used to extract these information from the original web page, and then save those information into store system. Therefore the indexing system can read the formatted document for store module.</p><p>In this year's task, we use the following information as contents of the document: title, body, anchor text, URL's text, and InLink value. The title part contains the text in the &lt;title&gt; tag. We don't extract the real title of this document. Body mainly contains HTML text without HTML tags. Anchor text includes text information showing that other pages point to this page. URL text contains text information belongs to the URL in this page. Inlink degree represents the total number page links pointing to this page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data Store Module</head><p>Web pages are allocated to different data servers by the hash values of their URLs. The hash function is designed in a way that pages from the same host are hashed to the same data server. In the allocating process, each page is assigned a unique 64-bit ID, the first 24 bits of which represent the data server and the last 40 bits is the page's sequence number on that data server.</p><p>A data server partitions the received web page data into a set of files, whose size can be configured. In this task, it is configured to 1GB. Data server's application interfaces provide sequential scan and random access functions. In this task, each data server maintains about 130GB web page data and processes 2,200,000 pages on average.</p><p>Two data formats are used on data servers. In one of them, namely the Tianwang format, web pages are simply sequentially stored, which provides good sequential scan performance but it is slow when random accessing. However, the whole processing rarely performs random access to the pages, so this format works well. Alternatively, the other format supports quick random access but not quick sequential scan. This format is designed for document summary and snapshot services in which case page data need be fetched efficiently.</p><p>Information after preprocessing includes the original web page and the result of preprocessor. We also store that information, such as the titles and the main contents on those store servers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Data Preprocessing and Indexing</head><p>The main target of preprocessing system is to extract useful information from various files, such as HTML, PDF, and MP3 etc. for retrieval system. When it extracts information, it usually contains the following steps: web page encoding transformation, page normalization, noise elimination, anchor text extraction, link-analysis, and duplicate pages elimination etc.</p><p>Web page encoding transformation translates various coding of html pages into one certain coding. Page normalization repairs the missing tags in HTML page. Noise elimination removes useless information like advertisements from the web page. We extract anchor text and URL pairs on multiple machines when eliminating noise information in HTML pages.</p><p>Duplicate pages elimination aims to find the duplicate pages, and to remove the Duplicate pages from the collection. It is useful in web search. But when we did experiments with GOV2 dataset, we found that lots of pages were removed by our program so that the recall was very low. In this task, we do not use this step when preprocess the collection. We use a simple version to remove the noise in web pages, by just removing the tags of HTML page.</p><p>We use Hadoop to merge anchor texts and compute the InLink degree for each page. The computing data size is about 1.7 TB. We have two copies for replication in Hadoop. The Map function <ref type="bibr" coords="2,435.10,180.42,11.69,8.96" target="#b0">[2]</ref> reads huge &lt;URL, anchor text&gt; key-value pairs from link list file. We found there are large amounts of duplication in anchor texts. So we encode the anchor texts and compress the data by merging the strings of anchor texts. This reduced 80%-90% storage compared with raw data. The reason why we use Inlink instead of PageRank is that computing InLink is more efficient.</p><p>The indexing system reads information about each web page from store module. In this year's task, we index four kinds of texts: title, body content, URL text, and anchor text. We also store InLink values, page ID and URL in index file. Indexing system tokenizes the text, removes stop words and stems word with poster algorithm. Then it builds the inverted file. It also writes the special information such as InLink value and the length of texts into a special file. This kind of files should be read fast, so this information always is kept in memory.</p><p>We submit three official runs for evaluation. They are generated by different information. Run1 and Run2 use the same copy of index, which only contains title and body. The index used in Run3 contains all information as we mentioned before. We also reserve the stop words in index using by Run3. Although it makes the index much bigger, stop words can help retrieval under some condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Retrieval Model</head><p>The retrieval model is based on BM25. We slightly extend this formula. Every field is extended according to its weight during the retrieval process <ref type="bibr" coords="2,482.02,522.11,10.69,8.96" target="#b1">[3]</ref>. InLink, term proximity and term occurrence are also taken into consideration. The final score formula of a document is (1) where β is set to 0 in Run1 and Run2. Table <ref type="table" coords="2,508.87,578.66,4.98,8.96">1</ref> shows the three official runs used information. Parameter c is the term occurrence score, which is calculated as <ref type="bibr" coords="2,549.72,632.66,11.69,8.96" target="#b0">(2)</ref> In this formula, q total is the number of unique terms in the query, and q occ represents number of terms which have occurrence in the current document. c 1 and c 2 are two smoothing parameters. We find it can get the best results when c 1 = 6 and c 2 = 5.5 in GOV2 data collection. Score BM25 is the score computed by BM25 model; Score InLink represents contribution made by InLink; and Score TP is defined as the score of term proximity. Each of the three is described below. Score BM25 is calculated as normal BM25 formula with a small modification, that is, the term frequencies is extended in each field. For example, a term t appears once in title, 3 times in content. If we define the title weight as 5 and content weight as 1, the final term frequencies is 1*5+3*1 = 8. The BM25 parameters are set Title and content are treated equally inRun1. The computation of Score tp and the value of γ are different between Run1 and Run2. In Run2 and Run3, the proportion of title and content is set to 2:1. Score InLink is calculated <ref type="bibr" coords="3,278.21,215.70,11.54,8.96" target="#b2">[4,</ref><ref type="bibr" coords="3,289.75,215.70,7.69,8.96" target="#b3">5]</ref> as <ref type="bibr" coords="3,285.77,257.13,11.69,8.96" target="#b1">(3)</ref> where N is the value of InLink, and c 3 is a parameter. The parameter β is set to 0 in Run1 and Run2. We set c 3 is 0.5 in our runs.</p><p>Score TP is described as follow. For a query t 1 t 2 …t n with n terms, there exists n-1 adjacent term pairs: t 1 t 2 , t 2 t 3 …t n-1 t n . For each adjacent term pair t i t i+1 in different fields, we can compute the minimum distance between t i and t i+1 , which is denoted as MinDist i,f. The score is calculated <ref type="bibr" coords="3,235.85,355.17,11.54,8.96" target="#b4">[6,</ref><ref type="bibr" coords="3,247.39,355.17,7.69,8.96" target="#b5">7]</ref> as <ref type="bibr" coords="3,285.77,387.35,11.69,8.96" target="#b2">(4)</ref> where Boost f denotes the weight of field f, F is the set of indexed fields. The score of all adjacent t i+1 in all fields is <ref type="bibr" coords="3,285.77,443.15,11.69,8.96" target="#b3">(5)</ref> The final Score TP is .(6) C 4 is a smoothing parameter, which is set to 0.5 in our experiment. We use RawScoretp in Run1, and Scoretp in Run2 and Run3.</p><p>Table <ref type="table" coords="3,89.75,539.75,4.98,8.96">1</ref> The information and method each run used</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Result and Analysis</head><p>In this section, we analyze of three official runs we submitted. Though, the results are not as good as we expected, we find some important and worth-exploring factors.</p><p>In this year's task, the average length of 50 topics is 2.1, which is shorter than that of previous Terabyte Track by 1. In addition, there are also many single-word topics. We turn our system parameters based on GOV2 dataset using topic 701~850 without any special optimization on short queries. We also remove the stop words from the topics, which make the topics shorter. The description of topics is show in table <ref type="table" coords="3,339.89,121.62,3.77,8.96" target="#tab_0">2</ref>. Due to these short topics, we give an analysis of how they affect the performance of our system. Among 17 oneword topics, 14 topics need to find the homepage, only three topics are purely information topic (wt09-04: totlet, wt09-12: djs, wt24: diversity). In official Run1 and Run2, these methods only find one topic which has relevant results in top10. For other 16 topics, we don't find any relevant document in top10. Link method (Run3) can find at least 7 topics which at least one relevant document in top 10. From the above results, we can find link method is better than previous two methods we mentioned for one-word topics. It may because link method combines the URL content and link information. However, it performs worse than the previous two methods for information topic wt09-12. For two-word queries, our runs give bad results due to several reasons. First, 13 of these 17 topics are needed to find homepage. Second, we filter out stop words and stems word which makes the topics shorter. However, we need further experiments to find out the true reasons. We also find that the methods using document structural information performs slightly worse than that without structural information. Maybe we use different term proximity scores. Most of these two-word topics are phrases, while our system doesn't optimize for them. Although we use the proximity techniques, we limited the maximum proximity score is 1. For other 16 longer queries, we find more relevant documents in top 5 ranks and top 10 ranks. This may suggest that our system is more robust for longer queries.</p><p>Since our system finds none relevant docs in top 10 for nearly half of all topics, the whole score we get is much lower than that of GOV2.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>The Web track provides a good test bed for retrieving documents from a very large Web document collection. We find out some deficiency of the PARADISE system, including: 1) It performs worse for short queries; 2) There is no query analysis system. It is supposed to perform better if we can distinguish multiple query intents; 3) It has not employed much information from web structure, such as PageRank.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,323.35,139.50,224.37,52.92"><head>Table 2 . Length of topics in Wt09 and GOV2</head><label>2</label><figDesc></figDesc><table coords="3,323.35,151.19,224.37,41.22"><row><cell>Topic Length</cell><cell>Wt09(total 50)</cell><cell>701-850(total 150)</cell></row><row><cell>1</cell><cell>17(34%)</cell><cell>2 (1.3%)</cell></row><row><cell>2</cell><cell>17(34%)</cell><cell>39 (26%)</cell></row><row><cell>&gt;2</cell><cell>16(32%)</cell><cell>109(72.7%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,317.95,372.45,239.97,119.78"><head>Table 3 The number of topics find at least one relevant document @5,@10</head><label>3</label><figDesc></figDesc><table coords="3,323.35,395.80,222.11,96.42"><row><cell>Topic Length</cell><cell>Run1</cell><cell>Run2</cell><cell>Run3</cell><cell>Med</cell></row><row><cell>Rel Retr @ 5(Len=1)</cell><cell>1</cell><cell>1</cell><cell>5</cell><cell>4</cell></row><row><cell>Rel Retr @ 10(Len=1)</cell><cell>1</cell><cell>1</cell><cell>7</cell><cell>7</cell></row><row><cell>Rel Retr @ 5(Len=2)</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>7</cell></row><row><cell>Rel Retr @ 10(Len=2)</cell><cell>6</cell><cell>5</cell><cell>8</cell><cell>12</cell></row><row><cell>Rel Retr @ 5(Len&gt;2)</cell><cell>8</cell><cell>8</cell><cell>7</cell><cell>10</cell></row><row><cell>Rel Retr @ 10(Len&gt;2)</cell><cell>10</cell><cell>10</cell><cell>9</cell><cell>11</cell></row><row><cell>Rel Retr @ 5(all)</cell><cell>14</cell><cell>14</cell><cell>17</cell><cell>21</cell></row><row><cell>Rel Retr @ 10(all)</cell><cell>16</cell><cell>16</cell><cell>24</cell><cell>30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,59.42,74.70,224.70,52.92"><head>Table 4 . Effectiveness of office run</head><label>4</label><figDesc></figDesc><table coords="4,59.42,86.39,224.70,41.22"><row><cell>Run</cell><cell>bpref</cell><cell>map</cell><cell>P5</cell><cell>P10</cell></row><row><cell>1.pkuTp</cell><cell>0.170</cell><cell>0.059</cell><cell>0.132</cell><cell>0.148</cell></row><row><cell>2.pkuSturct</cell><cell>0.171</cell><cell>0.062</cell><cell>0.132</cell><cell>0.146</cell></row><row><cell>3.pkuLink</cell><cell>0.159</cell><cell>0.045</cell><cell>0.108</cell><cell>0.116</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="9.">Acknowledgments</head><p>This work is partially supported by <rs type="funder">China MOE</rs> under the grant number <rs type="grantNumber">2008107</rs>, <rs type="funder">NSFC</rs> under the grant number <rs type="grantNumber">70903008</rs> and <rs type="grantNumber">60933004</rs>, and <rs type="grantNumber">863</rs> Grant <rs type="grantNumber">2007AA01Z154</rs>. We also thanks to <rs type="person">Kai Fan</rs> who help us to calculate InLink values and merge anchor texts via <rs type="person">Hadoop Cluster</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MGqCyns">
					<idno type="grant-number">2008107</idno>
				</org>
				<org type="funding" xml:id="_9DDsgEN">
					<idno type="grant-number">70903008</idno>
				</org>
				<org type="funding" xml:id="_wZ7aVwC">
					<idno type="grant-number">60933004</idno>
				</org>
				<org type="funding" xml:id="_DEEBvWr">
					<idno type="grant-number">863</idno>
				</org>
				<org type="funding" xml:id="_AX3vDgT">
					<idno type="grant-number">2007AA01Z154</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,75.98,362.42,218.02,8.10;4,75.98,372.98,149.46,8.10" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,187.57,362.42,106.43,8.10;4,75.98,372.98,99.02,8.10">MapReduce: Simplified data processing on large clusters</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,75.98,383.54,217.88,8.10;4,75.98,394.12,218.10,8.10;4,75.98,404.68,23.49,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,242.67,383.54,51.19,8.10;4,75.98,394.12,144.96,8.10">Simple BM25 Extension to Multiple Weighted Fields</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,231.53,394.12,43.49,8.10">CIKM 2004</title>
		<imprint>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,75.98,415.24,218.18,8.10;4,75.98,425.80,218.23,8.10;4,75.98,436.36,218.05,8.10;4,75.98,446.92,46.29,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,269.23,415.24,24.94,8.10;4,75.98,425.80,184.22,8.10">Queryindependent evidence in home page finding</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Upstill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,275.21,425.80,19.00,8.10;4,75.98,436.36,161.09,8.10">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="286" to="313" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,75.98,457.48,218.15,8.10;4,75.98,468.04,218.08,8.10;4,75.98,478.60,72.68,8.10" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,80.08,468.04,206.42,8.10">Relevance weighting for query independent evidence</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>ACM</publisher>
			<biblScope unit="page">423</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,75.98,489.16,217.92,8.10;4,75.98,499.72,218.11,8.10;4,75.98,510.28,17.73,8.10" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,192.27,489.16,101.63,8.10;4,75.98,499.72,187.08,8.10">Term Proximity Scoring for Ad-Hoc Retrieval on Very Large Text Collections</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lushman</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Third Text</note>
</biblStruct>

<biblStruct coords="4,75.98,520.84,217.86,8.10;4,75.98,531.40,218.02,8.10;4,75.98,541.96,142.80,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,108.25,531.40,185.75,8.10;4,75.98,541.96,40.13,8.10">Viewing Term Proximity from a Different Perspective</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Asia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,125.66,541.96,17.35,8.10">Work</title>
		<imprint>
			<biblScope unit="page" from="346" to="357" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
