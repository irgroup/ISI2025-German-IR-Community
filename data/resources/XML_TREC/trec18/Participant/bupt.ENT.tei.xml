<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,177.60,77.08,240.16,14.42">BUPT at TREC 2009: Entity Track</title>
				<funder ref="#_FHG6x59">
					<orgName type="full">Project</orgName>
				</funder>
				<funder>
					<orgName type="full">NSFC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,159.00,114.54,56.24,9.88"><forename type="first">Zhanyi</forename><surname>Wang</surname></persName>
							<email>wangzhanyi@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.62,114.54,54.77,9.88"><forename type="first">Dongxin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.48,114.54,44.99,9.88"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,338.58,114.54,52.89,9.88"><forename type="first">Guang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.37,114.54,36.99,9.88"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Lab</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,177.60,77.08,240.16,14.42">BUPT at TREC 2009: Entity Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">481F54F71062A178ADBFCE345C88F105</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report introduces the work of BUPT (PRIS) in Entity Track in TREC2009.</p><p>The task and data are both new this year. In our work, an improved two-stage retrieval model is proposed according to the task. The first stage is document retrieval, in order to get the similarity of the query and documents. The second stage is to find the relationship between documents and entities. We also focus on entity extraction in the second stage and the final ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Entity track is a new one in TREC. The overall aim is to create a corpus for the evaluation of entity-related searches on Web data. [1] The task is related entity finding. It is motivated to a large degree by the expert finding task at the TREC Enterprise track. But they are different from many aspects, such as the definition of entity and task, entity type, primary homepage, even some specific method of IR and IE.</p><p>The task of related entity finding is defined as follow. Given an input entity, by its name and homepage, the type of the target entity, as well as the nature of their relation, described in free text, find related entities that are of target type, standing in the required relation to the input entity.</p><p>In our work, we improve a two-stage retrieval model according to the task. Moreover, we focus on entity extraction and ranking. The process of document retrieval is realized by indri toolkit [2], which is based on a combination of the language modeling and inference network retrieval frameworks.</p><p>The report is organized as follows. Section 2 introduces our search model briefly. Section 3 describes the process of related entity finding. Submitted runs shows in section 4 and section 5 gives the conclusion and Future work.  In order to finding entities and ranking support documents, a two-stage search model which is used in Enterprise track before is adopted. <ref type="bibr" coords="2,286.32,260.94,12.84,9.88" target="#b0">[3]</ref> Furthermore, we improve it according to the task. The structure is shown in Figure <ref type="figure" coords="2,264.85,280.92,4.10,9.88" target="#fig_1">1</ref>. Take documents (d 1 , d 2 ,…,d m ) as a bridge between query(q) and entities(e 1 , e 2 ,…,e n ). Then computing the score of query and entities transforms to two steps. The first step is to retrieve documents based a query. It is the same as general ad hoc retrieval. The second step is to find the relationship between documents and entities. The final score is got by combining previous results. The similarity of query and entity is:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Search Model</head><formula xml:id="formula_0" coords="2,207.26,375.02,302.74,27.35">( ) ( ) ( ) 1 , , , m j i i j i Sim q e Sim q d Sim d e = = ⋅ ∑ (1)</formula><p>Here m is the number of relevant documents. d i is the ist document and e j is the jst entity.</p><p>The model is simple and original. In following sections, improvements for it will be elaborated, such as entity extraction and classification, computing the similarity of document and entity, also the final score which is used to rank entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related Entity Finding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The system architecture is designed as Figure <ref type="figure" coords="2,307.83,560.10,4.10,9.88" target="#fig_2">2</ref>. First, we preprocess data which include many html tags. Meanwhile, some useful information (id, title, URL) is extracted. Second, we use indri toolkit to build two kinds of index. One is ordinary. The other makes a title field additionally. The index is the core in the system. Third, the represented or expanded query is sent to the indri, and then ranked documents and similarity of the query and documents return.</p><p>Next, entities are extracted from the documents. We choose one type of the target entity and find ranked documents related to these entities by indri again, in order to get the similarity.</p><p>Finally, similarities integrate to ranking score, also entities and support documents are given.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Document Retrieval Based Query</head><p>The process of document retrieval is ad hoc retrieval. We focus on three aspects, query representation, the special field in the text and the number of returned documents.</p><p>The type of a query is shown in figure <ref type="figure" coords="3,291.46,332.11,4.13,9.88" target="#fig_3">3</ref>. Besides the entity name, other three tags are also useful. An entity URL uniquely identifies an entity. It can be located to a document. The type of target entity is necessary. There are three types in the task, people, organization and product. Each query maps to a particular type of entity. So we only need to extract the just one. The narrative field is optional. However, we find that if we add some words into a query, the result will be better. Moreover, we find the title is essence in each web page. So we use it as an additional field. In the preprocess stage, titles of web pages are extracted. Then we modify the parameter file and build an index that includes a title field.</p><p>We don't need all relevant documents for the ones at the bottom of ranking list are almost irrelevant to the query. Their contribution to the final score can be negligible. In addition, the computational complexity increases with the scale of document. Taking into account the above factors, we control the number of relevant documents in the range of about 20 to 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Entity Extraction</head><p>The methods of entity extraction include the statistic-based approach and rule-based approach.</p><p>Both are adopted in our experiment. Recently, statistic-based approaches of Named Entity Recognition (NER) are widely used. NER labels sequences of words in a text which are the names of things, such as person and company names, or gene and protein names. It is usually involved in the theories of Maximum Entropy (ME) <ref type="bibr" coords="4,322.42,140.53,12.84,9.88" target="#b1">[4]</ref> and Conditional Random Field (CRF) <ref type="bibr" coords="4,90.00,160.51,11.64,9.88" target="#b2">[5]</ref>. Here we select a Name Entity Recognizer which is implemented by the Stanford NLP Processing Group <ref type="bibr" coords="4,173.52,180.55,11.59,9.88">[6]</ref>. The software provides a general implementation of linear chain CRF sequence models coupled with well-engineered feature extractors for Named Entity Recognition. It provides 3 types of entity, people, organization and location. According to our task, we modify its code and make it output the people and organization. The most serious problem is lack of training data, so we utilize MUC6, MUC7, and ACE et al. to train an appropriate model.</p><p>The name of people or organization often appears in some meaningful passage. However, the product may be in a list or table of a product's web site. Only use the sequence labeling approach like CRF is not enough. We also use some rules and manual ways. A part of products and URLs are extracted by generative rules to some special web site. Then we choose them manually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Document Retrieval Based Entity</head><p>As in eq. 1, the similarity of d and e should be calculated. Some common ways of statistics for all the document and entities are very complex. We adopt the retrieval approach to keep it consistent with the similarity of q and d. Then we can take entities as queries mentioned in the 3.2 section. We get documents related to entities and their similarities. The ones appear in the relevant documents of query are used in the next step. They are just the bridge in the model, see also figure <ref type="figure" coords="4,156.23,520.54,4.13,9.88" target="#fig_1">1</ref>. Others are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Ranking</head><p>After previous work, documents and entities are both received. We need to find the most relative ones by some ranking algorithms. Considering that exponent function is monotonous, and the range is (0,1] while the domain is (-∞,0], it is fit for ranking entities. We define the score of a entity as:</p><formula xml:id="formula_1" coords="4,178.51,662.76,262.97,37.34">( ) ( ) ( ) ( ) 1 exp exp , , , j m j i i j i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score e</head><p>Sim q e Sim q d Sim d e</p><formula xml:id="formula_2" coords="4,198.61,644.30,311.39,56.97">α α =           = - = -       ⋅     ∑ (2)</formula><p>in which α is a parameter for scaling. For each ranked entity, support documents can be listed by similarity.</p><p>Then we allocate a homepage for each entity. In our task, for each target entity at least one homepage must be returned. Documents returned in the homepage and Wikipedia fields must not be retrieved for multiple entities in the same topic. For a topic, we can't ensure that the homepages returned are absolutely correct. If it is forbidden to retrieve for multiple entities in the same topic, once the former homepages are wrong, the later homepages will be influenced. In that condition, for one topic only one entity and homepage (or WP) pair is returned in our experiment this time. So at least a homepage is shown, even some entities have Wikipedia page. HP or WP is determined by:</p><formula xml:id="formula_3" coords="5,214.37,240.66,295.63,32.33">( ) ( ) , , arg max exp i r i HP WP d D sim d e d e β ∈       =          <label>(3)</label></formula><p>in which β is a empirical parameter like α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Submitted Runs</head><p>The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In our work, an improved two-stage retrieval model is proposed according to the task. The first stage is document retrieval, in order to get the similarity of the query and documents. The second stage is to find the relationship between documents and entities. Final scores are computed by combining previous results. We also focus on entity extraction in the second stage and the final ranking. As of future work, we will care about entity disambiguation and entity-relationship recognition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,250.98,221.58,93.39,9.02"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Search model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,230.70,252.78,133.96,9.02"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The system architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="3,241.68,541.68,112.00,9.02;3,111.00,561.30,394.39,9.88;3,141.48,449.04,312.30,82.44"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. An example query An ordinary full-text index must be built. It can be taken as a baseline in the experiment.</figDesc><graphic coords="3,141.48,449.04,312.30,82.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,90.00,355.32,415.43,409.81"><head></head><label></label><figDesc>Entity Track uses the "Category B" subset of ClueWeb09 dataset which is new. It contains about 50 million English pages. Three quarters are webpage, and others are Wikipedia page. The size decreases from 1.39TB to 267GB by preprocessing.For each query, we return up to 100 related entities. Each entity corresponds to up to 10 supporting documents. We treat different types of query as four runs, original queries, original queries and narratives, terms of queries must appear ordered and retrieving queries in title field. Table1lists the 4 runs including numbers of entities and support documents related to 20 topics.</figDesc><table coords="5,153.72,415.98,287.71,349.16"><row><cell cols="5">Table 1. Four runs including numbers of entities and support documents</cell></row><row><cell></cell><cell cols="4">Run1(ENT/SP) Run2(ENT/SP) Run3(ENT/SP) Run4(ENT/SP)</cell></row><row><cell>Q1</cell><cell>100/18</cell><cell>100/9</cell><cell>100/9</cell><cell>28/12</cell></row><row><cell>Q2</cell><cell>100/14</cell><cell>100/15</cell><cell>100/12</cell><cell>5/7</cell></row><row><cell>Q3</cell><cell>100/6</cell><cell>89/6</cell><cell>95/6</cell><cell>36/6</cell></row><row><cell>Q4</cell><cell>100/6</cell><cell>40/6</cell><cell>100/6</cell><cell>100/20</cell></row><row><cell>Q5</cell><cell>7/4</cell><cell>1/1</cell><cell>4/3</cell><cell>2/5</cell></row><row><cell>Q6</cell><cell>14/5</cell><cell>24/6</cell><cell>5/4</cell><cell>27/12</cell></row><row><cell>Q7</cell><cell>100/6</cell><cell>100/5</cell><cell>98/6</cell><cell>100/16</cell></row><row><cell>Q8</cell><cell>11/3</cell><cell>79/6</cell><cell>13/3</cell><cell>12/2</cell></row><row><cell>Q9</cell><cell>13/6</cell><cell>11/7</cell><cell>10/5</cell><cell>51/17</cell></row><row><cell>Q10</cell><cell>82/6</cell><cell>53/6</cell><cell>88/6</cell><cell>100/20</cell></row><row><cell>Q11</cell><cell>51/10</cell><cell>16/11</cell><cell>9/4</cell><cell>44/17</cell></row><row><cell>Q12</cell><cell>63/6</cell><cell>100/6</cell><cell>86/6</cell><cell>100/20</cell></row><row><cell>Q13</cell><cell>4/3</cell><cell>1/2</cell><cell>3/2</cell><cell>2/6</cell></row><row><cell>Q14</cell><cell>21/6</cell><cell>8/5</cell><cell>21/6</cell><cell>100/18</cell></row><row><cell>Q15</cell><cell>16/6</cell><cell>26/5</cell><cell>75/6</cell><cell>100/19</cell></row><row><cell>Q16</cell><cell>59/6</cell><cell>8/5</cell><cell>4/1</cell><cell>92/19</cell></row><row><cell>Q17</cell><cell>4/3</cell><cell>7/5</cell><cell>9/5</cell><cell>18/14</cell></row><row><cell>Q18</cell><cell>17/4</cell><cell>65/6</cell><cell>3/5</cell><cell>62/18</cell></row><row><cell>Q19</cell><cell>15/6</cell><cell>50/6</cell><cell>23/3</cell><cell>61/19</cell></row><row><cell>Q20</cell><cell>54/6</cell><cell>94/7</cell><cell>53/6</cell><cell>100/19</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by <rs type="funder">Project</rs> "<rs type="projectName">Multidimensional latent feature extraction model based Evolutional document filtering</rs>" supported by <rs type="funder">NSFC</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_FHG6x59">
					<orgName type="project" subtype="full">Multidimensional latent feature extraction model based Evolutional document filtering</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Clean Data</head><p>Preprocess</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="6,109.31,515.71,395.97,9.88;6,90.00,535.75,84.05,9.88" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Zhao</forename><surname>Ru</surname></persName>
		</author>
		<title level="m" coord="6,160.69,515.71,344.60,9.88;6,90.00,535.75,50.91,9.88">TREC 2005 Enterprise Track Experiments at BUPT. In proceedings of TREC-2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.22,555.73,398.01,9.88;6,90.00,575.71,415.23,9.88;6,90.00,595.75,58.96,9.88" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,183.12,555.73,303.88,9.88">Automatic Entity Relation Extraction Based on Maximum Entropy</title>
		<author>
			<persName coords=""><forename type="first">Zhang</forename><surname>Suxiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,90.00,575.71,415.23,9.88;6,90.00,595.75,54.43,9.88">Proceedings of the Sixth International Conference on Intelligent Systems Design and Applications</title>
		<meeting>the Sixth International Conference on Intelligent Systems Design and Applications</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.20,615.74,396.20,9.88;6,90.01,635.72,415.31,9.88;6,90.01,655.76,24.77,9.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,180.75,615.74,324.66,9.88;6,90.01,635.72,98.75,9.88">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,208.40,635.72,292.21,9.88">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
