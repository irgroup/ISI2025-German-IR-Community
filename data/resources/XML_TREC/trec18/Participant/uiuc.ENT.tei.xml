<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,97.91,72.35,413.91,16.84;1,170.23,92.27,269.26,16.84">Finding Related Entities by Retrieving Relations: UIUC at TREC 2009 Entity Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,93.31,137.97,114.91,11.06"><forename type="first">V</forename><forename type="middle">G Vinod</forename><surname>Vydiswaran</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,217.40,137.97,81.67,11.06"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.87,137.97,59.86,11.06"><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.05,137.97,37.53,11.06"><forename type="first">Jing</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,424.05,137.97,92.37,11.06"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
							<email>czhai@cs.uiuc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,97.91,72.35,413.91,16.84;1,170.23,92.27,269.26,16.84">Finding Related Entities by Retrieving Relations: UIUC at TREC 2009 Entity Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9CCE49342344AE01E041D13B4F4DC5EB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our goal in participating in the TREC 2009 Entity Track was to study whether relation extraction techniques can help in improving accuracy of the entity finding task. Finding related entities is informational in nature and we wanted to explore if inducing structure on the queries helps satisfy this information need. The research outlook we took was to study techniques that retrieve relations between two entities from a large corpus, and from those, find the most relevant entities that participate in the given relation with another given entity. Instead of aiming at retrieving pages about specific entities, we tried to address the problem of directly finding the entities from the text. Our experimental results show that we were able to find many related entities using relation-based extraction, and ranking entities based on further evidence from the text helps to a certain extent.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">PROBLEM FORMULATION</head><p>The TREC 2009 Entity Track concentrated on finding related entities. Given an entity of focus, the nature of relation between this entity and other entities, and some information of the type of other entities, the goal was to find all the related entities.</p><p>Instead of taking a search perspective looking for homepages of related entities, we wanted to explore the information seeking aspects of the query. Our general goal for the Entity track was to study the usefulness of information extraction techniques in improving the accuracy of the entity finding task. In particular, we focused on investigating whether we can improve accuracy by formulating such entity-finding queries as a relation query, which can be answered through relation extraction. We formulated the query, described by the narrative, as [entity -relation -entity] triplet, where relation and the first entity are given, and the type of the other entity is known. The task is to then find instances of the other entity that satisfy the relation. Such a formulation also reflects many other semantic search applications such as redacting (anonymizing) sensitive information, question answering, and intelligence gathering applications. This formulation was similar to a relation retrieval problem, explored earlier in <ref type="bibr" coords="1,131.62,658.88,9.20,7.86">[7]</ref>. A relation is assumed to be binary verb predicate over entities, where the entities can potentially have roles in which they participate in the relation. For example, the relation of touring a new city can be modeled as a person visiting a location. Here, the person always fills in the first slot and the location fills in the second. Spe-cial filters can additionally be applied on the two slots to restrict specific subsets of persons or locations (such as a city or a country). In this year's task at TREC, one entity (usually the "first slot") is deterministic and fixed and the second entity is restricted by the type of the named entity. The relation was specified in the narrative, or had to be derived from there.</p><p>In the next sections, we describe our approach in detail. We start with an overall system architecture in section 2, detailing the core modules in sections 2.1, 2.2, and 2.3. We explain the parameters of our submitted runs in section 3 and briefly summarize our preliminary evaluation in section 4. Finally, we discuss some challenges we faced in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SYSTEM ARCHITECTURE</head><p>Our basic approach can be summarized by the following stages:</p><p>1. Formulate a structured query based on the given entity and the relation expressed by the narrative.</p><p>2. Retrieve relevant snippets that match the relations specified in the query.</p><p>3. Identify named entities in the resultant snippets using state-of-the-art NE taggers (for persons and organizations) and product identifiers.</p><p>4. Rank retrieved entities and find homepages for the entities.</p><p>We further extend this basic approach in two ways:</p><p>• Before the retrieval step, we expand the relation expressed in the given query with semantically similar and related words, derived from WordNet and other linguistic resources such as distributional similarity; resulting in an expanded query for retrieval.</p><p>• After retrieval, we explore techniques to improve the accuracy of extraction by searching for more relations that link the two entities in similar contexts, from the corpus. This is expected to help us improve our entity identification task and improve the relative ranking of relevant entities.</p><p>The following sections explain the three steps in our model, viz. query formulation and retrieval, entity recognition, and entity filtering and re-ranking.</p><p>Figure <ref type="figure" coords="2,87.40,216.09,4.12,7.89">1</ref>: Screen shot of a sample search system <ref type="bibr" coords="2,281.72,216.09,11.19,7.89">[7]</ref> that searches for related entities given the relation and one of the entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relation Retrieval</head><p>As we described earlier, we model the information need as a structured query. We identify three parts to the structure: the relation, the entity of focus, and the entity of interest. A sample snapshot of the query interface from a demo system is shown in Fig. <ref type="figure" coords="2,123.19,334.60,3.58,7.86">1</ref>. This formulation does not describe an arbitrary relation, but we postulate that any long-distance relation could be modeled as a series of multiple binary relations. For example, the task of finding "all team-mates of Michael Schumacher" could be addressed by formulating two related relation queries: "[Michael Schumacher] [drives for] [ORG-1]" and "[PER] [drives for] [ORG-1]", to find related entities through ORG-1 (the team), which is as yet unknown, but would hopefully get filled in by "Ferrari" during execution. Such a formulation would still not capture all pieces of information or relations, such as co-occurrence relation or "is-a" (sub-class) relation (e.g., sportspersons, German nationals, etc.). We plan to treat these as filters that would need external "world knowledge" to solve.</p><p>One of the primary challenges is to recognize the relation. For all TREC queries, we use the narrative to derive what the intent of the query is, and hence decide on the relation. In most cases, we could parse the narrative to identify the verb directly or indirectly, when the verb is present in nominalized form (i.e. in noun form). In cases where parsing failed to recognize the relation, simple rewrite rules such as converting the "headline-style" narrative into a grammatical sentence helped. For example, the narrative for query number 1 in test topics, "Carriers that Blackberry makes phones for." was preceded by "There are many" to construct a valid grammatical sentence and help parse the narrative better. We restricted our model to a single relational query in the current runs.</p><p>Once the relation predicate was identified, we augment it with its synonyms from WordNet <ref type="bibr" coords="2,191.32,658.88,9.20,7.86" target="#b4">[4]</ref>. We also incorporated similar words found using distributional similarity computed over a large text corpus. Other works in literature <ref type="bibr" coords="2,253.14,679.80,9.71,7.86" target="#b3">[3,</ref><ref type="bibr" coords="2,265.30,679.80,7.16,7.86" target="#b5">5]</ref> have shown that words belonging to word-classes built in such an unsupervised fashion have high similarity and relatedness among them.</p><p>Finally, the given entity is used to restrict the searches to pertain to a primary entity. This way, we hope to retrieve all relations expressed in different surface forms, but related to the specific entity; thereby improving recall without losing too much on precision. We also add other noun phrases from the narrative to the final query as optional keywords.</p><p>We built a retrieval system over the ClueWeb09 corpus using the Indri toolkit <ref type="bibr" coords="2,384.28,130.86,9.20,7.86" target="#b8">[8]</ref>, and utilized the rich IndriQuery querying language to query the index. The final query formulation had the primary entity, the relation word with its synonyms, optional noun phrases from the narrative, and the type information of the desired entity, combined in such a way that the retrieval system enforces matching of the primary entity and one of the relation words in all retrieved documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Identifying Entities</head><p>The next step is to find the entities participating in the relation of interest. From the relevant documents returned by the retrieval system, we first identify relevant snippets.</p><p>A snippet is primarily a passage of 2-3 sentences around the words that match the query. Since our queries have both entity and relation components, we hypothesize that the snippets would also contain the second entity that is related to the given entity. The retrieved snippets are passed through state-of-the-art NER taggers and product extractors to identify the entities in the snippets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Names and Organizations</head><p>Researchers have been dealing with named entities for over a decade now, and have proposed and evaluated many models to this effect <ref type="bibr" coords="2,374.38,383.53,9.71,7.86" target="#b2">[2,</ref><ref type="bibr" coords="2,388.85,383.53,6.47,7.86" target="#b6">6]</ref>. Like most NLP tasks, these models derive local and global features based on the actual named entity itself and the context in which it appears; and train a classifier to recognize and classify an entity from free text, using external resources when available. Recognizing named entities is now considered one of the pre-processing steps to analyzing text for deeper semantics, and many NLP toolkits are available for entity recognition.</p><p>We used the LBJ-based Named Entity Tagger<ref type="foot" coords="2,506.75,475.91,3.65,5.24" target="#foot_0">1</ref> to tag the retrieved snippets with named entities, viz. person names (PER), organizations (ORG), locations (LOC), and other classes (MISC). This state-of-the-art tagger <ref type="bibr" coords="2,465.93,509.06,9.71,7.86" target="#b6">[6]</ref> uses non-local features, external knowledge such as gazetteers derived from Wikipedia, and features based on word cluster hierarchy derived using distributional similarity over a larger text corpus. The tagger has also been shown to perform well on Webpages, where most named entities have less context around them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Products</head><p>For the TREC task, we were primarily concerned with person names, organizations, and product names. Since the state-of-the-art named entity recognizer that we used only identified entities such as person, locations, and organizations, we implemented a fairly simple tool to recognize products. Our product recognizer uses a rule based approach and is context independent. It mainly relies on a dictionary of company names and a pre-defined set of patterns for product recognition.</p><p>The search for product names starts with the generation of a set of candidate phrases. Candidate phrases are phrases that match a pre-defined set of regular expression patterns. These candidate phrases could eventually turn out to be true product names. Applying a regular expression pattern, such as "find capitalized phrases containing some numbers with length greater than two", on the text "The Nokia 6600 was one of the oldest models." will result in "The Nokia 6600" being tagged as a potential product name.</p><p>To be certain that candidate product names found through regular expression matches are indeed true product names, further analysis is needed. For the example provided, the candidate phrase, "The Nokia 6600" will be further analyzed with validation and refinement steps, as follows:</p><p>• Removal of stop words at the beginning of a candidate product name</p><p>• Phrase length validation (varies based on matched pattern)</p><p>• Occurrence of company name within a candidate phrase Various regular expression patterns were defined to capture different types of products with the most specific pattern being at the top. If two patterns match overlapping candidate phrases, the longer phrase is always chosen although this phrase is subject to further validation. Although regular expression matches alone may be sufficient in identifying a product name, to avoid false positives or wrong start and end boundaries it is necessary to validate them through checks like the ones mentioned above. In our implementation, the types of refinement and validation checks performed depend on the regular expression patterns matched.</p><p>The product class, in itself, is a heterogeneous mix of multiple classes, depending on the categories they belong to.</p><p>A music album could have any generic name, whereas a laptop model has a more generalizable name. A pharmaceutical product name, such as "Synagis R ", is not a company name but is simply a capitalized word ending with a symbol. Such a name will not be correctly identified as a true product name if the above refinement steps are used. Thus, different types of products will need different forms of validation. This is one of the major problems that we faced in recognizing products. Products of different genres have very different ways of being defined -common consumer products often contain model numbers or company names within them, pharmaceutical products tend to be single word names, names of music albums are simply plain text often capitalized, and so on. Thus, we feel that a better approach would be to first identify the origin domain of the text to be tagged (e.g., pharmaceutical, music, journal, etc.), and then apply tagging rules that are specific to that domain.</p><p>Extending state-of-the-art NE taggers to new classes is indeed a potential research direction to be explored, as has been done in bio-medical and chemical domains. However, for this task, we decided to go with the simpler approach of applying a general set of rules that would capture most common product names with refinement steps specific to the matched regular expression pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Filtering and re-ranking entities</head><p>Once the entities are identified, we try to find which entities are relevant to the query. As of now, the only filter we have applied is that the candidate entities identified are colocated with the entity of interest. We apply the following filter rules to shorten the list of candidate entities.</p><p>1. We first drop the entity that has high lexical overlap with the given entity in the query.</p><p>2. We look at the type of the desired entity from the query topic and remove all entities that are not of that type. The queries looking for persons and organizations directly correspond to PER and ORG classes of the NE tagger. But for products, we consider input from Product identifier and the "other" MISC class tagged by the LBJ-based NE tagger. This way, we hope to cover a broader class of product names.</p><p>3. We also try to prune candidates based on semantic structure of the sentences. The idea is to include candidates from only those sections of the sentences that are part of the SRL predicate-argument structure corresponding to the relation word. However, we found that this rule was very restrictive, in that it implicitly assumed that all entity-relation matches occurred in well-formed sentences (which was not the case for many queries). So, the rule ended up removing many valid occurrences.</p><p>4. Finally, we compute string edit-distance between remaining entities; and merge candidates that have high similarity. This heuristic also tries to merge candidate people names that specify only the last name. For example, this assimilation was important in case of Karen Spärck-Jones, an "ACM Athena Award winner" (query number 2 in test topics). This way, we could handle slight variations in her name, like Karen Spärck-Jones, Karen Sparck Jones, and Sparck-Jones, and treat them all as one.</p><p>The next step was to score the candidate entities and get a ranked list of candidates. We could try out two measures for scoring and re-ranking in our runs. These are explained below.</p><p>1. Support in the retrieved snippets. Support was computed by simply counting the number of times a candidate name appeared in the retrieved snippets. If two candidate names were merged because of small spelling variations, their counts were added up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Relatedness with the given entity. We issue multiple queries, one per candidate, that look for possibly other relations between the two entities (i.e. the given entity and one candidate entity per query). We calculated support based on documents retrieved by such a query. The intuition behind this measure is that if there are many documents that mention the two entities together in close proximity, then this evidence of high co-occurrence may indicate some relationship between the two entities, even if there is no explicit mention of the relation asked for We combined the two scores using a simple weighted sum, with the relative weight of importance manually set to prefer support over relatedness in the ratio of 2:1.</p><p>As the final step, we searched the corpus for homepages of the final, ranked list of candidate entities. This was done using a simple IndriQuery that weighted the occurrence of the candidate name in the title and headings higher than the body (in the ratio of 5:4:1, respectively). We pruned the retrieved set of results to only consider the top 3 documents as homepages, as per the submission guidelines. If one of the top 3 pages returned was a Wikipedia page, then we assigned that document id to the optional "Wikipedia homepage" field and continued up to the top 4 documents instead of 3. A shortcoming of this approach was that a document might come as a top-ranked result for many entities if it is significant for multiple candidates. For example, the DBLP page of one of the co-authors might have multiple occurrences of other candidate entities, and hence might come as a top retrieved document for many entities. Since finding homepages was not the primary focus of the research ideas we wanted to explore, we applied simple rules to check that the resultant pages do not repeat under one query topic, again to follow the submission guidelines.</p><p>The process of finding homepages also acted as the final pruning step. If we could not find any document returned for a candidate entity, we dropped that candidate from the final list. This was also mandated by the submission guidelines.</p><p>Once the final ranked list of candidates was decided, we collected all documents that supported these candidates from the original list of documents returned for the relation query. This subset was mentioned as the list of supporting documents in the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DETAILS OF THE SUBMITTED RUNS</head><p>We submitted three runs, viz. UIauto, UIqryForm, and UIqry-Form3; and they are summarized in Table <ref type="table" coords="4,217.44,690.26,3.58,7.86" target="#tab_0">1</ref>. None of the runs handled Wikipedia sub-collection in any special way. The details about the runs are explained below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">UIauto</head><p>This was an automatic run. We constructed the relation query with only the words in the narrative. We did not use WordNet, but considered only the closest word from the distributional similarity-based word cluster as the synonym. The top 100 documents were retrieved and the relevant snippets were passed through the named entity recognizers. Then, the candidate entities were re-ranked based on both support and relatedness metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">UIqryForm</head><p>This run was manual. We first applied WordNet based synonym expansion to the relation word. However, we found that it added many words that drifted the intent of the query. So, we have to manually prune out the other irrelevant senses from the expansion list. We considered the top 20 documents and identified entities from the snippets as described earlier. The entities were ranked only on the support metric. All the short-listed entities were returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">UIqryForm3</head><p>This run was also manual. It was basically the same setup as UIqryForm, except that only the top 10 documents were considered while finding related entities, and only top 3 entities were returned for each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EVALUATION</head><p>As per the official results released, the UIauto run seemed to perform the best among the runs we submitted. The results are summarized in the first row of Table <ref type="table" coords="4,482.45,575.20,3.58,7.86" target="#tab_1">2</ref>.</p><p>Since our primary focus was to check if we are able to retrieve the related entities, and not on finding homepages corresponding to the related entities, we also evaluated our performance on recognizing relevant named entities alone.</p><p>For this, we considered all the name strings identified in the released qrel file for this track and computed the retrieval measures over the names of the entities. It must be noted that a name was judged correct if it matched up with something else in the record, even if the record was neither primary nor relevant for the topic <ref type="bibr" coords="4,456.43,690.26,9.20,7.86" target="#b1">[1]</ref>. This means that, for the purpose of evaluating names alone, the qrel file may include spurious entries. We were not aware of this anomaly till the TREC workshop and we could not find an automated approach to easily overcome this.</p><p>Table <ref type="table" coords="5,79.26,254.85,4.61,7.86" target="#tab_1">2</ref> summarizes our performance on retrieving relevant named entities. In the table, micro-averaged precision is calculated by accumulating counts of relevant and retrieved entities over all query topics, and then finding the precision over the accumulated counts. In contrast, macro-averaged precision is calculated by first computing the precision for each query topic and then taking their average.</p><p>As shown in Table <ref type="table" coords="5,132.60,338.54,3.58,7.86" target="#tab_1">2</ref>, we get a macro-averaged precision of over 0.36 for both UIauto and UIqryForm. In UIqryForm3, since we restricted our results to only top 3 named entities for each topic query, the macro-averaged precision was significantly higher at 0.51, but at the cost of lower number of returned entities. This probably suggests that we were more successful in finding the relevant entities, but could not get valid homepages for most of the entities we found. The Precision at 5 and Precision at 10 measures also show that UIauto run performed better over the other runs. It is able to achieve an average of 60% precision, computed at 5 results, adjusted for number of entities retrieved.</p><p>In our experiments, when we added WordNet based synonyms, we added too many digressing words, leading to poor results. In the submitted runs UIqryForm and UIqryForm3, we manually pruned the expansion list to only retain valid synonyms. So, the main reason for poor performance of the manual runs probably comes from the fact that these use fewer documents to find related entities. Additionally, these two runs did not use relatedness measure to further improve confidence of the extracted entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION</head><p>Large corpora often test the existing tools and system implementations to the core, for both scalability and robustness. This was the case also with the ClueWeb09 corpus. During the initial stages, we wanted to explore if we could parse the corpus with NLP tools such as the Named Entity tagger and co-reference resolver. This way we could use special indexes over the named entities for better retrieval, we hoped. But processing the large corpus took inordinate time, so we had to revert to applying NLP tools only on the smaller snippets, increasing the query time.</p><p>Another important issue was to overcome the errors of ex-isting NE taggers and filters. On analyzing the candidates, we saw that the two main classes of errors that the taggers produced were erroneous classification (identifying the wrong named entity type) and to a lesser extent, identifying partial entities. We tried to overcome these by also including entities marked as MISC to overcome the type-naming errors. This was especially important for the product class of queries. We tried to overcome the partial entity recognition problem with edit-distance based clustering of similar candidate names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>To find the related entities from text, we have tried to incorporate NLP resources to analyze deeper semantics of text rather than surface matches. Our experiments validated our assumption that it is possible to find related entities using NLP techniques such as relation identification. Further, the results show that ranking related entities is improved by finding other supporting relations between entities from text. However, the manual improvements to the relation extraction stage does not show improvement; and further experimentation and analysis would be required to better understand the reason. The performance can be further improved with better techniques to filter false-positive entities and improve the ranking based on external corpora, such as Wikipedia. We believe that IR methodologies can help from deeper natural language processing and hope to continue this direction of research of combining NLP tools and techniques for improving focused searches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,339.23,679.80,216.70,39.25"><head>Table 1 :</head><label>1</label><figDesc>Parameters of the submitted runs justify relation between Claire Cardie and her students, even though it did not mention the advisorstudent relationship on the page.</figDesc><table coords="3,453.63,679.80,102.29,7.86"><row><cell>. A good example here is</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,145.17,55.47,319.38,137.07"><head>Table 2 :</head><label>2</label><figDesc>Summary of results</figDesc><table coords="5,145.17,55.47,319.38,115.79"><row><cell>Particulars ⇓</cell><cell cols="4">Run ID ⇒ UIauto UIqryForm UIqryForm3</cell></row><row><cell>nDCG (official)</cell><cell></cell><cell>0.0575</cell><cell>0.0302</cell><cell>0.0189</cell></row><row><cell cols="2"># Named Entities (NEs) returned</cell><cell>624</cell><cell>510</cell><cell>57</cell></row><row><cell cols="2"># relevant NEs returned</cell><cell>139</cell><cell>89</cell><cell>28</cell></row><row><cell cols="2">Micro-averaged precision</cell><cell>0.2228</cell><cell>0.1745</cell><cell>0.4912</cell></row><row><cell cols="2">Macro-averaged precision</cell><cell>0.3876</cell><cell>0.3671</cell><cell>0.5083</cell></row><row><cell>Precision @ 5</cell><cell></cell><cell>0.5400</cell><cell>0.4200</cell><cell>0.2800</cell></row><row><cell>Precision @ 10</cell><cell></cell><cell>0.4050</cell><cell>0.2350</cell><cell>0.1400</cell></row><row><cell cols="2">Precision @ R (R: # retrieved NEs)</cell><cell>0.3876</cell><cell>0.3671</cell><cell>0.5083</cell></row><row><cell cols="2">Precision @ 5 (adjusted for R)</cell><cell>0.6083</cell><cell>0.5083</cell><cell>0.5083</cell></row><row><cell cols="2">Precision @ 10 (adjusted for R)</cell><cell>0.5158</cell><cell>0.4018</cell><cell>0.5083</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,321.42,711.19,233.40,8.11"><p>From http://L2R.cs.uiuc.edu/∼cogcomp/software.php</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,321.30,537.70,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.01,550.29,224.92,7.86;5,331.01,560.75,205.36,7.86;5,331.01,571.21,219.31,7.86;5,331.01,581.67,129.89,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,392.99,560.75,143.37,7.86;5,331.01,571.21,21.12,7.86">Overview of the TREC 2009 Entity Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Serdyukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,370.91,571.21,179.40,7.86;5,331.01,581.67,101.68,7.86">Proceedings of the Eighteenth Text REtrieval Conference (TREC 2009)</title>
		<meeting>the Eighteenth Text REtrieval Conference (TREC 2009)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.01,593.13,212.57,7.86;5,331.01,603.59,207.45,7.86;5,331.01,614.05,216.46,7.86;5,331.01,624.51,89.95,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,531.55,593.13,12.02,7.86;5,331.01,603.59,165.12,7.86">An Algorithm that Learns What&apos;s in a Name</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Bikel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,504.36,603.59,34.10,7.86;5,331.01,614.05,212.29,7.86">Machine Learning Special issue on Natural Language Learning</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="211" to="231" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.01,635.97,220.56,7.86;5,331.01,646.43,197.26,7.86;5,331.01,656.89,186.29,7.86;5,331.01,667.35,82.28,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,406.22,646.43,122.04,7.86;5,331.01,656.89,70.49,7.86">Class-Based n-gram Models of Natural Language</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">F</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">J D</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,409.12,656.89,104.35,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.01,678.81,224.91,7.86;5,331.01,689.27,69.28,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="5,385.65,678.81,166.00,7.86">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.01,700.73,216.84,7.86;5,331.01,711.19,189.10,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,362.71,700.73,185.14,7.86;5,331.01,711.19,21.59,7.86">Automatic Retrieval and Clustering of similar words</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,371.47,711.19,56.08,7.86">COLING-ACL</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="768" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,57.64,193.51,7.86;6,67.99,68.10,196.70,7.86;6,67.99,78.56,177.95,7.86;6,67.99,89.02,171.36,7.86;6,67.99,99.48,203.89,7.86;6,67.99,109.94,218.51,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,170.51,57.64,91.00,7.86;6,67.99,68.10,181.01,7.86">Design Challenges and Misconceptions in Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,67.99,78.56,177.95,7.86;6,67.99,89.02,171.36,7.86;6,67.99,99.48,57.04,7.86">Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06">June 2009</date>
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,121.40,186.76,7.86;6,67.99,131.86,197.21,7.86;6,67.99,142.32,224.91,7.86;6,67.99,152.78,217.06,7.86;6,67.99,163.24,172.38,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,247.84,121.40,6.91,7.86;6,67.99,131.86,181.52,7.86">A Framework for Entailed Relation Recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vydiswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,67.99,142.32,224.91,7.86;6,67.99,152.78,25.36,7.86">Proceedings of the ACL-IJCNLP 2009 Conference Short Papers</title>
		<meeting>the ACL-IJCNLP 2009 Conference Short Papers<address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-08">August 2009</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,174.70,217.93,7.86;6,67.99,185.16,195.22,7.86;6,67.99,195.62,208.90,7.86;6,67.99,206.08,164.93,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,67.99,185.16,195.22,7.86;6,67.99,195.62,62.75,7.86">Indri: A language-model based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,149.12,195.62,127.77,7.86;6,67.99,206.08,136.89,7.86">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
