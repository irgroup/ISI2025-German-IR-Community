<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,196.20,76.31,214.21,12.58;1,202.32,93.77,204.61,12.58">A Study of Faceted Blog Distillation --PRIS at TREC 2009 Blog Track</title>
				<funder>
					<orgName type="full">LQE</orgName>
				</funder>
				<funder>
					<orgName type="full">Indri</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.10,134.13,19.42,9.45"><forename type="first">Si</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,184.17,134.13,39.26,9.45"><forename type="first">Huiji</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.12,134.13,34.31,9.45"><forename type="first">Hao</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.76,134.13,35.91,9.45"><forename type="first">Fei</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.28,134.13,54.76,9.45"><forename type="first">Oupeng</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,378.36,134.13,53.86,9.45"><forename type="first">Sanyuan</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,148.02,149.73,44.68,9.45"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,200.26,149.73,50.81,9.45"><forename type="first">Xinsheng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.71,149.73,37.25,9.45"><forename type="first">Caili</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.35,149.73,43.89,9.45"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,353.99,149.73,50.43,9.45"><forename type="first">Guang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,412.04,149.73,35.22,9.45"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,196.20,76.31,214.21,12.58;1,202.32,93.77,204.61,12.58">A Study of Faceted Blog Distillation --PRIS at TREC 2009 Blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC4E6C20B9390812BFC02909B79768A2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes BUPT (pris) participation in faceted blog distillation task at Blog Track 2009. The system adopts a two-stage strategy in faceted blog distillation task. In the first stage, the system carries out a basic topic relevance retrieval to get the top k blogs for each query. In the second stage, different models are designed to judge the facets and ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Blog track <ref type="bibr" coords="1,171.06,383.73,12.27,9.45" target="#b0">[1]</ref> had two tasks in the TREC 2009 and we participate in the faceted blog distillation task. This task involves locating blogs that contain relevant information about a given target topic, and judging the facet of each relevance blog.</p><p>The PRIS system is submitted by Pattern Recognition and Intelligent System Lab at Beijing University of Posts and Telecommunications.</p><p>This system adopts a two-stage strategy in faceted blog distillation. The goal of the blog distillation task, which is the baseline of the faceted blog distillation, is to find relevant blogs for specific topics. And the faceted blog distillation is used to explore the facets of the topic-relevant blogs. In order to achieve the in-depth blog distillation, a two-stage strategy is employed. In the first stage, the PA (Posts Average) algorithm is involved into the blog distillation. In PA algorithm, the relevance degree of the blog to the topic is decided by its posts' similarity scores. Besides, a Learning Query Expansion (LQE) algorithm is designed to improve the precision of topic-relevance retrieval. In the second stage, different facets are automatically identified by different models. There are three facet groups, which are opinionated vs. factual (o.f), personal vs official (p.o) and in-depth vs. shallow (i.s). For opinionated vs. factual, the o.f model combining Maximum Entropy <ref type="bibr" coords="1,173.21,617.73,12.32,9.45" target="#b1">[2]</ref> based classifiers is used to implement opinion polarity judging and ranking. The named entity recognition [3] is employed in p.o model. The boundary between in-depth and shallow is defined according to the document length in our i.s model. We use a criterion related to two factors. One factor is documents lengths. Because the lengths of in-depth documents are usually long, and the long documents are usually in-depth after we exclude those with a lot of spam information or only a small part of relevant content. However, it is difficult to clean these spam, at the same time, if we give more consideration on the length, these spam will take negative influence on in-depth analysis. The other factor is topic-relevance information which is important but usually neglected. We propose the L-Qtf (Length-Query term frequency) coefficient with considering these factors. In this coefficient, the relationship between the lengths and average length is involved to reduce the spam's influence. Meanwhile, the query term frequency is employed to present the relevant information. The in-depth analysis model with the L-Qtf coefficient is used in the retrieved blogs form the first step. Finally, for each facet, the retrieved top 100 blogs are submitted. The framework of the overall processing is shown in Figure <ref type="figure" coords="2,466.09,123.15,3.95,9.45" target="#fig_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. System Framework</head><p>In Section 2 and Section 3, we introduce the blog distillation algorithm and facets models respectively. In Section 4, the evaluation of the faceted blog distillation system is presented. Finally in Section 5, conclusions and comments on the future work are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Blog distillation</head><p>Our system contains two stages. In the first stage, the blog distillation, which is concerned with the search of blogs rather than blog posts and it is the baseline for the in-depth analysis, is performed to find the topic-relevant blogs. A blog's relevance degree and in-depth degree are evaluated by checking its containing posts. Traditional blog distillation approaches view the whole blog collection as a complete document <ref type="bibr" coords="2,261.43,450.75,11.19,9.45" target="#b2">[4]</ref>, which use Eq. ( <ref type="formula" coords="2,346.22,450.75,3.71,9.45" target="#formula_0">1</ref>), called Baseline A, to sum up each post's similarity score for the given topic query Q. The score is defined as the ranking function of the topic-relevant blogs.</p><formula xml:id="formula_0" coords="2,173.10,496.07,281.69,25.11">( , ) ( , ) 1 n Score blog Q Score post Q x i i = ∑ = (<label>1</label></formula><formula xml:id="formula_1" coords="2,454.79,505.35,4.08,9.45">)</formula><p>where n is the number of the posts in blog x, and the similarity scores of posts are supplied by Indri <ref type="bibr" coords="2,113.05,544.35,11.18,9.45" target="#b3">[5]</ref>. But this algorithm isn't sufficiently reasonable. Let's look at a failure example using Eq. ( <ref type="formula" coords="2,483.83,559.95,4.09,9.45" target="#formula_0">1</ref>) by considering the following two feeds. Feed X contains 10 posts and all are relevant to a given query, feed Y contains 100 posts including the 10 of X. According to <ref type="bibr" coords="2,362.49,591.15,11.19,9.45" target="#b0">(1)</ref>, feed X should have the same similarity score as feed Y for the given query if the other 90 posts of feed Y are totally irrelevant. However, considering the obviously different relevancies (100% vs 10%), we should judge that feed X is much more relevant to the given query than feed Y. To address this problem, we take the average value of the sum of posts' similarity scores as a new ranking function as Eq. ( <ref type="formula" coords="2,450.67,653.55,3.73,9.45">2</ref>). </p><formula xml:id="formula_2" coords="2,175.08,670.49,291.35,35.15">n Score post Q i i Score blog Q x n ∑ = = (2)</formula><p>We call Eq. (2) Posts Average (PA) as well as Baseline B. In our system, query expansion is added automatically to improve the retrieval accuracy. From the aspect of topic understanding, the Learning Query Expansion (LQE) model based on semi-machine learning method is designed.</p><p>The topic given by the Blog track is as shown in <ref type="bibr" coords="3,308.90,91.95,11.19,9.45" target="#b0">[1]</ref>. The topic is composed of 5 parts: number, title which is the original query, description, facet and narrative. With considering the Indri query language, expansion words and their weighting, we introduce two kinds of features into the LQE model. These two kinds of features are extracted from the sentences in the topic description and topic narrative which supply training data and testing data. One kind is syntactic feature which contains part of speech (POS) tags and syntax analysis tags. The other kind is distance feature which is a novel feature in the query expansion. Firstly, we define an ordered center word list which contains the words regarded as the center word of a sentence, such as "not", "relevant", "find", and so on. Each sentence has one center word at most. The words "not" and "no" have the highest priority to be the center word in one sentence, while the "find" has the lowest. Secondly, in a sentence, we calculate the distance from each word to the center word and this distance value is deemed as the distance feature for the word.</p><p>We trained LQE model based on CRFs with the manual Blog track 2006 queries which were expanded based on the human common sense and comprehension. After the classifier was trained, it was applied to the whole Blog track 2009's queries for query expansion which contains both expansion words and their weightings with Indri query language. One of the final query examples is as the following: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Opinionated vs. Factual Model</head><p>This model contains two stages. In the first stage, the sentiment analysis model <ref type="bibr" coords="3,438.45,514.17,12.27,9.45" target="#b1">[2]</ref> is applied to the posters in the baseline feeds to generate opinion judgments. The analysis model we used is the same as the model we used in the Blog Track 2008 <ref type="bibr" coords="3,307.92,545.37,11.17,9.45" target="#b4">[6]</ref>. In the second stage, the facet of the feed is judged based on the poster sentiment analysis results. For the factual facet, two rules are defined: 1. If objective posters occupy more than 50% in a feed, this feed is deemed as factual. 2. If the number of posters in a feed is more than 150, the feed is regarded as factual.</p><p>For the opinionated, we calculate the feed by this function:</p><formula xml:id="formula_3" coords="3,196.14,623.81,262.73,34.88">neg pos neg pos o N N N N S + - = | | (3)</formula><p>N pos is the number of the positive posters, while N neg is the negative posters number. The lager the opinionated score S o is, the higher level of opinionatedness has.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Personal vs. Official Model</head><p>We find that the difference between personal blogs and official blogs is the frequency of the same organization named entity. First, organization entity type is identified by Stanford Named Entity Recognizer <ref type="bibr" coords="4,170.84,76.35,11.19,9.45">[7]</ref>. Because there are a lot of advertisements in the blog web pages, and the advertisements contain too many organization named entities, it is necessary to detect the spam organization entities. We regard one organization entity as spam entity if it appears in the same position of each poster in the same feed. An organization entity list without spam can be got orderly for each poster. Then according to the position in the list, the weight of each entity is given as the following.</p><formula xml:id="formula_4" coords="4,183.12,170.09,275.75,69.52">⎪ ⎪ ⎪ ⎩ ⎪ ⎪ ⎪ ⎨ ⎧ &lt;≤ &lt; ≤ &lt; ≤ &lt; = L p L L p L L p w 3 2 2 . 0 3 2 3 8 . 0 3 0 0 . 1<label>(4)</label></formula><p>P is the position of the entity in the list. L represents the length of the list. W is the weight given to the entity. Then, in a feed, each entity's weight WF is calculated using the Eq. ( <ref type="formula" coords="4,422.69,263.55,3.72,9.45" target="#formula_5">5</ref>).</p><formula xml:id="formula_5" coords="4,206.40,284.23,252.47,30.03">∑ = = n i j i j w WF 1 ,<label>(5)</label></formula><p>In this function, n is the number of the relevance posters in the feed j. w i can be got from the Eq. ( <ref type="formula" coords="4,93.73,341.55,3.73,9.45" target="#formula_4">4</ref>). Finally, the score of the feed is measured using the Eq. ( <ref type="formula" coords="4,343.60,341.55,3.73,9.45">6</ref>),</p><formula xml:id="formula_6" coords="4,180.72,362.40,278.15,29.66">2 1 × + = max max p n lg n lg n WF S (6)</formula><p>n is defined the same as the Eq. ( <ref type="formula" coords="4,234.55,403.95,3.73,9.45" target="#formula_5">5</ref>). n max is the maximum posters number in the whole relevance feeds to a topic. WF max is the maximum entity value in the feed j. We think larger S p corresponds to higher possibility that feed might be an official one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">In-depth vs. Shallow Model</head><p>In the second stage, we use the in-depth analysis model. The facet of a blog is judged based on all the posts in it. What kind of posts is considered as in-depth? In common sense, an in-depth post expresses author's opinion on the given topic in detail with a long length in ideal situation. For minimizing the impact of spam contents, the length with average length is considered as a feature of the in-depth degree. But only using the length feature isn't sufficient, to confirm the relevance degree, considering the query term frequency in the post is also necessary. We combine the posts' length and the query term frequency in the following L-Qtf coefficient:</p><formula xml:id="formula_7" coords="4,164.82,596.32,289.25,29.85">t Q D 1 + ln (1 + ln ( )) = (1 -) + tf L -Q tf qtf d l s s a v d l ∈ ∩ × ∑<label>(7)</label></formula><p>where tf and qtf represent the query term frequency in the post and in the query respectively. is the post length and is the average-length of the whole relevant posts for the topic. is a parameter which is set as 0.2 in our experiments. L-Qtf coefficient is a kind of pivoted weighting coefficient <ref type="bibr" coords="4,137.37,684.75,11.17,9.45" target="#b5">[8]</ref>.</p><p>Based on the whole posts of the topic-relevant blogs given by the blog distillation, the posts are ranking according to the in-depth coefficient. In this ranking list, the top 45% of topic-relevant posts are considered as the in-depth, while the last 45% posts are the shallow. The in-depth degree (ID) of each blog is calculated according to the relationship between the in-depth posts and shallow posts as Eq. ( <ref type="formula" coords="5,183.05,76.41,3.72,9.45" target="#formula_4">4</ref>), where , is 1 if post i is in-depth, and 0 otherwise. Similarly, , is 1 if post i is shallow. The larger the ID is, the deeper the feed is. Otherwise, the shallower the feed is. </p><formula xml:id="formula_8" coords="5,142.50,125.58,319.91,35.79">1 ( , ) ( , ) ( , ) n n i i i i i x in post Q sh post Q S ID blog Q n = = - = = ∑ ∑<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Combination model</head><p>In the task, the feed should be judged not only the topic relevance but also the facets. By considering these two points, the combination model is adopted.</p><formula xml:id="formula_9" coords="5,132.30,217.72,330.11,17.32">) feed ( S ) ( ) Q , log b ( Score S j x j × - + × = μ μ 1 (9)</formula><p>S j is the final confidence value of the feed j. Facet means the facet's value from different model. S(feed j ) is got from function 1. µ is a weighting parameter distributing in the interval [0, 1]. µ is a parameter balancing the scores of facet level and similarity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we present a system for the faceted blog distillation, propose a novel L-Qtf coefficient for the in-depth analysis and make a discussion on what kinds of factors may influence the in-depth analysis. The experiments prove that the topic-relevance information is an important factor for in-depth analysis, while the length factor should be considered but not too much.</p><p>Our system still has some weak points. The results of opinionated blog distillation and personal blog distillation are not good. In the future research, more factors influencing the faceted analysis should be explored and key words representing the faceted meanings should also be taken into consideration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,226.38,144.30,2.77,4.98"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,158.58,76.22,278.08,154.70"><head>Table 3 . Different in-depth coefficients for ID</head><label>3</label><figDesc></figDesc><table coords="7,158.58,92.92,278.08,138.01"><row><cell></cell><cell></cell><cell>A</cell><cell>B</cell><cell>C</cell><cell>D</cell></row><row><cell>%MAP</cell><cell></cell><cell cols="3">0.78 2.38 4.17</cell><cell>4.45</cell></row><row><cell cols="2">% MAP improvement over Baseline</cell><cell>0</cell><cell cols="2">+1.6 +3.39 +3.67</cell></row><row><cell cols="5">Table 4．In-depth blog distillation results</cell></row><row><cell cols="5">L-Qtf Fused with coefficient B Fused with L-Qtf</cell></row><row><cell>MAP 0.0445</cell><cell>0.1955</cell><cell></cell><cell></cell><cell>0.2614</cell></row><row><cell>P@10 0.0500</cell><cell>0.1167</cell><cell></cell><cell></cell><cell>0.2278</cell></row><row><cell>bPref 0.0475</cell><cell>0.2050</cell><cell></cell><cell></cell><cell>0.2461</cell></row><row><cell>rPrec 0.0380</cell><cell>0.2290</cell><cell></cell><cell></cell><cell>0.2620</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4">Submission and Evaluation Results</head><p>We submitted 2 runs. The difference between the 2 runs is query. The first run prisb's query is without query expansion, the words in the title field are only used. The second run pris's query is expanded by <rs type="funder">LQE</rs>. The evaluation results of the 2 submitted runs are listed in the following Table 1. From these data, it proves that the LQE is effective.</p><p>We have done some experiments after this track. In this section, we present empirical evaluation results to assess the effectiveness of our technique for the in-depth blog distillation. In particular, we conducted experiments on the permalink HTML pages of Blog08 [1] Collection to show that our algorithm is effective. We selected Indri as our information retrieval platform and preprocessed the data collection. A post is very similar to a web page which contains many HTML tags and scripts, so we parsed the HTML pages and reserved the texts in the same way dealing with a web page. In addition, we applied some rules for abbreviations, for example "I'm" was processed to "I am". And we stemmed the texts by <rs type="funder">Indri</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Blog distillation</head><p>To evaluate the performance of Baseline A, Baseline B and the LQE model on blog distillation, we made an experiment with 39 queries given by Blog track 2009, among them 18 queries were used for in-depth blog distillation.</p><p>The evaluation results are illustrated in Table <ref type="table" coords="5,296.22,591.15,3.95,9.45">2</ref>. We employed four performance metrics: mean average precision (MAP), P@10, binary preference (bPref) and rPrec. It is obvious that Baseline B outperforms Baseline A on MAP, bPref and rPrec. From the results, we can see that PA algorithm is an effective algorithm for blog distillation, and that the results with query expansion outperform the baseline results in four performance metrics. We believe that the LQE model is an effective model for query expansion and information retrieval if the query is given as in Blog track task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">In-depth analysis model</head><p>Experiments with in-depth analysis coefficients were done on the retrieved blogs by Baseline B with LQE. The in-depth blogs were ranked according to their ID values. The top 100 blogs with positive ID values were evaluated. To find which factors are more efficient for in-depth analysis, we used four kinds of in-depth coefficients for comparison: (1) Length (baseline, coefficient A), ( <ref type="formula" coords="6,379.06,395.91,4.07,9.45">2</ref>)</p><p>), and (4) L-Qtf (coefficient D). Table <ref type="table" coords="6,126.90,427.05,5.25,9.45">3</ref> shows MAP of each ID's result, comparing with the Length coefficient. From Table <ref type="table" coords="6,497.51,427.05,3.94,9.45">3</ref>, we can see that the results of coefficient B and coefficient C significantly outperform coefficient A. The improvements by coefficients B and C over A are found to be statistically significant for MAP with large margin, but the results from C and D are not significantly different. The L-Qtf (coefficient D) achieves the best MAP, because it considers the average lengths of the posts that counteract parts of the impact produced by spam information. At the same time, query term frequency in L-Qtf, added as a factor for in-depth analysis, considers the relevance to the topic. From the results of the four coefficients, it can be concluded that the length isn't the most important factor for in-depth analysis, because there are a lot of spam information which are difficult to be detected in the blog posts. The comparative results from the coefficients B and D indicate that the lengths can't be seen as a single factor in the in-depth analysis. When the length without average length is considered as a single factor, spam is involved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">In-depth blog distillation system</head><p>We conducted experiments to examine the effect of our in-depth blog distillation system, and show the results in Table <ref type="table" coords="6,198.67,661.05,3.92,9.45">4</ref>. We see that the combination model outperforms the model only using the in-depth analysis. While the combination model with the coefficient B was the best run in Trec 2009 in-depth blog distillation <ref type="bibr" coords="6,221.68,692.25,11.19,9.45" target="#b3">[5]</ref>, from Table <ref type="table" coords="6,289.35,692.25,5.25,9.45">4</ref> the improvement over the Trec 2009 best run for the combination model with the coefficient D is large, showing more than 6% increase of MAP. This improvement also proves that it is not necessary to give high weighting on the length. With considering the performance of the combination model, we think that the topic-relevance information is a kind of much more important factor for in-depth analysis.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,104.72,440.28,400.58,9.02;7,103.50,455.88,86.21,9.02" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,278.01,440.28,164.35,9.02">Overview of the TREC-2009 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Soboroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,106.67,471.48,398.73,9.02;7,103.50,487.08,369.94,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,219.09,471.48,286.31,9.02;7,103.50,487.08,73.97,9.02">Constructing maximum entropy language models for movie review subjective analysis</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,183.86,487.08,180.18,9.02">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="239" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,106.77,518.28,398.45,9.02;7,103.50,533.88,274.34,9.02" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,152.05,518.28,134.64,9.02;7,400.08,518.28,105.14,9.02;7,103.50,533.88,35.27,9.02">Distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<editor>W. B. Croft</editor>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="page" from="127" to="150" />
			<pubPlace>Norwell</pubPlace>
		</imprint>
	</monogr>
	<note>Advances in Information Retrieval</note>
</biblStruct>

<biblStruct coords="7,104.80,549.48,400.52,9.02;7,103.50,565.08,143.87,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,310.50,549.48,144.23,9.02">Indri at TREC 2004: Terabyte track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,473.08,549.48,32.25,9.02;7,103.50,565.08,114.36,9.02">Proc. of the 2004 Text Retrieval Conf</title>
		<meeting>of the 2004 Text Retrieval Conf</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,104.30,580.68,400.94,9.02;7,103.50,596.28,22.53,9.02" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,250.11,580.68,128.46,9.02">PRIS in TREC 2008 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,104.61,627.48,400.75,9.02;7,103.50,643.08,402.00,9.02;7,103.50,658.68,58.35,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,244.60,627.48,157.68,9.02">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,409.31,627.48,96.04,9.02;7,103.50,643.08,398.41,9.02">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
