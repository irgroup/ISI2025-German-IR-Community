<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,120.06,148.86,362.88,15.15;1,235.81,170.78,131.39,15.15">York University at TREC 2009: Relevance Feedback Track</title>
				<funder ref="#_hfvxf6R">
					<orgName type="full">NSERC of Canada</orgName>
				</funder>
				<funder ref="#_SSCDjFY">
					<orgName type="full">Doctoral Fund of Ministry of Education of China</orgName>
				</funder>
				<funder ref="#_yzRc3mk">
					<orgName type="full">National High Tech Research and Development Plan of China</orgName>
				</funder>
				<funder ref="#_cGw3H67 #_RyQMKXp #_HK27NPc">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,186.31,204.67,40.96,8.74"><forename type="first">Zheng</forename><surname>Ye</surname></persName>
							<email>yezheng@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Managment Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.16,204.67,63.65,8.74"><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
							<email>jhuang@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Managment Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.36,204.67,32.25,8.74"><forename type="first">Ben</forename><surname>He</surname></persName>
							<email>benhe@yorku.ca</email>
						</author>
						<author>
							<persName coords="1,361.16,204.67,51.07,8.74"><forename type="first">Hongfei</forename><surname>Lin</surname></persName>
							<email>hflin@dlut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Managment Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,120.06,148.86,362.88,15.15;1,235.81,170.78,131.39,15.15">York University at TREC 2009: Relevance Feedback Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">56276D73678A8D7957B422218628E9DF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>Measurement, Performance, Experimentation Weighting Model, Relevance Feedback, DFR, BM25, Context</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a series of experiments conducted in our participation in the Relevance Feedback Track. We evaluate two traditional weighting models (BM25 and DFR) for the phase 1 task, which are widely used in text retrieval domain. We also evaluate a statistics-based feedback model and our proposed feedback model for the phase 2 task. Currently, we are waiting for the overview paper to facilitate further analyses.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe the work done by members at York University in Canada and Dalian University of Technology in China for the TREC 2009 Relevance Feedback Track. In particular, we present a series of experiments conducted in Relevance Feedback Track 2009. This is the first year that we participate in this track. Our experiments mainly focus on the following aspects: (1) how the traditional retrieval models perform in identifying useful feedback documents; (2) how different relevance feedback models perform under Rocchio's relevance feedback framework <ref type="bibr" coords="1,450.20,612.59,30.88,8.74" target="#b8">[Roc71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Relevance Feedback Track</head><p>In Information Retrieval (IR), Relevance feedback (RB) is a process that IR systems use the feedback information provided by users to optimize the retrieval results. Relevance Feedback has been one of the most important successes of IR research for the past decades. Feedback information can be from the real users, or from implicit evidence. Relevance feedback has been proven to be effective in both cases <ref type="bibr" coords="1,188.63,706.69,27.99,8.74" target="#b2">[BR08]</ref>.</p><p>However, there has been comparatively few research advances in RF in recent years. There is no general agreement of what the best RF approach is, or what relative benefits and costs of the various approaches are <ref type="bibr" coords="1,192.04,742.56,30.87,8.74" target="#b3">[Buc08]</ref>. Relevance Feedback Track is held under this circumstance. Last year's (2008) TREC Relevance Feedback (RF) Track just concentrated on the RF algorithm itself: Given a topic and a set of judged documents for that topic, how does a system take advantage of the judgments in order to return more documents that will be useful to the user. This year (2009), the track evaluates how well systems can find good documents to be judged, as well as the improvement due to the RF algorithm. In the first phase, each group will identify a small number of documents (e.g. 5 per run) for which they wish relevance judgments. In the second phase, the organizer would like to evaluate how well an algorithm is coupled with documents obtained in different ways, for example, documents ranked by the probability of relevance or docs which represent different aspects of relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Collection</head><p>In this year's RF track, a new test collection, ClueWeb09, is used. It contains approximately 1,000,000,000 Web pages. This is the first real attempt to have a test collection be representative of the entire Web. For teams that do not have enough computation power, they can choose B subset of ClueWeb09. Note that the B subset is still quite large -over 3 times the size of the Terabyte GOV2 collection. More detailed information about ClueWeb09 can be found in 1 .</p><p>The remainder of this paper is organized as follows. In Section 2, we describe the weighting models used in Phase 1. In Section 3, we present two feedback models used in phase 2. In Section 4, we present our official results in TREC 2009 Relevance Feedback Track. In Section 5, we conclude the paper with a look at the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Weighting Models in Phase 1</head><p>There are several choices for identifying documents for the feedback algorithms. For example, we can provide feedback documents according to the following ways:</p><p>1. the probability of relevance of documents to a query, 2. documents likely to draw the line between relevant and non-relevant, 3. documents representing different aspects of relevance, 4. documents representing different interpretations of a possibly ambiguous topic statement, 5. documents which may not be relevant in themselves, but may offer good general background (and thus expansion terms) in the area of the topic <ref type="bibr" coords="2,375.57,527.88,30.87,8.74" target="#b4">[Buc09]</ref>.</p><p>In our experiments, we provide the feedback documents according to the probability of relevance. In particular, we explore two traditional weighting models, BM25 [HBGH + 96] and DFR <ref type="bibr" coords="2,90.00,571.72,34.14,8.74" target="#b0">[Ama03]</ref>, which perform well on a large number of IR collection. The corresponding weighting functions are as follows:</p><formula xml:id="formula_0" coords="2,114.91,603.60,398.09,55.83">BM25 ω = (k 1 + 1) * tf k 1 * ((1 -b) + b * dl/avdl) + tf * log N -n + 0.5 n + 0.5 * (k 3 + 1 ) * qtf k 3 + qtf<label>(1)</label></formula><p>DFR</p><formula xml:id="formula_1" coords="2,101.09,689.56,176.78,8.44">1 http://boston.lti.cs.cmu.edu/Data/clueweb09/ ω = T F * qtf * N ORM * log e ( N + 1 n exp ) T F = tf * log 2 (1 + c * avdl/dl) N ORM = (tf + 1)/(df * (T F + 1)) n exp = idf * (1 -e -f ) f = qtf /df (2)</formula><p>where w is the weight of a query term, N is the number of indexed documents in the collection, n is the number of documents containing the term, tf is within-document term frequency, qtf is within-query term frequency, dl is the length of the document, avdl is the average document length, nq is the number of query terms, the k i s are tuning constants (which depend on the database and possibly on the nature of the queries and are empirically determined).</p><p>In our experiments, the values of k 1 , k 3 and b in the BM25 function are empirically set to be 1.2, 8 and 0.35 respectively, which has proven to perform well on a large number of collections. For the DFR weighting, its parameter c is default to 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Methods for Phase 2</head><p>In this section, we first present Rocchio's Query Expansion method and a DFR-based weighting model. Then, we describe the proposed term weighting model for query expansion under Rocchio's framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Rocchio Query expansion</head><p>Rocchio's classical algorithm <ref type="bibr" coords="3,231.88,414.25,32.52,8.74" target="#b8">[Roc71]</ref> provides a general framework for implementing relevance feedback. It models a way of incorporating relevance feedback information into the vector space model. In particular, it takes a set of documents for feedback. Candidate terms in this set of documents are ranked according to the following formula:</p><formula xml:id="formula_2" coords="3,206.72,469.82,306.28,26.88">Q 1 = α * Q 0 + β * rel D i |D i | -γ * nonrel D i |D i |<label>(3)</label></formula><p>where Q 0 and Q 1 represent the initial and first iteration query vectors, D i represents document weight vectors, |D i | is the corresponding Euclidian vector length, and α, β, γ are tuning constants. Many other relevance feedback techniques and algorithms have been developed, mostly derived under Rocchios framework. For example, a popular and successful relevance feedback algorithm was proposed by Robertson <ref type="bibr" coords="3,215.73,555.23,33.35,8.74" target="#b7">[Rob90]</ref> while developing the Okapi system. Okapis relevance feedback algorithm is similar to Rocchios, while using a different term weighting strategy called the Robertson Selection Value (RSV) weights <ref type="bibr" coords="3,278.99,579.14,31.60,8.74" target="#b7">[Rob90]</ref>. More recently, Amati proposed a relevance feedback algorithm in his Divergence from Randomness (DFR) framework <ref type="bibr" coords="3,422.47,591.10,34.14,8.74" target="#b0">[Ama03]</ref>, which similarly follows Rocchios algorithm. However, in Amatis method, term weights are assigned by a DFR term weighting model, such as the Kullback-Leibler divergence (KLD) <ref type="bibr" coords="3,424.49,615.01,49.07,8.74" target="#b5">[CdMRB01]</ref>.</p><p>In our experiments, we explore two weighting schemes under Rocchio's framework, and the parameters α, β, γ are empirically set to be 1, 0.4 and 0.15 respectively. In addition, the number of expansion terms, exp term, is empirically set to be 35. In the following subsection, we describe the algorithms in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bose-Einstein distribution Weighting Scheme</head><p>The first term weighting model used in our experiments is DFR-based weighting model described in <ref type="bibr" coords="3,138.12,721.06,34.14,8.74" target="#b0">[Ama03]</ref>. The basic idea of these term weighting models for query expansion is to measure the divergence of a term's distribution in a pseudo relevance set from its distribution in the whole collection. The higher this divergence is, the more likely the term is related to the query topic.</p><p>We use the Kullback-Leibler (KL) divergence model in this set of experiments. Using the KL model, the weight of a term t in the exp doc top-ranked documents is given by: w(t) = P (t|D) log 2 P (t|D)</p><formula xml:id="formula_3" coords="4,328.19,175.05,184.81,15.57">P (t|C)<label>(4)</label></formula><p>where P (t|D) = c(t,D) c(D) is the generation probability of term t from D, the set of feedback documents. c(t, D) is the frequency of t in D, and c(D) is the count of words in D. P (t|C) = c(t,C) c(C) is the collection model. c(t, C) is the frequency of t in collection C, and c(C) is the count of words in the whole collection C. exp doc usually ranges from 3 to 10 [Ama03]. Another parameter involved in the query expansion mechanism is exp term, the number of terms extracted from the exp doc top-ranked documents. exp term is usually larger than exp doc [Ama03].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">A Context Sensitive Weighting Scheme</head><p>In traditional QE weighting models, the expansion terms are selected only by their statistics in the top k documents and the whole collection. In the process of the selection of expansion terms, the context informations are always ignored, for example, the domain of users' interest, knowledge about the query's subject. Zhai et al. <ref type="bibr" coords="4,262.70,346.53,44.28,8.74" target="#b1">[BNCB07]</ref> studied using query-specific contexts to boost IR performance. It showed that context factors can bring significant performance improvements in terms of MAP. In this paper, we propose a context sensitive weighting to select the expansion terms. In particular, the candidate terms are ranked according to the following formula: P (t|C) ∝ P (t)P (C|t) = P (t)P (c 1 , . . . , c m |t)</p><formula xml:id="formula_4" coords="4,239.51,413.67,273.49,30.32">= P (t) m i=1 P (c i |t) (5)</formula><p>where C represents the context for a query and it consists of a number of feature contexts. A feature context c i represents a certain kind of context, such as click information and users' background. The probability P (t) can be interpreted as the prior probability. It means that how likely it is that candidate term t can be selected as an expansion term without taking into account any context information. The probability P (c|t) can be interpreted as: given the expansion candidate term t, how likely it is that the feature context c i will be observed. This probability is estimated according to the type of context. In this paper, we define a co-occurrence feature context, which means the probability that a candidate expansion co-occurs with the query. We only explore the co-occurrence feature context in this RF track.</p><p>Co-occurrence with the query terms J. Xu et al. <ref type="bibr" coords="4,147.06,587.67,29.89,8.74" target="#b9">[XC00]</ref> proposed an PRF approach, called "local context analysis", in which it is suggested that useful expansion terms tend to co-occur with the original query. In this paper, we define a co-occurrence context, and the corresponding probability P (c i |t) can be interpreted as, given a candidate term t, how likely it is that t will co-occur with the original query. In this paper, we propose to use the term weighting function in <ref type="bibr" coords="4,302.18,635.49,29.89,8.74" target="#b9">[XC00]</ref> to estimate the probability P (c i |t), which is shown as follows:</p><formula xml:id="formula_5" coords="4,160.29,677.73,352.71,48.84">P (c|t i ) ∝ g(t i , Q) = wiinQ (σ + co degress(t i , w i )) (6) co degress(t i , w i ) = log 10 ( d in S tf (t i , d)tf (w i , d))idf (t i )/log 10 (n) (<label>7</label></formula><formula xml:id="formula_6" coords="4,508.76,706.43,4.24,8.74">)</formula><p>where S is the set of documents for PRF, Q is the original query. σ is a smoothing parameter, and we empirically set it to be 0.001 in our experiments.</p><p>We preprocess the collection by removing all the HTML tags. Words in the collection are segmented by spaces and punctuations. Porter stemming and stopword removal are conducted in both indexing and searching processes. Beside these simple procedures, no further technologies have been used. In the following, we present our official experimental results.</p><p>Table <ref type="table" coords="5,133.38,181.66,4.98,8.74" target="#tab_0">1</ref> shows our official runs for phase 1 task. The values in parentheses are the counts of worse or better when the run is used as input for RF for each evaluation measure. The final score is the ratio of better/(better + worse). For phase 1 runs, we did not lowercase the words for indexing, which is a kind of mistake. So the results do not reflect the real performance of BM25 and DFR.  <ref type="table" coords="5,133.07,333.59,4.98,8.74" target="#tab_1">2</ref> shows our official runs for phase 2 task. Three runs marked by superscript "c" are obtained by using our proposed weighting model described in Section 3.3. Since these three runs are obtained based on the un-lowercase index, they also do not reflect the real effectiveness of the proposed context-based feedback approach. In Table <ref type="table" coords="5,323.31,369.46,3.87,8.74" target="#tab_1">2</ref>, we provide the corrected results in terms of "stapMAP". For the other runs, the feedback weighting function used is the Bose-Einstein distribution weighting scheme under Rocchio's framework. For the base run "YUIR.base", we use the top 5 documents and top 35 terms to conduct PRF.</p><p>From Table <ref type="table" coords="5,161.38,417.28,3.87,8.74" target="#tab_1">2</ref>, in general, the performance of feedback based on the judged documents is significantly better than that based on pseudo relevance documents. Although feedback from users requires additional efforts, it brings great benefits for improving the retrieval performance. For the relevance feedback in phase 2, the performance is not determined by the results in phase 1 in our experiments. From Table <ref type="table" coords="5,244.81,465.10,3.87,8.74" target="#tab_1">2</ref>, we do not see any correlation between the performance in phase 2 and the performance in phase 1, which is different from that in PRF. This indicates that the judged irrelevant documents (top ranked in phase 1) are beneficial to feedback. Actually, we also conduct experiments of relevance feedback based solely on the relevant documents, the performance of which is not as good as that based on all the judged documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we present our participation in Relevance Feedback Track 2009. First, we evaluate two traditional weighting models (BM25 and DFR) for phase 1 task, which are widely used in text retrieval domain. Second, we evaluate a statistical-based weighting model and our proposed weighting model for phase 2 task.</p><p>In future work, we will work on the following two directions. First, we plan to explore different strategies for identifying documents for relevance feedback. Second, we plan to incorporate more feature contexts into our proposed weighting model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,104.94,257.69,332.44,84.64"><head>Table 1 :</head><label>1</label><figDesc>Phase 1 results</figDesc><table coords="5,104.94,281.62,332.44,60.71"><row><cell>Run</cell><cell>emap</cell><cell>mapA</cell><cell>P10A</cell><cell>stAP</cell><cell>score</cell></row><row><cell>BM25 (YUIR.1)</cell><cell>(4, 9)</cell><cell cols="4">(14, 0) (14, 0) (5, 8) 0.3148</cell></row><row><cell cols="6">DFR (YUIR.2) (18, 13) (0, 0) (22, 9) (22, 9) 0.3548</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,182.13,543.06,232.09,131.50"><head>Table 2 :</head><label>2</label><figDesc>Phase 2 results</figDesc><table coords="5,182.13,567.00,232.09,107.57"><row><cell>Run</cell><cell>MAP</cell><cell cols="2">emap stAP (corrected)</cell></row><row><cell>YUIR.base</cell><cell></cell><cell></cell><cell>0.2113</cell></row><row><cell cols="3">YUIR.CMIC.1 c 0.0780 0.0367</cell><cell>0.1546 (0.2585)</cell></row><row><cell cols="3">YUIR.UCSC.2 c 0.0650 0.0392</cell><cell>0.1586 (0.2540)</cell></row><row><cell cols="3">YUIR.YUIR.2 c 0.0301 0.0322</cell><cell>0.1386 (0.2103)</cell></row><row><cell>YUIR.FDU.1</cell><cell cols="2">0.0258 0.0511</cell><cell>0.2471</cell></row><row><cell>YUIR.ugTr.1</cell><cell cols="2">0.0481 0.0523</cell><cell>0.2460</cell></row><row><cell cols="3">YUIR.UMas.2 0.0426 0.0536</cell><cell>0.2638</cell></row><row><cell cols="3">YUIR.YUIR.1 0.0320 0.0474</cell><cell>0.2403</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>6 Acknowledgements This research is jointly supported by <rs type="funder">NSERC of Canada</rs>, the <rs type="grantName">Early Researcher/Premier's Research Excellence Award</rs>, <rs type="funder">Natural Science Foundation of China</rs> (No. <rs type="grantNumber">60373095</rs>, <rs type="grantNumber">60673039</rs> and <rs type="grantNumber">60973068</rs>), the <rs type="funder">National High Tech Research and Development Plan of China</rs> (<rs type="grantNumber">2006AA01Z151</rs>) and <rs type="funder">Doctoral Fund of Ministry of Education of China</rs> (No.<rs type="grantNumber">20090041110002</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hfvxf6R">
					<orgName type="grant-name">Early Researcher/Premier&apos;s Research Excellence Award</orgName>
				</org>
				<org type="funding" xml:id="_cGw3H67">
					<idno type="grant-number">60373095</idno>
				</org>
				<org type="funding" xml:id="_RyQMKXp">
					<idno type="grant-number">60673039</idno>
				</org>
				<org type="funding" xml:id="_HK27NPc">
					<idno type="grant-number">60973068</idno>
				</org>
				<org type="funding" xml:id="_yzRc3mk">
					<idno type="grant-number">2006AA01Z151</idno>
				</org>
				<org type="funding" xml:id="_SSCDjFY">
					<idno type="grant-number">20090041110002</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,146.91,305.24,366.09,8.74;6,146.91,317.19,366.09,8.74;6,146.91,329.15,22.69,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,197.68,305.24,315.32,8.74;6,146.91,317.19,48.93,8.74">Probabilistic models for information retrieval based on divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="6,146.91,349.08,366.09,8.74;6,146.91,361.03,366.09,8.74;6,146.91,372.99,366.09,8.74;6,146.91,384.94,180.19,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,421.11,349.08,91.89,8.74;6,146.91,361.03,100.24,8.74">Using query contexts in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugues</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,267.82,361.03,245.18,8.74;6,146.91,372.99,335.56,8.74">SIGIR &apos;07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,404.87,366.09,8.74;6,146.91,416.82,340.46,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,329.97,404.87,183.03,8.74">Relevance feedback track overview: Trec</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,186.48,416.82,270.26,8.74">Proceedings of the 17th Text Retrieval Conference TREC 2008</title>
		<meeting>the 17th Text Retrieval Conference TREC 2008</meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,436.75,366.08,8.74;6,146.91,448.70,235.97,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,215.28,436.75,214.20,8.74">Proposal for a trec 2008 relevance feedback track</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,451.42,436.75,61.58,8.74;6,146.91,448.70,205.33,8.74">Proceedings of the 17th Text Retrieval Conference TREC 2008</title>
		<meeting>the 17th Text Retrieval Conference TREC 2008</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,468.63,366.09,8.74;6,146.91,480.58,197.27,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,216.25,468.63,172.50,8.74">Trec 2009 relevance feedback guidelines</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,411.63,468.63,101.38,8.74;6,146.91,480.58,144.55,8.74">Proceedings of the 18th Text Retrieval Conference TREC</title>
		<meeting>the 18th Text Retrieval Conference TREC</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,500.51,366.09,8.74;6,146.91,512.46,366.09,8.74;6,146.91,524.42,101.13,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,499.99,500.51,13.01,8.74;6,146.91,512.46,275.08,8.74">An information-theoretic approach to automatic query expansion</title>
		<author>
			<persName coords=""><forename type="first">Claudio</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renato</forename><surname>De Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brigitte</forename><surname>Bigi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,436.08,512.46,76.92,8.74;6,146.91,524.42,19.70,8.74">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,544.34,32.59,8.74;6,122.59,542.77,6.12,6.12;6,129.20,544.34,383.80,8.74;6,146.91,556.30,366.08,8.74;6,146.91,568.25,158.93,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,307.75,556.30,66.01,8.74">Okapi at trec-5</title>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><surname>Hbgh + 96]</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangji</forename><surname>Gatford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">W</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Williams</surname></persName>
		</author>
		<idno>TREC) TREC-5 Proceedings</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,396.65,556.30,116.34,8.74">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,588.18,366.09,8.74;6,146.91,600.13,22.69,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,228.26,588.18,169.91,8.74">On term selection for query expansion</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,410.09,588.18,30.76,8.74">J. Doc</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="364" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,620.06,344.28,8.74" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,199.76,620.06,192.04,8.74">Relevance Feedback in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.91,639.98,366.09,8.74;6,146.91,651.94,311.41,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,287.47,639.98,225.53,8.74;6,146.91,651.94,114.45,8.74">Improving the effectiveness of information retrieval with local context analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,269.88,651.94,97.04,8.74">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
