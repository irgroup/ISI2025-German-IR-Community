<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.42,68.55,341.17,12.29">Microsoft Research Asia at the Web Track of TREC 2009</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,78.38,112.91,69.92,10.51;1,148.31,111.04,1.41,7.44"><forename type="first">Zhicheng</forename><surname>Dou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,160.21,112.91,49.83,10.51;1,210.04,111.04,1.88,7.44"><forename type="first">Kun</forename><surname>Chen</surname></persName>
							<email>cs.kunchen@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.47,112.91,63.30,10.51;1,284.78,111.04,1.41,7.44"><forename type="first">Ruihua</forename><surname>Song</surname></persName>
							<email>rsong@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.68,112.91,59.97,10.51;1,356.65,111.04,1.41,7.44"><forename type="first">Yunxiao</forename><surname>Ma</surname></persName>
							<email>yunxiaom@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,368.55,112.91,63.31,10.51;1,431.87,111.04,1.41,7.44"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<email>shumings@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,465.22,112.91,63.67,10.51;1,528.89,111.04,1.41,7.44"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
							<email>jrwen@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,176.71,127.35,94.00,10.26"><forename type="first">Microsoft</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiongtong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.42,68.55,341.17,12.29">Microsoft Research Asia at the Web Track of TREC 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E6F561FF83FBC89F28BC0D0178305D7C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2009, we participate in the Web track, and focus on the diversity task. We propose to diversify web search results by first mining subtopics, and then rank results based on mined subtopics. We propose a model to diversify search results by considering both relevance of documents and richness of mined subtopics. Our experimental results show that the model improves diversity of search results in terms of α-NDCG, and combining subtopics from multiple data sources helps further improve result diversity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We propose mining subtopics to diversify search results. A subtopic approximates to a piece of information or user intent covered by a query. Different from the previous work that focuses on one source, e.g., search logs or page content, we argue that mining subtopics from multiple complementary sources can help better understand user intents. We preliminarily mine subtopics from the following data sources: <ref type="bibr" coords="1,400.42,330.99,11.62,8.76" target="#b0">(1)</ref> anchor texts that represent the opinions of web annotators; (2) clusters of search results that show the perspective of page content; (3) websites of search results that reflect web information organization.</p><p>We propose a search result diversification model that diversifies search results based on our mined subtopics. As shown in Figure <ref type="figure" coords="1,159.07,378.81,3.74,8.76">1</ref>, given a query, we first mine subtopics together with their importance. We then combine the original query and the subtopics to retrieve documents for ranking. We diversify retrieved search results by considering both their relevance and their subtopic richness. A greedy algorithm is employed to iteratively select the next best document from the remaining documents.</p><p>We design experiments and submit official runs to answer the following questions: (1) can our search result diversification algorithms improve diversity of search results? (2) can subtopics from multiple data sources help predict user intents and further improve search result diversity? (3) can diversification algorithms improve or harm adhoc ranking effectiveness?</p><p>The remaining parts of the report are organized as follows. In Section 2, we briefly introduce our retrieval platform. We then introduce our methods of mining subtopics in Section 3, and propose a search result diversification model in Section 4. We report our experimental results in Section 5, and then conclude our work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Retrieval Platform</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">WebStudio</head><p>We use the WebStudio 1 , an experimental search system for facilitating large-scale, end-to-end search experiments, to index and retrieve documents. Using the WebStudio, users can easily do search experiments, by implementing pre-defined interfaces or inheriting existing implementations. Multiple users can run different search experiments simultaneously. As an end-to-end search system, the WebStudio also provides search interfaces, via which we can input queries and get search results.</p><p>We use 40 machines, each of which has 4 CPU's, 16GB memory, and 4 1T IDE disks, to deploy an instance of WebStudio. We index all English pages in the ClueWeb09 dataset (about 500M pages) using this WebStudio instance. Note that web pages are distributed into these machines. There are about 12.5M web pages on each machine. It takes about 20 hours for each machine to index the data. Before indexing the data, anchor texts are</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anchor texts</head><p>Query logs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results for subtopics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results for subtopics</head><p>Search result diversification model Sub-topic 1 Sub-topic 2 ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-topic mining</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-topic mining</head><p>Sub-topic 1 Sub-topic 2 ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get search results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results for original query</head><p>Diversified search results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dimension 1 Dimension 2</head><p>Figure <ref type="figure" coords="2,150.93,410.12,4.15,9.44">1</ref>. Framework of search result diversification based on two types of subtopics extracted from source pages and merged into the pages they link to. In query phase, each query request from the client will be sent to all machines via an aggregator. Each machine will process the query and retrieve top results separately. The aggregator then collects and aggregates all results and returns them to the client. For the ClueWeb09 dataset, it takes averagely about 5 seconds to get top 1,000 results for a query using WebStudio.</p><p>WebStudio is a flexible indexing and ranking platform. It is designed to support different types of source data and index structures. Besides web pages, we index all unique anchor texts of the ClueWeb09 dataset using the WebStudio. We treat each anchor text as a document, and build statistics of anchor text (such as the number of links with this anchor text) as attributes of the document. Given a query, we can search and rank all related anchor texts which include one or more query terms. Other similar data, such as query logs, can be processed in the same manner. Figure <ref type="figure" coords="2,137.26,552.87,4.98,8.76" target="#fig_1">2</ref> shows two snapshots for search results of the query "yahoo". The left shows general web page results, and the right shows anchor text results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Ranking function</head><p>As introduced in Section 1, our primary goal is to develop search result diversification methods, but not to tune an optimal general search function. We simply use a ranking function named MSRA2000, which was proposed and used in TREC 2004 <ref type="bibr" coords="2,158.41,637.95,10.58,8.76" target="#b0">[1]</ref>. It combines augmented BM25 scores of four different fields including title, body, URL, and anchor. The augmented BM25 function considers the proximity between query term occurrences.</p><p>We do not use PageRank in MSRA2000 for TREC 2009. Instead we use an aggregated weight of incoming links which is calculated based on the number of incoming links and sources sites.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">subtopic Mining</head><p>Usually different types of sources contain somehow different information on user intentions. We assume that better understanding of user intentions can be achieved by combining the subtopics from these complementary sources. In this paper, we mine subtopics from three different data sources, including anchor texts, search result clusters, and web site of search results. Other data sources, such as query logs and dictionaries, are also good data sources that show different dimensions of diversity. We will investigate these data sources in future work. Given a source, we associate a weight with each mined subtopic on how important the subtopic is. In the following sections, we will briefly introduce subtopics we have mined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Anchor texts</head><p>Anchor texts created by web designers provide descriptions of target documents. They are usually short and descriptive, and share similar characteristics with web queries. We use the WebStudio system to index all unique anchor texts together with some statistics about their popularity, and use the following ranking function to retrieve top 10 anchor texts related to a given query:</p><formula xml:id="formula_0" coords="3,97.88,658.51,442.12,9.30">f (q, c) = NumOfSites + log(NumOfLinks -NumOfSites + 1) + 10 * QueryLengh/AnchorLength (1)</formula><p>In the above ranking function, NumOfLinks means the number of links that contain the anchor text c, and NumOfSites means the number of unique source sites. AnchorLength is the number of terms contained in the anchor text. An anchor text will be ranked higher if it is more popular and it contains less words. Note that here we assume a default AND operator between query terms. This means that all query terms must appear in retrieved anchor texts.</p><p>We simply assume that each anchor text can stand for an unique subtopic contained in the query. Based on (1), we use the following formula to calculate importance of a subtopic. We assume that an anchor text has an average weight, namely 0.5, if it has about 50 unique sources sites.</p><formula xml:id="formula_1" coords="4,251.74,145.98,106.83,22.49">w c = 1 1 + e -(f (q,c)-50)/50</formula><p>For each subtopic, we treat it as a new query and get its top 100 results using the WebStudio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Search results clusters</head><p>Search result clustering is one of the ways to solve the problem of query ambiguity. There has been much work on this area. By using clustering algorithm, documents with similar content and key phrases are grouped together. We use the search result clustering algorithm introduced in <ref type="bibr" coords="4,324.13,246.40,11.62,8.76" target="#b1">[2]</ref> to group top 200 original search results into 10 clusters (i.e., subtopics) based on key phrases in documents. We treat each cluster as a subtopic, and assume that a subtopic is more important if: (1) the cluster is ranked higher than other clusters; (2) the cluster contains a document which is ranked higher in original ranking list. We use the following equation to calculate importance of a subtopic:</p><formula xml:id="formula_2" coords="4,176.39,290.45,259.22,30.51">w c = 0.5 × ( 10 -ClusterRank + 1 10 + 1.0 HighestRankInCluster )</formula><p>Here ClusterRank is rank of the cluster among all clusters, and HighestRankInCluster is the original rank of the document which has the highest rank within the cluster. Note that we also include the "Other" cluster which includes documents that are not grouped into any other clusters.</p><p>We do not need to retrieve search results for subtopics because we can directly get documents in each subtopic. In each cluster, the order of documents in the original query is reserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Sites of search results</head><p>As web pages from the same web site are sometimes providing similar information, it is natural to rank results from multiple different web sites, instead of the same site, in top results. It is quite easy to accomplish this in our framework: just treating each web site as a subtopic.</p><p>We count the number of results for each site which appears in the top 200 results, and use the following equation to calculate its importance:</p><formula xml:id="formula_3" coords="4,240.21,480.48,129.89,24.05">w c = 1 1 + e -(NumOfResults-2)</formula><p>Here NumOfResults is the number of results in the site. We assume that the more results a site includes, the more important the site is. We assume that a site gets a medium score 0.5 when there are two results from this site.</p><p>We also do not need to retrieve search results for site-based subtopics because we have already retrieved the documents in an initial search. Ranking order of documents in original search are kept in subtopics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Search Result Diversification</head><p>In this section, we propose a search result diversification algorithm which uses explicit subtopics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Algorithm</head><p>To better illustrate our algorithm, we first define the following symbols:</p><p>• R: candidate search results. It may be the set of all documents, or the set of document to be re-ranked (coming from the original query or subtopics); • s(q, d): the relevance score of document d for query q; • r(q, d): the importance (0 to 1) of document d for query q according to original relevance;</p><p>• r(q c , d): the importance of document d for subtopic q c ; • C: the set of all diversity categories; • C ∈ C: one specific diversity category (e.g., anchor text); We assume that a good ranking should cover as many relevant subtopics as possible. As it is a NP problem to find such a ranking, we employ a greedy algorithm to iteratively select the best document from the remaining documents. Given R as the set of document to be ranked, and suppose S is the set of documents which have already been selected, we use the following equation to select next best document from remaining documents:</p><formula xml:id="formula_4" coords="5,206.75,163.21,329.37,17.29">d |S|+1 = arg max d∈R\S [αr(q, d) + ℜ C∈C v(d, S, C)] (<label>2</label></formula><formula xml:id="formula_5" coords="5,536.12,163.41,3.87,8.76">)</formula><p>here α is a parameter which controls the importance of original relevance and the diversity of ranking. ℜ is a operator which is used to combine multiple dimensions of subtopics. It can be ∑ , ∏ , max , or min . v(d, S, C) is the importance score of document d in terms of subtopic definition C given a set of document S already selected, and</p><formula xml:id="formula_6" coords="5,227.83,226.94,156.35,30.20">v(d, S, C) = ∑ c∈C w c • ϕ(c, S) • r(q c , d)</formula><p>w c is the weight of subtopic c in subtopic definition C for query. ϕ(c, S) is the current importance of subtopic c after documents set S have been selected. We assume that for a subtopic, if some documents have already been selected for it in previous steps, its importance should be reduced. By using this method, we prompt search result diversity based on mined explicit subtopics. Suppose that documents are independent in terms of importance to one subtopic, we use the following function, which is similar to that in <ref type="bibr" coords="5,350.49,312.50,10.58,8.76" target="#b2">[3]</ref>, to calculate ϕ(c, S):</p><formula xml:id="formula_7" coords="5,204.65,321.22,335.35,31.55">ϕ(c, S) = { 1 if S = {}; ∏ ds∈S [1 -r (q c , d s )] else.<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Parameters</head><p>We have the following parameter settings in our search result diversification algorithm.</p><p>• α. Similar to the MMR algorithm <ref type="bibr" coords="5,230.44,402.26,10.58,8.76" target="#b3">[4]</ref>, parameter α in Equation 2 decides a tradeoff between original document relevance and diversity on subtopics. Documents will be ranked totally based on subtopic diversity when α equals to 0, while it will be equivalent to original ranking when α is very large. • r(q, d) and r(q c , d). These two functions decide how important the documents are for the original queries and corresponding subtopics. We use the same setting for these two functions in a run. Suppose we already have a rank list for query q, the following functions can be used to decide the importance of document d for query q:</p><p>-OriScore: r(q, d) = s(q, d). This just uses the original relevance score s(q, d) . Please note that s(q, d) should be normalized to [0, 1]; The problem is that the distribution of original relevance score is decided by original ranking function, and different ranking functions may generate different distributions of ranking scores. -Sigmoid. Suppose s(q, d) has been normalized to [0,1]. By using the sigmoid function, we can get a new distribution of document importance.</p><p>r(q, d) = 1 1 + e -(s(q,d)-0.5) * m -Rank. When s(q, d) is unknown, we can directly use the rank of document: r(q, d) = 1.0 rank(q,d) . r(q, d) will decrease rapidly with the increasing of document rank.</p><formula xml:id="formula_8" coords="5,99.49,614.04,143.33,15.69">-RankSqrt. r(q, d) = 1 √ rank(q,d)</formula><p>. It is similar to the previous one, but is less sensitive to the rank of document.</p><p>-LinearRank. r(q, d) = N -rank(q,di)+1 N . Here N is the total number of results.</p><p>• Results to be diversified. For some subtopics, such as subtopics mined from anchor texts, we can get additional search results for subtopics. These results may not appear in results of the original query. It may help discover new relevant documents for the original query if these results are used, but it may also increase the danger of more irrelevant results being ranked higher.</p><p>• Combination of diversity dimensions ℜ. We can use different functions, such as</p><formula xml:id="formula_9" coords="6,435.17,63.04,26.01,16.88">∑ , ∏</formula><p>, max , or min , to combine subtopics from different diversity dimensions. For example, a document needs to be novel enough in each diversity dimension if function min is used, while it just needs to be novel in one diversity dimension if function max is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>We design several experiments to investigate whether our proposed algorithm can improve diversity of search results. We try several combinations of mined subtopics which are described in the following list (note that MSRA is abbreviation of Microsoft Research Asia). New documents from subtopics are included. As we do not have judgment data to tune ranking functions and select parameters, we just simply select the following settings for our official run submissions:</p><p>• α = 1.3, which means that the original relevance is slightly more important than subtopic richness; • ℜ =</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∑</head><p>. We assume that a document should have a reasonable overall subtopic diversity score across all diversity dimensions.</p><p>• Use RankSqrt to calculate document importance to the original query and subtopics, i.e., r(q, d) = 1 √ rank(q,d) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Diversity task</head><p>As we are allowed to submit up to three runs, we submitted MSRABASE, MSRACS, and MSRAACSF to the diversity task. We evaluate the other runs using the tool provided by TREC after the judgments are released. As there may be some new documents that are not judged in these runs, the results for new runs might be worse than correct results.</p><p>Table <ref type="table" coords="6,107.34,472.44,4.98,8.76">1</ref> includes the results of all runs. This table shows that:</p><p>• All runs with result diversification outperform the baseline run MSRABASE in terms of α-NDCG. They also outperform the baseline on the top five results in terms of IA-P (intention aware precision). • The method MSRAACSF performs the best among three submitted runs in terms of α-NDCG@10, the primary measurement used in the diversity task. Note that MSRAACSF is also the best run in the diversity task. After experimenting with different settings of the combination parameter α, we find that MSRAACSF is consistently better than other methods. This means that combining multiple types of subtopics can further improve result diversity over any sole use of one type of them. • The anchor text based methods, MSRAAF and MSRAAT, perform the worst result among all diversification methods. This may caused by the following reasons. Firstly, this method needs additional search results for subtopics. It heavily depends on whether the baseline ranking function can retrieve good results for these subtopics. We do find some bad results are ranked to top for some sub-queries, and these results may be ranked higher in final ranking. Secondly, our mined anchor texts (subtopics) may not fully matched with those given by judgments. For example, anchor text-based subtopics "castle defender" and "public defender" are not listed in the judgments. • For runs which use anchor text based subtopics, the differences are not significant when new documents from subtopics are used (runs with T) or not (runs with F). This may by caused by: (1) anchor texts have been used in the original ranking function;</p><p>(2) we assign a high weight to original ranking. For new documents, their ranking scores will be assumed to be 0, which may stop them being ranked to top.</p><p>Table <ref type="table" coords="7,111.44,66.10,4.15,9.44">1</ref>. Diversity task results. Runs with * are submitted to the diversity task. Note that MSRAACSF performs the best α-NDCG@10 results among all offical runs in the diversity task run alpha-ndcg@5 alpha-ndcg@10 alpha-ndcg@20 IA-P@5 IA-P@10 IA-P@20 MSRABASE* </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Adhoc task</head><p>We also submitted three runs, including MSRANORM, MSRAAF, and MSRAC, to the adhoc task to investigate whether diversification algorithms can help improve general ranking. Here MSRANORM is also a baseline ranking function which does not consider search result diversity. It is just slightly different from MSRABASE with same different settings of term proximity on anchor field. Note that all other runs submitted to adhoc task are generated based on MSRANORM instead of MSRABASE. Results are shown in Table <ref type="table" coords="7,390.41,395.95,3.74,8.76" target="#tab_0">2</ref>. This table shows:</p><p>• MSRAC outperforms the baseline model in terms of map, R prec, P@10, and P@20, while MSRAACSF and MSRAACST outperform the baseline model in terms of P@5 and recip rank. This means that MSRAACSF and MSRAACST can help improve top results, while MSRAC can help improve overall ranking. • Compared with Table <ref type="table" coords="7,183.91,445.76,3.74,8.76">1</ref>, we find evaluation results based on two different types of judgments and evaluation metrics are not totally consistent. For example, MSRAS performs the best in diversity task in terms of IA-P@10, while it performs worse than baseline model in adhoc task in terms of P@10. This may caused by the following reasons. Firstly, judgments are made by different annotators. Secondly, judgments may bias towards different types of judgment tools and methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Parameters</head><p>Table <ref type="table" coords="7,107.99,544.79,4.98,8.76">3</ref> shows performance of MSRAACSF and MSRAACST when different methods of combining multiple subtopic sources are used. This tables shows that the ∑ combination method performs the best, and max also shows good results in terms of α-NDCG@10 and IA-P@10.</p><p>Table <ref type="table" coords="7,106.33,580.65,4.98,8.76" target="#tab_1">4</ref> shows performance of MSRAACSF and MSRAACST when different types of function r(q, d) and r(q c , d) are used. This tables shows that our selected function, namely RankSqrt, performs consistently well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In the Web track of TREC 2009, we proposed to mine subtopics from multiple perspectives to diversify search results for a query. We think that mining subtopics across multiple dimensions can help better understand user intents. We proposed an algorithm which combines multiple types of subtopics to diversity search results. Our experimental results show that proposed search result diversification algorithms improve diversity of search results in terms of α-NDCG, and multiple types of subtopics do help predict user intents and further improve result Table <ref type="table" coords="8,103.83,66.10,4.15,9.44">3</ref>. Performance of MSRAACSF with different methods for combining multiple diversity dimensions runid alpha-ndcg@5 alpha-ndcg@10 alpha-ndcg@20 IA-P@5 IA-P@10 IA-P@20 MSRAACSFProduct 0. diversity. Furthermore, we found that different types of judgments in the diversity and the adhoc tasks (considering diversity or not) yield inconsistent evaluation results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.00,412.20,468.02,9.44;3,72.00,424.15,302.00,9.44;3,78.24,71.10,224.57,316.38"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Web page and anchor text search results for query "yahoo" retrieved from the WebStudio system. Note that Figure (b) shows top anchor texts related to query "yahoo".</figDesc><graphic coords="3,78.24,71.10,224.57,316.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,81.96,192.45,345.38,8.76;6,81.96,204.40,315.97,8.76;6,81.96,216.36,308.79,8.76;6,81.96,228.31,458.06,8.76;6,81.96,240.27,458.06,8.76;6,81.96,252.22,439.11,8.76;6,81.96,264.18,458.06,8.76;6,92.02,276.13,201.36,8.76;6,81.96,288.09,458.06,8.76"><head>•</head><label></label><figDesc>MSRABASE -Baseline, a general ranking function without results diversification • MSRAC -Search result diversification based on search result (C)lustering. • MSRAS -Search result diversification based on (S)ites of search results. • MSRAAF -Search result diversification based on anchor texts. New documents from subtopics are not included. • MSRAAT -Search result diversification based on (A)nchor texts. New documents from subtopics are included. • MSRACS -Search result diversification based on search result (C)lustering and (S)ites of search results. • MSRAACSF -Search result diversification based on (A)nchor texts, (C)lusters, and (S)ites of search results. New documents from subtopics are not included. • MSRAACST -Search result diversification based on (A)nchor texts, (C)lusters, and (S)ites of search results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,128.74,112.24,348.32,184.94"><head>Table 2 .</head><label>2</label><figDesc>Adhoc task results. Runs with * are submitted to adhoc task</figDesc><table coords="7,128.74,112.24,348.32,184.94"><row><cell></cell><cell>0.244</cell><cell cols="2">0.286</cell><cell>0.328</cell><cell cols="2">0.116</cell><cell>0.105</cell><cell>0.098</cell></row><row><cell>MSRAC</cell><cell>0.248</cell><cell cols="2">0.293</cell><cell>0.334</cell><cell cols="2">0.117</cell><cell>0.109</cell><cell>0.099</cell></row><row><cell>MSRAS</cell><cell>0.285</cell><cell>0.31</cell><cell></cell><cell>0.351</cell><cell></cell><cell>0.13</cell><cell>0.117</cell><cell>0.101</cell></row><row><cell>MSRACS*</cell><cell>0.281</cell><cell>0.31</cell><cell></cell><cell>0.357</cell><cell cols="2">0.126</cell><cell>0.112</cell><cell>0.106</cell></row><row><cell>MSRAAF</cell><cell>0.261</cell><cell cols="2">0.295</cell><cell>0.334</cell><cell cols="2">0.121</cell><cell>0.103</cell><cell>0.091</cell></row><row><cell>MSRAAT</cell><cell>0.262</cell><cell cols="2">0.288</cell><cell>0.33</cell><cell cols="2">0.124</cell><cell>0.099</cell><cell>0.09</cell></row><row><cell>MSRAACSF*</cell><cell>0.281</cell><cell cols="2">0.316</cell><cell>0.365</cell><cell cols="2">0.127</cell><cell>0.112</cell><cell>0.108</cell></row><row><cell>MSRAACST</cell><cell>0.287</cell><cell cols="2">0.318</cell><cell>0.366</cell><cell></cell><cell>0.13</cell><cell>0.113</cell><cell>0.108</cell></row><row><cell>runid</cell><cell>map</cell><cell>gmmap</cell><cell>Rprec</cell><cell>bpref</cell><cell>reciprank</cell><cell>P5</cell><cell>P10</cell><cell>P20</cell></row><row><cell cols="2">MSRANORM* 0.0832</cell><cell>0.036</cell><cell cols="2">0.1324 0.2227</cell><cell>0.5824</cell><cell>0.4</cell><cell>0.37</cell><cell>0.312</cell></row><row><cell>MSRAC*</cell><cell>0.0867</cell><cell>0.0372</cell><cell>0.1439</cell><cell>0.2276</cell><cell>0.5893</cell><cell>0.428</cell><cell>0.4</cell><cell>0.328</cell></row><row><cell>MSRAS</cell><cell>0.0756</cell><cell>0.0317</cell><cell cols="2">0.1274 0.2237</cell><cell>0.5917</cell><cell>0.42</cell><cell cols="2">0.356 0.262</cell></row><row><cell>MSRACS</cell><cell>0.0784</cell><cell>0.0332</cell><cell>0.1297</cell><cell>0.2243</cell><cell>0.5947</cell><cell>0.44</cell><cell cols="2">0.374 0.285</cell></row><row><cell>MSRAAF*</cell><cell>0.0829</cell><cell>0.0363</cell><cell>0.136</cell><cell>0.2185</cell><cell>0.6201</cell><cell cols="3">0.404 0.354 0.321</cell></row><row><cell>MSRAAT</cell><cell>0.0808</cell><cell>0.0354</cell><cell cols="2">0.1354 0.2183</cell><cell>0.6056</cell><cell>0.4</cell><cell cols="2">0.348 0.313</cell></row><row><cell>MSRAACSF</cell><cell>0.088</cell><cell>0.0357</cell><cell>0.1342</cell><cell>0.2287</cell><cell>0.6721</cell><cell>0.448</cell><cell cols="2">0.378 0.319</cell></row><row><cell>MSRAACST</cell><cell>0.0828</cell><cell>0.0352</cell><cell>0.1346</cell><cell>0.2232</cell><cell>0.6518</cell><cell>0.448</cell><cell>0.38</cell><cell>0.322</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,95.08,100.29,421.84,188.33"><head>Table 4 .</head><label>4</label><figDesc>Performance of MSRAACSF and MSRAACST with different types of r(q, d) and r(q c , d)</figDesc><table coords="8,111.70,100.29,388.59,188.33"><row><cell></cell><cell>259</cell><cell>0.294</cell><cell>0.338</cell><cell>0.12</cell><cell>0.105</cell><cell>0.099</cell></row><row><cell>MSRAACSFMax</cell><cell>0.26</cell><cell>0.318</cell><cell>0.355</cell><cell>0.115</cell><cell>0.122</cell><cell>0.105</cell></row><row><cell>MSRAACSFMin</cell><cell>0.259</cell><cell>0.3</cell><cell>0.337</cell><cell>0.12</cell><cell>0.108</cell><cell>0.099</cell></row><row><cell>MSRAACSF</cell><cell>0.281</cell><cell>0.316</cell><cell>0.365</cell><cell>0.127</cell><cell>0.112</cell><cell>0.108</cell></row><row><cell>MSRAACSTProduct</cell><cell>0.256</cell><cell>0.29</cell><cell>0.333</cell><cell>0.121</cell><cell>0.103</cell><cell>0.096</cell></row><row><cell>MSRAACSTMax</cell><cell>0.264</cell><cell>0.32</cell><cell>0.356</cell><cell>0.117</cell><cell>0.122</cell><cell>0.105</cell></row><row><cell>MSRAACSTMin</cell><cell>0.263</cell><cell>0.296</cell><cell>0.335</cell><cell>0.124</cell><cell>0.106</cell><cell>0.097</cell></row><row><cell>MSRAACST</cell><cell>0.287</cell><cell>0.318</cell><cell>0.366</cell><cell>0.13</cell><cell>0.113</cell><cell>0.108</cell></row><row><cell>runid</cell><cell cols="6">alpha-ndcg@5 alpha-ndcg@10 alpha-ndcg@20 IA-P@5 IA-P@10 IA-P@20</cell></row><row><cell>MSRAACSFRank</cell><cell>0.278</cell><cell>0.31</cell><cell>0.356</cell><cell>0.127</cell><cell>0.11</cell><cell>0.1</cell></row><row><cell>MSRAACSFLinearRank</cell><cell>0.286</cell><cell>0.311</cell><cell>0.36</cell><cell>0.11</cell><cell>0.093</cell><cell>0.094</cell></row><row><cell>MSRAACSFSigmoid</cell><cell>0.288</cell><cell>0.315</cell><cell>0.37</cell><cell>0.112</cell><cell>0.097</cell><cell>0.1</cell></row><row><cell>MSRAACSF</cell><cell>0.281</cell><cell>0.316</cell><cell>0.365</cell><cell>0.127</cell><cell>0.112</cell><cell>0.108</cell></row><row><cell>MSRAACSTRank</cell><cell>0.275</cell><cell>0.311</cell><cell>0.356</cell><cell>0.127</cell><cell>0.11</cell><cell>0.1</cell></row><row><cell>MSRAACSTLinearRank</cell><cell>0.27</cell><cell>0.293</cell><cell>0.346</cell><cell>0.108</cell><cell>0.09</cell><cell>0.093</cell></row><row><cell>MSRAACSTSigmoid</cell><cell>0.277</cell><cell>0.303</cell><cell>0.362</cell><cell>0.113</cell><cell>0.096</cell><cell>0.1</cell></row><row><cell>MSRAACST</cell><cell>0.287</cell><cell>0.318</cell><cell>0.366</cell><cell>0.13</cell><cell>0.113</cell><cell>0.108</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,87.43,379.08,452.55,7.88;8,87.44,389.04,308.09,7.88" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,455.02,379.08,84.96,7.88;8,87.44,389.04,160.78,7.88">Microsoft research asia at web track and terabyte track of trec 2004</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,269.32,389.13,98.86,7.69">Proceedings of TREC 2004</title>
		<meeting>TREC 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,87.43,408.97,452.57,7.88;8,87.44,418.93,452.57,7.88;8,87.44,428.89,137.45,7.88" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,293.02,408.97,139.25,7.88">Learning to cluster web search results</title>
		<author>
			<persName coords=""><forename type="first">H.-J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q.-C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.97,409.06,88.03,7.69;8,87.44,419.02,402.69,7.69">SIGIR &apos;04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="210" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,87.43,448.82,452.56,7.88;8,87.44,458.78,444.79,7.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,302.34,448.82,98.25,7.88">Diversifying search results</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gollapudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Halverson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ieong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,421.62,448.91,118.37,7.69;8,87.44,458.87,265.14,7.69">WSDM &apos;09: Proceedings of the Second ACM International Conference on Web Search and Data Mining</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="5" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,87.43,478.71,452.55,7.88;8,87.44,488.67,336.72,7.88" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,213.71,478.71,326.27,7.88;8,87.44,488.67,36.36,7.88">The use of mmr, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,155.74,488.76,190.51,7.69">Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
