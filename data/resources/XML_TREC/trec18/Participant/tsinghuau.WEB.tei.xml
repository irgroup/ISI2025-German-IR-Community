<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,71.30,82.88,452.29,13.50;1,210.29,114.10,169.97,13.50;1,380.35,110.91,4.74,8.53">THUIR at TREC 2009 Web Track: finding relevant and diverse results for large scale Web Search 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,75.62,138.73,23.90,9.50"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,106.20,138.73,28.36,9.50"><forename type="first">F</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName coords="1,142.06,138.73,35.55,9.50"><forename type="first">Q</forename><forename type="middle">L</forename><surname>Xing</surname></persName>
						</author>
						<author>
							<persName coords="1,184.99,138.73,36.56,9.50"><forename type="first">J</forename><forename type="middle">W</forename><surname>Miao</surname></persName>
						</author>
						<author>
							<persName coords="1,229.04,138.73,31.15,9.50"><forename type="first">Y</forename><forename type="middle">F</forename><surname>Xue</surname></persName>
						</author>
						<author>
							<persName coords="1,267.90,138.73,23.69,9.50"><forename type="first">T</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName coords="1,299.09,138.73,29.46,9.50"><forename type="first">B</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName coords="1,336.16,138.73,34.23,9.50"><forename type="first">R</forename><forename type="middle">W</forename><surname>Cen</surname></persName>
						</author>
						<author>
							<persName coords="1,377.80,138.73,30.65,9.50"><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName coords="1,415.35,138.73,36.62,9.50"><forename type="first">M</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,459.52,138.73,25.40,9.50"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName coords="1,491.31,138.73,28.34,9.50"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">State Key Lab of Intelligent Technology &amp; Systems</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Tsinghua National Laboratory for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>10084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,71.30,82.88,452.29,13.50;1,210.29,114.10,169.97,13.50;1,380.35,110.91,4.74,8.53">THUIR at TREC 2009 Web Track: finding relevant and diverse results for large scale Web Search 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1D8909A702A744FD400E6EE9E573EF40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is the 8th year that IR group of Tsinghua University (THUIR) participates in TREC. This year we focus on Web track, which contains two tasks, namely ad hoc and diversity. On ad hoc task, we improved the efficiency of our distributed retrieval system TMiner to handle terabytes of Web data. Then three studies have been done, namely page quality estimation, ranking feature analysis, and model comparison. On diversity task, we proposed several new approaches on searching strategy, user intention detection, and duplication elimination. To mine user"s intention, we proposed and compared two different strategies, namely "searching + content-based diversity" which is a kind of result clustering, and "user based diverse intention prediction + searching" which is in the branch of query expansion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>IR group of Tsinghua University (THUIR) participates in this year"s Web track. It"s also our 8 th year"s TREC experience.</p><p>On ad hoc task, we improved the efficiency of our distributed retrieval system TMiner to handle terabytes of Web data. Then three studies have been done, namely page quality estimation, ranking feature analysis, and model comparison. First, we propose several features for web page spam detection, including title, length, content compression ratio, keyword-based filtering, and PageRank features. The impacts of the features are observed. Then an effective algorithm has been proposed to filter spam pages. Second, we embedded different types of ranking features in our distributed retrieval system TMiner. One is link and web usage based page importance factors, such as PageRank, top sites based on website traffic, etc. Another is the usage of different content of the document, namely original page full text, and in-link anchor text. Third, we compare the effectiveness of different ranking models on searching with large scale data. One is the BM25-based probabilistic model, another is the improved probabilistic model with word-pair proximity by TMiner, and the last one is the probabilistic model by Lucene.</p><p>On diversity task, we proposed several new approaches on searching strategy, user intention detection, and duplication elimination. To mine user"s intention, we proposed and compared two different strategies, namely "searching + content-based diversity" which is a kind of result clustering, and "user based diverse intention prediction + searching" which is in the branch of query expansion. One is to automatically find the self organized topics of content by result clustering. In this strategy, the level and the granularity of the clusters is one of the key factors to consider. A hierarchical incremental online clustering algorithm is proposed for both effectiveness and efficiency. Furthermore, we also used a content analysis algorithm to extract the core part of the page. Then we made comparative study on the clustering result base on the extract content and the original full text. This is the strategy of "searching + content-based diversity". Another one is to predict the user"s intention before search. A good choice is to use user log which is hard to achieve. So an alternative choice is to use the external resource. We automatically submit each query to the commercial search engine, and collected the query suggestion and related search queries without any manual labeling. We assume that each new query represents one aspects of the potential user intention. Then each new query is taken as the expanded one and submitted to our retrieval system. To combine the multiple result lists, we implemented the diversity result selection algorithm, which selects two or three most relevant pages for each user intention based on the probability. To make a comparative research, we also generate a baseline study which is "search + duplicate elimination" and no efforts on finding diverse intentions. Both content-based and site-based duplicate elimination approaches are integrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Web page spam detection</head><p>On real world search task, web spam pages are considered as one of the dominant factors to hurt the search system performance. In our data cleansing work, 4 features were proposed, including title length, content length, content compression ratio and keyword-based filtering. To draw the threshold analysis, a small sample set, including 100 pages, is created according to the 4 features and manual annotation is made. Since this training set is not large enough, the parameters set in the final experiments might not be optimized. And further analysis will be made afterwards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title length:</head><p>One popular practice of creating spam pages is "title keyword stuffing" <ref type="bibr" coords="2,457.54,448.96,11.16,9.50" target="#b0">[1]</ref>. During the process of stuffing, the title of the web page is growing larger with lots of keywords which are not relevant to the content of the page. So that the page title will match much more queries and can be accessed by more users. To find this kind of pages, we made the statistics of the title length. But unfortunately, on the rough observing results, nearly half of the pages with long title are not spam, and even high-quality one. Hence this feature is not used in the final experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Content length:</head><p>The underlining assumption for this feature is that a page with little words may contain nothing but spam, or at least less useful information. But the result is not encouraging based on the initial analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Content compression ratio:</head><p>Repeating hot query words in the content is another popular way of SEO. Hence the content compression ratio (CCR, or the compressibility) <ref type="bibr" coords="2,364.39,616.98,12.28,9.50" target="#b0">[1]</ref> will be much more different than normal pages. The content compression ratio is calculated by the following Eq. 1.</p><p>CCR = content length (in terms of # of words) / # of vocabulary (Eq. 1) When the CCR is larger than θ, the page is taken as spam. According to the observation on the sampled page set, the threshold θ is set to 8.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keyword-based filtering:</head><p>Porn words" filtering is also one of the anti-spam techniques in real world search engines. A list of porn words was found from the internet <ref type="bibr" coords="2,319.75,716.61,11.16,9.50">[2]</ref>. When the numbers of the porn words in the page is larger than α, then the page is taken as the spam. In our experiments, the threshold is set to 16.</p><p>The spam filtering work is embedded into our ranking system, as shown in the following section 4.1. By this spam pages detection, 1873 pages have been filtered in retrieval results list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and system preparation 3.1 Training set construction</head><p>To tune the parameter of system and methods, we construct a small training set with 11 queries and corresponding answers. The query set is manually selected according to the "hot query list" of commercial searching engines, which are different from the queries used in Web track task. Then the answer set is constructed with the pooling technique. Documents from three different sources are gathered into the pooling set. First, we submitted these queries to our TMiner system retrieved on the full text of the ClueWeb dataset (the data of the Web track task), and gained the top 50 documents for each query. Then the same system with anchor text index of the ClueWeb is used to gain the top 50 documents for each query. To avoid overtraining, we collected the top 100 results of online Google search engine for each query, and kept the documents in the ClueWeb. Then 11 assessors were asked to annotate these queries, each of them was assigned two queries and each query was annotated by two persons. Hence the final training dataset is generated, which is used to tune all the parameter of our system and algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System preparation</head><p>We improved the efficiency of our distributed retrieval system TMiner to handle terabytes of Web data. 500 million web documents are divided into 138 barrels. Each barrel is considered as a unit node of the distributed system, which can index and retrieval independently. In the pre-processing step, the original html tags are removed, while user defined tags are added. These tags are used to label the different fields of the text, including title, Meta keyword, Meta description, bold, italic, sub header and anchor text. The anchor text is made by link analysis module. Not all the terms in the web page will be indexed. Firstly, 466 stopwords and all the punctuation except "-" are removed; secondly, terms whose length is greater than 25 and terms with digit whose length is greater than 4 are removed. Thus, much noise are Eliminated. For the mass data, stemming technique is not used. The filtered web text and anchor text are built into inverted file index. The positions in the text and field type of the term are recorded in the index item for each document. Each barrel manages the data independently; therefore, the global information such as global document frequency of terms and average document length need be calculated separately. The features of each document for spam detection such as title length, content compression rate, and keyword-based filtering, are all built into the index, as well as the document quality factor such as pagerank, which can help the retrieval. The size of each index is between 12GB and 17GB except for some especially small ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Ranking features and models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Improved probabilistic model in our TMiner system</head><p>In retrieval step, each barrel returns 1000 documents ranking according to the relativity to the query, and then the results of all the barrels are merged to generate the final document list. The traditional probabilistic modal is used to measure the relationship between the query and a document. Several additional techniques are recommended. We use "AND search" to the query, which require the retrieved document contain all the terms of the query. The conjoint terms in the query which co-occur in the document will enhance the relativity, which we call the word pair model <ref type="bibr" coords="3,158.90,731.61,12.28,9.50" target="#b1">[3]</ref> (shown as W wp in the Eq 2). Further, when a term occurs in a special field, a higher weight of the term is signed. As the pagerank and spam detection method added, finally the relevance between query Q and document D is computed as Eq 2. </p><formula xml:id="formula_0" coords="4,71.48,93.39,344.18,146.97">            spam I D Q I D PageRank W W D Q R wp BM         10 2 1 25 log ,                                     m i i i i i BM avgdl D b b k D q f k D q f q n q n N W 1 1 1 25 / 1 , 1 , 5 . 0 5 . 0 log , (Eq 2)                                        1 1 1 1 1 1 1 1 / 1 , 1 , 5 . 0 5 . 0 log m i i i i i i i i i wp avgdl D b b k D q q f k D q q f q q n q q n N W ,         k i i i field q f D q f 0 ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event</head><p>means that the document is not detected as spam by the spam detection module described in the section 2. N is the total number of documents, n(q) is the number of documents contain q, k 1 and b are experimental parameters of BM25 ranking, |D| is the length of document D, avgdl is the average document length, f (q,D) is the virtual term frequency of q in D which is the total count of q in every field multiplied by the corresponding field weight β, W wp is also gotten from traditional probabilistic modal with that conjoint terms considered as one term, α 1 and α 2 are the combination weights for word pair modal and pagerank.</p><p>After merging results of 138 barrels, the top 1000 documents are generated for ad hoc task. Parameters were tuned on the training set, by which we set α 1 = 0.2, α 2 = 0.8, double the weight of the term frequency on title field and meta field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Using Lucene BM25 package</head><p>We construct another retrieval system based on Lucene. Lucene uses VSM as its original ranking model. As the performance of VSM in Lucene is not so good as TMiner which used BM25 Model, we use a BM25 package for Lucene to improve the system. The package is written by Joaquí n Pé rez-Iglesias and has BM25 and BM25f implementation for Lucene Java <ref type="bibr" coords="4,259.97,524.94,11.16,9.50" target="#b2">[4]</ref>. To compare the system performance, most of the data preprocessing is the same as that of our improved probabilistic model with TMiner system, such as 138 data buckets, global DF (Document Frequency) calculation, multi-field extraction.</p><p>We search the queries in 8 different fields, namely content, anchor text, title, meta keywords, black, meta data, italics and headings. The anchor text field has a very large weight of 7, and title field and meta keywords field are also important to have the weight of 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Finding diverse information</head><p>We think that diversity may be explored in three levels: semantic diversity, topic diversity and service diversity. The semantic diversity in IR is also taken as the expression"s ambiguity problem. For example, when the user is querying about "windows", he might denote to the windows of the house (in architecture domain), or find the information of Microsoft Windows (in computer domain). Even if the user is searching for Microsoft Windows, he might need the topics of windows new version release, download, windows update, etc, which goes to the topic diversity. Furthermore, if the user"s intention is the windows update, he might expect the windows update service URL, or the FAQ for the problems for windows update, which leads to the different service homepage. It is called service diversity. The diversity of the user"s intention may include either of the three types of the diversity, or even all of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Diverse information finding strategy</head><p>To mine user"s intention, we should firstly know how many diverse intentions could be. We call it the intention targeting problem. We proposed and compared two different strategies One is "searching + diverse result clustering", which first finds the information that is relevant to the user"s need using similarity measure, and then clusters the information to generate the diverse topics. Another strategy is the "diverse intention prediction + searching", which first predicts the diverse intention of the user according to the user"s behavior or background knowledge, and then finds the relevant information with each topic.</p><p>The original retrieval results are got by our ad hoc search task, which is implemented with word pair model and improved probabilistic model with PageRank ranking on the full text combined with in-link anchors, and taken spam pages detection into consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Searching + diverse result clustering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Clustering algorithm</head><p>With "searching + content-based diversity" strategy, we try to automatically find the self organized topics of content by result clustering. In this strategy, a hierarchical incremental online clustering algorithm is used for both effectiveness and efficiency <ref type="bibr" coords="5,233.33,349.36,11.16,9.50" target="#b3">[5]</ref>. In this algorithm, a good way to compute similarity (distance) between every two documents is a critical factor for good results. In our method, the similarity of document d and d  is taken as following Eq 3: Clustering is constructed to get a new document when the similarity of any two documents is bigger than a predefined threshold. The same one of 225 was set as that in <ref type="bibr" coords="5,334.87,565.74,11.16,9.50" target="#b3">[5]</ref>. And then similarities related to this new document are refreshed in the distance matrix. Clusters are done until all similarities between any two documents are smaller than the predefined threshold.</p><formula xml:id="formula_1" coords="5,155.61,408.03,195.71,22.69">      ' ) , ( * ) , ( ) , (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Diverse result selection algorithm</head><p>After clustering, categories are obtained for a certain query. They are taken as the probable user intentions for this query, and then the improved diversifying search algorithm is adopted for people"s diversified search.</p><p>The original diversity calculation model of IA-SELECT algorithm proposed by Agrawal et al <ref type="bibr" coords="5,467.98,682.77,12.28,9.50" target="#b4">[6]</ref> is showed as follows:</p><formula xml:id="formula_2" coords="5,126.30,713.97,287.21,22.47">      c S d c q d V q c P q S P )) , | ( 1 ( 1 )( | ( ) | ( (Eq. 4)</formula><p>Where S is the final returned page list and q is a query dealt in this issue. P(c|q) stands for the probability of query q belonging to category c, and V(d|q,c) denotes the quality value of document d for query q when user"s intended category is c. And the task is to choose a set S so that P(S|q) reaches to its max value, which in details is the main work of <ref type="bibr" coords="6,196.11,107.53,11.18,9.50" target="#b4">[6]</ref>.</p><p>Then we made some modification in our experiment: First, we selected the top 1 document from each category by default, and made them the top |C| documents ordered by descending V(d|q,c),where |C| is the total number of categories. There are two reasons for this.</p><p>(1) We believe that top results should cover as much user intention as possible. But if one aspect of intention has a low proportion, saying P(c|q), IA-SELECT algorithm may not show any document of this intention in the front. (2) Some category"s top document may has a extra large value of V(d|q,c) than the other documents in the category. Once this top document is selected, it will cause a big penalty to the category. For example, the documents in the category whose top document has V(d|q,c)=1 even never get opportunity to be selected by making U(c|q,S)=0 once the top document is selected, according to IA-SELECT. Hence picking out top documents in each category is one way to smooth the penalty and avoid the noise. And by this way, it"s guaranteed that at least one page is chosen from every category. Furthermore, the remains are deciding the parameters in the equations introduced above. We get these values as follows:</p><formula xml:id="formula_3" coords="6,176.93,325.96,237.42,18.81">N N q c P c / ) | (  (Eq. 5)</formula><p>c N is the number of documents contained in class c after clustering, and N is the number of all the clustered documents.</p><formula xml:id="formula_4" coords="6,72.61,388.76,339.19,45.07">min max min ) , ( ) , | ( R R R d q R c q d V c    (Eq. 6) ) , ( c d q R</formula><p>is the score of document d in category c retrieved with query q . min R , max R stands for</p><p>)} , ( min{</p><formula xml:id="formula_5" coords="6,94.41,437.68,118.64,12.14">c d q R and )} , ( max{ c d q R</formula><p>respectively. Finally, although the algorithm showed above can deal with diversified intentions, more than two web pages may be chosen, which are both in the same site and the same clustered category. However, web pages from the same site and are also clustered into the same category, are more likely to be in the same subtopic. Hence domain-level duplicate elimination of the web page is performed. At last, all the documents chosen by the diversity algorithm are sorted depending on their original relevance ranking scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Web page content extraction</head><p>Besides the result clustering based on the original web pages, we also studied the clustering effect based on the extracted web page content. Hence a content analysis algorithm is used as preprocessing. In this process, the title and body of the web page are extracted, while other things, such as advertisements, content-related anchors (which we think is the description of the linked target page but not the current page), site navigations etc. are abandoned. This task is taken without any manual labeling, so noise and incorrect filtering occur. For example, if the title inside a page is set by script code rather than text, or the content is rather short with many pictures, our extracting tool cannot work effectively as expected.</p><p>Finally, experiments are done to make compares between these two methods (clustering based on the original web page, shown as method 1; and clustering based on extracted content, shown as method 2). Take the first query "obama family tree" for example, after clustering, 422 categories are left in the first method, and 460 categories in the second. By the way, the final results returned to users are 1000, so about 2.5 web pages should be chosen from every category on average. From these experiments, it"s found that for a certain query, documents laid in the first half of the returned list are almost the same with both methods, except few documents appear only in one list. But in the latter half, there exists many differences in both documents and their ranks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">More discuss on the clusters control</head><p>The following table shows the effectiveness by using different number of the clusters in our experiments. The results show that different control degree of the number of the clusters do not affect the result much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy</head><p>Selection alg. #Clusters alpha-nDCG@10 IA-P@10 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Diverse intention prediction + searching</head><p>The strategy of "user based diverse intention prediction + searching" is to predict the user"s intention before search. A good choice is to use user log but large scale real data is hard to achieve. So an alternative choice is to use the external resource.</p><p>First, in order to obtain sub-topics of each query, we automatically submit each query to Google, and collected the query suggestion and related search queries without any manual labeling. The query suggestion refers to the queries in the prompt box while typing the query to the query box, and related search queries refer to the recommended queries shown at the bottom of the result page.</p><p>Second, some rules is conducted to filter the queries from Google and obtain more relevant and accurate phrases and sub-topics.</p><p>(1) The query suggestion and related search queries should fully contain the original query terms.</p><p>(2) If rule (1) is not satisfied, and the original query is a substring of one expanded query term, then the expanded query is preserved only if it is a URL like string, i.e. ended with ".com", ".org", ".edu", ".net" etc. (3) If there are duplicate phrases satisfy the conditions above in both query suggestion and related search queries, we preserve only one.</p><p>Third, each new query is taken as the expanded one and submitted to our retrieval system.</p><p>Finally, to combine the multiple result lists, the same diversity result selection algorithm is performed as shown in the previous section 5.2.2, which selects two or three most relevant pages for each user intention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Searching + Duplication elimination</head><p>In our duplicate eliminating study, content-based and site-based approaches are integrated. We first calculate the cosine similarity between two document pairs, and obtain an upper triangular matrix Aij (where each element aij represent the similarity between document i and j, where i &lt; j) as similarity matrix. Then if aij is greater than θ, the document j is eliminated. In our experiments, θ is set to 0.4. Then in the second traversal process, site-based approach is taken as follows:</p><p>(1) We keep at most m results from a distinct website in the result list, where m is set to 2.</p><p>(2) We keep at most one result from a distinct website in any w coterminous results, where w is set to 5.</p><p>After the two steps, final result is generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submitted results</head><p>We submitted three runs for each task, all of which are automatic ones. The evaluation results are shown below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Ad hoc task (category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Per-topic analysis</head><p>Following figures show the topic-by-topic analysis results on the two typical results of the two diversity strategies in terms of alpha-nDCG@10 and IA-p@10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Conclusion and the discussion</head><p>This is the first year"s experiment on the diversity task for Web IR. Several conclusions can be drawn by our research and there are many problems leave for further study. First, In-link anchor text is shown to be powerful! (Even much more effective than the full text) Second, PageRank is definitely helpful! Third, the improved probabilistic model is effective. Finally, on finding diverse result strategies, we conclude that (1) "Searching + Result clustering" is a good choice for diversity task;</p><p>(2) the strategy of "User intention prediction + searching" still need more analysis;</p><p>(3) There is bias on the task, such as the bias of the diversity definition, the bias of the diversity judgment, and bias on using different user log data to model the user"s intention. In fact, these biases coming from one problem: the difficulties in understanding a global diversity, which still need further study.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,86.14,224.01,2.32,8.34;4,119.03,223.57,5.09,8.88;4,70.94,249.25,432.95,9.50;4,503.98,253.27,17.87,6.26;4,521.86,249.25,2.64,9.50;4,70.94,265.21,84.61,9.50;4,155.54,269.23,8.52,6.26;4,166.82,265.21,357.73,9.50;4,70.94,281.32,453.45,9.50"><head></head><label></label><figDesc>,  Three parts are linear combined in the model, namely traditional probabilistic BM25 modal weight W BM25 , word pair weight W wp and pagerank of the document PageRank (D). I() is indicator function, return value 1 when the event occurs, 0 otherwise. Event Q D means the document D contains all the terms in query Q.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,216.67,424.42,3.62,6.31;5,206.66,424.42,3.62,6.31;5,197.97,424.42,4.83,6.31;5,339.32,409.54,8.27,10.80;5,324.83,409.54,6.20,10.80;5,287.73,409.54,31.45,10.80;5,266.86,409.54,8.27,10.80;5,255.23,409.54,6.20,10.80;5,218.14,409.54,31.45,10.80;5,171.35,409.54,6.20,10.80;5,159.92,409.54,6.20,10.80;5,108.95,409.54,45.43,10.80;5,458.14,424.48,26.44,9.50;5,142.85,456.93,11.08,13.78;5,146.92,470.67,4.30,5.35;5,276.14,458.08,5.69,9.19;5,268.56,457.50,2.56,9.19;5,223.79,458.08,5.69,9.19;5,186.39,457.50,2.56,9.19;5,265.61,441.67,5.69,9.19;5,217.78,441.67,5.69,9.19;5,126.37,448.02,5.69,9.19;5,150.83,470.73,3.02,5.30;5,142.24,470.73,4.03,5.30;5,261.85,458.18,6.91,9.10;5,245.98,458.18,9.66,9.10;5,212.10,458.18,8.63,9.10;5,179.68,458.18,6.91,9.10;5,169.82,458.18,5.18,9.10;5,158.09,458.18,5.41,9.10;5,253.74,441.77,6.91,9.10;5,237.88,441.77,9.66,9.10;5,206.09,441.77,8.63,9.10;5,176.08,441.77,6.91,9.10;5,166.23,441.77,5.18,9.10;5,154.48,441.77,5.41,9.10;5,113.93,448.12,6.91,9.10;5,104.08,448.12,5.18,9.10;5,72.65,448.12,26.60,9.10;5,146.44,470.73,1.09,5.30;5,306.85,456.53,3.02,5.30;5,296.09,458.18,10.21,9.10;5,291.17,458.18,5.18,9.10;5,288.62,458.18,2.59,9.10;5,283.55,458.18,5.18,9.10;5,270.95,458.18,3.45,9.10;5,258.04,458.18,3.45,9.10;5,239.31,458.18,5.98,9.10;5,234.54,458.18,3.45,9.10;5,230.26,458.18,5.18,9.10;5,193.21,458.18,18.69,9.10;5,188.78,458.18,3.45,9.10;5,175.87,458.18,2.59,9.10;5,166.17,458.18,3.45,9.10;5,154.76,458.18,3.45,9.10;5,285.55,441.77,6.83,9.10;5,280.64,441.77,5.18,9.10;5,278.10,441.77,2.59,9.10;5,273.02,441.77,5.18,9.10;5,260.42,441.77,3.45,9.10;5,249.95,441.77,3.45,9.10;5,233.27,441.77,2.88,9.10;5,228.53,441.77,3.45,9.10;5,224.22,441.77,5.18,9.10;5,187.19,441.77,18.69,9.10;5,182.74,441.77,3.45,9.10;5,172.27,441.77,2.59,9.10;5,162.58,441.77,3.45,9.10;5,120.60,448.12,3.45,9.10;5,110.11,448.12,2.59,9.10;5,100.43,448.12,3.45,9.10;5,366.27,443.24,11.86,14.90;5,369.23,458.10,4.62,5.80;5,357.32,444.50,6.09,9.93;5,373.55,458.16,4.68,5.75;5,365.85,458.16,3.24,5.75;5,401.63,444.61,7.40,9.84;5,391.18,444.61,5.54,9.84;5,378.72,444.61,5.78,9.84;5,344.14,444.61,7.40,9.84;5,327.31,444.61,10.27,9.84;5,408.68,444.61,3.69,9.84;5,397.60,444.61,2.77,9.84;5,387.31,444.61,3.69,9.84;5,351.20,444.61,3.69,9.84;5,340.11,444.61,3.69,9.84;5,70.94,486.77,453.80,10.64;5,70.94,503.46,71.37,9.50;5,182.10,502.72,4.11,10.64;5,169.86,502.72,3.08,10.64;5,158.55,502.72,23.99,10.64;5,162.82,502.72,6.17,10.64;5,149.08,502.72,6.40,10.64;5,193.49,502.17,331.49,11.18;5,70.94,518.90,242.18,10.52;5,342.00,518.82,4.17,10.61;5,329.54,518.82,12.87,10.61;5,315.17,518.82,11.53,10.61;5,348.43,518.27,176.43,11.11;5,70.94,535.50,154.71,9.50"><head></head><label></label><figDesc>w is any non-stop word contained in a document, function weight implements the TF-IWF model. In this equation, ) , ( w d tf stands for the frequency of word w appeared in document d , W is the frequency of all the non-stop words appeared in d , and ) (w wf is the frequency of word w appeared in all the four thousand documents D .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,202.69,161.86,12.74,10.80;8,155.90,190.33,52.07,9.50;8,444.94,190.33,20.97,9.50;8,487.54,190.33,26.25,9.50;8,76.34,206.29,55.52,9.50;8,155.90,206.29,278.33,9.50;8,155.90,221.89,277.13,9.50;8,444.94,206.29,71.64,9.50;8,76.34,237.97,357.88,9.50;8,155.90,253.57,278.34,9.50;8,155.90,269.17,112.42,9.50;8,444.94,237.97,71.64,9.50;8,76.34,285.40,357.87,9.50;8,155.90,301.00,267.20,9.50;8,444.94,285.40,71.64,9.50;8,70.94,317.08,323.82,9.50;8,70.94,340.21,158.07,10.80;8,95.54,364.48,36.00,9.50;8,257.57,364.48,52.07,9.50;8,418.51,356.68,42.09,9.50;8,421.51,372.28,36.12,9.50;8,472.54,364.48,41.98,9.50;8,76.34,388.24,68.84,9.50;8,161.42,388.24,244.38,9.50;8,161.42,403.84,194.94,9.50;8,416.59,388.24,23.76,9.50;8,473.26,388.24,23.76,9.50;8,76.34,419.92,66.75,9.50;8,161.42,419.92,244.38,9.50;8,161.42,435.52,88.91,9.50;8,161.42,451.12,130.35,9.50;8,416.59,419.92,23.76,9.50;8,473.26,419.92,23.76,9.50;8,76.34,467.22,329.42,9.50;8,161.42,482.82,239.46,9.50;8,416.59,467.22,23.76,9.50;8,473.26,467.22,23.76,9.50;8,76.34,499.02,329.55,9.50;8,161.42,514.62,85.95,9.50;8,161.42,530.22,103.24,9.50;8,416.59,499.02,23.76,9.50;8,473.26,499.02,23.76,9.50"><head></head><label></label><figDesc>Improved probabilistic model (with PageRank, Wordpair and anti-spam embedded), retrieved on anchor text only 0.3840 0.3740 THUIR09TxAn TMiner system, Improved probabilistic model (with PageRank, Wordpair and anti-spam embedded), retrieved on the full page combined with anchor text 0.3800 0.3640 THUIR09LuTA Lucene with BM25f model, re-ranking with PageRank, anti-spam, retrieved on the full page combined with anchor text 0.2120 0.2100 THUIR09TxAn is used for the following diversity task as the baseline result. clustering on the full page + site-based duplicate elimination + improved IA-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="9,71.25,74.82,431.55,166.13"><head></head><label></label><figDesc></figDesc><graphic coords="9,71.25,74.82,431.55,166.13" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,79.22,747.37,445.11,8.96;1,70.94,758.58,213.99,10.72"><p>Supported by Natural Science Foundation (60736044， 60903107) and Research Fund for the Doctoral Program of Higher Education of China (20090002120005)</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>We would like to thank <rs type="person">Qian Wang</rs>, <rs type="person">Huijia Yu</rs>, <rs type="person">Xudong Li</rs>, <rs type="person">Yu Sun</rs> and <rs type="person">Wei Yang</rs> for their help on system building and data preprocessing.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,86.06,520.98,438.57,9.50;9,70.94,536.58,332.45,9.50" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,250.70,520.98,221.42,9.50">Detecting spam Web pages through Content Analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,491.01,520.98,33.62,9.50;9,70.94,536.58,286.17,9.50">Proc. of the 15th International Conference on World Wide Web (WWW2006)</title>
		<meeting>of the 15th International Conference on World Wide Web (WWW2006)</meeting>
		<imprint>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,86.90,567.78,437.59,9.50;9,70.94,583.38,90.86,9.50;9,161.78,580.80,5.40,6.26;9,169.46,583.38,267.06,9.50" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,276.59,567.78,213.60,9.50">THUIR at TREC 2003: Novelty, Robust and Web</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,511.64,567.78,12.85,9.50;9,70.94,583.38,90.86,9.50;9,161.78,580.80,5.40,6.26;9,169.46,583.38,108.87,9.50">the proceedings of the 12 th Text Retrieval Conference</title>
		<meeting><address><addrLine>Maryland, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="556" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.82,598.98,276.83,9.50" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Joaquin</forename><surname>Perez-Iglesias</surname></persName>
		</author>
		<ptr target="http://nlp.uned.es/~jperezi/Lucene-BM25/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,85.83,614.58,438.78,9.50;9,70.94,630.18,142.47,9.50" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,153.62,614.58,325.16,9.50">Research on News Issue Construction and Topic Mining in Web Environment</title>
		<author>
			<persName coords=""><forename type="first">Chanhui</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="22" to="25" />
		</imprint>
		<respStmt>
			<orgName>Tsinghua University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,86.42,645.78,437.99,9.50;9,70.94,661.41,453.57,9.50;9,70.94,677.01,75.36,9.50" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,326.60,645.78,181.77,9.50">Samuel Ieong, Diversifying Search Results</title>
		<author>
			<persName coords=""><forename type="first">Sreenivas</forename><surname>Rakesh Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Gollapudi</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Halverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,70.94,661.41,448.78,9.50">WSDM &apos;09: Proceedings of the Second ACM International Conference on Web Search and Data Mining</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="5" to="14" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
