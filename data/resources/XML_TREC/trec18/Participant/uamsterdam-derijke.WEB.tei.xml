<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,94.22,83.76,421.28,15.48">Heuristic Ranking and Diversification of Web Documents</title>
				<funder ref="#_DJ65Kdq #_uuTr6jy #_8htMK2p #_AZQvewa #_eknVstb">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_9pYmqhw">
					<orgName type="full">Dutch and Flemish Governments</orgName>
				</funder>
				<funder ref="#_VBPqjqR">
					<orgName type="full">DAESO</orgName>
				</funder>
				<funder ref="#_BJcEkrq">
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
				<funder ref="#_uYqwJvM">
					<orgName type="full">Dutch Ministry of Education, Culture and Science</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,157.24,116.28,42.85,10.75"><forename type="first">Jiyin</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.04,116.28,80.04,10.75"><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.04,116.28,80.70,10.75"><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.69,116.28,58.77,10.75"><forename type="first">Edgar</forename><surname>Meij</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,150.18,130.23,90.19,10.75"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.32,130.23,82.71,10.75"><forename type="first">Manos</forename><surname>Tsagkias</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.98,130.23,97.60,10.75"><forename type="first">Wouter</forename><surname>Weerkamp</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,94.22,83.76,421.28,15.48">Heuristic Ranking and Diversification of Web Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F3DB89D76FAA9B1A20C7CD59C3FEE3D7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the participation of the University of Amsterdam's Intelligent Systems Lab in the web track at TREC 2009. We participated in the adhoc and diversity task. We find that spam is an important issue in the ad hoc task and that Wikipedia-based heuristic optimization approaches help to boost the retrieval performance, which is assumed to potentially reduce spam in the top ranked results. As for the diversity task, we explored different methods. Clustering and a topic model-based approach have a similar performance and both are relatively better than a query log based approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year's Web track consists of two tasks, the ad hoc and diversity task. The ad hoc task is traditional ad hoc retrieval in a web setting, where the goal is to return a list of documents from a static document collection, ranked by decreasing relevance. Document relevance is considered independent from the rest of the documents within the list.</p><p>The second task, diversity, is new; the goal is to return a ranked list of documents which together provide complete coverage of a query, while avoiding excessive redundancy in the result list. Here, in contrast to the ad hoc task, a document's relevance is dependent on the presence of other documents in the same ranked list.</p><p>For the ad hoc task we explore two basic approaches: (i) query rewriting using Markov Random Fields to get a better representation of the original query, and (ii) remodeling the query using an external collection as source for adding and reweighing query terms. On top of these approaches we (i) remove Wikipedia pages that are not content pages (e.g., category pages, link-to pages, etc.), and (ii) promote Wikipedia pages in the initial ranked list to the top of the ranking.</p><p>For the diversity task we experiment with three types of method for result diversification, an AOL query log based approach, a topic model based approach as well as a clustering based approach. We find that the topic model based ap-proach and clustering based approach outperform our baseline run, i.e., the MRF ad hoc run as measured by diversity metrics.</p><p>In the remainder of this paper, we first describe the approaches we applied to both tasks in Section 2. Then we describe our experimental settings in Section 3, the results and a discussion of our submitted runs in Section 4. Section 5 concludes the description of our participation in this year's Web track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In this section, we describe our proposed approaches to the ad hoc task, in Section 2.1 and to the diversity task (Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Ad hoc Task</head><p>The goal of the ad hoc task can be considered as one of the most basic ones in IR: to rank documents according to their relevance to a given query. Despite its "standard" character, the nature and the size of the new Clueweb collection render the task challenging and interesting.</p><p>We do not apply spam filtering on the collection, although insights from preliminary data exploration suggested that retrieval results may benefit substantially for any ad hoc retrieval system on this collection. For now, we try two basic approaches and use two optimization techniques. Below we describe the two approaches and the optimizations.</p><p>Markov Random Fields Following the ideas from <ref type="bibr" coords="1,533.23,615.18,18.15,8.64;1,316.81,627.14,80.43,8.64" target="#b8">(Metzler and Croft, 2005)</ref>, we use Markov Random Fields (MRF) to rewrite our initial query. The goal of applying this technique is to be better able to represent possible phrases in the query. A three term query like "obama white house" would result in all possible phrases (e.g., "obama white," "white house," "obama house," and "obama white house") as well as the single terms <ref type="bibr" coords="1,396.22,698.87,115.42,8.64" target="#b9">(Mishne and de Rijke, 2005)</ref>. Previous TREC years showed that this technique is very effective.</p><p>External expansion Given that we are dealing with a web collection that can be quite noisy, we use external query expansion, a technique that proved useful in retrieval in the blogosphere <ref type="bibr" coords="2,105.59,93.14,89.93,8.64" target="#b0">(Arguello et al., 2008;</ref><ref type="bibr" coords="2,198.62,93.14,94.28,8.64">Weerkamp et al., 2009;</ref><ref type="bibr" coords="2,53.80,105.10,121.32,8.64">Weerkamp and de Rijke, 2009)</ref>) and that originated from targeting better relevance model estimations <ref type="bibr" coords="2,219.04,117.05,73.86,8.64;2,53.80,129.01,21.44,8.64" target="#b5">(Diaz and Metzler, 2006)</ref>. The goal of this technique is to use an "external" collection that is less noisy than the target collection to improve the estimation of the query model.</p><p>The Clueweb collection offers a natural "external" collection, Wikipedia, as this part of the collection is free of spam and relatively clean (compared to other web documents). Wikipedia would therefore be usable in modeling our query: We run our queries against the Wikipedia collection, select the top 10 terms (using relevance models from <ref type="bibr" coords="2,251.71,227.84,41.20,8.64;2,53.80,239.79,65.03,8.64" target="#b7">(Lavrenko and Croft, 2001)</ref> and mix these with the original query terms.</p><p>Optimizing our approaches We use two ways of optimizing our runs: (i) Wikipedia filtering, and (ii) Wikipedia promotion. The first technique is used to filter out Wikipedia pages that do not contain real content. These pages are for example the link-to, category, and disambiguation pages that are mainly included for navigational purposes. We feel that these pages can be removed without danger of missing relevant documents, thereby possibly pushing relevant documents higher up the ranking. The second technique, Wikipedia promotion, is based on the observation that Wikipedia pages are pages we can certainly trust, whereas other web documents could very well be spam. We translate this observation into the promotion of all Wikipedia pages in the results to the top of the ranking (maintaining their relative order).</p><p>Our three final runs for the ad hoc task use: (i) Markov Random Fields and Wikipedia filtering, (ii) Markov Random Fields and Wikipedia filtering and promotion, and (iii) External expansion and Wikipedia filtering. We report on the results of the runs in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Diversity Task</head><p>For the diversity task, we experimented with 3 types of approach: Single Pass Clustering (SPC), a topic model-based approach, and AOL query suggestion. The first two approaches share common features: they re-rank an initially retrieved list of documents for generating the final result list, and try to model the topical facets contained in the initial retrieved ranking list without using external resources. The difference between the two approaches mainly lies in the methods used for detecting topics and for re-ranking. For topic detection, the first approach, SPC, clusters documents into a number of topics and each document is assigned to one topic, while the topic model-based approach represents each document as a mixture of topics. For re-ranking, the SPC approach selects documents from different clusters so that selected documents are supposedly about different topics, while the topic model-based approach tries to maximize the probability that most if not all topics being present in the selected document list. The third approach, AOL query suggestion uses an external resource, i.e., AOL query logs, for modeling the topical facets of a query. It also generates the final result list in a different fashion which will be further described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single Pass Clustering</head><p>The first method we employed is Single Pass Clustering (SPC) <ref type="bibr" coords="2,438.29,183.59,44.09,8.64" target="#b6">(Hill., 1968</ref>), which provides not only an efficient clustering algorithm, but also mimics a reasonable heuristic that a user might employ. That is, start at the top and work down the initial retrieved list of documents, and assign each to a cluster. The process for assignment is performed as follows: The first document is taken and assigned to the first cluster. Then each subsequent document is compared against each cluster with a similarity measure (in our case a standard cosine measure using a TF.IDF weighting scheme). A document is assigned to the most likely cluster, as long as the similarity score is higher than a certain threshold (set to 0.2 for our run); otherwise, the document is assigned to a new cluster.</p><p>Once this clustering has been performed on the initial result list, we re-rank documents as follows. First, we output a single document from each cluster, specifically, the ones that were ranked the highest initially. Second, we iterate over the initial list of documents, and output each that has not been returned in the first phase.</p><p>Topic Model Approach This approach is inspired by previous work on diversifying a ranked list with Maximal Marginal Relevance (MMR) by <ref type="bibr" coords="2,470.72,456.57,80.54,8.64;2,316.81,468.52,48.81,8.64" target="#b2">Carbonell and Goldstein (1998)</ref> and based on a topic modeling approach, i.e., LDA <ref type="bibr" coords="2,340.12,480.48,70.45,8.64" target="#b1">(Blei et al., 2003)</ref>. It treats the reranking problem as a procedure of selecting a sequence of documents, where a document is selected depending on both its relevance with respect to the query and the documents that have already been selected before it, so as to have a set of documents that (i) are most relevant to the query and (ii) represent most if not all topical aspects.</p><p>We proceed as follows. First, we use LDA to extract 10 topics from the top 2,500 documents in the initial retrieved set of results, where the initial results are generated from the ad hoc run uvamrf as described above, and each document can be represented as a mixture of 10 topics. On top of that, we start the re-ranking procedure by selecting the top relevant document in the initial list as the first document in the new ranked list. Then, we select a next document that can maximize the expected joint probability of presence of all topics in the selected result set. Since the sum of topic proportions within a document equals 1, the maximum joint probability (i.e., product of the probabilities of presence of each topic) occurs when the topics have equal proportion in the selected set. On the other hand, we use the retrieval score from the initial run as a prior probability that a document is selected as the next one, so as to take into account the relevance relation between the document and the original query.</p><p>Formally, given a query q, a set of candidate documents Ca = {d j } n j=1 and a set of latent topics T = {t i } m i=1 , a document is selected from Ca for inclusion in the ranked list S such that arg max</p><formula xml:id="formula_0" coords="3,114.10,168.35,178.81,27.16">d∈Ca P(q|d) m ∏ i=1 P(t i ∈ S ∪ {d}),<label>(1)</label></formula><p>where P(q|d) is the query likelihood between the query q and document d calculated as in a standard language modeling framework. The term P(t i ∈ S ∪ {d}) denotes the probability of a topic being present in the set S = S ∪ {d}, which is estimated by</p><formula xml:id="formula_1" coords="3,107.02,286.28,185.88,19.99">P(t i ∈ S ) = ∑ d j ∈S P(t i ∈ d j )P(d j ).<label>(2)</label></formula><p>AOL -Diversification using query logs This approach employs queries from a query log to discern and obtain diverse query formulations. The intuition is that terms that are frequently queried in conjunction with a set of given query terms provide a diverse set of aspects of those given query terms. We proceed as follows. First, we normalize all the queries in the AOL query logs and remove web addresses and non-alphabet characters. We then look up for each test topic whether it appeared as a phrase in the query logs. If so, we take the top 25 queries with a minimum number of occurrences of 5. An example is given in Table <ref type="table" coords="3,243.95,458.90,3.74,8.64" target="#tab_0">1</ref>. For each of these "expanded" queries we generate an MRF query and, on the basis of this, a new ranking. Each of these ranked lists now represents a ranking of documents based on one aspect of the initial topic. In order to arrive at a final ranking, the lists are merged. We do so by first sorting them by aspect occurrence frequency (as found in the query log) and then adding the highest ranked document that has not been selected yet to the final ranking in a round-robin fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic</head><p>3 Experimental Settings</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>For both tasks in the Web track, we use the category A set of the Clueweb collection (the full collection). For indexing, we do not use any form of stemming and remove a conservative list of 588 stopwords. We index the headings, titles, and contents as searchable fields and do not remove any HTML tags. Our approaches retrieve against the text content of the web pages and leave out information provided by anchor texts or hyperlinks among web pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation metrics</head><p>For the ad hoc task, we use the traditional relevance oriented measures, i.e., MAP, P@5 and P@10. For the diversity task, the results are evaluated with the α-NDCG measure as proposed by <ref type="bibr" coords="3,355.43,298.73,75.53,8.64" target="#b4">Clarke et al (2008)</ref> and IA-Precision as developed in this year's Web Track <ref type="bibr" coords="3,422.73,310.68,82.04,8.64" target="#b3">(Clarke et al., 2009)</ref>. The latter two metrics allow for measuring both the relevance and the novelty of the result ranked list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Significant test</head><p>We use the Wilcoxon signed-rank test to test for significant differences between runs. We report on significant increases (or drops) for p &lt; .01 using (and ) and for p &lt; .05 using (and ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Adhoc Task</head><p>The results of our adhoc runs are displayed in Table <ref type="table" coords="3,530.81,538.70,3.74,8.64">2</ref>. We observe that the run using Wikipedia promotion outperforms the other two runs significantly. The difference with its baseline, MRF with just filtering, is huge, especially on the precision metrics. Comparing the two approaches, external expansion and MRF, in their "baseline" setting, we see a marginal advantage for external expansion, but differences are not significant.</p><p>Figure <ref type="figure" coords="3,356.17,639.09,4.98,8.64" target="#fig_0">1</ref> shows the per-topic level run comparison between the MRF run and the Wikipedia promotion run. We see that most topics are helped and only a small portion of the topics are slightly hurt by Wikipedia promotion, which indicates that Wikipedia is a reliable resource for web retrieval, and is probably due to the fact that Wikipedia does not contain any spam. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Diversity Task</head><p>Table <ref type="table" coords="4,79.00,391.45,4.98,8.64" target="#tab_1">3</ref> shows the results of our submitted runs for the diversity task. The results can only be considered indicative considering the heuristic selection of parameter values. Nevertheless, we observe that SPC and the topic model based methods display a similar performance. Intuitively, this is likely due to the common features shared during the topic detection process: given that LDA can also be seen as a method for clustering, the resulting clustering/topic structure may be similar. However, in order to gain insight into the similarities and differences in behavior of the two approaches, further comparison and analysis are needed.</p><p>On the other hand, when we the results compare to the initial ranked list, i.e., the MRF run, we see that all methods outperform the baseline, where the improvements of SPC and the topic modeling-based method are significant. More interestingly, we see that if we evaluate the MRF run with Wikipedia promotion with the diversity metrics, the performance is better than all three diversification methods. The Wikipedia promotion run retrieves more relevant documents at the top of the ranked list than the MRF run on which our submitted diversification runs are based.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year's web track, we submitted runs for the ad hoc task and diversity task. For the ad hoc task, we explored Approach α-ndcg@5 α-ndcg@10 α-ndcg@20 uvamrf 0. Expansion with Wikipedia filtering. Although we did not explicitly apply any spam filtering techniques, the preliminary results suggest that spam is an important issue for experiments based on the ClueWeb collection. For the diversity task, we explored three types of approach: (i) Single Pass Clustering, (ii) topic modeling, and (iii) diversification using a query log. All three methods outperform the baseline approach, i.e., the MRF run without diversification.</p><p>Although the results are not exactly comparable across methods, we were able to identify issues shared by all three methods. For example, the heuristic method for choosing parameters calls for systematic experiments that will allow us to gain further insights in to the algorithms' performance under different parameter settings. On the other hand, intuitively, the performance of the clustering and topic modelbased methods depends heavily on the initial retrieval run used for re-ranking, which is an interesting issue for further analysis.</p><p>In addition, we found that our heuristic Wikipedia-based promotion technique results in high scores in terms of diversity metrics. The Wikipedia promotion retrieves more relevant documents at the top of the ranked list, while our other diversification runs our MRF-based baseline run based diversification runs in general have very few relevant docu-ments being retrieved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,53.80,326.17,239.10,8.64;4,53.80,338.13,43.75,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Per-topic comparison of AP between uvamrf and uvamrftop.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.80,488.35,239.10,110.22"><head>Table 1 :</head><label>1</label><figDesc>Example of using the AOL query logs for diversification.</figDesc><table coords="3,71.82,488.35,203.06,73.42"><row><cell>AOL query</cell><cell>Frequency</cell></row><row><cell cols="2">dinosaurs remote control dinosaurs 30</cell></row><row><cell>dinosaurs jim henson dinosaurs</cell><cell>25</cell></row><row><cell>dinosaurs allosaurus dinosaurs</cell><cell>24</cell></row><row><cell>dinosaurs flying dinosaurs</cell><cell>21</cell></row><row><cell>dinosaurs walking with dinosaurs</cell><cell>16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,316.81,76.22,239.10,347.98"><head>Table 3 :</head><label>3</label><figDesc>Result of diversity task. The names of approaches correspond to AOL query suggestion (AOL), single pass clustering (SPC) and topic model based approach(TM). Results of diversification runs are compared to the baseline run MRF.</figDesc><table coords="4,328.13,76.22,206.86,161.25"><row><cell></cell><cell>042</cell><cell>0.060</cell><cell>0.076</cell></row><row><cell cols="2">uvamrftop 0.123</cell><cell>0.129</cell><cell>0.139</cell></row><row><cell>AOL</cell><cell>0.055</cell><cell>0.074</cell><cell>0.098</cell></row><row><cell>SPC</cell><cell>0.068</cell><cell>0.093</cell><cell>0.127</cell></row><row><cell>TM</cell><cell>0.090</cell><cell>0.097</cell><cell>0.125</cell></row><row><cell cols="2">Approach IA-P@5</cell><cell>IA-P@10</cell><cell>IA-P@20</cell></row><row><cell>uvamrf</cell><cell>0.020</cell><cell>0.028</cell><cell>0.035</cell></row><row><cell cols="2">uvamrftop 0.090</cell><cell>0.089</cell><cell>0.079</cell></row><row><cell>AOL</cell><cell>0.023</cell><cell>0.030</cell><cell>0.037</cell></row><row><cell>SPC</cell><cell>0.036</cell><cell>0.043</cell><cell>0.051</cell></row><row><cell>TM</cell><cell>0.047</cell><cell>0.041</cell><cell>0.043</cell></row></table><note coords="4,316.81,331.88,239.10,8.64;4,316.81,343.83,239.10,8.64;4,316.81,355.79,239.10,8.64;4,316.81,367.74,239.10,8.64;4,316.81,379.70,239.10,8.64;4,316.81,391.65,239.10,8.64;4,316.81,403.61,239.10,8.64;4,316.81,415.56,239.10,8.64"><p>a basic retrieval approache, viz. Markov Random Fields for modeling query term proximity and external query expansion. On top of that, we applied two types of heuristic optimization, i.e., Wikipedia filtering and Wikipedia promotion. Combining the basic approaches with the optimization methods, we submitted three runs: (i) Markov Random Fields with Wikipedia filtering, (ii) Markov Random Fields with Wikipedia filtering and promotion, and (iii) External</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>This research was supported by the <rs type="funder">DAESO</rs> and <rs type="person">DuO-MAn</rs> project carried out within the <rs type="programName">STEVIN program</rs> which is funded by the <rs type="funder">Dutch and Flemish Governments</rs> under project number <rs type="grantNumber">STE-09-12</rs>, and by the <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs> under project numbers <rs type="grantNumber">640. 001.501</rs>, <rs type="grantNumber">640.002.501</rs>, <rs type="grantNumber">612.066.512</rs>, <rs type="grantNumber">612.061.814</rs>, <rs type="grantNumber">612.061.815</rs>, <rs type="grantNumber">640.004.802</rs>, and by the <rs type="programName">Virtual Laboratory for e-Science project</rs>, which is supported by a <rs type="grantName">BSIK grant</rs> from the <rs type="funder">Dutch Ministry of Education, Culture and Science</rs> and is part of the <rs type="programName">ICT innovation program</rs> of the <rs type="institution">Ministry of Economic Affairs</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VBPqjqR">
					<orgName type="program" subtype="full">STEVIN program</orgName>
				</org>
				<org type="funding" xml:id="_9pYmqhw">
					<idno type="grant-number">STE-09-12</idno>
				</org>
				<org type="funding" xml:id="_BJcEkrq">
					<idno type="grant-number">640. 001.501</idno>
				</org>
				<org type="funding" xml:id="_DJ65Kdq">
					<idno type="grant-number">640.002.501</idno>
				</org>
				<org type="funding" xml:id="_uuTr6jy">
					<idno type="grant-number">612.066.512</idno>
				</org>
				<org type="funding" xml:id="_8htMK2p">
					<idno type="grant-number">612.061.814</idno>
				</org>
				<org type="funding" xml:id="_AZQvewa">
					<idno type="grant-number">612.061.815</idno>
				</org>
				<org type="funding" xml:id="_uYqwJvM">
					<idno type="grant-number">640.004.802</idno>
					<orgName type="grant-name">BSIK grant</orgName>
					<orgName type="program" subtype="full">Virtual Laboratory for e-Science project</orgName>
				</org>
				<org type="funding" xml:id="_eknVstb">
					<orgName type="program" subtype="full">ICT innovation program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,75.32,276.75,66.65,12.90;5,53.80,302.76,239.10,8.64;5,63.76,314.72,229.14,8.64;5,63.76,326.50,160.48,8.82" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,63.76,314.72,229.14,8.64;5,63.76,326.67,85.02,8.64">Document representation and query expansion models for blog recommendation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>References Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Elsas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note>In ICWSM</note>
</biblStruct>

<biblStruct coords="5,53.80,348.10,239.10,8.64;5,63.76,359.88,218.47,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,267.45,348.10,25.45,8.64;5,63.76,360.06,73.68,8.64">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,144.83,359.88,80.95,8.59">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,381.49,239.10,8.64;5,63.76,393.44,229.14,8.64;5,63.76,405.22,229.14,8.82;5,63.76,417.35,92.13,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,218.31,381.49,74.59,8.64;5,63.76,393.44,229.14,8.64;5,63.76,405.40,83.59,8.64">The use of MMR, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,165.07,405.22,38.83,8.59">SIGIR &apos;98</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,438.78,239.10,8.64;5,63.76,450.56,229.14,8.82;5,63.76,462.52,40.68,8.59" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,260.24,438.78,32.66,8.64;5,63.76,450.74,164.45,8.64">Preliminary report on the TREC 2009 Web Track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,246.29,450.56,46.60,8.59;5,63.76,462.52,36.16,8.59">TREC 2009 Notebook</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,484.12,239.10,8.64;5,63.76,495.90,228.52,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,148.04,484.12,144.86,8.64;5,63.76,496.08,74.73,8.64">Novelty and diversity in information retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">Clarke</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,156.82,495.90,39.21,8.59">SIGIR &apos;08</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="659" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,517.51,239.10,8.64;5,63.76,529.29,229.14,8.82;5,63.76,541.24,196.47,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,182.47,517.51,110.43,8.64;5,63.76,529.46,183.57,8.64">Improving the estimation of relevance models using large external corpora</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,268.01,529.29,24.90,8.59;5,63.76,541.24,11.83,8.59">SIGIR &apos;06</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,562.85,239.10,8.64;5,63.76,574.63,229.14,8.82;5,63.76,586.58,220.95,8.82" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,147.43,562.85,122.41,8.64">A vector clustering technique</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,141.46,574.63,151.44,8.59;5,63.76,586.58,101.55,8.59">Mechanised Information Storage, Retrieval and Dissemination</title>
		<editor>
			<persName><forename type="first">In</forename><surname>Samuelson</surname></persName>
		</editor>
		<meeting><address><addrLine>North-Holland, Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,608.19,239.10,8.64;5,63.76,619.97,142.36,8.82" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,208.65,608.19,84.25,8.64;5,63.76,620.14,53.09,8.64">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,135.69,619.97,39.21,8.59">SIGIR &apos;01</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,641.57,239.10,8.64;5,63.76,653.35,229.14,8.82;5,63.76,665.48,133.11,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,199.73,641.57,93.17,8.64;5,63.76,653.53,115.70,8.64">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,200.41,653.35,39.75,8.59">SIGIR &apos;05</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,53.80,686.91,239.10,8.64;5,63.76,698.87,229.14,8.64;5,63.76,710.65,180.97,8.82" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,198.85,686.91,94.05,8.64;5,63.76,698.87,102.89,8.64">Boosting Web Retrieval through Query Operations</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,132.66,710.65,42.56,8.59">ECIR 2005</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Fernández-Luna</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="502" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,316.81,57.28,239.10,8.64;5,326.78,69.23,229.14,8.64;5,326.78,81.01,206.52,8.82" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="5,521.46,57.28,34.45,8.64;5,326.78,69.23,229.14,8.64;5,326.78,81.19,113.91,8.64">A generative blog post retrieval model that uses query expansion based on external collections</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<idno>ACL-ICNLP 2009</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,316.81,101.11,239.10,8.64;5,326.78,112.89,229.14,8.82;5,326.78,124.84,130.33,8.82" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,481.57,101.11,74.34,8.64;5,326.78,113.07,104.83,8.64">External query expansion in the blogosphere</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,449.75,112.89,106.17,8.59;5,326.78,124.84,45.56,8.59">Seventeenth Text REtrieval Conference</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2008">2009. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
