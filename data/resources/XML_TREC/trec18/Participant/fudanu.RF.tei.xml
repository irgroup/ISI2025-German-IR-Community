<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.87,116.10,333.60,12.64;1,254.48,134.03,106.39,12.64">Relevance Feedback based on Constrained Clustering: FDU at TREC 09</title>
				<funder ref="#_tjt9K5f">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_gFc9p7k">
					<orgName type="full">Shanghai Committee of Science and Technology, China</orgName>
				</funder>
				<funder ref="#_t4kh556">
					<orgName type="full">Ph.D Programs Foundation of Ministry of Education of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,233.64,171.76,62.59,8.76"><forename type="first">Bingqing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.59,171.76,66.13,8.76"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.87,116.10,333.60,12.64;1,254.48,134.03,106.39,12.64">Relevance Feedback based on Constrained Clustering: FDU at TREC 09</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">76B88C1D8962405FAD4BFE6F35546DAA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce our participation of the TREC Relevance Feedback(RF) TRACK in 2009. The RF09 TRACK is focused on the explicit relevant feedback, where a few relevant and irrelevant documents are available to each query. Our system is implemented under the framework of probabilistic language model. We apply the constrained clustering on the top returned documents and extract the expanded words to reform the query. We also extract the named entities from the explicit relevant documents to expand the query. The experiment was conducted on the ClueWeb09 TREC Category B, which is a new and huge test collection for the TREC TRACKs. The evaluation result shows the performance of the constrained clustering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relevance Feedback(RF) utilizes the relevance evaluation information to reform the user's query so that the overall retrieval performance (such as MAP, NDCG) can be improved. Although it has been proposed for many years, some questions still remain unexplored. Therefore, TREC organizes the Relevance Feedback Track to offer a chance for researchers to study the problems in RF. In 2009, it is the second year of the RF Track and this year's task focuses on the explicit relevance feedback. The participants are given the queries together with a few relevant documents and irrelevant documents to reform the original query. The "ClueWeb09" test collection is the new test bed for the RF Track, which is a challenge for the researchers to handle huge amount of test collection. The detailed process of the RF Track can be found in the google's group <ref type="foot" coords="1,474.12,508.37,3.49,6.13" target="#foot_0">1</ref> . The description of the ClueWeb 09 collection can be found on the website <ref type="foot" coords="1,430.03,520.32,3.49,6.13" target="#foot_1">2</ref> .</p><p>There are 50 test queries to be retrieved. The whole process of RF Track is composed of two phases. The first phase requires each participant to submit one or two runs. "Phase 1 run" returns 5 documents for each query. The relevance of the 5 documents will be evaluated and a small query relevance pool will be built by these small runs. The Phase 2 is based on the phase 1. In the phase 2, each participant is given their own and other team's evaluated "Phase 1 run". The word "evaluated" means that we can definitely know which documents of the "Phase 1" run are relevant and which are not.</p><p>According to the requirements above, we mainly use two techniques in the RF09 task.</p><p>1 We conduct the constrained clustering on the top retrieved documents. The expanded words are extracted from the clustered pseudo relevant document set. 2 We extract the named entities from the relevant documents in the "Phase 1 run" and add these named entities as expanded terms to reform the query.</p><p>Constraint Clustering: the main character of the RF09 task is the explicit relevance feedback. However the few relevant documents are far from sufficient. We want to find more relevant documents by using the Phase 1 run. So it is intuitive to use constrained clustering on the top documents returned by the first-pass retrieval.</p><p>Named Entity: Considering that many queries are related with some events or famous persons and organizations. And these named entities usually show a low raw frequency compared with other single words in the documents. We empirically extract the name entities (Name, Location, Organization) from the relevant documents to expand the original query.</p><p>Since the new test bed is far bigger than previous TREC test collections, we conducted the experiments with the help of lemur/indir toolkit version 4.10<ref type="foot" coords="2,426.78,292.95,3.49,6.13" target="#foot_2">3</ref> , which provides us convenient utilities to process the TREC data set. The experiments are implemented with the indri toolkit, which is based on the probabilistic language model. The result shows the effectiveness of the proposed approach, which is not sensitive to input explicit relevance feedback information. While the effect of the named entity extraction depends on the quality of the Phase 1 run. The named entities can also be a good source for query expansion but need additional exploration.</p><p>The rest of this paper is structured as follows. Section 2 introduces the constrained clustering algorithm. Section 3 introduces the named entity extraction for query expansion. Section 4 describes our experiment result and discussion. The paper is concluded in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Clustering for Query Expansion 2.1 Constrained Clustering</head><p>Constrained Clustering or semi-supervised clustering <ref type="bibr" coords="2,360.90,489.97,11.75,8.76" target="#b0">[1]</ref> is suitable for handling the explicit relevance feedback in our task, which is to conduct the clustering with some constraints on the instances. There are two types of constraints, the must-link constraint c = (x, y) and the can-not-link constraint c (x, y), meaning that the instance x and y can or cannot be partitioned into the same cluster. The must-link constraint is transitive, meaning that c = (x, y), c = (y, z) ⇒ c = (x, z). The can-not-link constraint can be entailed.</p><p>Suppose that CC i and CC j are connected components and let x ∈ CC i and y ∈ CC j .</p><p>must-link is transitive:</p><formula xml:id="formula_0" coords="2,141.74,581.10,334.64,42.09">if c = (x, y) exits, then ∀a ∈ CC i and b ∈ CC j , c = (a, b) holds -can-not-link is entailed: if c (x, y), then ∀a ∈ CC i and b ∈ CC j , c (a, b) holds According to [1][3], given the input instances {x 1 , x 2 , • • • , x N }, where x i ∈ R D .</formula><p>The goal is to partition these instances into K cluster. We note the clusters as π k , k = 1, • • • , K, where K = 2 in our task. We use the indicator variable r nk to represent the partition. r nk takes the 1-of-K schemes, which means that ∑ k r nk = 1, r nk ∈ {0, 1}. If x n belongs to the kth cluster r nk = 1, and in other cases, r nk = 0. Suppose that µ k is the center of the kth cluster. The optimization criteria function is shown as follows,</p><formula xml:id="formula_1" coords="3,207.95,165.04,199.71,31.13">Loss = N ∑ x n ∈π k ,n=1 (x n -µ k ) 2 = N ∑ n=1 K ∑ k=1 r nk (x n -µ k ) 2 .</formula><p>(</p><formula xml:id="formula_2" coords="3,472.84,176.11,7.74,8.76">)<label>1</label></formula><p>The algorithm to iteratively compute r nk and µ k is the variation of the K-Means algorithm, which is shown in Fig. <ref type="figure" coords="3,267.70,217.05,3.74,8.76" target="#fig_0">1</ref>. Details of the algorithm can be referred to <ref type="bibr" coords="3,442.22,217.05,38.37,8.76;3,134.76,229.00,42.98,8.76" target="#b1">(Wagstaff et al. 2001)</ref> for i = 1 do N 9:</p><formula xml:id="formula_3" coords="3,134.76,229.00,177.81,57.35">[1][2] Algorithm 1 COP-KMeans Algorithm 1: Input: N instances {x 1 , x 2 , • • • , x N }, C = : set of</formula><p>(1) assign x i to nearest cluster ◃ nearest cluster center 10:</p><p>(2) if assignment of x i always violates a constraint, then exit with failure 11:</p><p>end for 12:</p><p>Recalculate the cluster centers µ 1 , • • • , µ k , take the weight of instance into count 13:</p><p>until Loss in Equ. 1 converges 14: End</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Implementation in Document Cluster</head><p>We first made the initial retrieval for each query. The top 100 retrieved documents were collected, on which we would make clustering. The Phase 1 evaluated run was used to build the "Must-Link" and "Can-Not-Link" constraint. Then we used the COP-KMeans algorithm to cluster the top 100 documents. The cluster containing the relevant document was taken as the relevant document set R, while the other cluster was taken as the irrelevant documents U. We extracted the expanded words from R.</p><p>The divergence between two documents is important when we made clustering, which can be modeled by different approaches. We measured the divergence between documents in the vector space model, with each document d i converted into a vector x i . Each element of x i is corresponded to a word in the document d i , which is the BM25 term weight in the document. Considering the efficiency of the algorithm, we empirically discarded those words with a low BM25 weight. We believe that the remaining words could represent the main semantic content of the document.</p><p>For some queries, the Phase 1 run contains only the relevant documents(easy query) or only the irrelevant documents(difficult query). When no relevant documents were available, we assumed that the top 5 returned documents excluding the irrelevant ones were taken as the relevant documents R. When no irrelevant documents were available, we empirically selected 5 low-ranked documents as the irrelevant ones.</p><p>After clustering on the documents, we extracted the expanded words from the relevant document cluster. The expanded words were ranked by the sum of the BM25 weight over the relevant documents. The top expanded words were incorporated into the reformed indri query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Named Entity</head><p>Previous work on the query has studied the classification of the query, which shown that some of the queries are entities focusing on some specific topics or domains. Named Entity (including People's Name, Location, Organization Names) are helpful to discriminate the relevant documents from the irrelevant documents. For example, given the query "out space universe", the organization name "NASA" is a good candidate expanded word.</p><p>In the conversional method, we select those words that show significant statistical connection the expanded terms. However, mixed with the high-frequency single words, the low-frequency named entities can only get a low rank the whole expansion terms. So we have to extract the named entities independently and add these entities into the indri query.</p><p>We extracted the named entities from the relevant documents in the Phase 1 run. We used the Stanford Named Entity Recognizer <ref type="bibr" coords="4,309.97,411.29,13.15,8.76" target="#b4">[5]</ref> <ref type="foot" coords="4,323.12,409.65,3.49,6.13" target="#foot_3">4</ref> to extract the named entities. with the default model in the package, trained on the CoNLL, MUC-6, MUC-7 and ACE named entity corpora.</p><p>We extracted the People's Name, Location and Organization Names and ranked these entities based on the raw frequency in the relevant documents. Some queries do not have relevant documents, so we did not extract named entities for these queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment and Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview of the Experiment Settings</head><p>We used the ClueWeb 09 TREC Category B test collection for both the Phase 1 and Phase 2 runs, which is a sub collection of the whole ClueWeb09 DataSet. The dataset was collected in January and February of year 2009. Statistics about the dataset is given in Tab. 1.</p><p>We conducted the experiment with the help of the Indri toolkit. We used the probabilistic language model as the retrieval model with the Dirichlet Smoothing method. In the Phase 1 run, the parameter µ in the Smoothing method is set to be the default value of 2500 in indri, which showed a poor experiment result. Since the language model is sensitive to the smoothing parameters, we set µ = 800 in all the Phase 2 runs.</p><p>Table <ref type="table" coords="5,159.25,115.93,3.36,7.90">1</ref>. ClueWeb09 Category A and Category B, "Pages" shows the web pages count, "M" means Million, "Size" gives the compressed and uncompressed size of the collection, "Lang" is the language contained in the collection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ClueWeb09 Pages</head><p>Size Lang Category A 1,040M 5T / 25T Many Category B 50M 250G / 1T English In the Phase 2, we first made the baseline run according to the settings described above. The top 100 documents were extracted for clustering. The evaluated Phase 1 run were used to construct the constraints. After the constrained clustering, the top 20 expanded words were added to the original query. Meanwhile, the top 10 name entities extracted from the relevant document were also extracted and added to the original query.</p><p>For the Indri query language, the expanded query takes the form as #weight( 1.0 #combine(&lt;query&gt;) 1.0 #uw(&lt;query&gt;) 1.0 #combine(WordCluster) 1.0 #combine(-NameEntity)). Each term in the indri query could be given a weight. &lt;query&gt; is the original input query. We did not focused on the weight assignment, so we simply set all the weight to be 1.0 in our experiments. We report the evaluation results in Tab. 2. The Phase 1 runs only retrieve 5 documents for each query. The Qrel-Phase1 is a small query relevance pool generated from all the Phase 1 submissions. We did not receive the qrels pool of Phase 2, because we only used the ClueWeb09 Category B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Submissions and Evaluation Results</head><p>In the Phase 2, the input is the top 100 documents of "Baseline" and the Phase 1 run, the output is the final submission which returns the top 2500 documents for each query. The evaluation result is the Million Query Style(EMAP and StAP). The MAP@5 evaluation is made by ourselves. For each Phase 2 final submissions, we evaluated the MAP of the top 5 documents by using the Qrel-Phase 1 so that we can compare the retrieval performance before and after the relevance feedback. All the MAP@5 is improved significantly compared with the "Baseline", also higher than their corresponding "Phase 1 run". To compare the input "Phase 1 run" and the output "Phase 2 run", we use the Qrel-Phase 1 pool to evaluate them and present the detailed results in Fig. <ref type="figure" coords="6,430.90,155.06,3.74,8.76" target="#fig_0">1</ref>. In Fig. <ref type="figure" coords="6,178.10,479.97,3.74,8.76" target="#fig_0">1</ref>, the red bars correspond to the Phase 2 run using the clustering method, the green bars corresponds to the Phase 2 run with both the clustering and the named entity extraction approach. We show the P@5, R-prec, bpref and MAP evaluation results. The results indicate interesting phenomena here. For most of the runs, query expansion can raise the precision and recall both. But for some good Phase 1 runs such as UMas.1 and WatS.1, query expansion will raise the recall significantly and sacrifice a little precision to achieve a better MAP evaluation. The named entity extraction can raise the overall performance but the improvement is marginal for some Phase 1 run.</p><p>Besides the results above, we also show the performance of each query here. The evaluation of the Phase 2 runs are the million query style. The Expected Mean Average Precision(EMAP) <ref type="bibr" coords="6,203.94,604.01,13.84,8.76" target="#b5">[6]</ref> and Statistical Sampling Precision(StAP) <ref type="bibr" coords="6,386.01,604.01,12.73,8.76" target="#b6">[7]</ref> of each query topic are presented in the Fig. <ref type="figure" coords="6,233.26,615.97,3.74,8.76" target="#fig_1">2</ref>.</p><p>The problem of the pseudo-relevance feedback can be shown in Fig. <ref type="figure" coords="6,434.78,632.41,3.74,8.76" target="#fig_1">2</ref>. For easy queries, the relevance feedback seems to help the performance but it seems still not effective to help those difficult queries. We introduce our query expansion approach on the explicit relevance feedback of TREC RF09 TRACK. We adopt the constrained clustering and named entity extraction in the task and verify the effectiveness of our approach in the experiments.</p><p>We are focused on a more general approach for the explicit relevant feedback. In the future work, we will continue to study the approach to improve the constrained clustering model and adapt the model for the query expansion task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,245.85,437.12,123.65,8.01;6,142.81,311.13,161.30,97.05"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Evaluation by Qrel-Phase 1</figDesc><graphic coords="6,142.81,311.13,161.30,97.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,249.46,522.98,116.43,8.01;7,163.18,380.23,288.98,114.17"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Evaluation of the Phase 2</figDesc><graphic coords="7,163.18,380.23,288.98,114.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,186.76,411.52,241.84,118.02"><head>Table 2 .</head><label>2</label><figDesc>Evaluation on Phase 2 runs</figDesc><table coords="5,186.76,430.79,241.84,98.74"><row><cell cols="5">Submission MAP@5 EMAP StAP Impt MAP@5 Impt StAP</cell></row><row><cell>Baseline</cell><cell>0.0501</cell><cell>NA 0.1645</cell><cell>NA</cell><cell>NA</cell></row><row><cell>FDU.1</cell><cell cols="2">0.0735 0.0439 0.2268</cell><cell>46.7%</cell><cell>37.9%</cell></row><row><cell>PRIS.1</cell><cell cols="2">0.0782 0.0440 0.2311</cell><cell>56.1%</cell><cell>40.5%</cell></row><row><cell>QUT.1</cell><cell cols="2">0.0594 0.0486 0.2386</cell><cell>18.6%</cell><cell>45.0%</cell></row><row><cell>UMas.1</cell><cell cols="2">0.0998 0.0461 0.2437</cell><cell>99.2%</cell><cell>48.1%</cell></row><row><cell>WatS.1</cell><cell cols="2">0.0915 0.0466 0.2382</cell><cell>82.6%</cell><cell>44.8%</cell></row><row><cell>fub.1</cell><cell cols="2">0.0761 0.0498 0.2450</cell><cell>51.9%</cell><cell>48.9%</cell></row><row><cell>twen.2</cell><cell cols="2">0.0763 0.0467 0.2285</cell><cell>52.3%</cell><cell>38.9%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,646.02,157.21,7.88"><p>http://groups.google.com/group/trec-relfeed</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,656.98,160.44,7.88"><p>http://boston.lti.cs.cmu.edu/Data/clueweb09/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,656.98,102.27,7.88"><p>http://www.lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,656.98,175.33,7.88"><p>http://nlp.stanford.edu/software/CRF-NER.shtml</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by the <rs type="funder">National Natural Science Foundation of China</rs> (Grant NO. <rs type="grantNumber">60673038</rs>), in part by the <rs type="funder">Ph.D Programs Foundation of Ministry of Education of China</rs> (Grant <rs type="grantNumber">NO. 200802460066</rs>), and in part by the <rs type="funder">Shanghai Committee of Science and Technology, China</rs> (Grant No. <rs type="grantNumber">08511500302</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_tjt9K5f">
					<idno type="grant-number">60673038</idno>
				</org>
				<org type="funding" xml:id="_t4kh556">
					<idno type="grant-number">NO. 200802460066</idno>
				</org>
				<org type="funding" xml:id="_gFc9p7k">
					<idno type="grant-number">08511500302</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,330.07,337.96,7.88;8,150.95,341.03,228.42,7.88" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,271.63,330.07,205.35,7.88">A Survey of Clustering with Instance Level Constraints</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sugato</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,150.95,341.03,198.44,7.88">ACM Transactions on Knowledge Discovery from Data</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,351.99,337.96,7.88;8,150.95,362.95,274.20,7.88" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,301.94,351.99,178.64,7.88;8,150.95,362.95,103.27,7.88">Stefan Schroedl: Constrained K-Means Clustering with Background Knowledge</title>
		<author>
			<persName coords=""><forename type="first">Kiri</forename><surname>Wagstaff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Seth</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,270.50,362.95,75.50,7.88">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,373.91,337.96,7.88;8,150.95,384.86,94.38,7.88" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m" coord="8,241.89,373.91,158.16,7.88">Pattern Recognition and Machine Learning</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="179" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,395.82,337.96,7.88;8,150.95,406.78,165.60,7.88" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,257.99,395.82,191.19,7.88">Query Type Classification of web document retrieval</title>
		<author>
			<persName coords=""><forename type="first">In-Ho</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilchang</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,465.14,395.82,15.44,7.88;8,150.95,406.78,96.08,7.88">Proceedings of the 26th SIGIR</title>
		<meeting>the 26th SIGIR</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,417.74,337.96,7.88;8,150.95,428.70,329.63,7.88;8,150.95,439.66,114.20,7.88" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,380.34,417.74,100.24,7.88;8,150.95,428.70,243.64,7.88">Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling</title>
		<author>
			<persName coords=""><forename type="first">Jenny</forename><surname>Rose Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,412.23,428.70,68.35,7.88;8,150.95,439.66,35.04,7.88">Proceedings of the 43nd ACL</title>
		<meeting>the 43nd ACL</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,450.62,337.97,7.88;8,150.95,461.58,322.47,7.88" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,443.45,450.62,37.14,7.88;8,150.95,461.58,167.99,7.88">Evangelos Kanoulas: Million Query Track 2007 Overview</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Virgil</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Blagovest</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dachev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,334.96,461.58,107.28,7.88">Proceedings of the 16th TREC</title>
		<meeting>the 16th TREC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,472.54,337.96,7.88;8,150.95,483.49,254.72,7.88" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,373.71,472.54,106.87,7.88;8,150.95,483.49,100.25,7.88">Evangelos Kanoulas: Million Query Track 2008 Overview</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javed</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Virgil</forename><surname>Pavlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,267.21,483.49,107.28,7.88">Proceedings of the 17th TREC</title>
		<meeting>the 17th TREC</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,494.45,337.96,7.88;8,150.95,505.41,329.63,7.88;8,150.95,516.37,136.07,7.88" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,421.15,494.45,59.43,7.88;8,150.95,505.41,182.67,7.88">An Information-Theoretic Approach to Automatic Query Expansion</title>
		<author>
			<persName coords=""><forename type="first">Claudio</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renato</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brigitte</forename><surname>Bigi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,339.56,505.41,141.02,7.88;8,150.95,516.37,15.34,7.88">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
