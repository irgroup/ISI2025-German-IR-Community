<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,57.84,107.03,479.55,12.90;1,268.30,124.97,58.62,12.90;1,128.52,140.56,338.19,10.75">Mining Specific and General Features in Both Positive and Negative Relevance Feedback QUT E-Discovery Lab at the TREC&apos;09 Relevance Feedback Track</title>
				<funder ref="#_rBE3tWF">
					<orgName type="full">National Science Council of Taiwan</orgName>
				</funder>
				<funder ref="#_wCcMdsJ">
					<orgName type="full">Australian Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,178.45,178.89,51.90,10.37"><forename type="first">Yuefeng</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,237.88,178.89,56.98,10.37"><forename type="first">Xiaohui</forename><surname>Tao</surname></persName>
							<email>x.tao@qut.edu.au</email>
						</author>
						<author>
							<persName coords="1,303.00,178.89,106.53,10.37;1,409.53,176.89,1.88,6.99"><forename type="first">Abdulmohsen</forename><surname>Algarni</surname></persName>
							<email>abdulmohsen.algarni@student.qut.edu.au</email>
						</author>
						<author>
							<persName coords="1,256.68,192.84,77.13,10.37;1,333.81,190.84,1.41,6.99"><forename type="first">Sheng-Tang</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Information Science and Applications</orgName>
								<orgName type="institution">Asia University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,57.84,107.03,479.55,12.90;1,268.30,124.97,58.62,12.90;1,128.52,140.56,338.19,10.75">Mining Specific and General Features in Both Positive and Negative Relevance Feedback QUT E-Discovery Lab at the TREC&apos;09 Relevance Feedback Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9425851DA29F21F992FC02D3164A5581</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>User relevance feedback is usually utilized by Web systems to interpret user information needs and retrieve effective results for users. However, how to discover useful knowledge in user relevance feedback and how to wisely use the discovery knowledge are two critical problems. In TREC 2009, we participated in the Relevance Feedback Track and experimented a model consisting of two innovative stages: one for subject-based query expansion to extract pseudo-relevance feedback; one for relevance feature discovery to find useful patterns and terms in relevance judgements to rank documents. In this paper, the detailed description of our model is given, as well as the related discussions for the experimental results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Web users' personal interests and preferences can be drawn in their user profiles. In Web information gathering, user profiles are used by many works to search information for users according to their personal needs <ref type="bibr" coords="1,258.20,549.10,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="1,270.59,549.10,11.83,8.64" target="#b9">10]</ref>. However, effectively acquiring user profiles is difficult. To acquire user profiles, some techniques explicitly interview users <ref type="bibr" coords="1,73.93,584.96,15.27,8.64" target="#b12">[13]</ref>, some use user relevance feedback <ref type="bibr" coords="1,237.83,584.96,15.27,8.64" target="#b13">[14]</ref>. These mechanisms require user-effort in the user profile acquisition process. Attempting to release such burden from users, alternatively some automatic techniques have been developed to acquire user profiles from a collection of user personal information, for example, browsing history <ref type="bibr" coords="1,257.51,644.74,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="1,270.59,644.74,11.83,8.64" target="#b16">17]</ref>. User profiles acquired by such techniques, however, usually contain noise and uncertainties. Hence, a method to acquire user profiles effectively and efficiently (without the burden of user-effort) is an urgent need for personalized Web information gathering.</p><p>Relevance features describe what a user wants. They can be discovered from user relevance feedback. Over the years, pattern-based approaches have been expected to outperform term-based techniques when discovering relevance features. Patterns are more discriminative and carry more "semantics". However, according to information retrieval (IR) experiments, few significant improvements have been made by using pattern-based methods to replace term-based methods <ref type="bibr" coords="1,344.56,373.77,15.96,8.64" target="#b14">[15,</ref><ref type="bibr" coords="1,360.51,373.77,11.97,8.64" target="#b15">16]</ref>. When utilizing pattern mining techniques, people encountered two problems: (i) high frequent patterns are usually general, whereas specific patterns are usually with low frequency (this is because the measuring methods for pattern learning, such as "support" and "confidences", appeared unsuitable in the filtering stage <ref type="bibr" coords="1,472.24,433.55,15.12,8.64" target="#b10">[11]</ref>); (ii) negative user feedback is difficult to use when revising the features extracted from the positive user feedback. Relevance feature discovery is challenging <ref type="bibr" coords="1,425.88,469.41,15.77,8.64" target="#b9">[10,</ref><ref type="bibr" coords="1,442.95,469.41,11.83,8.64" target="#b11">12]</ref>.</p><p>Motivated by these challenges, we proposed a relevance feature discovery model and tested the model in the Relevance Feedback track in TREC 2009. This Relevance Feedback track was designed to evaluate a system's capacity of finding quality user relevance feedback, as well as its relevance feedback algorithms. Thus, two phases were conducted in the track corresponding to this design: (i) identifying a small number of documents for (pseudo) relevance feedback; (ii) running relevance feedback algorithms with relevance judgements. In accordance to the two phases, we participated with also a two-stage information filtering model: (i) subject-based query expansion for pseudo relevance feedback extraction; (ii) pattern-based relevance feature discovery using both positive and negative feedback. The model aimed to discover relevance features for Web user profile acquisition.</p><p>The first stage was to expend a query (topic) to retrieve pseudo relevance feedback. To expand queries, we used a subject ontology LCSH (Library of Congress Subject Head-ings). The ontology specified commonsense knowledge obtained by people through their experience and education, and was successfully evaluated in our prior work reported in <ref type="bibr" coords="2,60.97,111.34,15.27,8.64" target="#b17">[18]</ref>. Given a query, the topic-related subjects were extracted from the LCSH ontology. On the basis of these subjects, user background knowledge was discovered and a personalized ontology was constructed. Based on the personalized ontology and using an information gathering system, a training set (consisting of a positive and a negative subsets) was extracted from the ClueWeb09 Category-B corpus based on title search, and treated as pseudo relevance feedback.</p><p>At the second stage, relevance features were discovered from both positive and negative pseudo relevance feedback, using a model introduced in <ref type="bibr" coords="2,167.52,245.76,10.58,8.64" target="#b8">[9]</ref>. These relevance features consisted of high-level pattern features and low-level term features. Based on the high-level features, the low-level features were classified into three groups: positive specific terms, general terms, and negative specific terms. When applying negative patterns to revise the discovered features, we increased the weight of positive specific terms but declined that of negative specific terms. This feature revision went into a loop to optimize the relevance feature extraction. Finally, documents highly relevant to these relevance features were retrieved from the ClueWeb09 Category-B as the final submission results.</p><p>In this paper, the two-stage model and the related evaluation in TREC 2009 Relevance Feedback track are presented and discussed. Section2 introduces the subject-based query expansion, and Section 3 presents relevance feature discovery using positive and negative samples. After that, the evaluation results are discussed in Section 4. Finally, the last section makes conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Subject-Based Query Expansion for Pseudo Relevance Feedback</head><p>The first stage aims to automatically retrieve pseudo relevance feedback from the ClubWeb09 Category-B. Because there was only a limited number of terms in given topics, the key issue here was how to acquire user interest from the limited information. In this work, we utilized a world knowledge ontology to analyze the concepts in the given topics. For an incoming topic, the positive subjects were extracted from the ontology. Based on these subjects and their referring-to instances, user background knowledge was discovered and utilized to expand the given query terms and to search the ClueWeb09 Category-B for pseudo relevance feedback. The top five ranked results were considered relevance feedback from users. Figure <ref type="figure" coords="2,198.22,692.56,4.98,8.64" target="#fig_0">1</ref> illustrates the architecture of our Stage 1 process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">World Ontology and Instances</head><p>The world ontology was encoded from the Library of Congress Subject Headings<ref type="foot" coords="2,418.81,331.21,3.49,6.05" target="#foot_0">1</ref> , a library catalog system. The LCSH system is a categorization developed for organizing the large volumes of library collections and for retrieving information from the library. The references specified in LCSH for subject headings were encoded into the semantic relations associated with and linking the subjects, where Broader term/Narrower term were for is-a, Usedfor for part-of, and related-to for related-to relations. The LCSH ontology contained about 400,000 topical, geographical, and corporate subjects.</p><p>The LCSH ontology was populated using the instances encoded from the information items in a library catalog <ref type="foot" coords="2,538.64,462.95,3.49,6.05" target="#foot_1">2</ref> . Figure <ref type="figure" coords="2,337.19,476.57,4.98,8.64">2</ref> illustrates a sample information item for instances. The descriptive information, such as the title and table of contents, are the knowledge resource extensive from the LCSH ontology. Such descriptive information was used for the content of an instance. A list of indexed content-based descriptors (subjects) is cited by each item (instance). Thus, we could have a matrix constructed by instances and subjects. Each instance may cite a list of subjects, and each subject may refer to a list of instances. Based on this matrix, the belief (bel) of an instance to a subject can be determined:</p><p>bel</p><formula xml:id="formula_0" coords="2,372.96,604.01,119.13,22.31">(i, s) = 1 index(s, i) × |η(i)| ;</formula><p>where η(i) is the set of subjects cited by i, index(s, i) is the index (starting with one) of s on the citing list. Us-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. An Instance from A Library Catalog Item</head><p>ing the instance displayed in Fig. <ref type="figure" coords="3,192.10,372.33,4.98,8.64">2</ref> as a sample, let i be this instance; s be the subject Consumption (Economics)-Germany (East). We have index(s, i) = 1 and |η(i)| = 4, and can thus calculate bel(i, s) = 0.25. The less subjects cited by an instance and the higher index a subject on a citing list, the stronger belief the instance holds to the subject. The bel(i, s) will be used to select the right instances to populate the LCSH ontology.</p><p>A method, specificity <ref type="bibr" coords="3,150.47,472.67,15.77,8.64" target="#b17">[18,</ref><ref type="bibr" coords="3,167.61,472.67,13.28,8.64" target="#b18">19]</ref> (denoted as spe), was further utilized to measure the focus of a subject in the LCSH ontology. The subjects located at upper bound levels in the ontology are more abstractive than those at lower bound levels towards the "leaves". Also, upper bound level subjects have more descendant subjects in shadow, in comparison with lower bound level subjects. Thus, an upper bound subject has weaker focus than a lower bound subject in its shadow.</p><p>The spe value of a subject s is determined by analyzing its associated hierarchical relations of is-a and part-of. By setting the spe value for "leave" subjects as 1, toward the root of the ontology, the spe value decreases for each level up. If a subject has all direct child subjects in shadow with is-a relationship, the smallest spe of its child subjects is chosen for the subject's spe value by decreasing 10%. If a subject has all direct child subjects in shadow with part-of relationship, its spe is defined as the average spe value of its child subjects, applying the 10% decreasing rate. If the direct child subjects in shadow are mixed with is-a and part-of relations to their parent subject, two spes are calculated: one for is-a child subjects, and one for part-of subjects. The smaller spe is then chosen to value the spe of the parent subject. As a result, the specificity of a upper bound subject is guaranteed smaller than that of a lower bound subject in its shadow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interesting Subject Discovery</head><p>Given a topic T := {t 1 , t 2 , . . . , t n }, two sets of subjects were extracted from the LCSH ontology: positive subjects S + being relevant to the topic; and negative subjects S - being paradoxical or ambiguous to the topic. If a subject's label contains any keywords in the topic (label(s) ∩ T = ∅), this subject is extracted and put into the initial positive subject set (S + = S + ∪ {s}). The positive level of s to T is thus measured by</p><formula xml:id="formula_1" coords="3,308.86,585.51,234.93,71.67">pos(s, T ) = spe(s) × |label(s) ∩ T | × i∈η -1 (s) sup(i, T ) where sup(i, T ) = s ∈η(i) bel(i, s ) × |label(s ) ∩ T |</formula><p>as defined previously, η(i) refers to the set of subjects cited by i, and η -1 (s) gives the set of instances citing s.</p><p>The reachable ancestor and descendant subjects of s in the ontology were also extracted. The "reachable" here is limited to the distance of three edges in the ontology. The subjects located more than that distance are unlikely important to T , as reported by <ref type="bibr" coords="4,148.79,99.39,10.58,8.64" target="#b5">[6]</ref>. These reachable subjects were extracted and put into the negative subject set (S -).</p><p>User background knowledge was discovered from the reference between the subjects and their instances. Let s 1 ∈ S + and s 2 ∈ S -. If η -1 (s 1 ) ∩ η -1 (s 2 ) = ∅, s 1 and s 2 have something in common and are relevant. The certainty level of s 2 being positive was thus determined by its linked positive subjects (e.g. s 1 ∈ S + ). A subject is more interesting if it has more linked positive subjects. Let S(s) be the set of linked positive subjects of s ∈ S -, we measure the certainty level of s to T by:</p><formula xml:id="formula_2" coords="4,50.11,241.33,230.70,72.92">pos(s, T |s ∈ S -) = s ∈ S(s) conf (s , s) × pos(s , T ) | S(s)| where conf (s , s) = |η -1 (s ) ∩ η -1 (s)| η -1 (s )</formula><p>Considering such discovered user background knowledge, if a s ∈ S -has pos(s, T ) &gt; 0, it would be removed from S -and replaced to S + .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query Expansion for Pseudo Relevance Feedback Extraction</head><p>The query terms were expanded based on the positive subjects discovered in the previous section. In Section 2.2, a set of positive subjects S + was discovered, in which each subject was assigned a pos value indicating the certainty level of the subject being relevant to the given topic. In Section 2.1, we know that a subject refers to a set of instances. Thus, a training set D + could be generated, in which each document d was from the content of an instance i referred to by a positive subject s ∈ S + . A support value was calculated for each document in the training set, by accumulating all pos values of the subjects on the citing list of the instance. The expanding terms were extracted from the training set.</p><p>The training set was first used to evaluate weights for a set of selected terms T . After text pre-processing of stopword removal and word stemming, the semantic space referred to by a d was represented by its normal form β(d) = {(t 1 , w 1 ), (t 2 , w 2 ), . . . , (t k , w k )}, where w is the weight distribution of terms and w i = fi k j=1 fj and f i is the term frequency of t i in d. A probability function on T was derived based on the normal form of positive documents and their supports for all t ∈ T : The terms with top 150 pr β (t) values were then selected to expand the query terms given in T . The details of evaluation can be referred to <ref type="bibr" coords="4,399.32,316.86,15.27,8.64" target="#b9">[10]</ref>.</p><formula xml:id="formula_3" coords="4,83.40,693.98,169.41,20.61">pr β (t) = d∈D + ,(t,w)∈β(d) support(d) × w</formula><p>The documents in the ClueWeb09 corpus were indexed by accumulating the pr β (t) of the expanded top 150 terms that occurred in the document titles. Because ClueWeb09 Category-B is a large corpus, in order to reduce the complexity, only the title of documents counted into this index calculation. The top five indexed documents were chosen as the pseudo relevance feedback from users, and submitted as the results for Phase 1 of the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relevance Feature Discovery</head><p>Relevance feature discovery aims to discover a set of features from text documents to describe what a user wants. In Phase 2 of TREC'09 Relevance Feedback track, a given topic was represented by a set of user judgements containing documents associated with values of 0, 1, or 2, indicating being non-relevant, relevant, and highly relevant to the topic, respectively. Treating the documents associated with 1 and 2 as equally positive and those with 0 negative, we had two different sets: positive and negative feedback. In this Stage 2 method, relevance features were to be discovered from both of the positive and negative relevance feedback.</p><p>When generating the positive and negative feedback, two special problems were encountered: (i) positive feedback was unavailable because all judgements were with 0 (nonrelevant). For this problem, we formed a positive document by using the query terms expanded in Stage 1 (as discussed in Section 2.3), and weighted these terms equally as 1; (ii) negative feedback was unavailable because all judgement were with 1 or 2. For this problem, we used only positive feedback for feature discovery. The pattern-based features were first extracted from the positive user feedback. After that, these features were used to iteratively select and re-select meaningful negative documents (called offenders in this paper) from the negative feedback. These offenders were used to revise the extracted features. Finally, the revised features were used to retrieve the final results from the ClueWeb09 Subset-B. Figure <ref type="figure" coords="5,269.96,281.23,4.98,8.64" target="#fig_1">3</ref> illustrates the architecture of our model in Stage 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Frequent and Closed Sequential Patterns</head><p>For a given topic, relevance feature discovery extracts from a document set a set of features, including patterns and terms, and assigns them weights. The document set, usually called a training set and denoted as D, consists of a set of positive documents (D + ) and a set of negative documents (D -). When splitting a document into paragraphs, a document d can also be represented by a set of paragraphs P S(d).</p><p>Let T = {t 1 , t 2 , . . . , t m } be a set of terms extracted from D + ; X be a set of terms (called a termset) in document d. coverset(X) denotes the covering set of X for d, which includes all paragraphs dp ∈ P S(d) where X ⊆ dp, i.e., coverset(X) = {dp|dp ∈ P S(d), X ⊆ dp}. The absolute support of X is the number of occurrences of X in P S(d): sup a (X) = |coverset(X)|. The relative support of X is the fraction of the paragraphs that contain the pattern:</p><formula xml:id="formula_4" coords="5,71.97,543.24,100.00,14.38">sup r (X) = |coverset(X)| |P S(d)|</formula><p>. A termset X is then called a frequent pattern if its sup a (or sup r ) ≥ min sup, a minimum support.</p><p>Table <ref type="table" coords="5,86.37,583.26,4.98,8.64" target="#tab_0">1</ref> lists a set of paragraphs for a document d, where P S(d) = {dp 1 , dp 2 , . . . , dp 6 } with duplicate terms removed. Assume min sup = 3, ten frequent patterns would be extracted as shown in Table <ref type="table" coords="5,174.52,619.12,3.74,8.64" target="#tab_1">2</ref>.</p><p>Given a set of paragraphs Y ⊆ P S(d), we can also define its termset, which satisfies</p><formula xml:id="formula_5" coords="5,88.16,663.21,160.16,8.74">termset(Y ) = {t|∀dp ∈ Y ⇒ t ∈ dp}.</formula><p>By defining the closure of X as: Let X be a closed pattern. We have</p><formula xml:id="formula_6" coords="5,97.45,704.20,141.58,8.74">Cls(X) = termset(coverset(X))</formula><formula xml:id="formula_7" coords="5,381.51,323.77,163.60,9.65">sup a (X 1 ) &lt; sup a (X)<label>(1)</label></formula><p>for all patterns X 1 ⊃ X.</p><p>A taxonomy can be constructed by using closed patterns with is-a (or subset) relations. A sequential pattern s =&lt; t 1 , . . . , t r &gt; (t i ∈ T ) is an ordered list of terms. Denoted by s 1 s 2 , a sequence s 1 =&lt; x 1 , . . . , x i &gt; is a sub-sequence of s 2 =&lt; y 1 , . . . , y j &gt;, iff ∃j 1 , . . . , j i such that 1 ≤ j 1 &lt; j 2 . . . &lt; j i ≤ j and x 1 = y j1 , x 2 = y j2 , . . . , x i = y ji . Given s 1 s 2 , we call s 1 a sub-pattern of s 2 , and s 2 a super-pattern of s 1 . To simplify the explanation, we refer to sequential patterns as patterns.</p><p>As the same as those defined for normal patterns, we define the absolute support and relative support for a pattern (an ordered termset) X in d. We also denote the covering set of X as coverset(X), which includes all paragraphs ps ∈ P S(d) such that X ps, i.e., coverset(X) = {ps|ps ∈ P S(d), X ps}. X is then called a frequent pattern if sup r (X) ≥ min sup. By using Eq. ( <ref type="formula" coords="5,491.03,680.60,3.53,8.64" target="#formula_7">1</ref>), a frequent sequential pattern X is closed if any super-pattern X 1 of X such that sup a (X 1 ) = sup a (X).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Deploying High-Level Patterns on Low-Level Terms</head><p>To overcome the problem of patterns with lowfrequency, a method was developed to deploy high level patterns over low-level terms. The evaluation of term supports (weights) in this paper is different from that in termbased approaches. For a term-based approach, the value of a term is scaled based on its appearance in documents. In our method, the value of terms are scaled based on their appearance in discovered patterns.</p><p>To improve the efficiency of the pattern taxonomy mining (PTM), an algorithm, SPMining(D + , min sup), was introduced by <ref type="bibr" coords="6,107.93,229.97,16.60,8.64" target="#b20">[21]</ref> and further developed in <ref type="bibr" coords="6,227.43,229.97,15.77,8.64" target="#b10">[11,</ref><ref type="bibr" coords="6,244.58,229.97,13.28,8.64" target="#b19">20]</ref> to find closed sequential patterns from positive documents D + . The SPMining algorithm used the well-known Apriori property to narrow down the searching space.</p><p>Let SP 1 , SP 2 , ..., SP n be the sets of discovered closed sequential patterns for all documents</p><formula xml:id="formula_8" coords="6,50.11,287.85,236.25,22.49">d i ∈ D + (i = 1, • • • , n), where n = |D + |.</formula><p>For a given term t, its weight in discovered patterns is assigned by:</p><formula xml:id="formula_9" coords="6,93.54,327.69,188.95,30.49">w(t, D + ) = n i=1 t∈p⊆SPi sup r (p, d i ) |p| (<label>2</label></formula><formula xml:id="formula_10" coords="6,282.49,338.42,3.87,8.64">)</formula><p>where |p| is the number of terms in p.</p><p>With weights assigned to the terms in D + , a function can be used to rank and judge the relevance of incoming documents:</p><formula xml:id="formula_11" coords="6,113.75,418.99,108.97,20.06">rank(d) = t∈T w(t)τ (t, d)</formula><p>where w(t) = w(t, D + ); and τ (t, d) = 1 if t ∈ d, otherwise τ (t, d) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mining Negative Patterns for Revising Low-Level Features</head><p>In general speaking, the definition of relevance is subjective. People may describe the relevance of a topic (or a document) in two dimensions, specificity and exhaustivity, where specificity describes the focus of the topic on what users want, and exhaustivity describes the extent of the topic dealing what users want. Such two-dimension description is easy for human beings to use, however, difficult for a computational system to apply. In this section, we first discuss how to use the two dimensions to understanding the semantic meanings of low-level feature terms. We also present an algorithm for negative pattern discovery and term weight revision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Specific and General Features</head><p>Let DP + be the union of all patterns in pattern taxonomies discovered from D + , and DP -be the union of all negative patterns in the pattern taxonomies discovered from D -. A closed sequential pattern of D + (or D -) is called a positive pattern (or negative pattern).</p><p>Given a term t ∈ T , its exhaustivity refers to the number of discovered patterns containing t in both DP + and DP -, and its specificity refers to the number of discovered patterns containing t in only DP + but not DP -. Based on these, we can classify terms into three groups: general terms (GT ,) for those appearing in both positive patterns and negative patterns; positive specific terms (T + ) for those appearing in only positive patterns; negative specific terms (T -) for those appearing in only negative patterns. They are defined by:</p><formula xml:id="formula_12" coords="6,308.86,238.69,238.39,33.09">GT = {t|(∃p 1 ∈ DP + )∧(∃(p 2 ∈ DP -) ⇒ t ∈ (p 1 ∩p 2 )}, T + = {t|t / ∈ GT, ∃(p ∈ DP + ) ⇒ t ∈ p},<label>and</label></formula><formula xml:id="formula_13" coords="6,308.86,279.35,202.13,29.18">T -= {t|t / ∈ GT, ∃(p ∈ DP -) ⇒ t ∈ p} where GT ∩ T + ∩ T -= ∅.</formula><p>Specific terms contain more semantic meanings and distinguish a topic from others. Thus, specific terms are useful to describe the relevance feature of a topic. However, using specific terms alone may be insufficient when trying to improve the performance of relevance feature discovery. Documents containing no specific terms may also highlight user information needs as well. Therefore, one possible solution is to use the hybrid of specific terms, general terms, and negative terms. However, adequate control is necessary for the side effects generated by using general terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Revision Strategy</head><p>In this section, we discuss the basic strategies of revising the features discovered from a training set. This feature revising process takes place only after terms are classified into three categories of general, positive specific, and negative specific terms.</p><p>From the positive documents in a training set, the revising process first discovers initial positive features including high-level positive patterns and low-level terms. Selecting some negative samples from the negative documents in the training set, the process also discovers negative patterns and terms by using the same pattern mining technique as that used for positive feature discovery. The process then revises the initial features to obtain revised features. This process can be repeated several times: selecting negative documents, mining negative features and revising revised features.</p><p>Algorithm NFMining(D) describes the details of the the revision strategy, with an assumption that the number of negative documents is greater than the number of positive documents. For a given training set D = {D + , D -}, we assume that the initial features, (DP + , DP -, T ), have been  extracted from positive documents D + before the algorithm starts, where T = {t ∈ p|p ∈ DP + } and DP -= ∅. The experimental parameter is set as α = -1 to calculate the weights of terms in negative patterns.</p><p>Step 1 initializes the sets of general terms GT , positive specific terms T + , and negative specific terms T -. loop is used to control the number of revision cycles. Step 2 and 3 compute weights for all terms in T . Table <ref type="table" coords="7,221.83,619.23,4.98,8.64" target="#tab_3">3</ref> shows a set of terms and their weights deploying from positive patterns. In experiments, when positive documents were unavailable, a set of 100 terms with weight set to 1 from query expansion (as discussed in Section 2.3) were used as positive terms.</p><p>Steps 4 and 5 rank documents in the negative document set. If t is a negative specific term, its has an revising weight evaluated in step 10 and 11. The weight function is de-scribes as:</p><formula xml:id="formula_14" coords="7,326.05,90.91,195.70,34.92">weight(t) =    its revising weight, if t ∈ T - support(t, D + ), otherwise</formula><p>Steps 6 and 7 sort the negative documents based on their rank values, and select offenders (meaningful negative documents). A document is considered negative to the topic if it is ranked lower than or equal to 0. For the first loop the minimum weight that we can get is 0 because there is no negative weight in the term set T . However, from the next loop some negative terms from D -with negative weight are added. Then it is most likely to get weight less than 0. If a document has a high rank, the document is selected as an offender because it forces the system to make a mistake. The offenders are normally defined as the top-K negative documents in sorted D - <ref type="bibr" coords="7,414.70,268.40,15.27,8.64" target="#b9">[10]</ref>. Given that positive documents are the main source of features, we expect the total number of offenders not more than the positive documents. Therefore, we set K = |D + | 3 in our experiments. In the first revision (loop = 0), where T contains only positive terms and no negative terms having added yet, the top-j negative documents are omitted for offender selection. The initial features come from positive documents only, and the positive features are more important than negative features at the beginning. An experimental parameter σ is used here and set as σ = |D -| |D + | . To be clear, Table <ref type="table" coords="7,398.55,405.64,4.98,8.64" target="#tab_3">3</ref> and 4 are used as an example for the selection of offenders process. Table <ref type="table" coords="7,477.71,417.59,4.98,8.64" target="#tab_4">4</ref> shows a list of ranked negative documents using the terms appearing in Table <ref type="table" coords="7,325.15,441.50,3.74,8.64" target="#tab_3">3</ref>. The first step is to eliminate the documents with weight less than or equal 0. Thus, d 6 , d 7 from Table <ref type="table" coords="7,513.07,453.46,4.98,8.64" target="#tab_4">4</ref> are ignored for offenders. For the sample shown on Table <ref type="table" coords="7,514.15,465.41,4.98,8.64" target="#tab_3">3</ref> and<ref type="table" coords="7,537.64,465.41,3.74,8.64" target="#tab_4">4</ref>, the number of training documents is 13 with a distribution of |D + | = 6 and |D -| = 7. Therefore, K = 6 3 = 2 and if (loop = 0) then j = σ = 7 6 = 1; otherwise, j = 0. After that, started from j + 1 and counting for K documents, the documents in this range are selected as offenders. As a result d 3 , d 4 from Table <ref type="table" coords="7,414.24,537.14,4.98,8.64" target="#tab_4">4</ref> are selected as offenders at the first loop (loop = 0). In the second and third loops the same process is repeated with j = 0 and the updated list of terms is used.</p><p>Steps 8 and 9 extract negative features (DP -, T 0 ) from selected negative documents D - 3 . The SPMining(D - 3 , min sup) algorithm is employed to discover negative patterns DP -and T 0 , including all terms in patterns of DP -. Table <ref type="table" coords="7,375.91,632.78,4.98,8.64" target="#tab_5">5</ref> shows a list of terms extracted from offenders.</p><p>Steps 10 to 12 revise the weights for negative specific terms. These steps go three times through a loop with the iteration controlled by Step 13. In each loop, if a specific negative term is extracted at the first time, the algorithm negates its support obtained from the selected negative doc- uments; otherwise, the algorithm cumulates its weight as follows:</p><formula xml:id="formula_15" coords="8,73.09,374.77,190.29,13.03">weight(t) = α × weight(t, D - 3 ) + weight(t).</formula><p>After three loops, the algorithm partitions T into general terms GT and positive specific terms T + at Step 14 and 15. It also revises positive specific term weights using the following equation in Step 16 and 17:</p><formula xml:id="formula_16" coords="8,55.09,454.56,231.27,23.89">weight(t) = weight(t) × (1 + |{d|d ∈ D + , t ∈ d}| |D + | )<label>(3)</label></formula><p>Finally, T is updated to include negative specific terms at Step 18.</p><p>Table <ref type="table" coords="8,87.45,514.45,4.98,8.64" target="#tab_3">3</ref> and 5 show a set of terms extracted from positive documents and offenders. The method introduced in Section 2.3 is again used to classify those terms into three main groups: specific positive, specific negative, and general terms:</p><formula xml:id="formula_17" coords="8,81.88,581.92,172.72,53.76">T + = { t 2 0.90 , t 4 0.65 , t 5 0.75 , t 6 0.84 } T -= { t 7 -0.50 , t 8 -0.75 } G = { t 1 (0.34, -0.20) , t 3 (0.65, -0.45) }</formula><p>The terms in T + and T -have only one weight. However, the terms in general group G have two weights: the first one is for the term occurred in D + ; the second one is for the term occurred in offenders D - 3 . Because the group T + is more important than T -and G, the weight of a t ∈ T + is awarded by Eq. ( <ref type="formula" coords="8,179.99,704.51,3.87,8.64" target="#formula_16">3</ref>) based on t's appearance on positive documents. For negative terms T -, the term weights are updated via a three-loops technique as shown at Step 11. The groups of terms with updated weights are:</p><formula xml:id="formula_18" coords="8,321.31,114.28,100.47,13.22">T + = { t 2 1.8=0.90 * (1+<label>6</label></formula><p>6 ) , t 4 1.19 , t 5 1.5 , t 6 1.12 } T -= { t 7 -0.50 , t 8 -0.75 } G = { t 1 0.34 , t 3 0.65 } NFMining calls three times SPMining. The total number of negative documents used in these three times equals O(|D + |). Therefore, NFMining for mining negative patterns has the same complexity as the SPMining for mining positive patterns in D + . NFMining also takes times for sorting D -, assigning weights to terms, and partitioning terms into categories. The time complexity for these operations is</p><formula xml:id="formula_19" coords="8,308.86,248.40,131.91,11.96">O(|D -|(log |D -| + |T |) + |T | 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Final Retrieval</head><p>Given a topic, the feature terms are extracted by using Algorithm NFMining and assigned with a value weight(t), as discussed previously. These features were used in our experiments to perform the final retrieval. Because the volume of ClueWeb09 Category-B corpus is huge, the final retrieval was separated to two steps in order to reduce the complexity.</p><p>At the first step, for each topic we retrieved about 30,000 candidate documents based on only title search from the ClueWeb09 Category-B corpus. The process of query expansion (discussed in Section 2.3) was reused here for candidate retrieval. In our investigation on the results of Phase 1 submission, a limitation was exposed that the knowledge specified in the world ontology was not up-to-date. The LCSH system used for ontology construction was the 2006 version. As a result, the ontology missed some up-to-date knowledge, e.g., that about "Obama" and "Obama family tree". In order to solve this problem, at Stage 2 we used world knowledge extracted from the Web using Google API. For each topic, ten Web documents were retrieved and pooled with the training set generated from the instances (library catalog). As discussed in Section 2.3, a set of expanding query terms was then extracted and used for candidate retrieval. Finally, approximately 30,000 candidate documents were retrieved from the Category-B corpus by accumulating the pr β (t) of the terms that occurred in the document titles.</p><p>In the next step, we filtered the candidates based on document contents using the features discovered from positive and negative judgements, as discussed previously. The 30,000 candidates were re-ranked by accumulating the weight(t) of features (see Algorithm NFMining) that occurred in document contents. After that, the top 1,000 documents were selected and submitted as the final retrieved results against the given topic. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussions</head><p>As discussed previously, the Relevance Feedback track was designed to evaluate a system's capacity of finding quality user relevance feedback and utilizing relevance judgement. In Phase 1, each group submitted five documents for (pseudo) relevance feedback; in Phase 2, groups ran their relevance feedback algorithms based on different sets of judged docs from Phase 1, including their own Phase 1 docs, and several other groups' Phase 1 documents. Evaluation then compared the intrinsic quality of the Phase 1 feedback, as well as each group's relevance feedback algorithm.</p><p>Four methods, εMap <ref type="bibr" coords="9,148.35,535.77,10.58,8.64" target="#b0">[1]</ref>, MapA, P10A, and StatAP <ref type="bibr" coords="9,272.25,535.77,10.58,8.64" target="#b1">[2]</ref>, were used in the track to measure the performance of Phase 2 runs. εMap and StatAP were applied to the runs using the testing set of only ClueWeb09 Category-B, whereas MapA and P10A were applied to those using the whole ClueWeb09 English set. Because our experiments were based on only ClueWeb09 Category-B, measuring our performance by MapA and P10A might not give us an adequate, substantial analysis. Thus, we investigated our results with only the εMap and StatAP in this discussion.</p><p>The quality of a set of Phase 1 extracted documents could be marked if more groups using the set in Phase 2 had better performance than using other Phase 1 sets, when applying to the same relevance feedback algorithm. Table <ref type="table" coords="9,253.34,692.56,4.98,8.64" target="#tab_6">6</ref> shows the detailed results for the evaluation of our Phase 1 re-sults. In each εMap or StatAP column, the first digit shows the number of runs that using our Phase 1 set was outperformed by using another groups' Phase 1 sets, whereas the second digit shows the number of runs that using ours outperformed using others. Therefore, a larger deviation of two digits indicates higher quality of our pseudo relevance feedback retrieved in Phase 1 when the second digit is greater than the first. In Table <ref type="table" coords="9,404.24,456.55,3.74,8.64" target="#tab_6">6</ref>, those tie or wining comparisons are flagged by the bold, italic font. In terms of εMap performance, using our Phase 1 retrieved feedback was better then (or equal to) using other groups' retrieved feedbacks in 23 out of 49 topics (Topic 20 was dropped because it had no relevant docs). In terms of StatAP, the tie or wining topic number is 24 out of 49. In overall εMap performance of counting 49 topics, the number of runs our Phase 1 set was better than is 16, much more than the number of runs (9) our Phase 1 set was worse than. In overall StatAP performance, the two numbers in the pair is quite close (13 vs. 12). Base on the results, the pseudo relevance feedback retrieved by our group in Phase 1 had a relatively high quality. This is also confirmed by the performance comparisons illustrated in Fig. <ref type="figure" coords="9,382.66,623.92,3.74,8.64">4</ref>, where our submission (QUT.1) is indexed in a middle position (ahead of 16 groups but behind 13 groups). Out system's capacity of finding quality user relevance feedback is encouraging.</p><p>Phase 2 evaluated a system's performance of using relevance judgement for retrieval. The Stage 2 in our model was to use both positive and negative feedback judgements for information retrieval. Though many reports suggested that negative relevance judgements were useless or of a little help <ref type="bibr" coords="11,81.68,99.39,11.54,8.64" target="#b3">[4,</ref><ref type="bibr" coords="11,93.22,99.39,7.69,8.64" target="#b4">5,</ref><ref type="bibr" coords="11,100.91,99.39,7.69,8.64" target="#b6">7]</ref>, this idea has been successfully tested in our previous work <ref type="bibr" coords="11,109.05,111.34,11.62,8.64" target="#b8">[9]</ref> on an experimental environment setup by Reuters Corpus Volume 1 (RCV1) corpus <ref type="bibr" coords="11,216.78,123.30,11.62,8.64" target="#b7">[8]</ref> and TREC filtering track. The work showed that the method significantly outperformed both the state-of-the-art term-based methods underpinned by Okapi BM25 or Support Vector Machine and pattern based methods on precision, recall and F measures. However, in this track our Phase 2 performance was unsatisfactory, according to the comparison plotted in Fig. <ref type="figure" coords="11,69.27,206.98,3.74,8.64">5</ref>. In our investigation, we found that the unsatisfactory performance was largely caused by the difficulties encountered when coping with the large testbed, ClueWeb09 Category-B.</p><p>Performing content search in ClueWeb09 Category-B for each topic was time and computational resource consuming that we could not afford, according to the track's tough schedule and our accessible resources. ClueWeb09 Category-B is a huge corpus with 1.5 terabyte data, approximate 45,000,000 documents. Pre-processing of ClueWeb09 Category-B required investment of a large amount of time and use of high performance computer. Unfortunately, as the first time in our lab to deal with the High Performance Computer (HPC) Centre in QUT, the poor collaboration and the shortage of HPC experience stole a large amount of our time. As a result, time became against us in the experiments. Consequently, in order to simplify the complexity in maximum with only minimal sacrifice of effectiveness, as discussed in Section 3.4 we separated the Phase 2 search into two steps: for each topic, (i) retrieving about 30,000 candidates from ClueWeb09 Category-B based on only title search; (ii) re-ranking those candidates based on contents and submitting the top 1,000 documents as the final results. We expected with 30,000 candidates we could have only a limited portion of relevant documents missing. However, as shown on Fig. <ref type="figure" coords="11,109.39,509.55,3.74,8.64">5</ref>, the final result of Phase 2 was disappointing.</p><p>The evaluation methods and our Stage 2 method have a basic difference on term weight evaluation. This may also cause the disappointing result in Phase 2. εMap and StatAP are term-based methods that evaluate term weights based on term distribution in documents. Due to the large volume, the ClueWeb09 corpus does not have precise judgements for the testing set (like those manual judgements in RCV1 for topics R101-R150 in TREC 11 Filtering track). In order to test a relevance feedback method, based on term-based algorithms, εMap and StatAP computationally judged the testing set. However, our Stage 2 method is pattern-based. Term weights are evaluated based on term distribution in discovered patterns rather than that in documents (as discussed in Section 3). Therefore, there may exist a problem that the performance of our pattern-based method could be underestimated when using term-based computational judgements to measure. This problem actually happened in our previous experiments: when using RCV1's manual judgements (topics R101-R150), this pattern-based Stage 2 method was largely succeed in the experiments and significantly improved the performance of an information filtering system from using Rocchio, BM25, and SVM <ref type="bibr" coords="11,353.89,159.16,10.79,8.64" target="#b8">[9]</ref>; however, such performance improvement became relatively slight when experimented with RCV1's computational judgements (topics R151-R200). Though at this stage it is still too early to justify this problem, it will be interesting to investigate this problem in our future work and test our pattern-based method with more data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper investigated a model that was experimented in the TREC 2009 Relevance Feedback track. The model had two stages, corresponding to the design of the track. Given a topic, the first stage of our model used a world knowledge ontology to discover user background knowledge for query expansion, and then retrieved the pseudo relevance feedback. From both the positive and negative user relevance judgements, the second stage method mined specific and general features, and used these features to benefit information retrieval. According to the evaluation results, the model performed well in Stage 1 but unsatisfactory in Stage 2. The unsatisfactory performance was caused by the difficulties in coping with the large ClueWeb09 Category-B corpus.</p><p>Our participation on this TREC 2010 Relevance Feedback track was an innovative exploration of using both positive and negative feedback judgements in information retrieval. The participation also demonstrated that using a world knowledge ontology is capable of discovering user background knowledge and improving information retrieval. In our future work, further investigation and experiments will be carried on based on full content search on ClueWeb09 Category-B, rather than half title-search half content-search in this reported experiment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,346.31,262.13,161.36,9.35;2,347.79,72.00,158.40,175.41"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The Stage 1 Architecture</figDesc><graphic coords="2,347.79,72.00,158.40,175.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,346.31,251.12,161.36,9.35;4,329.79,72.00,194.40,164.40"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The Stage 2 Architecture</figDesc><graphic coords="4,329.79,72.00,194.40,164.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,66.49,82.99,93.79,7.17;7,66.49,91.46,144.24,8.62;7,88.41,100.93,160.03,8.62;7,88.41,111.85,149.40,7.17;7,88.41,121.31,122.31,7.17;7,66.49,130.72,159.78,7.22;7,66.49,149.65,29.22,7.17;7,66.49,157.73,136.83,8.62;7,66.49,168.59,65.92,7.22;7,66.49,176.66,121.31,8.62;7,66.49,186.13,72.55,8.62;7,66.49,197.05,148.97,8.89;7,66.49,206.02,184.13,10.35;7,74.46,217.88,128.30,7.17;7,66.49,225.90,21.61,9.38;7,82.11,226.66,124.69,10.60;7,66.49,236.13,85.70,9.38;7,146.20,238.35,121.79,9.14;7,66.49,246.37,194.51,9.16;7,66.49,257.23,95.92,7.77;7,66.49,265.30,192.93,9.38;7,253.42,267.52,9.78,9.15;7,84.42,275.54,124.88,9.32;7,203.31,277.75,57.35,9.15;7,66.49,285.77,128.41,9.16;7,66.49,296.63,106.35,7.22;7,66.49,306.09,119.94,7.22;7,66.49,314.17,136.52,8.62;7,86.41,323.64,73.22,8.56;7,66.49,333.11,75.99,8.62;7,66.49,347.26,128.26,7.17;7,197.83,342.78,52.83,7.06;7,216.09,351.18,16.32,6.26;7,251.86,347.26,5.51,6.99;7,66.49,357.51,60.15,8.62"><head>Algorithm 1 . 1 :</head><label>11</label><figDesc>NFMining(D)Input: A training set, {D + , D -}, α = -1;extracted features (DP + , DP -, T ), DP -= ∅; support function, minimum support min sup, and experimental parameters K and σ. Output: Updated term set T and function weight.Method: GT = ∅, T + = ∅, T -= ∅, loop = 0; 2: foreach t ∈ T do 3: weight(t) = weight(t, D + ); 4: foreach d ∈ D -do 5: rank(d) = Σ t∈d∩(T ∪T -) weight(t); 6: let D -= {d 0 , d 1 , ..., d |D -|-1 } in descendent order, let j = σ if loop = 0, otherwise j = 0; 7: D - 3 = {d i |d i ∈ D -, j ≤ i &lt; K + j}; 8: DP -=SPMining(D -3 , min sup); //find negative patterns 9: T 0 = {t ∈ p|p ∈ DP -}; // all terms in negative patterns 10:foreach t ∈ (T 0 -T ) do 11: if (loop = 0) then weight(t) = α × weight(t, D - 3 ) else weight(t) = α × weight(t, D - 3 ) + weight(t); 12: T -= T -∪ (T 0 -T ),loop + +; 13: if loop &lt; 3 then goto step 4; 14: foreach t ∈ T do //term partition 15: if (t ∈ T -) then GT = GT ∪ {t} else T + = T + ∪ {t}; 16: foreach t ∈ T + do 17: weight(t) = weight(t) × (1 + |{d|d∈D + ,t∈d}| |D + | ); 18: T = T ∪ T -;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,194.60,353.64,206.02,9.35;10,106.81,91.86,381.60,247.05"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>Figure 4. Phase 1 Performance Comparison</figDesc><graphic coords="10,106.81,91.86,381.60,247.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,153.61,72.00,288.01,252.85"><head></head><label></label><figDesc></figDesc><graphic coords="3,153.61,72.00,288.01,252.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,102.02,82.04,132.43,94.10"><head>Table 1 . A set of paragraphs</head><label>1</label><figDesc></figDesc><table coords="5,110.30,94.35,120.23,81.78"><row><cell>P aragraph</cell><cell>T erms</cell></row><row><cell>dp 1</cell><cell>t 1 t 2</cell></row><row><cell>dp 2</cell><cell>t 3 t 4 t 6</cell></row><row><cell>dp 3</cell><cell>t 3 t 4 t 5 t 6</cell></row><row><cell>dp 4</cell><cell>t 3 t 4 t 5 t 6</cell></row><row><cell>dp 5</cell><cell>t 1 t 2 t 6 t 7</cell></row><row><cell>dp 6</cell><cell>t 1 t 2 t 6 t 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,308.86,82.04,236.25,204.71"><head>Table 2 . Frequent patterns and covering sets</head><label>2</label><figDesc>F requent P attern Covering Set {t 3 , t 4 , t 6 } {dp 2 , dp 3 , dp 4 } {t 3 , t 4 } {dp 2 , dp 3 , dp 4 } {t 3 , t 6 } {dp 2 , dp 3 , dp 4 } {t 4 , t 6 } {dp 2 , dp 3 , dp 4 } {t 3 } {dp 2 , dp 3 , dp 4 } {t 4 } {dp 2 , dp 3 , dp 4 } {t 1 , t 2 } {dp 1 , dp 5 , dp 6 } {t 1 } {dp 1 , dp 5 , dp 6 } {t 2 } {dp 1 , dp 5 , dp 6 } {t 6 } {dp 2 , dp 3 , dp 4 , dp 5 , dp 6 }</figDesc><table /><note coords="5,308.86,266.06,236.25,8.96;5,308.86,278.01,34.95,8.74"><p>a pattern (or termset) X is closed if and only if X = Cls(X).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,308.86,381.80,236.25,120.20"><head></head><label></label><figDesc>Table 2 contains three closed patterns, &lt; t 3 , t 4 , t 6 &gt;, &lt; t 1 , t 2 &gt;, and &lt; t 6 &gt;, within ten frequent patterns. After pruning the non-closed patterns, a pattern taxonomy P T can be constructed, like P T = { t 3 , t 4 , t 6 , t 1 , t 2 , t 6 } in Table 2 when considering t 6 a subset of t 3 , t 4 , t 6 . Small patterns (e.g. t 6 ) in a taxonomy are usually general because they have more chance to be used frequently. Vice versa, large patterns (e.g. t 3 , t 4 , t 6 ) are relatively specific because they usually have a low frequency.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,62.07,396.83,212.34,98.59"><head>Table 3 . Example of a set of terms discovered from</head><label>3</label><figDesc></figDesc><table coords="7,78.97,421.41,189.74,74.02"><row><cell>term</cell><cell cols="2">weight # of docs that include the term</cell></row><row><cell>t1</cell><cell>0.34</cell><cell>4</cell></row><row><cell>t2</cell><cell>0.90</cell><cell>6</cell></row><row><cell>t3</cell><cell>0.55</cell><cell>3</cell></row><row><cell>t4</cell><cell>0.65</cell><cell>5</cell></row><row><cell>t5</cell><cell>0.75</cell><cell>6</cell></row><row><cell>t6</cell><cell>0.84</cell><cell>2</cell></row></table><note coords="7,86.77,409.17,14.92,8.74;7,103.08,407.60,6.12,6.12;7,109.69,408.78,20.46,9.35;7,131.54,407.60,6.12,6.12;7,140.92,409.17,17.66,8.74;7,158.85,407.60,6.12,6.12;7,168.24,408.78,31.50,9.35;7,200.01,407.60,6.12,6.12;7,206.63,409.17,23.80,8.74"><p>DP + , DP + ∈ D + and |D + | = 6.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,62.07,86.02,212.34,109.75"><head>Table 4 . A set of ranked negative documents with their weight,</head><label>4</label><figDesc>|D -| = 7.</figDesc><table coords="8,96.12,110.60,139.75,85.17"><row><cell></cell><cell>Negative documents</cell><cell>weight</cell></row><row><cell>1</cell><cell>d1</cell><cell>0.67</cell></row><row><cell>2</cell><cell>d2</cell><cell>0.60</cell></row><row><cell>3</cell><cell>d3</cell><cell>0.44</cell></row><row><cell>4</cell><cell>d4</cell><cell>0.34</cell></row><row><cell>5</cell><cell>d5</cell><cell>0.30</cell></row><row><cell>6</cell><cell>d6</cell><cell>0.00</cell></row><row><cell>7</cell><cell>d7</cell><cell>0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,62.07,233.59,212.34,74.29"><head>Table 5 . A set of terms discovered from of- fender documents.</head><label>5</label><figDesc></figDesc><table coords="8,131.74,255.78,73.00,52.10"><row><cell>terms</cell><cell>weight</cell></row><row><cell>t1</cell><cell>-0.20</cell></row><row><cell>t3</cell><cell>-0.45</cell></row><row><cell>t7</cell><cell>-0.50</cell></row><row><cell>t8</cell><cell>-0.75</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,156.45,73.52,282.33,276.00"><head>Table 6 . Evaluation of Phase 1 performance</head><label>6</label><figDesc></figDesc><table coords="9,156.45,73.52,282.33,254.09"><row><cell>Topic</cell><cell cols="2">εMap</cell><cell cols="2">StatAP</cell><cell>Score</cell><cell>Topic</cell><cell cols="2">εMap</cell><cell cols="2">StatAP</cell><cell>Score</cell></row><row><cell>1</cell><cell>13</cell><cell>11</cell><cell>12</cell><cell>12</cell><cell>0.371</cell><cell>26</cell><cell>5</cell><cell>19</cell><cell>9</cell><cell>16</cell><cell>0.6557</cell></row><row><cell>2</cell><cell>10</cell><cell>13</cell><cell>10</cell><cell>15</cell><cell>0.6613</cell><cell>27</cell><cell>16</cell><cell>9</cell><cell>16</cell><cell>9</cell><cell>0.3</cell></row><row><cell>3</cell><cell>4</cell><cell>11</cell><cell>7</cell><cell>9</cell><cell>0.5676</cell><cell>28</cell><cell>16</cell><cell>9</cell><cell>21</cell><cell>4</cell><cell>0.2459</cell></row><row><cell>4</cell><cell>17</cell><cell>7</cell><cell>17</cell><cell>7</cell><cell>0.2982</cell><cell>29</cell><cell>12</cell><cell>3</cell><cell>11</cell><cell>8</cell><cell>0.3235</cell></row><row><cell>5</cell><cell>12</cell><cell>4</cell><cell>9</cell><cell>12</cell><cell>0.4286</cell><cell>30</cell><cell>10</cell><cell>15</cell><cell>8</cell><cell>17</cell><cell>0.6508</cell></row><row><cell>6</cell><cell>19</cell><cell>5</cell><cell>19</cell><cell>5</cell><cell>0.2545</cell><cell>31</cell><cell>21</cell><cell>4</cell><cell>18</cell><cell>7</cell><cell>0.2419</cell></row><row><cell>7</cell><cell>8</cell><cell>15</cell><cell>9</cell><cell>16</cell><cell>0.7258</cell><cell>32</cell><cell>19</cell><cell>6</cell><cell>11</cell><cell>14</cell><cell>0.3621</cell></row><row><cell>8</cell><cell>6</cell><cell>11</cell><cell>12</cell><cell>7</cell><cell>0.5</cell><cell>33</cell><cell>12</cell><cell>12</cell><cell>10</cell><cell>14</cell><cell>0.5088</cell></row><row><cell>9</cell><cell>13</cell><cell>10</cell><cell>9</cell><cell>16</cell><cell>0.5345</cell><cell>34</cell><cell>16</cell><cell>7</cell><cell>16</cell><cell>8</cell><cell>0.3519</cell></row><row><cell>10</cell><cell>15</cell><cell>7</cell><cell>17</cell><cell>6</cell><cell>0.3585</cell><cell>35</cell><cell>9</cell><cell>15</cell><cell>7</cell><cell>17</cell><cell></cell></row><row><cell>11</cell><cell>9</cell><cell>14</cell><cell>13</cell><cell>11</cell><cell>0.4833</cell><cell>36</cell><cell>11</cell><cell>12</cell><cell>15</cell><cell>8</cell><cell>0.4074</cell></row><row><cell>12</cell><cell>21</cell><cell>4</cell><cell>14</cell><cell>11</cell><cell>0.2344</cell><cell>37</cell><cell>15</cell><cell>2</cell><cell>11</cell><cell>7</cell><cell>0.2857</cell></row><row><cell>13</cell><cell>11</cell><cell>1</cell><cell>7</cell><cell>6</cell><cell>0.4194</cell><cell>38</cell><cell>10</cell><cell>14</cell><cell>7</cell><cell>18</cell><cell>0.5873</cell></row><row><cell>14</cell><cell>12</cell><cell>13</cell><cell>14</cell><cell>11</cell><cell>0.45</cell><cell>39</cell><cell>13</cell><cell>10</cell><cell>11</cell><cell>14</cell><cell>0.4483</cell></row><row><cell>15</cell><cell>9</cell><cell>16</cell><cell>12</cell><cell>13</cell><cell>0.5333</cell><cell>40</cell><cell>8</cell><cell>1</cell><cell>12</cell><cell>5</cell><cell>0.2</cell></row><row><cell>16</cell><cell>10</cell><cell>10</cell><cell>10</cell><cell>15</cell><cell>0.5536</cell><cell>41</cell><cell>4</cell><cell>17</cell><cell>7</cell><cell>15</cell><cell>0.6226</cell></row><row><cell>17</cell><cell>23</cell><cell>1</cell><cell>19</cell><cell>6</cell><cell>0.1455</cell><cell>42</cell><cell>17</cell><cell>3</cell><cell>7</cell><cell>6</cell><cell>0.25</cell></row><row><cell>18</cell><cell>12</cell><cell>11</cell><cell>6</cell><cell>18</cell><cell>0.6481</cell><cell>43</cell><cell>9</cell><cell>15</cell><cell>9</cell><cell>16</cell><cell>0.5517</cell></row><row><cell>19</cell><cell>6</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>44</cell><cell>9</cell><cell>11</cell><cell>13</cell><cell>11</cell><cell>0.434</cell></row><row><cell>20</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>45</cell><cell>18</cell><cell>7</cell><cell>8</cell><cell>17</cell><cell>0.5937</cell></row><row><cell>21</cell><cell>11</cell><cell>12</cell><cell>16</cell><cell>7</cell><cell>0.5085</cell><cell>46</cell><cell>8</cell><cell>15</cell><cell>9</cell><cell>15</cell><cell>0.5902</cell></row><row><cell>22</cell><cell>9</cell><cell>16</cell><cell>9</cell><cell>16</cell><cell>0.7187</cell><cell>47</cell><cell>8</cell><cell>13</cell><cell>9</cell><cell>13</cell><cell>0.5357</cell></row><row><cell>23</cell><cell>5</cell><cell>11</cell><cell>11</cell><cell>7</cell><cell>0.5</cell><cell>48</cell><cell>15</cell><cell>4</cell><cell>14</cell><cell>6</cell><cell>0.25</cell></row><row><cell>24</cell><cell>8</cell><cell>8</cell><cell>10</cell><cell>3</cell><cell>0.3421</cell><cell>49</cell><cell>11</cell><cell>9</cell><cell>10</cell><cell>10</cell><cell>0.3958</cell></row><row><cell>25</cell><cell>10</cell><cell>15</cell><cell>10</cell><cell>15</cell><cell>0.6562</cell><cell>50</cell><cell>13</cell><cell>8</cell><cell>12</cell><cell>9</cell><cell>0.375</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>All</cell><cell>9</cell><cell>16</cell><cell>13</cell><cell>12</cell><cell>0.4844</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,323.21,667.69,89.57,6.91"><p>http://classificationweb.net/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,323.21,677.42,221.90,6.91;2,308.86,686.88,236.25,6.91;2,308.86,696.35,236.25,6.91;2,308.86,705.81,95.70,6.91"><p>In particular, the QUT library. For the sake of simplicity, only the abstracted information (title, table of content, and summary) was used to represent an instance. Example of instances can be found on http://www.library.qut.edu.au.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The work presented in this paper was partially supported by Grants <rs type="grantNumber">DP0988007</rs> from the <rs type="funder">Australian Research Council</rs> and <rs type="grantNumber">NSC98-2218-E-468-002</rs> from the <rs type="funder">National Science Council of Taiwan</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_wCcMdsJ">
					<idno type="grant-number">DP0988007</idno>
				</org>
				<org type="funding" xml:id="_rBE3tWF">
					<idno type="grant-number">NSC98-2218-E-468-002</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,327.12,677.42,217.99,6.91;11,327.12,686.74,217.99,6.87;11,327.12,696.20,217.99,6.87;11,327.12,705.81,154.52,6.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,377.68,677.42,150.99,6.91">Robust test collections for retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,327.12,686.74,217.99,6.87;11,327.12,696.20,215.09,6.87">SIGIR &apos;07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,76.77,217.99,6.91;12,68.37,86.10,217.99,7.05;12,68.37,95.56,217.99,6.87;12,68.37,105.02,212.52,7.05" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,281.05,76.77,5.31,6.91;12,68.37,86.24,72.44,6.91">If i had a million queries</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,157.84,86.10,128.53,6.87;12,68.37,95.56,217.99,6.87;12,68.37,105.02,19.85,6.87">ECIR &apos;09: Proceedings of the 31th European Conference on IR Research on Advances in Information Retrieval</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="288" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,118.03,217.99,6.91;12,68.37,127.35,217.99,7.05;12,68.37,136.96,71.95,6.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,208.57,118.03,77.80,6.91;12,68.37,127.49,87.82,6.91">Ontology-based personalized search and browsing</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gauch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaffee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pretschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,165.74,127.35,117.22,6.87">Web Intelligence and Agent Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="219" to="234" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,149.82,217.99,6.91;12,68.37,159.29,217.99,6.91;12,68.37,168.61,174.00,7.05" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,271.75,149.82,14.61,6.91;12,68.37,159.29,217.99,6.91;12,68.37,168.75,118.47,6.91">University of glasgow at trec 2008: Experiments in blog, enterprise, and relevance feedback tracks with terrier</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,200.97,168.61,17.18,6.87">TREC</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,181.61,217.99,6.91;12,68.37,190.94,181.49,7.05" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,209.23,181.61,77.13,6.91;12,68.37,191.08,125.17,6.91">The impact of positive, negative and topical relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kaptein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,208.46,190.94,17.18,6.87">TREC</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,203.94,217.99,6.91;12,68.37,213.26,217.99,7.05;12,68.37,222.73,175.20,7.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,193.29,203.94,93.07,6.91;12,68.37,213.41,153.61,6.91">Retrieval effectiveness of an ontology-based model for information selection</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mcleod</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,229.76,213.26,56.60,6.87;12,68.37,222.73,108.45,6.87">The International Journal on Very Large Data Bases</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="85" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,235.73,217.99,6.91;12,68.37,245.05,155.20,7.05" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,102.17,235.73,184.19,6.91;12,68.37,245.20,98.64,6.91">Incorporating relevance and pseudo-relevance feedback in the markov random field model</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lease</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,182.17,245.05,17.18,6.87">TREC</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,258.06,217.99,6.91;12,68.37,267.38,217.99,7.05;12,68.37,276.85,81.59,6.87;12,190.03,276.99,17.93,6.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,213.20,258.06,73.17,6.91;12,68.37,267.52,160.68,6.91">RCV1: A New Benchmark Collection for Text Categorization Research</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,237.18,267.38,49.18,6.87;12,68.37,276.85,78.12,6.87">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,289.85,217.99,6.91;12,68.37,299.17,217.99,7.05;12,68.37,308.64,217.99,7.05;12,68.37,318.24,49.81,6.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,214.58,289.85,71.79,6.91;12,68.37,299.32,133.54,6.91">Mining negative relevance feedback for information filtering</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Algarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,223.46,299.17,62.90,6.87;12,68.37,308.64,195.12,6.87">Proceedings of the IEEE/WIC/ACM international conference on Web Intelligence</title>
		<meeting>the IEEE/WIC/ACM international conference on Web Intelligence</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="606" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,331.11,217.99,6.91;12,68.37,340.43,217.99,7.05;12,68.37,349.89,130.61,7.05" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,136.69,331.11,149.67,6.91;12,68.37,340.57,91.44,6.91">Mining Ontology for Automatically Acquiring Web User Information Needs</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,165.63,340.43,120.73,6.87;12,68.37,349.89,55.88,6.87">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="554" to="568" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,362.90,217.99,6.91;12,68.37,372.22,217.99,7.05;12,68.37,381.69,217.99,6.87;12,68.37,391.29,170.46,6.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,217.54,362.90,68.82,6.91;12,68.37,372.36,109.60,6.91">A two-stage text mining model for information filtering</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,192.28,372.22,94.08,6.87;12,68.37,381.69,214.12,6.87">CIKM &apos;08: Proceeding of the 17th ACM conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1023" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,404.16,217.99,6.91;12,68.37,413.48,217.99,7.05;12,68.37,422.94,217.99,6.87;12,68.37,432.41,217.99,7.05;12,68.37,442.01,74.15,6.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,217.09,404.16,69.27,6.91;12,68.37,413.62,162.83,6.91">Mining multi-faceted overviews of arbitrary topics in a text collection</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,252.63,413.48,33.74,6.87;12,68.37,422.94,217.99,6.87;12,68.37,432.41,123.46,6.87">KDD &apos;08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="497" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,454.88,217.99,6.91;12,68.37,464.20,217.99,7.05;12,68.37,473.66,138.66,7.05" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,248.73,454.88,37.63,6.91;12,68.37,464.34,122.17,6.91">Ontological user profiling in recommender systems</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Middleton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">R</forename><surname>Shadbolt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C D</forename><surname>Roure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,196.61,464.20,89.75,6.87;12,68.37,473.66,71.92,6.87">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="88" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,486.67,217.99,6.91;12,68.37,495.99,131.94,7.05" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,176.10,486.67,110.26,6.91;12,68.37,496.13,11.87,6.91">The TREC 2002 filtering track report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,94.70,495.99,82.19,6.87">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,509.00,217.99,6.91;12,68.37,518.32,217.99,6.87;12,68.37,527.78,217.99,7.05;12,68.37,537.39,110.05,6.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,144.68,509.00,129.99,6.91">Feature engineering for text classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,68.37,518.32,217.99,6.87;12,68.37,527.78,57.64,6.87">ICML &apos;99: Proceedings of the Sixteenth International Conference on Machine Learning</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="379" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,550.25,217.99,6.91;12,68.37,559.57,169.09,7.05" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,118.50,550.25,164.72,6.91">Machine learning in automated text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,68.37,559.57,105.87,6.87">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,572.58,217.99,6.91;12,68.37,581.90,217.99,7.05;12,68.37,591.36,217.99,6.87;12,68.37,600.83,181.97,7.05" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,197.06,572.58,89.31,6.91;12,68.37,582.04,93.11,6.91">Web search personalization with ontological user profiles</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sieg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,176.98,581.90,109.38,6.87;12,68.37,591.36,217.99,6.87;12,68.37,600.83,13.99,6.87">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on Conference on information and knowledge management<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="525" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,613.83,217.99,6.91;12,68.37,623.16,217.99,7.05;12,68.37,632.62,127.94,7.05" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,160.71,613.83,125.66,6.91;12,68.37,623.30,68.20,6.91">A personalized ontology model for web information gathering</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,182.22,623.16,104.14,6.87;12,68.37,632.62,69.83,6.87">IEEE Transaction on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2009-12">December 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,645.63,217.99,6.91;12,68.37,654.95,217.99,7.05;12,68.37,664.41,217.99,6.87;12,68.37,674.02,69.95,6.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,216.98,645.63,69.38,6.91;12,68.37,655.09,131.84,6.91">Ontology mining for personalized web information gathering</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nayak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,223.07,654.95,63.29,6.87;12,68.37,664.41,214.95,6.87">Proceedings of the 2007 IEEE/WIC/ACM International Conference on Web Intelligence</title>
		<meeting>the 2007 IEEE/WIC/ACM International Conference on Web Intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,68.37,686.88,217.99,6.91;12,68.37,696.20,217.99,7.05;12,68.37,705.67,171.27,7.05" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,165.40,686.88,120.96,6.91;12,68.37,696.35,75.28,6.91">Deploying approaches for pattern refinement in text mining</title>
		<author>
			<persName coords=""><forename type="first">S.-T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,161.89,696.20,124.47,6.87;12,68.37,705.67,87.78,6.87">Proceedings of the Sixth International Conference on Data Mining</title>
		<meeting>the Sixth International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1157" to="1161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,327.12,76.77,217.99,6.91;12,327.12,86.10,217.99,7.05;12,327.12,95.56,217.99,7.05;12,327.12,105.17,57.34,6.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,464.92,76.77,80.20,6.91;12,327.12,86.24,100.78,6.91">Automatic pattern taxonomy exatraction for web mining</title>
		<author>
			<persName coords=""><forename type="first">S.-T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,442.70,86.10,102.42,6.87;12,327.12,95.56,145.89,6.87">Proceedings of IEEE/WIC/ACM International Conference on Web Intelligence</title>
		<meeting>IEEE/WIC/ACM International Conference on Web Intelligence<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>Beijing</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="242" to="248" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
