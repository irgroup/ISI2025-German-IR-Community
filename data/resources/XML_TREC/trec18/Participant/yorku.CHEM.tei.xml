<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,100.44,160.39,411.25,16.37">York University at TREC 2009: Chemical Track</title>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,178.92,194.23,52.51,9.62"><forename type="first">Jiashu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Managment Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.92,194.23,63.68,9.62"><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
							<email>jhuang@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Managment Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.20,194.23,40.91,9.62"><forename type="first">Zheng</forename><surname>Ye</surname></persName>
							<email>yezheng@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Managment Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.04,194.23,54.64,9.62"><forename type="first">Jianhan</forename><surname>Zhu</surname></persName>
							<email>jianhan.zhu@ucl.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,100.44,160.39,411.25,16.37">York University at TREC 2009: Chemical Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B448C85B7C0960595F58AF2DD0F872CA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Chemical Information Retrieval</term>
					<term>Mean Average Precision</term>
					<term>Patent</term>
					<term>BM25</term>
					<term>DFR</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our chemical experiments mainly focus on addressing three major problems in two chemical information retrieval tasks, Technology Survey (TS) task and Prior Art (PA) task. The three problems are: (1) how to deal with chemical terminology synonyms? (2) how to deal with chemical terminology abbreviation? (3) how to deal with long queries in Prior Art (PA) task? In particular, we propose a query expansion algorithm for TS task and a keyword-selection algorithm for PA task. The Mean Average Precision (MAP) for our TS task run "york09ca07" using Algorithm 1 was 0.2519 and for our PA task run "york09caPA01" using Algorithm 2 was 0.0566. The evaluation results show that both algorithms are effective for improving retrieval performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe the work done by members at York University in Canada and University College London in UK for the TREC 2009 Chemical track. This is the first year that the chemical track is carried out. We participated in both the Technology Survey (TS) and the Prior Art (PA) retrieval tasks of the Chemical track. Our goal of participating in this year's TREC Chemical track is to evaluate Information Retrieval (IR) models and their term weighting functions in the chemical domain, and to address the challenges in searching large-scale chemical and patent documents.</p><p>The test corpus used in this year's chemical track consists of two types of documents, chemical patents and chemical articles. There are 2,648,160 different patents with a total size of 112GB, and 59,000 different articles with the size of 3GB. Two retrieval tasks are provided this year, which are listed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Technology Survey (TS)</head><p>The TS task contains 18 short topics, which are generated with the help of the IP experts. These topics have been generously provided by chemical patent experts based on their own experience. The retrieval results from participants to these 18 topics have been evaluated manually by both graduate students specialized in chemistry and the domain experts who provide these topics. The purpose of this task is to understand the weak points of the participating systems and specific areas where effectiveness can be improved. The task aims to find patents or articles describing standard methods about organic, high molecular weight, pharmaceuticals, and inorganic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Prior Art (PA)</head><p>The PA task contains 1000 long automatically generated topics, each of which is a full patent. The aim of this task is to find relevant patents with respect to a set of 1,000 existing patents. The results were assessed based on existing citations from the 1,000 patents and their family members.</p><p>The remainder of this paper is organized as follows. In Section 2, we describe basic retrieval models utilized in this paper. In section 3, we present the algorithm and experimental results for TS task. In section 4, we propose an approach for BM25 based keyword selection for PA task and its experiment results. In section 5, we conclude the paper with a discussion of our findings and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Weighting Models</head><p>The retrieval documents are ranked in the order of their probabilities of relevance to the query. Search term is assigned weight based on its within-document term frequency and query term frequency. We used two well-known weighting models, BM25 <ref type="bibr" coords="2,293.89,303.91,10.57,9.62" target="#b0">[1]</ref> and DFR <ref type="bibr" coords="2,351.98,303.91,10.45,9.62" target="#b1">[2]</ref> in this year chemical track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">BM25</head><p>In BM25, search term is assigned weight based on its within-document term frequency and query term frequency <ref type="bibr" coords="2,159.00,361.75,9.91,9.62" target="#b2">[3]</ref>. The corresponding weighting function is as follows.</p><formula xml:id="formula_0" coords="2,141.00,389.85,376.78,51.12">w = (k 1 + 1) * tf K + tf * log (r + 0.5)/(R -r + 0.5) (n -r + 0.5)/(N -n -R + r + 0.5) * (k 3 + 1 ) * qtf k 3 + qtf ⊕ k 2 * nq * (avdl -dl ) (avdl + dl ) (<label>1</label></formula><formula xml:id="formula_1" coords="2,517.78,410.83,4.25,9.62">)</formula><p>where w is the weight of a query term, N is the number of indexed documents in the collection, n is the number of documents containing a specific term, R is the number of documents known to be relevant to a specific topic, r is the number of relevant documents containing the term, tf is withindocument term frequency, qtf is within-query term frequency, dl is the length of the document, avdl is the average document length, nq is the number of query terms, the k i s are tuning constants (which depend on the database and possibly on the nature of the queries and are empirically determined), K equals to k 1 * ((1b) + b * dl/avdl), and ⊕ indicates that its following component is added only once per document, rather than for each term. In our experiments, the values of k 1 , k 2 , k 3 and b are set to be 1.2, 0, 8 and 0.75 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">DFR</head><p>DFR is a generalisation of one of the very first models of Information Retrieval, Harter's 2-Poisson indexing-model <ref type="bibr" coords="2,159.73,603.19,10.00,9.62" target="#b3">[4]</ref>. Its weighting function has the following form.</p><formula xml:id="formula_2" coords="2,222.96,622.99,299.08,23.18">ω = T F * qtf * N ORM * log e ( N + 1 n exp ) (2)</formula><p>where w, qtf , N , tf , dl and avdl have the same meaning as in BM25, and</p><formula xml:id="formula_3" coords="2,228.72,680.13,154.60,56.40">T F = tf * log 2 (1 + avdl/dl) N ORM = (tf + 1)/(df * (T F + 1)) n exp = idf * (1 -e -f ) f = qtf /df</formula><p>where idf is the term's inverse document frequency weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TS Task</head><p>3.1 Query Expansion Algorithm for TS Task TS task's queries are one or two sentences long, which show research demanding of companies or experts. Some abbreviations of chemical terminologies are also appeared in the queries. Therefore, an important issue for TS retrieval task is how to expand the queries in the chemical realm so that information retrieval systems can get more information while searching. In the "narratives" of the queries, the chemical experts recommended that "There are other names see ChemID plus or PubChem", which are two well known websites that provide chemical termonology explanation. Therefore, we integrated the professional chemical information from the suggested website ChemID plus <ref type="bibr" coords="3,111.13,282.31,10.45,9.62" target="#b4">[5]</ref> and PubChem <ref type="bibr" coords="3,190.95,282.31,10.57,9.62" target="#b5">[6]</ref> in our Algorithm 1.</p><p>Input: a query from chemical experts Output: a list of possible variants for the chemical terminologies in the query Method:</p><p>(1) Extract keywords from the query by eliminating stop words (2) Search the extracted keywords on ChemID plus and PubChem, and add their variants in the list (3) Remove redundant keywords from the list </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Results</head><p>Our experiments were conducted on a double-processor server which has 2 Intel(R) Quad 2.66GHz CPU and 4G memory. York University submitted nine automatic runs in total for the 2009 TREC Chemical track, including seven TS task runs, and two PA task runs.</p><p>The Average Precision (AP) of our run "york09ca07" and the average AP over all the participants on the 18 TS topics are shown in Figure <ref type="figure" coords="3,264.02,525.55,3.90,9.62" target="#fig_2">2</ref>. We achieved better performance in our run "york09ca07" than the average AP.</p><p>We also compared the Mean Average Precision (MAP) of our run "york09ca07" with the average MAP over all participants and the best run in this year in Table <ref type="table" coords="3,377.76,561.43,4.98,9.62">1</ref> . The MAP of "york09ca07" is much higher than the average MAP, and very close to the best run's MAP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>MAP max MAP among all participants 0.3014 average MAP over all participants 0.1620 york09ca07 0.2909</p><p>Table <ref type="table" coords="3,142.32,659.47,3.90,9.62">1</ref>: MAP comparison of "york09ca07" and the best and average of all participants Moreover, the performance of some other official runs of York University is shown in Table <ref type="table" coords="3,500.78,693.31,3.90,9.62" target="#tab_1">2</ref>. In this table, comparisons are given for different approaches. Firstly, the BM25 model achieves better performance than the DFR model under given parameter settings. Secondly, using Algorithm 1 Figure <ref type="figure" coords="4,133.81,390.55,3.90,9.62" target="#fig_2">2</ref>: AP comparison on each topic of "york09ca07" and the average over all participants with extended keywords can improve both MAP for Chemical retrieval models. Therefore, our best run is "york09ca07" which uses BM25 as well as Algorithm 1. Most importantly, the performance of all the runs in Table <ref type="table" coords="4,193.58,446.35,4.98,9.62" target="#tab_1">2</ref> are all significantly better than that of the average's.  The uniqueness of this task is that a patent is normally very long, ranges from pages to hundreds of pages. In the mean time, it is not possible for an IR system to process a long topic containing tens of thousands words. Even if a system can handle the query, the retrieved documents will not be highly relevant to the query, due to too much less important information is retrieved. Therefore, an essential question in PA task is to preprocess the topics properly.</p><p>In our experiment, we firstly ranked the keywords within a query and extracted the top keywords for further retrieval. A good ranking algorithm should consider both the frequency of the keyword in the query and its effect on the whole collection <ref type="bibr" coords="5,309.01,123.55,9.91,9.62" target="#b6">[7]</ref>. Therefore, we consider to use a part of BM25 as weighting function. ŵ = log (r + 0.5)/(Rr + 0.5) (nr + 0.5)/(Nn -R + r + 0.5)</p><formula xml:id="formula_4" coords="5,371.86,155.49,150.18,23.64">* (k 3 + 1 ) * qtf k 3 + qtf<label>(3)</label></formula><p>The parameters are the same as described in Function 1. There are two parts of Function 3, where the first part is calculated based on the term frequency on the whole collection and the second part is calculated based on the term frequency on the query. We aim to lift the keywords that balance these two aspects at the same time. Algorithm 2 for PA task is described as following.</p><p>Input: a query(patent), the collection, number of output keywords n k for a query Output: a list of n k possible keywords Method:</p><p>(1) Extract all the keywords from the query, and put them in a list  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>Our experimental results of PA task are shown in Table <ref type="table" coords="5,342.03,428.11,3.90,9.62" target="#tab_2">3</ref>. We five runs with different n k , since it is hard to estimate how many keywords should be included in a query. With the n k increasing, the MAP decreases, which indicates that more keywords may not be better than fewer keywords in the PA task in 2009 Chemical track.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>The contributions of our work are as follows. First, we have designed and implemented two algorithms for 2009 Chemical track. Algorithm 1 uses website for chemical terminology expansion in TS task, and Algorithm 2 introduces the collection's information in PA task query keyword selection. We find that both algorithms are effective for improving retrieval performance in chemical domain. Second, we demonstrate that BM25 model is more effective than DFR model in chemical retrieval domain. Third, we show that less keywords even performs better in Chemical track PA task.</p><p>There is still future work to do in chemical and patent IR. One future work is to select more suitable IR model parameters for Chemical track. We only tried a group of default parameters in the adopted weighting models. So parameter selection of BM25 and DFR will be further investigated for improving retrieval performance. Another future work is to make better use of chemical domain knowledge, for a detail example, the structure of chemical compositions. Finally, the term selection problem in Chemical track could be further refined. We only considered a term's information both on the query and on the whole collection in this paper. Our further work will utilize IR feedback approaches to select the terms on some top ranked documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,230.28,410.11,151.55,9.62"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Algorithm 1 for TS task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,132.00,303.18,360.08,8.65;5,132.00,314.10,286.57,8.65;5,132.00,325.02,143.77,8.65;5,132.00,336.06,224.29,8.65"><head>( 2 )</head><label>2</label><figDesc>Go through the collection, and calculate the first part of Function 3 for each keyword (3) Calculate the second part of function 3, and therefore the weight ŵ (4) Rank the keywords by weight ŵ (5) Reserve the top n k keywords and remove the others</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,229.92,359.83,152.27,9.62"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Algorithm 2 for PA task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,207.00,495.06,9.47,8.26;5,243.12,495.06,9.17,8.65;5,280.68,495.06,9.17,8.65;5,318.24,495.06,9.17,8.65;5,355.68,495.06,9.17,8.65;5,390.96,495.06,13.73,8.65;5,201.36,506.46,209.09,8.65"><head></head><label></label><figDesc>0575 0.0566 0.0516 0.0450 0.0343</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,543.79,432.01,104.78"><head>Table 2 :</head><label>2</label><figDesc>More results on the 2009 Chemical TS task</figDesc><table coords="4,90.00,593.80,432.01,54.77"><row><cell>4 PA Task</cell></row><row><cell>4.1 Keyword Selection Algorithm for PA task</cell></row><row><cell>2009 Chemical track also includes another task, PA task, which contains 1000 patents as topics.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,145.68,537.31,317.34,9.62"><head>Table 3 :</head><label>3</label><figDesc>Performance of our PA task runs with respect to the parameter</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This research is supported in part by the research grant from the <rs type="funder">Natural Sciences and Engineering Research Council (NSERC) of Canada</rs>. We would also like to thank <rs type="person">Michael Siu</rs> at <rs type="institution">Vice-President Research Office of York University</rs> for support and advice.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.48,286.51,416.68,9.62;6,105.48,298.51,337.94,9.62" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Williams</surname></persName>
		</author>
		<title level="m" coord="6,496.34,286.51,25.82,9.62;6,105.48,298.51,250.52,9.62">Okapi at TREC-5. Proceedings of 5th Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="page" from="143" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,318.43,416.65,9.62;6,105.48,330.31,334.33,9.62" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,153.13,318.43,364.10,9.62">Probabilistic models for information retrieval based on divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="6,105.48,350.23,416.45,9.62;6,105.48,362.23,180.49,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,262.36,350.23,190.25,9.62">York University at TREC 2008: Blog Track</title>
		<author>
			<persName coords=""><forename type="first">Mladen</forename><surname>Kovacevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,460.44,350.23,61.50,9.18;6,105.48,362.23,149.48,9.18">Proceedings of the 17th Text Retrieval Conference</title>
		<meeting>the 17th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,382.15,416.49,9.62;6,105.48,394.15,166.81,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,161.42,382.15,249.07,9.62">A Probabilistic Approach to Automatic Keyword Indexing</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Harter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,417.60,382.15,104.37,9.18;6,105.48,394.15,136.18,9.18">Journal of the American Society for Information Science</title>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,414.07,307.15,9.62" xml:id="b4">
	<monogr>
		<ptr target="http://chem.sis.nlm.nih.gov/chemidplus/" />
		<title level="m" coord="6,105.48,414.07,56.38,9.62">ChemID plus</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,433.99,199.80,9.62" xml:id="b5">
	<monogr>
		<ptr target="http://pubchem.ncbi.nlm.nih.gov/" />
		<title level="m" coord="6,105.48,433.99,40.34,9.62">PubChem</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,453.91,416.62,9.62;6,105.48,465.91,311.77,9.62" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,371.36,453.91,150.75,9.62;6,105.48,465.91,247.81,9.62">Applying Data Mining to Pseudo-Relevance Feedback for High Performance Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Poon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ICDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
