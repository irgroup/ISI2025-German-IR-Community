<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,91.92,63.44,428.06,11.81;1,180.96,81.32,249.84,11.81">Combining Opinion Profile Modeling with Complex Context Filtering for Contextual Suggestion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,249.36,118.28,50.22,9.13"><forename type="first">Peilin</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,322.32,118.28,40.26,9.13"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,91.92,63.44,428.06,11.81;1,180.96,81.32,249.84,11.81">Combining Opinion Profile Modeling with Complex Context Filtering for Contextual Suggestion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">728954562308F151226B2A7F8ED00CB3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our effort on TREC 2015 Contextual Suggestion Track. Using opinions from online resources to model both user profile and candidate profile has been proven to be effective on previous TREC. This year we also leverage the power of building profile based on opinions. Opinions from well known commercial online resources are collected in order to build the profiles. Two kinds of opinion representations are used for the two submitted runs. Linear interpolation is leveraged to rank the candidate suggestions. Additionally, an advanced context filter which considers all possible factors such as trip type and trip duration is applied to the ranking results so that unwanted venues are removed from the final ranking list. Official results of our submitted runs show the effectiveness of the proposed method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>TREC 2015 Contextual Suggestion Track provides researchers the chance to test their methods on providing better personalized suggestions. For this year's track, the task changes in some way when comparing with previous tracks:</p><p>-There is a pre-task which aims to collect candidate suggestions from multiple sources. The candidate suggestions are served as the suggestion pool for the live experiment. -There are separated tasks: live experiment and batch experiment. The live experiment is designed as a web service which responses to the suggestion requests. Top results from different participants in live experiment are collected to serve as the suggestion pool. Finally only 30 suggestions are sampled for the batch experiment. The task of batch experiment is to rerank the sampled suggestions. There are 211 requests in total for both live experiment and batch experiment. -Several optional context requirements are added including the trip type, the trip duration, the type of group the person is travelling with and the season the trip will occur. Participants are expected to propose method which accommodates the context requirements. -Description generation requirement is removed.</p><p>For this year's TREC, we still rely on building user profiles to help ranking candidate suggestions. When building user profile, we utilize the opinions from online resource to enrich the profiles as what we did in the last year. For batch experiment, two review representations are examinated for two submitted runs. Linear interpolation is used to compute the similarity between user profile and candidate profile. The ranking list is generated by sorting the similarity scores in descending order. In order to meet the complex contexts requirement proposed this year, an advanced context filter is applied to the ranking list so that the unwanted candidate suggestions are put to the end of the list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Framework</head><p>Our method consists of the following parts:</p><p>-Useful information gathering, -Profile modeling, -Candidate suggestion ranking, -Complex context filtering.</p><p>We will describe them in details in the following sub-sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Useful Information Gathering</head><p>We did not participate the pre-task which aims to collect potential candidate suggestions from participants. Instead, we gather the online opinions for the all the candidate suggestions which is similar with what we did previously <ref type="bibr" coords="2,109.92,106.52,10.56,9.13" target="#b3">[4,</ref><ref type="bibr" coords="2,122.16,106.52,7.80,9.13" target="#b1">2,</ref><ref type="bibr" coords="2,131.52,106.52,7.04,9.13" target="#b2">3]</ref>. This year we conduct a best-effort strategy to crawl online opinions in the following way: We first use the candidate suggestion name with its location (city + state) as the query to Google<ref type="foot" coords="2,480.24,116.92,3.97,6.38" target="#foot_0">1</ref> it. We extract the search result pages belong to Yelp<ref type="foot" coords="2,227.88,128.80,3.97,6.38" target="#foot_1">2</ref> , TripAdvisor<ref type="foot" coords="2,291.00,128.80,3.97,6.38" target="#foot_2">3</ref> and OpenTable<ref type="foot" coords="2,365.64,128.80,3.97,6.38" target="#foot_3">4</ref> from the first 50 results. We then collect the information from the above mentioned web sites in order to get as many as possible opinions.</p><p>We call the above mentioned strategy as the best-effort strategy because sometimes the names of the candidates are not well organized as it should be. For example, the name "Mobile Home Parks near Watertown , NY : 153 Listed" in the official collection file could be better changed to "Watertown". Moreover, there are some unrelated venues accidentally appear in the first 50 search results returned by Google either because of their similar name or other factors which are also included as the information sources of the candidate.</p><p>After crawling, information including the category of the suggestion, the number of reviews, average rating, business hour, price range, all ratings and the associated text reviews of the candidate suggestion are extracted and kept in JSON format for further use. Finally, approximately 161,907 candidate suggestions are crawled out of 1,235,844 candidate suggestions in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Profile Modeling</head><p>We use opinion to model user profile as well as candidate suggestion profile due to its richness. Specifically, we use positive opinions of the suggestions that the user likes (positive suggestions in preferences) to build her positive user profile, and use negative opinions of suggestions that the user dislikes (negative suggestions in preferences) to build negative user profile. The intuition is that users with similar ratings of a suggestions share something in common of why they like or dislike the suggestion.</p><p>Formally, the user profiles are estimated as <ref type="bibr" coords="2,268.20,353.72,9.99,9.13" target="#b1">[2]</ref>:</p><formula xml:id="formula_0" coords="2,189.12,373.88,360.51,20.73">U pos = reqsi∈ES(U) RU (reqsi)=P OS REP (O pos (reqs i ))<label>(1)</label></formula><formula xml:id="formula_1" coords="2,188.04,403.40,361.59,20.73">U neg = reqsi∈ES(U) RU (reqsi)=NEG REP (O neg (reqs i ))<label>(2)</label></formula><p>where reqs i is the ith suggestion in preferences i. O pos (reqs i ) represents all positive text reviews about reqs i , O neg (reqs i ) represents all negative text reviews, and REP (O(reqs i )) denotes how to represent text reviews O(reqs i ) in the profile. R U (reqs i ) is the rating of example suggestion reqs i given by user U . The original value of R U (reqs i ) could be numerical, and we map these values into either POS or NEG. We build the positive and negative profile for a candidate suggestion similar to what we did in building user profile as follows:</p><formula xml:id="formula_2" coords="2,247.80,499.28,116.28,24.50">CS pos = REP (O pos (CS)) CS neg = REP (O neg (CS)).</formula><p>For user ratings in Contextual Suggestion Track collection, we map the example suggestions with rating {3, 4} from the user as positive and opinions with rating {0, 1} from the user as negative. Example suggestions with rating {2} are simply ignored since they are hard to categorize into either positive or negative. For the opinions crawled from Yelp, TripAdvisor and OpenTable (either for example or candidate), opinions with rating {4, 5} are viewed as positive and opinions with rating {1, 2} are treated as negative. Opinions with rating {3} are simply ignored and are not used for building the profiles since they often contain mixed polarities and thus are hard to categorize.</p><p>We tried two strategies of how to represent the profiles.</p><p>-Use full reviews (FR): use full text in the review.</p><p>-Use nouns (NR): nouns in the review.</p><p>Simple pre-processing are performed on the original text reviews: 1) Terms are lower cased; 2) Stop words are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Candidate Suggestion Ranking</head><p>Given a user U and a candidate suggestion CS, the similarity score can be computed as follows:</p><p>1. Build a positive and negative user profile, i.e., U pos and U neg , based on the information about example suggestions that the user has rated, i.e, ES(U ); 2. Build the positive and negative profile for the candidate suggestion CS, i.e., CS pos and CS neg ; 3. Predict the score of CS, i.e., S(U, CS), based on the similarities between U pos , U neg , CS pos and CS neg .</p><p>We use linear interpolation to compute S(U, CS). In previous TREC, we have also tried learning to rank (LTR) as the ranking method. However, linear interpolation is still favorable for following reasons:</p><p>1. It fits the requirement of live experiment. LTR often needs time to train the model which basically not applicable for real time service. Linear interpolation can compute the score really quick. 2. We did not get very promising performance using LTR in previous TREC.</p><p>The equation used to estimate the similarity between a user and a candidate suggestion is as follows:</p><formula xml:id="formula_3" coords="3,176.04,271.28,373.59,24.38">S(U, CS) = α × SIM (U pos , CS pos ) -β × SIM (U pos , CS neg ) -γ × SIM (U neg , CS pos ) + η × SIM (U neg , CS neg )<label>(3)</label></formula><p>where SIM (a, b) is text similarity measurement between any two profiles. α, β, γ, η ∈ [0, 1] are parameters that balance the impact of the different similarities to the final similarity score. We use an axiomatic similarity function F2EXP <ref type="bibr" coords="3,138.84,332.48,10.56,9.13" target="#b0">[1]</ref> when computing SIM (a, b). A preliminary training process was done on our self-crawled Yelp data collection<ref type="foot" coords="3,152.04,342.76,3.97,6.38" target="#foot_4">5</ref> . The trained parameters set is finally as α = 1.0, β = 0.0, γ = 0.9, η = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Context Filter</head><p>This year's track has a noticeable change comparing with previous tracks: The context is much more complex. Specifically, trip type, trip duration, type of group the person is travelling with, season of the trip are added to the context requirement. To better solve the context constraints of the problem, we propose an advanced context filter which can remove (actually it just removes the unwanted suggestions at the end of the ranking list) the unwanted suggestions if they do not meet with the context requirements.</p><p>Our context filter mainly has three kinds of operations: Boost, which boost the score of the suggestion; Avoid, which remove the suggestion; Mix, which basically pick suggestions from different categories in a round-robin fashion so that the diversity of the ranking list increases. Other information that is also used in the context filter includes the price, the category and business hours etc.</p><p>For trip type, there are three possible values: Business, Holiday, Other. For business, we simply boost the pricey hotels and restaurants. For holiday and other trip type the context filter just does nothing.</p><p>The possible trip durations are: Night Out, Day Trip, Weekend Trip, Longer. For night out, we boost bar, pub, theaters, music venues and avoid venues that are closed at night, e.g. brunch restaurants. For day trip, in contrast we avoid hotel, bar, pub, theaters and also avoid closed venues. For weekend trip, we mix hotels, restaurants and landmarks for every 5 suggestions in the ranking list. For longer trip, we mix hotels with other types of venues for every 5 suggestions in the ranking list.</p><p>The trip group includes: Travelling Alone, Travelling with a group of friends, Travelling with family, Travelling with an other group. For family trip we boost the amusement park. For group trips we boost the venues which bear "good for groups" property (Yelp and OpenTable have such information).</p><p>For season of the trip, we just avoid park, amusement park and zoo for winter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submitted Runs and Experiment Results</head><p>In this section, we report the results for batch experiment. We submitted two runs: UDInfoCS2015 fr and UD-InfoCS2015 nr. UDInfoCS2015 fr uses FR as the review representation and UDInfoCS2015 nr uses NR as the review representation. For both runs, we apply the advanced context filter to the ranking list. Table <ref type="table" coords="4,104.64,249.08,4.98,9.13" target="#tab_0">1</ref> shows the overall mean performances of our runs in terms of P@5. We also include the results of not applying the context filter as "-no-cf". We can see from the table that both of our runs have very promising performances. This confirms the effectiveness of using opinions to rank candidate suggestions. However, using context filter can hurt the performance a little bit as the performances with context filter are better. We may need to design more effective context filter in the future work. Since we have participated three years TRECs in a row, it is worthy to analyze more about our method since the main idea is highly consistent.</p><p>One important statistic we would like to evaluate is the number of reviews in both candidates and in our results. Our method in natural favors the suggestions with at least some amount of reviews (terms), especially the positive reviews. Table <ref type="table" coords="4,164.88,344.72,4.98,9.13" target="#tab_1">2</ref> shows the detailed statistics about the number of the reviews for both candidates and our results. From the table we can see that for our results the average number of reviews in the top 5 results is around 1,200 which is much larger than the average number (709) of reviews in the candidates. Even the number of reviews for relevant candidates is larger (average 938) the gap between it and our results is relatively huge. Moreover, we also have the statistic for number of terms in the reviews. This is a more reflective factor to look as the terms are directly used by our method. From the table we see that the average number of terms in the review for our results is much larger than that of for all the candidate suggestions. The gap between our results and the relevant candidate suggestions is also huge (approximately 15,000 terms difference). The quantities listed may unveil the shortage of our method and we would like to do more investigations about how the statistics of the reviews correlates with the performance in the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In Contextual Suggestion Track 2015, we leverage opinions as the source to model user and candidate profile. We use linear interpolation method as the ranking method which essentially computes the similarity between user profile and candidate profile. This year we also propose an advanced context filter which boost or remove the suggestions in the ranking list so that we can meet the context requirement. We submit two runs to Contextual Suggestion Track 2015. In general, both of them have promising performances. We further analyze the advantage and disadvantage of our method in order to provide more investigation results to the research community.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,230.04,62.67,151.71,38.57"><head>Table 1 .</head><label>1</label><figDesc>Overall Mean Performances</figDesc><table coords="4,234.24,81.63,143.70,19.61"><row><cell>Runs fr</cell><cell>nr fr-no-cf nr-no-cf</cell></row><row><cell cols="2">P@5 0.5583 0.5507 0.5972 0.6038</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,129.72,114.87,352.63,106.73"><head>Table 2 .</head><label>2</label><figDesc>Statistics of reviews</figDesc><table coords="4,129.72,133.95,352.63,87.65"><row><cell></cell><cell cols="3">reviews cnt. (mean) reviews cnt. (std) pos. terms cnt. (mean)</cell></row><row><cell>All Candidates</cell><cell>709</cell><cell>1650</cell><cell>46876</cell></row><row><cell>Relevant Candidates</cell><cell>938</cell><cell>1943</cell><cell>62288</cell></row><row><cell>Non-Relevant Candidates</cell><cell>491</cell><cell>1275</cell><cell>31977</cell></row><row><cell>fr</cell><cell>1217</cell><cell>1999</cell><cell>78586</cell></row><row><cell>fr-no-cf</cell><cell>1279</cell><cell>2080</cell><cell>81181</cell></row><row><cell>nr</cell><cell>1176</cell><cell>2017</cell><cell>76234</cell></row><row><cell>nr-no-cf</cell><cell>1183</cell><cell>2019</cell><cell>75390</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,72.36,690.75,98.74,8.21"><p>https://www.google.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,72.36,701.79,86.50,8.21"><p>http://www.yelp.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,72.36,712.71,113.87,8.21"><p>http://www.tripadvisor.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,72.36,723.63,108.94,8.21"><p>http://www.opentable.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,72.36,723.63,312.06,8.21"><p>Available at https://s3.amazonaws.com/irj2014 yelp data/irj2014 yelp.tar.gz.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,65.96,623.31,483.54,8.21;4,74.52,634.23,474.99,8.21;4,74.52,645.27,175.85,8.21" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,170.04,623.31,262.50,8.21">An exploration of axiomatic approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,454.92,623.58,94.58,7.54;4,74.52,634.23,446.25,8.21">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="480" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,65.96,656.19,454.53,8.21" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,165.85,656.19,209.99,8.21">An opinion-aware approach to contextual suggestion</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,395.64,656.46,95.84,7.54">Proceedings of TREC&apos;13</title>
		<meeting>TREC&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,65.96,667.11,483.68,8.21;4,74.52,678.15,20.80,8.21" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,168.49,667.11,258.22,8.21">Exploration of opinion-aware approach to contextual suggestion</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,448.08,667.38,96.43,7.54">Proceedings of TREC&apos;14</title>
		<meeting>TREC&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,65.96,689.07,483.78,8.21;4,74.52,699.99,194.78,8.21" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,241.67,689.07,308.07,8.21;4,74.52,699.99,39.96,8.21">Opinions matter: A general approach to user profile modeling for contextual suggestion</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,122.76,700.26,36.57,7.54">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="586" to="610" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
