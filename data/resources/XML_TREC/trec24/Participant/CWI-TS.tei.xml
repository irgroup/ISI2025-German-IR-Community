<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,114.08,71.87,381.56,16.84;1,215.07,91.79,179.58,16.84">CWI and TU Delft at the TREC 2015 Temporal Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,136.68,136.82,110.41,11.06"><forename type="first">Jeroen</forename><forename type="middle">B P</forename><surname>Vuurens</surname></persName>
							<email>j.b.p.vuurens@tudelft.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hague University of Applied Science Delft University of Technology</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,373.97,136.82,87.73,11.06"><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">CWI Delft University of Technology</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,114.08,71.87,381.56,16.84;1,215.07,91.79,179.58,16.84">CWI and TU Delft at the TREC 2015 Temporal Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C96443548E1CADE45F990E4E2E85C787</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Internet users are turning more frequently to online news as a replacement for traditional media sources such as newspapers or television shows. Still, discovering news events online and following them as they develop can be a difficult task. In previous work, we presented a novel approach to extract sentences from an online stream of news articles that summarizes the most important news facts for a given ad-hoc information need, which compared to existing systems obtained relatively high-precision results and a comparable recall <ref type="bibr" coords="1,105.26,306.99,9.52,7.77" target="#b8">[9]</ref>. In this track, we experiment with this approach to improve the recall of retrieved results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DESIGN 2.1 News extraction process</head><p>The core technique of temporal summarization is to summarize multiple texts by extracting salient sentences. Regarding measures of salience that can be used to choose the best sentences for news summarization, the literature provides no clear consensus. Two general criteria to select the best candidates sentences are the most useful and novel sentences, i.e., related to the topic and non-redundant <ref type="bibr" coords="1,108.33,439.12,10.45,7.77" target="#b0">[1]</ref> .</p><p>This track submission is based on previous work <ref type="bibr" coords="1,235.47,449.58,9.52,7.77" target="#b8">[9]</ref>, in which we propose to extract the most salient sentences from an online news stream using a three-step process: route, identify salient sentences and summarize. The key method underpinning this approach is a clustering method that takes care of both the routing and the identification of salient sentences. In the first step, the news articles are added in timely order to a clustering graph that aims to cluster news articles that discuss the same news, and identifying cluster that contain a news article that matching the topic as a 'topic matching cluster' . In the second step, per topic, we cluster the contents of clusters that match the topic to identify the most central sentences, which we consider the most salient ones. In the third step, we summarize the salient information by qualifying only the most novel and useful sentences from the current document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">3-Nearest-Neighbor clustering</head><p>For clustering of information, we use a 3-NN streaming variant of k-Nearest Neighbor clustering that assigns directed edges to each article's three nearest neighbors while not allowing nearest neighbor links within the same web domain <ref type="bibr" coords="1,193.82,648.71,9.52,7.77" target="#b8">[9]</ref>. In this clustering graph we detect newly formed clusters as 2-degenerate cores, according to the theory of k-degenerate graphs <ref type="bibr" coords="1,186.07,669.63,9.52,7.77" target="#b4">[5]</ref>. These 2-degenerate cores identify the most central information based on similarity in content, proximity in publication time and support by multiple news agents. The selected news is therefore is more likely to be factual, correct and important.</p><p>In Figure Figure <ref type="figure" coords="1,390.54,210.35,3.36,7.77">1</ref>, we illustrate the online process that takes place upon the arrival of new articles (that correspond to nodes in the graph), when clusters are formed, expanded or disbanded using 3-NN. Edges in the graph point to one of a node's k-nearest neighbors, labeled with the similarity between the nodes. Dashed arrows indicate the similarity between new arriving nodes and existing nodes. For the forming of clusters, we consider only bi-directional edges and form a 2-degenerate core when the arriving node and a group of previously unclustered nodes are all connected to at least 2 other nodes in the newly formed cluster. The most common scenario is a triangle of 3 nodes, but larger cores do occur. Nodes that are not part of a 2-degenerate core can still assigned to a cluster, during step 1 if their majority of nearest neighbors is a member of the same cluster, and in step 2 if there additionally exists a directed path to that node from one of the core nodes. For more information on 3-NN clustering, we refer to <ref type="bibr" coords="1,431.60,367.26,9.52,7.77" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Selection of top ranked sentences</head><p>Following <ref type="bibr" coords="1,364.57,397.65,9.52,7.77" target="#b8">[9]</ref>, a redundant stream of news articles is aggregated into a concise summary by selecting only sentences that are most relevant to the most recent developments for the topic. Without the use of training documents, we obtain a model of the most important information from the news stream, however, what information is important for a topic can change over time <ref type="bibr" coords="1,484.69,449.95,9.52,7.77" target="#b1">[2]</ref>. Yang et al. observed that a time gap between bursts of topically similar stories is often an indication of different events, suggesting a need for monitoring cluster evolution over time and a possible benefit from using a time window for event scoping <ref type="bibr" coords="1,440.51,491.80,13.74,7.77" target="#b9">[10]</ref>. If significant shifts in vocabulary indicate stories that report a novel event, this motivates the use of an adaptive model that allows to identify novel events. Analogous to <ref type="bibr" coords="1,367.56,523.18,9.52,7.77" target="#b2">[3]</ref>, we propose an unsupervised 'berry-picking' approach that estimates relevance at some point in time based on the information seen in a window over the prior h hours, and compare the estimated relevance of the candidate sentences to sentences already summarized, to selectively qualify only candidate sentences that rank among the top-r sentences. The rationale for this berrypicking approach is that news topics tend to evolve over several subtopics; consider for example a crime happening, the police investigation, a suspect being arrested, etc. Some subtopics are repeatedly reported over a longer period, while others are mentioned only briefly. We construct a relevance model for a news topic (a current 'event profile'), which is initially seeded with the terms that appear in the topic's query. The model is continuously expanded with the core node sentences from all topic matching clusters to limit the risk of adding off-topic information. An adaptive relevance model is obtained at time t by removing sentences that were published before th hours, allowing to shift the notion of relevance to recently seen information. In the event the relevance model contains no sentences published after th, the relevance model returns to .7 .6</p><p>.4</p><p>(d) E is assigned to the same cluster, because the majority of its nearest neighbors lie in the cluster formed by A, B, F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head><p>C D E F G .9</p><p>.9 .7</p><p>.7</p><p>.6</p><p>.5</p><p>.7 .7 .6 .7</p><p>.5</p><p>.4</p><p>(e) Upon arrival of G, A loses its edge to F, breaking the bi-directional loop that justified assigning A, B and F to the same cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head><p>C D E F G .9</p><p>.9 .7 .5 .6</p><p>.7</p><p>.4</p><p>.5 .7</p><p>.7</p><p>.7</p><p>(f) Consequently, nodes A, B, F, E no longer form a cluster. Note that the single connection from B and F to A is not sufficient to maintain the cluster, since A and D/E could be assigned to a different cluster each.</p><p>Figure <ref type="figure" coords="2,79.68,353.83,3.49,7.77">1</ref>: Explaining when clusters are created and broken using the nearest neighbor heuristic, K = 3, with the requirement that nodes are only clustered when they are members of a 2-degenerate core or when their majority of nearest neighbors is a member the same cluster. the original query terms. For ranking, we express the relevance at a given a point in time as a word vector, where the frequency of each word is the number of sentences it appeared in over the last h hours. The candidate sentences of the latest arriving document are then ranked among the sentences currently in the summary, using the cosine similarity between each sentence and the relevance vector. Candidate sentences ranked outside the top-r are disqualified for use in the summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Normalized Information Gain</head><p>In the original work <ref type="bibr" coords="2,138.71,502.26,9.52,7.77" target="#b8">[9]</ref>, cosine similarity was used to measure the similarity between sentences. In a previous study, for the task of constructing a hierarchical clustering of the sub news stories that are contained in the retrieved summary for a given topic, we proposed to cluster news articles that are likely to discuss the same news story using normalized information gain <ref type="bibr" coords="2,226.37,554.56,9.52,7.77" target="#b6">[7]</ref>. In that study, the use of normalized information gain appeared far more effective than using cosine similarity.</p><p>Following <ref type="bibr" coords="2,100.99,585.94,9.52,7.77" target="#b6">[7]</ref>, the dissimilarity (or impurity) between documents is estimated by a normalized version of the information gain. Information gain has been successfully used when considering a fixed number of non-sparse dimensions of a data set <ref type="bibr" coords="2,233.71,617.33,9.71,7.77" target="#b5">[6,</ref><ref type="bibr" coords="2,247.05,617.33,6.47,7.77" target="#b3">4]</ref>, however, in text collections the information gain is not comparable between subsets that use a different number of features. We introduce normalized information gain to address this problem, a measure that returns 0 for identical subsets and 1 for disjoint subsets. Formally, in Equation 1 H is the entropy over the words w in a bag of words s, given the size of the content c and f w,s is the frequency of word w in s. In Equation <ref type="formula" coords="2,116.94,690.55,3.36,7.77" target="#formula_1">2</ref>, the information gain IG is defined for separating a group of content s +t into two separate bags of words s and t, with |s|, |t| and |s + t| as the number of words contained. In Equa-tion 3, IG max is the maximum information gain that would be obtained given the sizes of data subsets t and s if these are completely disjoint, and in Equation <ref type="formula" coords="2,411.79,416.25,4.48,7.77" target="#formula_3">4</ref>IG is divided by IG max to normalize IG norm to a value in [0, 1]. We converted this dissimilarity measure into a similarity measure by simply using 1 -IG norm . To compare the difference between these cosine similarity and normalized information gain, the run titled "docs" clusters news articles in step 1 using cosine similarity between the entire documents, and the run titled "IGn" alternatively uses normalized information gain.</p><formula xml:id="formula_0" coords="2,356.48,502.41,199.44,22.21">H(s, c) = -∑ w∈s f w,s c log 2 f w,s c<label>(1)</label></formula><formula xml:id="formula_1" coords="2,354.76,529.62,201.15,33.86">IG(s,t) =H(s + t, |s| + |t|) - |s| |s| + |t| • H(s, |s|) - |t| |s| + |t| • H(t, |t|)<label>(2)</label></formula><formula xml:id="formula_2" coords="2,342.63,569.17,213.29,33.86">IG max (s,t) =H(s, |s| + |t|) + H(t, |s| + |t|) - |s| |s| + |t| • H(s, |s|) - |t| |s| + |t| • H(t, |t|)<label>(3)</label></formula><formula xml:id="formula_3" coords="2,339.38,608.26,216.53,20.90">IG norm (s,t) = IG(s,t) IG max (s,t)<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Improving Precision/Recall</head><p>We experimented with the above approach in a live demo <ref type="bibr" coords="2,528.44,659.17,9.52,7.77" target="#b7">[8]</ref>, and using the TREC 2014 Temporal Summarization track as training set. During these experiments we observed that the above approach works better for under-specified queries than for over-specified queries, e.g. "Buenos Aires train accident" as an over-specified query is likely to miss news articles that do not contain all words, while the Table <ref type="table" coords="3,76.02,55.28,3.49,7.77">1</ref>: Results for our runs on the 2015 TREC TS track and the average over all TREC participants for task 1. * indicates runs that were not included in the annotation pool, but results were estimated based on the sentences that were annotated. under-specified queries "Buenos Aires train" or "Buenos Aires" for large crisis are likely to be dominated by the train accident in the given time interval and therefore the higher recall is often not at the expense of (much) lower precision. The original approach selects only cluster that contain a news article with all the query terms in its title, which for over-specified queries can result in a very low recall. Alternatively, all runs with a name other than "titles" match news articles that contain all query terms in the entire document rather than only the title.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>To analyze the effect of changing parameters on the tradeoff between recall and precision, we submitted additional runs that specifically aimed at higher precision or recall (see <ref type="bibr" coords="3,246.76,307.49,10.45,7.77" target="#b8">[9]</ref> for a description of these parameters). By default, the runs used gain &gt;= 0.5, sentence length &lt;= 20, top-5 and a relevance model over the past hour. Alternatively, the runs titled "docsRecall" and "IGnRecall" used length &lt;= 30 and gain &gt;= 0.3, and the run titled "IGn-Precision" used top-1 and a time window = 0.5 hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Efficiency</head><p>For the run titled "titles" the three exact nearest neighbors were retrieved for each news article title, however, for alternative approaches that consider the entire documents brute force retrieval of the nearest neighbors is no longer feasible. Therefore we approximated the three nearest neighbors for a given news article by indexing the trigrams and bigrams contained in each news article (ignoring stop words), and considering only articles that have at least one trigram in common, and if less than 10 such news articles are found also consider the articles that have at least one bigram in common.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RESULTS</head><p>In Table <ref type="table" coords="3,96.78,533.64,4.48,7.77">1</ref> are the results of our submitted runs and the average over all TREC participants for task 1 "Filtering and Summarization". The original approach described in <ref type="bibr" coords="3,222.65,554.56,10.45,7.77" target="#b8">[9]</ref> was used in the run labelled "titles", which has a lower comprehensiveness (recall) compared to the other runs. In fact, for 4 out of the 21 topics no results were returned simply because of the lack of news article titles that contain all query terms. Recall was improved in the run titles "docs" by matching the query terms in the entire document rather than just the title, however the gain (precision) is much lower possibly indicating that clustering the news articles using cosine similarity over their complete contents may add more useless documents than using only their titles. Following the findings in <ref type="bibr" coords="3,246.23,648.71,9.52,7.77" target="#b6">[7]</ref>, we alternatively measured similarity between documents using normalized information gain in the runs that start with "IGn", which obtains a consistently better gain-comprehensiveness trade-off. The run that specifically targets a higher gain "IGnPrecision" obtained the overall best performance in F-measure. Since the run titled "IGnRecall" was not annotated, the reported numbers are an estimation based on the overlap in results with the other runs and ignoring sentences that were not scored, which may not be accurate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,101.97,99.27,6.47,7.77;2,165.84,99.15,5.98,7.77;2,134.03,67.41,5.98,7.77;2,197.41,67.33,6.47,7.77;2,197.90,130.96,5.48,7.77;2,133.77,87.04,6.72,7.77;2,133.77,111.29,6.72,7.77;2,114.66,86.18,6.72,7.77;2,178.36,124.56,6.72,7.77;2,165.45,67.87,6.72,7.77;2,184.43,92.50,6.72,7.77;2,184.54,118.38,6.72,7.77;2,96.39,149.32,125.53,6.91;2,96.39,158.29,125.53,6.91;2,96.39,167.25,125.53,6.91;2,96.39,176.22,125.53,6.91;2,96.39,185.19,125.53,6.91;2,96.39,194.15,125.53,6.91;2,247.67,91.54,6.47,7.77;2,311.54,91.41,5.98,7.77;2,279.73,59.68,5.98,7.77;2,343.11,59.60,6.47,7.77;2,343.61,123.23,5.48,7.77;2,280.23,135.95,4.99,7.77;2,248.92,136.03,3.98,7.77;2,279.48,79.31,6.72,7.77;2,279.48,103.55,6.72,7.77;2,260.37,78.45,6.72,7.77;2,324.06,116.82,6.72,7.77;2,311.16,60.13,6.72,7.77;2,330.13,84.76,6.72,7.77;2,263.62,120.28,6.72,7.77;2,295.15,119.94,6.72,7.77;2,311.09,135.96,6.72,7.77;2,261.93,142.31,6.72,7.77;2,330.24,110.64,6.72,7.77;2,242.09,158.29,125.53,6.91;2,242.09,167.25,125.53,6.91;2,242.09,176.22,125.53,6.91;2,242.09,185.19,125.53,6.91;2,242.09,194.15,118.45,6.91;2,393.37,101.11,6.47,7.77;2,457.25,100.99,5.98,7.77;2,425.43,69.25,5.98,7.77;2,488.81,69.17,6.47,7.77;2,489.31,132.80,5.48,7.77;2,425.93,145.53,4.99,7.77;2,425.18,88.68,6.72,7.77;2,425.18,113.32,6.72,7.77;2,406.07,88.02,6.72,7.77;2,475.94,120.21,6.72,7.77;2,475.83,94.34,6.72,7.77;2,405.16,133.02,6.72,7.77;2,405.16,133.02,6.72,7.77;2,456.86,69.71,6.72,7.77;2,436.71,126.75,6.72,7.77;2,445.01,132.67,6.72,7.77;2,413.48,127.08,6.72,7.77;2,457.93,151.27,6.72,7.77;2,387.80,167.25,125.53,6.91;2,387.80,176.22,125.53,6.91;2,387.80,185.19,125.53,6.91;2,387.80,194.15,112.23,6.91;2,101.97,241.46,6.47,7.77;2,165.84,241.34,5.98,7.77;2,134.03,209.61,5.98,7.77;2,197.41,209.53,6.47,7.77;2,197.90,273.16,5.48,7.77;2,134.52,285.88,4.99,7.77;2,133.77,229.03,6.72,7.77;2,133.77,253.68,6.72,7.77;2,114.67,228.37,6.72,7.77;2,184.54,260.57,6.72,7.77;2,184.43,234.69,6.72,7.77;2,113.76,273.38,6.72,7.77;2,113.76,273.38,6.72,7.77;2,165.46,210.06,6.72,7.77;2,145.30,267.10,6.72,7.77"><head></head><label></label><figDesc>The initial state has no clusters. Clusters are not formed on single connected subgraphs: C and D could have a majority of their nearest neighbors in two different clusters, which would lead to ambiguity in cluster assignment. When new node F arrives, edges of existing nodes to their weakest nearest neighbor are replaced if the new node is more similar. E.g., the edge from B to E is replaced by an edge from B to F. A cluster is created when 3 or more nodes form an bi-directional loop. E.g., A, B and F form a cluster sharing the majority of their nearest neighbors.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,336.23,241.24,219.69,7.77;3,336.23,251.55,219.68,7.93;3,336.23,262.01,219.69,7.72;3,336.23,272.47,182.98,7.93" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,480.45,241.24,75.47,7.77;3,336.23,251.70,49.29,7.77">Temporal summaries of new topics</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Khandelwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,406.76,251.55,149.16,7.72;3,336.23,262.01,219.69,7.72;3,336.23,272.47,83.20,7.72">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,290.25,219.68,7.77;3,336.23,300.56,219.68,7.93;3,336.23,311.02,219.69,7.72;3,336.23,321.48,182.98,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,467.17,290.25,88.75,7.77;3,336.23,300.71,59.74,7.77">On-line new event detection and tracking</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Papka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,412.97,300.56,142.94,7.72;3,336.23,311.02,219.69,7.72;3,336.23,321.48,83.20,7.72">Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 21st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,339.27,219.69,7.77;3,336.23,349.58,219.68,7.93;3,336.23,360.19,77.95,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,395.27,339.27,160.65,7.77;3,336.23,349.73,154.30,7.77">The design of browsing and berrypicking techniques for the online search interface</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,502.15,349.58,50.11,7.72">Online review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="407" to="424" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,377.82,219.69,7.77;3,336.23,388.13,219.68,7.93;3,336.23,398.75,20.17,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,485.24,377.82,70.68,7.77;3,336.23,388.28,160.78,7.77">Entropy-based subspace clustering for mining numerical data</title>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,520.80,388.13,30.10,7.72">SIGKDD</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,416.38,219.69,7.77;3,336.23,426.84,219.69,7.77;3,336.23,437.15,219.69,7.93;3,336.23,447.61,135.14,7.93" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,402.38,426.84,153.54,7.77;3,336.23,437.30,83.27,7.77">Degeneracy-based real-time sub-event detection in twitter stream</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Meladianos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Nikolentzos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Stavrakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vazirgiannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,435.47,437.15,120.45,7.72;3,336.23,447.61,108.53,7.72">Ninth International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,465.24,219.68,7.93;3,336.23,475.86,68.99,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,389.00,465.40,94.40,7.77">Induction of decision trees</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,489.81,465.24,62.48,7.72">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="106" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,493.49,219.69,7.77;3,336.23,503.80,219.69,7.93;3,336.23,514.26,88.09,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,537.18,493.49,18.74,7.77;3,336.23,503.95,158.11,7.77">Hierarchy construction for news summarizations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B P</forename><surname>Vuurens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,512.49,503.80,43.43,7.72;3,336.23,514.26,61.39,7.93">SIGIR TAIA Workshop. SIGIR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,532.05,219.69,7.77;3,336.23,542.35,219.68,7.93;3,336.23,552.97,44.72,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="3,541.98,532.05,13.94,7.77;3,336.23,542.51,175.12,7.77">Online news tracking for ad-hoc information needs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B P</forename><surname>Vuurens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,531.26,542.35,20.55,7.72">ICTIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,570.60,219.69,7.77;3,336.23,580.91,219.68,7.93;3,336.23,591.52,20.17,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="3,541.98,570.60,13.94,7.77;3,336.23,581.06,131.06,7.77">Online news tracking for ad-hoc queries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B P</forename><surname>Vuurens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,483.33,580.91,43.44,7.72">SIGIR Demo</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,336.23,609.16,219.69,7.77;3,336.23,619.47,219.69,7.93;3,336.23,629.93,219.69,7.72;3,336.23,640.39,211.62,7.93" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="3,469.72,609.16,86.20,7.77;3,336.23,619.62,94.65,7.77">A study of retrospective and on-line event detection</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,446.19,619.47,109.73,7.72;3,336.23,629.93,219.69,7.72;3,336.23,640.39,111.83,7.72">Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 21st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
