<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.91,78.57,408.17,14.36">Event Oriented Query Expansion for News Event Queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,252.59,118.35,43.85,9.52"><forename type="first">Kuang</forename><surname>Lu</surname></persName>
							<email>lukuang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.15,118.35,40.27,9.52"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.91,78.57,408.17,14.36">Event Oriented Query Expansion for News Event Queries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CCBD7F42F709E7713DF607362C52DF1E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Query expansion techniques have been commonly used by participants in Temporal Summarization tack. However, many previous attempts focused on expanding queries based on their event types, which only covers partially of the information need represented by queries. The reason is that the queries in the TS track are about news events, and for an event query, the event related entities, which are the entities mentioned in the queries, are essential when defining the event. Given the query "Vauxhall helicopter crash", without "Vauxhall" or "helicopter", the event cannot be specifically defined. Therefore, we argue that both event type and event related entities should be considered when expanding a query, and a model based query expansion framework is proposed which incorporates these two types of information. The framework is then employed by using external resources, such as external corpora and Wikipedia pages to build expansion models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Temporal Summarization track aims to develop systems for e ciently monitoring the information associated with an event over time, and the queries provided are about news events, such as protests, accidents or natural disasters <ref type="bibr" coords="1,161.09,417.26,11.67,9.52" target="#b0">[1]</ref>. Since the start of the track, query expansion is employed by many participants <ref type="bibr" coords="1,520.15,417.26,12.47,9.52" target="#b1">[2]</ref> [3] and seems to be essential. However, previous participants tend to use only event type related information to expand queries, meaning that they tried to find information usually used to describe an event type to obtain a richer query representation. Although this type of approach is indeed helpful since it reduces the vocabulary gap between the query and relevant documents/sentences, it is still insu cient for the event queries since it lacks of the information about another important aspect: event related entities. Here, event related entities are the entities mentioned in the query. They contain location, parties involved in the event and other information to a query that is essential for identifying the event of the query. Intuitively, when describing an event, usually two things are mentioned: event type and event related entities. Event type o↵ers general information about what the event is, whereas the event related entities can further specify the event instance. Therefore, these entities should also be considered when expanding event queries. For instance, for the query "Vauxhall helicopter crash", terms very related to the entity "Vauxhall"(e.g. London) can be very useful for capturing relevant information, since they are also likely to occur in relevant documents and sentences. Furthermore, information about event related entities could also help systems distinguishing between documents/sentences describing di↵erent events with the same event type. For instance, given the same query as above, if only event type information(e.g. air transport accident related terms such as "kill") is used to expand the query, a system could hardly distinguish truly relevant sentences from sentences describing other concurrently happening air transport accidents. Therefore, it can be argued that expanding queries with information about event-related entities in the query can be used to capture more aspects of queries and thus improve the performance.</p><p>In this year, we explore the potential of query expansion for event queries. Specifically, we identify two types of expansion information resources: event type information and event related entities. A language model based query expansion framework is built which incorporates these two types of information. Our system for the Temporal Summarization track employs this framework and uses auxiliary corpora and Wikipedia as the real sources of the two types of expansion information.</p><p>In order to fully expand an event query with all its aspects, we identify two types of information that should be used for query expansion: event type and event related entities. For event type, we could find terms usually used for describing the type of event that a query belongs to, and use the terms to expand the query. For instance, given a query "Vauxhall helicopter crash", if terms describing air transport accident, such as "kill" and "pilot", are added to the query, it is likely that a system could find relevant information more e↵ectively and accurately. For event related entities, which are the entities mentioned in queries, the terms used to describe these entities are likely to appear in relevant documents/sentences. For example, given the same query as above, there were other tra c accidents happening concurrently with this helicopter crash. Adding terms related to event related entities of this event instance, such as "London" and "UK", to the query model could help our system better distinguishes sentences related to the query from sentences related to other accident instances. This e↵ect can be illustrated in Figure <ref type="figure" coords="2,518.92,230.59,3.87,9.52" target="#fig_1">2</ref>. Model-based feedback has been shown e↵ective by previous studies <ref type="bibr" coords="2,384.71,483.55,12.15,9.52" target="#b3">[4]</ref>  <ref type="bibr" coords="2,400.16,483.55,9.96,9.52" target="#b4">[5]</ref>. Based on these studies, we propose a query expansion framework such that the expansion models come from both event type and event related entities. Our framework can be illustrated as Equation <ref type="formula" coords="2,389.09,507.46,3.87,9.52" target="#formula_0">1</ref>. For some query Q with event type T and a set of entities E, P (w | ✓Q ) denotes the estimate of the true query model. P (w | ✓Q ) is the maximum likelihood estimation of the query model using original query string. P (w | ✓ T ) is the estimate of the language model of event type T . P (w | ✓ E ) is the mixture of estimate language models of the event related entities. Note that ↵ + + = 1. If is set to zero, the expansion model is only about event type. Whereas if is set to zero, only event related entities contributes to the expansion model.</p><p>The model of event related entities can be estimated using Equation <ref type="formula" coords="2,399.80,580.16,3.87,9.52" target="#formula_1">2</ref>. e i is an event related entity mentioned in the query and P (w | e i ) is the language model usually used to describe the entity, |E| is the size of E, meaning the number of entities in the query.</p><formula xml:id="formula_0" coords="2,190.16,638.21,342.46,19.23">P (w | ✓Q ) = ↵P (w | ✓Q ) + P (w | ✓ T ) + P (w | ✓ E )<label>(1)</label></formula><formula xml:id="formula_1" coords="2,237.63,682.43,294.99,32.70">P (w | ✓ E ) = X ei2E 1 |E| P (w | e i )<label>(2)</label></formula><p>Although we submit multiple runs for task two and three of this year's TS track, the general framework of our methods is similar as shown in Figure <ref type="figure" coords="3,279.72,119.53,3.87,9.52">3</ref>. First, we pre-process the corpus to extract information such as sentence text, sentence id, document id, as well as document time, and the documents are stored in hourly batches for further process; second, we employ the query expansion model described above and estimate expansion model from external resources to build rich query representation and use them to compute relevance scores of documents and sentences; finally, relevant documents are selected, and from them, relevant sentences are selected with redundant sentences removed. Note that document selection is not always performed since for task three, all documents in the sub-corpus are relevant. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus Pre-processing</head><p>Since the corpus is stored in the Thrift format and contains information that might not be useful to the task, such as original html content, we chose to preprocess the corpus to store only the information that is used by us. First, we filtered out documents that are not news articles, as done by some participants of previous TS tracks <ref type="bibr" coords="3,173.14,549.16,11.81,9.52" target="#b1">[2]</ref>, since the sentences in news articles are well written and we do not need to worry about the documents being spam web pages. After that, for every document, only its document id, timestamp, sentence text and sentence id are extracted for latter usage. Porter stemming is performed on all sentences before they are stored. Because we decide to generate updates hourly, documents with timestamps of the same hour are stored into the same file to ease further process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Expansion Implementation</head><p>In order to avoid using future information, we decided to use external resources to build expansion models.</p><p>Using external resources is shown to be e↵ective for query expansion by previous study <ref type="bibr" coords="3,452.29,661.47,23.96,9.52">[5][6]</ref>. We use two types of external resources: external corpora and Wikipedia pages. For the external corpora, some of them are previous trec corpora: the AQUAINT corpus 1 which is divided into three corpora (apw, nyt, xie) according to the news agencies, trec-ap corpus<ref type="foot" coords="4,306.40,81.07,3.97,6.39" target="#foot_1">2</ref> and Wall Street Journal corpus<ref type="foot" coords="4,454.28,81.07,3.97,6.39" target="#foot_2">3</ref> . We also used a corpus of New York Times pages crawled from 2006 to 2011. These corpora consist of only news articles and thus the quality of the document text is high. Moreover, for the Wikipedia pages, we automatically crawled some Wikipedia page revisions according to the original queries. What are the pages that we crawled will be discussed later. It is important to note that we only use the documents and Wikipedia page revisions strictly before the query start time so that no future information is used.</p><p>In order to find event type related information, we first need to define event types for queries. Since the queries in the Temporal Summarization track are mostly disasters, we use and the disaster classification from an online disaster database maintained by the Center for Research on the Epidemiology of Disasters (CRED) <ref type="bibr" coords="4,120.09,190.33,10.51,9.52" target="#b6">[7]</ref> as well as the query and type field of the queries to manually define finer event types for all queries, as shown in Table <ref type="table" coords="4,214.18,202.29,3.87,9.52" target="#tab_0">1</ref>. To expand queries using event type related information, we employ a method similar to <ref type="bibr" coords="4,162.52,214.24,9.96,9.52" target="#b4">[5]</ref>. Specifically, for each event type, its name is used as query to search against all corpora. For every corpus, top ranked documents are used to estimate a language model. We take the average of these relevance models to form an expansion model for the event type with the term weights discounted by the corpus frequency of the term, meaning that the less the number of corpora a term occurs, the more its weigh is punished. Basically, we want to degrade the e↵ect of the terms which are only frequent in documents in some corpora but not in others. For example, the term "China" in the Xinhua corpus has very high weight, which is probably caused by the fact that Xinhua is a news agency in China. However, adding the term to queries might not help improving performance. Being able to punish such terms is also the reason why we use multiple corpora together. For each of this language model related to a certain event type, we call it the "profile" of the event type. Each query will have a event type profile associated with it, and the profile is added to the final query model for relevance calculation.</p><p>For estimating language models of event related entities, we use Wikipedia as the source. Specifically, inspired by <ref type="bibr" coords="4,124.54,370.09,11.90,9.52" target="#b5">[6]</ref>, we first use exact match to find the sub query strings that are the titles of some Wikipedia pages, and use them as event related entities. For every one of such Wikipedia pages, we find all other Wikipedia pages referred to, or referred by the page and crawled the content of the revisions of these pages as well as the original page. The original query substring is then used as the query to rank these pages, and top ranked pages were used to build a language model about the substring. All the language models of the querys substrings are combined to expand the query. The rational behind this method is that the top ranked Wikipedia pages for an event related entity contain considerable text that related to the entity, and thus it is reasonable to estimate the language of the entity from these Wikipedia articles. Moreover, it is also important to note that since some of the query entities can also be related to the disaster event, such as "explosion" in query "brazzaville explosion", and therefore the query expansion model generated by them are actually about event types. Such expansion models are also helpful in finding relevant information, and thus we did not try to distinguish these entities from others. We call the expansion model we obtain from Wikipedia pages as "Wikipedia expansion models". Note that, in order to avoid using future information, we used a dump of the Wikipedia page link information that was generate by dbpedia on March, 2010 <ref type="foot" coords="4,258.90,536.24,3.97,6.39" target="#foot_3">4</ref> to detect query entities and find related pages. Moreover, all the crawled revisions of the Wikipedia pages were written before the query start time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Document and Sentence Selection</head><p>The way we select relevant documents and sentences are very similar. Since we used language modeling based query expansion and documents and sentences are both represented as language models, it is reasonable to use the same method, which is query likelihood with Dirichlet smoothing <ref type="bibr" coords="4,457.19,627.50,9.96,9.52" target="#b7">[8]</ref>, to rank them. One of the di↵erences is that the document relevance scores are only computed by using documents, but the relevance scores of sentences are computed by using both sentences and the documents containing them. In other words, the sentence relevance score is a linear interpolation between relevance scores Another di↵erence between document and sentence selection is the selection cuto↵. For document selection, we chose to use top ten documents. Experiments on last years data showed that for various expansion models, using top 10 documents can cover more than 90% of nuggets. We think such nugget recall is su cient for generating sentence updates with reasonable performance. Moreover, the number of documents is also small enough to speed up sentence selection. However, the relevance score of sentences are very sensitive to what types expansion models are used, and it is not reasonable to set a fixed number as the cuto↵ since the number of relevant sentences is largely various among di↵erent queries. Therefore, for di↵erent runs we tuned the parameters of retrieval model as well as the relevance score threshold on last years data and apply them to this year 's methods. After finding candidate sentences, redundant sentences need to be removed. We use simple cosine similarity and also tuned the similarity threshold on last year 's data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submissions</head><p>In this years TS track, there are three tasks and the di↵erence is only the corpus. We chose to only participate in the second and third task since the sizes of the corpora are much smaller. All the parameters of the runs are tuned in previous year's data. The detailed description for our submissions are explained below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task 2</head><p>For task two which has a pre-filtered corpus with smaller number of documents that are more likely to be relevant, we submitted three runs. Since the aim of us in this year's track is to examine how e↵ective our expansion framework is, the only di↵erence between the three runs is the expansion model:</p><p>-WikiProfMixFS: In this run, we use the both event type profile and Wikipedia expansion model to expand the queries. -WikiOnlyFS: We only use Wikipedia expansion model in this run.</p><p>-ProfOnlyFS: Only event type profile is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task 3</head><p>For task three, the documents in the sub corpus is ensured to be relevant. We also choose to submit three runs. They are similar to the runs we submitted to task two without performing document filtering, since that is not necessary:</p><p>-WikiProfMix: In this run, we use the both event type profile and Wikipedia expansion model to expand the queries. -WikiOnly: We only use Wikipedia expansion model in this run.</p><p>-ProfOnly: Only event type profile is used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,115.20,447.88,381.60,8.57;2,92.16,264.16,427.68,169.13"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Adding Information about Event Related Entity Helps Improving System Performance</figDesc><graphic coords="2,92.16,264.16,427.68,169.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,234.94,438.70,142.12,8.57;3,194.55,223.45,222.91,200.66"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. General System Framework</figDesc><graphic coords="3,194.55,223.45,222.91,200.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,79.37,79.27,453.25,182.44"><head>Table 1 .</head><label>1</label><figDesc>The Event Types of Queries</figDesc><table coords="5,79.37,94.73,453.25,166.98"><row><cell>Query</cell><cell>Event Type</cell></row><row><cell>26</cell><cell>air transport accident</cell></row><row><cell>27</cell><cell>tropical storms</cell></row><row><cell>28, 38</cell><cell>collapse</cell></row><row><cell>29, 34, 35, 36 ,37,39, 40, 41</cell><cell>bombing</cell></row><row><cell>30</cell><cell>explosion</cell></row><row><cell>31</cell><cell>power explosion</cell></row><row><cell>32, 46</cell><cell>protest</cell></row><row><cell>33</cell><cell>conflict</cell></row><row><cell>42</cell><cell>fire</cell></row><row><cell>43</cell><cell>water transport accident</cell></row><row><cell>44, 45</cell><cell>earthquake</cell></row><row><cell cols="2">computed against document model and sentence model. It is reasonable since we argue that sentences in</cell></row><row><cell>a relevance document are more likely to be relevant.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,89.33,706.30,180.86,8.57"><p>http://www-nlpir.nist.gov/projects/aquaint/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,89.33,684.38,253.50,8.57"><p>http://www.daviddlewis.com/resources/testcollections/trecap/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,89.33,695.34,171.30,8.57"><p>https://catalog.ldc.upenn.edu/LDC93T3A</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,89.33,706.30,125.51,8.57"><p>http://dbpedia.org/data-set-36</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,82.95,157.72,449.67,8.57;6,91.52,168.68,314.38,8.57" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,418.06,157.72,114.56,8.57;6,91.52,168.68,90.62,8.57">Trec 2014 temporal summarization track overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,204.47,168.68,168.74,8.57">Proceedings of the 2014 TREC conference</title>
		<meeting>the 2014 TREC conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,179.64,449.68,8.57;6,91.52,190.60,123.91,8.57" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,239.91,179.64,197.12,8.57">Ictnet at temporal summarization track trec 2013</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,458.71,179.64,73.92,8.57;6,91.52,190.60,91.22,8.57">Proceedings of the 2013 TREC conference</title>
		<meeting>the 2013 TREC conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,201.56,449.67,8.57;6,91.52,212.52,102.42,8.57" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,235.53,201.56,180.40,8.57">Hltcoe at trec 2013: Temporal summarization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">D</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,437.66,201.56,94.96,8.57;6,91.52,212.52,69.72,8.57">Proceedings of the 2013 TREC conference</title>
		<meeting>the 2013 TREC conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,223.48,449.68,8.57;6,91.52,234.43,70.89,8.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,182.57,223.48,346.18,8.57">Model-Based Feedback in the Language Modeling Approach to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>La↵erty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,105.60,234.43,22.51,8.57">CIKM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,245.39,449.67,8.57;6,91.52,256.35,441.11,8.57;6,91.52,267.31,263.50,8.57" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,180.71,245.39,295.15,8.57">Improving the estimation of relevance models using large external corpora</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,497.41,245.39,35.22,8.57;6,91.52,256.35,441.11,8.57;6,91.52,267.31,81.49,8.57">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;06</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;06<address><addrLine>New York, NY, USA, ACM</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,278.27,449.67,8.57;6,91.52,289.23,329.02,8.57" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,215.76,278.27,191.16,8.57">Query expansion using wikipedia and dbpedia</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,228.20,289.23,154.39,8.57">Online Working Notes/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="middle">:</forename><surname>Eds</surname></persName>
		</editor>
		<editor>
			<persName><surname>Clef</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,300.19,449.68,8.57;6,91.52,311.15,125.23,8.57" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,220.00,300.19,179.50,8.57">Em-dat: International disaster database www</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Guha-Sapir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Below</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">H</forename></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>Universit Catholique de Louvain Brussels Belgium</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.95,322.11,449.67,8.57;6,91.52,333.06,203.23,8.57" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,184.50,322.11,344.56,8.57">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>La↵erty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,91.52,333.06,89.96,8.57">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004-04">April 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
