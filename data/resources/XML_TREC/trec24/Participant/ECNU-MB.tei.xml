<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,187.20,169.30,252.84,3.96">ECNU at TREC 2015: Microblog Track</title>
				<funder ref="#_uWcfSEu #_ARKGvP4">
					<orgName type="full">Science and Technology Commission of Shanghai Municipality</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,188.48,189.27,36.24,8.69"><forename type="first">Qin</forename><surname>Chen</surname></persName>
							<email>qchen@ica.stc.sh.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing East</orgName>
								<orgName type="institution">China Normal University</orgName>
								<address>
									<addrLine>500 Dongchuan Road</addrLine>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.41,189.27,34.20,8.69"><forename type="first">Bo</forename><surname>Wang</surname></persName>
							<email>bwang@ica.stc.sh.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing East</orgName>
								<orgName type="institution">China Normal University</orgName>
								<address>
									<addrLine>500 Dongchuan Road</addrLine>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.69,189.27,54.69,8.69"><forename type="first">Beijing</forename><surname>Huang</surname></persName>
							<email>bjhuang@ica.stc.sh.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing East</orgName>
								<orgName type="institution">China Normal University</orgName>
								<address>
									<addrLine>500 Dongchuan Road</addrLine>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.17,189.27,44.69,8.69"><forename type="first">Qinmin</forename><surname>Hu</surname></persName>
							<email>qmhu@cs.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing East</orgName>
								<orgName type="institution">China Normal University</orgName>
								<address>
									<addrLine>500 Dongchuan Road</addrLine>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,402.55,189.27,36.22,8.69"><forename type="first">Liang</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Multidimensional Information Processing East</orgName>
								<orgName type="institution">China Normal University</orgName>
								<address>
									<addrLine>500 Dongchuan Road</addrLine>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,187.20,169.30,252.84,3.96">ECNU at TREC 2015: Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9D9E2A670446AE977B9B81611E80B2E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in TREC 2015 Microblog track, which includes two tasks related to Scenario A and Scenario B. For Scenario A, we build a real-time tweet push system, which is mainly composed by three parts: feature extraction, relevance prediction and redundancy detection. Only the highly relevant and nonredundant tweets are sent to users based on the interest profiles. For Scenario B, we apply three query expansion methods, namely the web search based, the TFIDF-PRF based and the Terrier embedded PRF based. In addition, three state-of-the-art information retrieval models as the language model, BM25 model and DFRee model are utilized. The retrieval results are combined for final delivery. The experimental results in both scenarios demonstrate that our system obtains convincing performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2015 Microblog Track still focuses on the real time filtering. The goal is to push interesting content to a user according to his/her interest profile. Specifically, two concrete tasks are given to simulate two scenarios as Scenario A and Scenario B.</p><p>Scenario A is about pushing notifications on a mobile phone. A system for this scenario is allowed to return a maximum of 10 tweets per day per interest profile. The evaluation metric will penalize the gap between the tweet time and the notification time. To fulfill this task, we build a real-time tweet push system, whose architecture is shown in Figure <ref type="figure" coords="1,352.80,494.36,3.53,8.69" target="#fig_1">1</ref>. The system mainly consists of three parts: feature extraction, relevance prediction and redundancy detection. Only the tweets which are both relevant and nonredundant are finally sent to users. The performance of our submitted runs proves the e↵ectiveness of the system.</p><p>Regarding to Scenario B, it focuses on the periodic email digest. Specifically, a system for this scenario is required to deliver a batch of up to 100 ranked interesting tweets per day per interest profile. For this task, we leverage the Terrier search engine for indexing and retrieval, where the obtained tweets are indexed and retrieved by the hour. Three query expansion methods, namely the web search based <ref type="bibr" coords="1,189.32,581.61,9.08,8.69" target="#b1">[2]</ref>, TFIDF-PRF based <ref type="bibr" coords="1,284.81,581.61,9.59,8.69" target="#b1">[2]</ref> and the Terrier embedded pseudo relevance feedback based <ref type="bibr" coords="1,141.16,592.51,9.08,8.69" target="#b4">[5]</ref>, are applied for query expansion. In addition, we leverage three state-of-the-art information retrieval (IR) models, namely the language model <ref type="bibr" coords="1,321.19,603.42,9.08,8.69" target="#b5">[6]</ref>, the BM25 model <ref type="bibr" coords="1,408.04,603.42,9.59,8.69" target="#b6">[7]</ref> and the DFRee model <ref type="bibr" coords="1,116.59,614.33,9.08,8.69" target="#b0">[1]</ref>. Just before the day ends, all the results are combined and merged together to send to users.</p><p>2 Scenario A: Push Notifications on a Mobile Phone</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Overview</head><p>In this section, we demonstrate the architecture of our system, which is shown in Figure <ref type="figure" coords="2,490.51,166.44,3.53,8.69" target="#fig_1">1</ref>. It shows that our system mainly consists of three parts, namely feature extraction, relevance prediction and redundancy detection. The details of each part are demonstrated in the following sections.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature Extraction</head><p>We mainly focus on the three types of features as follows: (1) f(Q, T): the text similarity between the original query and the tweet; (2) f(GT, T): the text similarity between the Google searched titles and the tweet; (3) f(GS, T): the text similarity between the Google searched snippets and the tweet.</p><p>To calculate the text similarities, two widely used measures as the Jensen-Shannon Divergence (JSD) <ref type="bibr" coords="2,144.39,538.25,9.59,8.69" target="#b2">[3]</ref> and the Overlap Similarity(OS) are applied. Therefore, a total of six features can be extracted based on the text similarities. For the sake of simplicity, we only demonstrate how to extract f(Q, T). The features as f(GT, T) and f(GS, T) can be obtained in a similar way.</p><p>For the JSD measure, both the queries and tweets are required to be probability vectors, where all the entries sum up to 1. In our experiment, we obtain the vectors by normalized TF weighting with smoothing. Specifically, given a query vector as V Q and a tweet vector as V T , the JSD similarity is calculated as follows:</p><formula xml:id="formula_0" coords="2,225.23,610.45,281.57,21.29">JSD(Q, T ) = 1 2 KL(V Q ||M ) + 1 2 KL(V T ||M ) (<label>1</label></formula><formula xml:id="formula_1" coords="2,506.80,616.60,3.87,8.69">)</formula><p>where M is the average vector of the query and tweet. KL(V Q ||M ) denotes the Kullback-Leibler divergence <ref type="bibr" coords="2,161.05,646.92,9.59,8.69" target="#b3">[4]</ref> between the distributions of V Q and M .</p><p>To calculate the Overlap Similarity (OS) between a query and a tweet, we first obtain the corresponding word sets as S(Q) and S(T ). Then, OS(Q, T ) is formulated as:</p><formula xml:id="formula_2" coords="3,226.70,150.92,283.96,27.92">OS(Q, T ) = |S(Q) \ S(T )| |S(Q)| or |S(Q) \ S(T )| |S(T )|<label>(2)</label></formula><p>where S(Q) \ S(T ) represents the intersection of S(Q) and S(T ), and |.| denotes the size of the set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relevance Prediction Framework</head><p>Figure <ref type="figure" coords="3,153.71,214.15,4.54,8.69" target="#fig_2">2</ref> shows the framework of the relevance prediction part. A Logistic Regression model is trained o✏ine for its simplicity and e↵ectiveness. We use the o cial results of Microblog Track 2013 and 2014 as the training data set. The relevance judgement degree is ignored, which means both the relevant (judged as 1) and highly relevant (judged as 2) are assigned with a label 1. The features applied are demonstrated in Section 2.2. For a coming tweet in the tweet stream, we can quickly extract the features, and predict the relevance score with the trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Redundancy Detection Strategy</head><p>Since the pushed tweets are expected to be in di↵erent o cial clusters ideally, we perform redundant detection for the candidates. Specifically, for a candidate tweet specific to a query, we devise a redundancy detection strategy to determine whether it is redundant or not. The strategy is demonstrated in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Redundancy Detection</head><p>Input: a candidate pushed tweet T corresponding to query Q, the pushed tweet set P , the maximum pushed number n, the similarity threshold determining redundancy , the redundancy degree threshold ✓ Output: the Boolean redundancy label L(T ) // True: redundant, False: nonredundant We apply three query expansion methods, namely the web search based <ref type="bibr" coords="3,418.70,619.42,9.08,8.69" target="#b1">[2]</ref>, TFIDF-PRF based <ref type="bibr" coords="3,116.59,630.32,9.59,8.69" target="#b1">[2]</ref> and the Terrier embedded pseudo relevance feedback <ref type="bibr" coords="3,343.85,630.32,9.59,8.69" target="#b4">[5]</ref> based. By various combinations of the three methods, we obtain six kinds of queries as follows: (1) Q: the original query; (2) QG: query expanded by the Google searched results; (3) QT: query expanded with the TFIDF-PRF based method; (4) QP: query expanded with the Terrier embedded pseudo relevance feedback; (5) QGT: the union of QG and QT; (6) QGTP: the union of QG, QT and QP</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">IR models</head><p>With the daily tweet stream, we leverage the Terrier search engine <ref type="bibr" coords="4,394.15,141.52,9.59,8.69" target="#b4">[5]</ref> for indexing and retrieval. Three state-of-the-art information retrieval (IR) models, namely the language model <ref type="bibr" coords="4,456.01,152.43,9.08,8.69" target="#b5">[6]</ref>, the BM25 model <ref type="bibr" coords="4,143.59,163.34,9.59,8.69" target="#b6">[7]</ref> and the DFRee model <ref type="bibr" coords="4,247.19,163.34,9.08,8.69" target="#b0">[1]</ref>, are utilized for this task. Specifically, with the above six kinds of queries and three IR models, we can obtain eighteen scores for a tuple as (Query, Tweet).</p><p>By assuming that di↵erent retrieval models may compensate each other by combination, we do a linear combination of the scores to obtain better performance. We use the collection of Tweet2013 for training and try out all kinds of combinations. The best combination strategies are used for this year's task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup 4.1 Datasets</head><p>The training data sets as Tweet2013 and Tweet2014 is obtained with the o cial search API 1 . In this year's track, we use the o cially provided GatherStatusStream tool 2 to gather a parallel sample of tweets from the Twitter public stream during the evaluation period, i.e., from July 20, 2015, 00:00:00 UTC to July 29, 2015, 23:59:59 UTC.</p><p>Due to the government policy on networks, we have missed some data on the first day. To obtain the complete data set, we rent a Linode server and perform experiments on it. The total amount of tweets we obtained is about 14 million. Since the raw tweet texts contain a lot of noise, we perform data preprocessing to remove non-English tweets and specific symbols like URLs, mentions and so on. We also use Natural Language Toolkit 3 for tokenization, stemming and stop words removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Measures</head><p>For Scenario A, two metrics are designed for evaluation. The primary metric is expected latencydiscounted gain (ELG) from the temporal summarization track, which is formulated as:</p><formula xml:id="formula_3" coords="4,252.44,428.56,258.23,23.59">(1/|tweets|) ⇥ X Gain(tweet)<label>(3)</label></formula><p>where |tweets| denotes the total number of returned tweets. For a returned tweet, the gain is calculated according to the o cial guidelines 4 . The secondary metric is the normalized cumulative gain (nCG), which is formulated as:</p><formula xml:id="formula_4" coords="4,264.81,492.64,245.86,23.59">(1/Z) ⇥ X Gain(tweet)<label>(4)</label></formula><p>where Z is the maximum possible gain (given the 10 tweet per day limit).</p><p>In Scenario B, the list of tweets returned per day are treated as a ranked list for each topic. Then, NDCG@k is computed, where k is relatively small and determined based in part on the pool depth. The score of a topic is the average of the NDCG@k scores across all days in the evaluation period. The score of the run is the average over all topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussions</head><p>Table <ref type="table" coords="4,150.14,609.87,4.54,8.69" target="#tab_1">1</ref> shows the results of our submitted runs as well as the best published run for Scenario A. All the three runs vary in the parameter settings of ↵, , and ✓, which are demonstrated previously. The specific settings for each run is as follows: ECNURUNA1(0.17, 0.3, 0.3, 0.5), ECNURUNA2(0.18, 0.4, 0.25, 0.6), ECNURUNA3(0.20, 0.45, 0.20, 0.7). From this table, we observe that all of our three runs have the same performance with regard to the ELG and nCG metrics. The best run is human involved. There are total 31 automatic runs and we obtain a rank as 13 among them.</p><p>For Scenario B, the performance of our submitted runs and the best published run are shown in Table <ref type="table" coords="5,142.31,179.28,3.53,8.69" target="#tab_2">2</ref>. Specifically, ECNURUNB1 is combined by (QGTP, DFRee) and (Q, LM). Here we use (QGTP, DFRee) to denote the retrieval results configured with the query QGTP and the DFRee model, and so on. ECNURUNB2 is combined by (QGTP, DFRee), (Q, LM) and (QT, BM25). ECNURUNB3 is combined by (QGTP, DFRee), (Q, LM), (QG, BM25) and (QGTP, BM25). We observe that though the first run (ECNURUNB1) is combined by fewer retrieval scores, it performs the best. Thus, it is important to know the characteristics of each IR model and apply appropriate combination strategies. Combination by more retrieval results may harm the performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we present our work in two scenarios of the TREC 2015 Microblog Track. For Scenario A about pushing notifications on a mobile phone, we build a real-time tweet push system. It mainly performs three steps to determine whether to push a tweet or not. We obtain the best rank as 13 among all the 31 automatic runs. For Scenario B which focuses on the periodic email digest, we apply three query expansion methods and three state-of-the-art IR models for search. Various retrieval results are combined for final delivery. We obtain the best performance of nDCG@10 as 0.1610 (rank 12) in this scenario. Noting that the combination strategy does not work very well, we will extract more useful features and focus on the learning to rank approaches in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,162.98,435.95,120.92,8.69"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="2,318.68,435.95,170.25,8.69"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relevance Prediction Framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="3,121.48,420.26,6.01,1.83;3,132.04,413.46,266.47,9.09;3,121.48,431.16,6.01,1.83;3,132.04,423.46,24.42,10.47;3,159.44,424.93,6.05,14.98;3,168.02,424.36,21.16,9.09;3,121.48,442.07,6.01,1.83;3,141.12,434.37,171.91,10.47;3,121.48,452.98,6.01,1.83;3,141.12,445.27,97.02,10.47;3,121.48,463.88,6.01,1.83;3,150.21,457.08,50.23,9.09;3,121.48,474.79,6.01,1.83;3,141.12,467.99,25.52,9.09;3,121.48,485.69,6.01,1.83;3,132.04,478.89,32.15,9.09;3,121.48,496.60,6.01,1.83;3,132.04,489.80,78.90,9.09;3,212.20,490.36,2.52,14.98;3,121.48,507.51,6.01,1.83;3,132.04,500.70,78.64,9.09;3,117.62,518.41,9.87,1.83;3,141.12,511.61,52.30,9.09;3,117.62,529.32,9.87,1.83;3,132.04,522.52,16.61,9.09;3,117.62,540.22,9.87,1.83;3,141.12,533.42,55.22,9.09;3,117.62,551.13,9.87,1.83;3,132.04,544.33,25.52,9.09;3,116.59,576.69,241.82,13.10;3,116.59,600.88,68.42,10.92"><head>1 : 3 :</head><label>13</label><figDesc>Initialize: redundancy Count = 0, redundancy degree RD(T ) = 0 2: for T 0 2 P do Calculate the Overlap Similarity OS(T, T 0 ) end for 8: RD(T ) = Count/|P | 9: if RD(T ) &gt; ✓ then 10:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,116.59,265.02,394.09,84.30"><head>Table 1 :</head><label>1</label><figDesc>Performance of our submitted runs and the best published run for Scenario A: (1) Total 33 runs were submitted for this task including 2 manual runs; (2) the best results are shown in the last column, which incorporated manual interventions and (3) the results of our three automatic runs are the same, with a rank as 13 among all the 31 automatic runs.</figDesc><table coords="5,177.67,316.98,271.92,32.35"><row><cell cols="5">Metrics ECNURUNA1 ECNURUNA2 ECNURUNA3 Best m</cell></row><row><cell>ELG</cell><cell>0.2314</cell><cell>0.2314</cell><cell>0.2314</cell><cell>0.3175</cell></row><row><cell>nCG</cell><cell>0.2314</cell><cell>0.2314</cell><cell>0.2314</cell><cell>0.3127</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,116.59,373.72,394.09,73.03"><head>Table 2 :</head><label>2</label><figDesc>Performance of our submitted runs and the best published run for Scenario B: (1) Total 37 runs were submitted for this task including 7 manual runs; (2) the best results are shown in the last column without any manual interventions (3) all of our three runs are automatic and we obtain a best rank as 12 among all the 30 automatic runs.</figDesc><table coords="5,172.12,426.79,283.01,19.96"><row><cell>Metrics</cell><cell cols="3">ECNURUNB1 ECNURUNB2 ECNURUNB3</cell><cell>Best</cell></row><row><cell>nDCG@10</cell><cell>0.1610</cell><cell>0.1327</cell><cell>0.1416</cell><cell>0.2200</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>This research is supported by the <rs type="funder">Science and Technology Commission of Shanghai Municipality</rs> under research grant No.<rs type="grantNumber">14511107000</rs> and No.<rs type="grantNumber">14511106803</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uWcfSEu">
					<idno type="grant-number">14511107000</idno>
				</org>
				<org type="funding" xml:id="_ARKGvP4">
					<idno type="grant-number">14511106803</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 https://github.com/lintool/twitter-tools/wiki/TREC-2013-API-Specifications 2 https://github.com/lintool/twitter-tools/wiki/Sampling-the-public-Twitter-stream 3 http://www.nltk.org/ 4 https://github.com/lintool/twitter-tools/wiki/TREC-2015-Track-Guidelines</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="6,130.01,146.75,380.66,7.82;6,130.00,156.38,380.63,8.18;6,130.00,166.74,19.14,7.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,270.09,146.75,240.57,7.82;6,130.00,156.74,118.53,7.82">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,258.15,156.38,191.65,8.18">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,130.01,180.37,317.71,7.82" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,299.99,180.37,144.22,7.82">ECNU at TREC 2014: Microblog track</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,130.01,193.65,380.68,8.18;6,130.00,203.64,225.93,8.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,231.78,194.01,206.27,7.82">Jensen-shannon divergence and hilbert space embedding</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fuglede</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Topsoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,457.05,193.65,53.64,8.18;6,130.00,203.64,150.93,8.18">IEEE International Symposium on Information Theory</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="31" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,130.01,217.28,380.65,8.18;6,130.00,227.63,89.71,7.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,183.37,217.64,98.66,7.82">Kullback-leibler divergence</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Joyce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,303.80,217.28,179.05,8.18">International Encyclopedia of Statistical Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="720" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,130.01,241.27,380.66,7.82;6,130.00,250.90,292.43,8.18" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,407.30,241.27,103.37,7.82;6,130.00,251.26,30.11,7.82">Terrier information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,178.12,250.90,125.38,8.18">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,130.01,264.53,380.66,8.18;6,130.00,274.53,380.72,8.18;6,130.00,284.53,136.75,8.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,246.13,264.89,203.78,7.82">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,468.82,264.53,41.85,8.18;6,130.00,274.53,380.72,8.18;6,130.00,284.53,29.14,8.18">Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 21st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,130.01,298.52,380.66,7.82;6,130.00,308.16,218.11,8.18" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,441.73,298.52,68.94,7.82;6,130.00,308.16,134.46,8.18">Okapi at TREC-3. NIST SPECIAL PUBLICATION SP</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="109" to="109" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
