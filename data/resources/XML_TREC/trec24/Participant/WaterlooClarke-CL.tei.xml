<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,92.75,133.65,426.49,15.12">WaterlooClarke: TREC 2015 Clinical Decision Support Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-10-23">October 23, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,117.71,166.13,72.59,10.48"><forename type="first">Amira</forename><surname>Ghenai</surname></persName>
							<email>aghenai@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.18,166.13,74.94,10.48"><forename type="first">Eldar</forename><surname>Khalilov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.01,166.13,59.99,10.48"><forename type="first">Pavel</forename><surname>Valov</surname></persName>
							<email>pvalov@gsd.uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,383.66,166.13,105.89,10.48"><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
							<email>claclark@plg.uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,92.75,133.65,426.49,15.12">WaterlooClarke: TREC 2015 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-10-23">October 23, 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">D941877EF40F370ACCFF3D9799AED9BB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clinical decision support systems help physicians with finding additional information about a particular medical case. In this paper, we develop a clinical decision support system that, based on a short medical case description, can recommend research articles to answer some common medical questions (diagnosis, test and treatment articles). The two different full-text search engines we adopted in order to search over the collection of articles are Terrier and Apache Solr. We test each search engine with different settings and retrieval algorithms. Additionally, we combine the results of the two different search engines using reciprocal rank fusion. The evaluation of the submitted runs using partially marked results of Text Retrieval Conference (TREC) from the previous year shows that the methodologies are promising.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of the current clinical decision support track is to research how documented medical cases can be used when treating patients. When treating a patient, a doctor often needs to investigate additional information in order to determine patient's diagnosis, to select the best treatment plan for a patient with assigned diagnosis, or to decide whether additional testing of a patient is needed.</p><p>Sometimes physicians can find necessary information in existing medical research literature. However, considering the amount of published articles available, this investigation might take a considerable amount of time. The goal of clinical decision support systems is to help doctors by associating particular medical research literature with corresponding medical cases, thus making it more accessible. Clinical decision support track attempts to mimic the requirements for development of such systems and to promote their creation along with necessary tools and resources. The main focus of this track is to answer common clinical questions about medical cases, by extracting relevant medical research articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Medical Retrieval System</head><p>The two different retrieval search engines here are Terrier and Solr, since we plan to combine the runs using multiple retrieval functions and systems:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Terrier</head><p>We used the Terrier search engine<ref type="foot" coords="1,227.97,662.61,3.97,6.12" target="#foot_0">1</ref> (version 4.0) for the first and third run shown in table 1. Terrier is a highly flexible, efficient, and effective Java open source search engine, readily deplorable on large-scale collections of documents <ref type="bibr" coords="1,181.42,688.09,78.49,8.74" target="#b5">Ounis et al. [2006]</ref>.</p><p>TREC 2015 Clinical Decision Support Track 2.1.1 Document Pre-processing Our first step was to prepare a document collection consisting of well-formed XML files: We were interested in only certain fields from the articles tags. Instead of relying on Terrier to extract the needed tags, we decided to transform the articles ourselves and the tags that were included in the documents were: title, abstract, body. We chose those tags because of two main reasons: first, the main information relies in these tags and second, those tags can be identified easily. Both the title and abstract were taken from the documents &lt;front&gt;tag. Under this tag, the title was taken from the &lt;article-title&gt;tag. The abstract was taken from the &lt;abstract&gt;tag. Figure <ref type="figure" coords="2,249.65,186.88,4.98,8.74">1</ref> shows an example of an article pre-processed to be indexed by Terrier.</p><p>Figure <ref type="figure" coords="2,110.52,327.82,3.87,8.74">1</ref>: A sample document with PMCID 2198982 after pre-processing and before indexing by Terrier</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Text Indexing and Retrieval</head><p>We applied Porter stemming algorithm provided by Terrier and we removed stop-words from documents before indexing. Additionally, We indexed and searched only the text documents: No images or videos were considered in our experiments.</p><p>After indexing with Terrier, different retrieval functions were performed and the best ones were used in the runs shown in table <ref type="table" coords="2,199.66,455.74,3.87,8.74" target="#tab_1">1</ref>. Terrier provides built-in retrieval functions that we have tested on our articles after tuning the default parameters. The retrieval functions that we chose for our experiments are: BM25, BM25F, PL2 and LnL2 (PL2 and LnL2 achieved similar results that is why we only report PL2). Additionally, We expanded the query by running pseudo-relevance feedback <ref type="bibr" coords="2,404.79,491.60,92.23,8.74" target="#b1">Büttcher et al. [2010]</ref> using the top 20 documents retrieved using the initial query. We added a maximum of 10 new query terms to the initial query. Furthermore, we tested the effect of different term score techniques for relevance feedback that Terrier provides. More specifically, we evaluated the effectiveness of the query expansion with Bo1, Bo2 (Bose-Einstein), KL (Kullback-Leibler divergence), CS (chi-square divergence) and Rocchio's algorithm <ref type="bibr" coords="2,72.00,551.38,54.36,8.74" target="#b0">Amati [2003]</ref>. Finally, because of the limit of the number of runs (3), we had to pick the best run and submit it. That run is the first one listed in table 1:</p><p>• "UWCPL2" Run: PL2 retrieval function was used with Terrier search engine and Rocchio's algorithm for relevance feedback as proven experimentally to be the best method for query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Solr</head><p>We used Apache Solr search engine<ref type="foot" coords="2,234.76,639.92,3.97,6.12" target="#foot_1">2</ref> (version 5.2.1) for the second and third run in table 1. Solr is an open-source full-text search engine, written in Java. For the purpose of full-text indexing and search, Solr utilizes Apache Lucene, an open-source Java search library. Solr provides various search and integration features such as: faceted navigation, hit highlighting, query language, and extensible plugin architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Documents Pre-processing</head><p>We performed a thorough pre-processing of document collection before going through the indexing phase.</p><p>First of all, we used standard tokenizer to split documents into a set of tokens, while treating white space and punctuation as delimiters. Second, we applied lower case filter to tokens generated in the previous step. This filter simply converts all upper-case letters to lower-case letters, while ignoring all non-letter symbols. Finally, we applied porter stemming algorithm in order to remove common morphological and inflectional endings from tokens. We also tried using less aggressive stemmer called KStem, however this algorithm provided worse results than Porter stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Retrieval Functions</head><p>We used two different retrieval functions for Solr: TF-IDF and BM25. As expected, BM25 provided better results than TF-IDF, so we decided to submit the run with the retrieval function BM25 on Solr search engine as it was the best run we could get in terms of precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Query Pre-processing</head><p>When working with Solr, the main effort was spent trying to improve the input query. We tried five different approaches for query modification:</p><p>• Filtering the query: We performed a query filtering by keeping only medical terms. This was achieved using publicly available database of medical terms called UMLS Metathesaurus. We were expecting that filtering the query by removing all non-medical terms would increase information per data ratio and improve search accuracy.</p><p>Example: A 65-year-old male presents with dyspnea, tachypnea, chest pain on inspiration, and swelling and pain in the right calf.</p><p>Processed example (filtering): dyspnea tachypnea chest pain swelling pain in calf.</p><p>• Filtering and query expansion: We again filtered the query to leave only medical terms. Later, we expanded the query by adding all possible query terms synonyms from the database.</p><p>Example: A young woman in her second gestation presenting with anemia resistant to improvement by iron supplementation, elevated LDH, anisocytosis, poikilocytosis, hemosiderinuria and normal clotting screen.</p><p>Processed example (filtering + all synonyms): second gestation anaemia supplementation elevated ldh anisocytosis poikilocytosis secondary gestational anemic elevate anisocytotic.</p><p>• Filtering and one term query expansion: We performed a query filtering by keeping only medical terms as the first case. Then, we expanded it using only one synonym from the database that is the most different. We assessed this difference using Levenshtein distance metric.</p><p>Example: A 46-year-old woman with sweaty hands, exophthalmia, and weight loss despite increased eating.</p><p>Processed example (filtering + one synonyms): sweaty hands exophthalmia increased weight sweatiness gaining ponderal Unfortunately, we could not gain any improvement in terms of accuracy using any of those query modification methods. The best results were achieved only when the input query was left completely unmodified. Table <ref type="table" coords="4,99.03,226.27,4.98,8.74" target="#tab_1">1</ref> shows the best run we could achieve using Solr search engine which is represented in the second run:</p><p>• "U W CSolrBM 25": The query is pre-processed using the same process as medical articles. We use Standard Tokenizer, Lower Case Filter, and Porter or KStem Stemming Algorithm. Then, BM25 is used as the retrieval function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Summary</head><p>To sum up, we tried various combinations of retrieval functions, stemmers and query pre-processing techniques, to find out the best one. We tried two retrieval functions (TF-IDF and BM25), two different stemming algorithms (Porter and KStem), and five different query modification techniques. We found out that the best results are achieved when using BM25 as a retrieval function, Porter Stemming Algorithm for pre-processing of articles and input queries, and without using any query modification techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Rank Fusion</head><p>One hypothesis we wanted to test is to combine different retrieval functions to produce better results than having the individual functions run separately. Additionally, we wanted to tested the fusion of different search engine results such as combining Solr and Terrier result sets together. Inspired by <ref type="bibr" coords="4,474.37,434.39,65.63,8.74;4,72.00,446.35,24.20,8.74" target="#b2">Cormack et al. [2009]</ref>, we decided to use rank fusion that aims to combine multiple ranked document lists (ranks) into one single combined ranked list using reciprocal rank fusion (RRF) algorithm as it generally achieves good, all-round performance. The simple formula used to combine different retrieval functions as cited in <ref type="bibr" coords="4,501.23,470.26,38.77,8.74;4,72.00,482.22,50.92,8.74" target="#b2">Cormack et al. [2009]</ref> is as follows:</p><formula xml:id="formula_0" coords="4,240.67,492.12,299.33,26.65">RRF score(t) = i 1 60 + r i (t)<label>(1)</label></formula><p>Where r i (t) is the rank of the document t in the result set i.</p><p>We implemented the RRF algorithm ourselves and tried different combinations of retrieval functions using Terrier and Solr. We tested many combinations such as combining retrieval functions within the same search engine (BM25+PL2, BM25+InL2, PL2+BM25F...) and combining different search engine results together (Terrier BM25+Solr BM25, Terrier PL2+Sol2 BM25 , ...). However, due to a limited number (3) of submissions, only the best run/combination was submitted which is:</p><p>• "UWCSolrTerr" Run: PL2 retrieval function was used for Terrier search engine and Rocchio's Algorithm was used as a query expansion technique. In Solr search engine, the original query was expanded, where the query is first filtered to keep medical terms and then expanded with one synonym for each medical term. BM25 was used as the retrieval function for Solr search engine. Reciprocal rank fusion score was finally used to fuse the results of Terrier and Solr by producing a new combined ranked list. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The three runs discussed in section 2.1 and 2.2 were submitted. The evaluation metrices used for the clinical decision support track are infAP, infNDCG, R-prec and P@10 which are extended inferred metrics that are discussed in <ref type="bibr" coords="5,126.96,218.15,86.25,8.74" target="#b6">[Yilmaz et al., 2008]</ref>.</p><p>As table 2 shows, using Terrier search engine and PL2 as a retrieval function with Rocchio's algorithm for query expansion outperformed all the other search engine combinations and query expansion techniques. UWCPL2 got the highest P@10 score given across all runs with a value of 0.4300, the highest inferred normalized discounted cumulative gain and R-precision scores (0.2542 and 0.2195 respectively). These results suggest that the UWCPL2 run was successful for most of the topics using Rocchio's algorithm as query expansion and PL2 with Terrier. We observe that the queries corresponding to these topics were generally long in length (due to strong performance of query expansion). The refinement of these queries by detecting enough medically specific keywords in the query to retrieve highly relevant documents.</p><p>There were few topics for which the median of all three of our runs performed consistently poor such as 18, 20, 25, 27 and 28 where P@10 ≈ 0 and R-prec ≈ 0. This result reveals few limitations of our approach. Some of these topics were very short and contained very few technical, specific medical nouns. Thus, query expansion technique to expand the base query was not very helpful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we demonstrated our contribution to the 2015 TREC Clinical Decision Support Track in order to build a system able to recommend research articles and to answer common medical questions. More specifically, We opted for an exploratory approach in which we used different full-text search engines (Terrier and Solr Apache) and we explored the hypothesis of combining different retrieval functions and search engines. In Terrier, we studied the effect of different term score techniques when using pseudo-relevance feedback to expand the input query. For Solr, different retrieval functions were used and various input query expansion techniques were explored. We evaluated our system using TREC results from the previous year and the best runs were selected to be submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future Work</head><p>Although we believe that we achieved promising results, There is much to be done in future. First of all, pre-processing of medical articles could be done in a different way. Different tokenizers and stemmers can TREC 2015 Clinical Decision Support Track be used for both medical articles and input queries. Second, more retrieval functions can be explored for both Terrier and Solr search engine such as <ref type="bibr" coords="6,262.45,108.71,117.06,8.74">BM25L Lv and Zhai [2011]</ref> which is a modified version of BM25 that is known to handle long documents better than other retrieval functions. Third, despite the fact that query modification didn't improve retrieval results in Solr, it still might be possible to achieve some accuracy gain via query expansion using a different approach. Fourth, we can explore different methods of fusing the results of Terrier and Solr search engine rather than RRF technique such as Condorcet Fusion <ref type="bibr" coords="6,496.83,156.53,43.17,8.74;6,72.00,168.49,74.34,8.74" target="#b4">Montague and Aslam [2002]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,86.94,608.20,453.06,92.42"><head>•</head><label></label><figDesc>Filtering and special query expansion: We filtered the query by leaving only medical terms. Later, we expanded the query by adding all possible query terms synonyms from the database. By adding terms to the query, we forced at least one synonym from every synonym group to be present in returned documents.Example Young adult woman with 2 weeks of fever and migrating joint inflammation.TREC 2015 Clinical Decision Support Track• Filtering and one term special query expansion: We performed a query filtering by keeping only medical terms and expanded it using only one synonym from the database that is the most different. Later, we forced at least one synonym from every synonym group to be present in returned documents.</figDesc><table coords="4,96.91,132.59,443.10,56.59"><row><cell>Example: A 38 year old woman with severe dysmenorrhea, menorrhagia, and menometrorrhagia.</cell></row><row><cell>PMH of infertility treatment and ectopic pregnancy</cell></row><row><cell>Processed example (filtering + one synonyms+boolean operators): (dysmenorrhea OR men-</cell></row><row><cell>orrhalgia) AND (menorrhagia) AND (menometrorrhagia) AND (infertility OR infertile) AND (preg-</cell></row><row><cell>nancy OR cyophoric)</cell></row></table><note coords="3,96.91,667.95,443.09,8.77;3,96.91,679.93,443.09,8.74;3,96.91,691.89,79.34,8.74"><p>Processed Example (filtering + all synonyms+boolean operators): (fever OR pyrectic OR febrility OR pyretic OR febrile OR fevers) AND (joint OR articular OR arthral OR jointedness OR jointed OR joints)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,76.42,103.68,456.72,44.44"><head>Table 1 :</head><label>1</label><figDesc>Runs Summary</figDesc><table coords="5,76.42,114.86,456.72,33.25"><row><cell>Run id</cell><cell cols="3">Search Engine Retrieval Function Description</cell></row><row><cell>U W CP L2</cell><cell>Terrier</cell><cell>PL2</cell><cell>Using Rocchio's algorithm for query expansion and PL2 using Terrier search engine</cell></row><row><cell cols="2">U W CSolrBM 25 Solr</cell><cell>BM25</cell><cell>The run was generated using Solr search engine and BM25</cell></row><row><cell>U W CSolrT err</cell><cell>Solr, Terrier</cell><cell>BM25, PL2</cell><cell>Rank fusion of Solr results with query expansion and BM25 with Terrier with PL2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,154.30,318.72,303.40,57.50"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="5,183.51,318.72,274.19,57.50"><row><cell cols="3">: infAP, infNDCG, R-prec and P@10 scores for all of our runs</cell></row><row><cell>Run</cell><cell cols="2">infAP infNDCG R-prec P @ 10</cell></row><row><cell>UWCPL2</cell><cell>0.0630 0.2542</cell><cell>0.2195 0.4300</cell></row><row><cell cols="2">UWCSolrBM25 0.0449 0.2121</cell><cell>0.1793 0.3933</cell></row><row><cell>UWCSolrTerr</cell><cell>0.0053 0.0655</cell><cell>0.0235 0.1200</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.24,706.27,154.11,6.99"><p>Can be downloaded at http://terrier.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,87.24,696.29,199.06,6.99"><p>Can be downloaded at http://lucene.apache.org/solr/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,72.00,224.68,468.00,8.74;6,81.96,236.64,124.47,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,122.16,224.68,356.39,8.74">Probability models for information retrieval based on divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="6,72.00,256.56,467.99,8.74;6,81.96,268.52,110.11,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,283.71,256.56,256.29,8.74;6,81.96,268.52,30.49,8.74">Information retrieval: Implementing and evaluating search engines</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Mit Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,288.44,468.00,8.74;6,81.96,300.40,458.04,8.74;6,81.96,312.36,286.04,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,278.72,288.44,261.28,8.74;6,81.96,300.40,95.32,8.74">Reciprocal rank fusion outperforms condorcet and individual rank learning methods</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Buettcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,198.35,300.40,341.65,8.74;6,81.96,312.36,158.43,8.74">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,332.28,468.00,8.74;6,81.96,344.24,458.03,8.74;6,81.96,356.19,22.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,163.70,332.28,189.48,8.74">When documents are very long, bm25 fails</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,378.06,332.28,161.94,8.74;6,81.96,344.24,345.62,8.74">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1103" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,376.12,468.00,8.74;6,81.96,388.07,425.58,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,220.91,376.12,174.90,8.74">Condorcet fusion for improved retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montague</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,420.73,376.12,119.27,8.74;6,81.96,388.07,296.59,8.74">Proceedings of the eleventh international conference on Information and knowledge management</title>
		<meeting>the eleventh international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="538" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,408.00,468.00,8.74;6,81.96,419.95,458.04,8.74;6,81.96,431.91,183.13,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,394.18,408.00,145.82,8.74;6,81.96,419.95,175.46,8.74">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,282.32,419.95,257.68,8.74;6,81.96,431.91,152.59,8.74">Proceedings of ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval (OSIR 2006)</title>
		<meeting>ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval (OSIR 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,451.83,468.00,8.74;6,81.96,463.79,458.04,8.74;6,81.96,475.74,217.04,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,252.31,451.83,283.04,8.74">A simple and efficient sampling method for estimating ap and ndcg</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,94.63,463.79,445.37,8.74;6,81.96,475.74,89.44,8.74">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
