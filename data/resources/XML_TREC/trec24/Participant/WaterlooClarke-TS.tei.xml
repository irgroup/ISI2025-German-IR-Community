<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,114.73,55.67,382.54,20.73;1,201.30,83.56,209.41,20.73">WaterlooClarke: TREC 2015 Temporal Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,112.63,123.38,53.74,9.50"><forename type="first">Ahsan</forename><surname>Raza</surname></persName>
							<email>m6raza@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.98,123.38,84.42,9.50"><forename type="first">Devin</forename><forename type="middle">M</forename><surname>Rotondo</surname></persName>
							<email>drotondo@uwaterloo.ca</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,412.59,123.38,94.18,9.50"><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
							<email>charles.clarke@uwaterloo.ca</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,114.73,55.67,382.54,20.73;1,201.30,83.56,209.41,20.73">WaterlooClarke: TREC 2015 Temporal Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CF1B05920DEB850926C6FE44605BEFC0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Temporal Summarization Track looks at providing meaningful summaries of major events and sub-events as they occur. Difficulties arise due to the unique nature of the temporal summarization task in which the corpora is constantly changing along with the known information about the event <ref type="bibr" coords="1,48.96,282.60,10.58,8.64" target="#b0">[1]</ref>. This year, the temporal summarization track consists of three tasks, two filtering and summarization tasks and an ontopic summarization task. In the filtering and summarization tasks, relevant content must be extracted from a continuous stream of documents and gradually summarized while maintaining low redundancy, latency and verbosity. In the third task, only the summarization must take place on a corpora filled with many documents related to the event <ref type="bibr" coords="1,233.50,366.28,10.58,8.64" target="#b1">[2]</ref>. The overall goal of the track is to provide a sequence of short meaningful sentence length updates over the duration of the events taking into account sentence redundancy and latency. The summaries are scored using an expected latency gain metric (ELG) in which sentences are rewarded for containing handpicked key updates (nuggets) and are penalized for redundancy, latency and verbosity <ref type="bibr" coords="1,105.58,449.97,10.58,8.64" target="#b2">[3]</ref>. This track can help users deal with all of the vast information that comes as major events progress through the use of general impersonal updates.</p><p>Our approach for this track consists of a two step process. The first stage is a data preprocessing stage which extracts the information from the supplied web documents and only retains the information considered necessary for the second stage. The second stage is the filtering and summarization stage used to find and push the relevant sentence length updates. We have applied this methodology to both the second and third task. A total of six different runs have been submitted with all of them being judged. The run scores are comparable to those in 2014, however, with a larger latency gain and lower latency comprehensiveness. The submitted task 2 runs appear to have a slightly better performance than those of task 3. However, there were no apparent differences between the task 2 or the task 3 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DATA PREPROCESSING</head><p>It seems to be very common to usually filter out irrelevant content when searching and summarizing data no matter the source. For the temporal summarization corpus, once the data was decrypted and decompressed into a binary form, it was taken and processed using the TREC-KBA streamcorpus tool which provides three different views on each document. In order to better clean and extract information from the documents, the clean HTML view was used. The clean HTML was processed with python-goose <ref type="bibr" coords="1,454.15,255.66,10.58,8.64" target="#b3">[4]</ref>, a data processing tool which obtains the "relevant text" and document title from news articles, and python-readability <ref type="bibr" coords="1,442.60,279.57,11.62,8.64" target="#b4">[5]</ref> to get document statistics such as the number of paragraphs and images. Additionally, for UWCTSRun3 and UWCTSRun6, the cleaned HTML is transformed into a cleaner form first using python-readability before processing with python-goose. A simple way to look at the "relevant text" extraction is that it removes most of the advertisements and irrelevant data that make it harder to find the focus of the article. The last step of the preprocessing is to extract all of the sentences from the python-goose text and store them for streaming. This step was performed for each document and the preprocessed data for each document was stored in its own file.</p><p>A document metadata file was created which contained the metadata about each document, such as the document ID, stream time and document type. The metadata file allows for the documents to be looked up in an easy to process time ordered sequence. The entire data preprocessing did not take too long and would be well suited for a live temporal summarization task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. APPROACH A. High-level Approach</head><p>Dealing with a large continuous stream of data brings with it some issues. There are several additional details that should be considered such as deciding to filter and summarize the documents as they arrive or to wait a while until you have a perhaps more representative corpus of the event. It is reasonable to say that the first relevant documents on an event immediately after it occurs will contain some important information such as the date, time, and location and perhaps initial estimates of damages. The corpus should later expand to provide more precise information in the form of updates. Additionally, if we only look at news articles then these documents have a specific structure ideal for temporal summarization. News articles often have a short and relevant sentence as the title pertaining to the newest information on the event and are then structured as an inverted pyramid in which the first paragraph explains the new Algorithm 1 Document Summarization Algorithm end if 44: end for information on the event followed by supportive information in the later paragraphs <ref type="bibr" coords="2,142.93,624.49,10.58,8.64" target="#b5">[6]</ref>. This tends to make summarization of these types of articles a lot easier than the less structured web blogs or other such documents. Our approach attempts to build on this reasoning in creating event summaries.</p><p>In our approach we first index 20,000 documents prior to the event in order to have a reasonable document baseline for the event in task 2. These documents should all be irrelevant to the event assuming that the start time given by the user is a reasonable start time for the event. In the case of task 3, only those documents from the task 3 corpus are used which amounts to a much smaller amount of documents indexed prior to the event. Apache Lucene <ref type="bibr" coords="2,458.82,648.40,11.62,8.64" target="#b6">[7]</ref> has been used in this application for indexing, ranking and searching the documents using the Okapi BM25 ranking. Then at every five minute interval, the new data is indexed and ranked. The new data is additionally filtered prior to indexing in task 2 by removing those articles that are not news or MAINSTREAM NEWS from the stream. The Rocchio relevance feedback algorithm is also subsequently applied in order to complement the user query with additional search terms in order to obtain a more relevant top match. Based on this, the document summarization algorithm above is applied to decide if any of the new documents should be pushed for an update.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Algorithm</head><p>The document summarization algorithm is given a query object (query) -an object containing information about the event such as the name of the event, the start and end time of the event-and attempts to PUSH updates for that event. The document summarization algorithm processes documents in 5 minutes intervals, by looking at documents in each 5 minute interval after the event start time. It obtains the list of documents within the current interval and adds them to the document index (line <ref type="bibr" coords="3,161.98,243.29,3.82,8.64" target="#b4">[5]</ref><ref type="bibr" coords="3,169.61,243.29,7.64,8.64" target="#b5">[6]</ref>. Following this, the top 20 (maxHits) documents with the highest score according to the Okapi BM25 scoring and relevance feedback are returned (line 7). If no hits were found, the algorithm will continue checking at every 5 minute interval for a hit. Alternatively, if any hits were found then there are several options that can be taken. If a document has not recently been pushed, then the top ranked hit that is not redundant with any of the previous updates will be pushed (line 9-16). This document is now set as the high watermark, which is used to determine whether to push new updates later on or not.</p><p>If a document has recently been pushed then a high watermark will exist. All of the hits that are ranked higher than the high watermark document are obtained (line 21), and from those only documents that are within the current time interval are kept (line 25). From the remaining hits, the hits that are not redundant with any of the previous updates are retained (line 26). If any documents remain then the highest ranked one is pushed (line 28). If no documents remain, then the algorithm proceeds either to decrease the high watermark document (line 34-40) or to remove the high watermark (line 32-33).</p><p>The document summarization algorithm promotes pushing an update when updates have not been pushed for a while. The algorithm attempts to push lower scoring documents as time passes even though these documents may not contain the best information on the event at the time in order to consistently provide some new information on the event. The algorithm avoids pushing updates that are redundant to previous any of the previous updates, regardless of how long ago the update was sent. To do this, it uses cosine similarity on document titles in order to determine which documents are similar to each other. When the corpus is rapidly changing with respect to the event in the query, the algorithm tries to only give out updates that are ranked higher than the previous hits. This requirement decreases exponentially as time passes and no new hits are found, allowing for lower ranked hits to be sent as updates.</p><p>Cosine similarity is used with a threshold of 0.4 in order to avoid pushing redundant updates. This threshold was determined empirically after some testing with the documents.</p><p>The similarity check is based on the titles from each of the previously pushed documents with the title of the proposed documents. Additionally, a custom metric has been added to remove irrelevant documents based on their content. In order to exclude these documents, only articles with at least 3 paragraphs along with articles where number of paragraphs is greater than the number of images times 1.5 are kept. This ensures that if a sentence from a document is pushed for an update, the document is a news focused article and not an article that is primarily image or video-based.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. TRACK RUNS</head><p>Each run differs in the summarization strategy that it uses or on the task in which it is ran. The summarization strategy in UWCTSRun1, UWCTSRun2 and UWCTSRun3 for task 2 correspond to UWCTSRun4, UWCTSRun5, and UWCTSRun6 in task3. UWCTSRun1(4) follow the strategy of pushing the first sentence found in each article as determined natively by python-goose. For UWCTSRun2 <ref type="bibr" coords="3,484.18,267.35,16.28,8.64" target="#b4">(5)</ref>, the document summarization algorithm pushed only the document headline for each of the selected documents. For UWCTSRun3(6) a combination of python-readability and python-goose is used. Python-readability parses the clean HTML and only keeps the HTML containing the main article. Then python-goose is used to extract sentences from the HTML and the first sentence is pushed. All these approaches differ in that the updates pushed for UWCTSRun2(5) will be a short concise update for each event whereas for UWCTSRun1(4) and UWCTSRun3(6), the updates will be much more detailed and perhaps more informative. Table <ref type="table" coords="3,394.06,398.86,4.98,8.64">1</ref> illustrates the average results for all judged runs across all queries. Bold numbers representing best run results across the different evalation measures. From Table <ref type="table" coords="3,373.65,566.77,3.74,8.64">1</ref>, there does not appear to be any difference between the task 2 or the task 3 runs. The only apparent difference appears to be between task 2 and task 3 showing a better overall performance across all of the task 2 runs. This suggests that the algorithm may require modifications when dealing with a smaller and more focused corpus such as pushing updates more frequently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. IMPROVING THE PROCESSING AND RESULTS</head><p>The document preprocessing and processing should perform adequately with a real-time continuous stream of articles. However, as the current metric limits scoring to the original tokenized sentences, the sentences that are pushed to the user must currently be matched to those sentences for an update. This increases the amount of processing done currently for each update. Additionally, the proposed document summarization algorithm assumes that the top hits are well structured and focused primarily on the one query topic. However, in rare occasions the news articles contain information about more than one news story leading the summary to stray offtopic. Possible future considerations could be taken by further applying additional natural language processing in order to obtain a more relevant sentence for these documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,50.73,63.14,433.00,510.64"><head></head><label></label><figDesc>1: startTime ← query.startTime() , endTime ← query.endTime() , maxHits ← 20 2: previousHighWatermarkDocument ← NULL , previousDocumentsSentAsUpdate ← {} 3: for i = startTime, i ≤ endTime, i += MINS 5 do</figDesc><table coords="2,50.73,99.00,433.00,474.78"><row><cell>4:</cell><cell>lookAheadTime ← min(i + MINS 5, endTime)</cell></row><row><cell>5:</cell><cell>documentsWithinTimeRange ← getDocumentsWithinTimeRange(i, lookAheadTime)</cell></row><row><cell>6:</cell><cell>DocumentIndex.index(documentsWithinTimeRange)</cell></row><row><cell>7:</cell><cell>documentHits ← DocumentIndex.queryIndex(maxHits, query.getQuery())</cell></row><row><cell>8:</cell><cell>if documentHits = Empty then</cell></row><row><cell>9:</cell><cell>if previousHighWatermarkDocument = NULL then</cell></row><row><cell>10:</cell><cell>documentHits.retainAll(documentsWithinTimeRange)</cell></row><row><cell>11:</cell><cell>hitDocument ← getNonRedundantHit(documentHits, previousDocumentsSentAsUpdate);</cell></row><row><cell>12:</cell><cell>if hitDocument = NULL then</cell></row><row><cell>13:</cell><cell>PUSH hitDocument</cell></row><row><cell>14:</cell><cell>previousHitTime ← lookAheadTime</cell></row><row><cell>15:</cell><cell>previousHighWatermarkDocument ← hitDocument</cell></row><row><cell>16:</cell><cell>previousDocumentsSentAsUpdate.add(hitDocument)</cell></row><row><cell>17:</cell><cell>end if</cell></row><row><cell>18:</cell><cell>else</cell></row><row><cell>19:</cell><cell>previousHighWatermarkRank ← documentHits.indexOf(previousHighWatermarkDocument)</cell></row><row><cell>20:</cell><cell>if previousHighWatermarkRank ≥ 0 then</cell></row><row><cell>21:</cell><cell>newHits ← documentHits.subList(0, previousHighWatermarkRank)</cell></row><row><cell>22:</cell><cell>else</cell></row><row><cell>23:</cell><cell>newHits ← documentHits</cell></row><row><cell>24:</cell><cell>end if</cell></row><row><cell>25:</cell><cell>newHits.retainAll(documentsWithinTimeRange)</cell></row><row><cell>26:</cell><cell>hitDocument ← getNonRedundantHit(newHits, previousDocumentsSentAsUpdate)</cell></row><row><cell>27:</cell><cell>if hitDocument = NULL then</cell></row><row><cell>28:</cell><cell>PUSH hitDocument</cell></row><row><cell>29:</cell><cell>previousHitTime ← lookAheadTime</cell></row><row><cell>30:</cell><cell>previousHighWatermarkDocument ← hitDocument</cell></row><row><cell>31:</cell><cell>previousDocumentsSentAsUpdate.add(hitDocument)</cell></row><row><cell>32:</cell><cell>else if lookAheadTime -previousHitTime ≥ MINS 60 then</cell></row><row><cell>33:</cell><cell>previousHighWatermarkDocument ← NULL</cell></row><row><cell>34:</cell><cell>else if lookAheadTime -previousHitTime ≥ MINS 15 then</cell></row><row><cell>35:</cell><cell>if previousHighWatermarkRank = -1 then</cell></row><row><cell>36:</cell><cell>newWatermarkRank ← length(documentHits)</cell></row><row><cell>37:</cell><cell>else</cell></row><row><cell>38:</cell><cell>newWatermarkRank ← min(length(documentHits), currentWatermarkRank  *  2)</cell></row><row><cell>39:</cell><cell>end if</cell></row><row><cell>40:</cell><cell>previousHighWatermarkDocument ← documentHits.get(newWatermarkRank)</cell></row><row><cell>41:</cell><cell>end if</cell></row><row><cell>42:</cell><cell>end if</cell></row><row><cell>43:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,318.74,438.69,237.92,110.62"><head>TABLE I TRACK</head><label>I</label><figDesc>RUN RESULTS FOR UWCTS RUN 1 TO RUN 4.</figDesc><table coords="3,318.74,467.32,237.92,81.99"><row><cell>Run ID</cell><cell>EGτ (S)</cell><cell>Cτ (S)</cell><cell>H</cell></row><row><cell>-Task 2 -</cell><cell></cell><cell></cell><cell></cell></row><row><cell>UWCTSRun1</cell><cell>0.1547 ± 0.13</cell><cell cols="2">0.2065 ± 0.09 0.1553 ± 0.09</cell></row><row><cell>UWCTSRun2</cell><cell>0.1811 ± 0.13</cell><cell>0.1496 ± 0.08</cell><cell>0.1523 ± 0.09</cell></row><row><cell>UWCTSRun3</cell><cell>0.1491 ± 0.12</cell><cell>0.2026 ± 0.09</cell><cell>0.1511 ± 0.09</cell></row><row><cell>-Task 3 -</cell><cell></cell><cell></cell><cell></cell></row><row><cell>UWCTSRun4</cell><cell>0.0751 ± 0.09</cell><cell>0.0583 ± 0.06</cell><cell>0.0571 ± 0.06</cell></row><row><cell>UWCTSRun5</cell><cell>0.0830 ± 0.12</cell><cell>0.0279 ± 0.04</cell><cell>0.0398 ± 0.06</cell></row><row><cell>UWCTSRun6</cell><cell>0.0753 ± 0.09</cell><cell>0.0545 ± 0.07</cell><cell>0.0553 ± 0.07</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,63.24,194.79,236.78,6.91;4,63.24,203.62,236.79,7.05;4,63.24,212.73,117.69,6.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,186.57,194.79,113.46,6.91;4,63.24,203.76,18.76,6.91">Updating users about time critical events</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yom-Tov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,100.21,203.62,111.43,6.87">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer Berlin Heidelberg</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7814</biblScope>
			<biblScope unit="page" from="483" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,63.24,221.69,236.78,6.91;4,63.24,230.52,236.79,7.05;4,63.24,239.48,92.38,7.05" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,269.83,221.69,30.19,6.91;4,63.24,230.66,106.10,6.91">Temporal Summarization 2015 Guidelines</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,190.66,230.52,109.36,6.87;4,63.24,239.48,68.16,6.87">Proc. of the Twenty-Fourth Text REtrieval Conference</title>
		<meeting>of the Twenty-Fourth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,63.24,248.59,236.78,6.91;4,63.24,257.41,236.78,7.05;4,63.24,266.38,92.38,7.05" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,283.83,248.59,16.20,6.91;4,63.24,257.56,113.15,6.91">Temporal Summarization 2015 Metrics</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,195.31,257.41,104.71,6.87;4,63.24,266.38,68.16,6.87">Proc. of the Twenty-Fourth Text REtrieval Conference</title>
		<meeting>of the Twenty-Fourth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,63.24,275.49,236.78,6.91;4,63.24,284.46,88.52,6.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,112.19,275.49,41.88,6.91">Python-goose</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Grangier</surname></persName>
		</author>
		<ptr target="https://github.com/grangier/python-goose" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,63.24,293.42,236.78,6.91;4,63.24,302.39,173.52,6.91" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,176.71,293.42,58.15,6.91">Python-readability</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Baburov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Harding</surname></persName>
		</author>
		<ptr target="https://github.com/buriy/python-readability" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,63.24,311.36,236.78,6.91;4,63.24,320.32,236.78,6.91;4,63.24,329.15,236.79,7.05;4,63.24,338.25,84.88,6.91" xml:id="b5">
	<analytic>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">R R</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kitley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,229.40,311.36,70.62,6.91;4,63.24,320.32,236.78,6.91;4,63.24,329.29,142.28,6.91">Objectivity and Hard News Reporting across Cultures: Comparing the News Report in English, French, Japanese and Indonesian Journalism</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="212" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,63.24,347.22,233.35,6.91" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">"</forename><surname>Apache</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lucene</surname></persName>
		</author>
		<ptr target="https://lucene.apache.org/" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
