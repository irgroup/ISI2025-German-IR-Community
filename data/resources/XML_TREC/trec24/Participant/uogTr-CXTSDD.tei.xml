<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,99.11,89.78,426.95,5.05;1,84.16,107.95,456.85,5.05;1,201.58,126.13,222.01,5.05">University of Glasgow at TREC 2015: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Dynamic Domain Tracks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,165.06,153.41,93.32,13.50"><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.23,153.41,66.89,13.50"><forename type="first">Stuart</forename><surname>Mackie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.97,153.41,108.33,13.50"><forename type="first">Jarana</forename><surname>Manotumruksa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,136.32,163.96,91.40,13.50"><forename type="first">Graham</forename><surname>Mcdonald</surname></persName>
							<email>g.mcdonald.1@research.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.57,163.96,58.64,13.50"><forename type="first">Saúl</forename><surname>Vargas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.06,163.96,83.80,13.50"><forename type="first">M-Dyaa</forename><surname>Albakour</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.71,163.96,82.32,13.50"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.93,175.31,52.74,13.50"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,99.11,89.78,426.95,5.05;1,84.16,107.95,456.85,5.05;1,201.58,126.13,222.01,5.05">University of Glasgow at TREC 2015: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Dynamic Domain Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5BD772F7FAE19DDF3FD12303588402FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2015, we focus on tackling the challenges posed by the Contextual Suggestion, Temporal Summarisation and Dynamic Domain tracks. For Contextual Suggestion, we investigate the use of user-generated data in location-based social networks (LBSN) to suggest venues. For Temporal Summarisation, we examine features for event summarisation that explicitly model the entities involved in the events. Meanwhile, for the Dynamic Domain track, we explore resource selection techniques for identifying the domain of interest and diversifying sub-topic intents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In TREC 2015, we participate in both the "live" and "batch" experiments of the Contextual Suggestion track, the Summarisation Only task (Task 3) of the Temporal Summarisation track and the main task of the Dynamic Domain track. Our focus is the development of e↵ective and e cient approaches to these tasks, building upon our open-source Terrier Information Retrieval (IR) platform <ref type="bibr" coords="1,238.45,450.64,8.86,7.82" target="#b9">[9]</ref> and extensive experience working with machine learned models <ref type="bibr" coords="1,266.08,460.18,12.31,7.82" target="#b10">[10]</ref>.</p><p>In the Contextual Suggestion track, we leverage data from the Foursquare location-based social network (LBSN) to suggest venues to users. In particular, we propose two novel venue suggestion approaches, based on factorisation machines and a context-aware learning to rank technique, respectively. These approaches both use Foursquare data as well as the contextual information about the user to suggest venues. The factorisation machine-based approach uses check-in statistics and venue categories together with the context of the user to produce personalised suggestions. Meanwhile, our learning to rank approach incorporates two main components: a component containing user and venue-dependent features combined using the LambdaMART learning to rank technique; and a component that uses probabilistic time and term-based approaches to predict the contextual appropriateness of venues.</p><p>We also participate in the Temporal Summarisation track, specifically Task 3 "Summarisation Only" using the "RelOnly" corpus. The aim of our participation is to investigate algorithms for the summarisation of events, explicitly modelling the entities involved in an event, and the interaction be-tween such entities. We propose and evaluate features based on estimates of entity importance and entity-to-entity interactions, where the estimates are derived from the input document stream. Furthermore, we also investigate the effectiveness/latency trade-o↵ within the task, by testing two methods for processing the corpus, namely: by streaming over each event timespan and summarising document-bydocument; or batching documents in hourly chunks to be summarised.</p><p>Finally, for our participation in the Dynamic Domain track, we aim to investigate methods for minimising the number iterations of the retrieval-feedback cycle needed to correctly identify the sub-topics that are of interest to the user. To do this, we first view the task as a resource selection problem and experiment with resource selection and document prioritisation techniques for identifying the domain of interest for each topic. Secondly, we investigate search result diversification as a means to increase the number of potential sub-topic intents shown to the user within each iteration, thereby maximising the user's potential exploration rate.</p><p>The remainder of this paper is structured as follows. In Section 2, we describe our participation in the Contextual Suggestion track. Section 3 details our participation in the Temporal Summarisation track. In Section 4, we describe our participation in the main task of the Dynamic Domain track. Conclusions are provided in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CONTEXTUAL SUGGESTION TRACK</head><p>Similar to previous years, for TREC 2015, the Contextual Suggestion track asks participants to suggest a ranked list of venues to users, based upon their profiles and preferred contexts. The track consists of both live and batch experiments. For the live experiment, the participants have to setup and register their system with the organisers, and respond in real-time to user's requests. Each request consists of the user's profile (expressed as ratings of a set of venues) and contextual preferences (e.g. duration of visit). The response contains a list of venue IDs in the collection provided by TREC. For the batch experiment, given a user profile and contextual preferences, participants were asked to rank sets of candidate venues suggested during the live experiment.</p><p>For TREC 2015, the user's context contains the city where the user is looking for venues to visit, as well as newly pro-posed contextual preferences, namely: duration of trip (daytime, nighttime, weekend, longer), the season of the year (Spring, Summer, Autumn and Winter), the group of people the users are intending to visit the venue with (alone, friends, family and others) and the type of the trip (business, holiday and other). In the following, we describe our proposed approach for the live (Section 2.1) and batch experiments (Section 2.2). Finally, Section 2.3 highlights our submitted runs and their achieved performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Live Experiment</head><p>Our setup of the live experiment consisted of indexing venues from 272 cities, as listed in the Foursquare locationbased social network (LBSN). Then, we registered three different systems that ranked venue suggestions in response to a user query. For the live experiment, the user contexts were limited in nature, in that users only rate venues from 2 different cities. For this reason, and to ensure that Foursquare venues were represented in the batch experiment, we use three unsupervised ranking approaches to contribute a wide number of appropriate Foursquare venues. Our three di↵erent systems for the live experiment were as follows:</p><p>• Venue-independent: a system that ranks venues based upon popularity, computed from the number of checkins, photo and tips that each venue experiences on Foursquare.</p><p>• User-dependent: a system that ranks venues based on the Cosine similarity between the Foursquare categories of positively rated venues in the user's profile and the Foursquare categories of the venue itself.</p><p>• Contextual-preferences and User-dependent: a system that combines two aspects: (a) how well the venue matches the contextual preferences of the user (duration of visit, season, group, type of trip), computed based on the timestamps of photos of the venue from Foursquare; and (b) the user-dependent system described above. These two approaches are linearly combined with even weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Batch Experiment</head><p>In the batch experiment of the Contextual Suggestion track, we make use of two di↵erent learning approaches, as well as novel models for dealing with new aspects of the contextual preferences expressed by users. In particular, in the following we describe our factorisation machines and learning-to-rank approaches to both rank venues and predict the contextual appropriateness of a venue.</p><p>Note that while the batch experiment is intended to rank an initial set of venues, we make use of data from the Foursquare location-based social network, and therefore ignored venues that did not appear on Foursquare. More precisely, we assign any venue not appearing in Foursquare a zero score, and so appear at the bottom of our submitted rankings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Learning to Rank</head><p>For each venue in the initial set, we compute venue-dependent and user-dependent features, as proposed by Deveaud et al. <ref type="bibr" coords="2,95.13,631.95,8.39,7.82" target="#b3">[3]</ref>. In particular, a total of 49 features are computed for each venue-user pair based on the Foursquare data, such as check-ins, users and tips counts and venue categories. Moreover, following the same experimental setup as we applied for TREC 2014 <ref type="bibr" coords="2,381.31,64.39,12.31,7.82" target="#b12">[12]</ref>, we use the LambdaMART <ref type="bibr" coords="2,496.83,64.39,13.06,7.82" target="#b18">[18]</ref> learning to rank technique to learn an e↵ective combination of those features to re-rank venues. We train the learner using the 2014 Contextual Suggestion dataset. The final score for an unseen venue v for a user u is denoted scoreLT R(v, u).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Factorisation Machines</head><p>Factorisation machines <ref type="bibr" coords="2,421.81,133.70,13.05,7.82" target="#b14">[14]</ref> are a generalisation of the well-known matrix factorisation techniques <ref type="bibr" coords="2,480.13,143.25,8.86,7.82">[6]</ref> that have been successfully used in the area of collaborative filtering-based Recommender Systems. Factorisation machines can leverage not only the feedback of the user for venues she previously visited, but also user-related, venue-related and contextual information. They are therefore an appropriate approach for this track.</p><p>Factorisation machines receive as input instances that enclose the information related to a user, a venue he/she visited and the context of the visit in the form of numerical vectors. In our case, our instances are comprised of three blocks representing the following information: 1) a user indicator block to enable personalisation, 2) the user features and context provided in the batch requests and 3) venue-dependent features extracted from Foursquare, as described above. Note that, unlike a collaborative filtering setting where the suggested venues have previously been visited by at least one user, we do not use an item indicator block for our instances.</p><p>With the previous format for the instances, we train our factorisation machines to reduce the error in the ranking of the user profiles provided in the batch requests data. Specifically, we have adapted the list-wise error function of List-Rank <ref type="bibr" coords="2,345.43,353.19,13.05,7.82" target="#b16">[16]</ref> for our factorisation machine model. The optimal parameters of the model (learning rate, regularisation parameters) were determined with a train/test partition of the batch requests data, where the ratings expressed by users on venues from the two seed cities (Seattle and Detroit) were used for training the models, and the remainder of the venues were used for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Predicting Contextual Appropriateness</head><p>A major novelty in the setup of the TREC 2015 Contextual Suggestion track is the introduction of contextual aspects that can be expressed by users, namely: duration of visit (daytime, nighttime, weekend, longer); season (Spring, Summer, etc.), group (alone, with friends, with family, other), and type of trip (business, holiday, other). It is therefore important to take these contextual aspects into account when ranking venues.</p><p>In our participation, we developed di↵erent approaches to accomplish appropriate prediction of the contextual aspects of the venues, using timestamp and textual information that can be gleaned about the venues from the Foursquare locationbased social network, and the venues' websites.</p><p>• Timestamp: For the duration and season dimensions, we propose the use of timestamp information that can be gleaned about the venues from the Foursquare locationbased social network. In particular, we observe that the timing of photos of a venue uploaded to the LBSN can be indicative of appropriateness in terms of duration and season dimensions. For a venue v and a contextual dimension di 2 A for aspect A = {duration, sea-son} expressed by user u, we score the denote our the predicted contextually appropriateness as dA(v, di).</p><p>Submitted P@5 • Textual: For the group and type of trip contextual aspects, we use Terrier to index the websites of each venue. Then, given a contextual aspect dimension, we identify lists of terms related to that dimension, based on freely available Web resources. For instance, for the family dimension of the group aspect, our list had terms such as "brother", "mother", etc. We then score venue websites, based on mentions of dimension related terms, using the BM25 weighting model, i.e. for venue v with website vw for a dimension di 2 A for aspect A = {group, type}, calculate dA(v, d) = scoreBM25(vw, Qdi), where Qdi is the set of terms identified as related to dimension di.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Batch Experiment Runs &amp; Results</head><p>We submitted 2 runs to the Contextual Suggestion Batch Experiment:</p><p>• uogTrCSFM deploys factorisation machines (see Section 2.2.2).</p><p>• uogTrCSLVPC deploys our learning to rank approach (Section 2.2.1) and the prediction of contextual appropriateness (Section 2.2.3) in a linear combination.</p><p>Table <ref type="table" coords="3,116.25,407.09,4.20,7.82" target="#tab_0">1</ref> reports the performance of our two submitted runs together with the TREC Median using the o cial measures. For reference, we include a baseline run consisting in ranking first the venues in Foursquare by venue id (denoted Foursquare baseline). Note that the baseline itselfwhich our runs are based on -fares well with respect to the TREC median, particularly in terms of P@5. As the results show, our runs are competitive, performing above the baseline and the TREC median in both cases. In particular, the uogTrCSFM run (factorisation machines) is the best of the two. Overall, the results for both of our runs exhibit promising above-median performances, and hence merit further study in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TEMPORAL SUMMARISATION TRACK</head><p>The aim of our participation in the Temporal Summarisation track is to explore entity-focused models for the summarisation of evolving events <ref type="bibr" coords="3,198.03,574.70,8.39,7.82" target="#b4">[4]</ref>. In particular, we form the hypothesis that events are about entities, and e↵ective summaries of events can be produced using summarisation features that are derived from the entities involved in the events. The features we investigate are entity importance and entity-entity interaction, which attempt to capture the salient entities and how they connect with other entities. Entity importance is estimated via entity frequency, and entity-entity interaction is estimated via entity co-occurrence. The entity-focused features are used in event summarisation algorithms to score sentences for inclusion into the summary of the event. Further, we also investigated two distinct methods of processing the corpus, summarising the content of each event either document-by-document, or in hour-byhour batches. In the case of hour-by-hour, all sentences from documents within that hour are combined into a virtual document. Summarising each document as it arrives simulates a real-time scenario, whereas batching the documents in hourly chunks represents a near real-time task.</p><p>We submitted runs to Task 3 "Summarisation Only", using the "RelOnly" corpus, where the input to the event summarisation algorithm is a topically cohesive set of documents about an event. This contrasts with Task 1 and Task 2, and our participation in previous years <ref type="bibr" coords="3,456.58,188.44,13.05,7.82" target="#b11">[11,</ref><ref type="bibr" coords="3,473.30,188.44,9.79,7.82" target="#b12">12]</ref>, where participants are required to perform some form of topic detection and tracking <ref type="bibr" coords="3,371.46,207.53,8.85,7.82" target="#b1">[1]</ref> over a larger corpus containing non-relevant documents, in addition to summarisation <ref type="bibr" coords="3,473.21,217.07,8.86,7.82" target="#b5">[5,</ref><ref type="bibr" coords="3,484.14,217.07,9.79,7.82" target="#b13">13]</ref>. Documents in the relevant only corpus 1 were first converted to plain text TREC &lt;DOC&gt;'s, discarding the binary encoded metadata. Then, we used the CoreNLP toolkit to tokenise the (Serif) pre-tagged sentences within the documents, and identify three classes (&lt;PER&gt;, &lt;ORG&gt;, &lt;LOC&gt;) of named entities. We compute entity frequency at the document (or virtual document) level, and compute entity co-occurrence at the sentence level.</p><p>To produce temporal summaries of events, first, the topic query is used to produce an initial ranking of sentences. Sentences are scored by their cosine similarity to the query, and sentences with no similarity to the query are discarded. This set of candidate summary sentences is then passed to an entity-focused event summarisation algorithm, for reranking. Further, we submitted (un-pooled) baseline runs where no re-ranking was performed. Next, at each batch boundary (document-by-document or hour-by-hour), all candidate summary sentences are scored using the entity-focused features, and passed through a top-k selection procedure, where k = 1 in our submitted runs. The selection of k sentences is then passed to an anti-redundancy filtering component, which aims to minimise repetition in the sentences being emitted over time. In our submitted runs, we use a cosine similarity threshold filter. Sentences passing this cosine similarity threshold are emitted from the system and form the summary of the event.</p><p>Table <ref type="table" coords="3,354.83,474.73,4.20,7.82" target="#tab_2">2</ref> and Table <ref type="table" coords="3,401.40,474.73,4.20,7.82">3</ref> presents the results of our runs, and the track average. Table <ref type="table" coords="3,420.68,484.27,4.20,7.82" target="#tab_2">2</ref> gives results for our runs that were pooled, and Table <ref type="table" coords="3,412.92,493.81,4.20,7.82">3</ref> gives extended evaluation results using automatic matching of non-pooled updates. Statistically significant di↵erences from the TREC average are indicated in Table <ref type="table" coords="3,385.91,522.44,4.20,7.82" target="#tab_2">2</ref> and Table <ref type="table" coords="3,432.48,522.44,4.20,7.82">3</ref> using the " †" symbol, where the statistical test used is the Students t-test, paired-sample, with 95% confidence level. We submitted 6 runs in total, 4 of which were pooled, and 2 were un-pooled, as described below.</p><p>• Entity Importance: Scoring candidate summary sentences as a function of the entities they contain.</p><p>-uogTrdEQR1 (doc-by-doc)</p><p>-uogTrhEQR2 (hour-by-hour)</p><p>• Entity-entity Interaction: Scoring candidate summary sentences as a function of the entity pairs they contain. • Baselines (un-pooled): Scoring candidate summary sentences by their cosine similarity to the query.</p><p>-uogTrdSqCR5 (doc-by-doc) -uogTrhSqCR6 (hour-by-hour)</p><p>Under the track target metric of the harmonic mean of normalised expected latency gain and latency comprehensiveness, from Table <ref type="table" coords="4,161.73,164.36,3.26,7.82" target="#tab_2">2</ref>, we observe that all submitted runs performed above the track average. We also observe that processing the corpus using the hour-by-hour method is more e↵ective than processing document-by-document, when selecting 1 update per batch boundary (top-k, where k = 1). Also from Table <ref type="table" coords="4,163.27,212.07,3.26,7.82" target="#tab_2">2</ref>, we observe that the document-bydocument method is more e↵ective under comprehensiveness metrics, while the hour-by-hour method results are more e↵ective under gain metrics. Examining the two di↵erent entity-focused features, entity importance and entity-entity interaction, from Table <ref type="table" coords="4,171.34,259.79,4.20,7.82" target="#tab_2">2</ref> we observe that both features exhibit very similar e↵ectiveness under the harmonic mean metric. However, entity-entity interaction is more e↵ective than entity importance, for both document-by-document and hour-by-hour, under normalised expected gain, although not when latency is taken into account. Further, entity importance is more e↵ective than entity-entity interaction under comprehensiveness metrics for the document-by-document method.</p><p>We now examine results from Table <ref type="table" coords="4,221.15,345.67,3.26,7.82">3</ref>, which presents evaluation scores from the automatic matching of non-pooled updates. Table <ref type="table" coords="4,146.95,364.76,4.20,7.82">3</ref> includes results for our 2 baseline run submissions, uogTrdSqCR5 and uogTrhSqCR6, which were un-pooled. The system e↵ectiveness ordering (as shown in Table <ref type="table" coords="4,106.86,393.39,3.73,7.82" target="#tab_2">2</ref>) of our submitted runs, under harmonic mean, has not altered using this method of evaluation, but we note the track average has increased (from 0.0385 to 0.0472) due to the inclusion of un-pooled runs. This increase has resulted in only run uogTrdSqCR5 exhibiting a significant improvement over the track average, under the harmonic mean metric, with runs uogTrhEQR2 and uogTrhEEQR4 exhibiting p-values of 0.0594 and 0.0506 respectively. The performance of the baselines, ranking sentences by their cosine similarity to the query, exhibit similar e↵ectiveness over document-bydocument and hour-by-hour methods, and similar to results in Table <ref type="table" coords="4,116.99,498.35,3.26,7.82" target="#tab_2">2</ref>, hour-by-hour o↵ers better gain, and documentby-document o↵ers better comprehensiveness. The baseline runs, uogTrdSqCR5 and uogTrhSqCR6, are used as input to the entity-focused runs, uogTrdEQR1, uogTrhEQR2, uogTrdEEQR3 and uogTrhEEQR4, i.e. the entity-focused runs are re-ranking the baseline set of sentences. Under the harmonic mean metric, the re-ranking has led to a decrease in e↵ectiveness for the document-by-document method, and has had little e↵ect under the hour-by-hour method. However, examining the gain and comprehensiveness metrics, under document-by-document and hour-by-hour methods, we find that the re-ranking from the entity-focused event summarisation has led to improvements in the recall-oriented metric (comprehensiveness), but a loss in the precision-oriented metric (gain).</p><p>From the results in Table <ref type="table" coords="4,194.69,641.49,4.20,7.82" target="#tab_2">2</ref> and Table <ref type="table" coords="4,245.20,641.49,3.26,7.82">3</ref>, we conclude that using entities to derive event summarisation features can lead to e↵ective summaries of events. Further, the two entity-focused features we investigated performed broadly the same, and in future work a combination of features may lead to improvements in e↵ectiveness. Additionally, we found that processing the corpus in hourly batches results in more e↵ective event summary sentence selection decisions, possibly due to more information being available. Finally, we found that ranking sentences by their cosine similarity to the query, and selecting 1 sentence per batch boundary, o↵ers a reasonably e↵ective baseline for Task 3 of the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DYNAMIC DOMAIN</head><p>The primary aim of our participation in the first year of the Dynamic Domain track is to research and investigate the adaptation of resource selection and document prioritisation techniques for integration into our Terrier IR platform. More specifically, we explore two methods to minimise the number of iterations of the retrieval-feedback cycle needed to identify sub-topics that are of interest to the user. First, we a investigate a resource selection strategy to reduce the time taken to correctly identify the domain of interest for each query. Second, we investigate strategies to prioritise documents from the selected resources. Finally, we also investigate increasing the user's potential rate of exploration by diversifying the potential sub-topic intents presented to that user during each iteration. We summarise these methods in more detail below:</p><p>Resource Selection: We view the Dynamic Domain task as a resource selection problem, where each domain is considered as a separate resource. To prioritise resources, we use an implementation of CORI <ref type="bibr" coords="4,454.08,345.61,8.85,7.82" target="#b2">[2]</ref> to score each domain with respect to the frequency of the query terms within the domain. Having ranked the domains using resource selection, we investigate domain prioritisation strategies select documents to show to the user.</p><p>Domain Prioritisation Strategies: The domain prioritisation strategies that we investigate in our participation each select documents from all four domain resources to present to the user. However, each strategy apportions a di↵erent level of confidence based on the CORI ranking, by presenting the user with a proportionately higher percentage of documents from the top ranked domain. The details of the domain selection strategies are as follows:</p><p>• Interleaving: The Interleaving strategy attributes the least amount of confidence in the CORI ranking and therefore selects documents from all four domains to present to the user in each iteration. To prioritise resources, two documents from the top ranked domain and one document from each of the other of the three domains are selected to present to the user each in each iteration.</p><p>• Round Robin: The Round Robin strategy selects five documents from each domain resource within each iteration and presents the user documents from one resource at a time. The Round Robin strategy attributes a moderate degree of confidence to the CORI ranking, since if the domain of interest appears deeper in the CORI ranking then the number of iterations needed to present users documents from that domain is increased.</p><p>• Multi-Armed Bandit: For the Multi-Armed Bandit approach, we deploy a greedy approximation, namely  Table <ref type="table" coords="5,120.51,216.09,3.76,8.18">3</ref>: Un-pooled evaluation results, for Task 3, Summarisation Only, using the relevant only corpus.</p><p>Epsilon Greedy <ref type="bibr" coords="5,164.20,244.76,12.31,7.82" target="#b17">[17]</ref>. For each retrieval iteration, the probability of a document d being selected from the highest ranked domain resource, D1, is p(dD 1 ) = ✏ and the probability of d being selected from a randomly chosen domain that was not ranked highest by CORI is 1 ✏. For this run, we initially set ✏ = 1 and decrease the value of ✏ in steps of 0.2 every third iteration until ✏ = 0.2, at this point the run adopts the Interleaving approach for the remaining iterations. This approach initially assigns a high degree of confidence to the CORI ranking. The system becomes less confident in the CORI ranking as the number of iterations required to discover a relevant document increases.</p><p>Intent Diversification: Additionally we also investigate whether we can increase the user's exploration rate by increasing the diversity of content of the top ranked documents. One method to do so is to use search result diversification. There are two main approaches for diversifying search results, namely explicit and implicit diversification. Explicit search results diversification has previously been shown to perform well within the Web search domain <ref type="bibr" coords="5,292.82,441.10,8.86,7.82" target="#b7">[7,</ref><ref type="bibr" coords="5,83.56,450.64,10.72,7.82" target="#b11">11,</ref><ref type="bibr" coords="5,97.17,450.64,9.79,7.82" target="#b12">12]</ref>. Therefore, to maximise the number sub-topics presented to the user, we apply explicit search results diversification to each individual domain, before combining the rankings using a resource selection approach. To do this, we first identify potential sub-topic intents within a domain via topic modelling over the text of the top 30 ranked results returned from that domain. Then, we apply our state-ofthe-art xQuAD diversification framework <ref type="bibr" coords="5,240.07,517.44,13.06,7.82" target="#b15">[15]</ref> to maximise these sub-topic intents within the ranking shown to the user. Having diversified the domain rankings, documents are then selected from each of the diversified domains in turn using the Round Robin approach described above.</p><p>Runs and Results: To evaluate the approaches described above, we submitted five runs to the main task of the Dynamic Domain track. For these runs, we use Terrier v4.0 to index the CBOR collection, removing stopwords and applying Porter stemming. We selected the classical tf*idf as our retrieval model and we set our stopping condition as the first iteration where the system returns a relevant document. The runs uogTrSI, uogTrRR, uogTrIL and uogTrEpsilonG evaluate the implemented resource selection techniques, while uogTrxQuADRR evaluates the benefits of search result diversification for maximising the user's exploration rate. • uogTrSI: This run uses a single index of all four domains and serves as our baseline.</p><p>• uogTrRR: This run uses CORI to rank domain resources and selects documents from resources based on the Round Robin strategy.</p><p>• uogTrIL: This run uses CORI to rank domain resources and selects documents from resources based on the Interleaving strategy.</p><p>• uogTrEpsilonG: This run uses CORI to rank domain resources and selects documents from resources based on the Multi-Armed Bandit strategy.</p><p>• uogTrxQuADRR: This run enhances the uogTrRR run by applying xQuAD search results diversification to ranking of documents within a domain before selecting documents from resources based on the Round Robin strategy.</p><p>Table <ref type="table" coords="5,355.35,574.70,4.20,7.82" target="#tab_3">4</ref> presents the performance of our runs submitted to the main task, along with the TREC median and a manual resource selection run that only selects documents from the correct domain for the query (manual R.S.). The table reports the o cial track measures, uERR, Cube Test <ref type="bibr" coords="5,532.75,612.87,8.85,7.82" target="#b8">[8]</ref> (CT@10) and Averaged Cube Test (ACT@10), along with the mean reciprocal rank of the first relevant document(MRR). Firstly, we note from Table <ref type="table" coords="5,426.69,641.49,4.20,7.82" target="#tab_3">4</ref> that the single index baseline (uogTrSI) achieves a low MRR score (0.3506). Moreover, for this run, the first relevant document appears between ranks 151-992 for 23% of the topis. We suspect that this is mainly due to the low levels of completeness in the collection, as recognised by the track organisers. We also note that while tf*idf may not have been the optimal weighting model to deploy, it results in best completeness at ranks 100 and 1000 compared to a variety of weighting models implemented in Terrier. Secondly, we note from Table <ref type="table" coords="6,222.09,121.65,4.20,7.82" target="#tab_3">4</ref> that the resource selection approaches, uogTrRR, uogTrIL and uogTrEpsilonG, do not result in performance improvements over the single index baseline. This appears mainly to be due to the fact that CORI expects the query terms to have a higher relative frequency in the domain of interest than other domains. However, as we can see from the manual resource selection (manual R.S.) run, that only ranks documents from the correct domain, a system that selects the correct domain resource for each query achieves notable performance improvements. Lastly, we conclude that search result diversification can improve the user's exploration rate, since we see that our xQuAD based run with Round Robin resource selection, uogTrxQuADRR, achieves higher uERR and CT@10 scores than the same approach without applying diversification, uogTrRR. Moreover, uogTrxQuADRR achieves a higher CT@10 score than the single index baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>In TREC 2015, we participate in both the "live" and "batch" experiments of the Contextual Suggestion track, the Summarisation Only task (Task 3) of the Temporal Summarisation track and the main task of the Dynamic Domain track. In particular, for the Contextual Suggestion track we propose two novel venue suggestion approaches that leverage data from the Foursquare LBSN. Firstly we propose an approach based on factorisation machines that uses check-in statistics, venue categories and user contexts to make personalised suggestions. Our second approach deploys a linear combination of a learning to rank technique and contextual appropriateness prediction. Overall, our runs are competitive, with both approaches performing above the TREC median. In particular, the factorisation machines run is the best of the two. For the Temporal Summarisation track, we explore entity-focused models for the summarisation of evolving events. In particular, we investigate entity importance and entity-entity interaction features. Furthermore, we also investigate two distinct methods of processing the corpus for event summarisation, namely document-bydocument and hour-by-hour batches. Overall, our runs are competitive, with all submitted runs performing above the track average. Moreover, we note that processing the corpus in hourly batches results in more e↵ective event summary sentence selection, and we conclude that using entities to derive event summarisation features can lead to e↵ective summaries of events. For the Dynamic Domain track, we experiment with resource selection and document prioritisation strategies to reduce the number of iterations of the retrieval-feedback cycle needed to identify sub-topics that are of interest to the user. Moreover, we show that search result diversification can be used to increase the number of sub-topic intents within the document ranking and maximise the user's potential exploration rate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,323.91,659.25,3.33,4.99;3,327.69,660.58,207.88,7.82;4,91.85,64.03,4.83,8.18;4,100.78,70.15,53.21,2.06;4,156.78,64.39,46.62,7.82;4,91.85,76.22,4.83,8.18;4,100.78,82.34,53.64,2.06;4,157.21,76.58,54.61,7.82"><head>1</head><label></label><figDesc>dcs.gla.ac.uk/˜richardm/TREC-TS-2015RelOnly.aws.list -uogTrdEEQR3 (doc-by-doc) -uogTrhEEQR4 (hour-by-hour)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,83.56,62.44,218.12,85.07"><head>Table 1 :</head><label>1</label><figDesc>Results of our runs in the Contextual Suggestions track. Figures in bold represent the top performances.</figDesc><table coords="3,101.73,62.44,181.78,46.90"><row><cell></cell><cell></cell><cell>MRR</cell></row><row><cell>TREC Median</cell><cell>-</cell><cell>0.5090 0.6716</cell></row><row><cell>Foursquare baseline</cell><cell>6</cell><cell>0.5100 0.6509</cell></row><row><cell>uogTrCSFM</cell><cell>4</cell><cell>0.5706 0.7190</cell></row><row><cell>uogTrCSLVPC</cell><cell>4</cell><cell>0.5498 0.6758</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,83.56,121.00,458.05,84.38"><head>Table 2 :</head><label>2</label><figDesc>Performance of our submitted runs for Task 3, Summarisation Only, using the relevant only corpus.</figDesc><table coords="5,146.23,140.72,335.25,64.66"><row><cell>RunID</cell><cell cols="5">nE[Gain] nE[Lat. Gain] Comp. Lat. Comp. HM(nE[LG],Lat. Comp.)</cell></row><row><cell>TREC average</cell><cell>0.0595</cell><cell>0.0319</cell><cell>0.5627</cell><cell>0.3603</cell><cell>0.0472</cell></row><row><cell>uogTrdEEQR3</cell><cell>0.0418 †</cell><cell>0.0277</cell><cell>0.6096</cell><cell>0.4072 †</cell><cell>0.0505</cell></row><row><cell>uogTrdEQR1</cell><cell>0.0402 †</cell><cell>0.0275</cell><cell>0.6590 †</cell><cell>0.4614 †</cell><cell>0.0508</cell></row><row><cell>uogTrdSqCR5</cell><cell>0.0721</cell><cell>0.0363</cell><cell>0.4761 †</cell><cell>0.2534 †</cell><cell>0.0617 †</cell></row><row><cell>uogTrhSqCR6</cell><cell>0.1176 †</cell><cell>0.0466</cell><cell>0.3249 †</cell><cell>0.1232 †</cell><cell>0.0631</cell></row><row><cell>uogTrhEEQR4</cell><cell>0.0714</cell><cell>0.0365</cell><cell>0.5342</cell><cell>0.2983</cell><cell>0.0632</cell></row><row><cell>uogTrhEQR2</cell><cell>0.0667</cell><cell>0.0368</cell><cell>0.5459</cell><cell>0.3166</cell><cell>0.0639</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,323.49,242.63,218.12,114.82"><head>Table 4 :</head><label>4</label><figDesc>Results of our runs in the Dynamic Domain main track, the TREC median and a manual resource selection run. Figures in bold represent our top performing submitted runs.</figDesc><table coords="5,328.44,242.63,208.21,67.28"><row><cell></cell><cell cols="4">Submitted MRR uERR CT@10 ACT@10</cell></row><row><cell>TREC Median</cell><cell>-</cell><cell>-</cell><cell>0.2683 0.0575</cell><cell>0.1286</cell></row><row><cell>uogTrSI</cell><cell>4</cell><cell cols="3">0.3506 0.2317 0.0269 0.1699</cell></row><row><cell>uogTrRR</cell><cell>4</cell><cell cols="2">0.2535 0.1705 0.0228</cell><cell>0.1346</cell></row><row><cell>uogTrIL</cell><cell>4</cell><cell cols="2">0.1687 0.1602 0.0184</cell><cell>0.1107</cell></row><row><cell>uogTrEpsilonG</cell><cell>4</cell><cell cols="2">0.2434 0.1663 0.0215</cell><cell>0.1277</cell></row><row><cell>uogTrxQuADRR</cell><cell>4</cell><cell cols="3">0.4038 0.2256 0.0272 0.0850</cell></row><row><cell>manual R.S.</cell><cell>6</cell><cell cols="2">0.5113 0.3120 0.0330</cell><cell>0.2222</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,327.58,59.70,88.32,14.19" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,71.40,162.22,6.94;6,339.59,79.58,198.45,6.94;6,339.59,87.76,119.26,6.94" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,371.23,71.40,130.59,6.94;6,339.59,79.58,153.69,6.94">Topic Detection and Tracking. chapter Introduction to Topic Detection and Tracking</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,96.85,201.84,6.94;6,339.59,104.70,162.75,7.27;6,339.59,112.88,195.79,7.27;6,339.59,121.06,91.31,7.27" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,467.87,96.85,73.56,6.94;6,339.59,105.03,119.93,6.94">Searching Distributed Collections with Inference Networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,475.43,104.70,26.91,7.27;6,339.59,112.88,195.79,7.27;6,339.59,121.06,68.15,7.27">Proc. of Conference on Research and Development in Information Retrieval, SIGIR &apos;95</title>
		<meeting>of Conference on Research and Development in Information Retrieval, SIGIR &apos;95</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,130.47,193.12,6.94;6,339.59,138.65,178.31,6.94;6,339.59,146.51,195.42,7.27;6,339.59,154.69,201.29,7.27;6,339.59,163.19,32.16,6.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,339.59,138.65,178.31,6.94;6,339.59,146.83,139.98,6.94">On the Importance of Venue-Dependent Features for Learning to Rank Contextual Suggestions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,495.16,146.51,39.86,7.27;6,339.59,154.69,201.29,7.27;6,339.59,163.19,9.00,6.94">Proc. of the Conference Information &amp; Knowledge Management, CIKM &apos;14</title>
		<meeting>of the Conference Information &amp; Knowledge Management, CIKM &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,172.28,194.56,6.94;6,339.59,180.13,195.07,7.27;6,339.59,188.64,37.75,6.94" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yom-Tov</surname></persName>
		</author>
		<title level="m" coord="6,459.44,172.28,74.72,6.94;6,339.59,180.13,191.82,7.27">Updating Users about Time Critical Events. Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7814</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,197.73,184.27,6.94;6,339.59,205.91,169.12,6.94;6,339.59,214.09,171.92,6.94;6,339.59,221.94,191.38,7.27;6,339.59,230.12,148.16,7.27" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,383.32,205.91,125.39,6.94;6,339.59,214.09,171.92,6.94;6,339.59,222.27,49.41,6.94">A Repository of State of the Art and Competitive Baseline Summaries for Generic News Summarization</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,405.00,221.94,125.96,7.27;6,339.59,230.12,125.00,7.27">Proc. of the Conference on Language Resources and Evaluation, LREC &apos;14</title>
		<meeting>of the Conference on Language Resources and Evaluation, LREC &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,239.53,192.28,6.94;6,339.59,247.39,169.58,7.27;6,339.59,255.89,61.35,6.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,461.86,239.53,70.02,6.94;6,339.59,247.71,127.63,6.94">Matrix Factorization Techniques for Recommender Systems</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,473.46,247.39,31.75,7.27">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,264.98,168.27,6.94;6,339.59,273.16,199.61,6.94;6,339.59,281.34,180.49,6.94;6,339.59,289.19,194.81,7.27;6,339.59,297.37,164.76,7.27" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,495.83,273.16,43.37,6.94;6,339.59,281.34,180.49,6.94;6,339.59,289.52,152.15,6.94">University of Glasgow at TREC 2012: Experiments with Terrier in Medical Records, Microblog, and Web Tracks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,507.49,289.19,26.91,7.27;6,339.59,297.37,141.60,7.27">Proc. of the Text REtrieval Conference, TREC &apos;12</title>
		<meeting>of the Text REtrieval Conference, TREC &apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,306.79,182.13,6.94;6,339.59,314.97,177.72,6.94;6,339.59,322.82,169.91,7.27;6,339.59,331.00,201.30,7.27;6,339.59,339.50,32.16,6.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,485.25,306.79,36.47,6.94;6,339.59,314.97,177.72,6.94;6,339.59,323.15,114.44,6.94">The Water Filling Model and the Cube Test: Multi-dimensional Evaluation for Professional Search</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,469.65,322.82,39.85,7.27;6,339.59,331.00,201.30,7.27;6,339.59,339.50,9.00,6.94">Proc. of the Conference Information &amp; Knowledge Management, CIKM &apos;13</title>
		<meeting>of the Conference Information &amp; Knowledge Management, CIKM &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,348.59,194.74,6.94;6,339.59,356.77,178.90,6.94;6,339.59,364.62,133.00,7.27" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,339.59,356.77,178.90,6.94;6,339.59,364.95,21.99,6.94">From Puppy to Maturity: Experiences in Developing Terrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,367.28,364.62,81.10,7.27">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,374.04,191.49,6.94;6,339.59,382.22,199.00,6.94;6,339.59,390.07,177.42,7.27" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,509.66,374.04,21.43,6.94;6,339.59,382.22,195.60,6.94">About Learning Models with Multiple Query-dependent Features</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<idno>11:1-11:39</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,339.59,390.07,75.93,7.27">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,399.49,144.59,6.94;6,339.59,407.67,180.04,6.94;6,339.59,415.85,201.11,6.94;6,339.59,424.03,165.05,6.94;6,339.59,431.88,179.74,7.27;6,339.59,440.06,134.27,7.27" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,366.51,415.85,174.19,6.94;6,339.59,424.03,165.05,6.94;6,339.59,432.20,106.66,6.94">University of Glasgow at TREC 2013: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limosopathan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Dinçer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,461.93,431.88,57.40,7.27;6,339.59,440.06,111.11,7.27">Proc. of the Text REtrieval Conference, TREC &apos;13</title>
		<meeting>of the Text REtrieval Conference, TREC &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,449.47,188.78,6.94;6,339.59,457.65,202.03,6.94;6,339.59,465.83,175.76,6.94;6,339.59,474.01,175.34,6.94;6,339.59,481.86,196.95,7.27;6,339.59,490.04,151.81,7.27" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,386.99,465.83,128.36,6.94;6,339.59,474.01,175.34,6.94;6,339.59,482.19,141.44,6.94">University of Glasgow at TREC 2014: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Thonet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Dinçer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,496.68,481.86,39.86,7.27;6,339.59,490.04,128.65,7.27">Proc. of the Text REtrieval Conference, TREC &apos;14</title>
		<meeting>of the Text REtrieval Conference, TREC &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,499.46,197.09,6.94;6,339.59,507.31,189.34,7.27;6,339.59,515.82,17.59,6.94" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,445.08,499.46,87.80,6.94">Automatic Summarization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,339.59,507.31,161.22,7.27">Foundations &amp; Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,524.58,175.89,7.27;6,339.59,532.76,178.98,7.27;6,339.59,541.26,53.62,6.94" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,376.58,524.91,114.39,6.94">Factorization Machine with libFM</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,497.33,524.58,18.16,7.27;6,339.59,532.76,175.42,7.27">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,550.35,191.35,6.94;6,339.59,558.53,152.84,6.94;6,339.59,566.38,194.28,7.27;6,339.59,574.56,118.54,7.27" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="6,495.87,550.35,35.08,6.94;6,339.59,558.53,152.84,6.94;6,339.59,566.71,47.40,6.94">Exploiting Query Reformulations for Web Search Result Diversification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,402.37,566.38,131.51,7.27;6,339.59,574.56,95.38,7.27">Proc. of the International World Wide Web Conference, WWW &apos;10</title>
		<meeting>of the International World Wide Web Conference, WWW &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,583.98,194.94,6.94;6,339.59,592.16,201.61,6.94;6,339.59,600.01,183.08,7.27;6,339.59,608.52,38.55,6.94" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,463.04,583.98,71.50,6.94;6,339.59,592.16,198.49,6.94">List-wise Learning to Rank with Matrix Factorization for Collaborative Filtering</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanjalic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,349.23,600.01,173.44,7.27;6,339.59,608.52,35.55,6.94">Proc. of the Conference on Recommender Systems, RecSys &apos;10</title>
		<meeting>of the Conference on Recommender Systems, RecSys &apos;10</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,617.28,200.38,7.27;6,339.59,625.46,142.63,7.27" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="6,444.51,617.28,95.46,7.27;6,339.59,625.46,40.34,7.27">Reinforcement Learning: an Introduction</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT press Cambridge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,339.59,634.87,192.06,6.94;6,339.59,643.05,169.93,6.94;6,339.59,651.23,86.59,6.94" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="6,501.31,634.87,30.34,6.94;6,339.59,643.05,106.56,6.94">Ranking, boosting, and model adaptation</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
