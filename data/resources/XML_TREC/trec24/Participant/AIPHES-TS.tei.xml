<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.33,75.48,75.03,13.77;1,208.42,85.58,276.32,4.49;1,118.68,100.12,376.71,4.49">SeqCluSum: Combining Sequential Clustering and Contextual Importance Measuring to Summarize Developing Events over Time</title>
				<funder ref="#_R5EMGKk">
					<orgName type="full">German Research Foundation (DFG)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,275.98,124.89,62.11,3.74"><forename type="first">Markus</forename><surname>Zopf</surname></persName>
							<email>zopf@aiphes.tu-darmstadt.de</email>
							<affiliation key="aff0">
								<orgName type="department">AIPHES / Knowledge Engineering Group Department of Computer Science</orgName>
								<orgName type="laboratory">Research Training Group</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
								<address>
									<addrLine>Hochschulstraße 10</addrLine>
									<postCode>64293</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.33,75.48,75.03,13.77;1,208.42,85.58,276.32,4.49;1,118.68,100.12,376.71,4.49">SeqCluSum: Combining Sequential Clustering and Contextual Importance Measuring to Summarize Developing Events over Time</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BA2EC1EBEB40AEA9D47271D9C0EDB4C1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unexpected events such as accidents, natural disasters and terrorist attacks represent an information situation where it is essential to give users access to important and non-redundant information as fast as possible. In this paper, we introduce SeqCluSum, a temporal summarization system which combines sequential clustering to cluster sentences and a contextual importance measurement to weight the created clusters and thereby to identify important sentences. We participated with this system in the TREC Temporal Summarization track where systems have to generate extractive summaries for developing events by publishing sentencelength updates extracted from web documents. Results show that our approach is very well suited for this task by achieving best results. We furthermore point out several improvement possibilities to show how the system can further be enhanced.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Events like accidents, natural disasters and terrorist attacks provide a important information situation. Shortly after the event occurred, the information situation is usually unclear. There might be some first vague information available, for example that an earthquake had occurred, but details like the magnitude, the epicenter, and if a tsunami has to be expected are not known at this early point in time. More and more information will become available later when details about the event are published by the media.</p><p>Traditional summarization approaches fail due to this unique characteristic of these information access problems. But especially during such crisis events the affected people urgently need infor-mation. The fastest information channel for information is the internet, where information are distributed via news sites, blogs, and microblogging services. Unfortunately the internet is not only the fastest, but also a highly redundant, bulky, and unreliable information source. This makes it impossible for an end-user to monitor this stream of news to extract important information timely.</p><p>A system which aims to aid people in retrieving information out of the web site stream has to deal with several difficulties. Since there are vast amounts of documents in the web, a system has to be highly efficient in order to process the documents. A system has to filter out unrelated documents, since the majority of the documents appearing on the web in the investigated timespan will not be related to the event and can be considered as noise. But noisiness on the document level is not the only problem. Even relevant documents contain a lot of unimportant information like unrelated news articles, advertisements, and navigation elements. This within-document noise has to be removed as well. Since information about big events are usually repeated on different web sites several times, the system has to deal with a highly redundant information situation. Another critical aspect is the trustworthiness of the sources. Several news pages publish uncertain information and this tendency is even higher in weblogs and on microblogging sites. The last, but also one of the most crucial challenges during such events, is the timely detection of new information. Since the users urgently need information, new information has to be detected as fast as possible.</p><p>In this paper we present SeqCluSum, a system which is able to aid users to satisfy their information needs in the previously described situations. We mainly address the problems of withindocument noise, redundancy, and timely detection. Efficiency is only partially considered, since we assume a situation where our system is applied Step 3 illustrates the publishing of a sentence. The sentence is added to the summary with time marker u and the cluster is set to published.</p><p>after an information retrieval step where irrelevant documents has already been filtered out. Our system is, like in the most summarization scenarios, not concerned with trustworthiness. Therefore, we assume that all documents which are passed to our system can be considered as trustworthy.</p><p>An overview about the system is given in Figure <ref type="figure" coords="2,100.17,485.20,3.73,9.53" target="#fig_0">1</ref>. First, we use two preprocessing steps (Figure <ref type="figure" coords="2,291.81,485.20,3.73,9.53" target="#fig_0">1</ref>, step 1) which remove boilerplate content and stem all tokens. This step is further described in Section 3. Second, we use sequential clustering described in Section 4.1 to cluster similar sentences together (Figure <ref type="figure" coords="2,132.00,547.00,3.73,9.53" target="#fig_0">1</ref>, step 2). Last, we weight the clusters after processing a document according to their contextual importance and publish updates (Figure <ref type="figure" coords="2,291.81,571.71,3.73,9.53" target="#fig_0">1</ref>, step 3). This step is described in Section 4.2 in detail.</p><p>With this system, we participated in the Temporal Summarization track of the Twenty-Fourth Text REtrieval Conference (TREC). We describe the shared task in detail in Section 5 and our results in Section 5.4.</p><p>Due du time limitations, we did not push all components of our system to the limit. Therefore, we describe some improvement possibilities in Section 7 from which we expect a further improvement of performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early work on document summarization started with <ref type="bibr" coords="2,337.56,465.67,50.97,9.53" target="#b8">Luhn (1958)</ref>, <ref type="bibr" coords="2,398.40,465.67,96.05,9.53" target="#b1">Baxendale (1958), and</ref><ref type="bibr" coords="2,499.53,465.67,9.58,9.53;2,314.79,478.03,64.05,9.53" target="#b3">Edmundson (1969)</ref>, who used word frequencies, position features, and key phrases to detect important sentences. <ref type="bibr" coords="2,324.74,515.87,123.70,9.53" target="#b10">McKeown and Radev (1995)</ref> introduced the problem of multi-document summarization. Temporal summarization in the TREC-TS challenge is strongly related to extractive multi-document summarization <ref type="bibr" coords="2,359.99,565.31,126.50,9.53" target="#b13">(Nenkova and McKeown, 2011)</ref>, since the systems are only allowed to extract sentences from the source documents verbatim. <ref type="bibr" coords="2,466.72,590.03,47.18,9.53;2,314.79,602.39,26.53,9.53" target="#b15">Radev et al. (2004)</ref> presented an open-source multi-document summarization system, MEAD, which is able to summarize large news topics by clustering sentences and finding centroids. <ref type="bibr" coords="2,441.32,639.47,68.25,9.53;2,314.79,651.83,42.67,9.53" target="#b11">Mihalcea and Tarau (2004)</ref> used a graph-based method to extract text for summarization. <ref type="bibr" coords="2,414.97,664.19,98.94,9.53;2,314.79,676.55,26.53,9.53" target="#b2">Carbonell and Goldstein (1998)</ref> introduced the greedy approach MMR to extract topic related and non-redundant sentences jointly.</p><p>For the particular task of temporal summarization, we review some of the participating systems from last years TREC-TS challenges. The best performing run in the challenge in 2014 was the "2APSal" run by team "cunlp" <ref type="bibr" coords="3,242.78,122.00,56.50,9.53;3,100.17,134.36,21.42,9.53" target="#b5">(Kedzie et al., 2014)</ref>, who used affinity propagation clustering. <ref type="bibr" coords="3,100.17,146.72,71.95,9.53" target="#b18">Zhao et al. (2014)</ref> used a query expansion and information retrieval step with the Lemur toolkit<ref type="foot" coords="3,295.19,157.28,3.64,6.97" target="#foot_0">1</ref> and a k-means clustering <ref type="bibr" coords="3,202.74,171.44,79.46,9.53" target="#b17">(Zhang et al., 1996)</ref> and sentence selection step. <ref type="bibr" coords="3,201.27,183.80,98.00,9.53" target="#b9">McCreadie et al. (2014)</ref> used a pipeline to filter out unrelevant documents, to classify sentence according to their relevance, and to filter out redundant sentence to build a realtime summarization system.</p><p>Our approach described in this paper combines the timely detection of a pipelining approach like <ref type="bibr" coords="3,117.93,270.47,96.41,9.53" target="#b9">McCreadie et al. (2014)</ref> with the redundancy avoidance strategy of a clustering approach like <ref type="bibr" coords="3,100.17,295.19,70.31,9.53" target="#b18">Zhao et al. (2014)</ref> by using a sequential clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preprocessing</head><p>In this section, we describe two important preprocessing steps which are used to prepare the input documents for the temporal summarization system. Both preprocessing steps, boilerplate removal and word stemming, are well-known and crucial for the performance of the subsequent summarization. Since they are self-contained systems and independent from the subsequent summarization system we did not investigate them in detail and expect further potential for improvement of the whole system if these steps are improved.</p><p>Documents retrieved from the web are usually very noisy since they do not only contain one article, but also advertisements, navigation elements, text snippets from other websites, author information, templates, pictures, links to related articles, etc. This noise was described in the introduction as within-document noise and is commonly called boilerplate text. Content which is unrelated to the target topic should never be included in the output of a summarization system. Therefore, the first preprocessing removes the within-document noise. To tackle this problem, we utilize the software Boilerpipe <ref type="bibr" coords="3,166.93,621.31,105.26,9.53" target="#b6">(Kohlschütter et al., 2010)</ref> which uses shallow text features to remove unrelated text fragments. This preprocessing step is crucial for a good performance of the summarization system described below since it publishes frequent information without any knowledge of the actual query.</p><p>Since navigation elements and advertisements are very frequent on web sites the system would include a lot of this unimportant content into the summary.</p><p>In a second step, we stem all words in the source documents with the well-known Porter-stemmer <ref type="bibr" coords="3,314.79,147.39,55.04,9.53" target="#b14">(Porter, 1980)</ref>. This step is assumed to help the system to detect semantically similar but syntactically different words. Stemming will become important in Section 4.1 and Section 4.2 when we cluster similar sentences to measure their importance and to detect redundancy. More abstract semantic methods like word embeddings <ref type="bibr" coords="3,476.56,221.55,37.35,9.53;3,314.79,233.91,51.84,9.53" target="#b12">(Mikolov et al., 2013)</ref> are expected to model the semantic similarity of words better than stemming since they can, for example, not only detect a similarity between the words crash and crashed, but also between crash and accident. Therefore, we assume that a better representation could further improve the performance of similarity and redundancy detection in the following summarization system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Temporal Summarization with SeqCluSum</head><p>After explaining the preprocessing of the documents, we now describe the combination of two building blocks, a sequential clustering algorithm with a contextual importance measurement.</p><p>The first building block of the system, a sequential clustering algorithm, is responsible to detect redundant information by clustering similar sentences together. Since the second block will select at most one sentence per cluster, this will prevent the system to publish similar sentences (and therefore similar information) multiple times. The sequential clustering is described in Section 4.1.</p><p>To decide which sentences should be included in the summary, we apply in a second block a contextual importance measuring, which is further described in Section 4.2. This building block publishes sentences depending on the weight of the sentences, which itself depends on the content of the sentences as well as on already published sentences (therefore contextual), and the weight of the previously generated clusters.</p><p>The both blocks are applied for each document one after another and therefore work closely together to jointly solve the problem of timely detection of important information and reduction of redundancy. For convenience, we give pointers to the pseudo-code of the system in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sequential Clustering</head><p>The first building block of the temporal summarizer is a sequential clustering algorithm. We apply the Basic Sequential Algorithm Scheme (BSAS) <ref type="bibr" coords="4,136.49,128.42,158.50,9.53" target="#b16">(Theodoridis and Koutroumbas, 2009)</ref>, which is used to iterate over all (unpruned) sentences in the currently processed document (Algorithm 1, line 5). The algorithm searches for the nearest existing cluster by using a similarity measure (line 7) for all sentences which were not pruned in the boilerplate removal step. We describe the distance measure below in more detail. If the similarity to all existing clusters is lower than a fixed threshold ⇥ and the maximum number of clusters I is not already reached, a new cluster is created and the sentence is added to the new cluster (line 9). Otherwise, the sentences is added to the nearest existing cluster (line 11).</p><p>The similarity measure calculates the similarity between a sentence s i and a cluster C j by calculating the similarity between the sentence s i and the first sentence of the cluster C j 1 . By doing so, the sentences to cluster similarity measurement is reduced to a sentences to sentence similarity measurement. This has several advantages in comparison to considering all sentences in the cluster.</p><p>First, it emphasizes the notion of a cluster as a set of sentences which contains one distinct information. In a scenario where the similarity function works perfectly (i.e. equals 1 if the sentence matches the represented information by the cluster and equals 0 otherwise), there is no need to compare it to the other sentences. The result would be the very same for each sentence. We choose the first sentences of each cluster to be the representative of the cluster since each first sentence has a special role. This special role derives from the fact that the first sentence of each cluster was the reason why the cluster had been created. The sentences did not fit to another cluster and therefore created its own, new cluster.</p><p>Second, the center of the cluster is fixed when we compare only with the first sentence of the cluster. This prevents the cluster from a topic drift, which was a serious issue when we compared to more than one sentences. By adding more and more sentences and also using the newly added sentences for further distance calculations could instead change the initial notion of the cluster significantly since the center of the cluster would move.</p><p>Third, the approach is computational efficient in comparison to an approach, where we would compute the similarity by incorporating all sentence in a particular cluster.</p><p>The actual similarity measure metric (line 7) is a linear combination of various well-known similarity measures. We use five different n-gram Jaccard measures, for n 2 {1, 2, 3, 4, 5}. The n-gram Jaccard measure is defined in Equation <ref type="formula" coords="4,478.38,171.56,3.73,9.53">1</ref>, where ⇧ n (s) is the set of all n-grams in sentence s.</p><formula xml:id="formula_0" coords="4,328.69,214.15,185.21,30.83">jaccard n (s 1 , s 2 ) = |⇧ n (s 1 ) \ ⇧ n (s 2 )| |⇧ n (s 1 ) [ ⇧ n (s 2 )| (1)</formula><p>Furthermore, we use a longest common subsequence comparator. Additionally to the string comparison methods, we apply different variations of cosine similarities based on inverse term frequency (ITF) vectors. To calculate the ITF values, we use a small sample of 2,182 documents as background corpus B. The ITF value of a token t equals the logarithm of the quotient of the number of all tokens in the background corpus B, |B| and the number of appearances of the token t in the background corpus B, |t 2 B| (Equation <ref type="formula" coords="4,481.72,372.94,3.59,9.53">2</ref>). This value measures how common a token is in a background corpus and measures therefore how much information a token provides in general.</p><formula xml:id="formula_1" coords="4,362.27,425.44,151.63,35.64">IT F (t) = log ✓ |B| |t 2 B| ◆ (2)</formula><p>All documents in the background corpus were retrieved from documents which were created before the event started to ensure that we do not use information which were not available at the time when the event happened.</p><p>We combine these different similarity measures into one similarity measure to cover different aspects of similarity. The overall similarity measure for two sentences s 1 and s 2 is a linear combination as shown in Equation <ref type="formula" coords="4,403.72,572.79,3.73,9.53">3</ref>, where S is a set containing all previously described similarity measures  <ref type="bibr" coords="5,150.26,212.66,62.43,9.53" target="#b0">Bär et al. (2013)</ref>. In the example, sentence s 2 is a permutation of sentence s 1 , sentence s 3 was clustered to the same cluster as sentence s 1 , and sentence s 4 was assigned to a different cluster than sentence s 1 . We see that the cosine similarity is not affected by the ordering of the words in comparison to the n-gram Jaccard measure. Therefore, the cosine similarity properly detects when two sentences are using the same words, which signals that their content is similar. Nevertheless, incorporating the Jaccard measures gives additional insights to the similarity of two sentences, since the ordering of the words can be considered as an even stronger signal for similarity.</p><formula xml:id="formula_2" coords="4,314.79,597.51,191.37,51.84">sim i . sim (s 1 , s 2 ) = 1 |S| • X sim i 2S sim i<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Measuring Contextual Importance</head><p>After all unpruned sentences in a document are clustered with the previously described sequential clustering algorithm, the system evaluates the current cluster landscape to detect important information in the document stream. To achieve this, all clusters are weighted using a weight measures based on a TF*ITF values. The score of a cluster C i equals the sum of the weights of all sentences C i j in the cluster (Equation <ref type="formula" coords="5,212.05,511.85,3.59,9.53" target="#formula_3">4</ref>).</p><formula xml:id="formula_3" coords="5,129.91,540.62,169.37,33.29">weight(C i ) = X C i j 2C i weight(C i j )<label>(4)</label></formula><p>Summarizing over all sentences in a cluster addresses the assumed property of the document stream that more important information is repeated more frequently in the source documents since bigger clusters get higher weight scores.</p><p>The weight of a sentence s i is defined as the sum of the weights of the tokens s i j contained in sentence s i (Equation <ref type="formula" coords="5,188.89,672.25,3.59,9.53" target="#formula_4">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>weight(s</head><formula xml:id="formula_4" coords="5,387.34,76.57,126.56,32.42">i ) = X s i j 2s i weight(s i j )<label>(5)</label></formula><p>In the following we define a context-free and two contextual metrics to measure the weight of a single token. The context-free metric measures how important a token is. But since we actually want to know if we should publish a sentences or not, we have to consider already published sentences as well as the importance of the sentences because we don't want to publish an important sentence when a similar sentence has already been published. We assume that certain tokens are responsible for covering a particular information nugget. Therefore, the contextual token weights incorporate the already published tokens in the computation.</p><p>The context-free weight of a token weight cf is computed based on the temporal TF*ITF-based measures of the token (Equation <ref type="formula" coords="5,445.97,311.16,3.59,9.53">6</ref>).</p><formula xml:id="formula_5" coords="5,323.81,344.24,190.09,17.27">weight cf (t, D ⌧ ) = T F cf (t, D ⌧ ) • IT F (t) (6)</formula><p>The computation of the ITF value is described in Section 4.1. We use the ITF value not to measure if a document is relevant to a topic (like the commonly used IDF value does), but to calculate if a token is important in a stream of documents. Since we have no access to all documents in the stream, but only the documents which were published until a given timestamp ⌧ , we can only compute the temporal TF values for the set D ⌧ . We measure therefore, how salient a token i is in a document stream D ⌧ until the timestamp ⌧ . To do so, we count the number of appearances of token t in the documents D ⌧ and divide this quantity by the total number of tokens in the documents |D ⌧ |. This gives us an impression on how salient a token is in the document collection D ⌧ . Equation <ref type="formula" coords="5,491.47,552.32,4.98,9.53">7</ref>formalizes the computation of the context-free token weights.</p><formula xml:id="formula_6" coords="5,363.36,596.79,150.55,30.83">T F cf (t, D ⌧ ) = |t 2 D ⌧ | |D ⌧ | (7)</formula><p>Since the document collection D ⌧ changes after each time step ⌧ , the temporal TF values are constantly updated when new documents are processed.</p><p>The contextual weight of a token models the weight of a token with respect to already published tokens. We reduce the context-free TF values for end for 22: end for 23: return Updates tokens which have already been published. By implementing such a reduction of already published tokens, we achieve a contextual importance grading of the tokens which leads to an avoidance of redundancy.</p><p>We use two different strategies for the reduction of the T F cf values. In the first contextual strategy, cs 1 , the values of all already published tokens are set to 0, which leads to a very strict and extensive avoidance of redundancy. In the second contextual strategy, cs 2 , we reduced the values by dividing the context-free value T F cf (t, D ⌧ ) by the number of appearances of token t in the already published updates. This leads to a more laxly filtering which is expected to increase recall at the cost of precision. The computation of the second contextual importance measure is described in Equation <ref type="formula" coords="6,100.17,613.59,3.73,9.53">8</ref>, where |t 2 U | denotes the number of appearances of the token t in the current set of updates</p><formula xml:id="formula_7" coords="6,100.17,638.31,199.11,50.71">U . T F cs 2 (t, D ⌧ ) = T F cf (t, D ⌧ ) |t 2 U | (8)</formula><p>A cluster is considered as sufficiently important if a fixed threshold µ is exceeded (line 16). This threshold can be varied in a productive environment easily, to produce more or less verbose summaries. For the experiments, we choose two values by hand without any sophisticated evaluation or optimization method. If a cluster exceeds the threshold, the best sentence according to the sentence score described above is published. The cluster is marked as published in this case. This means, that the cluster will not be selected in the future to publish another sentence. Nevertheless, it is still possible to add new sentences to an published cluster. This is important because we will likely see more sentences, which are similar to already published sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Introduction</head><p>We described in Section 1 the task of temporal summarization and outlined its importance and special properties in comparison to classical multidocument summarization. In this section, we describe the Temporal Summarization track <ref type="bibr" coords="7,268.84,138.01,30.44,9.53;7,100.17,150.37,39.50,9.53" target="#b4">(Guo et al., 2013)</ref> of the Text REtrival Conference 2015 (TREC), or TREC-TS 2015 for short. The goal of this track is to develop systems which can detect useful, new, and timely sentence-length updates about a developing event.</p><p>The first major difference to classical summarization challenges like DUC<ref type="foot" coords="7,215.04,222.77,3.64,6.97" target="#foot_3">3</ref> and TAC<ref type="foot" coords="7,256.49,222.77,3.64,6.97" target="#foot_4">4</ref> is the notion of time during summarization. In TREC-TS it is not only crucial to detect and extract important information, but to detect the important information as early as possible during the developing of an event.</p><p>A second important difference compared to DUC is the evaluation methodology. In DUC, gold standard summaries were written by human experts and the automatically generated summaries are compared to these summaries with the ROUGE <ref type="bibr" coords="7,139.02,360.56,48.46,9.53" target="#b7">(Lin, 2004)</ref> score. In contrast, summaries produced by the TREC-TS participant systems have to cover as many as possible fixed information nuggets. If a sentence contains an information is evaluated by hand for each sentence. Furthermore, it is, compared to DUC and TAC, solely focused on information retrieval and not on writing quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Setup</head><p>The setup of the TREC-TS track is as follows. There are 3 subtasks in the track. Each subtask consists of 21 events. The first two subtasks, Filtering and Summarization, deal with high-volume streams of news article documents and blog posts which do not have to be related to the given event. In this scenario, the participants have to filter out irrelevant documents to be able to summarize the rest of the stream. In the third subtask, Summarization only, the participants face low-volume streams of pre-filtered documents. The corresponding corpus to this subtask is called TREC-TS-2015F-RelOnly<ref type="foot" coords="7,177.57,630.17,3.64,6.97" target="#foot_5">5</ref> . In this scenario, the information retrieval problem is considered to be solved on the document level. This means that all documents in the stream contain relevant information. We participated with our system in the latter subtask.</p><p>All documents in a stream have an associated timestamp which equals the crawling time of the document. The documents have to be processed in temporal order. The result of the system is a list of updates. These updates are considered to be sentence-length update messages, which could be published via a microblogging service like Twitter<ref type="foot" coords="7,325.29,194.36,3.64,6.97" target="#foot_6">6</ref> to keep an end-user up-to-date about the development of an event. When a system decides that a sentence from the stream should be published, this particular sentence is marked with the timestamp of the currently processed document. The systems are not allowed to use information from the future to make this decision. This means, incorporating information that was only available after the current timestamp is not allowed. One example for a not allowed usage would be the computation of TF*ITF values over the whole corpus since this would provide information about which words will become frequent in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation</head><p>The evaluation of the submissions was based on Wikipedia article revision histories of the corresponding events. In a first step, information nuggets were extracted from the revision histories by the track organizers. The nuggets were marked with a timestamp and classified with an importance score of 1, 2, or 3, where 1 is the least and 3 the most important category. This timestamp equals the time where the information was included in the Wikipedia article the first time. Therefore, it represents the time when the information could be considered to be publicly available. An example of such a nugget is VM26.002-1358344449-3-'On 16 January 2013,at around 0800 GMT', where VM26.002 is the nugget id, 1358344449 is the timestamp<ref type="foot" coords="7,433.05,564.34,3.64,6.97" target="#foot_7">7</ref> when the information has been published in Wikipedia, 3 is the importance of the nugget, and 'On 16 January 2013,at around 0800 GMT' is the actually information encoded by this nugget.</p><p>In a second step, sentences were pooled from each submission. For each submission, at most 60 sentences were pooled due to the huge annotation effort. These sentences were manually matched against the extracted information nuggets since there is no system available which is able to find these matchings precisely. A sentence could thereby match multiple nuggets as well as no nugget. A sentence, which matches relevant information nuggets, which were not matched by sentences published earlier by a submission, was considered to be a valuable sentence. If a sentence matches only already matched information nuggets or no nuggets at all, it was considered to be worthless. Since such sentences do not improve the information content of the summary, the system got penalty points for being to verbose.</p><p>For the evaluation, the precision of the generated summaries was evaluated with the (normalized) Expected Gain metric nEG(S). This metric measured to which degree the sentences in the summary were on-topic and novel. The recall was measured by the Comprehensiveness metric C(S). This metric measured how many of the information nuggets that could have been retrieved were covered by the summary. A third measure, the Expected Latency E[Latency], measured to which degree the information in the summary was outdated. A combined F-measure, H, based on the precision and recall which also incorporates the latency was used as official target measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>We submitted four runs for evaluation at the TREC-TS shared task. Runs 1 and 2 used the strict contextual strategy cs 1 . The runs 3 and 4 used the more laxly contextual strategy cs 2 . Runs 1, 2 and 4 had a maximum number of clusters of 1,000 whereas run 3 had a maximum of 100. The minimum cluster score, which had to be obtained by the cluster to be published was set to 1 for the runs 1, 3, and 4. For run 2, this value was set to 3. Furthermore, we modified the boilerplate removal for runs 3 and 4 slightly to prune less sentences during the preprocessing. The similarity function used was the very same for all four runs. These changes led to differently verbose runs, where run 1 was the least verbose run followed by run 2. Run 3 and run 4 were the runs which published most updates due to the more laxly contextual strategy.</p><p>Unfortunately, we introduced errors in the result files which resulted in invalid sentence identifiers. Therefore, our sentences could not be included in the pool of sentences which were matched against the information nuggets extracted from Wikipedia as described in Section 5.3. Since other systems selected at least some of the sentences, which we had selected, we were at least able to get some points for the overlapping sentences. Since we did not get points for sentences which were only selected by our system, this score represents only a lower bound for the true performance of the system. We report the percentage of unevaluated sentences in column unevaluated. The sentences which were not evaluated were considered as irrelevant or redundant without looking at them. As example, for run 1 only 41.59% of the top 60 updates were published by other systems as well and therefore only this amount was evaluated. The remaining 58.41% were considered to be irrelevant or redundant and we were penalized for them.</p><p>Nevertheless, run 1 and run 2 achieved considerable better results than the best other participating system. Run 3 and run 4 performed better than the second best system.</p><p>Table <ref type="table" coords="8,350.13,324.09,4.98,9.53" target="#tab_2">2</ref> shows the described lower bounds for our runs, a comparison with the best 3 systems and the average grading over all runs sorted by the main target metric H. Additionally, we provide the percentage of unevaluated sentences to make the results better assessable. The evaluation results of the other systems are taken from the overview paper of the TREC-TS challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We presented SeqCluSum, a system for temporal summarization based on sequential clustering and contextual importance measurement. The sequential clustering arranges similar sentences together to detect redundancy. The contextual importance measure weights the clusters according to their importance. During this step, we incorporate the knowledge about previously published sentences to avoid redundancy.</p><p>With this system, we participated in the Summarization only subtask of the Temporal Summarization track at the Twenty-Fourth Text REtrieval Conference. Unfortunately, we introduced errors in our submission and can only report lower bounds of the performance of our runs. Nevertheless, these lower bounds show already a better performance than the best fellow competitor run. Therefore, we conclude that our approach is well suited to handle the special difficulties in this challenge.  <ref type="bibr" coords="9,226.52,218.94,4.46,9.53">]</ref> show the results according to official evaluation metrics described in Section 5.3. The column unevaluated shows how many percent of the sentences were unevaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Work</head><p>We propose in the following several possibilities to further enhance the system in order to improve the performance of our system and subsystems which were not considered due to time limitations.</p><p>The sequential clustering depends strongly on the accuracy of the used similarity measure. Since we used predefined standard similarity measures without any fine-tuning or adaption to the task, we assume that a more sophisticated selection of similarity measures could lead to an improvement of the performance.</p><p>As described in Section 3, a semantic representation of the text could also help to detect similarities between sentences more accurately.</p><p>Another improvement of the similarity measure would be to utilize the weight of the tokens, which are used during the contextual measuring of importance also in the clustering. If we weight important tokens higher in the similarity metrics, we could achieve that the clusters would be more focused on a particular information nugget. For example, the token 15 should be more influential to the clustering when there were 15 people injured in an event and the token the should not have a high influence on the similarity of sentences. Generally speaking, a sentence A = (a, x, a, a, a) should be more similar to the sentence B = (b, b, b, x, b) than to sentence C = (a, a, a, a, a) when x is an important token in the current topic and a and b are two unimportant tokens, although the tokens a and b are more frequent in the sentences than token x.</p><p>The system described in this paper relies on the assumption that important information is mentioned frequently. This is in particular problematic for temporal summarization, because it takes some time (or documents) to detect that a word is irregularly frequent in the corpus. For example, during the first mentioning of the word bomb the word is not considered to be important for the corpus, because it occurred only once. Only when more documents are processed that contain the token the system is able to detect that this token is important. If we would leverage the fact that the mentioning of bomb is always important when summarizing in the domain of terrorist attacks, we would be able to detect the importance faster. For bomb this improvement can be rather easily achieved, because when a bomb explodes this is nearly always important. But the target of the bomb will also be very important. However, it is nearly impossible to know beforehand whether the word cab, Quetta, or main station will be important. Furthermore, it should be possible to add a sentence to multiple clusters because a sentence can contain multiple information nuggets. The general idea of the clustering is that each particular information nugget is represented by exactly one cluster. In the current system, a sentence can only be part of one cluster.</p><p>Another improvement concerning the clustering could be a re-cluster step, which could split a cluster into multiple clusters when the system detects that one cluster contains too diverse sentences. This is currently prevented by the parameter ⇥. By enabling the system to execute a re-clustering step, this parameter could become needless. The same holds for the upper bound of clusters. Furthermore, the system could merge multiple clusters to one cluster, if it detects that the content of the clusters are more similar as the seed sentences suggested. This situation can easily occur when synonyms are used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,100.17,315.93,235.65,9.53;2,338.35,319.32,39.44,6.66;2,380.34,315.93,133.56,9.53;2,100.17,328.29,413.74,9.53;2,100.17,340.65,65.86,9.53;2,168.85,347.37,51.98,2.51;2,224.93,340.65,81.85,9.53;2,309.60,347.37,4.66,2.51;2,317.09,340.65,151.68,9.53;2,471.60,340.65,19.74,10.05;2,494.16,340.65,19.74,10.05;2,100.17,353.01,206.16,9.53;2,308.98,359.73,4.66,2.51;2,316.30,353.01,7.74,9.53;2,326.70,353.01,25.65,10.05;2,355.01,353.01,158.89,10.05;2,100.17,365.37,262.78,9.53;2,365.43,372.09,5.69,2.51;2,373.62,362.91,134.61,11.99"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: System overview. The timely-ordered documents d 1 , d 2 , . . . run through a boilerplate removal and stemming system in step 1. Only relevant sentences should pass this step. The documents are marked with timestamps u, u + 1, . . .. In step 2, a sentence s is either added to the existing clusters c 1 or c 2 or creates a new cluster depending on the similarity of s to c 1 and c 2 . Step 3 illustrates the publishing of a sentence. The sentence is added to the summary with time marker u and the cluster is set to published.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,314.79,624.40,199.11,86.40"><head></head><label></label><figDesc>3) Some values for different similarity measures are listed in Table1. We show values of the 2-gram and 3-gram Jaccard measure, two different cosine similarity values, and the value of the longest common subsequence comparator. All measures are Measure s(s 1 , s 2 ) s(s 1 , s 3 ) s(s 1 , s 4 )</figDesc><table coords="5,100.17,84.30,199.11,137.89"><row><cell>2-gram J</cell><cell>0.097</cell><cell>0.400</cell><cell>0.118</cell></row><row><cell>3-gram J</cell><cell>0.032</cell><cell>0.269</cell><cell>0.059</cell></row><row><cell>cosine 1</cell><cell>1.000</cell><cell>0.078</cell><cell>0.024</cell></row><row><cell>cosine 2</cell><cell>1.000</cell><cell>0.814</cell><cell>0.290</cell></row><row><cell>LCSC</cell><cell>0.613</cell><cell>0.821</cell><cell>0.490</cell></row><row><cell>mean</cell><cell>0.696</cell><cell>0.397</cell><cell>0.148</cell></row><row><cell cols="4">Table 1: Different similarity measures</cell></row><row><cell cols="4">implemented in the software DKPro Similarity 2 ,</cell></row><row><cell>described in</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,100.17,70.60,413.74,158.47"><head>Table 2 :</head><label>2</label><figDesc>Lower bound evaluation values for AIPHES runs 1-4, the 3 best non-AIPHES runs and average scores of all participating runs sorted descending by H, the main metric of the challenge. The colums nEG(S), C(S), and E[Latency</figDesc><table coords="9,126.05,70.60,361.98,112.30"><row><cell>TeamID AIPHES</cell><cell>RunID Run1</cell><cell>H 0.1083</cell><cell cols="3">unevaluated nEG(S) C(S) E[Latency] 58.41% 0.1576 0.2854 0.4776</cell></row><row><cell>AIPHES</cell><cell>Run2</cell><cell>0.1016</cell><cell>59.97%</cell><cell>0.1260 0.2982</cell><cell>0.4607</cell></row><row><cell cols="3">WaterlooClark UWCTSRun4 0.0853</cell><cell>-</cell><cell>0.1840 0.1710</cell><cell>0.3983</cell></row><row><cell>AIPHES</cell><cell>Run4</cell><cell>0.0781</cell><cell>63.34%</cell><cell>0.0897 0.4005</cell><cell>0.5679</cell></row><row><cell>AIPHES</cell><cell>Run3</cell><cell>0.0722</cell><cell>62.64%</cell><cell>0.0905 0.4164</cell><cell>0.5061</cell></row><row><cell>BJUT</cell><cell>DMSL2N2</cell><cell>0.0649</cell><cell>-</cell><cell>0.0645 0.6557</cell><cell>0.5606</cell></row><row><cell>uogTr</cell><cell cols="2">uogTrhEQR2 0.0639</cell><cell>-</cell><cell>0.0667 0.5459</cell><cell>0.5335</cell></row><row><cell>Mean</cell><cell>-</cell><cell>0.0472</cell><cell>-</cell><cell>0.0595 0.5627</cell><cell>0.5524</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,114.89,701.37,132.51,8.57"><p>http://www.lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,114.89,692.28,117.78,8.57;5,100.17,701.37,78.98,8.57"><p>https://dkpro.github.io/ dkpro-similarity</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="6,331.15,612.68,182.75,3.74;6,314.79,639.47,199.11,9.53;6,314.79,650.49,199.11,10.87;6,314.79,664.19,199.11,9.53;6,314.79,676.55,199.11,9.53;6,314.79,688.91,199.11,9.53;6,314.79,701.27,96.17,9.53"><p>TREC Temporal Summarization TrackWe participated with the previously described system, SeqCluSum, in the TREC 2015 Temporal Summarization track. In the following section we give detailed information about the challenge, describe the evaluation methodology and discuss our performance in the task.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="7,114.89,672.44,93.25,8.57"><p>http://duc.nist.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="7,114.89,682.36,112.88,8.57"><p>http://www.nist.gov/tac</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5" coords="7,114.89,692.28,152.14,10.14;7,100.17,701.37,138.32,8.57"><p>http://dcs.gla.ac.uk/ ˜richardm/ TREC-TS-2015RelOnly.aws.list</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6" coords="7,329.51,682.44,93.25,8.57"><p>https://twitter.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7" coords="7,329.51,693.38,184.39,7.84;7,314.79,702.47,52.02,7.84"><p>The timestampes equal to the number of seconds since January 1, 1970</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been supported by the <rs type="funder">German Research Foundation (DFG)</rs> as part of the <rs type="programName">Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES)</rs> under grant No. <rs type="grantNumber">GRK 1994/1</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_R5EMGKk">
					<idno type="grant-number">GRK 1994/1</idno>
					<orgName type="program" subtype="full">Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES)</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,100.17,228.12,199.11,8.71;10,110.12,238.12,189.16,8.71;10,110.12,245.87,189.16,10.95;10,110.12,255.87,189.16,10.85;10,110.12,265.87,189.16,10.95;10,110.12,278.11,189.16,8.71;10,110.12,288.11,65.64,8.71" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,110.12,238.12,189.16,8.71;10,110.12,248.12,50.06,8.71">Dkpro similarity: An open source framework for text similarity</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Bär</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,181.21,245.87,118.06,10.85;10,110.12,255.87,189.16,10.85;10,110.12,265.87,122.18,10.85">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08">2013. August</date>
			<biblScope unit="page" from="121" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,307.34,199.11,8.71;10,110.12,315.09,189.16,10.95;10,110.12,325.08,155.63,10.95" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,208.40,307.34,90.88,8.71;10,110.12,317.33,124.49,8.71">Machine-made index for technical literature: an experiment</title>
		<author>
			<persName coords=""><forename type="first">Phyllis</forename><forename type="middle">B</forename><surname>Baxendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,242.82,315.09,56.46,10.85;10,110.12,325.08,97.43,10.85">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="354" to="361" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,346.56,199.11,8.71;10,110.12,356.55,189.16,8.71;10,110.12,364.31,189.16,10.95;10,110.12,374.30,189.16,10.85;10,110.12,384.30,189.16,10.85;10,110.12,394.30,117.30,10.95" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,260.80,346.56,38.48,8.71;10,110.12,356.55,189.16,8.71;10,110.12,366.55,123.17,8.71">The use of mmr, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,254.25,364.31,45.02,10.85;10,110.12,374.30,189.16,10.85;10,110.12,384.30,189.16,10.85;10,110.12,394.30,29.79,10.85">Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 21st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,415.77,199.11,8.71;10,110.12,423.52,189.16,10.95;10,110.12,435.76,56.29,8.71" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,221.22,415.77,78.06,8.71;10,110.12,425.77,66.07,8.71">New methods in automatic extracting</title>
		<author>
			<persName coords=""><surname>Harold P Edmundson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,187.93,423.52,106.93,10.85">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="285" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,454.99,199.11,8.71;10,110.12,464.99,189.16,8.71;10,110.12,474.98,189.16,8.71;10,110.12,484.98,189.16,8.71;10,110.12,492.73,189.16,10.95;10,110.12,502.73,189.16,10.95;10,110.12,512.73,189.16,10.95;10,110.12,524.97,101.05,8.71" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,110.12,464.99,150.10,8.71">Updating users about time critical events</title>
		<author>
			<persName coords=""><forename type="first">Qi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elad</forename><surname>Yom-Tov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,264.45,492.73,34.83,10.85;10,110.12,502.73,93.54,10.85">Advances in Information Retrieval</title>
		<title level="s" coord="10,283.13,502.73,16.15,10.85;10,110.12,512.73,121.66,10.85">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Pavel</forename><surname>Serdyukov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pavel</forename><surname>Braslavski</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sergeio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaap</forename><surname>Kuznetsov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stefan</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Eugene</forename><surname>Rüger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ilya</forename><surname>Agichtein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emine</forename><surname>Segalovich</surname></persName>
		</editor>
		<editor>
			<persName><surname>Yilmaz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7814</biblScope>
			<biblScope unit="page" from="483" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,544.20,199.11,8.71;10,110.12,551.95,189.16,10.95;10,110.12,561.95,188.60,10.85" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,133.93,554.19,116.10,8.71">Summarizing disasters over time</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Kedzie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,266.38,551.95,32.90,10.85;10,110.12,561.95,184.61,10.85">Proceedings of the Twenty-Third Text REtrieval Conference</title>
		<meeting>the Twenty-Third Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,583.42,199.11,8.71;10,110.12,593.42,189.16,8.71;10,110.12,601.17,189.16,10.95;10,110.12,611.17,189.16,10.85;10,110.12,621.16,87.85,10.95" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,180.84,593.42,118.44,8.71;10,110.12,603.41,61.00,8.71">Boilerplate detection using shallow text features</title>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Kohlschütter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Fankhauser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Nejdl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,191.84,601.17,107.44,10.85;10,110.12,611.17,189.16,10.85;10,110.12,621.16,24.45,10.85">Proceedings of the 3rd ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 3rd ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,642.63,199.11,8.71;10,110.12,650.39,189.16,10.95;10,110.12,660.38,162.73,10.95" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,180.98,642.63,118.30,8.71;10,110.12,652.63,86.48,8.71">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName coords=""><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,213.66,650.39,85.62,10.85;10,110.12,660.38,108.25,10.85">Proceedings of the ACL Text Summarization Workshop</title>
		<meeting>the ACL Text Summarization Workshop</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.17,681.86,199.11,8.71;10,110.12,689.61,189.16,10.95;10,110.12,699.61,104.11,10.95" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,201.66,681.86,97.62,8.71;10,110.12,691.85,66.89,8.71">The automatic creation of literature abstracts</title>
		<author>
			<persName coords=""><forename type="first">Hans</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luhn</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,187.36,689.61,111.92,10.85;10,110.12,699.61,45.91,10.85">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,73.14,199.11,8.71;10,324.74,83.14,189.16,8.71;10,324.74,93.13,189.16,8.71;10,324.74,103.13,189.16,8.71;10,324.74,113.13,189.16,8.71;10,324.74,123.13,189.16,8.71;10,324.74,130.88,189.16,10.95;10,324.74,140.88,43.83,10.85" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,375.63,93.13,138.28,8.71;10,324.74,103.13,70.59,8.71;10,431.74,103.13,82.17,8.71;10,324.74,113.13,189.16,8.71;10,324.74,123.13,185.74,8.71">University of glasgow at trec 2014: Experiments with terrier in contextual suggestion, temporal summarisation and web tracks</title>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Romain</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M-Dyaa</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stuart</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nut</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,335.74,130.88,178.16,10.85;10,324.74,140.88,39.85,10.85">Proceedings of the Twenty-Third Text REtrieval Conference</title>
		<meeting>the Twenty-Third Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Iadh Ounis, Thibaut Thonet, and Bekir Taner Dinc ¸er</note>
</biblStruct>

<biblStruct coords="10,314.79,161.30,199.11,8.71;10,324.74,171.29,189.16,8.71;10,324.74,179.05,189.16,10.85;10,324.74,189.04,189.16,10.85;10,324.74,199.04,153.41,10.95" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,324.74,171.29,174.22,8.71">Generating summaries of multiple news articles</title>
		<author>
			<persName coords=""><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,324.74,179.05,189.16,10.85;10,324.74,189.04,189.16,10.85;10,324.74,199.04,74.98,10.85">Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 18th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="74" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,219.46,199.11,8.71;10,324.74,229.46,189.16,8.71;10,324.74,239.46,72.21,8.71" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,479.34,219.46,34.56,8.71;10,324.74,229.46,90.84,8.71">Textrank: Bringing order into texts</title>
		<author>
			<persName coords=""><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,257.63,199.11,8.71;10,324.74,267.63,189.16,8.71;10,324.74,277.63,189.16,8.71;10,324.74,285.38,189.16,10.95;10,324.74,295.38,98.44,10.95" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,430.02,267.63,83.88,8.71;10,324.74,277.63,189.16,8.71;10,324.74,287.62,8.46,8.71">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,353.39,285.38,160.52,10.85;10,324.74,295.38,26.28,10.85">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,315.80,199.11,8.71;10,324.74,323.55,189.16,10.95;10,324.74,333.55,142.74,10.95" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,492.70,315.80,21.20,8.71;10,324.74,325.79,76.16,8.71">Automatic summarization</title>
		<author>
			<persName coords=""><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,412.72,323.55,101.18,10.85;10,324.74,333.55,77.60,10.85">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="103" to="233" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,353.97,199.11,8.71;10,324.74,361.72,93.02,10.95" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,392.77,353.97,117.68,8.71">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,324.74,361.72,30.15,10.85">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,382.14,199.11,8.71;10,324.74,392.14,189.16,8.71;10,324.74,399.89,189.16,10.95;10,324.74,409.89,117.45,10.95" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,413.05,392.14,100.85,8.71;10,324.74,402.14,96.11,8.71">Centroid-based summarization of multiple documents</title>
		<author>
			<persName coords=""><forename type="first">Hongyan</forename><surname>Dragomir R Radev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Małgorzata</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Styś</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,428.30,399.89,85.60,10.85;10,324.74,409.89,54.38,10.85">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="919" to="938" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,430.31,199.11,8.71;10,324.74,438.06,189.16,10.95;10,324.74,450.30,96.69,8.71" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Sergios</forename><surname>Theodoridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Konstantinos</forename><surname>Koutroumbas</surname></persName>
		</author>
		<title level="m" coord="10,350.10,438.06,115.44,10.95">Pattern Recognition, chapter 12</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Ltd</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="633" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,468.48,199.11,8.71;10,324.74,478.48,189.16,8.71;10,324.74,486.23,189.16,10.95;10,324.74,498.47,113.48,8.71" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,348.95,478.48,164.95,8.71;10,324.74,488.47,70.95,8.71">Birch: an efficient data clustering method for very large databases</title>
		<author>
			<persName coords=""><forename type="first">Tian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raghu</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miron</forename><surname>Livny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,412.10,486.23,81.44,10.85">ACM SIGMOD Record</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="103" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,314.79,516.65,199.11,8.71;10,324.74,526.64,189.16,8.71;10,324.74,534.40,189.16,10.95;10,324.74,544.39,69.70,10.85" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,353.83,526.64,160.08,8.71;10,324.74,536.64,17.03,8.71">Bjut at trec 2014 temporal summarization track</title>
		<author>
			<persName coords=""><forename type="first">Yun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huayang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,360.03,534.40,153.87,10.85;10,324.74,544.39,65.71,10.85">Proceedings of the Twenty-Third Text REtrieval Conference</title>
		<meeting>the Twenty-Third Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
