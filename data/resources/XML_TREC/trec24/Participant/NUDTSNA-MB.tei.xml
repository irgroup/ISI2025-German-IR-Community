<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,173.21,94.06,265.58,18.21;1,138.86,111.06,334.28,18.21;1,158.97,128.06,294.06,18.21">NUDTSNA at TREC 2015 Microblog Track: A Live Retrieval System Framework for Social Network based on Semantic Expansion and Quality Model</title>
				<funder ref="#_CTdCxPh">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_5v7Y3W3">
					<orgName type="full">National Key fundamental Research and Development Program No</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.03,174.86,46.09,10.54"><forename type="first">Xiang</forename><surname>Zhu</surname></persName>
							<email>zhuxiang@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.08,174.86,66.03,10.54"><forename type="first">Jiuming</forename><surname>Huang</surname></persName>
							<email>jiuming.huang@qq.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.31,174.86,46.70,10.54"><forename type="first">Sheng</forename><surname>Zhu</surname></persName>
							<email>zhusheng002@126.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,336.98,174.86,48.46,10.54"><forename type="first">Ming</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,394.49,174.86,61.34,10.54"><forename type="first">Chenlu</forename><surname>Zhang</surname></persName>
							<email>zhangchenlu.com@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,145.03,187.73,54.63,10.54"><forename type="first">Li</forename><surname>Zhenzhen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.63,187.73,81.29,10.54"><forename type="first">Huang</forename><surname>Dongchuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.12,187.73,75.07,10.54"><forename type="first">Zhao</forename><surname>Chengliang</surname></persName>
							<email>zhaochengliang1991@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,382.89,187.73,42.76,10.54"><forename type="first">Aiping</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,433.68,187.73,33.30,10.54"><forename type="first">Yan</forename><surname>Jia</surname></persName>
							<email>jiayanjy@vip.sina.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">National University of Defense Technology Changsha</orgName>
								<address>
									<postCode>410073</postCode>
									<settlement>Hunan</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,173.21,94.06,265.58,18.21;1,138.86,111.06,334.28,18.21;1,158.97,128.06,294.06,18.21">NUDTSNA at TREC 2015 Microblog Track: A Live Retrieval System Framework for Social Network based on Semantic Expansion and Quality Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C6F23491FD7807C46CE353D655E8CA84</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describe our approaches to real-time filtering task in the TREC 2015 Microblog track, including push notifications on a mobile phone task and periodic email digest task. In the push notifications on a mobile phone task, we apply a recommendation framework with rank algorithm and dynamic threshold adjustment which utilizes both semantic content and quality of a tweet. External information extracted from Google search engine and word2vec model based on existing corpus are well incorporated to enhance the understanding of a tweet's or a profile's interest. In the email digest task, based on the candidate tweets retrieved from the first task, we calculate the score of a tweet considering semantic features and quality features, all the tweets classified into a topic are ranked by our key word bool logistic model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Information retrieval and recommendation in online social network has attracted increasing attention with development of social network services. To explore user's interests and boost retrieval and recommendation performance in real-time environment, TREC first introduced real-time task in 2011 <ref type="bibr" coords="1,90.05,553.89,10.62,9.58" target="#b0">[1]</ref>, which is addressing a real-time adhoc search task. The information a user wishes to see is represented by a query, systems should respond to a query by providing a list of relevant tweets ordered by time, starting from the query is issued. In other words, systems should feed users with the most recently and relevant tweets. The Microblog Track in 2015 is a real-time filtering task, the goal of the realtime filtering task is to explore technologies for monitoring a stream of social media posts with respect to a user's interest profile. Different from a typical ad hoc query, there is not an actual information need. Instead, the goal is for a system to push interesting content to a user. The notion of what's interesting is considered in two concrete task models, push notification on a mobile phone as Scenario A and periodic email digest as Scenario B. In Scenario A, content identified as interesting by a system based on user's interest profile might be shown to the user through mobile phone notification. Under that circumstances, such notifications should be triggered a relatively short time after the content is generated. In Scenario B, content calculated as interesting by a system based on user's interest profile might be aggregated into an email form that periodically sent to a user. In that case, a user could read a longer story about the contents.</p><p>In the Scenario A, we apply a recommendation framework with rank algorithm and dynamic threshold adjustment. Semantic features and quality features are extracted to achieve good retrieval and recommendation performance in social media. For semantic features, we utilize different retrieval models, such as TFIDF, BM25, key word bool logic model, to calculate the relevance score of a given profile and a tweet. In order to enhance the performance of semantic features and ease the shortcomings of bag-ofwords(BoW) model, we take advantage of word2vec model <ref type="bibr" coords="1,315.00,509.09,44.79,9.58">[2] [3] [4]</ref> based on existing corpus, such as Wikipedia, KnowItAll <ref type="bibr" coords="1,360.78,520.29,10.62,9.58" target="#b4">[5]</ref>, Freebase <ref type="bibr" coords="1,415.88,520.29,10.62,9.58" target="#b5">[6]</ref>, Probase <ref type="bibr" coords="1,467.10,520.29,10.62,9.58" target="#b6">[7]</ref>. In order to expand semantic features of profiles, we also use Google search engine to acquire external information. We use abstract text of retrieval results to better understand the user's interests. For the quality features, we utilize several quality features extract from a tweet, such as the user who post the tweet, the number of repost, the number of comment, the number of URL, the number of hashtags, the number of meaningful words, the length of a tweet, etc. Topics for TREC 2013 Microblog track <ref type="bibr" coords="1,385.32,621.09,11.66,9.58" target="#b7">[8]</ref> are used for model training. With the artificial labeled data, we obtain our quality model. Finally, we combine semantic features and quality features to evaluate a tweet comprehensively. According to dynamic threshold adjustment, a tweet is decided to push or not by our system.</p><p>The candidate tweets identified in Scenario A are used as the input source of the task in Scenario B. We calculate the score of a tweet considering semantic features and quality features. The semantic features are used to classified a tweet into a topic or drop it if it does not match any topics and the tweet classified into a topic will get a semantic score. Then quality features are utilized to evaluate the importance and authority of a tweet. By the quality model we obtained, we could get a quality score of a tweet. With a rank framework, the tweets classified into a same topic can be ranked. The top k tweets will be pushed to the user who are interested in as a digest.</p><p>The remainder of the paper is organized as follows, we first propose our approach for push notifications on a mobile phone task in Section 2. In Section 3, we describe our system for periodic email digest task in detail. Section 4 presents our experimental results and analysis. At last we conclude our paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Push Notification on a mobile phone Task</head><p>In this section, we first introduce our system architecture for push notifications on a mobile phone task. Then, the recommendation framework are demonstrated in detail. At last, all the components of the system are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">System Overview</head><p>It is a real-time job in this year's Microblog track that teams listen to the twitter stream <ref type="bibr" coords="2,197.28,394.08,11.66,9.58" target="#b8">[9]</ref> via official common API. In this section, we briefly discuss the architecture of our system, which is shown in Figure .1. As depicted in the figure, we can see our system mainly contains four components as follow, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Feature Extraction Component</head><p>Twitter stream we listen to is during the evaluation time according to the official<ref type="foot" coords="2,415.63,386.25,3.50,6.71" target="#foot_0">2</ref> , and it lasts ten days. After obtaining twitter stream, we adopt preprocessing and filtering to reduce the tweets we need to process. The preprocessing and filtering utilized on tweet stream are as follow,</p><p>• Non-English Filtering, we abandoned the non-English tweets by a language detector with infinity gram, named ldig <ref type="bibr" coords="2,422.73,461.68,15.33,9.58" target="#b9">[10]</ref>. This tool kit is a prototype for short message service with 99.1% accuracy for 17 languages <ref type="foot" coords="2,400.25,482.50,3.50,6.71" target="#foot_1">3</ref> . By the way, we also use a method based on encoding set of characters to process tweets consist of both English characters and non-English characters. We only keep the tweet in which English characters is the vast majority with a threshold value.</p><p>• Redundant Retweet Elimination, we only keep one tweet and eliminate other tweets retweeted the same tweet by the retweet id information according to official requirements.</p><p>Then semantic features and social attributes are extracted from tweets. For semantic features, we selected nouns and verbs in tweet text. So semantic features of a tweet is represented as Equation.1,</p><formula xml:id="formula_0" coords="2,397.90,643.69,160.10,16.42">T = {t 1 , t 2 , ..., t n }<label>(1)</label></formula><p>T represents a tweet and t i stands for a key word in tweet text. The social attributes are extracted from structured data in a tweet. A tweet is structured as JSON format, it is convenient to get social attributes we need, such as the user who post the tweet, the number of repost, the number of comment, the number of URL, the number of hashtags, the number of meaningful words, the length of a tweet, etc.</p><p>For profiles, we extract the nouns and verbs from title, desc and narr field. We use a key word bool logic model to express the information of a profile as follow,</p><formula xml:id="formula_1" coords="3,60.25,175.07,236.75,16.42">P = {tid : xxx, keyword : {0 : p 1 ||p 2 , 1 : p 3 &amp;&amp;p 4 }}<label>(2)</label></formula><p>P represents a profile, tid stands for a topic id of a profile. The keyword field contains two fields, 0 for words that unnecessary but could increase the semantic score and 1 for words that need to be included. Symbol || means or logic and symbol &amp;&amp; stands for and logic. So it means p 3 and p 4 need to be included and p 1 or p 2 is optional for the profile of which topic id is xxx. In this section, we extract the features and store them by format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature Representation Component</head><p>After extracting the semantic features, we need to represent those features in a proper format so that it is convenient to calculate the relevance between tweets and profiles. For profiles, the key words extract from the files offered by the official is not enough to improve the performance because short text retrieval suffers severely from vocabulary mismatch problem. Terms overlapping between profiles and tweets are relatively small. Semantic expansion methods can be leveraged to enhance the retrieval performance. In this section, we introduce several semantic expansion methods to boost the performance.</p><p>There are two kinds of semantic expansion methods, knowledge repository based and search engine based. For profiles, we use Google search engine API to expand information about the profiles. The title field is used as a query for searching and the abstract text information of top 50 retrieval results are collected for each profile. Abstract text is treated as a document, each document contains several terms. After gathering all the documents, we use TFIDF algorithm to calculate TFIDF value of each term for all the profiles. The top k terms of each profiles are added to key word table in Equation.2 to expand the information.</p><p>Due to the vocabulary mismatch problem, vector model is utilized to process the semantic features. The word2vec technique is used to vectorization for the key words and gensim 4 tool is used in this paper. The training corpus we used is acquired from wikipedia English corpus. A word2vec knowledge base are trained by gensim tool using wikipedia English corpus. Tweets and Profiles can be represented by word2vec knowledge base as follow, </p><formula xml:id="formula_2" coords="3,129.53,684.96,167.47,10.01">T vec = (t 1 , t 2 , ..., t n ) T<label>(3)</label></formula><p>In Equation.4, n is same as in Equation <ref type="formula" coords="3,476.42,160.98,4.36,9.58">.</ref>3 and m stands for the number of profiles. A row (p i1 , ..., p in ) in the matrix stands for the normalized center vector of a profile by all the key words. After the procedure above, the semantic features of tweets and profiles are well represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Candidate Generation Component</head><p>In this section, we classify tweets into the most relevant profile or drop it directly if it does not match any profile and generate candidates based on semantic features in section 2.  </p><p>Then, the profile which has the maximum value and the terms in tweet satisfy the bool logic in Equation.2 will be choose as candidate. The semantic score c i is recorded simultaneously. We used two kinds semantic score to evaluate the relevance between tweets and profiles as follow,</p><p>• TFIDF Score, which calculates the cosine similarity between a tweet and a profile in vector space model with TFIDF weight of terms. Vector space model is a model which represents a document as a vector. Tweets and profiles can be expressed as vectors,</p><formula xml:id="formula_5" coords="3,415.73,488.91,142.27,10.01">T = (t 1 , t 2 , ..., t n )<label>(6)</label></formula><formula xml:id="formula_6" coords="3,413.61,508.32,144.39,10.01">P = (p 1 , p 2 , ..., p n )<label>(7)</label></formula><p>The TFIDF method use term weight and cosine similarity metric to evaluate the relevance between a tweet and a profile. Cosine similarity metric is defined as follow,</p><formula xml:id="formula_7" coords="3,412.61,578.12,145.39,31.70">Sim = T • P || T || • || P ||<label>(8)</label></formula><p>• BM25 Score, which utilizes the Okapi BM25 weighting function to measure the semantic relevance between a tweet and a profile. Okapi BM25 model is a bag of words model that rank documents based on the query terms appearing in each documents. The similarity between a document and a query is defined as Equation.9, where D represents a document, Q stands for a query. f (q i , D) is q i 's term frequency in document D, |D| is the length of the document D in words, avgdl is the average document length of all the documents to process and k 1 and b is adjustable parameters.</p><formula xml:id="formula_8" coords="4,57.05,99.61,239.95,40.19">Sim = X qi2Q IDF (q i ) • f (q i , D) • (k 1 + 1) f (q i , D) + k 1 • (1 b + b • |D| avgdl )<label>(9)</label></formula><p>Social attributes extracted in section 2.1 are used to train quality model. We label a tweet with a score from 0 to 1 artificially based on its quality. If the tweet provides more information and written more elaborately, it will get higher quality score. The model we use is logistic regression model in machine learning tool weka 5 . Then, the semantic score and quality score are utilized to evaluate the relevance and quality of a tweet for a certain profile. Based on the assumption that users prefer those tweets related to the profile and popular in social media, we consider social attributes as follow,</p><p>• User follower Count(FollowerCnt), which represents the number of followers of the user who post the tweet. The user whose followers count is high would be a famous user in social media and will post high quality tweet with a large probability.</p><p>• User status Count(StatusCnt), which represents the number of status of the user who post the tweet. The status count indicates the vitality of a user in social media. A energetic user will post higher quality tweet than others.</p><p>• Retweet Count(RetweetCnt), which represents the times a tweet is retweeted. The larger retweet count is, the more popular a tweet is in social media.</p><p>• Retweet Level(RetweetLvl), we use logarithm to measure retweet count to retweet level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Collect Count(CollectCnt), which represents the number of people who like it. People can collect a tweet or star a tweet if the tweet is attractive.</p><p>• Word Count(WordCnt), which calculates the number of words in a tweet without stop words. Generally, informative and high quality tweets may be longer than others.</p><p>• Character Count(CharCnt), which calculates the number of characters of a tweet without stop words.</p><p>• Short Url Count(UrlCnt), which represents the number of short url count of a tweet. Informative tweet and news will give a short url at the end of a tweet in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Scoring and Pushing Component</head><p>By the semantic features and social attributes, we got two score, the semantic score c i in Equation.5 and the quality score q i . Both value of them are from 0 to 1. The finally score we measured for a tweet to a profile is as follow, where s i stands for the final score.</p><formula xml:id="formula_9" coords="4,153.57,689.52,139.26,16.42">s i = c i • q i (<label>10</label></formula><formula xml:id="formula_10" coords="4,292.84,689.60,4.17,9.58">)</formula><p>5. http://www.cs.waikato.ac.nz/ml/weka/ When a candidate is added to the pushing queue, it is ranked by the final score s i . If a tweet is relevant and important to a profile, it is necessary to push it to the users who are interested in. But there is a limit in Scenario A that ten tweets could be pushed to a profile at most in one day and the gain will decrease over time. So it is a constraint satisfaction problem we need to handle. We used a dynamic threshold adjustment to make sure there are enough tweets for a profile and each tweet with a high score during one day. With a recently historical data of the tweets for a profile, we can get the highest final score s max . We make a piecewise function for the threshold as Equation.11,</p><formula xml:id="formula_11" coords="4,338.01,205.59,219.99,35.80">threshold = ⇢ (0.9 d) • s max d &lt; 0.4 0.5 • s max d 0.4<label>(11)</label></formula><p>where d stands for decay value and d = c • floor(t/2). c is decay coefficient which we set to 0.05 in our system, t is the hour in a day from 0 to 24. If a tweet's final score s i exceed the threshold at that time, it will be pushed immediately.</p><p>As described above, the live push algorithm based on semantic features and social attributes are summarized in Algorithm.1, the program won't stop until R is full for each profile with 10 tweets or T s is exhausted in a day. threshold will automatically adjust over time. </p><formula xml:id="formula_12" coords="4,320.78,465.68,78.11,24.67">T i = pop(T s)<label>4: preprocess(t i ) 5:</label></formula><p>T vec = vectorization(t i )</p><p>6:</p><formula xml:id="formula_13" coords="4,320.78,492.44,88.22,42.70">C = P mat • T vec 7: c j = max(C) 8: s j = c j • q j 9:</formula><p>if s j &gt; threshold then 10:</p><formula xml:id="formula_14" coords="4,316.78,537.24,94.19,20.30">R j = R j [ ts i 11:</formula><p>end if 12: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Periodic Email Digest Task</head><p>In periodic email digest task, we need to collect a batch of up to top 100 interesting tweets for each profile during one day and deliver those information to the particular profile after the day ends. It is expected that the system will complete that mission in a relatively short amount of time. The system framework used in scenario B is same as in scenario A as Figure .1 , except threshold adjustment component. All the tweets are classified into one profile or drop it if it does not match any profile, then the candidates are ranked by final score s based on semantic features and social attributes.</p><p>To supply diverse information for a particular profile, we utilized two kinds of techniques to eliminate redundant tweets.</p><p>• Redundancy Removal based on Id, which utilized the tweet's id to identify a tweet. If a tweet is original, we record the id of original tweet. If it is a tweet reposting another tweet, we record the id of the reposted tweet's id. It could decrease the tweet reposting a popular tweet.</p><p>• Simhash <ref type="bibr" coords="5,126.20,201.57,16.66,9.58" target="#b10">[11]</ref>  <ref type="bibr" coords="5,147.30,201.57,15.33,9.58" target="#b11">[12]</ref>, which is a popular method to handle web page redundancy. It turns a document into a fingerprint, called simhash code. The closer hamming distances between two documents is, the more similar they are. The simhash code is calculated as follow,</p><formula xml:id="formula_15" coords="5,126.18,267.29,170.83,25.86">Sim code = sign( X n i=1 w i • c i )<label>(12)</label></formula><p>where w i is the weight of term i and c i is the hash code of term i, sign is symbol function that make positive to 1 and negative to 0 for every bit in the code.</p><p>Our daily retrieval algorithm can be described as Algorithm.2</p><p>Algorithm 2 Daily Retrieval Algorithm Require:</p><p>Twitter retrieval set end while 9: end for where T r is daily candidates for m profiles acquired in scenario A. For each profile, we iteratively get the most interesting tweet from candidate set and drop the redundant tweet. At last, we get the daily retrieval set Dr.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Result and Analysis</head><p>The evaluation of TREC 2015 Microblog track lasts 10 days from Monday, July 20, 2015, 00:00:00 UTC to July 29, 2015, 23:59:59 UTC. It consists of 225 interest profiles, which the participants will be responsible for tracking. During the evaluation time, participants will listen to tweet stream continuously and deal with every tweet. After the evaluation period, based on post hoc analysis, NIST will There are some metrics to evaluate the performance of a system. In scenario A, the first metric is expected latencydiscounted gain (ELG) from the temporal summarization track, the ELG score is depicted as Equation.13</p><formula xml:id="formula_16" coords="5,367.25,287.06,190.75,29.80">ELG = (1/ |T r|) • X i gain(T r i )<label>(13)</label></formula><p>where T r is the returned tweet sets, gain() is the score function for a tweet. Not interesting, spam/junk tweets receive a gain of 0, somewhat interesting tweets receive a gain of 0.5, very interesting tweets receive a gain of 1.0. In addition, a latency penalty is applied to all tweets, the latency penalty is computed as max (0, (100 delay) /100), where the delay is the time elapsed(in minutes, rounded down) between the tweet creation time and the putative time the tweet is delivered. The secondary metric is normalized cumulative gain (nCG), which is depicted as Equation.14</p><formula xml:id="formula_17" coords="5,373.80,436.99,180.04,29.80">nCG = (1/Z) • X i gain(T r i ) (<label>14</label></formula><formula xml:id="formula_18" coords="5,553.84,446.52,4.17,9.58">)</formula><p>where Z is the maximum possible gain (given the 10 tweets per day limit).</p><p>In scenario B, for each topic, the list of tweets returned per day will be treated as a ranked list and from this nD-CG@k will be computed. The score of a topic is the average of the nDCG@k scores across all days in the evaluation period. The score of the run is the average over all topics. The results our system get is listed in SN ACS LA and SN ACS LB are the results pair that using search engines to expand to generate profiles. The summaryA and summaryB is the average score of the highest score of every topics. Non-expand algorithm gets higher ELG and nCG, however expand algorithm gets higher nDCG.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we present our system architecture framework and algorithms for TREC 2015 Microblog track. In the push notification on a mobile phone task, we apply a recommendation framework with rank algorithm and dynamic threshold adjustment which utilize not only semantic features but also social attributes in social media. In periodic email digest task, we calculate the score of a tweet considering semantic features and quality features, then we rank the tweets take the redundance into consideration. Experimental results show our effectiveness and efficiency of our system in both tasks. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,367.01,286.98,190.99,9.58;3,315.00,298.18,165.20,9.58;3,378.55,337.53,18.34,2.51;3,399.66,307.70,6.64,9.33;3,399.66,325.23,6.64,9.33;3,399.66,331.61,6.64,9.33;3,412.83,322.52,8.28,3.26;3,415.97,326.12,2.50,17.55"><head></head><label></label><figDesc>3. Firstly semantic features are utilized based on Equation.3 and Equation.4 as follow,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,330.00,665.89,228.00,9.58;5,315.00,677.09,243.00,9.58;5,315.00,688.29,243.00,9.58;5,315.00,699.49,243.00,9.58;5,315.00,710.69,243.00,9.58;6,54.00,72.29,243.00,9.58;6,54.00,83.49,52.96,9.58"><head>Figure. 2</head><label>2</label><figDesc>is the ELG vs. nCG pair of participants' runs, Figure.3 is the ELG distribution in different topics, Figure.4 is the nCG distribution in different topics and Figure.5 is the nDCG distribution in different topics. We can see our system is close to the max results in summaryA and summaryB among most topics, our algorithm is verified to be effective and efficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,136.57,298.65,77.86,7.66;6,54.54,105.83,241.92,181.44"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. ELG vs. nCG</figDesc><graphic coords="6,54.54,105.83,241.92,181.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,362.39,269.48,148.22,7.66;6,315.54,71.22,241.91,186.88"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. nCG distribution in different topics</figDesc><graphic coords="6,315.54,71.22,241.91,186.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,315.54,71.22,241.91,241.66"><head></head><label></label><figDesc></figDesc><graphic coords="2,315.54,71.22,241.91,241.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,62.00,72.29,496.00,647.42"><head></head><label></label><figDesc>In Equation.3, n is the dimensions in gensim tool, generally set to 200 or 400. The profiles can be demonstrated as a matrix as follow,</figDesc><table coords="3,370.21,104.54,132.58,55.57"><row><cell>P mat =</cell><cell>2 6 4</cell><cell cols="2">p</cell><cell>11 . . .</cell><cell>• • • . . .</cell><cell cols="2">p</cell><cell>1n . . .</cell><cell>3 7 5</cell></row><row><cell></cell><cell></cell><cell>p</cell><cell cols="2">m1</cell><cell cols="2">• • • p</cell><cell cols="2">mn</cell></row></table><note coords="3,62.00,712.04,148.68,7.66"><p>4. http://radimrehurek.com/gensim/index.html</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,315.00,73.64,243.00,166.65"><head>TABLE 1 .</head><label>1</label><figDesc>RESULTS IN SCENARIO A</figDesc><table coords="5,315.00,90.54,243.00,149.75"><row><cell>SNACSA</cell><cell cols="2">ELG 0.3086 0.3349 nCG</cell></row><row><cell>SNACS LA</cell><cell cols="2">0.2863 0.2974</cell></row><row><cell>summaryA</cell><cell cols="2">0.4623 0.4846</cell></row><row><cell cols="3">TABLE 2. RESULTS IN SCENARIO B</cell></row><row><cell></cell><cell></cell><cell>nDCG</cell></row><row><cell cols="2">SNACS SNACS LB</cell><cell>0.3345 0.3670</cell></row><row><cell cols="2">summaryB</cell><cell>0.5014</cell></row><row><cell cols="3">select a set of approximately 50 topics that will actually be</cell></row><row><cell>assessed.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,315.00,553.26,243.00,43.49"><head></head><label></label><figDesc>Table.1 and Table.2, SN ACSA and SN ACS are the results pair that only use the words in tweets to generate profiles in Equation.2.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,331.80,693.14,203.92,7.66;2,315.00,702.14,34.66,7.66"><p>https://github.com/lintool/twitter-tools/wiki/TREC-2015-Track-Guidelines</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,323.00,712.04,102.94,7.66"><p>3. https://github.com/shuyo/ldig</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Sponsored by <rs type="funder">National Key fundamental Research and Development Program No</rs>.<rs type="grantNumber">2013CB329601</rs> and <rs type="funder">National Natural Science Foundation of China</rs> No.<rs type="grantNumber">61372191</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5v7Y3W3">
					<idno type="grant-number">2013CB329601</idno>
				</org>
				<org type="funding" xml:id="_CTdCxPh">
					<idno type="grant-number">61372191</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,333.33,620.39,224.67,7.66;6,333.33,629.39,224.67,7.66;6,333.33,638.39,105.87,7.66" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,490.24,620.39,67.76,7.66;6,333.33,629.39,70.83,7.66">Overview of the trec-2011 microblog track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,423.33,629.46,134.66,7.51;6,333.33,638.46,81.63,7.51">Proceeddings of the 20th Text REtrieval Conference (TREC 2011)</title>
		<meeting>eeddings of the 20th Text REtrieval Conference (TREC 2011)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,333.33,652.72,224.67,7.66;6,333.33,661.72,224.67,7.66;6,333.33,670.72,65.24,7.66" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,502.95,652.72,55.05,7.66;6,333.33,661.72,148.62,7.66">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>arX- iv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,333.33,685.04,224.67,7.66;6,333.33,694.04,224.67,7.66;6,333.33,703.04,224.67,7.66;6,333.33,712.04,71.60,7.66" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,336.61,694.04,221.39,7.66;6,333.33,703.04,30.87,7.66">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,383.40,703.11,171.29,7.51">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,73.64,224.67,7.66;7,72.33,82.64,224.67,7.66;7,72.33,91.64,30.00,7.66" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,213.20,73.64,83.80,7.66;7,72.33,82.64,126.99,7.66">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,218.90,82.71,38.72,7.51">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,105.14,224.67,7.66;7,72.33,114.14,224.67,7.66;7,72.33,123.14,224.67,7.66;7,72.33,132.14,224.67,7.66;7,72.33,141.14,63.60,7.66" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,243.61,114.14,53.39,7.66;7,72.33,123.14,167.20,7.66">Web-scale information extraction in knowitall:(preliminary results)</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-M</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,257.37,123.21,39.63,7.51;7,72.33,132.21,190.31,7.51">Proceedings of the 13th international conference on World Wide Web</title>
		<meeting>the 13th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="100" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,154.64,224.67,7.66;7,72.33,163.64,224.67,7.66;7,72.33,172.64,224.67,7.66;7,72.33,181.64,220.36,7.66" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,279.97,154.64,17.03,7.66;7,72.33,163.64,224.67,7.66;7,72.33,172.64,32.64,7.66">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,122.91,172.71,174.10,7.51;7,72.33,181.71,114.81,7.51">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,195.14,224.67,7.66;7,72.33,204.14,224.67,7.66;7,72.33,213.14,224.68,7.66;7,72.33,222.14,63.60,7.66" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,217.13,195.14,79.87,7.66;7,72.33,204.14,105.70,7.66">Probase: A probabilistic taxonomy for text understanding</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,196.88,204.21,100.12,7.51;7,72.33,213.21,194.36,7.51">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="481" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,235.64,224.67,7.66;7,72.33,244.64,138.50,7.66" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,149.21,235.64,141.80,7.66">Overview of the trec-2013 microblog track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,81.35,244.71,68.70,7.51">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,258.14,224.67,7.66;7,72.33,267.14,134.53,7.66" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,155.71,258.14,141.29,7.66;7,72.33,267.14,131.09,7.66">Do multiple listeners to the public twitter sample stream receive the same tweets?</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,280.64,224.67,7.66;7,72.33,289.64,224.67,7.66;7,72.33,298.64,96.94,7.66" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,198.51,280.64,98.49,7.66;7,72.33,289.64,224.67,7.66;7,72.33,298.64,91.57,7.66">Pkuicst at trec 2014 microblog track: Feature extraction for effective microblog search and adaptive clustering algorithms for ttg</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L F F R</forename><surname>Qiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">F J</forename><surname>Yang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,312.14,224.67,7.66;7,72.33,321.14,224.67,7.66;7,72.33,330.14,178.90,7.66" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,214.55,312.14,82.45,7.66;7,72.33,321.14,55.24,7.66">Detecting near-duplicates for web crawling</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Manku</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Das</forename><surname>Sarma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,146.67,321.21,150.33,7.51;7,72.33,330.21,80.73,7.51">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.33,343.64,224.67,7.66;7,72.33,352.64,224.68,7.66;7,72.33,361.64,175.37,7.66" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,129.58,343.64,167.42,7.66;7,72.33,352.64,26.75,7.66">Similarity estimation techniques from rounding algorithms</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Charikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,116.40,352.71,180.61,7.51;7,72.33,361.71,77.49,7.51">Proceedings of the thiry-fourth annual ACM symposium on Theory of computing</title>
		<meeting>the thiry-fourth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="380" to="388" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
