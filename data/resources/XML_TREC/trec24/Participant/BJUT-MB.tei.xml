<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,186.12,93.54,239.77,18.66;1,173.90,109.17,264.20,18.66">BJUT at TREC 2015 Microblog Track: Real-Time Filtering Using Knowledge Base</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.85,138.00,60.13,15.55"><forename type="first">Luyang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<postCode>100124</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Beijing Key Laboratory of Trusted Computing</orgName>
								<address>
									<postCode>100124</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">National Engineering Laboratory for CTISCP</orgName>
								<address>
									<postCode>100124</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,307.87,138.00,55.78,15.55"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
							<email>⇤yangzhen@bjut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<postCode>100124</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Beijing Key Laboratory of Trusted Computing</orgName>
								<address>
									<postCode>100124</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">National Engineering Laboratory for CTISCP</orgName>
								<address>
									<postCode>100124</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,186.12,93.54,239.77,18.66;1,173.90,109.17,264.20,18.66">BJUT at TREC 2015 Microblog Track: Real-Time Filtering Using Knowledge Base</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C88B6E1299736E3B929FA0F26F73C094</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our efforts for TREC 2015 Microblog track. We applied the classic retrieval model combined with the external knowledge base, i.e., Wikipedia, for query expansion. Besides, we introduced the knowledge acquisition, query expansion, and retrieval model as well. Experimental results show the proposed approach is better than classical method in microblog real-time filtering with the usage of external knowledge base.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>As with the microblog such as Twitter rapidly getting popular, the information that microblog covered is rather numerous than expected. In addition, owing to the microblogs real-time property as well as its vast spreading speed, microblog have been a crucial way for users to get information through the Internet. However, faced with such colossal information, microblog search engine that designate a specific topic with respect to the users interest is the important method to satisfy users need. This years TREC 2015 is talking about the problem arose above.</p><p>TREC 2015 Microblog Track (abbreviate for MB Track) poses two involved scenarios. What we choose to take is the Scenario B: Periodic email digest. Unlike the MB Track years pasted, 2015 MB Track using the real-time tweeter data flow to dynamically evaluate the system. Whats more, this Track require participants to return the interesting microblogs with respect to the topic title and topic description that user given. The total number of the topics is 250. And each topic need to return up to 100 relevant microblogs <ref type="bibr" coords="1,101.32,567.78,24.90,9.54;1,128.71,574.50,19.92,2.71;1,151.13,567.78,21.44,9.54" target="#b1">(Duan et al. 2010)</ref>.</p><p>First, we claw the data of Wikipedia which is thought to be relevant of each topic. Then, according to the topic information and clawed data, combining the data we get to regenerate the expanded query. Last but not the least, we remove the duplicated microblog and resort it according to its final score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SYSTEM DESCRIPTION</head><p>During this year's MB TREC evaluation, we filtered about 10 days' tweets. Final corpus consists of 2Gbytes tweets after reducing the junk and other irrelevant tweets. Then the final result is about 210686 tweets in total 250 topics after reducing the duplicated tweets.</p><p>Our system consists of 3 blocks in all: data receive and pre-handle, query expansion, result generate and re-process.</p><p>• Tweeter data flow pre-process</p><p>According to the TREC official guideline and instruction, we setup a server to receive and process all the tweeter stream that evaluation needed. Note that all non-English language tweeter are supposed to be junk, thus we reduce that once we detect a non-English Unicode character in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Corpus Generation</head><p>When acquired the data of tweeter flow which have been pre-processed, we use the Lemur to build the corpus. We collect all day's data to generate the corpus of that day.</p><p>• User interest profile analysis TREC official user interest profile contains three main fields with the "title" containing a few keywords, the "description" containing a one-sentence statement of the information need, and the "narrative", a paragraph-length description of the information need. We take topic title as the searching term. In addition, we take it as the key words which would be searched in Wikipedia to get the relevant information about the topic. However, given the features of Wikipedia, we simply choose limited result of retrieval through Wikipedia. At last, we take both topic description as well as the retrieval result of Wikipedia to generate the new query which would be used in the topic retrieval(Baeza-Yates et al. 1999).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Expansion through Wikipedia</head><p>Wikipedia which is known to all is a numerous, widespread authorized extern knowledgebase. Wikipedia is currently the world's largest knowledge resource, featuring more than three million articles. It is actively updated by tens of thousands volunteers. Each Wikipedia article describes a single topic, with a succinct, well-formed title. To get the relevant information we need, we take the topic title as the keywords to search in Wikipedia through the API. Noted that, to avoid duplication, pages that describe the same thing would be redirected to the same page, which would lead to the inadequate retrieval result. Thus, when receiving the results, we simply take no less than top 5 pages as the relevant material that we need. Accordingly, each topic has a corresponding set of extern relevant information.</p><p>• Generate the new query When acquired the relevant information set we noted above, we will take it to generate the synonym list. Then select several relevant words to regenerate the new query.</p><p>According to the new query, we use it to generate Lemur Query Parameter File. Noted that we simply select the unigram Language Model with Dirichlet smoothing method as our final retrieval model(Joachims 2002)(Zhai and Lafferty 2002).</p><p>• Apply query to the corpus and result process When all the topic's Lemur Query parameter files were successfully generated, we would use it to search among the Corpus Index built before. To ensure the adequate amount of result when reduced the redundancy, the amount of retrieval result is restricted to 500 tweets. Then, these tweets would be sorted decently. Then reduce the reduplicated tweets which have similar content as well as the final score. Eventually, all result would be reformed to the format that TREC official required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Short Texts Implicit Retrieval Framework</head><p>Some real-time extern knowledge such as Baidu, Google etc, have some defects when taken as the knowledge base.</p><p>They cover too many irrelevant information such as ads or sponsors page which would import too many noise. Wikipedia, known as most famous, widespread, most authorized online encyclopedia, is a proper choose for our query expansion. Whats more, it provide convenient and fully function API for the programmer to use. Therefore, we take it as our choice.</p><p>As we described above, we assume that the each topic of interest profile Q(T, N ) include two parts: topic title T , topic description N. Extern relevant information M = [m ( i, j)] we acquire according to the specific topic is retrieved back through Wikipedia API using topic title T . Then we generate the relevant index term-document matrix S. Noted that we simply use T F as the basic element of matrix. Whats more, all terms covered in the matrix would be filtered. After that, we use S to generate the correlation matrix which aims to find the synonym in the extern relevant information set. The correlation matrix C generated as follow:</p><formula xml:id="formula_0" coords="2,387.56,187.91,92.41,50.54">M = 2 4 m 1,1 • • • m 1,d . . . . . . . . . m k,1 • • • m k,d<label>3 5</label></formula><p>(1)</p><formula xml:id="formula_1" coords="2,408.21,242.75,149.79,18.32">C = M ⇥ M T<label>(2)</label></formula><p>Then normalize C = [c ( i, j)]:</p><formula xml:id="formula_2" coords="2,415.16,277.46,142.84,13.17">C N = [c 0 i,j ]<label>(3)</label></formula><formula xml:id="formula_3" coords="2,391.56,310.33,166.44,23.45">c 0 i,j = c i,j c i,i + c j,j c i,j<label>(4)</label></formula><p>Then we could generate the synonym list now. Noted that d is number of relevant pages retrieved through Wikipedia. We sorted the index list according to its score in matrix C N . Then select top |d| index terms as the expansion terms which would combine original topic title to generate new query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result and Analysis</head><p>After 10 days evaluation, we filtered 210686 tweets in total. We submitted a run with its id: BJUTllyQE in this year's TREC MB Track. Its average nDCG is 0.1334.</p><p>That is what concerned after analyzing the submitted result. After analysis the result of our submission, we found that our query expansion method acts quite effectively and efficiently when concerning some topics about existed concept or events has happened long before. Some topics' nDCG even meet the official max value. However, we also found that Wiki has some defects when acting as the extern knowledge base faced with real-time filtering task. First, terms in Wikipedia were manually created through some experienced editors. Thanks to Wikipedia's great restriction towards every terms, lack of real-time would neutralize the Query expansion or even import some noises when filtering some topics about real-time events or concept. Secondly, retrieval results of Wikipedia remained quite too few to satisfy our query expansion. Thus, makes it difficult to add extra extern information to the result. Perhaps, combining some real-time knowledge base or search engines would somewhat raise the performance of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>In this paper, we present our systems for TREC 2015 Microblog track Real-Time Filtering Task. In the Real-Time Filtering Task, we applied a query expansion framework utilized extern knowledge base Wikipedia. The method is common and simple, and it achieve relative good performance in some topics, while in some other topics it turned out to be relatively poor performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,377.93,475.92,121.64,12.96;1,344.37,216.00,188.77,252.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System framework.</figDesc><graphic coords="1,344.37,216.00,188.77,252.00" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,54.00,125.80,202.22,9.54;3,260.96,132.53,31.54,2.71;3,54.00,143.27,86.51,2.71;3,143.69,136.54,148.81,9.54;3,54.00,147.28,22.42,9.54" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,260.96,132.53,31.54,2.71;3,54.00,143.27,82.88,2.71">Modern information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>ACM press</publisher>
			<biblScope unit="volume">463</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,54.00,160.73,238.50,9.54;3,54.00,171.47,238.50,9.54;3,54.00,182.21,39.26,9.54;3,95.49,188.94,197.01,2.71;3,54.00,199.68,122.15,2.71;3,179.24,192.95,113.26,9.54;3,54.00,203.69,147.51,9.54;3,54.00,217.14,81.25,9.54;3,150.88,217.14,141.63,9.54;3,54.00,227.88,96.29,9.54;3,155.75,234.61,136.76,2.71;3,54.00,245.35,238.50,2.71;3,54.00,256.09,67.81,2.71;3,124.30,249.36,114.72,9.54;3,54.00,262.81,238.50,9.54;3,54.00,273.55,141.74,9.54;3,198.18,280.28,94.32,2.71;3,54.00,291.02,238.50,2.71;3,54.00,301.76,177.69,2.71;3,237.06,295.03,55.44,9.54;3,54.00,305.77,49.69,9.54" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,117.35,171.47,175.15,9.54;3,54.00,182.21,23.95,9.54;3,54.00,217.14,81.25,9.54;3,150.88,217.14,141.63,9.54;3,54.00,227.88,71.09,9.54;3,211.76,262.81,80.75,9.54;3,54.00,273.55,126.43,9.54">Thorsten Joachims. Optimizing search engines using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,95.49,188.94,197.01,2.71;3,54.00,199.68,118.30,2.71;3,155.75,234.61,136.76,2.71;3,54.00,245.35,238.50,2.71;3,54.00,256.09,63.50,2.71;3,198.18,280.28,94.32,2.71;3,54.00,291.02,238.50,2.71;3,54.00,301.76,174.06,2.71">Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<editor>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</editor>
		<meeting>the 25th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2010. 2002. 2002</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
	<note>Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
