<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.42,151.67,295.74,12.54;1,279.41,169.07,36.70,12.54">HIT-WI at TREC 2015 Clinical Decision Support Track</title>
				<funder>
					<orgName type="full">TREC 2015 Clinical Decision Support</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,173.54,208.02,52.36,8.96"><forename type="first">Jingchi</forename><surname>Jiang</surname></persName>
							<email>jiangjingchi0118@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,234.29,208.02,34.12,8.96"><forename type="first">Yi</forename><surname>Guan</surname></persName>
							<email>guanyi@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,279.89,208.02,24.18,8.96"><forename type="first">Jia</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.27,208.02,44.04,8.96"><forename type="first">Chao</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.73,208.02,53.64,8.96"><forename type="first">Jinfeng</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin University of Science and Technology</orgName>
								<address>
									<postCode>150080</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.42,151.67,295.74,12.54;1,279.41,169.07,36.70,12.54">HIT-WI at TREC 2015 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DA38B10F28B91D2324CD31374FEE0EF7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC 2015 Clinical Decision Support track is composed of two subtasks, task A and task B. Similar to 2014 <ref type="bibr" coords="1,317.59,335.91,7.03,5.40" target="#b0">[1]</ref> , the participants need to answer 30 clinical questions from patient cases for each task. According to the three types of clinical question: diagnosis, test and treatment, these tasks are to retrieve relevant literatures for helping clinicians to make clinical decision.</p><p>This paper describes how the clinical decision support system is developed for completing the task A and B by the HIT-WI group. For the automatic runs, some classical retrieval strategies are adopted, including query extraction, query expansion and the process of retrieval. Moreover, we propose two novel reranking methods: the one uses SVM model with 10-dimensional feature to rerank the retrieved list, and the other is based on word co-occurrence network.</p><p>The 178 runs are submitted from 36 different groups. Our evaluation results show that 1) The Indri performs better than Lucene's for artificially-constructed queries. 2) Compare to the basic retrieval method, two re-ranking methods show the effectiveness in some topics. 3) Our results are higher than the median scores in most topics of task B. Furthermore, the system achieves the best scores for topics: #11 and #12.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a hot spot of academic frontier, Clinical decision support (CDS) provides clinicians and health professionals with knowledge and personalized information at appropriate times, to enhance the health level of patients. In making clinical decisions, clinicians often review the medical literature to further ensure the reliability for diagnosis and treatment. Medical literature can answer the three most common generic clinical questions faced by clinicians everyday <ref type="bibr" coords="1,366.91,613.91,7.56,5.83" target="#b1">[2]</ref> :"what is the patient's diagnosis?", "what tests should the patient receive?", "how should the patient be treated?". However, the problem of retrieving the relevant literatures can be timeconsuming and difficult under the circumstance of massive literatures.</p><p>Similar to the goal of 2014, the TREC 2015 Clinical Decision Support (CDS) track is designed to retrieve relevant medical articles for answering generic clinical questions, according to actual patient records <ref type="bibr" coords="1,308.45,682.91,7.56,5.83" target="#b2">[3]</ref> . A patient record typically describes a challenging medical case, and mainly contains two sections: description which describes patients' condition in detail and summary, which synthesizes meaningful information from description based on the experience of doctors. The corpus for the retrieval task is the Open Access Subset of PubMed Central (PMC) on January 21, 2014, which contains a total of 733,138 articles <ref type="bibr" coords="2,316.97,194.55,7.58,5.83" target="#b3">[4]</ref> .</p><p>In this paper, traditional retrieval techniques are adopted <ref type="bibr" coords="2,381.91,205.95,7.56,5.83" target="#b4">[5]</ref> , including medical terms extraction, query expansion and literature retrieval. Then, we propose two reranking methods to enhance the relevance of retrieved results.</p><p>The rest of this paper is arranged as follows. In Sec. 2, we discuss the materials and methods in detail, and also focus on the construction of re-ranking models. Moreover, we conduct the experiments to testify the effectiveness of clinical decision system in Sec. 3. In Sec. 4, we conclude this paper and discuss the directions for further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query construction</head><p>The query construction consists of query extraction, query expansion and query set generation. In the process of query's auto-construction, Metamap (a tool to map biomedical text to the UMLS Metathesaurus) is used for extracting the medical concepts from the summary section of patient records. In addition, some rules are established, according to whether the concept's semantic type belongs to what we summarize, such as Neoplastic Process, Sign or Symptom et al. Then we regard these filtered medical concepts as the basic query set.</p><p>However, the basic queries which are only extracted from the given patient record, cannot completely retrieve relevant literatures for answering the clinical questions. Therefore, we adopt the UMLS Metathesaurus to expand the concepts. In the process of expanding, we avoid the same words presented in query as much as possible and add the type words (diagnosis, test and treatment) for improving the accuracy.</p><p>After a series of steps, the query sets are generated automatically in a different formats, to fit the different search engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2</head><p>The process of retrieval</p><p>The PubMed Central articles are published in the form of XML, one file per article. Therefore, an XML parser is employed to extract PMC ID, keyword, title, abstract, body and reference from each article.</p><p>In order to compare the retrieval performance of search engine, we adopt two kinds of toolkits: Intri and Apache Lucene, respectively. The former provides state-of-theart text search and a rich structured query language. The latter is based on language model approach with Jelinek-Mercer smoothing for retrieving articles.</p><p>We start to retrieve the relevant literatures, including query extraction and expansion, building index. Each participant can only submit 1000 literatures at most for each topic. Therefore, we select the top 1000 literatures as the final result, which is ranked as the given score by the search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.3</head><p>Re-ranking model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Re-ranking based on machine learning</head><p>According to the relevant results of TREC 2014, it becomes possible for us to use machine learning method to re-rank the retrieved list. To judge whether a literature is relevant to the clinical decision, we think empirically that the appearing position of a query is a significant feature. Because, it is reasonable that the query appears in title of literature is more important than the same query appears in body. In addition, the position of type words, such as diagnosis, test or treatment, is also a strong feature to judge the relevance.</p><p>Due to a literature contains five fields, including title, abstract, keywords, body and reference, we extract the query feature and the type word feature from each fields, respectively. Therefore, a total of 10 features will be extracted for a certain literature.</p><p>We construct queries from TREC 2014 topics and obtain the retrieved results. Every retrieved literature is labeled as 0, 1 and 2, which represent the non-relevance, possible relevance and completely relevance. However, considering the quantity of relevant literatures is far less than the quantity of irrelevant ones, we regard the label 1 and 2 as relevant. Using the SVM classifier with a linear kernel to classify relevant literatures from irrelevant ones, the SVM model is trained. Then this model is applied to retrieved results of TREC 2015. Every result would be labeled either 1 if relevant, or 0 if not relevant. Adding this score with a 0.25 gain to the original indri score, we obtain the new score, which is used for our re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Re-ranking based on co-occurrence network</head><p>In order to improve the performance of relevance ranking, we propose a novel method to re-rank the retrieved results. The idea of this method is based on cooccurrence words. We build a co-occurrence network to mine the potential literatures. For improving the recall rate, the re-ranking formula is constructed based on some network features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.1">The construction of co-occurrence network</head><p>In the process of analysis for the TREC 2014, we find that these relevant literatures have a lot of co-occurrence words. We assume that these co-occurrence words can reveal the relevance of literature. In order to validate this assumption, an intuitive cooccurrence network based on 1000 retrieved literatures is needed. Firstly, we empirically extract the co-occurrence words from literature by the top level of MeSH hierarchy <ref type="bibr" coords="3,141.50,623.15,7.56,5.83" target="#b5">[6]</ref> :</p><p>-Diagnosis: B03, B04, C -Test: E01 -Treatment: D02, D04, D06, D26, D27, E02, E04 When a common medical word from MeSH appears on two literatures, an edge will be created to connect them. Moreover, the edge weight gradually grow, along with the number of common words increasing. After 1000 retrieved literatures are iterated, a co-occurrence network is built, which is composed of the literature as the node and the co-occurrence medical word as the edge. The topology of the cooccurrence network is shown in Fig. <ref type="figure" coords="4,272.50,186.18,3.86,8.96" target="#fig_0">1</ref>.</p><p>Fig. <ref type="figure" coords="4,223.47,399.21,4.98,8.96" target="#fig_0">1</ref> The topology of co-occurrence network As shown in Fig. <ref type="figure" coords="4,205.48,411.23,3.89,8.96" target="#fig_0">1</ref>, the network consists of several communities in different color. The features of the co-occurrence network include the followings: 1. The literature nodes within the same community are strongly attached to each other. 2. Instead, the nodes from different communities represent a "weaker" relation. Through observing and analyzing the judgment file of TREC 2014, we find that the most of relevant literature locate the inside of community, while the discrete nodes always play the nonrelevance or low relevance roles for each topic. Furthermore, we can summarize that every community have dissimilar emphases for the given patient record. The subject of some communities are appropriate to answer the clinical question, while the literatures from the other communities are irrelevant. Therefore, how to choose the appropriate communities is an important work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.2">Mining potential literatures</head><p>Because the automatic extraction and expansion have its limitations and uncertainties, lead to the incomplete and non-credibility of query set. Therefore, some relevant literatures might be missed except 1000 retrieved literatures. To solve this problem, we propose a method based on the co-occurrence network, to mining potential relevant literatures from the rest of the corpus. This method uses the indicator of clustering coefficient to determine whether a literature is associated with the topic.</p><p>Node coefficient is defined as the proportion of connections among its neighbors which are actually realized compared with the number of all possible connections. The parameter k is defined as the number of the common terms from MeSH between literature 𝑖 and community ζ. T(i) represents the number of all possible connections among the k vertices.</p><formula xml:id="formula_0" coords="5,267.87,185.50,202.83,10.24">( ) ( 1) / 2 T i k k  <label>(1)</label></formula><p>E(i) represents the actual number of edges among the k vertices. c(i) is the clustering coefficient of node i and can be computed as follows.</p><p>( )</p><formula xml:id="formula_1" coords="5,268.41,245.26,202.28,10.27">( ) / ( ) c i E i T i  (2)</formula><p>Community coefficient is defined as the mean of the entire node coefficient within the community. c(ζ) is defined as the clustering coefficient of community ζ :</p><formula xml:id="formula_2" coords="5,271.70,307.62,198.99,27.50">1 () () n i ci c n    <label>(3)</label></formula><p>If the node coefficient is greater than the community coefficient of a specific community, we can conclude that this node has similarity to this community, and put the node as a potential literature to the existing community. The bigger node coefficient means that the higher connectivity with the community. Along with the continuous increase of the potential literatures, some new MeSH terms will be found from the co-occurrence network, which can describe the topic better. After all of the literatures are traversed, a richer co-occurrence network is built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.3">Re-ranking calculation</head><p>Based on the richer co-occurrence network, we need to re-rank all the nodes. To calculate the score of re-ranking, some measures should be introduced, including the measure of node importance and the medical terms density of community where the node locate.</p><p>Because the potential literatures are different than the retrieved literatures which have a relevance score by search engine. Therefore, a computational method for calculating the relevance score of potential literature is also proposed, which is defined as follows:</p><formula xml:id="formula_3" coords="5,186.37,581.40,284.33,31.47">() () ( ) * ( ) / j Rscore i i RetrievedSet Score i NC i Rscore j n i PotentialSet          (4)</formula><p>Rscore(i) represents the relevance score of retrieved literature by search engine. NC(i) is the node coefficient of literature i. j is defined as a literature within retrieved set, while is connected to the literature i. n is the number of literature j.</p><p>The terms density of community is defined as the ratio of the number of terms to the number of relationships. In addition, we adopt the value of pagerank to regard as the measure of node importance. After the preparation of the theory, we propose the formula of re-ranking model:</p><formula xml:id="formula_4" coords="6,214.55,185.61,256.14,10.84">( ) ( ) ( ) i ReRankScore i CD PR i Score i        (5)</formula><p>CDi represents the density of community where is the literature i location. PR(i) is the importance of literature i. 𝛼 and 𝛽 are both the weight parameters for regulating the factor proportion between the co-occurrence network and the search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Clinical decision support system design</head><p>Our clinical decision support system consists of four main modules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparing Indri with Lucene</head><p>In the TREC 2015 Clinical Decision Support track, the task consists of two parts: the task A and task B which adds the "diagnosis" section from the last twenty topics. For the task A, we submit the retrieved results including artificial Indri result, automatic Indri result and automatic Indri result with the re-ranking model based on machine learning. Similar with task A, the artificial list of Lucene, automatic list of Indri and the automatic result with the co-occurrence network are submitted for the task B.</p><p>Because the topics of diagnosis type have exactly the same contents and structures in task A and B. So we can compare the result of artificial Indri and artificial Lucene based on the same query set. Figure <ref type="figure" coords="6,271.93,682.46,4.98,8.96" target="#fig_1">2</ref> shows the difference between Indri and Lucene using four different measurement indicators. We can see that the former outperforms the latter in most of topic. It follows that the search engine of Indri is more effective than Lucene for the retrieval task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparing submitted runs to each other</head><p>In order to testify the effectiveness of our methods, we compare the infAP and infNDCG of each method. For the task A as shown as Figure . 3, the artificial results are much higher than other automatic results. It is also find that the re-ranking model based on machine learning has less effective than the expectations. From the statistical results of Figure . 4, the re-ranking model based on cooccurrence network does not perform well enough. The performance of most topics is not improved except a small rise in the topic 9 and 27. For the possible reasons of unsatisfactory result, we analyze that it could be caused by the weight parameters of 𝛼 and 𝛽, which are not adjusted to the optimal values.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper described the clinical decision support task in the TREC 2015. To complete the task, a clinical decision support system based on literatures is designed and developed by the HIT-WI group. On the basis of traditional retrieval techniques, we propose two novel re-ranking methods to improve the retrieval results. The two methods use the models of the machine learning and the network. Moreover, the analysis of the experimental result demonstrates the effectiveness of our system. Our future work will focus on optimizing the re-ranking model and cutting down time consumption in the process of retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,180.98,537.28,233.17,8.10"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The flow diagram of the clinical decision support system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,229.85,342.02,135.47,8.10"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Comparing Indri with Lucene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,186.98,574.15,221.42,8.10"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Retrieval results for task A in two different indicators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,187.22,286.58,220.94,8.10;8,296.16,332.88,173.04,130.08"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Retrieval results for task B in two different indicators.</figDesc><graphic coords="8,296.16,332.88,173.04,130.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,147.02,472.12,301.37,8.10;8,124.68,334.44,171.48,128.88"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Comparing the automatic runs based on SVM model with other participants.</figDesc><graphic coords="8,124.68,334.44,171.48,128.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="8,127.82,631.63,339.77,8.10;8,297.60,493.32,172.32,129.60"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Comparing the automatic runs based on co-occurrence network with other participants.</figDesc><graphic coords="8,297.60,493.32,172.32,129.60" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The Open Access Subset of PubMed Central used in this paper were provided by <rs type="funder">TREC 2015 Clinical Decision Support</rs> (CDS) track, and thanks to the organizing committee of <rs type="institution">TREC</rs> and the evaluators of the results.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,132.67,426.88,337.79,8.10;9,141.74,437.92,328.73,8.10;9,141.74,448.84,148.88,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,280.41,426.88,190.04,8.10;9,141.74,437.92,36.75,8.10">Overview of the TREC 2014 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">M S</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hersh</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,197.39,437.92,139.33,8.10">Proc. 23rd Text Retrieval Conference</title>
		<meeting>23rd Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.67,459.88,332.82,8.10" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,265.30,459.88,184.44,8.10">A Hybrid Approach to Clinical Question Answering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.67,470.92,337.90,8.10;9,141.74,481.84,328.94,8.10;9,141.74,492.88,63.50,8.10" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,301.76,470.92,168.81,8.10;9,141.74,481.84,328.94,8.10;9,141.74,492.88,48.97,8.10">Full-texts representation with Medical Subject Headings, and co-citations network rerank-ing strategies for TREC 2014 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeillab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaudinata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Paschec</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.67,503.92,337.72,8.10;9,141.74,514.84,29.34,8.10" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,284.66,503.92,185.72,8.10;9,141.74,514.84,14.67,8.10">Atigeo at TREC 2014 Clinical Decision Support Task</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.67,525.88,337.72,8.10;9,141.74,536.92,260.05,8.10" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,294.73,525.88,175.65,8.10;9,141.74,536.92,245.34,8.10">UCLA at TREC 2014 Clinical Decision Support Track: Exploring Language Models, Query Expansion, and Boosting</title>
		<author>
			<persName coords=""><forename type="first">Garcia-Gathrighta J I</forename><surname>Menga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hsua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.67,547.84,337.64,8.10;9,141.74,558.88,32.81,8.10" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,274.53,547.84,195.78,8.10;9,141.74,558.88,18.23,8.10">NovaSearch at TREC 2014 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mourao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Magalhaes</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
