<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,169.23,116.90,276.90,12.90;1,134.77,134.83,345.83,12.90;1,293.80,152.76,27.76,12.90">Exploration of Semantic-aware Approach for Contextual Suggestion Using Knowledge from The Open Web</title>
				<funder ref="#_aNCXQVX">
					<orgName type="full">Science and Technology Planning Project of Tianjin</orgName>
				</funder>
				<funder ref="#_vgXSEVR">
					<orgName type="full">Natural Science Foundation of Tianjin</orgName>
				</funder>
				<funder>
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,137.83,191.05,45.96,8.64"><forename type="first">Yuan</forename><surname>Wang</surname></persName>
							<email>nkwangyuan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Control Engineering</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<postCode>300071</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Software</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<postCode>300071</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.86,191.05,66.69,8.64"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
							<email>xzhang92@ucsc.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.72,191.05,37.36,8.64"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.24,191.05,60.60,8.64"><forename type="first">Xintong</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,395.01,191.05,27.40,8.64"><forename type="first">Jie</forename><surname>Liu</surname></persName>
							<email>jliu@nankai.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Control Engineering</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<postCode>300071</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Software</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<postCode>300071</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,454.18,191.05,23.35,8.64;1,289.44,203.01,26.56,8.64"><forename type="first">Yalou</forename><surname>Huang</surname></persName>
							<email>huangyl@nankai.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Control Engineering</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<postCode>300071</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Software</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<postCode>300071</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,169.23,116.90,276.90,12.90;1,134.77,134.83,345.83,12.90;1,293.80,152.76,27.76,12.90">Exploration of Semantic-aware Approach for Contextual Suggestion Using Knowledge from The Open Web</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2CD0B60AB8F5899ABB8EB759536CB5EB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Contextual Suggestion</term>
					<term>User Modeling</term>
					<term>Semantic Analysis</term>
					<term>Domain Preference Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our group's first attempt on the Contextual Suggestion Track of the Twenty-fourth Text REtrieval Conference (TREC 2015). The task aims to provide recommendations on attractions for various kinds of users under different and complex contexts. TREC provides two ways to participate in the track: one is to create a web server that can respond to contextual related queries called "Live Experiment", the other is to submit run files that have all the responses to the released requests called "Batch Experiment". For Live Experiment, due to lack of training data, our approach sticks closely to the defined relevance judgement criteria and context knowledge. We take linear interpolation to combine a variety of factors and contextual related knowledge. For Batch Experiment, we further consider domain preference under user attributes, and take existing Machine Learning based methods in principle. We show that feature engineering is a vital part for attraction suggestions. We find that the performance of suggestions to the provided user profiles and contexts has been improved using domain preference analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2015 Contextual Suggestion task investigates search techniques for complex information needs that are highly dependent on context and user interests as suggested by the guidelines. The task is to develop a system that is able to give ranked suggestion (attractions) for a particular user out of user rating profiles with a particular context. Roughly speaking, given a user, the task focuses on traveling suggestions based on This work was finished when the first two authors were visiting University of California, Santa Cruz. two hypotheses. 1) A traveller prefers a suggestion that is appropriate to her/his profile based on the user's historical preferences. 2) A traveller prefers a suggestion that is highly related to the context that can be more than a city, also including a trip type, trip duration, the type of group the person is traveling with or the season in which the trip will occur. So we need to model user preferences out of her/his profile and the context as well.</p><p>The majority of the systems presented in the past collect attractions from wellknown location based recommender services <ref type="bibr" coords="2,315.23,204.99,8.26,8.64" target="#b0">[1]</ref><ref type="bibr" coords="2,323.48,204.99,4.13,8.64" target="#b1">[2]</ref><ref type="bibr" coords="2,323.48,204.99,4.13,8.64" target="#b2">[3]</ref><ref type="bibr" coords="2,327.61,204.99,8.26,8.64" target="#b3">[4]</ref> such as Google Places <ref type="foot" coords="2,428.22,203.06,3.69,6.39" target="#foot_0">5</ref> , Yelp <ref type="foot" coords="2,456.02,203.06,3.69,6.39" target="#foot_1">6</ref> , Tri-pAdvisor <ref type="foot" coords="2,171.85,215.02,3.69,6.39" target="#foot_2">7</ref> , Foursquare <ref type="foot" coords="2,226.32,215.02,3.69,6.39" target="#foot_3">8</ref> and etc. Most of them <ref type="bibr" coords="2,320.94,216.95,13.16,8.64" target="#b0">[1,</ref><ref type="bibr" coords="2,335.76,216.95,7.47,8.64" target="#b1">2,</ref><ref type="bibr" coords="2,344.89,216.95,8.30,8.64" target="#b3">4]</ref> exploited the open web to perform useful information extraction and collection. For example, Yang, et al <ref type="bibr" coords="2,436.65,228.90,11.29,8.64" target="#b1">[2]</ref> queried Yelp to gather reviews and ratings about attractions to build user opinion profiles, and then ranked attractions based on relevance between user profiles and attractions. Some of them <ref type="bibr" coords="2,164.97,264.77,13.52,8.64" target="#b2">[3]</ref> defined the personalized input to directly query these recommender service systems to get suggestions. Besides information gathering, participants tried many kinds of machine learning techniques, such as Learning To Rank methods <ref type="bibr" coords="2,432.79,288.68,13.37,8.64" target="#b1">[2,</ref><ref type="bibr" coords="2,447.82,288.68,7.19,8.64" target="#b4">5]</ref>, Support Vector Regression <ref type="bibr" coords="2,225.36,300.63,12.48,8.64" target="#b3">[4]</ref>, Hierarchical K-Means Clustering <ref type="bibr" coords="2,378.47,300.63,11.92,8.64" target="#b5">[6]</ref>. Vector Space Model (VSM) is widely used in contextual suggestions as well <ref type="bibr" coords="2,356.81,312.59,11.98,8.64" target="#b0">[1,</ref><ref type="bibr" coords="2,370.45,312.59,7.47,8.64" target="#b3">4,</ref><ref type="bibr" coords="2,379.59,312.59,7.19,8.64" target="#b6">7]</ref>. Thus, we observe one vital trend via the past works: feature extractions and machine learning techniques have been generally accepted to become the effective ways for the task.</p><p>Different from the track in years before, TREC provided an ad-hoc collection for suggestion this year, which consists of a set of 1,234,842 attractions. This becomes challenging due to the quantity and the variety of attractions. TREC provides two ways to participate, one is to create a web server that can respond to contextual related queries, called "Live Experiment", the other is to submit run files that include responses to all the requests, called "Batch Experiment". As to "Live Experiment", only one user is seen by our server each time, making it difficult to train sophisticated ranking models. This makes practical sense in real applications where we always face the same issue. To understand details of attractions, we have crawled a variety of indirect information about attractions from the open web, such as reviews, ratings and web page contents. Based on useful information gathering, we model user preference with multi-field descriptions in multiple text semantic modeling ways. We make effort to go the extra mile to build a contextual related dictionary to improve performance on the cases with more pieces about the trip. At last, we take linear interpolation to combine a variety of factors, as well as contextual related background knowledge from people and personal tags from a user. As for "Batch Experiment", a file with a set of requests that were made during the live experiment is available which provides us a chance to test machine learning methods during this phase. We model the suggestion task as a classification problem, where we predict the rating of each triplet of "user, attraction, context" ranging in (0, 1, 2, 3, 4), and then rank candidates according to the probability of classification results. Here, we want to investigate user domain preference and further extend our model with domain preference under user's attributes such as gender and age, taking advantage of useful information gathered in Live Experiment as well. After feature generation, we train prediction models by using Weka <ref type="bibr" coords="3,285.65,132.26,13.70,8.64" target="#b7">[8]</ref>, and submit two runs based on methods that show the best performance with 5-fold cross-validation on training data sets.</p><p>The remainder of the paper is organized as follows. Section 2 describes some preliminary knowledge about the task. In Section 3, we show how to obtain the used data. In Section 4 and Section 5, we describe the process of feature extraction and experimental setup for Live Experiment and Batch Experiment. The results are shown in Section 6. We concludes the paper in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Formulation</head><p>This section describes some preliminary information about the task. First, we describe the input and output of the task. Second, we discuss the evaluation metrics used to estimate the performance of different solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Description</head><p>The task is to develop a system that is able to generate a ranked list of up to 50 suggested attractions for a particular person (based upon her/his profile) with a particular context. TREC provides the complete set of contexts, an ad-hoc collection that consists of a set of attractions and user profiles. Each profile corresponds to a single user, and indicates trip-related context and user's preference with respect to each example suggestion. Each user indicates her/his preference with a rating from 0-4 for an attraction. If the user assigns a score equal to or greater than 3, it means that the user likes this suggestion. Otherwise, if the user assigns a score equal to or less than 1, it means that the user dislikes this suggestion. In the attraction collection file, there are an attraction ID, a context (city) ID, a URL and a title for each attraction. Note that this title is not always shown as the title of the page to that URL (contained in the "title" element under the HTML document's head). Each context is a city in which the user is located, which consists of an ID, a city name, a state name and an approximate latitude and longitude. Additionally, we can find more pieces of optional data about the trip, such as the trip type, the trip duration, the type of group and the season the trip will occur in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation Metrics</head><p>The TREC 2015 Contextual Suggestion Track takes Precision at Rank 5 (P@5) as main metrics. The track also uses Mean Reciprocal Rank (MRR) to evaluate the final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Cleaning and Useful Information Gathering</head><p>In this section, we describe how we create a sub-collection from the published attraction collection and gather useful information. Due to so many noisy URLs in the raw data, we manually make some rules to select reliable URLs. We pick up two types of URLs as suggested candidates. One is the URLs of the attraction pages from well-known social networks, namely Yelp, Foursquare and TripAdvisor, the other is the URLs of home pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Attractions from Yelp, Foursquare and TripAdvisor</head><p>Many commercial online review websites such as Yelp, Foursquare and TripAdvisor provide friendly APIs for developers to access their content, such as business information, ratings and reviews. We detect the URLs with more information about attractions on these websites as Tourist Sub-collection. We keep the URLs that start with one of the following parts:"https://foursquare.com/v/", "http://www.yelp.com/biz/" or "http://www.tripadvisor.com/Attraction". For the attractions of these URLs, we query their corresponding API to get more information about attractions, such as their titles, web page contents, positive reviews, negative reviews, all ratings and their average ratings. Due to the fact that the content of a page contains so much useless information, we use TextRank <ref type="bibr" coords="4,187.31,253.47,13.65,8.64" target="#b8">[9]</ref> to learn the review summary about the attractions in place of the full page content as an additional field. Thus, we obtain the URL, the title, ratings, positive and negative reviews, the review summary for each attraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Attractions from Home Page</head><p>The home page of an attraction is expected to contain the most important and valuable information about the attraction. Thus, we extract all URLs that include equal to or less than 3 forward slash "/" as Homepage Sub-collection. Due to homepages shown without reviews or ratings, we query Yelp API <ref type="foot" coords="4,323.65,372.39,3.69,6.39" target="#foot_4">9</ref> using the location and the title of the home page. In this step, the attraction whose location and title are the same as the input will be returned and crawled for more information. We summarize content of the home page to get summaries of attractions in the Homepage Sub-collection. This is the difference of the summary process between the Tourist Sub-collection and the Homepage Sub-collection.</p><p>All the crawlers are developed by Python and data is stored in json format. We have crawled 155,116 attractions in the Homepage Sub-collection and 479,058 attractions in the Tourist Sub-collection. We map the numeric rating scale of 1-5 or 1-10 into 1-5 scale. In sub-collections, we discard the ones of which average ratings are less than 3 to obtain general good attractions. The attractions from the Homepage Sub-collection and the Tourist Sub-collection are used to extract features for each candidate attraction and to model user preference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Live Experiment</head><p>In this section, we describe our approach for generating a personalized rank list of suggested attractions for each "user, context" pair in Live Experiment. First, we present our way of attraction representation and user preference profile modeling. Second, we rank attractions based on a linear interpolation among cosine similarities between attraction representation feature groups and user preference feature groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Representation of Attractions and User Profiles</head><p>According to the gathered useful information, we apply standard IR parsing techniques including turning all words into lower cases, stemming and removing stop words on five parts of attractions' text information respectively, including the title text provided by TREC (denoted as orititle), the title text we crawled (denoted as title), the content summary text (denoted as content), the positive review text (denoted as positive) and the negative review text (denoted as negative). Once texts have been parsed, we map terms into ID.</p><p>As for attractions, we represent their texts in two ways: Vector Space Model (VSM) and Latent Semantic Indexing (LSI) <ref type="bibr" coords="5,278.06,246.71,16.27,8.64" target="#b9">[10]</ref>. First, texts of candidate attractions are represented in VSM under the tf-idf weighting scheme <ref type="foot" coords="5,331.09,256.73,7.37,6.39" target="#foot_5">10</ref> . For LSI, we perform rank-reduced singular value decomposition on the term-document matrix based on VSM representation of each text. Here, we reduce the rank by keeping the largest 20 diagonal entries to represent each text information as a 20 dimension vector. Now, we get 10 semantic feature groups to represent an attraction. We denote feature groups as the name of the text part followed by its representation method. For example, title lsi means the feature group that represents the title text we crawled by LSI. Thus, we obtain the feature group set A = {orititle lsi, orititle t f id f ,title lsi,title t f id f , content lsi, content t f id f , positive lsi, positive t f id f , negative lsi, negative t f id f }.</p><p>As for users, we use features of attractions that a user has rated to represent preference of the user. The user preference representation also shares the same item as attractions, including VSM and LSI representation of 5 text parts. As mentioned before, the ratings of 3 and up show users' interest to attractions. We collect titles provided by TREC (orititle), titles we crawled (title), content summaries of the attractions (content) of which ratings are equal to or greater than 3 to represent user preference. Reviews from the open web show more details about attractions. Thus, we take reviews as well as other parts to model user preference. For a user, her/ his "positive reviews (positive)" collect all of the positive reviews about the attractions that she/he likes, and vice versa, i.e., "negative reviews (negative)" collect all of the negative reviews about the attractions that she/he dislikes. Then we represent these text information in ways of VSM and LSI. From an original user profile, we can find two more kinds of information. One is from tags that indicate why the user likes the particular attraction along with attractions added by the user, the other is from several pieces of optional context about the trip. We collect the tags and manually label key words highly related to context of the trip. On average, we pick up 100 key words about each piece of the trip. For example, we label the trip type of "Business" with words "flight", "conversation", "event", "meeting" and etc, and label the season of "Summer" with words "hot", "barbecue", "lemonade", "picnic outside" and etc. We combine the tags from the user and key words related to provided context as an additional text feature to represent user preference. Further, we apply SVM and LSI techniques on this new text to obtain two extra feature groups, denoted as keyword t f id f and keyword lsi. Here, we get 12 feature groups to represent a user's preference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ranking Strategy</head><p>To generate the final ranking list of attractions, we compute the similarity between attractions and a user preference profile. Representation of user preference profiles and attractions share the same kinds of 10 feature groups. We calculate the cosine similarities between these feature groups. Suppose that the user preference feature vector R(u) and the attraction feature vector R(t) denote any one of VSM representation or LSI representation on the title text provided by TREC, the title text we crawled, the content summary text, the positive review text or the negative review text respectively, the similarity between the two is:</p><formula xml:id="formula_0" coords="6,206.09,241.12,274.51,24.06">sim f (u,t) = cos(R f (u), R f (t)) = R f (u) • R f (t) R f (u) R f (t) ,<label>(1)</label></formula><p>where f comes from the feature set of A. For feature groups of tags and key words (keyword), we calculate the cosine similarity between keyword and attraction's positive reviews positive, because reviews always show more description about attractions. These two parts are denoted as keyword p lsi and keyword p t f id f . The final score is based on these similarity scores using linear interpolation. We use the following function to estimate the similarity between a user and a candidate attraction:</p><formula xml:id="formula_1" coords="6,139.17,367.71,341.42,29.70">score(u,t) = w 1 • sim keyword p lsi (u,t) + w 2 • sim keyword p t f id f (u,t) + ∑ f ∈A w f • sim f (u,t),<label>(2)</label></formula><p>where the value of w = {w 1 , w 2 } ∪ {w f } f ∈A must be summed up to 1. We use the score(u,t) to rank the attractions on our server. We have submitted two runs during Live Experiment. In the run of IRKM1, we do not consider two keyword feature groups, and the weight w is w 1 = w 2 = 0 and w f = {0.05, 0.05, 0.1, 0.1, 0.2, 0.2, 0.35, 0.35, -0.2, -0.2} (in the same order as A). In the run of IRKM2, the weight w is w 1 = w 2 = 0.1667 and w f = {0.0333, 0.0333, 0.0667, 0.0667, 0.1333, 0.1333, 0.2333, 0.2333, -0.1333, -0.1333}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Batch Experiment</head><p>In this section, we describe our approach for generating a personalized rank list of suggested attractions for each "user, context" pair in Batch Experiment. The set of all suggestion requests is released, which provides us a chance to learn like/dislike patterns from user's contextual preference to attractions. First, we derive features about each "user, attraction, context" triplet. Second, we utilize the power of machine learning methods to predict ratings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Feature Generation</head><p>Given attraction representation and user profile modeling in Section 4.1, we introduce more features to feed our predict algorithm for Batch Experiment. We use all of 12 cosine similarity scores used in IRKM2 as features. Besides VSM and LSI representation, we represent each text part of attraction descriptions with a topic vector based on Latent Dirichlet Allocation (LDA) <ref type="bibr" coords="7,310.15,120.31,18.32,8.64" target="#b10">[11]</ref>. For example, a content summary is mapped into a vector of 20 topics. Then the same operation is conducted on user preference profiles. To get more clues for the triplets, we compute the cosine similarity between user's keyword and attraction's negative reviews negative (denoted as keywordn), and the cosine similarity between user's keyword and attraction's content summary content (denoted as keywordc). So the features derived from text are (24 in total): {orititle lsi, orititle lda, orititle t f id f ,title lsi,title lda,title t f id f , content lsi, content lda, content t f id f , positive lsi, positive lda, positive t f id f , negative lsi, negative lda, negative t f id f , keyword p lsi, keyword p lda, keyword p t f id f , keywordn lsi, keywordn lda, keywordn t f id f , keywordc lsi, keywordc lda, keywordc t f id f }.</p><p>In this part, we also want to investigate user preference to URL domains. Thus we extend our features with domain preference under user's attributes such as gender and age. First, we map all distinct domains of attractions into IDs. Second, we count the rating frequency of each domain under each gender value (female and male) and each age group (0-10, 10-20, 20-30, 30-40, 40-50) appeared in the set of all user profiles. Third, we count the frequency of each domain of which the rating is equal to or greater than 3 under each gender value and each age scale. Fourth, we get an average rating for each domain under each gender value and each age scale. For each user, we count the rating frequency, the frequency of ratings equal to or greater than 3 and average rating for each domain. In a "user, attraction, context" triplet, we add these domain-related features according to the domain of the attraction and attribute values (gender, age and specific ID) of the user. Additionally, we add age and gender of the user as features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ranking Strategy</head><p>We formulate the problem as a classification problem. Afterwards, we rank the attractions according to their predicted ratings. For the ones with the same ratings, the one with a higher prediction probability provided by classification methods will be ranked higher. We can find a batch of training examples from user profiles. We build features for each "user, attraction, context" triplet. With the features, we try many classical classification methods using the data mining tool Weka <ref type="bibr" coords="7,333.98,481.55,14.59,8.64" target="#b7">[8]</ref> and pick up the two with the best performance on training data to submit as our runs. RUN1 uses Ensemble of Nested Dichotomies (END) model <ref type="bibr" coords="7,232.01,505.46,18.45,8.64" target="#b11">[12]</ref> that is a meta classifier for handling multi-class datasets with 2-class classifiers by building an ensemble of nested dichotomies, while RUN2 takes Sequential Minimal Optimization (SMO) <ref type="bibr" coords="7,318.82,529.37,19.92,8.64" target="#b12">[13]</ref> for training a support vector classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Runs and Results</head><p>We submitted two runs for Live Experiment: IRKM1 and IRKM2. They both use multiple fields to learn relevance between attractions and users with particular context. Additionally, IRKM2 incorporates user tags and labeled keywords as more feature groups. For Batch Experiment, we submitted two runs: RUN1 and RUN2. The two runs model the contextual suggestion task as a score prediction problem, and explore the contributions of domain preferences and user attributes for the contextual suggestion task, and apply classification techniques to predict the score of "user, attraction, context" triplets. The difference is that RUN1 uses END model, while RUN2 uses SMO model. For all runs, features benefit from titles, summaries of web page contents, reviews and ratings of attractions we crawled from the open web.</p><p>Table <ref type="table" coords="8,175.14,168.21,4.98,8.64" target="#tab_0">1</ref> shows the overall mean performances of our runs in terms of evaluation measures. First, we observe that our submitted runs in Live Experiment achieve above median performances for both P@5 and MRR. IRKM1 and IRKM2 have P@5 value of 0.3953 and 0.4079, respectively. The MRR of IRKM1 and IRKM2 are 22% higher than average Track Median at 0.4268. IRKM2 is slightly better than IRKM1. It shows that tags and our labeled contextual related keywords help to get the clues of user interests and contextual Second, results of RUN1 and RUN2 in Batch Experiment are better than both of IRKM1 and IRKM2. We can refer that machine learning methods and domain knowledges are useful for the task. Third, we see that performances of RUN1 and RUN2 are similar. We learn that feature engineering is vital for classical classification methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In TREC 2015 Contextual Suggestion Track, we submitted two runs for both Live Experiment and Batch Experiment. Attraction description and user profiles modeling in all runs take advantage of information from commercial attraction review websites. The information includes: web page content, titles, ratings and reviews of attractions.</p><p>For Live Experiment, we represented attractions and users using multi-filed texts in the ways of VSM and LSI. In IRKM1, we focus on the similarity between attractions and user historical preference, while we combine user tags and contextual related keywords to obtain the results of IRKM2. For Batch Experiment, we get more features by exploring domain preference under user's attributes such as gender and age, and using LDA to get topic distribution of each type of texts. Then we model the ranking problem as a classification problem using machine learning techniques to learn the ranking list. In the future, we plan to extend our method by considering the category of attractions, and try to aggregate user's category preference for a better user modeling.</p><p>(No. 61300166) and the Specialized Research Fund for the Doctoral Program of Higher Education (No. 20130031120042).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,164.26,317.19,284.28,65.95"><head>Table 1 .</head><label>1</label><figDesc>Results of our runs in the contextual Suggestion</figDesc><table coords="8,164.26,341.70,284.28,41.45"><row><cell></cell><cell cols="2">Live Experiment</cell><cell cols="2">Batch Experiment</cell></row><row><cell cols="5">Name of Run Track Median IRKM1 IRKM2 Track Median RUN1 RUN2</cell></row><row><cell>MRR</cell><cell>0.4268</cell><cell>0.5213 0.5461</cell><cell>0.6716</cell><cell>0.6594 0.6535</cell></row><row><cell>P@5</cell><cell>0.3163</cell><cell>0.3953 0.4079</cell><cell>0.5090</cell><cell>0.5156 0.4616</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="2,144.73,624.28,123.28,7.77"><p>https://www.google.com/business/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="2,144.73,635.58,78.12,7.77"><p>http://www.yelp.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2" coords="2,144.73,646.78,101.04,7.77"><p>http://www.tripadvisor.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3" coords="2,144.73,658.08,83.43,7.77"><p>https://foursquare.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_4" coords="4,144.73,658.08,222.71,7.77"><p>https://www.yelp.com/developers/documentation/v2/overview</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_5" coords="5,144.73,658.08,174.67,7.77"><p>https://en.wikipedia.org/wiki/Tf%E2%80%93idf</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. Part of this research is supported by the <rs type="funder">Natural Science Foundation of Tianjin</rs> (No. <rs type="grantNumber">14JCQNJC00600</rs>), the <rs type="funder">Science and Technology Planning Project of Tianjin</rs> (No. <rs type="grantNumber">13ZCZDGX01098</rs>), the <rs type="funder">National Natural Science Foundation of China</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vgXSEVR">
					<idno type="grant-number">14JCQNJC00600</idno>
				</org>
				<org type="funding" xml:id="_aNCXQVX">
					<idno type="grant-number">13ZCZDGX01098</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.61,187.71,337.98,7.77;9,150.95,198.67,329.64,7.77;9,150.95,209.62,85.90,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,314.82,187.71,165.77,7.77;9,150.95,198.67,203.48,7.77">Bjut at trec 2014 contextual suggestion track: Hybrid recommendation based on open-web information</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,374.41,198.67,106.18,7.77;9,150.95,209.62,55.30,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,220.58,337.98,7.77;9,150.95,231.54,172.10,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,220.44,220.58,227.68,7.77">Exploration of opinion-aware approach to contextual suggestion</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,466.65,220.58,13.94,7.77;9,150.95,231.54,141.51,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,242.50,337.98,7.77;9,150.95,253.46,188.29,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,336.11,242.50,107.40,7.77">University of delaware at trec</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sabhnani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zengin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,150.95,253.46,157.69,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,264.42,337.98,7.77;9,150.95,275.38,222.65,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,217.89,264.42,259.01,7.77">Modelling psychological needs for user-dependent contextual suggestion</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,163.16,275.38,157.69,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,286.34,337.98,7.77;9,150.95,297.30,329.64,7.77;9,150.95,308.25,57.28,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,423.59,286.34,57.00,7.77;9,150.95,297.30,175.42,7.77">Applying learning to rank techniques to contextual suggestions</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiseleva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pechenizkiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>De Bra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,348.73,297.30,131.87,7.77;9,150.95,308.25,26.68,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,319.21,337.98,7.77;9,150.95,330.17,329.64,7.77;9,150.95,341.13,123.01,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,333.34,319.21,147.25,7.77;9,150.95,330.17,216.47,7.77">University of waterloo at trec 2014 contextual suggestion: Experiments with suggestion clustering</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dean-Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Addala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,391.59,330.17,89.00,7.77;9,150.95,341.13,70.25,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,352.09,337.98,7.77;9,150.95,363.05,329.64,7.77;9,150.95,374.01,79.44,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,299.85,352.09,180.74,7.77;9,150.95,363.05,172.60,7.77">Better contextual suggestions in clueweb12 using domain knowledge inferred from the open web</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Samar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bellogın</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,347.61,363.05,132.98,7.77;9,150.95,374.01,26.68,7.77">The 23rd Text Retrieval Conference (TREC)</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,384.97,337.98,7.77;9,150.95,395.58,317.19,8.12" xml:id="b7">
	<analytic>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,428.22,384.97,52.37,7.77;9,150.95,395.93,96.28,7.77">The weka data mining software: an update</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,406.89,337.98,7.77;9,150.95,417.84,329.64,7.77;9,150.95,428.80,23.90,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,239.48,406.89,124.56,7.77">Textrank: Bringing order into texts</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,383.56,406.89,97.03,7.77;9,150.95,417.84,170.62,7.77">Proceedings of the Association for Computational Linguistics(ACL 2004)</title>
		<meeting>the Association for Computational Linguistics(ACL 2004)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,439.76,338.35,7.77;9,150.95,450.37,202.67,8.12" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,448.85,439.76,31.74,7.77;9,150.95,450.72,95.16,7.77">Indexing by latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,252.80,450.72,19.39,7.77">JAsIs</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,461.68,338.35,7.77;9,150.95,472.29,135.45,8.12" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,290.05,461.68,94.03,7.77">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,394.83,461.68,85.76,7.77;9,150.95,472.64,64.48,7.77">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,483.60,338.35,7.77;9,150.95,494.56,327.60,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,234.82,483.60,209.72,7.77">Ensembles of nested dichotomies for multi-class problems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,465.15,483.60,15.44,7.77;9,150.95,494.56,262.18,7.77">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,505.52,338.35,7.77;9,150.95,516.47,329.64,7.77;9,150.95,527.43,101.59,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,183.32,505.52,282.93,7.77">Fast training of support vector machines using sequential minimal optimization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,312.92,516.47,167.67,7.77;9,150.95,527.43,30.76,7.77">Advances in Kernel Methods -Support Vector Learning</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
