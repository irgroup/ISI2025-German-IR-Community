<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,104.56,85.26,400.60,5.54;1,119.87,105.19,369.97,5.54">QU at TREC-2015: Building Real-Time Systems for Tweet Filtering and Question Answering</title>
				<funder ref="#_3DpnEZs">
					<orgName type="full">Qatar National Research Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">Qatar Foundation</orgName>
				</funder>
				<funder ref="#_w7gkp3D">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,133.02,135.09,81.12,14.80"><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
							<email>reem.suwaileh@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department Qatar University Doha</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.19,135.09,88.24,14.80"><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
							<email>maram.hasanain@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department Qatar University Doha</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.74,135.09,155.97,14.80"><roleName>Tamer Elsayed</roleName><forename type="first">Marwan</forename><surname>Torki</surname></persName>
							<email>mtorki@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department Qatar University Doha</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,104.56,85.26,400.60,5.54;1,119.87,105.19,369.97,5.54">QU at TREC-2015: Building Real-Time Systems for Tweet Filtering and Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D6F584C1FABB68AFF50DD8FCEC360E96</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our participation in the microblog and LiveQA tracks in TREC-2015. Both tracks required building a "real-time" system that monitors a data stream and responds to users' information needs in real-time.</p><p>For the microblog track, given a set of users' interest profiles, we developed two online filtering systems that recommend "relevant" and "novel" tweets from a tweet stream for each profile. Both systems simulate real scenarios: filtered tweets are sent as push notifications on a mobile phone or as a periodic email digest. We study the e↵ect of using a static versus dynamic relevance thresholds to control the relevancy of filtered output to interest profiles. We also experiment with di↵erent profile expansion strategies that account for potential topic drift. Our results show that the baseline run of the push notifications scenario that uses a static threshold with light profile expansion achieved the best results. Similarly, in the email digest scenario, the baseline run that used a shorter representation of the interest profiles without any expansion was the best run.</p><p>For the LiveQA track, the system was required to answer a stream of around 1000 real-time questions from Yahoo! Answers. We adopted a very simple approach that searched an archived Yahoo! Answers QA dataset for similar questions to the asked ones and retrieved back their answers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Twitter has rapidly developed over the past years and become a massive information sharing network. It gained a reputation for carrying the heartbeat of the world by allowing users to continuously post and read tweets about current events and news. With a huge flood of tweets shared daily, users are overwhelmed by the amount of data they need to follow in order to track a certain event or a topic. Automatically-satisfying the user interest in following a certain topic over a non-stop stream of tweets is challenging as it requires a real-time system that filters relevant and novel tweets from a rapidly flowing stream. Moreover, the filtering system is required to address problems originating from the nature of tweets such as their limited number of characters; with maximum 140 characters per tweet, and their conversational and temporal characteristics. The shortness of Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.</p><p>TREC '15 Gaithersburg, Maryland, USA tweets causes a challenge known as sparsity and the change of the topic over time stems another dominant challenge called drifting challenge.</p><p>There have been several studies for applying online filtering on Twitter stream that attempts to overcome these challenges e.g <ref type="bibr" coords="1,378.55,273.16,9.71,8.57" target="#b1">[1,</ref><ref type="bibr" coords="1,391.78,273.16,6.48,8.57" target="#b3">3]</ref>. The first study adapted the state-ofthe-art news filtering technique that uses Incremental Rocchio classifier to continuously update the tracked topics on the tweets stream <ref type="bibr" coords="1,392.68,304.54,9.20,8.57" target="#b1">[1]</ref>. The proposed adaptation encounter the sparsity problem by expanding the userâ ȂŹ s profile with relevant and recent terms to enrich the interest representation. However, along with this solution, the possibility of topic drift arises especially that the tweets' stream is hastily developing and the topic representation should keep-up with that. Thus, in addition to investigating an event detection approach to detect the topic drift in the tweet stream, an attempt to balance the contribution of the long-term and short-term interest to the interest profile was applied. The adaptation was evaluated using TREC Microblog track 2012 and it showed the e↵ectiveness of this adaptation, but not to the extend achieved in news filtering. Another study experimented di↵erent smoothing models to integrate a background and a foreground language models (LM) that represent the tracked topics in the stream. Both LMs were trained per-topic using hashtags from Twitter stream <ref type="bibr" coords="1,543.65,473.23,9.20,8.57" target="#b3">[3]</ref>. The background language model represents the topic tracking on the continuous stream for about one month where the foreground language model represents the recently captured changes on the topic from the same stream. The approach was examined over ten topics and approved that it performs well in the filtering task.</p><p>In this work, we propose tweet filtering systems that attempts to handle these challenges for both scenarios in the TREC-2015 microblog track: push notifications on a mobile phone and a periodic email digest. The problem, our approach and evaluation results are further discussed in Section 2.</p><p>As with Twitter, social question answering (sQA) systems are increasingly gaining importance and attracting millions of users to post and answer questions. Yahoo! Answers<ref type="foot" coords="1,338.18,639.15,3.65,5.48" target="#foot_0">1</ref> is by far one of the largest sQA platforms. Questions and answers on such platforms share some characteristics with tweets in terms of being conversational and often very socially-oriented.</p><p>In the past few years, QA as a research problem has received significant attention, however, building e↵ective au-tomatic QA is impeded by a lack of suitable datasets to train these systems. Automatic QA is even more challenging when the focus goes beyond seeking short answers to factoid questions, to questions that require reasoning, explanations, etc. The datasets used in such previous systems are either too small to train a good system or not extensive to involve multiple domains <ref type="bibr" coords="2,185.34,120.20,9.20,8.57" target="#b5">[5]</ref>. However, the existence of large social question answering websites, such as Yahoo! Answers specifically, makes the development of automated answering systems more interesting due to the scale of the available datasets. But the amount of questions posted on such platforms is not usually matched by the number of answers provided; many questions are left unanswered and many are repeated. Automatically answering questions in such cases is a useful feature users of these sQA can benefit from which intrigues a need for designing automatic sQA systems. This is in fact the problem we tackle as part of the LiveQA track in TREC-2015. We discuss our approach and evaluation results for the LiveQA track in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">REAL-TIME TWEET FILTERING</head><p>Tweet filtering is the reverse of ad-hoc tweet search, where a user provides an information need at a certain point in time, and the filtering system is expected to filter relevant tweets to the information need from a stream of tweets posted after the query time.</p><p>Tweet filtering was first introduced in the microblog track in TREC-2012 <ref type="bibr" coords="2,116.46,346.92,9.20,8.57" target="#b4">[4]</ref>. The task ran on a simulated stream of tweets from a collection of 16M tweets <ref type="bibr" coords="2,211.94,357.38,9.71,8.57" target="#b4">[4]</ref> that was crawled prior to the running of the task. Di↵erently, the microblog track in TREC-2015 ran a real-time tweet filtering task that worked on a real stream of tweets in a 10-day evaluation period. Moreover, the 2015 task has two modes: 1) a scenario that pushes few filtered tweets as push notifications on a mobile phone to the user, and 2) a scenario where a periodic email digest of a 10-times larger set of top relevant tweets to the topic is sent to user <ref type="bibr" coords="2,163.13,441.07,9.20,8.57" target="#b2">[2]</ref>.</p><p>In both scenarios, the filtering system is expected to send a set of novel (i.e., non-redundant) and relevant (i.e., ontopic) tweets every day.</p><p>In this task, an interest profile that is composed of a title, description, and narrative is used as a representation of the user information need (or topic). The title is short, having few keywords to represent the topic, the description is a one sentence statement of the information need of the user, and the narrative is a full paragraph describing that information need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Approach</head><p>In this section, we first present the main approach of our solution for both scenarios, and then discuss further details that are specific to each of them. Figure <ref type="figure" coords="2,214.78,598.77,4.60,8.57" target="#fig_0">1</ref> shows a high-level overview of the core filtering system on which we build the systems for the two scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Core System Design</head><p>Cold Start and Preprocessing: Following the track guidelines, we only consider English tweets for filtering. The filtering system filters English tweets using an open-source language detection tool 2 . After that, it performs simple preprocessing on tweets and profiles including stemming, stopwords removal, and URL removal. The system represent tweets and profiles as vectors of terms weighted using inverse document frequency (idf)-based term weighting. Term weights are computed using the equation below:</p><formula xml:id="formula_0" coords="2,361.11,458.39,194.80,20.46">idf (term) = log N df (term) + 0.75 df (term) + 0.75<label>(1)</label></formula><p>Where N is the total number of tweets in the collection of tweets from which the system is extracting term statistics and df (term) is the document frequency of the term. As the equation shows, term weights are computed using a history of past tweets which is naturally not available when the system first starts. To solve this "cold start" problem, the system is initialized with an index 3 of a 3-day stream of tweets preceding the beginning of the evaluation period. Additionally, the system periodically indexes the incoming tweets during the evaluation period. Relevance and Novelty: For both scenarios, we used the following approach for filtering based on tweet relevance and novelty. Given an interest profile for a topic, the filtering system processes the incoming stream one tweet at a time. For each tweet, a relevance score to each interest profile is computed using Cosine similarity. A tweet with a similarity score above a relevance threshold ⌧r is considered relevant to the topic. However, the relevant tweet is not pushed to the user unless its novelty score is less than a novelty threshold ⌧n. Given a list of filtered tweets that were sent to user over 3 The index is created and updated using Apache Lucene 4.5.0 (https://lucene.apache.org/) previous days, the system computes the similarity between the incoming tweet and each of the tweets in that list using a modified version of Jaccard similarity. If the similarity of the tweet to any of the tweets in the list exceeds the novelty threshold ⌧n, then the system considers the tweet as redundant and elects not to send it to user. Otherwise, the tweet is considered both relevant and novel, and thus the system flags it to be sent to the user. Profile Expansion: Since topics are tracked over a period of time, the system periodically updates the topic representation to reflect the topic development over that period. To achieve that, the system performs profile expansion using pseudo relevance feedback; expansion terms are extracted from pseudo relevant tweets filtered before the expansion time. The expanded profile vector is computed using the following equation:</p><formula xml:id="formula_1" coords="3,146.98,234.68,142.35,8.57">q0 = q + (ẽ) (<label>2</label></formula><formula xml:id="formula_2" coords="3,289.32,234.68,3.58,8.57">)</formula><p>Where q0 is the expanded profile vector, q is the initial profile vector created when the system first starts and ẽ is the vector of expansion terms extracted from the pseudo relevant tweets for each profile independently. Common terms between the extracted expansion terms and the profile title terms are eliminated before creating ẽ. Parameter is used to control the contribution of expansion terms to the final profile vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Scenario A: Push Notifications</head><p>This scenario simulates a situation where updates about a topic are sent as mobile notifications to the user. The task requires pushing a maximum of 10 tweets per day not to overload the user with notifications. The main challenge in pushing such small number of tweets is that the system has very few opportunities to push high quality tweets to the user. To ensure pushing high quality tweets, the system should consider how fresh the tweets are in addition to how relevant and novel they are. In this context, the freshness of tweets is measured as the elapsed time between the tweet's creation time (the time when tweet appears in the stream) and the time it was pushed to the user. Profile Representation: We represent the initial interest profile as a vector of terms q modeled as follows:</p><formula xml:id="formula_3" coords="3,120.38,524.55,172.52,8.57">q = title + ↵( desc + ñarr)<label>( 3 )</label></formula><p>Where title, desc and ñarr are the vectors of the title, description, and narrative of the profile respectively. The title is given higher weight since it contains the most concise and relevant description of the topic while the description and narrative contribution to the topic is controlled by the parameter ↵ (&lt; 1). Since narrative and description are much longer than the title and might share terms, we further control their contribution to the topic vector by selecting top k weighted terms of the resulting vector ( desc + ñarr) to be added to the final topic vector. Selecting Tweets to Push: Following all interest profiles in parallel, the system monitors the tweet stream and filters tweets based on their similarity and novelty. Over time, the system maintains a list of relevant and novel tweets for each profile and only pushes a tweet from that list periodically with a time period of length or when the size of the list exceeds a limit l.</p><p>After scoring all tweets in that list using equation 4 below, the system pushes the top-scoring tweet to the user. The computed tweet score considers how relevant it is to the profile and how fresh as well. S(t) = Sr(t) ⇤ 100 (CurT ime time(t)) 100 ( <ref type="formula" coords="3,548.08,112.82,3.92,8.57">4</ref>)</p><formula xml:id="formula_4" coords="3,316.81,141.67,20.28,2.26">Sr(t)</formula><p>is the relevance score of tweet t computed using cosine similarity between a profile and the tweet, CurT ime is the current system time, and time(t) is the tweet creation time.</p><p>Threshold Updates: We experiment with using both static and dynamic relevance threshold settings. In the static threshold mode, the relevance threshold ⌧r is set before the system starts and it does not change during the evaluation period. As for the dynamic threshold mode, the system starts with an initial threshold for each interest profile pi and updates per-profile relevance threshold ⌧r periodically.</p><p>To update the threshold, the system maintains the number of tweets found relevant per profile in the last period. If the profile pi gets no relevant tweets in the past time period, then the relevance threshold ⌧r is decreased by 0.025 with a lower bound of 0.5. Otherwise, the threshold is increased using the following equation:</p><formula xml:id="formula_5" coords="3,382.74,311.71,173.18,18.64">⌧ 0 r i = ⌧r i + min( Rp i 100 , 0.15)<label>(5)</label></formula><p>Where ⌧r i is the current threshold of profile pi, ⌧ 0 r i is the updated threshold of that profile and Rp i is the number of relevant tweets filtered for profile pi within a time period tT . The threshold upper bound is set to 0.95.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Scenario B: Periodic E-mail Digest</head><p>This scenario simulates a filtering system that daily sends a list of m relevant and non-redundant tweets from the tweet stream to the user given an interest profile. Initial profiles are represented in the vector space by the weighted title terms:</p><formula xml:id="formula_6" coords="3,419.50,464.40,136.41,8.57">q = title<label>(6)</label></formula><p>Composing E-mail Digest: After the end of each day in the evaluation period, the system issues all profiles as queries against an Apache Lucene search engine that searches the system's tweets index. The search engine uses query-likelihood with Dirichlet smoothing to retrieve a ranked list of the most relevant 2m tweets for each profile. Given this list for each query, the system extracts top m novel tweets and sends them to the user as an email digest. The novelty score of a tweet is computed by its similarity to all tweets previously sent to the user. If the similarity exceeded novelty threshold ⌧n, the tweet is treated as redundant and then discarded, otherwise the tweets is added to the email digest to be sent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Profile Expansion:</head><p>The main focus in this scenario is to explore di↵erent sources of expansion terms for a profile. The baseline run does not perform expansion, but the remaining runs use di↵erent sources of expansion. In addition to extracting the top pseudo relevant tweets returned by searching the index as equation 2, the other expansion approach also uses the top weighted terms from description and narrative fields of the interest profile. In both approaches of expansion, the pseudo relevant tweets are extracted after filtering out tweets that exceeds the novelty threshold ⌧n, the terms of the novel tweets are ranked and the top t weighted ones are added to the profile vector as follows:</p><formula xml:id="formula_7" coords="4,115.28,77.14,177.62,8.57">q0 = q + ↵( desc + ñarr) + ẽ (7)</formula><p>Where the desc and ñarr are the terms vector of the description and narrative fields of the interest profile respectively and their contribution to the profile is controlled by ↵ parameter. Additionally, any common terms between the extracted terms and the initial profile terms are eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Evaluation Measures</head><p>The push notification scenario is evaluated using two main measures: the primary measure which is expected latencydiscounted gain (ELG) and the normalized cumulative gain (nCG) <ref type="bibr" coords="4,83.01,224.81,9.20,8.57" target="#b2">[2]</ref>. Measures can be computed as follows:</p><formula xml:id="formula_8" coords="4,125.04,238.64,167.87,59.36">ELG = 1 Rt X Gain(ti) ( 8 ) nCG = 1 Z X Gain(ti)<label>( 9 )</label></formula><p>where Gain(ti) is 0 if the tweet is not relevant, a spam or junk, or 0.5 if the tweet is somewhat interesting, otherwise, it is set to 1. The gain of a tweet is reduced using the following time latency penalty:</p><formula xml:id="formula_9" coords="4,110.67,350.83,182.23,20.45">latency = max(0, 100 delay 100 ) (<label>1 0 )</label></formula><p>where delay is the di↵erence in minutes between tweet creation time and tweet push time.</p><p>As for the e-mail digest scenario, the e-mail digest is evaluated as a ranked-list of tweets. The evaluation measure used in this task is the normalized discounted cumulative gain (NDCG) computed at length k of this list.</p><p>For all evaluation measures in all scenarios, the score of a topic is the average of the measure values over all days and a score of a run is the average of that across all topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Submitted Runs</head><p>In each day of the evaluation period, the filtering system of scenario A pushes a maximum of n = 10 tweets to the user. Where the in the email digest scenario, the system sends an email digest with a list of m = 100 tweets. This section describes our submitted runs for both scenarios. Table <ref type="table" coords="4,273.99,535.58,3.78,8.57" target="#tab_0">2</ref>.2.2 shows the di↵erent configuration settings is each run. Scenario A:</p><p>• QUBaseline: is a baseline that uses a static relevance threshold ⌧r when comparing a tweet to a profile. The system in this run represents the interest profile by title, narrative and description. The parameter ↵ = 0.2 controls the influence of the terms extracted from both description and narrative fields in profile representation, and 8 terms from these two fields are finally added to the profile. The profile is periodically expanded using a maximum of 4 expansion terms extracted from pseudo relevant tweets with = 0.2.</p><p>• QUDyn: this run has a similar configuration to QUBaseline, except that the relevance threshold is updated dynamically for each profile.</p><p>• QUDynExp: this run is similar to QUDynm, but the number of expansion terms extracted from pseudo relevant tweets is set to 12. The system selects 10 expansion terms from narrative and description fields to include in profile representation and uses = ↵ = 0.3.</p><p>Table <ref type="table" coords="4,342.04,127.38,4.60,8.57" target="#tab_0">2</ref> shows the results for the push notification scenario. The score of a run is computed as an average score of all profiles over all days. It can be clearly seen that the baseline run outperforms the other runs. • QUBaselineB: is the baseline run where the system filters tweets using the initial profiles representation shown in equation 6.</p><p>• QUExpB: in this run, the system extracts the expansion terms from the top pseudo relevant tweets returned by searching the index where these terms do not overlap with the profile's title terms.</p><p>• QUFullExpB: this run is similar to QUExpB but it also expands the profile using top weighted terms obtained from the description and narrative fields of the profile. The number of top terms taken from both sources is controlled by ↵ = 0.3 and = 0.2 parameters in order to balance their influence. Additionally, the maximum number of terms in the expanded profile is set to be 20 terms.</p><p>The performance of all runs is somewhat similar, however, the baseline run has a slightly better performance. We further investigated the poor performance of runs in scenario B and discovered a bug in our system that we think is behind the bad results. We fixed this issue in the system post-TREC submission and re-ran the system. Table <ref type="table" coords="4,510.03,514.25,4.60,8.57" target="#tab_1">3</ref> shows the NDCG results of submitted runs and the post-submission results for the runs of this scenario. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">LIVEQA</head><p>The LiveQA task is introduced this year for the first time in TREC. In this track, systems are supposed to return answers to real-time questions originating from real users via a live question stream. The language for the track is English for both questions and answers.</p><p>Several restrictions are applied to the track to make it more challenging. First restriction is the maximum allowed response time, which is set to be one minute only. Second is the maximum answer length, which is set to just 1000 characters. Third is the limit on returned answers by the system, which is set to be the top retrieved ranked answer by the system. The approach we followed for this task was to implement a simple system, which can be considered as a baseline for our future work on that problem/track for next year(s). The intuition behind that approach is also simple; since the expected questions are as of same type asked on Yahoo! Answers, we chose to use only Yahoo! Answers as the source of retrieving answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Pipeline</head><p>We describe the pipeline for question answering as follows:</p><p>1. Build/get access to an archive of questions and corresponding answers. In this step, we use the question answers dataset provided by <ref type="bibr" coords="5,229.88,357.11,9.20,8.57" target="#b5">[5]</ref>.</p><p>2. Index the archived the question answer dataset.</p><p>In this step we use Lucene 4.7.0<ref type="foot" coords="5,206.47,386.39,3.65,5.48" target="#foot_1">4</ref> with stop words removal. The objective here is to search the questions answers dataset for similar questions in real time.</p><p>3. Retrieve potential answers. For a newly-asked question, we search the pre-built index to find similar question(s). Answers for similar questions are retrieved and considered as potential answers for the asked question. <ref type="bibr" coords="5,64.58,491.17,3.58,8.57" target="#b4">4</ref>. Limiting the answer size. In some cases, the size of the potential answer exceeds the 1000-character limit set by TREC LiveQA task. Therefore, we limit the number of characters to 1000 character at maximum. We truncate those answers by returning the first k sentences whose total size is less than 1000 character.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Rank the potential answers.</head><p>We used a heuristic based on some of the features defined in <ref type="bibr" coords="5,109.44,589.58,9.20,8.57" target="#b5">[5]</ref>:</p><p>• Overall Match(AM): Number of non-stop question terms matched in the complete answer.</p><p>• Answer Span(AS): The largest distance (in words) between two non-stop question words in the answer.</p><p>• Same Word Sequence(WS): The number of non-stop question words that are recognized in the same order in the answer.</p><p>We score every possible answer ai with respect to a question q as follows:</p><p>score(q, ai) = AM (q, ai)+W S(q, ai) AS(q, ai) (11) Finally, we return only the answer ai with the highest score as our retrieved answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Evaluation Measures</head><p>The evaluation for TREC LiveQA track is based on 1087 questions. These 1087 questions were judged and scored using 4-level scale:</p><p>• 4: Excellent -a significant amount of useful information, fully answers the question.</p><p>• 3: Good -partially answers the question</p><p>• 2: Fair -marginally useful information</p><p>• 1: Bad -contains no useful information for the question</p><p>• -2: the answer is unreadable (only 15 answers from all runs were judged as unreadable)</p><p>Based on the four levels labeling, the evaluation measures adopted by TREC are:</p><p>• avg-score(0-3) -average "quality" score over all queries</p><p>• succ@i+ -number of questions with i+ score (i = 1..4) divided by number of all questions</p><p>• prec@i+ -number of questions with i+ score (i = 2..4) divided by number of answered only questions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Results</head><p>We present our results as reported by TREC in table 4. The first column names the evaluation measure, the second column shows our reported results, and third column shows the average results over all submitted runs of the di↵erent participating teams in the track. We show in table 5 the breakdown of the labels given to our system. We compare our breakdown to the average reports over the participating systems in the track. These percentages are calculated using the reported succ@i+ measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Discussion</head><p>The behavior of our system was fairly expected, as we did not incorporate more sophisticated steps in the body of our pipeline. Several enhancements can be applied in many parts of the system. For example, the system we presented uses only Yahoo! Answers; this is a limiting choice since there are more sources like Google web search, Wikipedia, and Quora that can be leveraged as well. Also, the ranking function is just a heuristic. We can use a more principled way to rank the answers using a learning to rank approach. Adding enhancements to the basic system we presented here might improve the performance in the future runs of the LiveQA track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>In this work we presented the real-time systems developed for the Microblog and LiveQA Tracks at TREC-2015. The main focus of our tweet filtering systems was to experiment with di↵erent relevance threshold modes: static and dynamic thresholds. In addition, we performed expansion of interest profiles to enrich the profile representation while giving the profile's title the largest influence in order to avoid drifting from the original topic. The expansion was applied in both push notification and email digest scenarios. The results show that the runs with static thresholds and light or no expansion in both scenarios outperform the other runs on all evaluation measures. For our future work, we plan to deeply investigate the reasons behind the relatively poor performance of scenario B by running more experiments. Additionally, we plan to experiment with re-ranking the results returned by the Lucene search engine using cosine similarity in order to maintain consistency with the relevance similarity method used in scenario A.</p><p>For Live QA track, we implemented a very simple system for the question-answering task; for a given posted question, we retrieved answers to questions that are similar to the asked question but were posted in the past; we then rank those answers using a heuristic approach and return one within the limit of 1000 characters imposed by the track. The system can be considered as a baseline for our future work with many possible directions for improvements that include enriching the sources of the answers and incorporating a more principled way for ranking answers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,316.81,369.86,239.10,8.97;2,316.81,380.32,71.63,8.97"><head>2Figure 1 :</head><label>1</label><figDesc>Figure 1: An Overview of the core real-time tweet filtering system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,316.81,188.22,239.11,86.18"><head>Table 2 :</head><label>2</label><figDesc>Results for runs of the tweet push notifica-</figDesc><table coords="4,316.81,198.68,179.53,75.72"><row><cell>tion scenario</cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell>ELG</cell><cell>nCG</cell></row><row><cell cols="3">QUBaseline 0.2750 0.2347</cell></row><row><cell>QUDyn</cell><cell cols="2">0.1850 0.1762</cell></row><row><cell cols="3">QUDynExp 0.1848 0.1763</cell></row><row><cell>Scenario B:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,316.81,562.89,239.10,52.40"><head>Table 3 :</head><label>3</label><figDesc>NDCG results of the e-mail digest scenario</figDesc><table coords="4,344.95,573.84,182.82,41.45"><row><cell>Run</cell><cell cols="2">submitted runs post-TREC</cell></row><row><cell>QUBaselineB</cell><cell>0.1288</cell><cell>0.2251</cell></row><row><cell>QUExpB</cell><cell>0.1180</cell><cell>0.1954</cell></row><row><cell>QUFullExpB</cell><cell>0.1196</cell><cell>0.1811</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,59.18,63.22,494.86,85.19"><head>Table 1 :</head><label>1</label><figDesc>Summary of submitted runs for the two scenarios Scenario Run Dynamic ⌧r? Base ⌧r Expansion? # Pseudo tweets # Expansion terms</figDesc><table coords="5,59.18,83.47,460.35,64.94"><row><cell>Mobile Push Notification</cell><cell>QUBaseline QUDyn QUDynExp</cell><cell>5 X X</cell><cell>0.6 0.8 0.8</cell><cell>X X X</cell><cell>20 20 20</cell><cell>4 4 12</cell></row><row><cell></cell><cell>QUBaselineB</cell><cell>5</cell><cell>-</cell><cell>5</cell><cell>-</cell><cell>-</cell></row><row><cell>Periodic Email Digest</cell><cell>QUExpB QUFullExpB</cell><cell>5 5</cell><cell>--</cell><cell>X X</cell><cell>5 10</cell><cell>3 10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,53.80,63.22,239.10,117.65"><head>Table 4 :</head><label>4</label><figDesc>QU-Results for LiveQA task compared to the average of the submitted runs.</figDesc><table coords="6,81.41,84.63,180.81,96.24"><row><cell>Evaluation Measure</cell><cell>QU</cell><cell>Track Average</cell></row><row><cell>avg score (0-3)</cell><cell>0.256</cell><cell>0.465</cell></row><row><cell>succ@1+</cell><cell>0.995</cell><cell>0.925</cell></row><row><cell>succ@2+</cell><cell>0.163</cell><cell>0.262</cell></row><row><cell>succ@3+</cell><cell>0.070</cell><cell>0.146</cell></row><row><cell>succ@4+</cell><cell>0.023</cell><cell>0.060</cell></row><row><cell>prec@2+</cell><cell>0.164</cell><cell>0.284</cell></row><row><cell>prec@3+</cell><cell>0.070</cell><cell>0.159</cell></row><row><cell>prec@4+</cell><cell>0.023</cell><cell>0.065</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,53.80,203.17,239.11,73.82"><head>Table 5 :</head><label>5</label><figDesc>Labels of QU run for LiveQA task compared to the average of the submitted runs.</figDesc><table coords="6,67.63,224.58,208.36,52.41"><row><cell>Label</cell><cell>QU</cell><cell>Track Average</cell></row><row><cell>Excellent(4)</cell><cell>2.3%</cell><cell>6%</cell></row><row><cell>Good(3)</cell><cell>4.7%</cell><cell>8.6%</cell></row><row><cell>Fair(2)</cell><cell>9.3%</cell><cell>11.6%</cell></row><row><cell cols="2">Bad/Unrecognized(1&amp; -2) 83.7%</cell><cell>73.8%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.42,710.98,113.43,8.57"><p>https://answers.yahoo.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,58.40,710.98,107.44,8.57"><p>https://lucene.apache.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">ACKNOWLEDGMENTS</head><p>This work was made possible by NPRP grant# <rs type="grantNumber">NPRP 6-1377-1-257</rs> and NPRP grant# <rs type="grantNumber">NPRP 7-1313-1-245</rs> from the <rs type="funder">Qatar National Research Fund</rs> (a member of <rs type="funder">Qatar Foundation</rs>). The statements made herein are solely the responsibility of the authors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_w7gkp3D">
					<idno type="grant-number">NPRP 6-1377-1-257</idno>
				</org>
				<org type="funding" xml:id="_3DpnEZs">
					<idno type="grant-number">NPRP 7-1313-1-245</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,321.30,97.12,96.81,15.55" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,331.00,115.41,192.81,8.57;6,331.01,125.87,203.48,8.57;6,331.01,136.33,57.07,8.57;6,391.14,142.65,119.20,2.26;6,331.01,153.11,221.10,2.26;6,331.01,163.57,106.70,2.26;6,440.77,157.26,111.24,8.57" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,511.54,115.41,12.27,8.57;6,331.01,125.87,203.48,8.57;6,331.01,136.33,41.43,8.57">On sparsity and drift for e↵ective real-time filtering in microblogs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,391.14,142.65,119.20,2.26;6,331.01,153.11,221.10,2.26;6,331.01,163.57,101.87,2.26">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="419" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,331.00,168.71,137.14,8.57;6,331.01,185.49,216.63,2.11;6,331.01,195.95,126.20,2.11" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://github.com/lintool/twitter-tools/wiki/TREC-2015-Track-Guidelines" />
		<title level="m" coord="6,360.40,168.71,103.92,8.57">Trec 2015 track guidelines</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,331.00,201.09,181.39,8.57;6,331.01,211.55,216.40,8.57;6,331.01,222.01,115.97,8.57;6,450.05,228.33,92.38,2.26;6,331.01,238.79,220.68,2.26;6,331.01,249.25,108.42,2.26;6,442.49,242.94,111.25,8.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,469.20,201.09,43.20,8.57;6,331.01,211.55,216.40,8.57;6,331.01,222.01,100.31,8.57">Smoothing techniques for adaptive online language models: topic tracking in tweet streams</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,450.05,228.33,92.38,2.26;6,331.01,238.79,220.68,2.26;6,331.01,249.25,104.09,2.26">Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="422" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,331.00,254.39,218.68,8.57;6,331.01,264.85,143.22,8.57;6,477.29,271.17,56.65,2.26;6,331.01,281.63,28.66,2.26;6,362.74,275.31,76.68,8.57" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,512.04,254.39,37.64,8.57;6,331.01,264.85,127.88,8.57">Overview of the trec-2012 microblog track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboro↵</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboro↵</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,477.29,271.17,56.65,2.26;6,331.01,281.63,22.93,2.26">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,331.00,286.77,224.92,8.57;6,331.01,297.23,215.48,8.57;6,331.01,314.01,21.50,2.26;6,355.58,307.69,83.88,8.57" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,520.48,286.77,35.44,8.57;6,331.01,297.23,200.09,8.57">Learning to Rank Answers on Large Online QA Collections</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,331.01,314.01,16.13,2.26">ACL</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="719" to="727" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
