<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,79.81,72.35,450.09,16.84">University of Waterloo at TREC 2015 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,154.03,118.05,61.70,11.06"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
							<email>luchen.tan@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.97,118.05,81.73,11.06"><forename type="first">Adam</forename><surname>Roegiest</surname></persName>
							<email>aroegies@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.93,118.05,103.76,11.06"><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
							<email>claclark@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,79.81,72.35,450.09,16.84">University of Waterloo at TREC 2015 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2277ACE908678CAECFCD8A03E362D910</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given a topic with title, narrative and description, we start by building a language model for the topic. The top 1000 tweets were retrieved from Twitter commercial search engine by applying the title of the topic as a query. We exploit pseudo relevance feedback technologies to estimate probability distributions of each term in the topic, then comparing these probabilities with a background distribution model. We select the highest different terms as our expanded query terms. We then generate a vector for each topic, the features of the vector are non-stop word title terms, selected narrative terms and query expansion terms. Different weights are assigned to the different types of terms. Since we are allowed to deliver at most 10 tweets every day, and the latency time can not exceed 100 minutes, we solve the tweet notification scenario as a multiple-choice secretary problem. Two different solutions were tested.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>TREC 2015 Microblog Track included a completely different task from previous years, which was the real-time filtering task. The goal of this task was to monitor the real Twitter streaming data and determine whether or not to push each tweet to a user. Each user's interest profile was given in the format of a traditional TREC topic; below is an example: &lt;top&gt; &lt;num&gt; Number: MB10001 &lt;title&gt; crossword puzzle tournaments &lt;desc&gt; Description: Return announcements of and commentary regarding crossword puzzle tournaments. &lt;narr&gt; Narrative: The user likes to do crossword puzzles and intends to participate in upcoming crossword puzzle tournaments. She wants to see any Tweets that relate to a tournament: Tweets that announce a tournament or give logistical information; Tweets about a tournament from its participants including Tweets that express anticipation of the tournament or travelling to/from the tournament; Tweets that comment on the quality of a tournament; etc. &lt;/top&gt; Two task models were provided:</p><p>• Scenario A: Push notifications on a mobile phone.</p><p>Participating systems should identify interesting tweets based on the user's interest profile(topic), and determine whether or not to push a notification to the user's mobile phone. Such notification is expected to be triggered within 100 minutes after the tweet is created. A maximum of 10 tweets is allowed to be pushed by a system to a single user per day.</p><p>• Scenario B: Periodic email digest. Participating Systems should identify tweets based on the user's interest profile, and aggregate them into an email. The email should be periodically sent (i.e. every day) to the user.</p><p>Scenario A is a real-time filtering task, but it does not require an on-line decision. It means that participating systems do not need to decide whether or not push notification for a tweet before seeing the subsequent tweets. A 100minute latency time is permitted. Thus, in addition to the normal retrieval processes, the choice of pushing strategy is also significant. However, Scenario B is more like a retrieval task based on a one-day tweet collection.</p><p>In this report, we describe our algorithm, decision and strategies of solving these two tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PRE-PROCESSING TWEETS</head><p>Tweets are relative short and informally written. To better understand tweets, a tokenizer that was designed for English Twitter text was used. We applied a simple method to remove non-English tweets and partially kept retweets. No stemming or stop word removal was utilized on tweets, but tweet quality was considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Language detection and Retweets</head><p>Tweets written in a language other than English would be judged as not relevant based on guidelines of Microblog Track. To obtain only English tweets, we read the language tag for each tweet feed by the streaming API, and only kept the English ones. In addition, we remove all NON-ASCII characters from the tweets, which also helps remove non-English tweets. The treatment of retweets is different from previous years. The retweets returned will be replaced by the original tweets that were retweeted. In this case, all additional commentary in the tweets will be ignored, and created time will be considered as the original tweets' time. Thus, there will still be high risk to return a retweet given the original tweets are posted older than the retweets. In our submitted runs, we ignore all retweets in Scenario A and keep them in Scenario B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tokenizer</head><p>Our tokenizer was based on Twokenize, which is a tokenizer designed specific for English tweet text. It is part of CMU's Tweet NLP project 1 . For the hashtags, we kept the base term without the '#' symbol as a token, as well as the hashtags themselves. Since tweets are short, the tokens were treated as token set, which means each token was only counted once in each tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Tweet Quality</head><p>With a tweet quality filter, we can filter out low quality tweets and some of junk tweets. Although tweets are at most 140 characters, short tweets are hard to extract topics from. We set an arbitrary threshold to detect high quality tweets, such that, any tweet that has fewer than 5 tokens, or tweets with more than three hashtags are treated as low quality tweets. These low quality tweets will be ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">USER PROFILES</head><p>User profiles are made up of three fields: titles, descriptions and narratives. Titles contain several key words or key phrases; descriptions are one-sentence statements of the users' information needs; narratives are paragraph-length descriptions of the tweets that the users want to receive. To implement the filtering tasks, we built a term vector for each user profile, and assigned different weights to different types of terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature Vector</head><p>Titles were tokenized by space and punctuation. The stop words were removed from these tokens. Additionally, for noun tokens, derived both singular and plural forms of these noun tokens. We processed the title of each user profile, and added processed tokens to the feature vectors of this user profile. To extract important words from descriptions and narratives. we applied a pointwise K-L divergence method <ref type="bibr" coords="2,284.66,566.71,9.72,7.86" target="#b2">[2,</ref><ref type="bibr" coords="2,53.80,577.18,6.48,7.86" target="#b3">3]</ref>, which was also applied later in the process to generate expansion terms. We took all the 225 user profiles as a background model. For each user profile, description and narrative sentences were combined together as a foreground model of the profile. To discover the most significant tokens in each user profile, we calculated pointwise K-L divergence and ranked the scores for each token in the profile:</p><formula xml:id="formula_0" coords="2,147.76,656.81,141.23,7.86">pt log(pt/qt), (<label>1</label></formula><formula xml:id="formula_1" coords="2,288.99,656.81,3.92,7.86">)</formula><p>where pt is the relative frequency of term t in the profile foreground model and qt is the relative frequency of term t in the overall background model. We took the top-10 terms 1 http://www.ark.cs.cmu.edu/TweetNLP from this ranking to form a set important narrative and description terms. In the runs that used narratives and descriptions, these terms were added to the feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pseudo-Relevance Feedback</head><p>We utilized the same idea of pointwise K-L divergence to generate expansion terms from pseudo-relevance feedback. We took a large collection of historical tweets as our background model. The collection was collected through the Twitter Streaming API from November 2013 to March 2015. We restricted the collection to English-language tweets on the basis of the language field associated with each tweet. There are in total approximately 291 million tweets in the collection. To build a foreground model for each user profile, we took the title terms as query, and searched the query in Twitter search engine. The top 1000 tweets were crawled on the search result pages as our foreground model. In the top retrieved tweets, URLs in each tweet were replaced by their web page titles, if the &lt;title&gt; tag existed in the HTML source of the web pages. To keep the foreground models upto-date, we re-built the foreground models every day during the evaluation period. A ranking of terms can be generated by the scores for each term in each foreground model. We took the top-10 normal terms and top-5 hashtags from the ranking and added them to the feature vector of each profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RELEVANCE SCORING</head><p>A simple vector space model was applied to calculate relevance score between each incoming tweet and each user profile. We set arbitrary weights to different types of feature terms based on our previous experience. There were three types of feature terms: title, narrative+description, expansion. We denote types of feature terms by i = {t, n, e}, where t stands for title, n stands for narrative+description and e stands for expansion.</p><formula xml:id="formula_2" coords="2,387.15,441.55,168.77,25.11">rel = i={t,n,e} wi * Ni N t |T |<label>(2)</label></formula><p>Here, wi denotes the weight for type i and Ni stands for the number of times type i feature terms appeared in the tweet. In the denominator, we normalized the score by ratio of title terms appeared in the tweet, where |T | denotes the total number of title terms of the user profile. We assumed that the more title terms appeared in the tweet, the more relevant the tweet would be. A naive and arbitrary method of deduplicating tweets was applied, which simply the unigram token overlap between candidate and previously pushed tweets. Two tweets with over sixty percent of overlapping unigrams would be counted as similar tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">PUSH NOTIFICATION STRATEGIES</head><p>The secretary problem is a famous optimal stopping problem. The basic form is described as hiring the best secretary out of n rankable applicants for a position. The applicants are interviewed one by one and the employee has to make immediate decision after each interview. An applicant cannot be recalled once rejected. A variation problem of multiplechoice secretary problem <ref type="bibr" coords="2,422.28,679.80,9.71,7.86" target="#b1">[1,</ref><ref type="bibr" coords="2,436.33,679.80,7.16,7.86" target="#b4">4]</ref> is that up to k secretaries are allowed to be hired during the interview period. A decision need not be made immediately after each interview. But it's better to be as fast as possible. We determined the Scenario A is a instance of the multiple-choice secretary problem. Two different strategies were tested by our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Strategy #1: Fix Time Window</head><p>Under this algorithm, we returned tweets periodically. A threshold based on historical results was set for each user profile, which was the score of the top 50 th ranked tweet returned in the previous day. Every day during the evalusation period, we updated the threshold. We selected the highest score in tweet that was also higher than the threshold in every k minutes, where k was smaller than 100 minutes. Pushed tweets not be redundant were those that were not previously returned nor were they redundant. If there was not any tweet returned during a k minute window, the slot would be carried to the next k minute window. Whenever we had returned 10 tweets of the profile one day, we would stop returning for that day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Strategy #2: Dynamic Emission</head><p>Our second algorithm used two thresholds for each user profile: k0, and k1, where k0 k1. k0 was the lower bound of relevant scores for the profile. Here we made several assumptions: any tweet that had score higher than k1 was relevant to the user's information need; tweets that were scored lower than k0 was not relevant; tweets with scores between k0 and k1 were considered potentially relevant. The value of k0 and k1 were based on the scores of returned tweet in the previous day, and would be updated every night. A dynamic k minute window was used for this algorithm. Algorithm 1 shows the strategy we applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RESULTS</head><p>For Scenario A, Table <ref type="table" coords="3,142.10,559.30,4.61,7.86" target="#tab_0">1</ref> reports the performance of our three submitted runs with 95% confidence intervals and the results of conducting pairwise t-tests (where p &lt; 0.01) between all runs 2 . As it turns out, UWaterlooATEK significantly outperforms both other runs, indicating that the dynamic emission strategy was successful in identifying relevant tweets. The results for Scenario A also indicates that using all parts of the information profile may not be of benefit and their inclusion may in fact negatively impact performance. Although, this impact was not significant between UWater-looATEK and UWaterlooATNDEK. B are not all that surprising and are inline with what we observed for Scenario A. That is, inclusing of the narrative and description fields did not aid performance. Furthermore, our approach for Scenario B of returning tweets for the sake of returning tweets was likely less than ideal and we should have likely adopted a more conservative strategy as we did in Scenario A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>In this work we presented a method for doing dynamic tweet emission in a real-time scenario based upon infomration profiles. We have observed that making use of all pieces of an information profile may not be of much benefit over just using the title alone. In addition, using this dynamic tweet emission algorithm was significantly better than either other simple fixed emission solution. In spite of its relatively simple nature, the good performance of the dynamic emission strategy bodes well for future work that explores the parameter space better than we were able to do for TREC this year. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.80,55.49,502.12,113.96"><head>Table 1 :</head><label>1</label><figDesc>Results for Scenario A (push notification) for submitted runs with 95% confidence intervals. † denotes p &lt; 0.01 in a paired t-test with run UWaterlooATDK.</figDesc><table coords="3,66.99,55.49,475.75,113.96"><row><cell>Strategy</cell><cell>RunID</cell><cell></cell><cell>ELG</cell><cell>nCG</cell></row><row><cell>Title only+Dynamic Emission</cell><cell>UWaterlooATDK</cell><cell cols="2">0.3150 (0.2366 -0.3933)</cell><cell>0.2679 (0.1864 -0.3494)</cell></row><row><cell>Title only+Fix time</cell><cell>UWaterlooATEK</cell><cell cols="3">0.2654 † (0.1892 -0.3415) 0.2365 † (0.1576 -0.3154)</cell></row><row><cell cols="5">Title+Narrative+Description+Fix time UWaterlooATNDEK 0.2470 † (0.1796 -0.3144) 0.2170 † (0.1474 -0.2865)</cell></row><row><cell>Strategy</cell><cell>RunID</cell><cell></cell><cell>nDCG</cell></row><row><cell>Title only</cell><cell cols="2">UWaterlooBT</cell><cell cols="2">0.2200 (0.1684 -0.2716)</cell></row><row><cell cols="5">Title+Narrative+Description UWaterlooBTND 0.2196 (0.1682 -0.2710)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,75.73,183.39,458.25,7.89"><head>Table 2 :</head><label>2</label><figDesc>Results for Scenarion B (email digest) for submitted runs with 95% Confidence Intervals.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,53.80,684.83,239.12,34.22"><head>Table 2</head><label>2</label><figDesc>reports our results for Scenario B, which simulated an email digest of interesting tweets. The results for Scenario</figDesc><table /><note coords="3,54.25,709.42,3.65,5.24;3,58.40,711.19,200.19,7.86"><p><p>2 </p>No multiple hypothesis correction was performed.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,53.80,153.80,501.32,466.77"><head>:</head><label></label><figDesc>Streaming of tweets Result: Relevant tweets to the user profile begin max waiting ←-k mins cur time ←-now last time ←-cur time -max waiting time out ←-0 k0 ←-score of top10 tweet yesterday k1 ←-score of top5 tweet yesterday candidate ←-highest score tweet between cur time and last time with score k0 while True do curr ←-highest score tweet between now and last time with score k0 curr time ←-time of curr / * If a tweet has score greater than k1, report it immediately, and restart the waiting window. * / if curr &gt; k1 then Report curr last time ←-curr time time out ←-0 end / * If a tweet is better than the candidate tweet, replace the candidate with the current tweet, and restart the waiting window. * / else if curr candidate then candidate ←-curr last time ←-curr time time out ←-0 end / * If a tweet is worse than the candidate tweet. * / else / * Have not reached maximum waiting time, keep waiting * / if time out &lt; max waiting then time out ←-now -curr time end / * Report the candidate, which is the best one during the waiting window. Then restart the waiting window.</figDesc><table coords="4,53.80,512.62,500.92,107.95"><row><cell>* /</cell></row><row><cell>else</cell></row><row><cell>Report candidate</cell></row><row><cell>last time ←-now</cell></row><row><cell>time out ←-0</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>Algorithm 1: Dynamic Tweet Emission Algorithm</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,321.30,437.58,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,331.00,450.16,208.41,7.86;3,331.01,460.63,217.52,7.86;3,331.01,471.09,192.35,7.86;3,331.01,481.55,189.20,7.86;3,331.01,492.01,173.17,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,387.92,450.16,151.49,7.86;3,331.01,460.63,142.31,7.86">A multiple-choice secretary algorithm with applications to online auctions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,491.86,460.63,56.66,7.86;3,331.01,471.09,192.35,7.86;3,331.01,481.55,76.21,7.86">Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms</title>
		<meeting>the sixteenth annual ACM-SIAM symposium on Discrete algorithms</meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="630" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,331.00,503.46,212.59,7.86;3,331.01,513.93,224.91,7.86;3,331.01,524.39,219.59,7.86;3,331.01,534.85,194.25,7.86;3,331.01,545.31,95.34,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,434.34,503.46,109.26,7.86;3,331.01,513.93,134.21,7.86">Succinct queries for linking and tracking news in social media</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,484.09,513.93,71.83,7.86;3,331.01,524.39,219.59,7.86;3,331.01,534.85,164.25,7.86">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1883" to="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,331.00,556.76,187.73,7.86;3,331.01,567.23,223.39,7.86;3,331.01,577.69,188.75,7.86;3,331.01,588.15,213.21,7.86;3,331.01,598.61,224.91,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,446.13,556.76,72.61,7.86;3,331.01,567.23,132.97,7.86">A language model approach to keyphrase extraction</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tomokiyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,482.46,567.23,71.93,7.86;3,331.01,577.69,188.75,7.86;3,331.01,588.15,141.74,7.86">Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment</title>
		<meeting>the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,331.00,610.06,159.34,7.86;3,331.01,620.53,194.13,7.86;3,331.01,630.99,210.70,7.86;3,331.01,641.45,204.05,7.86;3,331.01,651.91,220.41,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,431.49,610.06,58.86,7.86;3,331.01,620.53,158.33,7.86">Online retweet recommendation with item count limits</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,507.48,620.53,17.65,7.86;3,331.01,630.99,210.70,7.86;3,331.01,641.45,22.16,7.86">Web Intelligence (WI) and Intelligent Agent Technologies (IAT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
