<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.72,72.36,374.28,16.84">Overview of the TREC-2015 Microblog Track</title>
				<funder ref="#_Dx69pMC">
					<orgName type="full">U.S. National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council of Canada</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,99.16,115.20,52.12,14.80"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<email>jimmylin@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,163.58,115.20,57.80,14.80"><forename type="first">Miles</forename><surname>Efron</surname></persName>
							<email>mefron@illinois.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Urbana-Champaign</orgName>
								<orgName type="institution">University of Illinois</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,234.17,115.20,53.19,14.80"><forename type="first">Yulu</forename><surname>Wang</surname></persName>
							<email>ylwang@cs.umd.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,301.64,115.20,87.39,14.80"><forename type="first">Garrick</forename><surname>Sherman</surname></persName>
							<email>gsherma2@illinois.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Urbana-Champaign</orgName>
								<orgName type="institution">University of Illinois</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,426.29,115.20,80.11,14.80"><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
							<email>ellen.voorhees@nist.gov</email>
							<affiliation key="aff3">
								<orgName type="institution">NIST</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.72,72.36,374.28,16.84">Overview of the TREC-2015 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC6BCFFB9428EBC3DE914C7D31505EC1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The TREC 2015 Microblog track introduced a single realtime filtering task broken down into two scenarios. Our goal is to explore techniques for monitoring streams of social media posts with respect to users' interest profiles. An interest profile describes a topic about which the user wishes to receive information updates in real time, and is different from a typical ad hoc topic in that the profile represents a prospective (as opposed to a retrospective) information need. Thus, the nature of the desired information is qualitatively different. In real-time filtering, the goal is for a system to "push" (i.e., recommend, suggest) interesting and novel content to users in a timely fashion.</p><p>We operationalized this task in terms of two scenarios:</p><p>• Scenario A (push notification): Content that is identified as interesting and novel by a system based on the user's interest profile might be shown to the user as a notification on his or her mobile phone. The expectation is that such notifications are triggered a relatively short time after the content is generated. • Scenario B (email digest): Content that is identified as interesting and novel by a system based on the user's interest profile might be aggregated into an email digest that is periodically sent to a user (e.g., nightly). It is assumed that each item of content is relatively short; one might think of these as "personalized headlines".</p><p>In both scenarios, it is assumed that the content items delivered to the users are relatively short. For expository convenience and to adopt standard information retrieval parlance, we write of users desiring relevant content, even though "relevant" in our context might be better operationalized as interesting, novel, and timely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EVALUATION DESIGN 2.1 General Setup</head><p>Although we are interested in exploring filtering techniques over streams of social media posts in general, the Microblog track restricted the content under consideration to tweets. In particular, Twitter provides a streaming API through which clients can obtain a sample (approximately 1%) of public tweets-this level of access is available to anyone who signs up for an account.</p><p>During the official evaluation period, which began Monday, July 20, 2015, 00:00:00 UTC and lasted until Wednesday, July 29, 2015, 23:59:59 UTC, participants' systems "lis-tened" to Twitter's live tweet sample stream to identify relevant tweets with respect to users' interest profiles. The identified tweets were recorded by the participants' systems and submitted to NIST shortly after the conclusion of the evaluation period. Although systems were expected to conform to the temporal constraints imposed by the task scenarios (more details below), there was no enforcement mechanism because of the batch submission setup.</p><p>An important consequence of the evaluation setup is that, unlike in most TREC evaluations, no collection was distributed ahead of time. Since each participant "listened" to tweets from Twitter's streaming API, the collection was generated in real-time and delivered to each participant independently. In a separate pilot study <ref type="bibr" coords="1,476.75,346.00,9.22,7.92" target="#b5">[5]</ref>, we verified that multiple listeners to the public Twitter sample stream receive effectively the same tweets (Jaccard overlap of 0.999 across six independent crawls over a three day sample in March 2015). For evaluation purposes (i.e., pool formation for judgments) the stream collected by the organizers was arbitrarily designated as the "official" collection.</p><p>Another substantial departure from most previous TREC evaluations is the requirement that participants maintain a running system that continuously monitors the tweet sample stream during the evaluation period. The track organizers provided boilerplate code and reference implementations, but it was the responsibility of each individual team to run its own system and cope with crashes, network glitches, power outages, etc.</p><p>Additional details for each of the task scenarios are provided below:</p><p>• Scenario A (push notification): A system for this scenario (a "type A" system) is allowed to return a maximum of ten tweets per day per interest profile (and of course may choose to return fewer than ten tweets). Each day of the evaluation is defined in terms of the time range 00:00:00 to 23:59:59 UTC. Additional tweets beyond ten per day are simply ignored in computing evaluation metrics. Given the real-time nature of the task, each system was asked to record the time at which a tweet was putatively delivered as a push notification; this information is used to compute a latency penalty (more details later).</p><p>The per-day tweet delivery limit represents a crude attempt to model user fatigue in mobile push notifications. Note, however, that in this design we are not modeling real-world constraints such as "don't send users notifications in the middle of the night". This simplification is intentional.</p><p>• Scenario B (email digest). A system for this scenario (a "type B" system) is tasked with identifying a batch of up to 100 ranked tweets per day (per interest profile). In our task model, these tweets are delivered to the user daily. For simplicity, all tweets from 00:00:00 to 23:59:59 UTC are valid candidates for a particular day. It is expected that systems will compute the results in a relatively short amount of time after the day ends (e.g., at most a few hours), but this constraint was not enforced.</p><p>It is worth mentioning that despite superficial similarities, our task is very different from document filtering in the context of earlier TREC Filtering tracks, which ran from 1995 <ref type="bibr" coords="2,74.42,206.45,9.73,7.92" target="#b3">[3]</ref> to 2002 <ref type="bibr" coords="2,117.35,206.45,9.22,7.92">[6]</ref>, and the general research area of topic detection and tracking (TDT) <ref type="bibr" coords="2,167.43,216.91,9.22,7.92" target="#b1">[1]</ref>. The TREC Filtering tracks are best understood as binary classification on every document in the collection with respect to standing queries, and TDT is similarly concerned with identifying all documents related to a particular event-with an intelligence analyst in mind. In contrast, we are focused on identifying a small set of the most relevant updates to deliver to users. Furthermore, in both TREC Filtering and TDT, systems must make online decisions as soon as documents arrive. In our case, systems can choose to push older content (subjected to the latency penalty), thus giving rise to the possibility of algorithms operating on bounded buffers. Finally, previous evaluations merely simulated the streaming nature of the document collection, whereas participants in our evaluation actually operated on tweets posted in real time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Run Submission</head><p>In both scenarios, systems were asked to only consider tweets in English. Each team was allowed to submit up to three runs for scenario A and three runs for scenario B. Systems for either scenario were categorized into three different types based on the amount of human involvement:</p><p>• Automatic Runs: In this condition, system development (including all training, system tuning, etc.) must conclude prior to downloading the interest profiles from NIST (which were made available before the evaluation period). The system must operate without human input before and during the evaluation period. Note that it is acceptable for a system to perform processing on the profiles (for example, query expansion) before the evaluation period, but such processing cannot involve human input.</p><p>• Manual Preparation: In this condition, the system must operate without human input during the evaluation period, but human involvement is acceptable before the evaluation period (i.e., after downloading the interest profile). Examples of manual preparation include human examination of the interest profiles to add query expansion terms or manual relevance assessment on a related collection to train a classifier. However, once the evaluation period begins, no further human involvement is permissible.</p><p>• Manual Intervention: In this condition, there are no limitations on human involvement before or during the evaluation period. Crowd-sourcing judgments, humanin-the-loop search, etc. are all acceptable.</p><p>Participants were asked to designate the run type at submission time. All types of systems were welcomed; in particular, manual preparation and manual intervention runs are helpful in understanding human performance and enriching the judgment pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Interest Profiles</head><p>Our initial idea was to develop interest profiles that consisted of short English statements of information needs and a few example tweets. Upon further reflection, the history of previous TREC Filtering tracks suggested that this approach would have been problematic. The initial effectiveness of filtering systems is quite poor as the systems need to retrieve at least some non-relevant documents to learn to distinguish between relevant and non-relevant cases. Since there was no possibility of providing assessor feedback in the track setup this year and the few example tweets were guaranteed to be an incomplete, highly-biased sample of relevant tweets, systems would get caught in this initial effectiveness "trough" since they lack guidance in the form of incremental relevance judgments.</p><p>Instead, we adopted the "standard" TREC topic format of "title", "description", and "narrative" for the interest profiles. The so-called title consists of two to three keywords that provide the gist of the information need, akin to something a user might type into the query box of a search engine. The description is a one-sentence statement of the information need, and the narrative is a paragraph-length chunk of prose that sets the context of the need and expands on what makes a tweet relevant. By necessity, these interest profiles are more generic than the needs expressed in typical retrospective topics because the topic developer does not know what future events will occur. Thus, despite superficial similarities in format, we believe that interest profiles are qualitatively different from ad hoc topics.</p><p>Three sample profiles were released to participants prior to the evaluation period and were also provided to the NIST assessors as templates for profile development. Assessors were not required to use the samples as templates; they could (and did) use their own ideas as well. Assessors also performed web searches to find events that would happen during the evaluation period and constructed profiles targeting those events. Since profile development happened long before the evaluation period, we could not know which interest profiles would ultimately be appropriate for evaluationwe desired profiles that had neither too many nor too few relevant tweets (since the former would cause excessive evaluation burden and the latter would complicate system development). Thus, we created many (225) profiles as the test set, with the intention of culling a smaller set of around 50 profiles as the evaluation set.</p><p>Contrary to expectations, pooling statistics (how many documents retrieved per run, how much overlap in the retrieved sets across runs, etc.) did not provide any signal as to which profiles should be included in the evaluation set. We examined the statistics for a profile that could not possibly have any relevant tweets (terrorist activity on Bastille day; there wasn't any such activity) and could not distinguish that profile from the statistics for other profiles. During the evaluation, NIST (manually) monitored the news looking for stories that matched the interest profiles and was able to identify 12 profiles that definitely did have activity during the evaluation period (but not necessarily in the tweet stream); these profiles were added to the evaluation set. Beyond that, assessors were simply asked to pick profiles to judge from the set they had created based on their own interests. In the end, 51 interest profiles were judged. Of those, four have zero relevant tweets, and 47 have three or more relevant tweets. The largest number of relevant tweets is 1543, though the next largest is 583; a total of six profiles have more than 300 relevant tweets. We specifically retained profiles with no relevant tweets in the final evaluation set to test systems' ability to recognize and handle information needs with no relevant content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Judgments and Metrics</head><p>The assessment workflow was modeled after the TREC 2014 Microblog track <ref type="bibr" coords="3,140.56,204.46,9.73,7.92" target="#b4">[4]</ref> and proceeded in two major stages: relevance assessment and semantic clustering.</p><p>Relevance assessments were performed using pooling with a single pool across both scenario A and scenario B runs. Scenario A runs contributed a maximum of ten tweets per day to the pools; while this should have been their 'entirety', some systems returned (many) more than this limit (contrary to track guidelines). Scenario B runs contributed no more than 85 documents for each interest profile; tweets were added to the judgment pool in a round-robin fashion across days. That is, the top-ranked tweet from each day was first added to the pool, then the second-ranked tweet from each day, and so on. If we ran out of tweets from a particular day before the 85 limit had been reached, tweets were selected from the remaining days until the limit.</p><p>This year, NIST assessors judged tweets in chronological order in the pools, not clustered by textual similarity as in previous years. 1 Each tweet was independently assessed on a three-way scale of "not relevant", "relevant", and "highly relevant". Non-English tweets were marked as not relevant by fiat. If a tweet contained a mixture of English and non-English content, discretion was left to the assessor. As with previous TREC Microblog evaluations, assessors examined links embedded in tweets, but did not explore any additional external content beyond those.</p><p>After the NIST assessors conducted relevance judgments using the pooling procedure described above, six assessors at the University of Illinois, Urbana-Champaign (graduate students in Library and Information Science) proceeded to perform semantic clustering on the relevant tweets using the protocol from the tweet timeline generation (TTG) task from the TREC 2014 Microblog track <ref type="bibr" coords="3,216.46,528.74,9.73,7.92" target="#b4">[4,</ref><ref type="bibr" coords="3,230.77,528.74,6.49,7.92" target="#b7">7]</ref>. While it is not ideal that the tweets were clustered by a different group of assessors than those who performed the relevance assessments (just like last year), this was a necessary compromise due to NIST resource limitations.</p><p>The TTG protocol was specifically designed to reward novelty (or equivalently, to penalize redundancy) in system output. In both scenario A and scenario B, we assume that users would not want to see multiple tweets that "say the same thing", and thus the evaluation methodology should reward systems that eliminate redundant output. Following the TREC 2014 Microblog track, we operationalized redundancy as follows: for every pair of tweets, if the chronologically later tweet contains substantive information that is not present in the earlier tweet, the later tweet is considered novel; otherwise, the later tweet is redundant with respect 1 However, the assessors indicated that they would have preferred textual similarity clustering after the fact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grade Description</head><p>0 not relevant 1 relevant 2 highly relevant -1 not relevant (propagated) 3 relevant (propagated) 4 highly relevant (propagated)</p><p>Table <ref type="table" coords="3,391.22,142.03,4.13,8.02">1</ref>: Interpretation of qrels.</p><p>to the earlier one. In our definition, redundancy and novelty are antonyms, so we use them interchangeably but in opposite contexts. Due to the temporal constraint, redundancy is not symmetric. If tweet A precedes tweet B and tweet B contains substantively similar information found in tweet A, then B is redundant with respect to A, but not the other way around. We also assume transitivity. Suppose A precedes B and B precedes C: if B is redundant with respect to A and C is redundant with respect to B, then by definition C is redundant with respect to A.</p><p>In the TTG protocol, relevant tweets (from the judgment pool) for an interest profile were presented to a human assessor (from UIUC) in chronological order inside a JavaScript annotation interface. For each tweet, the assessor can add it to an existing cluster of semantically equivalent tweets or create a new cluster. Thus, the output of the assessment process (for each interest profile) is a list of clusters where tweets in each cluster represent a semantic equivalence class. Within each cluster, the earliest tweet is novel; all subsequent tweets are redundant with respect to all earlier tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Treatment of Retweets</head><p>In previous TREC Microblog tracks, retweets were treated as not relevant by fiat. A consequence of this decision is that systems are not able to effectively take advantage of the retweet signal (i.e., number of retweets). If retweets are considered not relevant and a system observes a highlyretweeted tweet, the original underlying tweet must be part of the sample stream to be a valid result. This is unlikely due to sampling. Thus, in this year's evaluation, retweets were treated the same as any other tweet. Note that for retweets, the temporal penalty (detailed later) is computed with respect to the tweet itself, not the underlying tweet that was retweeted. To be clear, if A is a retweet of B, and the system returns tweet A, the temporal penalty is computed based on the timestamp of A, not B.</p><p>To reduce the sparsity of relevance judgments, we performed label propagation on the retweets as follows: First, the judgment of the retweet was propagated to the underlying tweet that was retweeted. Thus, if an assessor judged tweet t1 and t1 is a retweet of tweet s1 (with or without additional commentary), then s1 received the judgment of t1. This label was then propagated to all other retweets of that tweet; that is, other tweets t2, t3, t4, . . . that were also retweets of s1 received its label. In cases where this label propagation yielded conflicts, we took the most common label, and in the case of ties, we broke them in favor of the higher relevance grade. The interpretation of the "relevance grade" in the official qrels file (i.e., the third column) is shown in Figure <ref type="figure" coords="3,395.59,700.67,3.58,7.92">1</ref>. In total, propagation of retweets led to an additional 2042 judgments across 25 interest profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Scenario A Metrics</head><p>To assess scenario A runs, we compute two temporallydiscounted gain measures (explained in detail below) for each interest profile for each day in the evaluation period. The score for an interest profile is the average of the daily scores in the evaluation period. The score of a run is the average of the scores across all interest profiles.</p><p>The first (and primary) metric is expected latency-discounted gain (ELG) adapted from the TREC temporal summarization track <ref type="bibr" coords="4,123.47,154.22,9.22,7.92" target="#b2">[2]</ref>:</p><formula xml:id="formula_0" coords="4,151.59,168.79,141.31,19.80">1 N G(t)<label>(1)</label></formula><p>where N is the number of tweets returned and G(t) is the gain of each tweet:</p><p>• Not relevant tweets receive a gain of 0.</p><p>• Relevant tweets receive a gain of 0.5.</p><p>• Highly-relevant tweets receive a gain of 1.0.</p><p>As with the TTG task, once a tweet from a cluster is retrieved, all other tweets from the same cluster automatically become not relevant. This penalizes systems for returning redundant information. Furthermore, a latency penalty is applied to all tweets, computed as MAX(0, (100-d)/100), where the delay d is the time elapsed (in minutes, rounded down) between the tweet creation time and the putative time the tweet was delivered. That is, if the system delivers a relevant tweet within a minute of the tweet being posted, the system receives full credit. Credit decays linearly such that after 100 minutes, the system receives no credit even if the tweet is relevant. Lacking any empirical guidance, the linear decay and the 100 minute threshold represented arbitrary decisions made by the organizers.</p><p>The second metric is normalized cumulative (nCG):</p><formula xml:id="formula_1" coords="4,152.07,435.46,136.91,19.80">1 Z G(t) (<label>2</label></formula><formula xml:id="formula_2" coords="4,288.98,441.26,3.93,7.92">)</formula><p>where Z is the maximum possible gain (given the ten tweet per day limit). The gain of each individual tweet is computed as above. Note that gain is not discounted (as in nDCG) because the notion of document ranks is not meaningful in this context. Finally, for both ELG and nCG, we handle days in which there are no relevant tweets as a special case, which we detail in Section 2.4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Scenario B Metric</head><p>Scenario B runs were evaluated in terms of nDCG as follows: for each interest profile, the list of tweets returned per day is treated as a ranked list and from this nDCG@10 is computed. Note that in this scenario, the evaluation metric does include gain discounting because the email digests can be interpreted as ranked lists of tweets. The score of an interest profile is the average of the nDCG@10 scores across all days in the evaluation period, and the score of the run is the average over all profiles. See additional discussion below for scoring days without any relevant tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.4">Additional Details and Corner Cases</head><p>For simplicity, the TTG clustering protocol was applied to all tweets for a particular interest profile across the entire evaluation period (as opposed to each day separately). Thus, it is possible that a cluster spans multiple days. However, if tweet t1 and tweet t2 are in the same cluster, but different days, t2 is still considered redundant if a run has already returned t1.</p><p>Due to the setup of the task and the nature of interest profiles, it is possible (and indeed observed empirically) that for some days, no relevant tweets appear in the judgment pool. In terms of evaluation metrics, a system should be rewarded for correctly identifying this case and not generating any output. We can break down scoring for scenario A (both ELG and nCG) and scenario B as follows.</p><p>If there are relevant tweets for a particular day:</p><p>. . . and the system returns zero tweets: the system receives a score of zero. . . . and the system returns any number of tweets: the score is computed normally per above.</p><p>If there are no relevant tweets for that day:</p><p>. . . and the system returns zero tweets: the system receives a score of one (i.e., perfect score). . . . and the system returns any number of tweets: the system receives a score of zero.</p><p>This means that an empty run that never returns anything may have a non-zero score.</p><p>It is not clear if this treatment appropriately captures the task model for the purpose of guiding system development. On the one hand, push notifications are associated with high cognitive effort since they may interrupt the user. From that perspective, we should reward systems for not generating spurious output. On the other hand, on a day for which there are no relevant tweets, the only possible scores are one or zero. Having such highly binarized scores creates many issues for system tuning since it creates discontinuities in the objective. We have no guidance on how to properly balance these two competing concerns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RESULTS</head><p>In total, we received 37 runs from 14 groups for scenario A and 42 runs from 16 groups for scenario B. Scenario A results are shown in Table <ref type="table" coords="4,421.09,496.74,4.61,7.92">2</ref> and scenario B results are shown in Table <ref type="table" coords="4,351.69,507.21,3.58,7.92">3</ref>. For reference, an empty run that does not return anything receives an ELG score of 0.2471 and an NCG score of 0.2471.</p><p>Figure <ref type="figure" coords="4,355.25,538.59,4.61,7.92">1</ref> shows a heatmap of the distribution of all relevant and highly-relevant tweets: each column corresponds to an interest profile and each row corresponds to a day in the evaluation period. For this visualization, we left out propagated retweets. Figure <ref type="figure" coords="4,412.52,580.43,4.61,7.92" target="#fig_0">2</ref> is organized in the same manner, but we only show the first tweet in each cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSIONS</head><p>To our knowledge, the TREC Microblog track in 2015 represented the first attempt by the information retrieval community to operationalize push notification and email digest into a concrete task to facilitate multi-system comparisons. Overall, this has been a good learning experience for us and the participants.</p><p>Next year, the Microblog track will merge with the Temporal Summarization track to form the Real-Time Summarization (RTS) track at TREC 2016. The creation of  RTS was designed to leverage synergies between the two tracks in exploring prospective information needs over document streams containing novel and evolving information.</p><p>By "joining forces", we plan to develop more refined push notification and email digest tasks, along with associated evaluation infrastructure to support online user-in-the-loop evaluations. Our hope is that these activities will grow the research community and push forward the state of the art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,53.80,322.74,502.11,8.02;5,53.80,333.20,142.00,8.02"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Heatmap of the distribution of the first tweet in each semantic cluster: interest profiles in columns, days of the evaluation in rows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,51.72,54.76,504.19,249.44"><head>Heatmap of the distribution of all relevant and highly-relevant tweets (leaving out retweet propa- gation): interest profiles in columns, days of the evaluation in rows.</head><label></label><figDesc></figDesc><table coords="5,51.72,54.76,499.48,249.44"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Topics</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">226</cell><cell>227</cell><cell>228</cell><cell>236</cell><cell>242</cell><cell>243</cell><cell>246</cell><cell>248</cell><cell>249</cell><cell>253</cell><cell>254</cell><cell>255</cell><cell>260</cell><cell>262</cell><cell>265</cell><cell>267</cell><cell>278</cell><cell>284</cell><cell>287</cell><cell>298</cell><cell>305</cell><cell>324</cell><cell>326</cell><cell>331</cell><cell>339</cell><cell>344</cell><cell>348</cell><cell>353</cell><cell>354</cell><cell>357</cell><cell>359</cell><cell>362</cell><cell>366</cell><cell>371</cell><cell>377</cell><cell>379</cell><cell>383</cell><cell>384</cell><cell>389</cell><cell>391</cell><cell>392</cell><cell>400</cell><cell>401</cell><cell>405</cell><cell>409</cell><cell>416</cell><cell>419</cell><cell>432</cell><cell>434</cell><cell>439</cell><cell>448</cell></row><row><cell></cell><cell></cell><cell>2015/07/20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/21</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/22</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/23</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Days</cell><cell>2015/07/24 2015/07/25</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/26</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/27</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/28</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2015/07/29</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Figure 1: 226</cell><cell cols="2">227</cell><cell>228</cell><cell>236</cell><cell>242</cell><cell>243</cell><cell>246</cell><cell>248</cell><cell>249</cell><cell>253</cell><cell>254</cell><cell>255</cell><cell>260</cell><cell>262</cell><cell>265</cell><cell>267</cell><cell>278</cell><cell>284</cell><cell>287</cell><cell>298</cell><cell>305</cell><cell>324</cell><cell>326</cell><cell>331</cell><cell cols="3">339 Topics 344 348</cell><cell>353</cell><cell>354</cell><cell>357</cell><cell>359</cell><cell>362</cell><cell>366</cell><cell>371</cell><cell>377</cell><cell>379</cell><cell>383</cell><cell>384</cell><cell>389</cell><cell>391</cell><cell>392</cell><cell>400</cell><cell>401</cell><cell>405</cell><cell>409</cell><cell>416</cell><cell>419</cell><cell>432</cell><cell>434</cell><cell>439</cell><cell>448</cell></row><row><cell></cell><cell cols="2">2015/07/20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/21</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/22</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/23</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Days</cell><cell cols="2">2015/07/24 2015/07/25</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/26</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/27</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/28</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">2015/07/29</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">ACKNOWLEDGMENTS</head><p>This work was supported in part by the <rs type="funder">U.S. National Science Foundation</rs> under IIS-1217279, IIS-1218043, and <rs type="grantNumber">CNS-1405688</rs>. Additional support was provided by the <rs type="funder">Natural Sciences and Engineering Research Council of Canada</rs>. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Dx69pMC">
					<idno type="grant-number">CNS-1405688</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="5,58.28,557.32,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,68.01,572.15,213.03,7.92;5,68.01,582.61,179.35,7.92;5,68.01,593.08,187.38,7.92" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,105.77,572.15,175.27,7.92;5,68.01,582.61,101.44,7.92">Topic Detection and Tracking: Event-Based Information Organization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,68.01,604.53,200.43,7.92;5,68.01,614.99,208.29,7.92;5,68.01,625.45,213.87,7.92;5,68.01,635.91,198.24,7.92;5,68.01,646.38,152.29,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,186.94,614.99,89.36,7.92;5,68.01,625.45,123.14,7.92">TREC 2014 Temporal Summarization Track overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,209.89,625.45,71.99,7.92;5,68.01,635.91,198.24,7.92;5,68.01,646.38,20.95,7.92">Proceedings of the Twenty-Third Text REtrieval Conference (TREC 2014)</title>
		<meeting>the Twenty-Third Text REtrieval Conference (TREC 2014)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,68.01,657.83,184.41,7.92;5,68.01,668.29,211.76,7.92;5,68.01,678.75,210.33,7.92;5,68.01,689.21,20.99,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,121.69,657.83,114.98,7.92">The TREC-4 Filtering Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,68.01,668.29,211.76,7.92;5,68.01,678.75,39.30,7.92">Proceedings of the Fourth Text REtrieval Conference (TREC-4)</title>
		<meeting>the Fourth Text REtrieval Conference (TREC-4)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="165" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,68.01,700.67,222.20,7.92;5,68.01,711.13,217.24,7.92;5,331.02,362.94,213.52,7.92;5,331.02,373.40,152.29,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,252.55,700.67,37.65,7.92;5,68.01,711.13,141.73,7.92">Overview of the TREC-2014 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sherman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,228.55,711.13,56.70,7.92;5,331.02,362.94,213.52,7.92;5,331.02,373.40,20.95,7.92">Proceedings of the Twenty-Third Text REtrieval Conference (TREC 2014)</title>
		<meeting>the Twenty-Third Text REtrieval Conference (TREC 2014)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.02,384.86,202.23,7.92;5,331.02,395.32,217.88,7.92;5,331.02,405.78,190.67,7.92;5,331.02,416.24,201.98,7.92;5,331.02,426.70,119.10,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,422.41,384.86,110.84,7.92;5,331.02,395.32,217.88,7.92">Do multiple listeners to the public twitter sample stream receive the same tweets?</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,342.54,405.78,179.16,7.92;5,331.02,416.24,201.98,7.92;5,331.02,426.70,24.19,7.92">Proceedings of the SIGIR 2015 Workshop on Temporal, Social and Spatially-Aware Information Access</title>
		<meeting>the SIGIR 2015 Workshop on Temporal, Social and Spatially-Aware Information Access<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.02,438.16,224.89,7.92;5,331.02,448.62,198.13,7.92;5,331.02,459.08,206.02,7.92;5,331.02,469.54,65.56,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,451.60,438.16,104.31,7.92;5,331.02,448.62,49.39,7.92">The TREC 2002 Filtering Track report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,398.92,448.62,130.23,7.92;5,331.02,459.08,143.31,7.92">Proceedings of the Eleventh Text REtrieval Conference (TREC 2002)</title>
		<meeting>the Eleventh Text REtrieval Conference (TREC 2002)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,331.02,481.00,218.30,7.92;5,331.02,491.46,197.39,7.92;5,331.02,501.92,183.62,7.92;5,331.02,512.38,223.54,7.92;5,331.02,522.84,214.77,7.92;5,331.02,533.30,150.83,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,515.57,481.00,33.75,7.92;5,331.02,491.46,197.39,7.92;5,331.02,501.92,40.52,7.92">Assessor differences and user preferences in tweet timeline generation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,390.18,501.92,124.46,7.92;5,331.02,512.38,223.54,7.92;5,331.02,522.84,210.58,7.92">Proceedings of the 38th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2015)</title>
		<meeting>the 38th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2015)<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="615" to="624" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
