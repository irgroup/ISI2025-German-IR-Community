<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.47,116.95,328.41,12.62">TREC 2016 Dynamic Domain Track Overview</title>
				<funder ref="#_P8kQnzu #_qWURQpb">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_gWyTHH5 #_UfFrKdv">
					<orgName type="full">DARPA</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.09,154.69,70.11,8.74"><forename type="first">Grace</forename><forename type="middle">Hui</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,327.36,154.69,53.44,8.74"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
							<email>ian.soboroff@nist.gov</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.47,116.95,328.41,12.62">TREC 2016 Dynamic Domain Track Overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B5C13F4FC99D830867E7C7527533B6DB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The main goal of TREC dynamic domain track is to explore and evaluate systems for interactive information retrieval, which reflects real-world search scenarios. Due to the importance of learning from user interactions, this track has been held for the second year. The name of the track contains two parts. "Dynamic" means that the search system dynamically adapts the provided ranking to the user through interactions. "Domain" stems from the fact that the search task in the track is on the domains of special interests, which tend to bring information needs that would not be met within a single interaction. The task is inspired by interested groups in government, including the DARPA Memex program. 3  Each search task in the DD track involves some interactions between a user and a search system. In the first iteration, the user submits a query and the target domain of interest to the search system. The system provides the user with an initial ranking of documents, and receives feedback from the user on the provided ranking. This interaction, providing the user with a ranking and receiving the user's feedback, continues until the search system stops the search task. The DD track introduces a new challenging search problem with the following important assumptions.</p><p>1. The DD task is an interactive search task, where the search system needs to dynamically adapt its ranking based on users' feedback. 2. During the search session, the user does not provide a new formulation of his/her information need. 3. The user provides fine-grained feedback information on a received list of documents, in which the passages of the retrieved documents that are relevant to his/her information need are specified. In addition, user's feedback indicates that passages of interest are relevant to which subtopic of the query with graded relevance degrees. 4. The search system is required to stop the search task when the user is provided with enough information regarding all aspects of his/her information need.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>These new settings of the search task in the DD track are motivated by professional search tasks such as finding a criminal network, or finding prior art for a patent application. In addition, the DD track emphasizes on finer-grained relevance judgments compared to open domain Web searches, since professional users have stringent relevancy requirements best expressed at the passage level rather than the whole document level.</p><p>To simulate the above defined search process, the DD track provided two newly-created corpora on specific Ebola and Polar domains. In addition, a system that simulates users' feedback based on fine-grained relevance judgment information provided for the query sets, is developed specifically for the task.</p><p>A total of 6 groups participated in the track this year, a slight decrease from last year, when 7 groups participated. One submitted run by the group from the RMIT university is marked as a manual run by the participants, which provides an interesting baseline for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dynamic Domain Track</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dynamic Domain Task Description</head><p>The dynamic domain task simulates an interactive search process, where the search system tries to dynamically adapt its ranking based on the user's feedback obtained in previous interactions.</p><p>At the first iteration, the search system receives an initial query for each topic. In response to that query, the system may present up to five documents to the user. The system then receives feedback only on the presented documents in a form that indicates which passages of the retrieved documents are relevant to the topic, and specifically to which subtopic of the topic along with the graded relevance degree. The DD Track emphasizes on finer-grained relevance judgment because professional users have stringent relevancy requirements best expressed at the passage level rather than the whole document level. Note that although feedback information provides relevance status regarding subtopics of the query, the total number of subtopics of a topic is not given to the search system in the beginning of a search session nor during the interactions with the user through feedback. Receiving feedback from the user, the search system decides whether to stop the interaction, or continues by providing the user an updated list of at most 5 documents. The two possible actions of the search system shows two points. The first point is that the search system is supposed to stop search sessions when sufficient information regarding all subtopics of a query is presented to the user. Based on this, one evaluation metric measures the speed of providing relevant documents to the user. The second point is that the search system needs to adopt received feedback in previous iterations to provide more effective results to the user in the next iteration.</p><p>The users' feedback is simulated by a system called Jig. <ref type="foot" coords="2,389.54,615.55,3.97,6.12" target="#foot_1">4</ref> The search systems interact with Jig, and receive feedback on retrieved documents at each iteration. The Jig system provides relevance information in the form described above only when relevance information on given documents is available. In contrast to the traditional TREC interpretation of judgments, no feedback on a document does not mean that the document is irrelevant to the query. This setting makes using of negative feedback challenging. The participants were supposed to develop an adapting search system. The Track looks forward to systems that are able to make educated guesses for later queries based on early feedback from the user, so that the entire search process can be sped up. Further, the Track expects the search system, not the user, to decide when to stop the search. This requires the search systems to just provide the right amount of information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Datasets and Domains</head><p>The TREC DD track provides two domains of documents; Ebola and Polar. Table <ref type="table" coords="3,162.65,657.11,4.98,8.74" target="#tab_0">1</ref> reports the statistics of the two domains. All the datasets are format- ted using the Common Crawl Architecture schema from the DARPA MEMEX project, and stored as sequences of CBOR objects. To find more details about the datasets, please refer to <ref type="bibr" coords="4,254.45,423.91,9.96,8.74">[1]</ref>. There are 53 topics in total. One sample of topics is shown in Listing 1.1. For each topic, there is relevance judgment information on the passage level as shown in Listing 1.2. Following, the process of assessing documents and passages is described.</p><p>Topic and Assessment Development The topics were developed by six NIST assessors over five weeks in the spring of 2016. A topic (which is like a query) contains a few words. It is the main search target for the dynamic search process. Each topic contains multiple subtopics, each of which addresses one aspect of the topic. Each subtopic contains multiple relevant passages that the assessors discovered from across the entire corpus. Each passage is tagged with a grade to mark how relevant it is to the subtopic. We treat the obtained set of passages as the complete set of relevant passages and use them in the evaluation.</p><p>The NIST assessors were asked to produce a complete set of subtopics for each topic using an annotation tool (Fig. <ref type="figure" coords="4,288.29,614.86,3.87,8.74" target="#fig_1">1</ref>). The tool provides five retrieval algorithms to compensate each other, which include the default search algorithms in Lemur<ref type="foot" coords="4,476.12,625.24,3.97,6.12" target="#foot_2">5</ref>  , Solr<ref type="foot" coords="5,158.55,369.70,3.97,6.12" target="#foot_3">6</ref> and Terrier<ref type="foot" coords="5,216.44,369.70,3.97,6.12" target="#foot_4">7</ref> (Circle 1 in Fig. <ref type="figure" coords="5,299.75,371.27,3.87,8.74" target="#fig_1">1</ref>), one relevance feedback algorithm and one adaptive search algorithm (Circle 2 in Fig. <ref type="figure" coords="5,342.04,383.22,3.87,8.74" target="#fig_1">1</ref>).</p><p>To get a list of documents to examine, the assessors enter search queries and choose Lemur, Solr or Terrier to retrieve. While examining the documents returned by the search engine, they can drag and drop a text fragment of any length to a box to mark it as relevant to a subtopic. Then they can grade the text fragments at a scale of 1: marginally relevant, 2:relevant, 3:highly relevant, and 4:key results. The assessors can also mark a document as irrelevant or duplicate to the topics (Circle 1 in <ref type="bibr" coords="5,245.54,467.58,25.32,8.74">Fig 2)</ref>.</p><p>The assessors can also get document list via relevance feedback algorithm and adaptive search algorithm, which are the pink and blue magnifiers in Fig. <ref type="figure" coords="5,452.87,492.16,3.87,8.74" target="#fig_1">1</ref>. The relevance feedback algorithm utilizes a subtopic's title and all relevant context to the subtopic to expand the original search query. The adaptive search algorithm utilize both relevant and irrelevant contents to generate retrieval list. Notice that our relevance feedback and adaptive search algorithms are conducted at the subtopic level, which means only relevant/irrelevant texts to the corresponding subtopics are utilized to optimize retrieval results.</p><p>For example (Fig. <ref type="figure" coords="5,229.68,576.52,3.87,8.74" target="#fig_1">1</ref>), "assr4" first used Lemur to search for query "availability of drugs". Along the process of examining retrieval results, s/he generated subtopics "Organizations involved in R&amp;D . . . ", "Ethical Issues", "Use in Humans" etc. for the topic "Experimental Drugs" and also located some relevant texts for these passages. And then s/he could generate more documents to exam by using Solr or Terrier to retrieve for the same query. S/he could also try to find more documents related to subtopic "Ethical Issues" by clicking the pink/blue magnifier icon next to the corresponding subtopic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation Measures</head><p>The primary measures to evaluate the effectiveness of search systems in the DD track are Average Cube Test (ACT) and Cube Test (CT), proposed in <ref type="bibr" coords="6,442.82,208.09,9.96,8.74">[5]</ref>. Both measures evaluate the speed of completion of an entire search task; how fast a system could fill up the task cube with diverse and relevant information. Before the detailed description of evaluation measures, we introduce some notations. We denote a query by q, the set of its subtopics by S q , a single document by d, and a set of documents by D.</p><p>The first measure CT is defined as follows:</p><formula xml:id="formula_0" coords="6,255.21,298.97,225.39,22.31">CT(q, D) = Gain(q, D) Time(D) ,<label>(1)</label></formula><p>where Time(D) denotes the number of iterations to obtain document set D, and Gain(q, D) is estimated by the following formula.</p><formula xml:id="formula_1" coords="6,168.85,367.49,311.74,31.02">Gain(q, d j ) = s∈Sq Γ θ s rel(d j , s)1 j-1 k=1 rel(d k , s) &lt; MaxHeight ,<label>(2)</label></formula><p>where the elements of the formula are as follows:</p><p>-Γ is a discounting factor to include novelty in the evaluation and is calculated by</p><formula xml:id="formula_2" coords="6,278.81,454.83,201.78,12.46">Γ = γ nrel(s,D j-1 ) ,<label>(3)</label></formula><p>where γ denotes the discount factor, and nrel(s, D j-1 ) is the number of documents relevant to subtopic s in the set of documents ranked higher than document d j . θ s denotes the importance degree of subtopic s such that one has s∈Sq θ i = 1, -1 is the indicator function, rel() denotes the relevance degree between a document and a subtopic, calculated as an average over all its passages relevant to the subtopic, and it is in the [0, 1] range.</p><p>The second metric for evaluation of search systems considering the time taken to accomplish the search task is Average Cube Test (ACT) defined as an average of values of cube test metric, calculated at each rank in the list. In particular, ACT metric is calculated as follows: where D k is the set of documents from rank 1 to rank k.</p><formula xml:id="formula_3" coords="6,232.36,637.85,248.23,31.41">ACT(q, D) = 1 |D| |D| k=1 Gain(q, D k ) Time(D k ) ,<label>(4)</label></formula><p>Finally, in the TREC 2016 DD, the parameters of these two evaluation metric are set as: γ = 0.5, MaxHeight = 5, and all subtopics are assumed as equally important.</p><p>In addition, since the search tasks are all multiple-faceted, we include IR metrics measuring subtopic relevance, including α-nDCG@k [3] and nERR-IA <ref type="bibr" coords="7,467.31,299.98,9.96,8.74" target="#b0">[2]</ref>. We also consider evaluation using session-based measures, such as snDCG <ref type="bibr" coords="7,467.31,311.94,9.96,8.74" target="#b2">[4]</ref>. At each iteration, the value of these measures are computed on the ranked list of documents obtained by concatenating all ranked lists from the first iteration to that iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submission and Results</head><p>We received 21 submissions from 6 groups mentioned in Table <ref type="table" coords="7,409.37,405.35,3.87,8.74" target="#tab_1">2</ref>.</p><p>Summary of the adopted methods. Descriptions of the submitted runs provided by the participant group are as follows: Run-ID:rmit-oracle.lm.1000: We run Solr with the content language model to get the first 1000 documents, then we use the ground truth to remove non relevant documents from the initial list of documents. For each iteration, we return the next 5 relevant documents from the initial list. A document is relevant if it was found in the topic's list of judged documents. The motive is to estimate an upper bound of the task and understand if the first 1000 documents are enough to get all relevant documents. Run-ID:rmit-lm-rocchio.Rp.NRd.10: We use the content of documents to build a content language model and get the top 5 documents. We then use the Rocchio algorithm to reformulate the current iteration query using the feedback provided by JIG. To represent relevant documents, we concatenate relevant passages from relevant documents into a pseudo relevant passages (Rp) whereas we use the content of the non relevant documents as the non relevant units of Rocchio (NRd). Lastly, we use the top 10 non negative terms from the new query vector generated by Rocchio to build the new query. In addition, we set Rocchio parameters to α=1, β=0.75 and γ=0.25. rmit lm nqe: In this method, we used the Language modeling approach as implemented in Apache Solr using Dirichlet smoothing and default parameters. We leveraged Solr's edismax query parser that scores documents by the similarity score between the page content and the sum of bi-gram and uni-gram queries. No query expansion (nqe) was applied. ufmgXS2: Flat diversification with single-source subtopics and cumulative stopping condition. ufmgHS2: Hierarchical diversification with single-source subtopics and cumulative stopping condition. ufmgHM3: Hierarchical diversification with multi-source subtopics and windowbased stopping condition. ufmgHM2: Hierarchical diversification with multi-source subtopics and cumulative stopping condition. ufmgXM2: Flat diversification with multi-source subtopics and cumulative stopping condition. LDA Indri73: We use Indri and LDA to access the first iteration of the first query. Then we use the MDP model which we has modified and get the next iteration.During the MDP model,we use the Indri to help to search and then get the final result. rmit lm psg.max: We split documents into half overlapped passages with a passage size of 200 words and index them as documents alongside their parent documents in Apache Solr. We then use Solr's block join query to score documents based on the maximum of their passage level relevance scores. The method scores passages using the sum of the passage language model score for a unigram query and a bigram based phrase query. UL LDA NE: LDA used on a corpus of 25 documents from solr, Oriented for NE topics by reducing the text from each document to sentences which contains a part of the NE. UPD IA BiQBFi: BM25 followed by 5 iterations of feedback based on an algorithm inspired by Quantum Detection (QB) that exploits binary representation for documents. Feedback consists in re-ranking the (residual) top 1000 documents. When relevant documents are present in the feedback set explicit feedback is performed; when no relevant documents are present, residual collection is re-ranked by PRF on the top 100 documents. Description selection is based on WPQ; top 35 terms + topic terms are used. UPD IA BiQBDiJ: BM25 followed by max 5 iterations of feedback based on an algorithm inspired by Quantum Detection (QB) that exploits binary representation for documents. Feedback consists in re-ranking the (residual) top 1000 documents. When relevant documents are present in the feedback set explicit feedback is performed; when no relevant documents are present, residual collection is re-ranked by PRF on the top 100 documents. Description selection is based on WPQ; top 35 terms + topic terms are used. After two PRF-based re-ranking no additional iterations are performed. UL BM25: BM25 similarity. UL Kmeans: Kmeans applied on a subset of documents retrieved by Solr, best document of each cluster is returned to the user. UL LDA 200: LDA is used to create 5 different topics from documents. We take 100 results from Solr, we remove documents which are too similar to others documents, then we fill the dataset with other documents to have 100 document to run LDA over the sample. UL LDA Psum: Probability for each document to be assigned to each topic multiplied by the global probability of each topic to obtain the document which covers the maximum of topic information.  Results. Figures <ref type="figure" coords="9,229.40,621.25,4.98,8.74">3</ref> and<ref type="figure" coords="9,258.01,621.25,4.98,8.74" target="#fig_3">4</ref> show the change of ACT and CT scores, respectively, over ten iterations for all runs. The evaluation results of the cube test and average cube test measures show a decreasing trend with iteration for almost all submitted runs. We further provide the change of ACT score for two specific  queries, DD16-20 and DD16-16. These DD16-20 and DD16-16 queries have 1.0 and 0.0 values for precision at 5 documents measure, respectively, thus they seem to be samples of difficult and easy queries. Figures <ref type="figure" coords="11,360.51,143.90,4.98,8.74">5</ref> and<ref type="figure" coords="11,388.63,143.90,4.98,8.74" target="#fig_4">6</ref> show the change of ACT scores for queries DD16-20 and DD16-16, respectively. The ACT scores for query DD16-16 are lower than those for query DD16-20, however some runs have improved the ACT score for query DD16-16 in following iterations, which is not the case for query DD16-20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The dynamic domain track ran for the second time at TREC 2016, focusing on the significant interactive search task based on the newly-built dataset and designed settings. We received 21 runs from 6 groups. The evaluation results demonstrate that the distance between the manual run and the best automatic run is substantial, therefore the dynamic domain task is a difficult search task and further investigation is required to achieve acceptable performance. In addition, the decision to stop the search session requires estimation of user satisfaction which is very challenging, and is rarely addressed in received runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detailed Results</head><p>The evaluation scores for the submitted runs calculated for iteration 1 to 10 are listed in Tables <ref type="table" coords="13,202.74,450.71,27.89,8.74" target="#tab_7">3 to 12</ref>, respectively. The average of the scores over all the topics are reported when duplicate documents in subsequent ranked lists are removed. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,245.13,330.89,125.09,7.89;3,146.32,344.68,333.14,4.37;3,173.73,350.66,5.40,4.37;3,146.32,356.65,3.39,4.35;3,166.01,356.64,288.94,4.37;3,187.40,362.63,40.55,4.35;3,146.32,368.61,3.39,4.35;3,166.01,368.59,46.08,4.37;3,146.32,374.59,3.39,4.35;3,166.01,374.57,302.37,4.37;3,146.32,380.56,3.39,4.35;3,166.01,380.55,46.08,4.37;3,146.32,386.54,3.39,4.35;3,166.01,386.53,313.35,4.37;3,187.39,392.52,36.49,4.35;3,146.32,398.50,3.39,4.35;3,166.01,398.48,46.08,4.37;3,146.32,404.46,41.36,4.37;3,245.16,426.86,125.04,7.89;3,146.32,440.65,333.14,4.37;3,173.73,446.63,5.40,4.37;3,146.32,452.63,3.39,4.35;3,202.62,452.61,90.83,4.37;3,146.32,458.60,3.39,4.35;3,214.83,458.59,77.84,4.37;3,236.39,464.58,243.00,4.35;3,236.15,470.56,24.34,4.35;3,146.32,476.54,3.39,4.35;3,214.83,476.52,74.55,4.37;3,146.32,482.51,3.39,4.35;3,214.83,482.50,256.38,4.37;3,236.32,488.49,230.14,4.35;3,236.93,494.47,241.42,4.35;3,234.75,500.43,33.87,4.37;3,146.32,506.42,3.39,4.35;3,214.83,506.41,78.62,4.37;3,146.32,512.40,3.39,4.35;3,202.62,512.39,42.01,4.37;3,146.32,518.38,3.39,4.35;3,202.62,518.36,90.83,4.37;3,146.32,524.36,3.39,4.35;3,214.83,524.34,85.91,4.37;3,236.38,530.33,234.87,4.35;3,236.15,536.31,24.34,4.35;3,142.93,542.29,6.78,4.35;3,214.83,542.27,74.55,4.37;3,142.93,548.27,6.78,4.35;3,214.83,548.25,256.50,4.37;3,236.49,554.24,217.76,4.35;3,236.93,560.22,241.42,4.35;3,234.75,566.18,33.87,4.37;3,142.93,572.18,6.78,4.35;3,214.83,572.16,82.69,4.37;3,142.93,578.15,6.78,4.35;3,214.83,578.14,78.62,4.37;3,142.93,584.13,6.78,4.35;3,202.62,584.12,42.01,4.37;3,142.93,590.11,6.78,4.35;3,205.06,590.11,9.11,4.35;3,142.93,596.07,56.95,4.37"><head></head><label></label><figDesc>Listing 1.1. One sample topic 1 &lt;t o p i c name = ' 'US M i l i t a r y C r i s i s R e s p o n s e ' ' i d = ' 'DD16-1 ' ' n u m o f s u b t o p i c s = ' ' 3 ' ' &gt; 2 &lt;s u b t o p i c name = ' ' West A f r i c a n m i s s i o n ' ' i d = ' 'DD16-1.1 ' ' n u m o f p a s s a g e s = ' ' 1 8 6 2 ' '&gt; 3 &lt;/ s u b t o p i c&gt; 4 &lt;s u b t o p i c name = ' ' Key P e r s o n n e l ' ' i d = ' 'DD16-1.2 ' ' n u m o f p a s s a g e s = ' ' 1 0 9 1 ' '&gt; 5 &lt;/ s u b t o p i c&gt; 6 &lt;s u b t o p i c name = ' ' P e r s o n n e l s a f e t y p r o t o c o l s ' ' i d = ' 'DD16-1.3 ' ' n u m o f p a s s a g e s = ' ' 6 9 2 ' '&gt; 7 &lt;/ s u b t o p i c&gt; 8 &lt;/ t o p i c&gt; Listing 1.2. Sample judgment 1 &lt;s u b t o p i c name = ' ' West A f r i c a n m i s s i o n ' ' i d = ' 'DD16-1.1 ' ' n u m o f p a s s a g e s = ' ' 1 8 6 2 ' ' &gt; 2 &lt;p a s s a g e i d = ' ' 2 5 2 6 8 ' '&gt; 3 &lt;d o c n o&gt;e b o l a -634445 e d a 1 4 a a 2 7 5 6 f b d 3 e f f 2 4 b 0 c c f 1 0 f 2 4 5 4 3 c 4 d a 9 b d d 5 4 c b b 3 5 4 c 4 6 b a 5 c 6 6&lt;/ d o c n o&gt; 4 &lt;r a t i n g&gt;3&lt;/ r a t i n g&gt; 5 &lt;t e x t&gt;&lt; ! [CDATA[ I n t h i s week ' s AFRICOM Update e n g i n e e r s c o n t i n u e t o b u i l d E b o l a T r e a t m e n t U n i t s i n L i b e r i a w h i l e a s p e c i a l f a c i l i t y f o r i n f e c t e d h e a l t h c a r e w o r k e r s n e a r s c o m p l e t i o n . ] ] &gt;&lt;/ t e x t&gt; 6 &lt;t y p e&gt;MANUAL &lt;/ t y p e&gt; 7 &lt;/ p a s s a g e&gt; 8 &lt;p a s s a g e i d = ' ' 2 5 2 7 3 ' '&gt; 9 &lt;d o c n o&gt;e b o l a -87627477 a 4 2 2 3 a 5 2 b 2 c a a 9 3 f 3 a 8 0 6 3 7 b 9 7 6 0 1 9 1 1 8 7 a c 7 a 2 7 9 4 2 f 1 6 c 6 2 e 2 f b 5 2 c&lt;/ d o c n o&gt; 10 &lt;r a t i n g&gt;3&lt;/ r a t i n g&gt; 11 &lt;t e x t&gt;&lt; ! [CDATA[ t h i s week ' s AFRICOM Update e n g i n e e r s c o n t i n u e t o b u i l d E b o l a T r e a t m e n t U n i t s i n L i b e r i a w h i l e a s p e c i a l f a c i l i t y f o r i n f e c t e d h e a l t h c a r e w o r k e r s n e a r s c o m p l e t i o n . ] ] &gt;&lt;/ t e x t&gt; 12 &lt;t y p e&gt;MATCHED &lt;/ t y p e&gt; 13 &lt;s c o r e&gt;0 . 9 3&lt;/ s c o r e&gt; 14 &lt;/ p a s s a g e&gt; 15 . . . 16 &lt;/ s u b t o p i c&gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,210.53,360.41,194.29,7.89;4,134.77,116.83,414.99,228.81"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. TREC 2016 DD Track Annotation Tool.</figDesc><graphic coords="4,134.77,116.83,414.99,228.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,210.53,336.20,194.29,7.89;5,134.77,116.83,414.99,204.60"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. TREC 2016 DD Track Annotation Tool.</figDesc><graphic coords="5,134.77,116.83,414.99,204.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,195.26,587.50,224.84,7.89"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. CT scores of submitted runs over ten iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="10,191.86,601.43,231.64,7.89"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. ACT scores of query DD16-16 over ten iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,166.36,116.91,282.63,49.63"><head>Table 1 .</head><label>1</label><figDesc>Dataset statistics.</figDesc><table coords="3,166.36,135.96,282.63,30.58"><row><cell cols="4">Domain Size of data on disk Number of documents Number of queries</cell></row><row><cell>Ebola</cell><cell>12.6 GB</cell><cell>682,157</cell><cell>27</cell></row><row><cell>Polar</cell><cell>158 GB</cell><cell>1,741,530</cell><cell>26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,198.05,116.91,219.26,94.81"><head>Table 2 .</head><label>2</label><figDesc>Participant groups.</figDesc><table coords="7,198.05,137.71,219.26,74.02"><row><cell>Group</cell><cell>Country</cell></row><row><cell cols="2">Federal University of Minas Gerais (UFMG) Brazil</cell></row><row><cell>Georgetown University</cell><cell>USA</cell></row><row><cell>Laval University &amp; Lakehead University</cell><cell>Canada</cell></row><row><cell>NanJing University (IAPLab)</cell><cell>China</cell></row><row><cell>RMIT University</cell><cell>Australia</cell></row><row><cell>University of Padua (UPD IA)</cell><cell>Italy</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,134.77,120.67,345.83,40.74"><head>Table 3 .</head><label>3</label><figDesc>5. J. Luo, C. Wing, H. Yang, and M. Hearst. The water filling model and the cube test: Multi-dimensional evaluation for professional search. In Proceedings of the 22Nd ACM International Conference on Information &amp; Knowledge Management, CIKM '13, pages 709-714, New York, NY, USA, 2013. ACM. TREC 2016 Dynamic Domain Track Evaluation Results -Iteration 1</figDesc><table coords="13,136.16,137.71,427.43,249.36"><row><cell>Run ID</cell><cell>ACT</cell><cell>CT</cell><cell cols="2">α-nDCG nERR-</cell><cell>AVG-</cell><cell>AVG-</cell><cell cols="2">nSDCG Precision</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>IA</cell><cell>αnDCG</cell><cell>nERRIA</cell><cell></cell><cell></cell></row><row><cell>rmit oracle.lm.1000</cell><cell>0.3196</cell><cell>0.4019</cell><cell>0.6874</cell><cell>0.6709</cell><cell>0.0568</cell><cell>0.0549</cell><cell>0.4993</cell><cell>0.9623</cell></row><row><cell cols="2">rmit lm rocchio.Rp.NRd.10 0.1860</cell><cell>0.2530</cell><cell>0.3715</cell><cell>0.3547</cell><cell>0.0312</cell><cell>0.0271</cell><cell>0.2531</cell><cell>0.3890</cell></row><row><cell>rmit lm nqe</cell><cell>0.1822</cell><cell>0.2479</cell><cell>0.3581</cell><cell>0.3438</cell><cell>0.0309</cell><cell>0.0268</cell><cell>0.2470</cell><cell>0.3708</cell></row><row><cell>ufmgXS2</cell><cell>0.1751</cell><cell>0.2309</cell><cell>0.3516</cell><cell>0.3383</cell><cell>0.0289</cell><cell>0.0280</cell><cell>0.2226</cell><cell>0.4000</cell></row><row><cell>ufmgHS2</cell><cell>0.1751</cell><cell>0.2309</cell><cell>0.3516</cell><cell>0.3383</cell><cell>0.0289</cell><cell>0.0280</cell><cell>0.2226</cell><cell>0.4000</cell></row><row><cell>ufmgHM3</cell><cell>0.1751</cell><cell>0.2309</cell><cell>0.3516</cell><cell>0.3383</cell><cell>0.0289</cell><cell>0.0280</cell><cell>0.2226</cell><cell>0.4000</cell></row><row><cell>ufmgHM2</cell><cell>0.1751</cell><cell>0.2309</cell><cell>0.3516</cell><cell>0.3383</cell><cell>0.0289</cell><cell>0.0280</cell><cell>0.2226</cell><cell>0.4000</cell></row><row><cell>ufmgXM2</cell><cell>0.1750</cell><cell>0.2474</cell><cell>0.3559</cell><cell>0.3355</cell><cell>0.0384</cell><cell>0.0371</cell><cell>0.2254</cell><cell>0.4226</cell></row><row><cell>LDA Indri73</cell><cell>0.1658</cell><cell>0.2220</cell><cell>0.3288</cell><cell>0.3150</cell><cell>0.0312</cell><cell>0.0272</cell><cell>0.2166</cell><cell>0.3811</cell></row><row><cell>TenthIterBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>SecondIterationBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>FirstIterBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>FifthIterBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>rmit lm psg.max</cell><cell>0.1236</cell><cell>0.1725</cell><cell>0.2707</cell><cell>0.2611</cell><cell>0.0193</cell><cell>0.0177</cell><cell>0.1655</cell><cell>0.3179</cell></row><row><cell>UL LDA NE</cell><cell>0.1103</cell><cell>0.1601</cell><cell>0.2257</cell><cell>0.2073</cell><cell>0.0306</cell><cell>0.0305</cell><cell>0.0954</cell><cell>0.2906</cell></row><row><cell>UPD IA BiQBFi</cell><cell>0.1050</cell><cell>0.1698</cell><cell>0.2275</cell><cell>0.2011</cell><cell>0.0176</cell><cell>0.0151</cell><cell>0.1412</cell><cell>0.2453</cell></row><row><cell>UPD IA BiQBDiJ</cell><cell>0.1050</cell><cell>0.1698</cell><cell>0.2275</cell><cell>0.2011</cell><cell>0.0176</cell><cell>0.0151</cell><cell>0.1412</cell><cell>0.2453</cell></row><row><cell>UL BM25</cell><cell>0.1050</cell><cell>0.1522</cell><cell>0.2094</cell><cell>0.1919</cell><cell>0.0161</cell><cell>0.0148</cell><cell>0.1178</cell><cell>0.2340</cell></row><row><cell>UL Kmeans</cell><cell>0.0902</cell><cell>0.1319</cell><cell>0.1796</cell><cell>0.1630</cell><cell>0.0136</cell><cell>0.0124</cell><cell>0.0799</cell><cell>0.2340</cell></row><row><cell>UL LDA 200</cell><cell>0.0792</cell><cell>0.1293</cell><cell>0.1740</cell><cell>0.1593</cell><cell>0.0183</cell><cell>0.0163</cell><cell>0.0709</cell><cell>0.2075</cell></row><row><cell>UL LDA Psum</cell><cell>0.0197</cell><cell>0.0291</cell><cell>0.0558</cell><cell>0.0514</cell><cell>0.0043</cell><cell>0.0038</cell><cell>0.0154</cell><cell>0.0868</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="14,136.16,254.36,427.43,270.16"><head>Table 4 .</head><label>4</label><figDesc>TREC 2016 Dynamic Domain Track Evaluation Results -Iteration 2</figDesc><table coords="14,136.16,275.16,427.43,249.36"><row><cell>Run ID</cell><cell>ACT</cell><cell>CT</cell><cell cols="2">α-nDCG nERR-</cell><cell>AVG-</cell><cell>AVG-</cell><cell cols="2">nSDCG Precision</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>IA</cell><cell>αnDCG</cell><cell>nERRIA</cell><cell></cell><cell></cell></row><row><cell>rmit oracle.lm.1000</cell><cell>0.2789</cell><cell>0.2543</cell><cell>0.7116</cell><cell>0.6830</cell><cell>0.0310</cell><cell>0.0293</cell><cell>0.3102</cell><cell>0.9623</cell></row><row><cell cols="2">rmit lm rocchio.Rp.NRd.10 0.1644</cell><cell>0.1439</cell><cell>0.3883</cell><cell>0.3630</cell><cell>0.0174</cell><cell>0.0144</cell><cell>0.1236</cell><cell>0.3422</cell></row><row><cell>rmit lm nqe</cell><cell>0.1614</cell><cell>0.1539</cell><cell>0.3908</cell><cell>0.3611</cell><cell>0.0164</cell><cell>0.0139</cell><cell>0.1243</cell><cell>0.3393</cell></row><row><cell>ufmgXM2</cell><cell>0.1612</cell><cell>0.1574</cell><cell>0.4028</cell><cell>0.3588</cell><cell>0.0217</cell><cell>0.0198</cell><cell>0.1275</cell><cell>0.4038</cell></row><row><cell>ufmgHS2</cell><cell>0.1611</cell><cell>0.1581</cell><cell>0.4079</cell><cell>0.3664</cell><cell>0.0182</cell><cell>0.0158</cell><cell>0.1305</cell><cell>0.4075</cell></row><row><cell>ufmgHM3</cell><cell>0.1601</cell><cell>0.1578</cell><cell>0.4055</cell><cell>0.3653</cell><cell>0.0183</cell><cell>0.0159</cell><cell>0.1306</cell><cell>0.4075</cell></row><row><cell>ufmgHM2</cell><cell>0.1601</cell><cell>0.1578</cell><cell>0.4055</cell><cell>0.3653</cell><cell>0.0183</cell><cell>0.0159</cell><cell>0.1306</cell><cell>0.4075</cell></row><row><cell>ufmgXS2</cell><cell>0.1587</cell><cell>0.1506</cell><cell>0.3987</cell><cell>0.3622</cell><cell>0.0165</cell><cell>0.0150</cell><cell>0.1305</cell><cell>0.4283</cell></row><row><cell>FirstIterBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>LDA Indri73</cell><cell>0.1425</cell><cell>0.1242</cell><cell>0.3350</cell><cell>0.3172</cell><cell>0.0162</cell><cell>0.0139</cell><cell>0.1000</cell><cell>0.2547</cell></row><row><cell>TenthIterBaseline</cell><cell>0.1352</cell><cell>0.1274</cell><cell>0.3142</cell><cell>0.2777</cell><cell>0.0160</cell><cell>0.0127</cell><cell>0.0920</cell><cell>0.2528</cell></row><row><cell>SecondIterationBaseline</cell><cell>0.1352</cell><cell>0.1274</cell><cell>0.3142</cell><cell>0.2777</cell><cell>0.0160</cell><cell>0.0127</cell><cell>0.0920</cell><cell>0.2528</cell></row><row><cell>FifthIterBaseline</cell><cell>0.1352</cell><cell>0.1274</cell><cell>0.3142</cell><cell>0.2777</cell><cell>0.0160</cell><cell>0.0127</cell><cell>0.0920</cell><cell>0.2528</cell></row><row><cell>rmit lm psg.max</cell><cell>0.1178</cell><cell>0.1275</cell><cell>0.3166</cell><cell>0.2836</cell><cell>0.0116</cell><cell>0.0098</cell><cell>0.0940</cell><cell>0.2985</cell></row><row><cell>UPD IA BiQBFi</cell><cell>0.1107</cell><cell>0.1281</cell><cell>0.2736</cell><cell>0.2238</cell><cell>0.0105</cell><cell>0.0086</cell><cell>0.0909</cell><cell>0.3038</cell></row><row><cell>UPD IA BiQBDiJ</cell><cell>0.1107</cell><cell>0.1281</cell><cell>0.2736</cell><cell>0.2238</cell><cell>0.0105</cell><cell>0.0086</cell><cell>0.0909</cell><cell>0.3038</cell></row><row><cell>UL LDA NE</cell><cell>0.1092</cell><cell>0.1309</cell><cell>0.2779</cell><cell>0.2319</cell><cell>0.0192</cell><cell>0.0177</cell><cell>0.0703</cell><cell>0.2868</cell></row><row><cell>UL BM25</cell><cell>0.1031</cell><cell>0.1097</cell><cell>0.2520</cell><cell>0.2131</cell><cell>0.0098</cell><cell>0.0083</cell><cell>0.0759</cell><cell>0.2811</cell></row><row><cell>UL Kmeans</cell><cell>0.0815</cell><cell>0.0803</cell><cell>0.1922</cell><cell>0.1685</cell><cell>0.0072</cell><cell>0.0064</cell><cell>0.0386</cell><cell>0.1887</cell></row><row><cell>UL LDA 200</cell><cell>0.0815</cell><cell>0.0995</cell><cell>0.2110</cell><cell>0.1772</cell><cell>0.0121</cell><cell>0.0096</cell><cell>0.0431</cell><cell>0.1981</cell></row><row><cell>UL LDA Psum</cell><cell>0.0274</cell><cell>0.0438</cell><cell>0.1039</cell><cell>0.0750</cell><cell>0.0052</cell><cell>0.0034</cell><cell>0.0165</cell><cell>0.1811</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="16,136.16,254.36,427.43,270.16"><head>Table 6 .</head><label>6</label><figDesc>TREC 2016 Dynamic Domain Track Evaluation Results -Iteration 4</figDesc><table coords="16,136.16,275.16,427.43,249.36"><row><cell>Run ID</cell><cell>ACT</cell><cell>CT</cell><cell cols="2">α-nDCG nERR-</cell><cell>AVG-</cell><cell>AVG-</cell><cell cols="2">nSDCG Precision</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>IA</cell><cell>αnDCG</cell><cell>nERRIA</cell><cell></cell><cell></cell></row><row><cell>rmit oracle.lm.1000</cell><cell>0.2434</cell><cell>0.1889</cell><cell>0.7346</cell><cell>0.6907</cell><cell>0.0171</cell><cell>0.0158</cell><cell>0.2445</cell><cell>0.9623</cell></row><row><cell>FirstIterBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>ufmgHM3</cell><cell>0.1371</cell><cell>0.1054</cell><cell>0.4377</cell><cell>0.3763</cell><cell>0.0106</cell><cell>0.0088</cell><cell>0.0858</cell><cell>0.3884</cell></row><row><cell>ufmgHM2</cell><cell>0.1367</cell><cell>0.1032</cell><cell>0.4325</cell><cell>0.3745</cell><cell>0.0108</cell><cell>0.0090</cell><cell>0.0853</cell><cell>0.3833</cell></row><row><cell>ufmgHS2</cell><cell>0.1366</cell><cell>0.0989</cell><cell>0.4335</cell><cell>0.3750</cell><cell>0.0107</cell><cell>0.0088</cell><cell>0.0810</cell><cell>0.3846</cell></row><row><cell>ufmgXM2</cell><cell>0.1360</cell><cell>0.1001</cell><cell>0.4243</cell><cell>0.3662</cell><cell>0.0120</cell><cell>0.0106</cell><cell>0.0774</cell><cell>0.3651</cell></row><row><cell>SecondIterationBaseline</cell><cell>0.1352</cell><cell>0.1274</cell><cell>0.3142</cell><cell>0.2777</cell><cell>0.0160</cell><cell>0.0127</cell><cell>0.0920</cell><cell>0.2528</cell></row><row><cell>ufmgXS2</cell><cell>0.1338</cell><cell>0.0981</cell><cell>0.4262</cell><cell>0.3711</cell><cell>0.0104</cell><cell>0.0086</cell><cell>0.0820</cell><cell>0.4025</cell></row><row><cell>rmit lm nqe</cell><cell>0.1307</cell><cell>0.0925</cell><cell>0.4250</cell><cell>0.3726</cell><cell>0.0088</cell><cell>0.0071</cell><cell>0.0688</cell><cell>0.3170</cell></row><row><cell cols="2">rmit lm rocchio.Rp.NRd.10 0.1278</cell><cell>0.0768</cell><cell>0.3968</cell><cell>0.3658</cell><cell>0.0094</cell><cell>0.0078</cell><cell>0.0621</cell><cell>0.2953</cell></row><row><cell>LDA Indri73</cell><cell>0.1116</cell><cell>0.0727</cell><cell>0.3457</cell><cell>0.3206</cell><cell>0.0089</cell><cell>0.0076</cell><cell>0.0526</cell><cell>0.1840</cell></row><row><cell>UL LDA NE</cell><cell>0.1092</cell><cell>0.1309</cell><cell>0.2779</cell><cell>0.2319</cell><cell>0.0192</cell><cell>0.0177</cell><cell>0.0703</cell><cell>0.2868</cell></row><row><cell>TenthIterBaseline</cell><cell>0.1051</cell><cell>0.0647</cell><cell>0.3141</cell><cell>0.2779</cell><cell>0.0080</cell><cell>0.0063</cell><cell>0.0420</cell><cell>0.1358</cell></row><row><cell>FifthIterBaseline</cell><cell>0.1051</cell><cell>0.0647</cell><cell>0.3141</cell><cell>0.2779</cell><cell>0.0080</cell><cell>0.0063</cell><cell>0.0420</cell><cell>0.1358</cell></row><row><cell>UL BM25</cell><cell>0.1031</cell><cell>0.1097</cell><cell>0.2520</cell><cell>0.2131</cell><cell>0.0098</cell><cell>0.0083</cell><cell>0.0759</cell><cell>0.2811</cell></row><row><cell>rmit lm psg.max</cell><cell>0.0998</cell><cell>0.0761</cell><cell>0.3493</cell><cell>0.2941</cell><cell>0.0062</cell><cell>0.0050</cell><cell>0.0491</cell><cell>0.2696</cell></row><row><cell>UPD IA BiQBFi</cell><cell>0.0984</cell><cell>0.0863</cell><cell>0.3016</cell><cell>0.2335</cell><cell>0.0058</cell><cell>0.0046</cell><cell>0.0603</cell><cell>0.3204</cell></row><row><cell>UPD IA BiQBDiJ</cell><cell>0.0984</cell><cell>0.0862</cell><cell>0.3009</cell><cell>0.2333</cell><cell>0.0064</cell><cell>0.0051</cell><cell>0.0602</cell><cell>0.3195</cell></row><row><cell>UL Kmeans</cell><cell>0.0815</cell><cell>0.0803</cell><cell>0.1922</cell><cell>0.1685</cell><cell>0.0072</cell><cell>0.0064</cell><cell>0.0386</cell><cell>0.1887</cell></row><row><cell>UL LDA 200</cell><cell>0.0815</cell><cell>0.0995</cell><cell>0.2110</cell><cell>0.1772</cell><cell>0.0121</cell><cell>0.0096</cell><cell>0.0431</cell><cell>0.1981</cell></row><row><cell>UL LDA Psum</cell><cell>0.0274</cell><cell>0.0438</cell><cell>0.1039</cell><cell>0.0750</cell><cell>0.0052</cell><cell>0.0034</cell><cell>0.0165</cell><cell>0.1811</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="22,136.16,254.36,427.43,270.16"><head>Table 12 .</head><label>12</label><figDesc>TREC 2016 Dynamic Domain Track Evaluation Results -Iteration 10</figDesc><table coords="22,136.16,275.16,427.43,249.36"><row><cell>Run ID</cell><cell>ACT</cell><cell>CT</cell><cell cols="2">α-nDCG nERR-</cell><cell>AVG-</cell><cell>AVG-</cell><cell cols="2">nSDCG Precision</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>IA</cell><cell>αnDCG</cell><cell>nERRIA</cell><cell></cell><cell></cell></row><row><cell>rmit oracle.lm.1000</cell><cell>0.2065</cell><cell>0.1489</cell><cell>0.7468</cell><cell>0.6932</cell><cell>0.0079</cell><cell>0.0073</cell><cell>0.2173</cell><cell>0.9623</cell></row><row><cell>FirstIterBaseline</cell><cell>0.1516</cell><cell>0.2174</cell><cell>0.2952</cell><cell>0.2691</cell><cell>0.0274</cell><cell>0.0231</cell><cell>0.1901</cell><cell>0.3208</cell></row><row><cell>SecondIterationBaseline</cell><cell>0.1352</cell><cell>0.1274</cell><cell>0.3142</cell><cell>0.2777</cell><cell>0.0160</cell><cell>0.0127</cell><cell>0.0920</cell><cell>0.2528</cell></row><row><cell>ufmgXM2</cell><cell>0.1237</cell><cell>0.0852</cell><cell>0.4265</cell><cell>0.3667</cell><cell>0.0094</cell><cell>0.0083</cell><cell>0.0714</cell><cell>0.3504</cell></row><row><cell>ufmgHM2</cell><cell>0.1219</cell><cell>0.0842</cell><cell>0.4367</cell><cell>0.3754</cell><cell>0.0066</cell><cell>0.0055</cell><cell>0.0774</cell><cell>0.3716</cell></row><row><cell>ufmgHS2</cell><cell>0.1215</cell><cell>0.0801</cell><cell>0.4368</cell><cell>0.3758</cell><cell>0.0076</cell><cell>0.0062</cell><cell>0.0749</cell><cell>0.3794</cell></row><row><cell>ufmgXS2</cell><cell>0.1188</cell><cell>0.0786</cell><cell>0.4324</cell><cell>0.3723</cell><cell>0.0059</cell><cell>0.0048</cell><cell>0.0752</cell><cell>0.3871</cell></row><row><cell>ufmgHM3</cell><cell>0.1181</cell><cell>0.0808</cell><cell>0.4481</cell><cell>0.3784</cell><cell>0.0053</cell><cell>0.0044</cell><cell>0.0737</cell><cell>0.3654</cell></row><row><cell>UL LDA NE</cell><cell>0.1092</cell><cell>0.1309</cell><cell>0.2779</cell><cell>0.2319</cell><cell>0.0192</cell><cell>0.0177</cell><cell>0.0703</cell><cell>0.2868</cell></row><row><cell>UL BM25</cell><cell>0.1031</cell><cell>0.1097</cell><cell>0.2520</cell><cell>0.2131</cell><cell>0.0098</cell><cell>0.0083</cell><cell>0.0759</cell><cell>0.2811</cell></row><row><cell>LDA Indri73</cell><cell>0.0985</cell><cell>0.0583</cell><cell>0.3532</cell><cell>0.3223</cell><cell>0.0064</cell><cell>0.0054</cell><cell>0.0421</cell><cell>0.1557</cell></row><row><cell>FifthIterBaseline</cell><cell>0.0944</cell><cell>0.0518</cell><cell>0.3138</cell><cell>0.2778</cell><cell>0.0064</cell><cell>0.0051</cell><cell>0.0327</cell><cell>0.1087</cell></row><row><cell>UPD IA BiQBDiJ</cell><cell>0.0938</cell><cell>0.0774</cell><cell>0.3066</cell><cell>0.2348</cell><cell>0.0058</cell><cell>0.0046</cell><cell>0.0543</cell><cell>0.3072</cell></row><row><cell>UPD IA BiQBFi</cell><cell>0.0925</cell><cell>0.0760</cell><cell>0.3073</cell><cell>0.2350</cell><cell>0.0047</cell><cell>0.0037</cell><cell>0.0529</cell><cell>0.3059</cell></row><row><cell cols="2">rmit lm rocchio.Rp.NRd.10 0.0866</cell><cell>0.0381</cell><cell>0.4097</cell><cell>0.3687</cell><cell>0.0043</cell><cell>0.0035</cell><cell>0.0293</cell><cell>0.2342</cell></row><row><cell>rmit lm nqe</cell><cell>0.0860</cell><cell>0.0426</cell><cell>0.4584</cell><cell>0.3794</cell><cell>0.0038</cell><cell>0.0029</cell><cell>0.0288</cell><cell>0.2484</cell></row><row><cell>UL Kmeans</cell><cell>0.0815</cell><cell>0.0803</cell><cell>0.1922</cell><cell>0.1685</cell><cell>0.0072</cell><cell>0.0064</cell><cell>0.0386</cell><cell>0.1887</cell></row><row><cell>UL LDA 200</cell><cell>0.0815</cell><cell>0.0995</cell><cell>0.2110</cell><cell>0.1772</cell><cell>0.0121</cell><cell>0.0096</cell><cell>0.0431</cell><cell>0.1981</cell></row><row><cell>rmit lm psg.max</cell><cell>0.0708</cell><cell>0.0404</cell><cell>0.3930</cell><cell>0.3028</cell><cell>0.0030</cell><cell>0.0021</cell><cell>0.0223</cell><cell>0.2310</cell></row><row><cell>TenthIterBaseline</cell><cell>0.0639</cell><cell>0.0259</cell><cell>0.3136</cell><cell>0.2778</cell><cell>0.0032</cell><cell>0.0025</cell><cell>0.0154</cell><cell>0.0543</cell></row><row><cell>UL LDA Psum</cell><cell>0.0274</cell><cell>0.0438</cell><cell>0.1039</cell><cell>0.0750</cell><cell>0.0052</cell><cell>0.0034</cell><cell>0.0165</cell><cell>0.1811</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="1,144.73,646.84,335.86,7.86;1,144.73,657.79,170.63,7.86"><p>The DARPA Memex program aims to advance the state of the art in domain-specific web crawling, visualization, and discovery.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,646.84,335.86,7.86;2,144.73,657.79,59.16,7.86"><p>The implementation of the Jig system is available online at https://github.com/trecdd/trec-dd-jig.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="4,144.73,658.44,131.81,7.47"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="5,144.73,647.48,145.93,7.47"><p>https://lucene.apache.org/solr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="5,144.73,658.44,89.44,7.47"><p>http://terrier.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The TREC 2016 Dynamic Domain Track is sponsored by the <rs type="funder">DARPA</rs> <rs type="programName">Memex program</rs>. We have our special thanks to <rs type="person">Razieh Rahimi</rs>, <rs type="person">Jiyun Luo</rs>, <rs type="person">Yunyun Chen</rs>, <rs type="person">Shiqi Liu</rs> from <rs type="affiliation">Georgetown university</rs>, and <rs type="person">Shahzad Rajput</rs> from <rs type="funder">NIST</rs>. We thank the following contributors to TREC DD Track in crawling the data: Diffeo, <rs type="person">Giant Oak</rs>, <rs type="person">Hyperion Gray</rs>, <rs type="institution">NASA JPL</rs>, and <rs type="institution">New York University</rs>.</p><p>This research was supported by <rs type="funder">DARPA</rs> grant <rs type="grantNumber">FA8750-14-2-0226</rs>, <rs type="funder">NSF</rs> grant <rs type="grantNumber">IIS-145374</rs>, and <rs type="funder">NSF</rs> grant <rs type="grantNumber">CNS-1223825</rs>. Any opinions, findings, conclusions, or recommendations expressed in this paper are of the authors, and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gWyTHH5">
					<orgName type="program" subtype="full">Memex program</orgName>
				</org>
				<org type="funding" xml:id="_UfFrKdv">
					<idno type="grant-number">FA8750-14-2-0226</idno>
				</org>
				<org type="funding" xml:id="_P8kQnzu">
					<idno type="grant-number">IIS-145374</idno>
				</org>
				<org type="funding" xml:id="_qWURQpb">
					<idno type="grant-number">CNS-1223825</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,138.35,538.07,342.24,7.86;11,146.91,549.02,333.68,7.86;11,146.91,559.98,61.31,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,430.62,538.07,49.97,7.86;11,146.91,549.02,239.99,7.86">Intent-based diversification of web search results: Metrics and algorithms</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Velipasaoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-L</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,395.09,549.02,36.66,7.86">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="572" to="592" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,570.53,342.24,7.86;11,146.91,581.49,333.68,7.86;11,146.91,592.45,333.68,7.86;11,146.91,603.41,333.67,7.86;11,146.91,614.37,92.40,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,231.21,581.49,230.52,7.86">Novelty and diversity in information retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kolla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vechtomova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ashkan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mackinnon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,146.91,592.45,333.68,7.86;11,146.91,603.41,219.34,7.86">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;08</title>
		<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="659" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,624.92,342.24,7.86;11,146.91,635.88,333.68,7.86;11,146.91,646.84,333.68,7.86;11,146.91,657.79,217.12,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,408.09,624.92,72.50,7.86;11,146.91,635.88,217.63,7.86">Discounted cumulated gain based evaluation of multiple-query ir sessions</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">L</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">M L</forename><surname>Delcambre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,381.41,635.88,99.18,7.86;11,146.91,646.84,329.01,7.86">Proceedings of the IR Research, 30th European Conference on Advances in Information Retrieval, ECIR&apos;08</title>
		<meeting>the IR Research, 30th European Conference on Advances in Information Retrieval, ECIR&apos;08<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
