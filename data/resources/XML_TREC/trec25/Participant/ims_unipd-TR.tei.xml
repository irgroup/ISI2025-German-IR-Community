<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.56,116.75,330.24,12.62;1,242.55,134.69,130.26,12.62">The University of Padua (IMS) at TREC 2016 Total Recall Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.68,172.44,74.99,8.74"><forename type="first">Giorgio</forename><forename type="middle">Maria</forename><surname>Di</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.78,172.44,60.88,8.74"><forename type="first">Maria</forename><surname>Maistro</surname></persName>
							<email>maistro]@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,383.90,172.44,50.78,8.74"><forename type="first">Daniel</forename><surname>Zilio</surname></persName>
							<email>daniel.zilio@unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.56,116.75,330.24,12.62;1,242.55,134.69,130.26,12.62">The University of Padua (IMS) at TREC 2016 Total Recall Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BDF13281ACE5B58154BDC36D6D058C5E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The participation of the Information Management System (IMS) Group of the University of Padua in the Total Recall track at TREC 2016 consisted in a set of fully automated experiments based on the two-dimensional probabilistic model. We trained the model in two ways that tried to mimic a real user, and we compared it to two versions of the BM25 model with different parameter settings. This initial set of experiments lays the ground for a wider study that will explore a gamification approach in the context of high recall situations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The principal purpose of the Total Recall Track is to evaluate, through a controlled simulation, methods to achieve very high recall (close to 100%) with a human assessor in the loop. The task to be solved is the following: given a topic description, identify the documents in a corpus, one at a time or in batches, such that all relevant documents are identified before all non-relevant documents, as nearly as possible.</p><p>The Information Management Systems (IMS) research group of the University of Padua participated for the first time in one of the two sub-tasks available, namely the "At Home" with the "athome4" collection. This collection consists of 290,000 Jeb Bush email messages and a set of 34 topics. A subset of emails sampled using the continuous active learning method <ref type="bibr" coords="1,355.07,500.62,10.52,8.74" target="#b1">[2]</ref> was labeled by a primary assessor as "relevant" or "not relevant". Relevant documents were further labeled by the primary assessor as "important" or "not important" and categorized into sub-categories corresponding to different subtopics or aspects of relevance. During the experiments, the information made available to the participants for each submitted document was either "relevant" or "not relevant".</p><p>In this paper, we present the experiments we carried out using a fully automated system based on the two-dimensional interpretation of the BM25 model <ref type="bibr" coords="1,469.48,584.39,9.96,8.74" target="#b4">[5]</ref>. We implemented two versions of this system that mimic the behaviour of two users that try to find the optimal decision with two different strategies. We also run two runs using a "plain" BM25 with different parameters. The results of this first set of experiments will lay the ground for our current work on the study of gamification of classification problems that will directly involve users in the problem of high recall systems.</p><p>In this section, we present the models that we used to produce the four runs: the BM25 used as a baseline and the two-dimensional representation of the BM25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">BM25</head><p>For the BM25, we used the definition given by Zaragoza and Robertson in <ref type="bibr" coords="2,470.07,199.90,10.52,8.74">[7]</ref> where the weight of the i-th term in a document is equal to:</p><formula xml:id="formula_0" coords="2,209.85,229.68,270.74,26.00">w BM 25 i (tf ) = tf k 1 (1 -b) + b dl avdl + tf w BIM i<label>(1)</label></formula><p>where k 1 and b are two parameters (we used the default values used by Terrier<ref type="foot" coords="2,473.36,263.08,3.97,6.12" target="#foot_0">1</ref> , k 1 = 1.2 and b = 0.75), tf is the term frequency in the document, and w BIM i is the Binary Independence Model weight of the i-th term:</p><formula xml:id="formula_1" coords="2,237.06,306.28,243.53,26.35">w BIM i = log θ R i (1 -θ R i ) (1 -θ N R i ) θ N R i (2)</formula><p>where θ R i and θ N R i are the parameters of the Bernoulli random variable that represent the presence (or absence) of the i-th term in the relevant (R) and non-relevant (N R) documents. The estimate of each parameter is:</p><formula xml:id="formula_2" coords="2,264.07,385.49,216.52,23.89">θ R i = r i + α R R + α R + β R<label>(3)</label></formula><formula xml:id="formula_3" coords="2,242.08,418.34,234.27,23.89">θ N R i = n i -r i + α N R N -R + α N R + β N R (<label>4</label></formula><formula xml:id="formula_4" coords="2,476.35,426.66,4.24,8.74">)</formula><p>where R is the number of relevant documents, r i the number of relevant documents in which the i-th term appears, N is the total number of documents and n i is the total number of documents in which the i-th term appears. Parameters α and β correspond to the hyper-parameter of the conjugate beta prior distribution of the Bernoulli random variable. For α R = β R = 0.5 and β R = N R = 0.5, we obtain the definition of the well-known Robertson -Spärck Jones weight</p><formula xml:id="formula_5" coords="2,134.77,518.28,40.88,12.32">w RSJ i [7].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Two-Dimensional Model</head><p>The two-dimensional representation of probabilities <ref type="bibr" coords="2,362.71,566.49,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,374.88,566.49,7.01,8.74">8]</ref>, is an intuitive way of presenting a two-class classification problem on a two-dimensional space. Given two classes, for example R and N R, a document d is assigned to category R if the following inequality holds:</p><formula xml:id="formula_6" coords="2,251.98,622.28,228.61,23.80">P (d|N R) y &lt; m P (d|R) x +q<label>(5)</label></formula><p>Fig. <ref type="figure" coords="3,153.45,307.54,3.87,8.74">1</ref>: Layout of the original "classification game" ( <ref type="bibr" coords="3,358.88,307.54,10.96,8.74" target="#b5">[6]</ref>) that was adapted to the Total Recall track experiments.</p><p>where P (d|R) and P (d|N R) are the likelihoods of the object d given the two categories, while m and q are two parameters that can be assigned (automatically or by a user) to compensate for either the unbalanced classes situations or different misclassification costs.</p><p>If we interpret the two likelihoods as two coordinates x and y of a two dimensional space, the problem of classification can be studied on a two-dimensional plot. The decision of the classification is represented by the line y = mx + q that splits the plane into two parts: all the points that fall 'below' this line are classified as objects that belong to class R (see Figure <ref type="figure" coords="3,372.67,459.62,4.98,8.74">1</ref> for an example). Without entering into the mathematical details of this approach <ref type="bibr" coords="3,394.76,471.58,9.96,8.74" target="#b2">[3]</ref>, the basic idea is that the two parameters m and q can be optimized by a user or by an automatic approach to obtain a better separation of the points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Two-dimensional BM25</head><p>In order to link the two-dimensional model to the BM25 model, first we define the BIM weight as a difference of logarithms:</p><formula xml:id="formula_7" coords="3,171.73,576.31,308.86,26.35">w BIM i = log θ R i (1 -θ R i ) -log θ N R i (1 -θ N R i ) = w BIM,R i -w BIM,N R i (6)</formula><p>then, we can define the BM25 term weight accordingly</p><formula xml:id="formula_8" coords="3,168.82,643.20,311.77,26.00">w BM 25 i (tf ) = tf k 1 (1 -b) + b dl avdl + tf w BIM,R i -w BIM,N R i (7)</formula><p>We now have all the elements to define the two coordinates x = P (d|R) and y = P (d|N R) in the following way:</p><formula xml:id="formula_9" coords="4,249.54,152.18,231.06,22.89">P (d|R) = i∈d w BM 25,R i (tf )<label>(8)</label></formula><formula xml:id="formula_10" coords="4,239.89,180.13,240.70,22.89">P (d|N R) = i∈d w BM 25,N R i (tf )<label>(9)</label></formula><p>where i∈d indicates (with an abuse of notation) the sum over all the terms of document d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In the previous section, we presented the mathematical framework of the twodimensional framework and we showed that there are actually four parameters that can be used to optimize the classification (or retrieval) performance: α, β, m, and q. In our experiments, we fixed α and β and tweak m and q. There is also another issue related to the problem of finding a set of documents to be used as a training set in order to estimate P (d|R) and P (d|N R). We tackled this problem by iteratively identifying a potential training set of documents to be submitted to the "assessor" and use the new relevance information to find a better decision line. We repeat this process until we find a line (Equation <ref type="formula" coords="4,471.74,378.61,4.43,8.74" target="#formula_6">5</ref>) that allows us to obtain a recall on the already judged document greater than some 0.999 (this threshold can be optimized as well).</p><p>We submitted four runs: two baseline runs of BM25 with different smoothing parameters, one aggressive (baseline bm25 highly) and one mild (baseline bm25 smoothing); two two-dimensional runs with different strategies to send batches of documents (auto shift rotate exp and auto shift rotation). In Appendix A, we show the pseudo-code used to find the potentially relevant documents for each run.</p><p>Data pre-processing Each email was pre-processed in order to have only the textual content (i.e., not the FROM, TO fields, nor the URLs or links at the bottom of the page); then, standard text processing was performed for all the four runs: all letters converted to lowercase, punctuations and numbers were removed, a stoplist of 174 terms was applied (we used the one included in the 'tm' R package <ref type="bibr" coords="4,208.38,564.12,10.30,8.74" target="#b3">[4]</ref>), words were stemmed by means of a Snowball stemmer ('SnowballC' R package <ref type="bibr" coords="4,244.89,576.08,10.30,8.74" target="#b0">[1]</ref>). A maximum of 50,000 features were selected at each round according to the difference θ R i -θ N R i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, we briefly analyze some of results on four topics that we found representatives in terms of the range of behaviour of the best two runs, namely 'automatic shift rotate' and 'baseline bm25 smoothing', compared to the Baseline Model Implementation (bmi) run provided by the organizers of the track. We could group the performance of the system into four distinct categories:</p><p>-The system performed well and tracked the performance of the bmi. See for example Figure <ref type="figure" coords="5,222.16,174.57,9.96,8.74">3a</ref> for the topic "athome402". -The system performed well and the decision to "call the shot" early worked very well like, for example, the topic "athome424" as shown in Figure <ref type="figure" coords="5,459.77,198.44,8.86,8.74">3b</ref>. -When the number of initial relevant documents is small (we fixed a low threshold for the maximum number of relevant documents within the 100 top ranked, see Appendix A), the system tend to miss a lot of relevant information due to the strong initial bias and it takes some effort, in terms of documents to assess, to recover this wrong start like, for example, topic 'athome403' in Figure <ref type="figure" coords="5,250.66,270.13,8.49,8.74" target="#fig_0">4a</ref>. -The worst case is a negative start that continues with a negative feedback (only non relevant documents) that cannot recover the initial situation. See for example topic 'athome426' shown in Figure <ref type="figure" coords="5,360.05,305.95,8.86,8.74" target="#fig_0">4b</ref>.</p><p>At the end, we were positively surprised to see that in some cases this approach performed well and sometimes close to the bmi. These results are encouraging if we consider that i) our system is designed to be used by users who can provide feedback during the choice of the decision line, and ii) that it was the first time that we tried to implement an automatic strategy to find the best decision line. In confirmation of this intuition, we ran a quick manual search of the best decision line on topic 'athome403' (see Figure <ref type="figure" coords="5,305.34,397.43,4.98,8.74">2</ref> for the actual interface) and we were able to find about 92% of relevant documents within the first 1,363 documents while the automatic approach arrived to the same ratio of relevant documents after judging 8,000 documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This was the first participation of the IMS group to the Total Recall track.</p><p>Our main goal was to begin a set of experiments that will compare different strategies to the problem of high recall classification, from automatic approaches to gamification ones. We submitted four runs: two variations of the BM25 model and two variations of the two-dimensional probabilistic model, one with a simple three-step strategy to find the best decision line and another more complex that tried to mimic a human with small tweaks on the decision line. The results showed that the simpler the better in both cases: the best BM25 approach was the one with a classical smoothing approach, while the best automatic run was the simple three-step strategy. For the automatic runs, we could clearly find four different types of behaviour of the system, from the one with good performance and correct early stopping to the one with bad initial setting and continuous negative feedback that could not retrieve more than a few relevant documents.</p><p>Results are encouraging giving the fact that the two-dimensional approach is indeed an active learning approach where users can, and should, suggest the Fig. <ref type="figure" coords="6,153.45,347.26,3.87,8.74">2</ref>: Layout of the actual interactive system used for a manual check on topic 'athome403'.</p><p>direction of the decision line with small adjustments. Future work will involve users that not only adjust the decision line but they also provide a reformulation of the query to broaden the range of relevant documents that are fed to the system.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix: Settings and Stopping Strategies</head><p>The four runs we submitted had four parameters in common: α R , α N R , β R , β N R . The number of terms was fixed to 50,000; these terms were the top 50,000 of the list of terms ordered in decreasing order of the difference θ R i -θ N R i . In addition, we choose different approaches for the amount of documents that had to be sent to for relevance feedback at each round.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 BM25 Baseline</head><p>For the two BM25 runs, we choose different values for the four parameters in order to compare an aggressive smoothing to a classic one. We chose the same strategy for the number of documents that had to be sent for relevance feedback. In particular:</p><p>if feedback round &lt; 100, then top 50 (a total of 5,000 documents), if feedback round &lt; 200, then top 100 (a total of 10,000 documents), if feedback round &lt; 270, then top 500 (a total of 35,000 documents), else top 5,000 (remaining documents).</p><p>At the end of each round, the information about relevant documents is plugged in Equation 3 and 4. We did not "call the shot" on purpose. baseline bm25 The settings of this run were:</p><formula xml:id="formula_11" coords="9,140.99,523.89,69.46,48.00">-α R = 0.01 , -β R = 5, -α N R = 0.001, -β N R = 50.</formula><p>baseline bm25 smoothing The settings of this run were:</p><formula xml:id="formula_12" coords="9,140.99,616.86,59.49,48.00">-α R = 1 , -β R = 1, -α N R = 0.1, -β N R = 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Two-dimensional model</head><p>For the two-dimensional model, we decided to use the same 'mild' smoothing parameters of the second run of the BM25 and use two different approaches for finding the best subset of documents to assess. In both cases, the main idea is to start with a plain BM25 to retrieve at most the top k documents or stop this phase earlier if k relevant documents are found before reaching the k-th document. Then, we start to 'sweep' the two-dimensional space with a decision line that starts with a very low (in theory minus infinity) intercept and a slope greater than one in order to find the most relevant documents (in a probabilistic sense). We stop the search when the recall on the judged documents is above a certain threshold (0.999 in our experiments).</p><p>automatic shift rotation We need some intial rounds of feedback to gather some relevant information. We used a BM25 without explicit relevance feedback (probabilities are not updated when relevant documents are found in these rounds) in the following way:</p><p>select the top 10 documents and ask for relevance assessment, if 10 relevant documents are found or 100 documents are assessed, stop this initial search, otherwise repeat with the next 10 documents.</p><p>Then, the actual two-dimensional approach begins:</p><p>1. Find the coordinates of the two-dimensional space, 2. Find the interpolating line of the relevant documents and set this line as the initial decision line, 3. Find the un-judged documents that fall below the decision line, 4. While there are still documents to assess call relevance assesments, update estimates θ R i and θ N R i , recompute coordinates, recompute the interpolating line of the relevant documents, find the un-judged documents that fall below the decision line. 5. If recall is less than 0.999 and there are no documents to judge below the decision line increase the intercept or rotate the decision line (explained in the following paragraph). 6. If there are documents to judge repeat from 4 otherwise stop.</p><p>During phase 5, we shift or rotate the line in the following way:</p><p>-First round (only shift): if the shift is less than -10, increase by 2, otherwise increase by 0.5 (smaller increments). Stop when shift = -0. automatic shift rotation exp Even in this case, we need some initial set of relevant documents. The difference with the previous run is that BM25 is updated with relevance feedback information at each of the following rounds:</p><p>select the top 10 documents and ask for relevance assessment, update θ estimates with relevant information, if 20 relevant documents are found or 100 documents are assessed stop searching, otherwise repeat with next 10 documents.</p><p>Then the two-dimensional approach begins:</p><p>1. find the coordinates of the two-dimensional space, 2. find the interpolating line of the relevant documents and set this line as the decision line, 3. find the un-judged documents that fall below the decision line, 4. while there are still documents to assess:</p><p>call relevance assessments, update estimates θ R i and θ N R i , recompute coordinates, recompute the interpolating line of the relevant documents, compute the interpolating line of non-relevant documents, find the un-judged documents that fall below the decision line, 5. while recall is less than 0.999 and there are no documents to judge:</p><p>increase the intercept or rotate the decision line (explained later). 6. if there are still documents to judge repeat from 4 otherwise stop. About phase 5, the decision to shift or rotate the line:</p><p>-First round (only shift), repeat until the intercept of the decision line is greater or equal to the intercept of the non-relevant interpolating line:</p><p>• If shift &gt; -10, increase shift by 0.5,</p><p>• else if shift &gt; -50, increase shift by 1,</p><p>• else if shit &gt; -100, increase shift by 2,</p><p>• else if shift &gt; -200, increase shift by 5,</p><p>• otherwise increase shift by 10. -Second round (only rotation): decrease rotation by a fixed threshold. Stop when rotation equals the slope of the interpolating line of the relevant documents (adjusted if necessary). -Third round (only shift): increase shift by a fixed threshold until shift equals the intercept of the non-relevant interpolating line (adjusted if necessary). -Stop when recall &gt; 0.999.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,240.32,686.97,134.72,8.74;8,177.99,401.12,259.38,259.38"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Recall -Effort examples</figDesc><graphic coords="8,177.99,401.12,259.38,259.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,408.48,632.01,7.53,8.74;10,140.99,644.03,334.94,8.77;10,140.99,656.09,280.83,8.77"><head>5 .-</head><label>5</label><figDesc>Second round (only rotation): decrease by 0.01. Stop when rotation = 1.5. -Third round (only shift): increase shift by 0.1 until shift = -3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,152.06,115.83,311.25,180.18"><head></head><label></label><figDesc></figDesc><graphic coords="3,152.06,115.83,311.25,180.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,143.41,115.83,328.52,219.90"><head></head><label></label><figDesc></figDesc><graphic coords="6,143.41,115.83,328.52,219.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,177.99,115.84,259.38,259.38"><head></head><label></label><figDesc></figDesc><graphic coords="7,177.99,115.84,259.38,259.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,177.99,401.12,259.38,259.38"><head></head><label></label><figDesc></figDesc><graphic coords="7,177.99,401.12,259.38,259.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,134.77,119.67,345.83,63.87"><head></head><label></label><figDesc>ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2016), Pisa, Italy, July 21, 2016., pages 45-52, 2016. 7. Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr., 3(4):333-389, April 2009. 8. Rita Singh and Bhiksha Raj. Classification in likelihood spaces.</figDesc><table coords="9,146.91,164.72,333.68,18.82"><row><cell>Technometrics,</cell></row><row><cell>46(3):318-329, 2004.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.44,84.73,7.47"><p>http://terrier.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,490.76,342.24,7.86;6,146.91,501.72,184.28,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,241.34,490.76,239.25,7.86;6,146.91,501.72,55.61,7.86">SnowballC: Snowball stemmers based on the C libstemmer UTF-8 library</title>
		<author>
			<persName coords=""><forename type="first">Milan</forename><surname>Bouchet-Valat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>R package version 0.5.1</note>
</biblStruct>

<biblStruct coords="6,138.35,513.01,342.24,7.86;6,146.91,523.97,333.68,7.86;6,146.91,534.92,333.68,7.86;6,146.91,545.88,141.36,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,326.66,513.01,153.93,7.86;6,146.91,523.97,251.97,7.86">Machine learning for information retrieval: TREC 2009 web, relevance feedback and legal tracks</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mona</forename><surname>Mojdeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,422.84,523.97,57.75,7.86;6,146.91,534.92,171.35,7.86">Proceedings of The Eighteenth Text REtrieval Conference</title>
		<meeting>The Eighteenth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-11-17">2009. November 17-20, 2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,557.17,123.80,7.86;6,286.23,557.17,194.36,7.86;6,146.91,568.13,298.96,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,255.24,557.17,6.91,7.86;6,286.23,557.17,194.36,7.86;6,146.91,568.13,39.12,7.86">A Decision to Take for Cost-Sensitive Naïve Bayes Classifiers</title>
		<author>
			<persName coords=""><forename type="first">Giorgio</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,193.67,568.13,155.67,7.86">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="653" to="674" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,579.42,342.24,7.86;6,146.91,590.38,195.74,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,348.53,579.42,128.98,7.86">Text mining infrastructure in r</title>
		<author>
			<persName coords=""><forename type="first">Ingo</forename><surname>Feinerer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,146.91,590.38,119.98,7.86">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,601.67,342.25,7.86;6,146.91,612.63,333.68,7.86;6,146.91,623.59,281.43,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,253.75,601.67,115.50,7.86">Shiny on your crazy diagonal</title>
		<author>
			<persName coords=""><forename type="first">Giorgio</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,388.52,601.67,92.07,7.86;6,146.91,612.63,333.68,7.86;6,146.91,623.59,34.73,7.86">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">August 9-13, 2015. 2015</date>
			<biblScope unit="page" from="1031" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,634.88,342.24,7.86;6,146.91,645.84,333.67,7.86;6,146.91,656.80,333.68,7.86;7,280.67,380.75,54.01,7.86;7,280.42,666.03,54.52,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,380.32,634.88,100.27,7.86;6,146.91,645.84,130.02,7.86">Gamification for machine learning: The classification game</title>
		<author>
			<persName coords=""><forename type="first">Giorgio</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maria</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Zilio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,297.87,645.84,182.71,7.86;6,146.91,656.80,333.68,7.86">Proceedings of the Third International Workshop on Gamification for Information Retrieval co-located with 39th International</title>
		<meeting>the Third International Workshop on Gamification for Information Retrieval co-located with 39th International</meeting>
		<imprint>
			<biblScope unit="page">424</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,240.32,686.97,134.72,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,259.00,686.97,116.03,8.74">3: Recall -Effort examples</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
