<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.51,98.99,338.99,12.90">BJUT at TREC 2016: Real-Time Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,247.07,137.64,47.81,10.75"><forename type="first">Kai</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,304.42,137.64,55.78,10.75;1,360.20,136.11,1.41,6.99"><forename type="first">Zhen</forename><surname>Yang</surname></persName>
							<email>yangzhen@bjut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Information</orgName>
								<orgName type="institution">Beijing University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.51,98.99,338.99,12.90">BJUT at TREC 2016: Real-Time Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B73BF3F9BAE5016530E3D281D892382B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approaches to Real-Time Summarization Track in the TREC 2016, including pushing notifications on a mobile phone task (Task A) and periodic email digesting task (Task B). In Task A, we applied the classifiers to categorize all of the input tweets. External information extracted from Google search engine was well incorporated to enhance the understanding of a users interest. In Task B, all the tweets were classified into a specific topic which was ranked by a scoring system. Finally, we used the non-negative matrix factorization clusering to remove redundancy of the classification results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>With the diversification of social media and the popularity of the Internet, data explosion and information overload problems are becoming increasingly serious, so that people cannot quickly and accurately find their own interest in the event-related information. For example, the Web forum because it contains a lot of useful information has became a typical representative of Web. Users are not only users of information in the network forum, but also the creator of information. This makes the network forum a lot of information every day, and information updates fast. A lot of new information makes the forum sensitive to current events, especially some unexpected events. The general users to enter the forum are basically the main post or replies as the object of browsing, the most common form is the same way to browse the forum content. If he wants to understand the whole process of an event and some of the events associated with the description, he may need to browse a large number of topics in order to find the required information, but find out the information may not be complete. The result of this browsing is to spend a lot of time, and not necessarily find satisfactory result. How to effectively summarize from the mass media, such as forums and automated detection of related topics, to help target customers accurate access to the most valuable relevant information abstracts more and more people's attention.</p><p>In the field of computer information retrieval, Text Retrieval Conference (TREC) came into being in 1992, along with the development of search technology and the deepening of research, driven by various problems and require-ments. This is an activity conducted by the Information Retrieval (IR) community to conduct a search system and user evaluation. It is co-sponsored by the National Institute of Standards and Technology (NIST) and the Advanced Research Projects Agency (DARPA), and is held annually , Its participating groups from many countries, research and academic institutions, government departments and industrial and commercial enterprises, constitute a broad representation of the basis of the search evaluation, the participating units with their own systems for NIST unified corpus and for common tasks To carry out research, and finally by the organizers of NIST to determine the relevance of a unified.</p><p>This work is aimed at TREC's Real-Time Summarization Track project and will develop a new system according to the new requirements of the conference. The system can play back the useful, up-to-date and timely update of emergencies in chronological order. Information, so that users can in the event of an emergency, can effectively monitor and event-related information, but also to facilitate public opinion monitoring of government departments, to take preventive measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Framework</head><p>It is a real-time job in this years Microblog track that teams listen to the twitter stream via official common API.</p><p>• Web Crawler, according to profiles provided by the official crawling the search results as an extended database.</p><p>For profiles, we extract key words as our basic features.</p><p>• Query expansion, Extend the database according to the event, we will deal with the expansion of each event, through the TF-IDF algorithm to query the results of the keywords extracted.</p><p>• Text preprocessing, the tweets are processed into the document vectors that we can use.</p><p>• Text categorization, According to TREC's official 2015 Twitter data set for classifier training, in the better performance of the classifiers to select three classifiers, as our evaluation classifiers. Each classifier is independent.</p><p>• Text clustering, we use the non-negative matrix factorization method to cluster. The relevant tweets in the cluster centers are extracted as our abstracts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Web Crawler</head><p>Short text retrieval suffers severely from vocabulary mismatch problem. Terms overlapping between profiles and tweets are relatively small. Semantic expansion methods can be leveraged to enhance the retrieval performance. Through TREC official title and description of the incident, we have to do an expansion of each event, mainly based on the search engine query results. We take the headline of the incident as a query, the search engine returns the results obtained by the crawler, we only crawl the first N results of the search results, save the documents, and these documents will serve as our event expansion database. Abstract texts are treated as a document, each document contains several terms. After gathering all the documents, we use TFIDF algorithm to calculate TFIDF value of each term for all the profiles. The top k terms of each profiles are used to expand the information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Expansion</head><p>Because the data in the tweets are mostly short text, we will encounter a problem in the process of text processing. That is, in the short text, because the text is short, Understanding queries and documents is a loss of semantics, causing the query and the document to lose their original connection. Therefore, we extend the event. Extend the database according to the event, we will deal with the expansion of each event, through the TF-IDF algorithm to query the results of the keywords extracted. Specifically, the TF-IDF value is calculated for each word in the database, and then the first N values are extracted as the result of our query expansion by sorting according to the TF-IDF value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Preprocessing</head><p>Due to the large amount of data and the redundancy of the data, the data are preprocessed. First of all, we removed non-English and text length is too short tweet. The filtered text is used to stop the words and stemming, and the processed tweets are used to construct the document word frequency vector according to the word frequency. And we remove non-English and short tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Categorization</head><p>According to TREC's 2015 tweeter dataset <ref type="bibr" coords="2,248.96,530.46,43.54,8.64;2,54.00,541.41,21.44,8.64" target="#b1">(Zhu et al. 2015)</ref>, three classifiers were selected as the classifiers. The selected classifiers are: random forests, gradient bo decision trees, and decision trees.</p><p>The decision tree is a prediction model; it represents a mapping between object attributes and object values. Each node in the tree represents an object, and each branch path represents a possible attribute value, and each leaf node corresponds to the object represented by the path experienced by the root node to the leaf node value. Decision tree only a single output, if you want a complex output, you can create an independent decision tree to deal with different output. Decision trees in data mining are a common technique that can be used to analyze data and can also be used for forecasting purposes (as the above bank officials use to predict loan risk).</p><p>Random forest as the name suggests, is to use a random way to build a forest, there are a lot of forest decision tree composition, and random forest each tree is not associated with the decision tree. After getting the forest, when there is a new input sample, let each decision tree in the forest make a decision to see which class (for the classification algorithm) this sample should belong to, and then see which One class is selected the most, and the sample is predicted for that class.</p><p>GBDT (Gradient Boosting Decision Tree), also known as MART (Multiple Additive Regression Tree), is an iterative decision tree algorithm, the algorithm consists of multiple decision trees, and all the tree's conclusions add up to do the final answer. It was proposed to be the beginning of the SVM together with the ability to be considered a generalization algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Clustering</head><p>Since we classify each of the tweets with a classifier, the purpose of our text clustering is to deduce the weights of the same or similar meanings in the classified tweets, of tweets. However, because the classification results are not necessarily correct, we hope to use the positive and negative results of the classification to guide our clustering results, so we use non-negative matrix decomposition method to cluster.</p><p>The relevant tweets in the cluster centers are extracted as our abstracts.We define the differences between tweets that have different classification results as C(i, j). The conflicts regularization is to minimize the following term as <ref type="bibr" coords="2,525.47,364.92,32.53,8.64;2,319.50,375.88,33.62,8.64" target="#b0">(Tang et al. 2013)</ref>,</p><formula xml:id="formula_0" coords="2,360.43,387.67,156.15,30.32">min n i=1 n j=1 C(i, j)||U (i :) -U (j :)|| 2 2</formula><p>(1) Tweets close to each other in the low-rank space are more likely to have the small the conflict and their distances in the latent space are controlled by their conflicts. For example, C(i, j) controls the latent distance between u i and u j . A smaller value of C(i, j) indicates that u i and u j are more likely to have the small the conflict according to the property of conflicts. Thus we force their latent representations should be as close as possible, while a larger value of C(i, j) tells that the distance of their latent representations should be larger. After some derivations, we can get the matrix form of conflicts regularization,</p><formula xml:id="formula_1" coords="2,354.75,545.37,203.25,155.49">1 2 n i=1 n j=1 C(i, j)||U (i :) -U (j :)|| 2 2 = 1 2 n i=1 n j=1 d k=1 C(i, j)(U (i :) -U (j :)) 2 = n i=1 n j=1 d k=1 C(i, j)U 2 (i, k) - n i=1 n j=1 d k=1 C(i, j)U (i, k)U (j, k) =T r(U T LU )<label>(2)</label></formula><p>Where L = D -Z is the Laplacian matrix and D is a diagonal matrix with the i-th diagonal element D(i, j) = n j=1 Z(j, i) and Z(i, j) =</p><formula xml:id="formula_2" coords="3,54.00,77.19,238.50,23.81">1 ||a[i]-a[j]|| , a[i] is the label from classifier.</formula><p>With the definition of conflicts regularization, we propose a framework, based on matrix factorization. The problem is to solve the following optimization,</p><formula xml:id="formula_3" coords="3,54.00,141.58,238.50,96.52">min F = ||A -U V T || 2 F + α||U || 2 F + β||V || 2 F + γT r(U T LU ) (3) s.t.U ≥ 0, V ≥ 0 by removing constants in the objective function, F =T r(-2A T U V T + V U T U V T ) + αT r(U U T ) + βT r(V V T ) + γT r(U T LU )<label>(4)</label></formula><p>using the KKT complementary condition and we can get the result of the optimization,</p><formula xml:id="formula_4" coords="3,96.40,274.97,196.10,11.03">AV + γZD = U V T V + αU + γDU<label>(5)</label></formula><p>with define M = AV +γZD and N = U V T V +αU +γDU so,</p><formula xml:id="formula_5" coords="3,114.40,329.00,178.10,22.31">U (i, k) ← U (i, k) M (i, k) N (i, k)<label>(6)</label></formula><p>the same with V,</p><formula xml:id="formula_6" coords="3,101.97,382.95,190.53,23.15">V (i, k) ← V (i, k) A T U V U T U + βV<label>(7)</label></formula><p>We alternatively update U and V until achieving convergence. After topic clustering, we select each topic clustering center as the final tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Results</head><p>There are some results of our system. And the evaluation is not complete, the ranking results is as (http://www.trects.org/), In Task A, we present the results in real time, using classifiers as random forests, decision trees, and gradient boosting decision trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we presented the implementation details of our runs for Real-Time Summarization Track, the future works emphasis should be on how to improve the accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,319.50,57.16,238.49,8.96;3,329.46,68.44,33.22,8.64;3,319.50,94.42,238.49,8.96;3,329.46,105.70,33.22,8.64;3,319.50,131.69,238.49,8.96;3,329.46,142.96,33.22,8.64;3,319.50,168.95,238.49,8.96;3,329.46,180.23,33.22,8.64;3,319.50,206.53,238.50,8.64;3,319.50,217.49,147.77,8.64"><head></head><label></label><figDesc>system achieves the score of 246.1, where the 760578482128752640 is the tweetid.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,319.50,399.47,238.50,8.64;3,319.50,410.26,238.50,8.81;3,319.50,421.22,238.50,8.58;3,319.50,432.18,88.43,8.81" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,515.93,399.47,42.07,8.64;3,319.50,410.43,144.70,8.64">Exploiting homophily effect for trust prediction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,483.33,410.26,74.67,8.58;3,319.50,421.22,238.50,8.58;3,319.50,432.18,25.86,8.58">Proceedings of the sixth ACM international conference on Web search and data mining</title>
		<meeting>the sixth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="53" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,319.50,451.70,238.50,8.64;3,319.50,462.66,238.50,8.64;3,319.50,473.62,238.50,8.64;3,319.50,484.57,238.50,8.64;3,319.50,495.36,115.67,8.81" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,319.50,473.62,238.50,8.64;3,319.50,484.57,238.50,8.64;3,319.50,495.53,69.87,8.64">Nudtsna at trec 2015 microblog track: A live retrieval system framework for social network based on semantic expansion and quality model</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Dongchuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chengliang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,408.32,495.36,21.48,8.58">TREC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
