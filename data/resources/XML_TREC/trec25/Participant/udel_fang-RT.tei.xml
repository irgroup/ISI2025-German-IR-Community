<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,92.91,79.49,426.18,12.62;1,273.97,97.42,64.07,12.62">Query Performance Prediction and Topic Shift in Microblog Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,252.59,137.31,43.86,8.74"><forename type="first">Kuang</forename><surname>Lu</surname></persName>
							<email>lukuang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.15,137.31,40.27,8.74"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<addrLine>140 Evans Hall</addrLine>
									<postCode>19716</postCode>
									<settlement>Newark, Delaware</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,92.91,79.49,426.18,12.62;1,273.97,97.42,64.07,12.62">Query Performance Prediction and Topic Shift in Microblog Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4A0E3E1C80064F82284715595CFFC5CC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In Microblog retrieval, a system's ability to know when to "shut up" and how many results to return for a given query can have huge impact on its performance <ref type="bibr" coords="1,418.64,270.21,9.22,7.86" target="#b0">[1]</ref>. In addition, since relevant but redundant tweets will be deemed as irrelevant, it is also important to detect whether a tweet contain novel information or not. Therefore, in this year's Real-Time Summarization Track, we focus on estimating result cut-off thresholds and redundancy thresholds. Query performance prediction techniques [2, 3] can be used to predict the performance of a query and therefore would be helpful in deciding both thresholds. Moreover, we define topic shift of a query as the change of subtopics or aspects discussed or mentioned on Twitter over time. We suggests that using it could help us further refine the thresholds since it reflects how much new information emerges on Twitter.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Real-Time Summarization Track aims to build systems to retrieve tweets for interest profiles in two scenarios: 1.tweets are posted to the evaluation broker as soon as detected relevant; 2. relevant tweets are identified at the end of each day, simulating an email digest summaries for interest profiles. In both scenarios, the retrieved tweets should be both relevant and novel.</p><p>There are two core issues that a system needs to address in order to produce good results. A study about the previous year's Microblog Track suggests that a system's ability to identify "silent days", meaning days without relevant tweets, has huge impact on the system's performance <ref type="bibr" coords="1,454.35,498.15,9.96,8.74" target="#b0">[1]</ref>. In addition, it is also important to decide how many tweets to return for each interest profile since there might not be as many as 10 relevant tweets, which is the limit per topic per day, given a query and a day. These two issues both can be solved by setting proper cut-off score thresholds. The number of returned tweets can be controlled by the score threshold. In the extreme case, if the score threshold is higher than the highest score of tweets of a day, the system will return no tweets for the day, which is ideal for a "silent day".</p><p>Query performance prediction techniques, such as clarity score <ref type="bibr" coords="1,364.54,572.10,9.96,8.74" target="#b1">[2]</ref>, are used to predict the performance of a query. Intuitively, how good the performance is for a query is closely related to how many relevant documents there are at the top of the result list. Therefore, we leverage clarity scores to decide cut-off score thresholds. In addition to that, query performance predictor could help adjusting the redundancy threshold. If a query performs well in a day, the redundancy threshold can be relaxed, and vise versa. Besides query performance prediction, the topic shift of a query seems to be beneficial as well. We define topic shift of a query between two days as the change of subtopics or aspects for the query mentioned or discussed on Twitter of the two days. If the topic shift is significant for a query, it is likely that novel information about the interest profile emerges on the latter day. In this case, it is desired that our system returns more tweets on the day to cover the new subtopics.</p><p>In this year's Real-Time Summarization Track, we aim to explore how query performance prediction and topic shift could help us to accurately predict the cut-off score threshold and redundancy threshold.</p><p>We use the same corpus we downloaded using twitter "sample" end point of the twitter stream api<ref type="foot" coords="2,512.81,103.93,3.97,6.12" target="#foot_0">1</ref> for both scenarios. Non-English tweets were filtered out. For the downloaded tweets, only "id" and "text" fields are used. If a tweet is a retweet, the "text" field of the original tweet is used since retweets will be normalized to the underlying tweets for evaluation. For the interest profiles, we only use "title" field as initial queries for our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Scenario A</head><p>In scenario A, we mainly focus on employing query performance prediction techniques to predict the cut-off score threshold for each query of each day. Before doing that, we need a reasonable baseline to start with. Our baseline is similar to <ref type="bibr" coords="2,242.87,225.19,9.96,8.74" target="#b3">[4]</ref>. We use the "title" field of interest profiles as queries and issue these queries to three commercial search engines: Yahoo, Google, and Bing. The top 100 results' snippets of each query are retrieved and merged together to form a corpus. We use mutual information between the query terms and other terms in the corpus to select semantically related terms of the original queries and use them as expansion terms to perform retrieval on the tweet corpus <ref type="bibr" coords="2,405.81,273.01,9.96,8.74" target="#b4">[5]</ref>.</p><p>After building the baseline, the next step is to predict the score thresholds using query performance prediction techniques. Clarity score <ref type="bibr" coords="2,239.95,296.92,10.52,8.74" target="#b1">[2]</ref> seems suitable for our purpose since it is a query performance predictor which indicates how ambiguous or difficult a query is. More difficult a query is, it is more likely that there are less relevant tweets of the query. However, clarity score itself is not enough since it cannot directly reflects how many relevant tweets are on the top of the result list. Considering a theoretical case when a corpus replicates itself several times, the number of relevant tweets of a query will increase if there are any relevant tweets in the original corpus, whereas the clarity score of the query will remain the same. Therefore, we incorporate the highest score of the result list, as well as the score difference between top 10 results into our system. This additional information shows the score change trend of the top scores which may indirectly show how many relevant tweet are likely to be in the top results.</p><p>We trained a linear regression model based on the idea described above to predict the score threshold. More specifically, the clarity score, the highest score, and score differences between top 10 results of one day are used as features, while the ideal score threshold of the next day is used as the expected output value of the system. When deciding the ideal score threshold for a day, we choose to use two different performance metrics: precision and f1, which results in two different regression models, which are named as precision model and f1 model. These trained models are then used to on refine the results of the baseline. Afterwards, a simple redundancy check, which uses Jaccard distances between a tweet and all previous retrieved tweets, is used to remove redundant tweets. We submitted three runs described below:</p><p>-U DInf oSP P : In this run, the snippets are crawled before the evaluation period started and all the expansion terms are generated based on these snippets. The precision model is used to predict score threshold. -U DInf oSF P : Similar to the previous run, except that the f1 model is used.</p><p>-U DInf oDF P : Similar to U DInf oDF P , except that the snippet corpus of the new interest profiles of this year, whose topic ids have "RTS" as prefix, are crawled at the beginning of everyday. Thus, the expansion terms are newly generated each day. In this way, we hope that the expansion terms could capture the emerging new aspects of the interest profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Scenario B</head><p>In scenario B, in addition to using query performance prediction, we aim to explore how the topic shifts of queries between days could help deciding the score thresholds and redundancy thresholds. If topic shift seems to be small between two days, it is reasonable to return fewer, or even no, results for the latter day, and vice versa. Similarly, when the topic shift is very significant, the redundancy threshold could be decreased in order to capture the emerging information of the query for the latter day.</p><p>The topic shift can be captured by measuring the difference between relevance language models between the two days. Since the true relevant language model for a query is unknown, it needs to be estimated. We chose to estimate the relevant language model of a query for a day by using top 100 results of the query for the day generated by the baseline system. However, since the accuracy of the estimation varies among days and queries, using only the estimated relevant language model differences can be misleading. If a query performs well on a day for a query, it is likely that our estimation closely captures the original model. On the other hand, if a query performs poorly on a day, or in the extreme case that there are no relevant tweets for the day, our estimation can hardly be trusted. Therefore, in order to correctly use the estimated relevant language model differences, we also need to incorporate the query performance information of the days that the relevant language models are estimated. In other words, by combining these two types of information, we could more accurately estimate the topic shift over time.</p><p>Based on the idea discussed above, we incorporate the topic shift into our cut-off score threshold framework by adding the difference between the estimated relevant language models between a day and the day before, as well as the clarity scores of the two days of the query as additional features to the linear regression model used in scenario A. We tried various language model difference measures and tested them on 2015 Microblog Track data. Jaccard distance was chosen since it produced the best performance. It is also important to note that, instead of using f1 and precision, we used ndcg@10 in scenario B for tuning since it is the official evaluation metric for scenario B.</p><p>For redundancy threshold, we trained a linear regression model based on last year's data. Given a query and any two days of the evaluation period, we select one tweet from each day to form a tweet pair. The topic shift information, meaning the clarity scores and language model difference, of these two days for the query was computed and used as features. For all the tweet pairs of the two days, the Jaccard distances are computed and the optimal value of it in terms of f1 score for redundancy classification is used as the predicted threshold.</p><p>We submitted three runs for scenario B to explore the usefulness of topic shift:</p><p>-U DInf o T N : A baseline run for scenario B without using topic shift. It is similar to UDInfoSFP of scenario A except the fact that we use the clarity, top score, and score differences of the day itself instead of that of the previous day to predict the cut-off score threshold of the current day. Furthermore, we use ndcg@10 as the metric in training the cut-off threshold prediction model. The redundancy threshold is the same as what is used in scenario A: a fixed redundancy threshold.</p><p>-U DInf o T lmN : It is built by adding topic shift features to the cut-off threshold prediction to U DInf o T N .</p><p>-U DInf o T lmN lm: It is built by adding topic shift features to the redundancy threshold prediction to U DInf o T lmN .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Analysis</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,135.46,651.21,114.45,7.86;3,130.95,668.52,50.43,7.89;3,228.19,668.55,30.38,7.86;3,128.29,679.95,54.47,7.86;3,230.58,679.95,25.60,7.86;3,128.29,691.36,54.47,7.86;3,230.58,691.36,25.60,7.86;3,127.43,702.77,56.19,7.86;3,230.58,702.77,25.60,7.86;3,362.03,651.21,114.58,7.86;3,357.58,668.52,50.43,7.89;3,441.66,668.55,56.69,7.86;3,356.00,679.95,52.63,7.86;3,457.21,679.95,25.60,7.86;3,350.49,691.36,63.64,7.86;3,457.21,691.36,25.60,7.86;3,344.98,702.77,75.64,7.86;3,457.21,702.77,25.60,7.86"><head>- 1 U</head><label>1</label><figDesc>DInf oSP P 0.0915 U DInf oSF P 0.0642 U DInf oDF P 0.0699 (b) Performances of Task B Run Name nDCG@10-1 U DInf o T N 0.1315 U DInf o T lmN 0.1451 U DInf o T lmN lm 0.1445</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,213.07,629.31,185.86,8.74"><head>Table 1 :</head><label>1</label><figDesc>Performances of Submitted Runs</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,89.33,706.51,265.62,7.86"><p>https://dev.twitter.com/streaming/reference/get/statuses/sample</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The performances of submitted runs for different tasks are shown in Table <ref type="table" coords="4,420.09,82.53,3.87,8.74">1</ref>. Note that only primary metrics, which are EG -1 for task A, and nDCG@10 -1 are reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="4,82.95,175.86,449.67,7.86;4,91.52,186.82,441.11,7.86;4,91.52,197.78,263.50,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,266.90,175.86,262.03,7.86">An exploration of evaluation metrics for mobile push notifications</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,104.79,186.82,427.84,7.86;4,91.52,197.78,81.49,7.86">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;16</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="741" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,82.95,208.74,449.68,7.86;4,91.52,219.70,441.11,7.86;4,91.52,230.66,192.76,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,287.00,208.74,120.33,7.86">Predicting query performance</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,434.04,208.74,98.59,7.86;4,91.52,219.70,441.11,7.86;4,91.52,230.66,10.75,7.86">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;02</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,82.95,241.61,449.68,7.86;4,91.52,252.55,258.56,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,352.28,241.61,180.36,7.86;4,91.52,252.57,40.54,7.86">Predicting query performance by query-drift estimation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Raiber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Markovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,140.20,252.57,89.97,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,82.95,263.53,449.68,7.86;4,91.52,274.49,123.92,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,172.74,263.53,263.35,7.86">Evaluating the effectiveness of axiomatic approaches in web track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,458.16,263.53,74.48,7.86;4,91.52,274.49,91.23,7.86">Proceedings of the 2013 TREC conference</title>
		<meeting>the 2013 TREC conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,82.95,285.45,449.67,7.86;4,91.52,296.41,441.11,7.86;4,91.52,307.37,221.63,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,167.11,285.45,288.46,7.86">Semantic term matching in axiomatic approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,474.95,285.45,57.67,7.86;4,91.52,296.41,441.11,7.86;4,91.52,307.37,39.60,7.86">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;06</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;06<address><addrLine>New York, NY, USA, ACM</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
