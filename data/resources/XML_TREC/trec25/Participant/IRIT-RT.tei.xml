<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.42,88.00,287.45,12.90">IRIT at TREC Real Time Summarization 2016</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,107.43,126.35,91.05,8.64"><roleName>Lamjed</roleName><forename type="first">Bilel</forename><surname>Moulahi</surname></persName>
							<email>moulahi@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,200.97,126.35,42.96,8.64"><forename type="first">Ben</forename><surname>Jabeur</surname></persName>
							<email>jabeur@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.49,126.35,79.11,8.64"><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
							<email>abdelhamid.chellal@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,336.00,126.35,60.79,8.64"><forename type="first">Thomas</forename><surname>Palmer</surname></persName>
							<email>palmer@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.65,126.35,54.94,8.64"><forename type="first">Lynda</forename><surname>Tamine</surname></persName>
							<email>tamine@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,465.66,126.35,33.21,8.64;1,192.73,138.30,45.58,8.64"><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
							<email>boughanem@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.86,138.30,90.15,8.64"><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.61,138.30,53.96,8.64"><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
							<email>hubert@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.42,88.00,287.45,12.90">IRIT at TREC Real Time Summarization 2016</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FC387685B295F006C8E6230859EA6432</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>real-time</term>
					<term>social media</term>
					<term>user profile</term>
					<term>word similarity</term>
					<term>filtering</term>
					<term>clustering</term>
					<term>rapidity</term>
					<term>entities</term>
					<term>personalization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the participation of the IRIT laboratory (University of Toulouse) to the Real Time Summarization track of TREC 2016. This track consists in a real-time filtering the tweet stream and identifying both relevant and novel tweets to be pushed to user in real-time. Our team proposes three different approaches: (1) The first approach consist of a filtering model that combines several summarization constraints (2) The second approach for the scenario A is composed of three filters adjusted sequentially in which we use word similarity based function to evaluate the relevance of an incoming tweet. The generation of a batch of up to 100 ranked tweets is formulate as an optimization problem. (3) The third approach consist of a step by step stream selection method focusing on rapidity, and taking into account tweet similarity as well as several features including content, entities and user-related aspects. We describe in this paper the three proposed approaches and we discuss official obtained results for each of them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media streams provide real time updates that cover scheduled and unscheduled events which makes them a valuable source of information for user who wishes to receive timely notification to keep up-to-date on topic of interest. Indeed of the volume and the redundancy of the posted information in the social media stream, one of the main challenge consists in the fact that to be effective, notifications must achieve a balance between pushing too much and pushing too little updates. Push too little and the user misses important updates; push too much and the user is overwhelmed by irrelevant/redundant information <ref type="bibr" coords="1,150.77,499.23,10.43,8.64" target="#b0">[1]</ref>. Although several models have been proposed in the context of ad-hoc tweet search <ref type="bibr" coords="1,495.01,499.23,10.64,8.64" target="#b1">[2,</ref><ref type="bibr" coords="1,101.89,511.19,7.05,8.64" target="#b2">3]</ref>, the task of prospective notification in tweet stream, which is proposed by the real time summarization Track of TREC 2016, is still under-explored.</p><p>The Microblog real time summarization Track aim at monitoring the social media data-stream in order to push tweets to users with respect to their topical interest-based profile. One main assumption yields in the TREC guidelines is that notifications and digests might enable the user to keep up-to-date on the topic of interest. In this aim, the track is split into two main scenarios:</p><p>1. The Scenario A, called "Push notifications", consists in an instantly tweet notification assuming a short time period between the tweet publication and the tweet pushing. Participating system are allowed to push up to 10 notifications per day per interest profile. 2. The scenario B, called "Periodic email digest" consist on daily selecting up to 100 tweets for each interest profile to be send to user via email. It's required that tweets should be relevant and novel but timeliness is not important.</p><p>In this paper, we investigate three main approaches aiming at retrieving tweets in a real-time fashion with respect to the push and digest scenarios:</p><p>-Filtering model that decompose the filtering task to several sub-tasks in accordance to the summarization constraints. The final filtering score is aggregated as the product of scores obtained by sub-filtering functions. -Real time filtering approach composed of three filters adjusted in sequential way which are related to topicality, relevance and novelty respectively. The decision to push/ignore a tweet is made immediately. The main contribution of this approach is we propose an adaptation of the extend Boolean model based on word similarity to evaluate the relevance score of the incoming tweet with respects to the topic. Indeed, we formulate tweet summarization problem as an optimization problem to general a email digest summary for the scenario B. -A step by step stream selection that focuses on rapidity and that takes into account several features.</p><p>These features are divided into three groups, including features about content, entities and user.</p><p>This paper is organized as follows. Section 2 introduces the streaming filter model for real-time summarization. Section 3 describes word similarity based approach for Real time tweet summarization. Section 4 presents the tweet selection approach based on speed and feature scores. Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Streaming filter model for real-time summarization</head><p>Real-time summarization of tweets consist in selecting from a continuous stream of tweets T =&lt; t 1 ,t 2 , . . . ,t n &gt; the set of relevant ones with respect of the tracked topic q. The result summary S =&lt; t 1 ,t 2 , . . . ,t m &gt; must not include redundant tweets and must respect a length constraint in terms of the number of tweets. This problem can be viewed as a filtering task where filtering function F(t i ) is applied to the incoming tweet t i in order to decide if the tweet must be included in summary F(t i ) = 1 or neglected F(t i ) = 0. We propose here a filtering model that combines several summarization constraints that must be verified, namely the tweet quality, the topical relevance and the information redundancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Streaming filter model</head><p>Tweets to be included in the summary must respect several constraints, for instance, the summary length, the topical relevance and the non-redundancy of information with regards to past included tweets. Hence, we propose to decompose the filtering task into sub-filtering tasks where each verifies that the tweet respect a particular constraint. A sub-filtering functions F k (t i ) is defined in accordance to the k th summarization constraint with F k (t i ) = 1 allows to include tweet t i in the summary or F k (t i ) = 0 otherwise. The global filtering function F(t i ) is computed as the product these functions requiring that tweet t i must verify all constraints. F(t i ) is computed as the following.</p><formula xml:id="formula_0" coords="2,269.85,567.47,234.55,18.65">F(t i ) = ∏ ∀k F k (t i )<label>(1)</label></formula><p>Table <ref type="table" coords="2,142.17,600.38,5.08,8.64" target="#tab_0">1</ref> lists constraints that we suggest to consider for summarizing real-time stream. Further constraints could be added to this list in order to satisfy advanced users preferences. A detailed description of computation of each filtering function is defined in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Computing filtering scores</head><p>We details in the section the computation of filtering functions introduced in table <ref type="table" coords="2,429.64,685.23,3.74,8.64" target="#tab_0">1</ref>. Summary length. The length constraint suggest that the length of the summary must not overpass l.</p><p>As proposed in summarization scenarios A and B, the length constraints is defined for a limited time window (i.e. day). The length constraint is set to l = 10 and l = 100 for scenario A and scenario B, respectively. Let θ i be the timestamp of tweet t i and d(θ i ) the day in witch t i is published. The current daily summary is defined by the subset of tweets S d(θ i ) = {t j ∈ S|d(θ j ) = d(θ i )}. Accordingly, we define the filtering function F 0 (t i ) in respect of summary length as the following:</p><formula xml:id="formula_1" coords="3,251.45,306.36,252.96,23.30">F 0 (t i ) = 1, |S d(θ i ) | &lt; l 0, otherwise<label>(2)</label></formula><p>Language preference. It is interesting to push tweets in user's language. Tweets in other languages are useless unless they are translated. For this aim we propose to compute a language filtering score F 1 (t i ) as the following.</p><formula xml:id="formula_2" coords="3,248.46,387.12,255.95,23.30">F 1 (t i ) = 1, lang(t i ) ∈ G 0, otherwise<label>(3)</label></formula><p>With lang(t i ) is the language of the tweet and G is a set of language preferences for the user. In the context of this track, we consider tthat G = {en} since only English tweet are taken into consideration.</p><p>Lexical restriction. In order to ensure a high quality of tweets, we propose to apply a lexical filter that eliminates tweet containing "bad words". Let L = {w 1 , w 2 , ..., w p } be the lexicon of undesirable words. The lexical filtering score F 2 (t i ) is computed as the following:</p><formula xml:id="formula_3" coords="3,251.21,509.72,253.19,23.30">F 2 (t i ) = 1, |t i ∪ L| = 0 0, otherwise<label>(4)</label></formula><p>The lexical filter may be extended to include other types of lexicon in addition to "bad words" such as "power words" (e.g. "free", "easy" and "best" ) which are used for catching attention and emotionally impacting the reader.</p><p>URL presence. Experiments results on previous TREC microblog track <ref type="bibr" coords="3,400.94,598.06,11.85,8.64" target="#b3">[4]</ref> show that presence of URL in the tweet is a good indicator of its relevance. Accordingly we propose a strict filtering constraint that suggest to filter out tweets that do not contain any URL.</p><formula xml:id="formula_4" coords="3,250.12,646.32,254.29,23.30">F 3 (t i ) = 1, urls(t i ) ≥ 1 0, otherwise<label>(5)</label></formula><p>With urls(t i ) is the number of URLS in the tweet.</p><p>Topical relevance. Notified tweet may be relevant with regards to interest profile. In order to determine the relevance of the tweet we adopt a strict policy suggesting that a significant number of terms from tracking topic must be included in the tweet. In fact, tracking topic are different from regular search query in terms of motivation since user have an exact idea about what she is looking for and carefully choose a tracking query that target his need. Hence, we propose that tweet must contain at least α terms. If α &gt; |q|, all topic terms must be present in the tweet. The topical filtering score F 4 (t i )is defined as the following:</p><formula xml:id="formula_5" coords="4,231.92,180.96,272.49,23.30">F 4 (t i ) = 1, |q ∪ t i | ≥ min(α, |q|) 0, otherwise<label>(6)</label></formula><p>with |q ∪ t i | is the number of distinct common terms between the topic and the tweet. We propose to set up parameter α to arbitrary value α = 3. This value may be adjusted by futher experiments.</p><p>Non redundancy. Pushed tweets to notification may be not redundant and deliver a new information to user at each time. Otherwise, redundant notifications may cause user fatigue regardless if there are relevant or not. For this aim, we propose to apply a redundancy filter that eliminates tweet containing repeated information to what have been previously notified. In particular, we propose to check the similarity of incoming tweet with recently pushed ones across the past time window ∆t.</p><p>Let Q =&lt; t 1 ,t 1 , . . . ,t q &gt; a timed-queue of previously pushed tweet. All tweets in Q belong to the last window ∆t verifying so the condition θ i &lt;= θ now -∆t, ∀t i ∈ Q with θ now is the actual time. We propose to compute a redundancy score of incoming tweet as the maximum similarity score to tweets in queue Q. In this context, we define the similarity between two tweets t i and t j as the proportion of common terms while taking into account the length of reference tweet t i . The redundancy score, noted r(t i , Q), is computed as follows.</p><formula xml:id="formula_6" coords="4,253.86,398.25,250.54,25.00">r(t i , Q) = argmax t j ∈Q |t i ∪ t j | |t i |<label>(7)</label></formula><p>With |t i | is the number of distinct terms in t i and |t i ∪ t j | is the number of distinct common terms between t i and t j . We note that normalizing the number of common terms over the length of incoming tweet t i in the similarity quotient</p><formula xml:id="formula_7" coords="4,238.55,459.47,18.09,7.53">|t i ∪t j |</formula><p>|t i | instead of using the minimum length of the two tweets as in overlap coefficient</p><formula xml:id="formula_8" coords="4,178.16,477.04,36.09,16.85">|t i ∪t j | min(|t i |,|t j |)</formula><p>reduces the fallacy of too short tweets in queue Q in terms of redundancy towards longer novel tweets.</p><p>In order to compute the redundancy filtering score, we propose to compare the redundancy score r(t i , Q) of t i to a fixed threshold. Tweet t i will be filtered out if respective redundancy score overpass β . The filtering redundancy score F 5 (t i ) is defined as follows.</p><formula xml:id="formula_9" coords="4,249.15,559.27,255.25,23.30">F 5 (t i ) = 1, r(t i , Q) &lt; β 0, otherwise<label>(8)</label></formula><p>In this experiments we set up β parameter to arbitrary value β = 0, 6 which represent a strict threshold for eliminating redundant tweet. The value of β could be configured experimentally as the average overlap similarity between the relevant tweets of each topic from past released datasets of TREC microblogs. Besides, we set up the time window ∆t parameter of the timed-queue Q to arbitrary value of ∆t = 1day requiring that user must not receive a redundant tweet in the same day. This value is reasonable as most news editor refresh their content daily. Increasing this time window to several days may cause over-filtering of novel tweets that may use partial vocabulary from past tweets in summary but announce a novel information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results</head><p>As our filtering model is compatible for both scenarios A and B, we submitted the same generated summary for both of them. For scenario A, tweet are pushed in real time to the evaluation API. The same tweets are used to make our run for scenario B while ranking them based on their recency. We notice that we include only 10 tweet per daily digest summary for scenario B although 100 tweets are allowed. We discuss in what follows obtained results for scenario A and scenario B  <ref type="table" coords="5,179.80,306.76,5.08,8.64" target="#tab_1">2</ref> compares the number of relevant, redundant tweet, non relevant tweet, judged tweet and submitted tweets the for our system and track baseline. First, we note that a large part of submitted tweets by our system (76%) are unjudged and the same for the baseline (77%). Having the similar proportions of judged tweets, the comparison must be fair but deeper pooling for relevance judgment is required to confirm this analysis. Besides, our system is able to deliver more relevant tweets (201) compared to the baseline (148). We report in the last column of the table the precision of relevant tweet out of the summary length. Precision values show that our system slightly overpass the baseline with overall precision of 0,09 compared to 0,07. We notice that The precision values for both systems are considerably low and this is due to large number of unjudged tweets considered as irrelevant. Table <ref type="table" coords="5,141.66,540.60,5.08,8.64" target="#tab_2">3</ref> compares values of official measures obtained by our system and the track baseline. We notice that in contrast of EG1 and nCG1 , the EGO and nCG0 ignore silent days where no relevant document is published so participating systems receive equal gain. Our system overpasses values obtained by baseline for the four measures EG1, EGO, nCG1 and nCG0. This highlights that our filtering model is more effective for summarization in terms of the relevance of included tweets as well as recognition that there are no relevant tweets to push.</p><p>Table <ref type="table" coords="5,140.85,613.50,4.90,8.64" target="#tab_2">3</ref> present also obtained results for Gain Minus Pain (GMP) measure with different configurations GMP.33, GMP.5 GMP.66. Our systems present negative values for All the the three configurations. This highlights however that our system generates summaries with more irrelevant tweet than relevant ones. Despite these negative results, our system show always higher GMP values compared to the baseline. Finally and comparing the latency values, we note that our system and baseline show near mean values while our system present a very low median values compared to the baseline. We conclude that our model is more active. It pushs relevant tweets to summary in too short time. scenario B. Table <ref type="table" coords="6,178.20,91.42,4.96,8.64" target="#tab_3">4</ref> show nDCG1 and nDCG0 values obtained by our system and track baseline. We remember that these measures are computed as the average of nDCG@10 scores for each day and topic. In contrast of nDCG1, the nDCG0 discard silent days so participating systems receive equal gain. As shown in the table 5. the performances of our system overpass the baseline for nDCG1 with an improvement of 5% for nDCG1 and 7% for nDCG0 . However, this improvement do not imply stable effectiveness of our model due the low values for nDCG0. A further analysis on our submitted run shows that the good performances our system for nDCG1 measure are explained due to its "timid" behaviour in contrast of "verbose" systems continuously sending tweets every day . In fact, Our system submit only 102 out of 560 (18%) expected daily digest emails for all topics confused where 387 are actually not salient. Besides, results for nDCG0 which also evaluate tweet ranking process show that our ranking strategy that suggest to order tweets according to their timestamp have limited performances. 3 Word similarity based approach for Real time tweet summarization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Relevance score</head><p>The main drawback of the use of statistical weighting techniques is that statistics change when a new tweet arrives leading to update the index every time which is a challenging task regarding the velocity in the tweet stream. In addition, given the short length of tweets the statistical features appear to have limited value. We believe that the similarity between the tweet words and topic words is the key feature to estimate the relevance score of incoming tweet. Hence, we propose to use adapt the extended Boolean model <ref type="bibr" coords="6,163.73,448.89,11.38,8.64" target="#b4">[5]</ref> to evaluate the relevance score of tweet. We propose to consider the similarity score between topic title words and tweet words to evaluate the weight of topic words instead of using the TF-IDF weighting technique.</p><p>Topics provided in TREC RTS 2016 task include a title and a description of the information need. While, participants were permitted to use these two filed for filtering, we use in our participation the title field to estimate the relevance score of the tweet with respect to a topic. The topic title QT is considered as "ANDed terms". In the Extended Boolean model, the relevance score of tweet T = {t 1 , ...,t n } to "And query" QT is estimated as follows:</p><formula xml:id="formula_10" coords="6,209.05,554.34,295.36,24.02">RSV (T, QT and ) = 1 - ∑ qt i ∈QT (1 -W T (qt i )) 2 |QT |<label>(9)</label></formula><p>Where W T (qt i ) is the weight of the query term qt i in the tweet T . Instead of using TF-IDF weighting technique, we propose to estimate the weight W T (qt i ) by evaluating the similarity between the query term qt i and all the terms of tweet T , which is measured by cosine similarity between their word2vec vector <ref type="bibr" coords="6,295.72,626.52,11.62,8.64" target="#b5">[6]</ref> as follows:</p><formula xml:id="formula_11" coords="6,240.97,646.25,263.43,15.86">W T (qt i ) = max t j ∈T [w2vsim(t j , qt i )]<label>(10)</label></formula><p>Where w2vsim(t j , qt i ) is the similarity between tweet word t j and query word qt i . It is measured by cosine similarity between their vector which are generated by word2vec model <ref type="bibr" coords="6,426.33,685.23,11.85,8.64" target="#b5">[6]</ref> using a training tweet stream collection. The intuition behind this proposition is that tweets that have words sharing many contexts with the query words will be more relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Novelty score</head><p>Novelty can be evaluated by conducting a pairwise comparison between incoming tweet and those already selected in the summary using cosine similarity and Kl-divergence. However due to the shortness of tweet, meaningful words rarely occur more than once which implies that cosine similarity and Kl-divergence are not suitable for evaluating the distance between two tweets. Indeed, a pairwise comparison dose not fit real time filtering (particularly for the scenario A). Hence, in this run we use the novelty estimation proposed in <ref type="bibr" coords="7,244.32,208.30,11.84,8.64" target="#b6">[7]</ref> in which all summary's tweets are merge into one "summary word set" and word overlap is used to evaluate the novelty score of the incoming tweet. Assume that RW is the set of words that occur in current summary then the novelty score of the incoming tweet is evaluated as follows:</p><formula xml:id="formula_12" coords="7,247.34,252.37,257.07,22.32">NS(T, RW ) = 1 - |RW ∩ T | |T |<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Run for Scenario: A Real Time summarization</head><p>For the scenario A, our approach is composed of three filters related to the topicality, relevance and novelty. These filters are adjusted in sequential way. To reduce the latency between tweet creation time and tweet notification time, the decision of pushing/ignoring an incoming tweet is made immediately as soon as the tweet occurs in the stream. A tweet passes a filter if its novelty score is above a certain threshold.</p><p>The first filter eliminates non-English tweets and those containing less than three tokens. It also drops all an incoming tweets that do not contain a predefined number of title words. An incoming tweet is considered related to a topic if and only if its number of words overlap with the query title is higher than a minimum of either a predefined constant (K) or the length of the query title (min(K, |QT |).</p><p>Based on pilot experiments on TREC MB RTF 2015 data-set <ref type="bibr" coords="7,343.74,417.41,10.40,8.64" target="#b3">[4]</ref>, we set the value of the threshold k to k = 2.</p><p>In the second filter, the relevance score of incoming tweet that passes the first is estimated. A tweet pass to the next filter if its score is above the following threshold:</p><formula xml:id="formula_13" coords="7,220.35,475.03,284.05,22.00">Rel T hreshold = MAX(0.4, 1 - 2 |QT | )<label>(12)</label></formula><p>In the third filter, a novelty score of a tweet is estimated as described in the equation 11. Tweets with novelty score less than 0,6 were discarded. We based the novelty threshold on pilot experiments conducted on TREC MB RTF 2015 date set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Run for Scenario B: Retrospective notification</head><p>To generate run for scenario B, we formulate tweet summarization problem as an optimization problem based on the tweet relevance function defined in the equation 12. we use Integer Linear Programming to select tweets that optimize a global objective function. To solve the problem, we use the GNU Linear Programming kit footnotehttps://www.gnu.org/software/glpk/, which is a free optimization package.</p><p>More specifically, we would like to select from M candidate tweets (those that pass the topicality filter ) N tweets which receive the highest relevance score with respect to the user interest subject to a series of constraints related to redundancy and length limit (maximum number of tweets allowed in the summary). The tweet summarization problem can be formulated as the following ILP problem:</p><p>We include indicators variable X i which is 1 when tweet T i is added in a summary and 0 otherwise. Notice here that the first constraint simply states that the indicator variables are binary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∀i ∈ [1, M], X i ∈ {0, 1}</head><p>Objective function: Top ranked tweets are supposed to be the most relevant tweets which we want to include in the final summary. Thus, we are looking for maximizing the global relevance score of selected tweets to improve the overall coverage and relevance of the final summary. The objective function is defined as follows:</p><formula xml:id="formula_14" coords="8,249.49,174.24,108.09,12.87">max(∑ M i=1 X i × RSV (T i , Q))</formula><p>Redundancy Constraints: To prevent redundancy, we compute a pairwise similarity between tweets and if the similarity is above a certain threshold (Sim threshold) then we drop the tweet that have a lower relevance score. This constraint is formulated as follows:</p><formula xml:id="formula_15" coords="8,189.10,252.41,227.59,9.72">∀i, j ∈ [1, M], (X i + X j ) × sim(T i , T j ) ≤ 2 × Sim threshold</formula><p>The similarity between two tweets is computed based on the word2vec similarity function as it takes into account the semantic relation between two words as follows:</p><formula xml:id="formula_16" coords="8,225.02,313.67,279.39,25.85">Sim(T, T ) = 1 |T | ∑ t i ∈T max t j ∈T w2vsim(t i ,t j )<label>(13)</label></formula><p>The similarity threshold used in the redundancy constraints is set to 0.75, which means that to be added to the summary, a tweet has to have a similarity score higher than 0.75 with all other selected tweets.</p><p>Length Constraints: We add this constraint to ensure that the length of the final summary is limited to the minimum of either a 100 (the maximum allowed number of pushed tweets) or M -1 where M is the number of candidates tweets (those that pass the topicality filter).</p><formula xml:id="formula_17" coords="8,241.78,418.65,33.04,13.92">∑ C i=1 ∑ L i</formula><p>j=1 X i j min(N, M -1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results</head><p>For Scenario A, Table <ref type="table" coords="8,188.78,481.06,4.88,8.64" target="#tab_4">5</ref> reports the performance of our submitted run based on word similarity extended Boolean model (WSEBM). In terms of EG1 and nCG1 our approach dose not outperform the organizer baseline. These results reveals that our strategy of setting the relevance threshold is not effective. In fact, in terms of EG1 and nCG1 systems achieved high scores by simply pushing few tweets. In these metric system that push zero tweet for sailing day receive score of 1 for that day and the system receive score of 0 otherwise. Unfortunately, in our run we used a threshold that is not restrictive enough. Hence, 6887 tweets were pushed and among them only 1417 tweets were judged. Our run contains 354 relevant which represents 24.98% of pushed tweets. These results can also be partially explain by the fact that only 20.57% of pushed tweets were judged by assessors. In terms of EG0 and nCG0 our approach outperforms the baseline which shows that our approach perform well in the case of "eventful days" where there are relevant tweets in the stream. The results for Scenario A also indicates that the latency of our approach is better than the latency of the baseline. Table <ref type="table" coords="8,142.61,625.46,5.08,8.64" target="#tab_5">6</ref> reports our results for Scenario B, which aggregated the the user's interest in a daily summary with a maximum of 100 tweets. in terms of nDCG1 in which pushing tweet for salient day is penalizing the performance of our run is bellow the baseline but the difference is not significant. However, in terms of nDCG1 our run outperforms the baseline the improvement is to 422.07%. These results reveals that our approach achieve a good balance between pushing too much tweets and pushing too little tweets. Our approach aims to perform an automatic retweet recommendation with a model that automatically relays a selective set of relevant tweets from data streams given an interest profile. This model relies on contextual features that are associated with every tweet, combined to content processing. This model focuses on respecting time constraints for processing and keeps prompt retweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Context-based Model</head><p>Our context-based model relies on content and context evaluations, which serve as the basis for a retweet decision function. These model constituents are described in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Content Evaluation</head><p>First, each profile p and each tweet t i associated with content C O t i receive the same text processing, in order to maximize the possible matchings. After pre-processing we obtain a profile representation p = {w p 0 , ..., w p k } composed of k ≤ k terms w p j ; and a pre-processed tweet content C O t i = {w t i 0 , ..., w t i n } composed of n ≤ n terms w t i j . The aim of the content model is to evaluate tweet relevance with respect to the interest profile, i.e., to match C O t i with p . We evaluate a content acceptance criterion (CAC) as:</p><formula xml:id="formula_18" coords="9,236.99,502.23,267.42,35.72">CAC(p , C O t i ) = ∑ n j=1 1 {w t i j ∈p } ∑ k j=1 1 {w p j ∈p } (14)</formula><p>where 1 is an indicator function which is equal to 1 if the attached condition is validated and 0 otherwise (e.g.,</p><formula xml:id="formula_19" coords="9,124.24,554.49,89.40,12.48">1 {x∈R} = 1 ; if x ∈ R).</formula><p>Concretely, we evaluate the ratio of common terms between the tweet content C O t i and the interest profile p , by the number of terms in p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Context Evaluation</head><p>In addition to content, we associate each tweet with a context C X t i composed of additional information. These information are either extracted or calculated from tweet metadata M t i . M t i is defined as {st t i , hash t i , men t i , url t i , med t i , us t i } where :</p><p>st t i is the tweet status (initial tweet or retweet of another user), hash t i is the set of hashtags in t i , men t i is the set of mentions in t i , url t i is the set of urls in t i , med t i is the set of medias (image, sound, video, etc.) in t i , us t i is the set of information about the author of t i . us t i = { f ol t i , stat t i , f r t i , list t i , f av t i , desc} where f ol t i is the number of followers, stat t i is the number of status (number of tweets and retweets issued by the author), f r t i is the number of friends, list t i is the number of public lists the author is member of, f av t i is the number of favourites, and desc t i is the author profile description composed of nDesc terms w d j .</p><p>C X t i is defined as a set of features f l , whose values are evaluated using M t i . Each feature f l is associated to a threshold λ l , over which a tweet is considered relevant regarding the feature. We distinguish two types of features, major and minor ones, regarding their influence according to the state of the art. Table <ref type="table" coords="10,186.01,289.22,4.88,8.64" target="#tab_6">7</ref> sums up all of the features f l with their associated thresholds λ l , as well as their significance set (Major or Minor). f 9 is for instance categorized as a major feature, since <ref type="bibr" coords="10,459.69,301.17,11.73,8.64" target="#b7">[8]</ref> showed that the presence of an URL in tweets is an indicator of relevance. λ l may be evaluated using a set of resources R detailed in next section. Features are organized into three categories : Content, Entities, and Author. For each feature f l we evaluate a score Sc l ( f l , p, R) as follows:</p><formula xml:id="formula_20" coords="11,214.73,111.91,285.53,68.50">Sc l ( f l , p, R) =              |hash t i | ∑ y=1 1 { f l &gt; λ l } if l = 6 |men t i | ∑ y=1 1 { f l &gt; λ l } if l = 8 1 { f l &gt;λ l } otherwise (<label>15</label></formula><formula xml:id="formula_21" coords="11,500.26,141.19,4.15,8.64">)</formula><p>Each feature is associated to a score equal to 1 if its value is greater than λ l . The only particularity comes from f 6 , respectively f 8 , which score is summed up for each hashtag, respectively mention, if present in interest profile p.</p><p>A feature-based score (FBS) is then evaluated for the tweet as:</p><formula xml:id="formula_22" coords="11,126.07,253.86,378.34,27.40">FBS(C X t i , p, R) = m ∑ l=1 [(Sc l ( f l , p, R) . 1 {l∈C X m t i } ) + 2 (Sc l ( f l , p, R) . 1 {l∈C X M t i } )]<label>(16)</label></formula><p>where C X m t i is the set of minor features and C X M t i is the set of major ones ; with</p><formula xml:id="formula_23" coords="11,101.89,287.66,402.53,27.73">C X t i = C X M t i ∪ C X m t i and C X M t i ∩ C X m t i = / 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Context Evaluation</head><p>The retweet decision function f , which relies on the aforementioned content and context evaluations, is defined as follows:</p><formula xml:id="formula_24" coords="11,113.97,386.41,390.44,22.97">f (t i , p, T s , R) = {rt i } if CAC(p , C O t i , T s ) &gt; λ C O and FBS(C X t i , p, R) &gt; λ C X / 0 otherwise<label>(17)</label></formula><p>where λ C O and λ C X are thresholds associated with CAC and FBS. A tweet is thus retweeted if its content and context are considered as relevant enough according to the user profile p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model implementation</head><p>We focused on scenario A even though responded to scenario B. For the track, a usual pre-processing is applied on profiles p and tweet contents C O t i consisting in stopword removal, lower case standardization, and Porter stemming <ref type="bibr" coords="11,217.06,504.16,14.97,8.64" target="#b10">[11]</ref>. A language detection is also performed on tweets to keep only those written in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Scenario A</head><p>For our context model, the set of resources R used to evaluate C X t i was composed of Twitter data collected last year. R was used to fixed the thresholds λ 11 to λ 15 associated to features f 11 to f 15 by computing the third quartile of the features. The thresholds for the remaining features were manually determined by observing feature distributions or according to the state of the art (see Table <ref type="table" coords="11,465.28,601.55,3.60,8.64" target="#tab_6">7</ref>).</p><p>Regarding the two global thresholds λ C O and λ C X , associated to CAC and FBS, we implemented the model with best pairs of values (λ C O , λ C X ) computed during tests on the TREC Microblogs 2015 collection. We fixed λ C X to 5 (to eliminate tweets with poor contexts), and λ C O to 0.6 (to keep high related tweets). Finally, we added the imposed limitation of ten notifications per day.</p><p>The major differences regarding our last year participation ( <ref type="bibr" coords="11,358.47,661.32,15.66,8.64" target="#b11">[12]</ref>) resides in considering retweets (i.e., adding a feature related to the tweet status), reducing processing time, removing "query expansion" treatments on description query part, and improving the content evaluation (regarding profile matching).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Scenario B</head><p>We used the same implementation of our model as for scenario A, except that λ C O which was set to 0.3 in order to accept more related tweets in the system. The main difference lies in the additional step after the context model: ranking (the 100 best) results for each profiles at the end of the day. We compute a global score GCFS gathering both content and context scores (CAC and normalized FBS) as: GCFS(p, p , C O t i , C X t i , R) = CAC + FBS . 0.02 (18)</p><p>At the end we ordered tweets for each profile according to GCFS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>In this TREC 2016 Real-Time Summarization Track, we submitted one run for each scenario; the obtained results are shown in Table <ref type="table" coords="12,243.36,268.22,4.93,8.64" target="#tab_7">8</ref> for counting and Table <ref type="table" coords="12,342.63,268.22,4.93,8.64" target="#tab_8">9</ref> for official results in scenario A, and in Table <ref type="table" coords="12,125.96,280.17,9.96,8.64" target="#tab_9">10</ref> for scenario B. Details about metrics are in official Guidelines. Regardless the results, our main goal was achieved: the system returned selected tweets in five seconds maximum during peak times for scenario A and one hour for scenario B. Unfortunately, this response time was not taking into account into basic metrics and we obtained high latency measures due to earlier tweets belonging to the same evaluation cluster. Future work will be devoted to an in-depth study of the context features, their impact on the global model and interactions between them. We will add profile classification to fix thresholds according to these different groups.</p><p>We presented in this paper three different approaches for real time summarization of tweet stream. The proposed approaches compute either a relevance score or filtering score which allow to determine if a new tweet should be included in the summary. We have have compared official results with those obtained by the track baseline. We believe that these results are quite promising but should be however compared with further experiments, more particularly to study the impact of some tuning parameter on the effectiveness of proposed models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,118.10,87.93,292.67,104.28"><head>Table 1 .</head><label>1</label><figDesc>Filtering functions respective Summary constraints</figDesc><table coords="3,118.10,112.44,273.96,79.78"><row><cell cols="2">Function Constraint</cell><cell>Description</cell></row><row><cell>F 0 (t i )</cell><cell>Summary length</cell><cell>Summary must be limited to l tweets</cell></row><row><cell>F 1 (t i )</cell><cell cols="2">Language preference Tweet t i must be in user's language</cell></row><row><cell>F 2 (t i )</cell><cell>Lexical restriction</cell><cell>Tweet t i must not include "bad words"</cell></row><row><cell>F 3 (t i )</cell><cell>URL presence</cell><cell>Tweet t i must include an URL</cell></row><row><cell>F 4 (t i )</cell><cell>Topical relevance</cell><cell>Tweet t i must be relevant to tracked topic</cell></row><row><cell>F 5 (t i )</cell><cell>Non redundancy</cell><cell>Tweet t i must not be redundant</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,101.59,196.68,404.33,118.71"><head>Table 2 .</head><label>2</label><figDesc>Tweet counting for the two summaries generate by our system (run IRIT-iritRunBiAm-21) and baseline.</figDesc><table coords="5,172.51,221.19,259.04,34.69"><row><cell></cell><cell cols="6">#rel #redundant #non-rel #unjudged #total-length precision</cell></row><row><cell cols="2">Our system 201</cell><cell>6</cell><cell>323</cell><cell>1674</cell><cell>2177</cell><cell>0.09</cell></row><row><cell>Baseline</cell><cell>148</cell><cell>12</cell><cell>286</cell><cell>1461</cell><cell>1888</cell><cell>0.07</cell></row></table><note coords="5,101.89,306.37,75.28,9.03"><p>scenario A. Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,125.24,446.00,353.58,59.20"><head>Table 3 .</head><label>3</label><figDesc>Official results of our system (run IRIT-iritRunBiAm-21) and baseline for Scenario A.</figDesc><table coords="5,125.24,470.51,353.58,34.69"><row><cell cols="3">EG1 EG0 nCG1 nCG0 GMP.33 GMP.5 GMP.66 mean latency median latency</cell></row><row><cell>Our system 0.2493 0.0332 0.2541 0.0380 -0.5464 -0.3817 -0.2267</cell><cell>102630.1</cell><cell>23.0</cell></row><row><cell>Baseline 0.2289 0.0253 0.2330 0.0295 -0.6000 -0.4317 -0.2733</cell><cell>120908.6</cell><cell>8718.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,155.87,241.53,294.56,59.20"><head>Table 4 .</head><label>4</label><figDesc>Official results of our system (run RunBIch) and baseline for Scenario B.</figDesc><table coords="6,230.88,266.04,142.29,34.69"><row><cell>nDCG1</cell><cell>nDCG0</cell></row><row><cell>Our run 0,2481</cell><cell>0,0321</cell></row><row><cell cols="2">baseline 0.2352 (+5%) 0.0299 (+7%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,110.76,87.87,382.54,58.87"><head>Table 5 .</head><label>5</label><figDesc>Results of the real-time summarisation task for scenario A.</figDesc><table coords="9,110.76,109.32,382.54,37.41"><row><cell></cell><cell cols="3">EG1 EG0 nCG1 nCG0 GMP.33 GMP.5 GMP.66 mean latency median latency</cell></row><row><cell cols="2">IRIT-WSEBM 0.1224 0.0402 0.1916 0.1095 -2.5321 -1.8348 -1.1785</cell><cell>112089.1</cell><cell>74.5</cell></row><row><cell>Baseline</cell><cell>0.2289 0.0253 0.2330 0.0295 -0.6000 -0.4317 -0.2733</cell><cell>120908.6</cell><cell>8718.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,101.89,161.24,321.76,96.37"><head>Table 6 .</head><label>6</label><figDesc>Results of the real-time summarisation task for scenario B.</figDesc><table coords="9,101.89,182.69,290.34,74.92"><row><cell>nDCG1 nDCG0</cell></row><row><cell>IRIT-ILPWSEBM 0.2208 0.1262</cell></row><row><cell>TREC Baseline 0.2352 0.0299</cell></row><row><cell>4 Retweet Recommendation Using Contextual Features</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="10,101.59,397.52,402.97,292.11"><head>Table 7 .</head><label>7</label><figDesc>Features considered for the context evaluation. Acquisition way is either M (metadata extraction) or C (calculated). Threshold determination ways are * for statistic method using R, † for pilot study method, or ‡ for defined in the literature. Description references the related work when appropriate.</figDesc><table coords="10,146.63,441.82,314.40,247.82"><row><cell></cell><cell cols="4">Feature Acquisition Threshold Significance</cell><cell>Description</cell></row><row><cell></cell><cell>f l</cell><cell></cell><cell>λ l</cell><cell></cell><cell></cell></row><row><cell></cell><cell>f 1</cell><cell>M</cell><cell>0  ‡</cell><cell>Major</cell><cell>Initial tweet or retweet of another user. 1 if</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>initial tweet ; 0 otherwise [9]</cell></row><row><cell>Content</cell><cell>f 2 f 3</cell><cell>C C</cell><cell>10  † 0.6  †</cell><cell>Minor Minor</cell><cell>Number of terms after text pre-processing (n ) Ratio between n and n (number of terms be-fore pre-processing) [9]</cell></row><row><cell></cell><cell>f 4</cell><cell>C</cell><cell>0.6  †</cell><cell>Minor</cell><cell>Ratio between the size of hash ti and n</cell></row><row><cell></cell><cell>f 5</cell><cell>C</cell><cell>1  †</cell><cell>Minor</cell><cell>size of hash ti . Derived from [10]</cell></row><row><cell>Entities</cell><cell>f 6 f 7 f 8</cell><cell>C C C</cell><cell>0  ‡ 0  † 0  †</cell><cell>Minor Minor Minor</cell><cell>For h in hash ti presence of h in profile p Size of men ti . Derived from [10] For m in men ti presence of m in p</cell></row><row><cell></cell><cell>f 9</cell><cell>M</cell><cell>0  ‡</cell><cell>Major</cell><cell>Size of url ti . Derived from [8]</cell></row><row><cell></cell><cell>f 10</cell><cell>M</cell><cell>0  †</cell><cell>Minor</cell><cell>Size of med ti</cell></row><row><cell></cell><cell>f 11</cell><cell>M</cell><cell>945  *</cell><cell>Major</cell><cell>f ol ti . Derived from [10]</cell></row><row><cell></cell><cell>f 12</cell><cell>M</cell><cell>27689  *</cell><cell>Major</cell><cell>stat ti .[9], and derived from [10]</cell></row><row><cell>Author</cell><cell>f 13 f 14</cell><cell>M M</cell><cell>759  *  7  *</cell><cell>Major Minor</cell><cell>f r ti . Derived from [10] list ti</cell></row><row><cell></cell><cell>f 15</cell><cell>M</cell><cell>3166  *</cell><cell>Minor</cell><cell>f av ti</cell></row><row><cell></cell><cell>f 16</cell><cell>C</cell><cell>0.3  †</cell><cell>Minor</cell><cell>Cosine similarity between author description</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>desc ti and p</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,153.32,311.09,299.67,59.20"><head>Table 8 .</head><label>8</label><figDesc>Tweet counting generate by our system (run IritIris-SDA-22) and baseline.#rel #redundant #non-rel #unjudged #total-length</figDesc><table coords="12,190.34,351.55,209.44,18.73"><row><cell>Our system 136</cell><cell>17</cell><cell>448</cell><cell>1467</cell><cell>2060</cell></row><row><cell>Baseline 148</cell><cell>12</cell><cell>286</cell><cell>1461</cell><cell>1888</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,125.24,421.93,353.58,59.20"><head>Table 9 .</head><label>9</label><figDesc>Official results of our system (run IritIris-SDA-22) and baseline for Scenario A.</figDesc><table coords="12,125.24,446.43,353.58,34.69"><row><cell cols="2">EG1 EG0 nCG1 nCG0 GMP.33 GMP.5 GMP.66 mean latency median latency</cell></row><row><cell>Our system 0.2181 0.0270 0.0270 0.0406 -1.1275 -0.8161 -0.5229 123012.6</cell><cell>13047</cell></row><row><cell>Baseline 0.2289 0.0253 0.2330 0.0295 -0.6000 -0.4317 -0.2733 120908.6</cell><cell>8718.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="12,148.15,532.77,310.00,59.20"><head>Table 10 .</head><label>10</label><figDesc>Official results of our system (run IritIris-SDB) and baseline for Scenario B.</figDesc><table coords="12,250.80,557.27,102.46,34.69"><row><cell></cell><cell>nDCG1 nDCG0</cell></row><row><cell cols="2">Our system 0.1062 0.0651</cell></row><row><cell>Baseline</cell><cell>0.2352 0.029</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,109.73,230.55,394.82,7.77;13,118.08,241.35,386.33,7.93;13,117.75,252.31,203.19,7.93" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,357.43,230.55,147.13,7.77;13,118.08,241.51,68.71,7.77">Simple dynamic emission strategies for microblog filtering</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Lin Luchen Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Roegiest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,206.17,241.35,298.23,7.72;13,117.75,252.31,177.23,7.93">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;16</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,263.27,394.68,7.93;13,118.08,274.23,107.17,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,291.67,263.42,152.20,7.77">Overview of the trec-2012 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,460.12,263.27,44.29,7.72;13,118.08,274.23,28.55,7.72">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,285.19,394.68,7.93;13,118.08,296.30,42.59,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,224.06,285.34,153.97,7.77">Overview of the trec-2013 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,394.46,285.19,75.86,7.72">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,307.26,394.68,7.77;13,118.08,318.07,387.45,7.93;13,118.08,329.18,20.17,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,460.34,307.26,44.07,7.77;13,118.08,318.22,106.60,7.77">Overview of the trec 2015 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yulu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Garrick</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,241.17,318.07,93.91,7.72">Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">November 17-20, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,339.98,395.79,7.93;13,118.08,351.09,131.22,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,295.04,340.14,143.59,7.77">Extended boolean information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harry</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,446.28,339.98,53.92,7.72">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1022" to="1036" />
			<date type="published" when="1983-11">November 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,362.05,394.67,7.77;13,117.85,372.86,153.01,7.93" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="13,337.82,362.05,166.59,7.77;13,117.85,373.01,42.98,7.77">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR, abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,383.97,396.16,7.77;13,118.08,394.78,386.33,7.93;13,117.48,405.74,273.30,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,353.76,383.97,152.13,7.77;13,118.08,394.93,122.54,7.77">Multi-criterion real time tweet summarization based upon adaptive threshold</title>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><surname>Dousset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,257.05,394.78,247.36,7.72;13,117.48,405.74,20.54,7.72">2016 IEEE/WIC/ACM International Conferences on Web Intelligence (WI16</title>
		<meeting><address><addrLine>Omaha, Nebraska USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">October 13-16, 2016. 2016</date>
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,416.85,394.68,7.77;13,118.08,427.65,378.93,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,444.83,416.85,59.58,7.77;13,118.08,427.81,159.49,7.77">Effectiveness of state-of-the-art features for microblog search</title>
		<author>
			<persName coords=""><forename type="first">Firas</forename><surname>Damak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Cabanac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,294.09,427.65,117.71,7.72">Proceedings of Int. Conf. SAC&apos;13</title>
		<meeting>Int. Conf. SAC&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="914" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.73,438.77,394.68,7.77;13,118.08,449.57,315.76,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,358.77,438.77,145.64,7.77;13,118.08,449.72,47.20,7.77">A survey of learning to rank for real-time twitter search</title>
		<author>
			<persName coords=""><forename type="first">Fuxing</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tiejian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenjie</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,181.81,449.57,166.55,7.72">Proceedings of Joint Int. Conf. ICPCA/SWS&apos;12</title>
		<meeting>Joint Int. Conf. ICPCA/SWS&apos;12</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="150" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.36,460.68,395.20,7.77;13,118.08,471.49,386.33,7.93;13,117.41,482.60,56.04,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,242.09,460.68,262.47,7.77;13,118.08,471.64,220.92,7.77">Konstantinos Tserpes, and Theodora Varvarigou. Content vs. context for sentiment analysis: A comparative analysis over microblogs</title>
		<author>
			<persName coords=""><forename type="first">Fotis</forename><surname>Aisopos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Papadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,358.48,471.49,117.92,7.72">Proceedings of Int. Conf. HT&apos;12</title>
		<meeting>Int. Conf. HT&apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.36,493.41,306.47,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,178.84,493.56,116.16,7.77">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,301.64,493.41,29.74,7.72">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,109.36,504.52,396.16,7.77;13,118.08,515.33,386.33,7.93;13,117.78,526.28,115.97,7.93" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,324.49,515.48,96.59,7.77">IRIT at trec microblog 2015</title>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lamjed</forename><surname>Ben Jabeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laure</forename><surname>Soulier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bilel</forename><surname>Moulahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lynda</forename><surname>Tamine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,437.09,515.33,67.32,7.72;13,117.78,526.28,41.00,7.72">34th Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
