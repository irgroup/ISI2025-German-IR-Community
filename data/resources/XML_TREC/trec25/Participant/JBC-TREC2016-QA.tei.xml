<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.25,77.12,324.12,16.70;1,221.25,101.87,168.06,16.70;1,78.75,126.62,453.03,16.70">University of Texas Rio Grande Valley TREC LiveQA 2016: Using Topic Modeling to Answer Complex Questions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,240.75,174.38,130.16,10.21"><forename type="first">Josue</forename><forename type="middle">Balandrano</forename><surname>Coronel</surname></persName>
							<email>jcoronel@tacc.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Texas Rio Grande Valley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.25,77.12,324.12,16.70;1,221.25,101.87,168.06,16.70;1,78.75,126.62,453.03,16.70">University of Texas Rio Grande Valley TREC LiveQA 2016: Using Topic Modeling to Answer Complex Questions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">59AA5993A6A82AC992F8D81DFD668A96</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the system submitted to the TREC 2016 LiveQA track. This year, the TREC 2016 LiveQA track consists of implementing a web service to answer user-submitted questions. The newest unanswered question from Yahoo! Answers will be posted to the web service, a question every minute for 24 hours. The implementation described in this paper uses natural language processing (NLP) to extract keywords from the question given as input. A web search together with a Yahoo! Answer search is used to select candidate answers. A latent dirichlet allocation (LDA) model is trained in order to compute a topic distribution of the different candidate answers. Finally, the Jensen-Shannon distance is used as similarity measure between the candidate answers and the question given as input. This implementation performed better than the average scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering Systems (QA-Systems) is a research field which has been improving since the 1950's. Answering open domain questions (questions which can belong to one or more topics in particular) is particularly difficult because of the vast amount of information that one has to analyze in order to retrieve a specific answer. This year the LiveQA track asks its participants to answer the latest unanswered question submitted to Yahoo! Answers. These questions are posted by real humans in real time. This means, that the question is not only an open domain question but also a complex question. Meaning, that the question will be verbose, will probably pertain multiple topics and, more often than not, it will contain repetitive information. Because of the details described above about these questions, implementing an automated way to answer them is an ongoing research field.</p><p>I chose a more statistical approach using, in the heart of the implementation, an unsupervised algorithm called latent dirichlet allocation (LDA). LDA helps in extracting the topics and distribution of these topics in a set of documents. An LDA model still needs to be trained but it does not need any manual labeling of the data that is fed into the algorithm. This algorithm was chosen, mainly, because of the unknown nature of the questions that were going to be submitted throughout the LiveQA track. Using LDA is not enough to implement a QA-System, there is still the question of what information is given to the algorithm in order to train it. For this a Web Search is made using keywords extracted from the question given as input. The results are not only used to train the LDA model but also as an alternative corpus (set of documents) if the search results from Yahoo! Answers is not satisfactory. Using the distribution from the LDA model output the Jensen-Shannon distance (JSD) is calculated between every candidate answer and the given question. Finally, the candidate answer with the shortest JSD is chosen as the correct answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><note type="other">Figure 1</note><p>Figure <ref type="figure" coords="2,142.33,661.05,6.00,10.54">1</ref> represents a block diagram of the QA-System architecture implemented in this paper. The "question processing" block uses the "NLTK processing" block to extract the keywords for further queries. The "NLTK processing" uses the python NLTK library to remove stop words, punctuation and then uses a lemmatizer to normalize the keywords. This process takes place on every document in the corpus constructed. The "Web Search" block uses the Bing Web API and the previously processed question to extract document related to the given query. The "YahooAnswers Search" block is used to retrieve candidate related question/answer tuples from the YahooAnswers database. The "LDA Modeling" block uses the gensim python library to construct a model based on LDA <ref type="bibr" coords="3,233.29,158.55,79.14,10.54" target="#b0">(Blei et al. 2003)</ref>. Gensim implements an online LDA model, meaning that the probabilistic variables are calculated with each iteration of the algorithm. The Answer ranking model feeds every candidate question/answer tuple into the "LDA Modeling" to get a topic probabilistic distribution of each of the question/answer tuples and then calculates the Jensen-Shannon distance (JSD) to get a similarity measure between the given question and the candidates question/answer tuples. Finally, the answer from the question/answer tuple with the shortest JSD to the given question is selected as the answer.</p><p>There are a few inferences made based on a quick analysis of the YahooAnswers database. First, it is observed that the title of each question includes the most important keywords referent to that question. This observation is used when searching for related documents using the Bing Web API. Second, it is noted that the first word usually describe the type of question that is being asked. For instance "Which teams are going to participate in March Madness?", they word "Which" together with the rest of the keywords ("team", "go", "participate", "march", "madness") yields better results when searching for related documents in the web. Third, when searching for candidate questions in YahooAnswers and using a large amount of keywords, the results are not very good and often times the only result is the given question itself. In order to get better results when searching YahooAnswers multiple searches are conducted by randomly removing keywords until the results yield at least 10 candidate related question/answer tuples. The steps of the QA-System implemented in this paper are the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question Processing</head><p>The first block of the system is in charge of the question processing. When processing a given question the system retrieves the title and body of the question. Second, the question is process to extract the keywords by removing stop words, punctuation and lemmatizing the keywords using the NLTK package with the WordNet database. After extracting the keywords, these are fed into the Bing Web Search API and a set of 20 documents are processed the same way the question is processed. Then, an LDA model is constructed to infer the topics the given question contains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Documents Retrieval</head><p>The keywords extracted from the question are then used as a query to the YahooAnswers service to retrieve a set of 50 candidate related questions. The retrieved questions and answers are used to construct the corpus, for this they are processed by removing stop words, punctuation and lemmatizing the keywords. If this query does not yields enough candidate question/answer tuples then results from the web search are incorporated into the corpus. The web search results are processed in the same way as the candidate question/answer tuples are in order to normalize the entire corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Answer Retrieval</head><p>The LDA model is used to calculate the probability distribution of the topics for each document in the corpus. Then, the Jenssen-Shannon distance (JSD) divergence is calculated for each of the documents. The JSD is calculated as a similarity measure between pairs of question/answers from the corpus and the given question. The candidate related questions are then ranked from more related to less related. The system then returns the more related pair of candidate questions/answers pairs. With the top related candidate question/answer pair the more upvoted answer is then return as the result. The JSD was used a similarity measure based on the work of <ref type="bibr" coords="4,112.66,398.55,117.97,10.54">Celikyilmaz et al. (2010)</ref>. The JSD measures the shannon entropy between two probability measures. The JSD is often used instead of the KL-Divergance because it is symmetric and, as such, a true metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation and Results</head><p>The LiveQA track is evaluated by TREC editors using a 4 level scale:</p><p>-4: Excellent -a significatn amount of useful information, fully answers the question.</p><p>-3: Good -partially answers the question.</p><p>-2: Fair -marginally useful information.</p><p>-1: Bad -contains no useful information for the question.</p><p>--2: the answer is unreadable.</p><p>The performance measures are: -avg-score(0-3) -average score over all queries (transferring 1-4 level scores to 0-3, hence comparing 1-level score with no-answer score, also considering -2-level score as 0) -succ@i+ -number of questions with i+ score (i=2..4) divided by number of all questions -prec@i+ -number of questions with i+ score (i=2..4) divided by number of answered only questions</p><p>Table <ref type="table" coords="5,138.32,125.55,6.00,10.54" target="#tab_0">1</ref> shows the results of the implementation described in this paper Run #Answers avgScore (0-3) succ@2+ succ@3+ succ@4+ prec@2+ prec@3+ prec@4+ Table <ref type="table" coords="5,138.32,314.55,6.00,10.54">2</ref> shows the overall results.</p><p>Table <ref type="table" coords="5,282.32,622.05,6.00,10.54">2</ref> 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>As we can see my approach successfully scored above the average score. Looking at the average score does not gives us the complete story. If we pay attention to the overall results we can see that this implementation scored in #11 out of 26 runs. This tells us that here is still a lot of room from improvement, specially if we notice that the best performance score almost double as my implementation (1.260 vs 0.727).</p><p>Next year I will look into improving the different parts of this implementation. First, a better NLP processing for the input as well as the corpus. Second, a pre filter of candidate documents to train the LDA model as well as select the list of candidates question/answer tuples. Finally, adding more measurements to the answer selection other than JSD. Hopefully there will be time for all of these improvements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,73.50,307.50,468.00,303.75"><head></head><label></label><figDesc></figDesc><graphic coords="2,73.50,307.50,468.00,303.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,73.50,328.50,468.00,284.25"><head></head><label></label><figDesc></figDesc><graphic coords="5,73.50,328.50,468.00,284.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,78.00,215.38,441.50,76.72"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="5,78.00,215.38,441.50,56.03"><row><cell>UTRGV-</cell><cell>882</cell><cell>0.7271</cell><cell>0.3704</cell><cell>0.2433</cell><cell>0.1133</cell><cell>0.4263</cell><cell>0.2800</cell><cell>0.1304</cell></row><row><cell>JBC-TRE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>C2016</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Average</cell><cell cols="2">771.0385 0.5766</cell><cell>0.3042</cell><cell>0.1898</cell><cell>0.0856</cell><cell>0.3919</cell><cell>0.2429</cell><cell>0.1080</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,72.00,346.05,440.21,10.54;6,72.00,362.55,183.28,10.54" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,282.95,346.05,128.08,10.54">Latent Dirichlet Allocation</title>
		<author>
			<persName coords=""><forename type="first">Blei</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ng</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jordan</forename><forename type="middle">I</forename><surname>Michael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,418.90,346.05,93.30,10.54;6,72.00,362.55,90.29,10.54">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,395.55,460.22,10.54;6,72.00,412.05,285.57,10.54" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,237.98,395.55,251.04,10.54">Text Categorization with Latent Dirichlet Allocation</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>JÃ¡n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jozef</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anton</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,496.90,395.55,35.33,10.54;6,72.00,412.05,195.77,10.54">Journal of Electrical and Electronics Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="161" to="164" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,445.05,421.90,10.54;6,72.00,461.55,333.57,10.54" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,260.31,445.05,233.58,10.54;6,72.00,461.55,116.55,10.54">Supervised labeled latent Dirichlet allocation for document categorization</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,196.28,461.55,96.71,10.54">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">581</biblScope>
			<date type="published" when="2014">2015. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,494.55,458.57,10.54;6,72.00,511.05,409.58,10.54" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,323.61,494.55,206.96,10.54;6,72.00,511.05,47.09,10.54">Lda based similarity modeling for question answering</title>
		<author>
			<persName coords=""><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,140.31,511.05,336.17,10.54">Proceedings of the NAACL HLT 2010 Workshop on Semantic Search</title>
		<meeting>the NAACL HLT 2010 Workshop on Semantic Search</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,544.05,445.24,10.54;6,72.00,560.55,467.53,10.54;6,72.00,577.05,276.95,10.54" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,253.31,544.05,263.94,10.54;6,72.00,560.55,112.34,10.54">Topic-based document segmentation with probabilistic latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,207.63,560.55,331.89,10.54;6,72.00,577.05,175.12,10.54">Proceedings of the 11th International Conference on Information and Knowledge management (CIKM-02)</title>
		<meeting>the 11th International Conference on Information and Knowledge management (CIKM-02)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,610.05,467.88,10.54;6,72.00,626.55,467.55,10.54" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,400.92,610.05,138.96,10.54;6,72.00,626.55,40.00,10.54">Indexing by Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,120.00,626.55,272.91,10.54">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">391</biblScope>
			<date type="published" when="1986">1986-1998. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
