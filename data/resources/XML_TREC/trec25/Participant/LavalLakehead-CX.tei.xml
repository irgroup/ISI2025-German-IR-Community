<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.12,109.14,374.33,14.56;1,260.52,129.66,73.59,14.56">Word embeddings and Global Preference for Contextual Suggestion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.84,162.33,34.88,9.44"><forename type="first">Jian</forename><surname>Mo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Laval University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.37,162.33,72.77,9.44"><forename type="first">Luc</forename><surname>Lamontagne</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Laval University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.36,162.33,69.48,9.44"><forename type="first">Richard</forename><surname>Khoury</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Laval University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.12,109.14,374.33,14.56;1,260.52,129.66,73.59,14.56">Word embeddings and Global Preference for Contextual Suggestion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ED5794BE6D0E027CDF70E38D66E10271</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Word embeddings</term>
					<term>Ranking</term>
					<term>Document Similarity</term>
					<term>Recommendation System</term>
					<term>Pointwise re-ranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our effort on 2016 Contextual Suggestion Track. We present a new ranking model that captures both global trend of interests as well as contextual individual preference. We trained a regressor on common users data thus it can prioritize popular places and categories. In order to model individual user preference, we introduce word embeddings to represent both user profiles and candidate places as vectors in a same Euclidean space.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In the Contextual Suggestion Track of the TREC conference, participants were asked to develop a system that is able to make suggestions for a particular person with a particular context. The recommendations are contextual as they are based on user's location, profile, and preferences <ref type="bibr" coords="1,81.72,420.90,10.47,8.51" target="#b0">[1]</ref>.</p><p>Two separate tasks are also available in this year conference: live experiment and batch experiment. For the live experiment this year, each group is provided only the user profiles and asked to submit proper recommendations. For batch experiments, several candidate suggestions are provided for participants to re-rank the results and a final precision at 5 is calculated. Unlike last year, teams are no longer asked for setting up a real time server. Thus the focus is on how to generate good ranking for large numbers of candidates. In this paper we present our research group's new approach to the ranking problem demanded in the contextual suggestion task this year.</p><p>We participated in both tasks of this track. For the live experiment, we use the same framework as last year which was composed of an ElasticSearch engine for the initial selection and a customized ranking module to re-rank the results <ref type="bibr" coords="1,228.26,633.54,10.32,8.51" target="#b1">[2]</ref>.</p><p>For the batch experiment this year, we adopted a new ranking model combining a word2vec based ranker and a global preference regressor.</p><p>We use Precision at 5 to present the results obtained for the evaluation of our system configurations. Our P@5 results of Phase 2 reached 50.7% comparing to TREC median 39.3% which demonstrates the effectiveness of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OUR APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. System Framework</head><p>To perform our experiments, we relied on the following components:</p><p>i Information gathering: a) Crawlers ii Recommendation System a) User profile modeling b) ElasticSearch and Customized Queries c) Ranking Model 1. Word embeddings Model 2. Global Preference Regressor The entire framework is illustrated in Figure <ref type="figure" coords="1,507.95,452.10,4.85,8.51" target="#fig_0">1</ref> and each component is described in detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. System Overview</head><p>Figure <ref type="figure" coords="1,357.94,505.62,4.85,8.51" target="#fig_0">1</ref> showed the overview of our system. We store both our corpus and TREC corpus in ElasticSearch. In the live run we query ElasticSearch for initial candidate suggestions. For details of this part, please refer to our last year paper <ref type="bibr" coords="1,340.00,561.66,10.42,8.51" target="#b1">[2]</ref>. Then a pre-trained regressor will score each candidate suggestion according to their popularity among all people. Word vectors are generated from both user profile and candidates then candidates will be scored by their distance to the profile vector. Linear interpolation is used to combine the two scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. INFORMATION GATHERING</head><p>We use our old data crawled last year since the application domain and context this year remains the same. Most of our data are coming from Yelp and TripAdvisor <ref type="bibr" coords="2,149.05,454.87,10.32,8.51" target="#b1">[2]</ref>.</p><p>The crawler extracts structural information such as rating, open hours, price, review count, category for each candidate attraction from the webpages. Business information such as has Wi-Fi, has parking lot, smoking allowed are also extracted and stored into the database.</p><p>User reviews were often too numerous to download entirely. Hence we just get the most popular reviews of each attraction, i.e. the first page of reviews. Positive and negative reviews are downloaded separately and stored in two different database tables.</p><p>We also used the crawled corpus provided by TREC this year. However these crawled files are raw html and have a lot of noise such as html tags and JavaScripts. So we extract only text and some metadata as representation for each site.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RECOMMENDATION SYSTEM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. User Profile Modeling</head><p>We create the user's positive profile by merging the positive information from all the examples our user likes, and likewise build the negative profile by merging the negative information from the examples our user dislikes. The intuition is that the preferences of one user are reflected by the attractions he/she likes and dislikes. Consequently, we can compare the user profiles with every candidate suggestion in the database and rank them by similarity. For instance, if one candidate suggestion has many elements in common with the positive user profile, this candidate obtains a higher ranking score. In contrast, if the attraction is very similar to the negative user same profile, its ranking score is penalized and will be very low.</p><p>According to the task defined for this track, one user might provide 6 different rating: 4: Strongly interested 3: Interested 2: Neutral 1: Disinterested 0: Strongly disinterested -1: Website didn't load or no rating given We selected rating 4 and 3 as positive and 1 and 0 as negative. Ratings 2 and -1 were taken as neutral and simply ignored.</p><p>Formally, the user profile can be expressed as:</p><p>Where is positive example suggestion i, and Pesik is element k (categories, tags, positive reviews, business info) of this positive suggestion. defines a special representation or form of the element.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Initial selection by Elasticsearch</head><p>Once the user profile is built, we formulate a customized query to search our ElasticSearch database. For example, let's suppose the user likes Mexican food, dislikes Japanese food, appreciates Wi-Fi and parking lot and hates smoking. We use a bool boosting query to wrap up the elements of the user profile into one query, which can then be sent to ElasticSearch to retrieve relevant new attractions.</p><p>These returned 100 attractions are used as our initial selection pool for later ranking. For further details on this part, please refer to our last year paper <ref type="bibr" coords="3,105.75,272.94,10.37,8.51" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ranking Model</head><p>Initially selected candidates are then re-ranked by the ranking model. There are two major module in our ranking model -Word embeddings Model and Global Preference Regressor. The first one is used to capture individual interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Word embeddings Model</head><p>Word embeddings are known for performing well at analogical reasoning. Example given by Mikolov <ref type="bibr" coords="3,124.30,416.58,11.57,8.51" target="#b2">[3]</ref> -king-man=queen-womanshowed that word embeddings could reason analogy or indirect relationship between words.</p><p>This property of word embeddings makes us wonder if it could be applied to recommendation or ranking problem. In Contextual Suggestion, a user who likes organic food and yoga would probably enjoy vegetarian restaurant and modern art while may dislikes fast food. Word embeddings model seems promising in finding subtle relationships in these occasions.</p><p>So we introduce word embeddings as special representations for candidates aiming to find semantic or contextual similarity between users and attractions.</p><p>Firstly, for every attraction we extract a list of nouns as representation of the place. For example, a Macdonald can be represented by words list -Fast-food, American, Restaurant. And a user can be represented by positive keywords and negative keywords as stated in user profile modeling section.</p><p>Then, we use Genism [4] trained on the GoogleNews corpus [5] to generate word vectors for each keywords in list.</p><p>A rather intuitive method is adopted to merge word vectors by summing all up into one. So in the end every attraction is represented by one vector while user profiles are matrices composed of rows of attraction vectors multiplied by their rating.</p><p>Finally we calculate similarity between attraction vectors and user matrix. The first method is to sum up user matrix vertically to merge it to a single vector and then calculate the dot product of attraction vector and user vector.</p><p>The second method is only calculate the one vector in user matrix which is nearest (smallest inner product) with attraction vector. The algorithm is simply multiplying user matrix and attraction vector then taking the smallest number in the vector.</p><p>Both of these two methods achieved similar results in our test runs. We used the first method in our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Regressor Trained on Global Preference</head><p>After examining the user data and candidate attractions, we found that sometimes categories appearing in candidates does not show in user profiles. For instance, one user only rated restaurants but his preference towards sports and activates remains unknown. The situation is common in recommendation problems.</p><p>Our approach to this missing profile problem is to recommend popular places all people favor. A Gradient Boosting Tree is trained on 2015 TREC data with features of ratings, review count, category and relevant index in the list. The relevant index means the order of appearance of the candidate place. We introduce this feature to model declining interest of user namely the law of diminishing marginal utility.</p><p>The trained regressor would prioritize the popular category and attractions and those who appear earlier in the candidate list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Combine the two models</head><p>An overall ranking is given by arbitrarily averaging both ranking from the two modules. That is to say both modules have the same proportional votes for the final ranking. The weighting parameters might be learnt by another training process which we didn't apply in these experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evaluation Metric</head><p>An attraction is considered relevant for P@5 if it has a geographical relevance of 1 or 2 and if the user reported that both the description and document were found to be interesting (3) or strongly interesting (4). A P@5 score for a particular topic (a profile-context pair) is determined by how many of the top 5 ranked attractions are relevant, divided by 5. <ref type="bibr" coords="3,461.77,695.70,11.40,8.51" target="#b0">[1]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Submitted Runs</head><p>Three runs were submitted to the competition:  LavalIVA_live1, live run  LavalIVA_batch1 is batch run 1, which applies only the global regressor.</p><p> LavalIVA_batch2 is batch run 2, using only the word vector model.</p><p> LavalIVA_batch3 is batch run 2, which combined the two modules.  <ref type="table" coords="4,120.80,333.30,4.85,8.51" target="#tab_0">1</ref> shows our final results. The low score of live run was caused by a sorting problem in our code which was fixed later in batch runs. So we will mainly discuss about the three batch runs.</p><p>As can be seen from the table, all the three batch runs scored higher than TREC median.</p><p>Batch_1 used only the Global Preference regressor which only recommend popular places for everyone regardless of their personal interest. Surprisingly this model scored above average even though it does not consider user profile at all.</p><p>Batch_2 used only the word embeddings module which only focus on the individual user preference.</p><p>Batch_3 is a result of the combination of the two models. The fact this run scored highest indicates that the two modules cover different aspect of the final recommendation and gives a better result we.</p><p>Here we study some cases to show how these two modules worked respectively showed in Table <ref type="table" coords="4,81.60,568.38,3.68,8.51" target="#tab_1">2</ref>. For user 740, only global regressor could make correct recommendations partly because the user was not consistent with his profile and favors popular places when re-rated.</p><p>User 774 is picky and only has two very positive scores on beer bars so the word embeddings module correctly selected 5 beer bars for these user while global regressor fail to guess it right.</p><p>Both modules get parts of the user 705 preferences so the combined model gave highest accuracy. For details on how each run scored please check the table in appendix at the end of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results on Test set</head><p>We also tested our model on 2015 data. A noticeable result showed in Table <ref type="table" coords="4,445.56,183.30,4.85,8.51" target="#tab_1">2</ref> is that regressor which models the declining user interest scores much better than the one without. So we suggest user do have a tendency to like top results more than those placed at very bottom of the list.</p><p>A decay model is used in our submitted runs. However we did not observe such behavior in 2016 data after the validation results released.</p><p>It was later revealed that the 2016 request list had been random shuffled in case this vulnerability being exploited again as some team just returned the original requests and still got good scores at 2015 TREC conference. In this paper, we have presented our new approach to contextual suggestion. Both the global regressor and word embeddings model showed effectiveness respectively and so the combined model could capture individual preference when training data is sufficient while provide popular recommendations for user with less data.</p><p>Specially, we showed that contextual recommendation problem can be tackled by cultivating analogical power of word embeddings. Even naïve approach at this stage showed good results.</p><p>We only sum up word vectors to represent the paragraph vector in which the order of words is lost. A more fine grained representations could be obtained as Doc embeddings or paragraph vector proposed in <ref type="bibr" coords="4,362.75,617.22,10.47,8.51" target="#b3">[6]</ref>.</p><p>While word embeddings works well on textual data such as comments and categories, a different approach would be to use word2vec technique to encode venues just by their interrelationship <ref type="bibr" coords="4,489.21,662.10,10.47,8.51" target="#b4">[7]</ref>.</p><p>RNN or other models that also vectorize documents fit well to our model and remains to be tested in future experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,214.68,381.81,179.21,6.87;2,95.64,105.00,431.16,275.16"><head>Fig 1 .</head><label>1</label><figDesc>Fig 1. Overall framework for contextual recommendation</figDesc><graphic coords="2,95.64,105.00,431.16,275.16" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,95.64,224.62,141.41,117.20"><head>Table 1 :</head><label>1</label><figDesc>TREC CS 2016 results</figDesc><table coords="4,95.64,234.42,139.62,107.39"><row><cell>Run</cell><cell>P@5</cell></row><row><cell>Live_1</cell><cell>0.27</cell></row><row><cell>Batch_1</cell><cell>0.4345</cell></row><row><cell>Batch_2</cell><cell>0.4276</cell></row><row><cell>Batch_3</cell><cell>0.5069</cell></row><row><cell>TREC median</cell><cell>0.393103</cell></row><row><cell>Table</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,100.80,590.26,159.94,63.18"><head>Table 2 .</head><label>2</label><figDesc>Model on 2015 validation set</figDesc><table coords="4,100.80,600.33,159.94,53.11"><row><cell cols="5">User/Runs median b1 b2 b3</cell></row><row><cell>740</cell><cell>0</cell><cell cols="2">0.6 0</cell><cell>0</cell></row><row><cell>774</cell><cell>0</cell><cell>0</cell><cell cols="2">0.4 0</cell></row><row><cell>705</cell><cell>0.4</cell><cell cols="3">0.4 0.2 0.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,308.64,339.46,173.67,92.12"><head>Table 3 .</head><label>3</label><figDesc>Model on 2015 validation set</figDesc><table coords="4,308.64,349.38,162.65,82.19"><row><cell>Run</cell><cell>P@5</cell></row><row><cell>NoDecay</cell><cell>0.581</cell></row><row><cell>DecayInterest</cell><cell>0.6932</cell></row><row><cell cols="2">VI. CONCLUSION AND FUTURE WORK</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="5,122.76,124.06,157.00,6.87;5,81.60,133.06,198.22,6.87;5,81.60,141.94,167.45,6.87" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,132.47,133.06,147.34,6.87;5,81.60,141.94,53.43,6.87">Overview of the TREC 2015 Contextual Suggestion Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dean-Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,148.60,141.94,76.85,6.87">Proceedings of TREC&apos;15</title>
		<meeting>TREC&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,126.59,152.86,153.35,6.87;5,81.60,161.74,198.31,6.87;5,81.60,170.74,200.30,6.87" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,194.78,161.74,85.13,6.87;5,81.60,170.74,88.58,6.87">Experiments at TREC 2015 Contextual Suggestion Track</title>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luc</forename><surname>Lamontagne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,182.89,170.74,75.86,6.87">Proceedings of TREC&apos;15</title>
		<meeting>TREC&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>Richard Khoury Laval University and Lakehead University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="5,122.76,181.78,157.06,6.87;5,81.60,190.54,198.25,6.87;5,81.60,199.54,48.91,6.87" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,247.85,181.78,31.97,6.87;5,81.60,190.54,179.17,6.87">Linguistic Regularities in Continuous Space Word Representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,122.76,241.42,157.18,6.87;5,81.60,250.30,198.43,6.87;5,81.60,259.30,163.25,6.87" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,244.63,241.42,35.30,6.87;5,81.60,250.30,138.26,6.87">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,228.93,250.30,51.10,6.87;5,81.60,259.30,62.13,6.87">Int. Conf. Mach. Learn. -ICML 2014</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,126.59,270.10,153.31,6.87;5,81.60,279.10,101.67,6.87" xml:id="b4">
	<analytic>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Ozsoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,176.53,270.10,103.37,6.87;5,81.60,279.10,52.72,6.87">From Word Embeddings to Item Recommendation</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
