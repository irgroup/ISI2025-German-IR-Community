<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.66,72.35,350.41,16.84;1,131.58,92.27,346.55,16.84">Light-weight, Conservative, yet Effective: Scalable Real-time Tweet Summarization</title>
				<funder ref="#_qAEnNQG">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">Qatar Foundation</orgName>
				</funder>
				<funder ref="#_nA6SXsB">
					<orgName type="full">Qatar National Research Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.82,137.97,81.12,11.06"><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
							<email>reem.suwaileh@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department Qatar University Doha</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.00,137.97,175.90,11.06"><roleName>Tamer Elsayed</roleName><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
							<email>maram.hasanain@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department Qatar University Doha</orgName>
								<address>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.66,72.35,350.41,16.84;1,131.58,92.27,346.55,16.84">Light-weight, Conservative, yet Effective: Scalable Real-time Tweet Summarization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">54899693B29BD822ADB1C3134FB5B083</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Microblogging platforms and Twitter specifically have become a major resource for exploring diverse topics of interest that vary from the world's breaking news to other topics such as sports, science, religion and even personal daily updates. Nevertheless, one by herself cannot easily follow her topics of interest while tackling the challenges that stem from the Twitter timeline nature. Among those challenges is the huge amount of posted tweets that are either not interesting, noisy, or redundant. Additionally, one cannot survive with manual techniques to summarize tweets related to topics that are discussed on the stream and are developed rapidly. In this paper, we tackle the problem of summarizing a stream of tweets given a pre-defined set of topics in the context of Qatar University's participation in TREC-2016 Real-Time Summarization (RTS) track. We participated in both push notification and e-mail digest scenarios. Given a set of users' interest profiles, our RTS system for push notifications scenario adopts a light-weight and conservative filtering strategy that monitors the continuous stream of tweets over a pipeline of multiple stages, while maintaining a scalable processing of a large number of interest profiles. For the e-mail digest scenario, we adopted a similar but even simpler approach. At the end of each day, a list of potentially relevant tweets is retrieved using a query of topic title terms that is issued against an index of all streamed tweets of that day. Our push-notification runs exhibited the best performance among all submitted automatic runs in the push notification task this year. Moreover, our bestperforming email-digest run was the second-best among all submitted automatic runs in the email-digest task this year. However, the evaluation results show that the performance is still away from being adopted in practice.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Twitter is one of the leading social media networks through which users post information as personal as their daily habits to updates and opinions on the world's breaking news. This rich and diverse stream of posts attracted users to turn to Twitter as a major source of information on ongoing topics and events. However, due to the continuous and enormous volume of the Twitter stream, manually looking for updates on topics of interests is a very daunting task for users. This TREC '16 Gaithersburg, Maryland USA necessitates the need for a real-time summarization system that automatically tracks events or topics of interest to users (perhaps millions of topics for millions of users) in parallel and generates a summary of representative on-topic tweets in real-time for each.</p><p>Given the continuous tweet stream, a real-time summarization (RTS) system aims to monitor the online stream and identify the tweets that are relevant to a set of predefined interest profiles (representing the users' topics of interest) while taking their novelty and freshness into account. For instance, if a user is interested in following the updates on the "Brazilian Soccer League", the system should efficiently monitor the stream and capture the on-topic tweets including all aspects of the topic (e.g., results and standings) which might change over time. Accordingly, real-time summarization approaches should use simple and efficient approaches that can scale to follow multiple interest profiles in parallel. Most importantly, the RTS systems are expected to overcome many challenges that stem from the nature of tweets, such as sparsity and topic drift. The former challenge originates from the very short length of tweets. One way to tackle such a challenge is by enriching the tweet text by contextual terms. The latter challenge requires the system to cope with the changes of the topic over time. One possible solution to this challenge is to update the topic representation by terms from the topic's new aspects that are discovered over the live stream.</p><p>In this paper, we present our real-time summarization system as a participant in TREC-2016 Real-time Summarization Track. Given a live stream of tweets and a set of interest profiles of users that represent their topics of interest, the RTS track has two main scenarios: (1) Scenario A (push notification), in which the system is expected to push few (relevant and novel) tweets per day as notifications on the user's mobile phone for each topic, and (2) Scenario B (email digest), in which the system suggests a list of tweets that summarizes the topic over a period of time and sends it to the user as a periodic email digest for each topic. This year, the track organizers provided a broker through which participants can fetch the interest profiles and push the filtered tweet immediately when they system decides to elect one <ref type="bibr" coords="1,543.65,639.50,9.20,7.86" target="#b2">[2]</ref>. The interest profile is composed of three main fields: title (short query), description (1-2 sentences describing the information need), and narrative (a paragraph describing the information need).</p><p>For the push notifications scenario, we adopted a lightweight and conservative filtering strategy that listens to the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweets Nomination Indexing</head><p>Figure <ref type="figure" coords="2,162.30,176.49,4.13,7.89">1</ref>: A high-level overview of the core real-time summarization system English tweets over the 1% sample of the Twitter stream, and processes the incoming tweets successively. Our system processes the incoming tweets in a pipeline that involves preprocessing, pre-qualification, relevance filtering, novelty filtering, and tweet nomination. Our system is considered a pure "streaming" system as it adopts "one-tweet at-a-time" processing model to ensure the least possible latency in making pushing decisions. To alleviate the sparsity and topic drift problems, we followed the typical solution, that is topic expansion; we attempt two expansion methods: (1) over the local stream and (2) over Twitter search service. In the former, we extract the expansion terms from the potentiallyrelevant documents that are identified by the system. In the latter, we search Twitter online and extract the expansion terms from the top returned tweets. Surprisingly, according to our results, both expansion methods affect the system performance negatively; our best run is the one that does not perform any expansion.</p><p>For the email digest scenario, we adopted a similar but even simpler approach. At the end of each day, a list of potentially-relevant tweets was retrieved by searching the index of all streamed tweets of that day. We experimented with different ranking models with a static relevance threshold. The tweets go through similar novelty check to the one adopted in the push notifications scenario, and the surviving tweets are ranked based on their relevance scores before being added to the submitted digest. Our results show that a ranking algorithm that uses language modeling with Jelinek Mercer smoothing outperforms other models.</p><p>The remainder of the paper is organized as follows. We present the design of our systems in detail in Section 2. We then discuss our official TREC results in Section 3 followed by the drawn conclusions and some guidelines for the future work in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">APPROACH</head><p>Our system this year extends upon the system that we participated with in TREC-2015 Microblog Filtering track <ref type="bibr" coords="2,285.37,606.58,9.20,7.86" target="#b5">[5]</ref>. The system adopts a light-weight and conservative filtering strategy; it monitors and processes the stream of tweets following a pipeline of multiple stages, while tracking a large number of topics in a scalable manner. Each topic is represented by an interest profile consisting of three fields: a short title that describes information need, a description of one or two sentences and a narrative paragraph that articulates the information need in detail. This year, we only utilize the title to represent the topic in our system since our experiments over TREC-2015 test collection showed that adding the other two fields to the topic representation negatively affects the system performance <ref type="bibr" coords="2,444.35,216.61,9.20,7.86" target="#b5">[5]</ref>.</p><p>In this section, we first present the core architecture of our RTS system that was leveraged in both scenarios, then we discuss each component in the system in detail for both scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Design</head><p>Figure <ref type="figure" coords="2,354.46,292.51,4.61,7.86">1</ref> depicts the high-level architecture of our system. As we indicated earlier, our system is a pure "streaming" system, in contrast to "micro-batching" systems. It adopts one-tweet-at-a-time processing model to ensure the shortest possible latency in making pushing decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Pre-qualification</head><p>As the system gathers tweets from the Twitter stream, it ignores non-English tweets detected using the tweet language attribute provided by the Twitter API, and replaces all retweets by their original tweets. The incoming tweet is not eligible to pass to the subsequent pipeline components if it is a low-quality tweet. We define low-quality tweets as tweets with very few terms, too many hashtags or too many URLs. Based on this criteria, we filter out any tweet that has less than 5 terms or more than one URL or more than 3 hashtags. Furthermore, we drop any tweet that does not match at least one title term of any interest profile from being further processed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Preprocessing</head><p>A tweet that survives the pre-qualification filter will be passed to the preprocessing stage where a sequence of steps are included: special characters (e.g., emoticon and symbolic characters) removal, stop-words removal, URL removal, and stemming. We also expand the tweet with the hashtags but as terms (i.e., without the '#' prefix), before it is examined against all interest profiles for relevancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Indexing</head><p>Since we acquire term statistics in other components of the system, we initialized the system with an index of a 5-day stream of tweets preceding the beginning of the evaluation period. The system also incrementally indexes all incoming English tweets during the evaluation period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Relevance Filtering</head><p>We use the vector space model to represent each interest profile (title specifically) and each incoming tweet as a vector using idf -based term weighting scheme. We compute the term weights using the following equation:</p><formula xml:id="formula_0" coords="3,100.10,74.05,192.81,19.75">w(t) = idf (t) = log N -df (t) + 0.75 df (t) + 0.75 (1)</formula><p>where N is the number of tweets indexed at the time of constructing the vector, and df (t) is the document frequency of the term. We chose this term weighting function due to being light-weight (which is necessary for real-time and scalable systems) and also very similar to the standard tf -idf weighting function noticing that terms rarely appear more than once in a tweet due to the limited length (140 characters).</p><p>Once the incoming tweet is represented in the vector space, the RTS system computes its relevance score against each interest profile using the standard Cosine Similarity function. To efficiently compute relevance scores, an in-memory index of profile vectors is maintained to match an incoming tweet with interest profiles. The relevance model makes a threshold-based decision in which it considers a tweet with a similarity score above a relevance threshold τr as a potentiallyrelevant tweet to the corresponding profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">Novelty Filtering</head><p>The RTS system should only pushes tweets that are relevant and novel to the user. Therefore, a novelty model has to be used to estimate the novelty for each potentiallyrelevant tweet. In our system, any potentially-relevant tweet of a profile has to be examined against all previously-pushed tweets for the corresponding profile to estimate its novelty before deciding to push it to the corresponding user. To estimate the novelty of a potentially-relevant tweet, we leverage a lexical similarity measure, that is a variant of Jaccard similarity, which computes the lexical overlap between the tweet and each pushed tweet for the corresponding profile as follows:</p><formula xml:id="formula_1" coords="3,122.28,430.85,170.62,19.75">J (Q, T ) = |Q| ∩ |T | max(|Q|, |T |)<label>(2)</label></formula><p>Where Q and T are the profile and the tweet term sets, and |Q| and |T | are their lengths (in terms) respectively. A tweet is considered novel if its similarity score with every pushed tweet is below a novelty threshold τn (i.e., it is different enough from any of the pushed tweets), otherwise, the system does not consider pushing it to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Push Notifications Scenario</head><p>The push notifications scenario simulates a recommender system that sends pop-up messages to users on their mobile phones after capturing tweets that match their interests. The task design restricts the number of pushed tweets per profile to a maximum of 10 tweets per day to avoid overwhelming the users. Having such constraint on the number of tweets to push, the system should wisely select the best candidate tweets to elect to the user in a timely fashion. We explain next how we used tweet freshness to nominate tweets to be pushed for an interest profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Tweets Nomination</head><p>While tracking all interest profiles simultaneously and monitoring the tweets stream, the system maintains, for each of the interest profiles, a list of candidate tweets that contains the tweets that were found relevant and novel so far. The RTS system periodically nominates a tweet to push to the broker <ref type="bibr" coords="3,346.27,57.64,9.71,7.86" target="#b4">[4]</ref> for a topic if the system overtakes a silence period δ or it has already found l candidate (i.e., potentially relevant and novel) tweets for that topic. Before actually pushing a candidate tweet to the user of a specific profile through the broker, the system re-ranks tweets in the candidates list of that profile based on relevance and freshness using equation 3 below. The top tweet is then pushed to the user through the broker.</p><formula xml:id="formula_2" coords="3,350.19,147.01,205.73,19.75">S(t) = Sr(t) * 100 -(CurT ime -time(t)) 100<label>(3)</label></formula><p>Sr(t) is the relevance score of tweet t (computed using Cosine similarity as we discussed earlier), curtime is the current system time (in minutes), and time(t) is the tweet creation time (in minutes). The final nomination score S(t) adopts a linear decay factor that linearly penalizes the tweets based on their posting time, hence favoring fresh tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Profile Expansion</head><p>To cope with topic development over time, the system periodically enriches the topic representation for an interest profile using Rocchio's pseudo relevance feedback. The main idea is to periodically select k "relevant" terms from p tweets that are potentially-relevant to the topic, and add those terms to the topic representation.</p><p>We utilized two different sources of the expansion. The first is the list of potentially-relevant tweets as detected by the relevance filtering, and the second is the top resulting tweets from searching Twitter using the online search service <ref type="foot" coords="3,332.41,360.54,3.65,5.24" target="#foot_0">1</ref> . For the latter, we used the topic title as a query and restricted the search date to the current date to get as fresh tweets as possible. The system also applies the same qualification and preprocessing rules to the tweets and deduplicates the result list. For both sources, terms of all candidate tweets are scored by adding up their idf-based scores as follows:</p><formula xml:id="formula_3" coords="3,393.10,441.51,162.82,7.86">we(t) = nR(t) * idf (t)<label>(4)</label></formula><p>Herein, we(t) is the score of the term t in the pseudo-relevant tweet set R, nR(t) indicates the number of tweets in R that contains t, and idf (t) is the idf-based weight of t as computed earlier.</p><p>After scoring all terms, the top k terms, denoted as expansion terms, are added to the topic vector. To avoid topic drift, the topic vector is reset to the title terms (i.e., original vector) before each expansion, as shown below.</p><formula xml:id="formula_4" coords="3,409.23,550.68,142.77,7.86">q = q + β * e (<label>5</label></formula><formula xml:id="formula_5" coords="3,552.00,550.68,3.92,7.86">)</formula><p>where e is the normalized vector of the k expansion terms, and β is a parameter used to restrict the influence of expansion terms on the new topic vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Periodic E-mail Digest Scenario</head><p>In this scenario, the RTS system is required to compile a daily list of a maximum of m tweets per interest profile and send it as an email digest to the user. For that, we adopted a similar but even simpler approach than the approach for push notification scenario. At the end of each day of the evaluation period, the system issues the title of the interest profile against the local tweet index that is incrementally updated over time. We experimented with three retrieval models: query-likelihood model with Dirichlet smoothing, query-likelihood model with Jelinek-Mercer smoothing, and a combination of both <ref type="bibr" coords="4,145.22,78.56,9.20,7.86" target="#b1">[1]</ref>. The system retrieves a list of 2m tweets and filters out the tweets that have a relevance score below a static relevance threshold τr. The survived tweets are then passed to the novelty filtering that is exactly similar to the push notification scenario. The tweets that pass the novelty checking are then ranked based on their relevance scores before sending the top m as a digest email to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL EVALUATION</head><p>In this section, we present the evaluation measures used to evaluate our RTS system in both scenarios, and the results of our official TREC-2016 runs. The RTS system for the push notifications scenario is allowed to push a maximum of n = 10 tweets per topic in each day of the evaluation period. If a system pushes more than 10 tweets, the extra tweets will be just ignored. For the other scenario, the system is expected to send a daily tweet list of a maximum of m = 100 tweets per topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Measures</head><p>Three basic evaluation measures were used in push notifications scenario: the expected gain (EG) (which is the official measure), the normalized cumulative gain (nCG), and the Gain minus Pain (GMP) measures. All of them were computed per day per topic and then averaged per topic.</p><p>• Expected Gain (EG):</p><formula xml:id="formula_6" coords="4,149.18,382.43,143.72,23.59">EG = 1 N t∈P G(t)<label>(6)</label></formula><p>P is the set of tweets that are pushed by the system and N is the number of those tweets (i.e., N must be ≤ 10 tweets). G(t) is 0 if the tweet is judged as nonrelevant, 0.5 if it is judged as relevant, and 1 if it is judged as highly-relevant. The measure also penalizes redundancy in pushed tweets using the semantic clusters (each contains a set of relevant tweets that are semantically similar to each other) that are released as part of the relevance judgments; once a tweet from a cluster is pushed, all upcoming pushed tweets from the same cluster are considered non-relevant.</p><p>• Normalized Cumulative Gain (nCG):</p><formula xml:id="formula_7" coords="4,147.15,554.09,145.76,23.59">nCG = 1 Z t∈P G(t)<label>(7)</label></formula><p>Z is the maximum possible gain for that topic in that specific day based on all judged pushed tweets.</p><p>• Gain minus Pain (GMP):</p><formula xml:id="formula_8" coords="4,123.68,635.24,169.22,17.80">GMP = α t∈P G(t) -(1 -α)P<label>(8)</label></formula><p>P is the number of non-relevant tweets pushed by the system and α is a parameter to balance between gain and pain.</p><p>Unlike in TREC-2015 filtering track, this year, the freshness is not considered in evaluating the system output, hence the gain of a run is not subject to temporal penalty. However, the latency was reported separately for tweets that contribute to the gain using mean (M LT ) and median (M edLT ) latency measures. Those measures compute the difference between the pushing time of a tweet and the first tweet of the cluster which the pushed tweet belongs to (i.e., reference tweet).</p><p>As for the e-mail digest scenario, the daily e-mail digest is evaluated as a ranked list of tweets using normalized discounted cumulative gain (nDCG) computed at cutoff 10 of the list. The measure also penalizes redundancy in the same manner followed in the push notifications scenario.</p><p>For all evaluation measures in both scenarios, the score of a submitted run is the average of scores over all topics. Moreover, for all measures, there are two variations based on how the silent days (i.e., days when there were not any relevant tweets) are treated. The measures that have "1" as a suffix reward a system by a score of 1 if it kept quiet on silent days, while measures that have "0" as a suffix treat all systems the same way by assigning a score of 0 on silent days regardless of how they behaved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Official Runs</head><p>In this section, we discuss our submitted runs for both scenarios in detail including the configuration and results. We used the test collection from the microblog track of TREC-2015 <ref type="bibr" coords="4,338.27,330.58,9.72,7.86" target="#b3">[3]</ref> to tune parameters of all our runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Push Notifications Scenario</head><p>We submitted three runs in this scenario. In all of them, we set both of the relevance and novelty thresholds τr and τn to 0.6 according to the experiments we conducted on TREC-2015 test collection.</p><p>• QUBaseline is the baseline run that does no expansion to the topic profile.</p><p>• QUExpP has a similar configuration to QUBaseline except that it uses pseudo relevance feedback to expand the profile hourly. It extracts the top k = 2 terms from the top p = 20 potentially-relevant tweets detected by the relevance filtering. We set the expansion term weight factor to be β = 0.2 to avoid the topic drift.</p><p>• QUExpT also performs hourly expansion, but using Twitter search API. It adds the top k = 1 term extracted from the top p = 20 pseudo-relevant tweets returned from Twitter live search. Similar to the previous run, we set the expansion factor β to 0.2.</p><p>Table <ref type="table" coords="4,350.78,585.66,4.61,7.86" target="#tab_1">1</ref> shows the results for our official runs for the push notifications scenario in comparison to the baseline run (i.e., YoGosling) <ref type="bibr" coords="4,364.74,606.58,9.72,7.86">[6]</ref> provided by the track organizers. The table also shows the performance of two other hypothetical runs denoted as Median and Best, which indicate the average of the best and median scores respectively per topic among all participated runs. These scores were provided by the track organizer for EG-1, nCG-1 and GMP.5 measures. Note that the unit of both the mean latency (MLT) and median latency (MedLT) is seconds.</p><p>The table clearly shows that our baseline run (QUBaseline) outperforms the other two runs and also the track baseline in terms of the official measure EG-1. It is interesting to note that topic expansion had a negative effect on the system performance in both expansion runs. This could have happened due to several reasons. One possible reason is that we did not exhaustively tune the expansion parameters. Perhaps performing expansion at a lower rate or using a different expansion β could have helped improve the overall system performance. Moreover, as topic expansion might cause drift in some topics, a further failure analysis of the topics that got drifted is needed to explore better methods of expansion term selection. Compared to the other submitted runs, we notice that all our runs outperform the median for the measures EG-1 and nCG-1. Indeed, our best submitted run scored above the median over EG-1 measure in 19 topics out of the 56 evaluated topics. While there is a significant difference with the "oracle" best run, our best submitted run exhibited the best score over EG-1 measure for 15 topics. It is worth mentioning that our runs exhibited the best performance (according to the official evaluation measure, EG-1) among all submitted automatic runs (42 runs submitted by 19 participating teams) in this scenario this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">E-mail Digest Scenario</head><p>We have also submitted three runs in this scenario. In all of them, we set the novelty threshold τn to 0.6.</p><p>• QUDR8 retrieves tweets using a language model with Dirichlet smoothing while setting the smoothing factor µ to 2000. The relevance threshold τr is set to 8.</p><p>• QUJM16 retrieves tweets using a language model with Jelinek-Mercer smoothing while setting the interpolation factor λ to 0.7. The relevance threshold τr is set to 16.</p><p>• QUDRJM24: ranks tweets using a scoring function that combines evidence from two retrieval models <ref type="bibr" coords="5,280.64,544.77,9.20,7.86" target="#b1">[1]</ref>: language model with Dirichlet smoothing (µ = 2000) and Jelinek-Mercer smoothing (λ = 0.7). The relevance threshold τr is set to 24.  <ref type="table" coords="5,351.94,183.97,4.61,7.86" target="#tab_2">2</ref> shows our results for this scenario compared to the YoGosling baseline run provided by the track organizers <ref type="bibr" coords="5,331.78,204.89,9.20,7.86">[6]</ref>. The table shows that QUJM16 run (that retrieves tweets using a language model with Jelinek-Mercer smoothing) is the best performing run compared to all other runs. Overall, that run was ranked second among all submitted automatic runs in that scenario this year. We plan to work on improving this simple approach by experimenting with more effective retrieval models. Additionally, a more thorough parameter tuning is needed to set λ, and the novelty and relevance thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION AND FUTURE WORK</head><p>In this work, we presented a light-weight scalable real-time tweet summarization system as our participation in the realtime summarization track in TREC-2016. For both of the scenarios of the track (i.e., push notifications and e-mail digest scenarios) we followed a simple pipeline that includes multiple stages: pre-qualification, preprocessing, relevance filtering, novelty filtering, and tweets nomination. As for the push notification scenario, we experimented with different interest profile expansion approaches to test how we can enrich the topic representation with terms of interest to cope with topic development over time. Surprisingly, our results showed that the baseline run that does not perform any expansion outperformed the ones used expansion. As for the e-mail digest scenario, we used simple daily ad-hoc search over the index of tweets collected during a day to retrieve the set of potentially-relevant tweets that went through the same pipeline. Our results showed that a simple language modeling retrieval model with Jelinek-Mercer smoothing achieved the best performance compared to other runs. Overall, our push notification runs exhibited the best performance among all submitted automatic runs this year.</p><p>We plan to further perform failure analysis on all components of the system. We specifically plan to investigate the poor performance of runs that perform expansion by conducting experiments with different expansion techniques to update the topic profile over time. We also plan to experiment the effect of using dynamic thresholds on the system performance. Additionally, we are planning to study the effect of using different similarity features in both relevance and novelty filters such as the semantic and social features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,53.80,63.80,502.13,96.51"><head>Table 1 :</head><label>1</label><figDesc>Official TREC 2016 results of QU runs for the push notifications scenario. Best value per column is boldfaced.</figDesc><table coords="5,93.95,83.10,421.81,77.20"><row><cell>Run</cell><cell>EG-1</cell><cell>EG-0</cell><cell>nCG-1</cell><cell cols="4">nCG-0 GMP.33 GMP.5 GMP.66</cell><cell>MLT</cell><cell>MedLT</cell></row><row><cell cols="5">QUBaseline 0.2643 0.0321 0.2479 0.0157</cell><cell>-0.1357</cell><cell>-0.0888</cell><cell>-0.0447</cell><cell>173843</cell><cell>62478</cell></row><row><cell>QUExpP</cell><cell>0.2519</cell><cell>0.0233</cell><cell>0.2413</cell><cell>0.0127</cell><cell>-0.1641</cell><cell>-0.1134</cell><cell>-0.0657</cell><cell>161403</cell><cell>56863</cell></row><row><cell>QUExpT</cell><cell>0.2552</cell><cell>0.0230</cell><cell>0.2455</cell><cell cols="5">0.0133 -0.0986 -0.0647 -0.0329 141163</cell><cell>46025</cell></row><row><cell>YoGosling</cell><cell>0.2289</cell><cell>0.0253</cell><cell cols="3">0.2330 0.0295 -0.6000</cell><cell>-0.4317</cell><cell cols="2">-0.2733 120909</cell><cell>8718</cell></row><row><cell>Median</cell><cell>0.2335</cell><cell>-</cell><cell>0.2303</cell><cell>-</cell><cell>-</cell><cell>-0.1049</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Best</cell><cell>0.3816</cell><cell>-</cell><cell>0.4576</cell><cell>-</cell><cell>-</cell><cell>0.0388</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,53.80,183.97,294.23,531.44"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="5,53.80,608.45,239.11,106.97"><row><cell cols="3">: Official TREC 2016 results of QU runs for</cell></row><row><cell cols="3">the e-mail digest scenario. Best value per column is</cell></row><row><cell>boldfaced.</cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell cols="2">nDCG1 nDCG0</cell></row><row><cell>QUDR8</cell><cell>0.2344</cell><cell>0.0094</cell></row><row><cell>QUJM16</cell><cell cols="2">0.2621 0.0300</cell></row><row><cell>QUDRJM24</cell><cell>0.2558</cell><cell>0.0237</cell></row><row><cell cols="2">YoGoslingBSL 0.2352</cell><cell>0.0299</cell></row><row><cell>Median</cell><cell>0.1931</cell><cell>0.0325</cell></row><row><cell>Best</cell><cell>0.4427</cell><cell>0.2481</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,321.42,711.19,173.57,7.86"><p>https://dev.twitter.com/rest/public/search</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">ACKNOWLEDGMENTS</head><p>This work was made possible by NPRP grant# <rs type="grantNumber">NPRP 6-1377-1-257</rs> and NPRP grant# <rs type="grantNumber">NPRP 7-1313-1-245</rs> from the <rs type="funder">Qatar National Research Fund</rs> (a member of <rs type="funder">Qatar Foundation</rs>). The statements made herein are solely the responsibility of the authors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qAEnNQG">
					<idno type="grant-number">NPRP 6-1377-1-257</idno>
				</org>
				<org type="funding" xml:id="_nA6SXsB">
					<idno type="grant-number">NPRP 7-1313-1-245</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,58.28,55.51,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,70.79,209.00,7.86;6,67.99,81.25,215.91,7.86;6,67.99,91.71,173.46,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,177.54,70.79,99.45,7.86;6,67.99,81.25,32.57,7.86">Combination of Multiple Searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,119.20,81.25,164.70,7.86;6,67.99,91.71,42.61,7.86">Proceedings of the Second Text REtrieval Conference</title>
		<meeting>the Second Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,103.17,168.56,7.86;6,67.99,113.63,210.92,7.86" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://trecrts.github.io/TREC2016-RTS-guidelines.html" />
		<title level="m" coord="6,97.39,103.17,112.60,7.86">TREC 2016 track guidelines</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,125.08,181.25,7.86;6,67.99,135.54,211.72,7.86;6,67.99,146.01,194.49,7.86;6,67.99,156.47,117.68,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,121.64,135.54,158.08,7.86;6,67.99,146.01,21.13,7.86">Overview of the TREC-2015 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,107.90,146.01,154.58,7.86;6,67.99,156.47,90.09,7.86">Proceedings of the 24th Text REtrieval Conference, TREC &apos;15</title>
		<meeting>the 24th Text REtrieval Conference, TREC &apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,167.92,224.92,7.86;6,67.99,178.38,213.43,7.86;6,67.99,188.84,216.92,7.86;6,67.99,199.31,159.18,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,121.41,178.38,160.01,7.86;6,67.99,188.84,85.05,7.86">Overview of the TREC-2016 Real-Time Summarization Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,171.83,188.84,113.08,7.86;6,67.99,199.31,131.59,7.86">Proceedings of the 25th Text REtrieval Conference, TREC &apos;16</title>
		<meeting>the 25th Text REtrieval Conference, TREC &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,210.76,214.64,7.86;6,67.99,221.22,211.84,7.86;6,67.99,231.68,178.50,7.86;6,67.99,242.14,204.74,7.86;6,67.99,252.61,67.75,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,67.99,221.22,211.84,7.86;6,67.99,231.68,162.54,7.86">QU at TREC-2015: Building Real-Time Systems for Tweet Filtering and Question Answering</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Torki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,67.99,242.14,204.74,7.86;6,67.99,252.61,40.15,7.86">Proceedings of the 24th Text REtrieval Conference, TREC &apos;15</title>
		<meeting>the 24th Text REtrieval Conference, TREC &apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.99,264.06,214.72,7.86;6,67.99,274.52,215.13,7.86;6,67.99,284.98,213.80,7.86;6,67.99,295.44,176.79,7.86;6,67.99,305.91,207.97,7.86;6,67.99,316.37,20.96,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,255.61,264.06,27.10,7.86;6,67.99,274.52,211.41,7.86">Simple Dynamic Emission Strategies for Microblog Filtering</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,79.49,284.98,202.31,7.86;6,67.99,295.44,176.79,7.86;6,67.99,305.91,132.26,7.86">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR &apos;16</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1009" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
