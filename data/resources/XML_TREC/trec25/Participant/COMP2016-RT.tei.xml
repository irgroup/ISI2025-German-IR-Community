<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.89,89.47,370.46,15.80">PolyU at TREC 2016 Real-Time Summarization</title>
				<funder ref="#_gyMuKXY">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_CxcG7vn">
					<orgName type="full">Research Grants Council of Hong Kong</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.19,131.67,53.99,9.48"><forename type="first">Haihui</forename><surname>Tan</surname></persName>
							<email>tanhaihui92@gmail.com</email>
						</author>
						<author>
							<persName coords="1,278.29,131.67,50.93,9.48"><forename type="first">Dajun</forename><surname>Luo</surname></persName>
							<email>luodajun100@gmail.com</email>
						</author>
						<author>
							<persName coords="1,345.85,131.67,46.70,9.48"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
						</author>
						<title level="a" type="main" coord="1,89.89,89.47,370.46,15.80">PolyU at TREC 2016 Real-Time Summarization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0E448ED8F39623C7A69D47B42FEA92FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the participation of The Hong Kong Polytechnic University (PolyU) to the TREC 2016 Real-Time Summarization track. The two tasks related to Scenario A and Scenario B both focuses on information real-time processing. During the evaluation period, the system monitors the Twitter sample stream with respect to a number of "interest profiles". We submitted three runs for both scenarios. We describe the system overview and the implementation details in this paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The TREC Real-Time Summarization (RTS) track explores techniques for constructing real-time update summaries from social media streams in response to users' information needs. The TREC 2016 Real-Time Summarization evaluation took place from August 2, 2016 00:00:00 UTC to August 11, 2016 23:59:59 UTC. During the evaluation period, participating systems monitor the Twitter sample stream with respect to a number of "interest profiles" that represent users' information needs. The Twitter streaming API offers an approximately 1% sample of all tweets (sometimes called the "spritzer"). For this year, 203 interest profiles (queries) are given.</p><p>In Scenario A, the content that is identified as relevant by a system based on the user's interest profile will be pushed in real-time. At a high level, push notifications should be relevant (i.e., on topic), timely (i.e., to provide updates as soon after the actual event occurrence as possible), and novel (i.e., users should not be pushed multiple notifications that are about the same thing).</p><p>In Scenario B, a system can identify a batch of up to 100 ranked tweets per day per interest profile. At a high level, these results should be relevant and novel. Timeliness is not important as long as the tweets were all posted on the previous day.</p><p>Comparing these two scenarios, Scenario A is a "really" real-time task while Scenario B is not, which means we may utilize some more sophisticated real-time techniques and pay more attention on the efficiency problem during implementation.</p><p>To fulfil the requirements mentioned above, we develop a system, which consists of pre-processing, relevance measurement, redundancy detection and push strategy. We also take efficiency, robustness and reliability into consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SYSTEM OVERVIEW</head><p>The whole system is based on the "bag-of-words" model. As shown in Figure <ref type="figure" coords="1,151.34,748.31,3.36,7.80" target="#fig_0">1</ref>, the system consists of two parts: Offline Part and Online Part.</p><p>Offline Part: 1. In order to find the synonyms and related keywords to better measure the relevance, we expand the original query (interest profiles) utilizing the Bing News Search API and Reuters Corpus. 2. In order to measure the relevance of each coming tweet w.r.t the query, we train a Relevance Measurement Model based on the labelled data of Microblog Track from past years, 3. Utilizing the clustered data from past years, we train a clustering model to do redundancy detection and discard the redundant ones.</p><p>Online Part: 1. Use official API to listen the Tweet Stream. 2. Pre-process a vast amount of tweets to filter out most of the "trash" or irrelevant tweets and transform each tweet into a standard and clean format. 3. Extract the feature vector from each tweet based on tweet text, URL external text and metadata. 4. Estimate Relevance score. 5. Check the redundancy. 6. Do a Scenario A Push and Scenario B Ranking using certain rules (such as daily quota, etc.).</p><p>Since the core tasks in Scenario A and Scenario B are the same, i.e., to estimate the tweet relevance to interest profiles, the workflows for these two scenarios are merged into one single system, except the last module (Push for Scenario A and Rank for Scenario B).</p><p>The difference among PolyURunA1, PolyURunA2, PolyURunA3 (PolyURunB1, PolyURunB2, PolyURunB3) is in the Relevance Measurement Model. There's a slightly difference in Relevance Measurement strategy among 3 runs. We will describe in more detail in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">COMPONENTS Offline Part:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Expansion</head><p>In order to find the synonyms and related keywords to measure the relevance better, inspired by the approaches proposed in <ref type="bibr" coords="1,354.58,602.15,9.95,7.80" target="#b3">[3]</ref>[4], we do the query expansion. For every topic, we feed the topic title into Bing News Search API and get top 50 search results' snippets. Then we calculate the TF-IDF score based on Reuters Corpus for every term in all snippets, and select top-20-score terms as "Expansion Terms". We select top 10 terms from narrative and description the same way as above, as "Narr-Desc Terms". All terms except stopwords in title as "Title Terms".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relevance Model Training</head><p>For 3 different runs, we implement 3 different Relevance Measurement strategies. And we use the same relevance measurement on both scenarios. Almost the same as Run 2, except that we add an additional feature: word2vec-info. To briefly explain the intuitive idea behind this feature, let's look at an example. For topic MB236, "California drought agricultural effects", after query expansion, we can get these terms as expanded query: "water" "groundwater" "california" "drought" "impact" and etc. Now, let's imagine there are two different tweets comming:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>tweet A: "water drought groundwater" tweet B: "water California impact"</head><p>Both can be hit 3 times by terms in query. However tweet B is more relevant, apparently, because tweet B gives more information. In other words, "water" "California" "impact" these three words are semantically "distant" from each other so they bring more relevant information. On the other hand, "water" "groundwater" "drought" are semantically close to each other (actually all about water), although they hit 3 times, they bring less information.</p><p>Under this intuition, we utilize the word2vec model <ref type="bibr" coords="2,266.23,619.19,10.45,7.80" target="#b6">[5]</ref> to calculate the similarity between words, and then we can calculate how much relevant information a tweet brings to us. We give the equation: Here, 洧노 1 denotes the term which hits the text, 洧녜 denotes the number of terms which hit the text, 洧노 34567 denotes the most similar term to 洧노 1 which hits the text. The range of 洧멇롐뒳롐뛿롐뒳롐뙗롐뀛롐洧녰洧노洧녽(洧노 = , 洧노 &gt; ) function is (0, 1] where 1 means 洧노 = and 洧노 &gt; are the same word. The word2vec model is trained on GoogleNews Corpus.</p><formula xml:id="formula_0" coords="2,106.78,676.92,145.03,9.26">洧녰洧녵洧녭洧녶 = (1 -洧멇롐뒳롐뛿롐뒳롐뙗롐뀛롐洧녰洧노洧녽(洧노 1 , 洧노 34567 ))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run 2: 11-features model (without word2vec-info feature)</head><p>In a word, the core task is to determine whether a tweet is relevant to an interest profile (profile) or not. Intuitively, we consider the relevance estimation as a classification problem in which we should classify each coming tweet into three classes: 2 (highly-relevant), 1 (relevant) or 0 (not-relevant).</p><p>Inspired by <ref type="bibr" coords="2,352.22,481.43,10.11,7.80" target="#b2">[2]</ref>[4] <ref type="bibr" coords="2,372.44,481.43,10.11,7.80" target="#b2">[2]</ref>, we utilize a 11-features vector space to represent every tweet to a corresponding interest profile (query), and we list all of them as following:</p><p>count_ti: the number of times "Title Terms" appear in tweet text count_te: the number of times "Title Terms" appear in external URL text count_di: the number of times "Narr-Desc Terms" appear in tweet text count_de: the number of times "Narr-Desc Terms" appear in external URL text count_ei: the number of times "Expansion Terms" appear in tweet text count_ee: the number of times "Expansion Terms" appear in external URL text is_link: a tweet consists of URL for 1; otherwise for 0 log_followers_count: the log of the number of followers of the author who publishes the tweet.</p><p>log_statuses_count: the log of the number of tweets the author publishes.</p><p>world_count: the number of words in this tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>hashtag_count: the number of hashtag in this tweet</head><p>We train a SVM model based on labelled Microblog Track past data. For each coming tweet, we predict it into 2 (highly-relevant), 1 (relevant) or 0 (not-relevant) with a probability based on well-trained SVM classifier. Since the metrics this year lays emphasis on precision rather than recall, so only if a tweet is predicted into highly-relevant class, then we let the corresponding probability value be its Relevant Score and do the next processing; otherwise we discard this tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run 3: Naive Strategy</head><p>This Run implements a na칦ve but efficient strategy to estimate the relevance between an interest profile and a tweet. Intuitively, more "profile terms" appears in a tweet more relevant they are. We regard this na칦ve strategy as a reference compared to other two runs with more complicated relevance-estimation strategy. So, we just add up 6 kinds of number of appearance as following:</p><p>ti: the number of times "Title Terms" appear in tweet text te: the number of times "Title Terms" appear in external URL text di: the number of times "Narr-Desc Terms" appear in tweet text de: the number of times "Narr-Desc Terms" appear in external URL text ei: the number of times "Expansion Terms" appear in tweet text ee: the number of times "Expansion Terms" appear in external URL text</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>洧녠洧뉧롐뙗롐뉧롐洧녩洧녵洧녫洧 洧녡洧녫洧녶洧洧 = 洧노洧녰 + 洧노洧 + 洧녬洧녰 + 洧녬洧 + 洧뉧롐 + 洧뉧롐</head><p>Online Part:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pre-processing</head><p>(a) Language detection: Based on RTS official guideline, Non-English tweets should be judged as not relevant. To filter out non-English tweets, we read the "lang" field of Tweet Stream API attribute and retain only the "en" ones. If length (ASCII characters)/length (the whole text) &lt; 0.8, we discard this tweet, because that means this tweet consists of too many non-ASCII characters. Then, we use langdetect <ref type="bibr" coords="3,112.24,576.71,10.45,7.80" target="#b1">[1]</ref> package to detect the language and discard non-English tweets. The main reason why we use these three-level detector to detect non-English tweets is that efficiency is crucial in this real-time track. We will discuss the efficiency issue in the Section 4.</p><p>(b) Trash discard: Learned from <ref type="bibr" coords="3,196.96,634.55,9.54,7.80" target="#b2">[2]</ref>, we decide to discard "trash tweet" before further processing. If a tweet meets one or more these conditions below, we regard it as "Trash" tweet and filter out it (bracketed texts are intuitive reasons):</p><p>1. the length of text is less than 20; (too few words to provide enough information)</p><p>2. the number of hashtag is more than 5; (typical trash tweet)</p><p>3. All characters are capital. (typical trash tweet) (c) Keyword filtering: In consideration of efficiency, we implement a keyword filtering to filter out the vast majority of apparently irrelevant tweets. We select keywords from every topic's title based on the IDF score on Reuters Corpus and check them manually. If a coming tweet does not match any one of these keywords, we discard it.</p><p>(d) Crawl URL: crawl external URL webpage text to get more text about this tweet for further process.</p><p>(e) Clean original tweet text: remove hashtag, remove RT@, remove all URLs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Redundancy Detection</head><p>For each tweet considered as relevant to an interested topic, an efficient and naive similarity measurement was adopted to detect redundancy.</p><p>We observe that most of redundant tweets are not rephrased but simply copies of the original tweet. Hence our method assumes that the similarity between two tweets is merely determined by occurrences of their common vocabulary.</p><p>The similarity for redundancy detection is defined as the union score divided by the intersection score of two tweets.</p><p>Similarity t ; , t N = union_score(t_1, t_2) / intersection_score(t_1, t_2)</p><p>The union score of two tweets is defined as the sum of word length of the union of two tweets. And the intersection score is defined as the sum of word length of the common word of the two tweets.</p><p>For example, tweet A is "I have a cat", tweet B is "My cat has claws I do not have". The union of these tweets is "I have a cat my cat has claws I do not have". "I" length is 1, "have" length is 4, and etc.. So the union score is 1+4+1+3+2+3+3+5+1+2+3+4 = 32. While the intersection is "I have cat cat I have". Hence the intersection score is 1+4+3+3+1+4 = 16. By our definition, the similarity of sample tweets is 16 / 32 = 0.5.</p><p>Using the training data from previous years, we find an optimal threshold of 0.6 for redundancy detection. For each topic we maintain a list of pushed tweets. Before pushing a new tweet, it's similarity with every tweet which is pushed previously in the list corresponding to the topic is computed to determine redundancy. Then discard the redundant ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Push Strategy and Ranking Strategy</head><p>As for Scenario A, it seems like a variant of The Secretary Problem. However, a crucial difference is that The Secretary Problem aims to get more sum of gain or sum of score, regardless of average gain or "precision". In Scenario A, according to metrics of guideline, recall is much less important than precision. So, a "cautious" push strategy is reasonable. We set thresholds based our observation on the Tweet Stream for days before evaluation period. As for Run1, we only push the tweets which were classified as "highly-relevant" with the probability of 0.7 or higher. For Run2, we only push the tweets which were classified as "highly-relevant" with the probability of 0.6 or higher. For Run3, we only push the tweets with the relevance score of 7 or higher.</p><p>As for Scenario B, we use the same relevance measurement with Scenario A. The only difference is that we collect and store all the tweets relevant to each topic during one day.</p><p>Then select top ten tweets to push, ordered by the probability to be classified as "highly-relevant".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ABOUT EFFICIENCY</head><p>The efficiency of the whole system is significant in this year's Track, since the listening and pushing part are both truly real-time. The Twitter streaming API offers an approximately 1% sample of all tweets. According to docs <ref type="bibr" coords="4,71.89,161.75,9.54,7.80" target="#b7">[6]</ref>, Twitter streaming volume is not constant. Throughout the course of a 24 hour period, there is a natural ebb and flow to the number of Tweets delivered per second. According to our test, the coming data rate of Twitter Public Stream is about 50 tweets/s ~ 80 tweets/s. So that is to say, if the rate of a system's pipeline to process all coming tweets is less than this rate, there might be some problem.</p><p>Our approach to tackle this problem is to set 5 levels of filters as mentioned above. The idea is that put the compute-fast filtering module front in pipeline, so only a few of tweets need to pass compute-intensive or time-consuming module, such as external URL webpage crawling or Relevance Estimation. For Scenario A, Table <ref type="table" coords="4,153.59,552.95,4.44,7.80" target="#tab_0">1</ref> and Table <ref type="table" coords="4,197.92,552.95,4.44,7.80" target="#tab_1">2</ref> report the performance of our three runs. As we can see, Run3 outperforms both other runs, indicating that a na칦ve strategy is very useful in such kind of task. Note that Run3 gets a worst GMP (.33) in Table <ref type="table" coords="4,94.62,594.47,3.36,7.80" target="#tab_1">2</ref>. It means although the na칦ve strategy gains much, it suffers from pushing too many non-relevant tweets. Run2 performances better under GMP (.33) metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head><p>For Scenario B, Table <ref type="table" coords="4,152.10,631.43,4.44,7.80" target="#tab_2">3</ref> reports the performance of our three runs. Apparently, Run3 significantly outperforms other two runs. That means a na칦ve strategy is effective for this scenario.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,219.36,348.55,155.89,8.64;2,151.33,72.58,292.08,273.36"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An Overview of the system</figDesc><graphic coords="2,151.33,72.58,292.08,273.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,71.89,328.79,214.79,115.08"><head>Table 1 :</head><label>1</label><figDesc>Performance of submitted runs for Scenario A (evaluated by the mobile assessors)</figDesc><table coords="4,71.89,328.79,214.79,115.08"><row><cell></cell><cell>Run ID</cell><cell cols="2">P (strict)</cell><cell>P (lenient)</cell></row><row><cell>COMP2016</cell><cell>run1-11</cell><cell cols="2">0.5143</cell><cell>0.5238</cell></row><row><cell>COMP2016</cell><cell>run2-12</cell><cell cols="2">0.5465</cell><cell>0.5581</cell></row><row><cell>COMP2016</cell><cell>run3-13</cell><cell cols="2">0.5710</cell><cell>0.5828</cell></row><row><cell>Team</cell><cell>Run ID</cell><cell>EG-1</cell><cell>nCG-1</cell><cell>GMP(.33)</cell></row><row><cell cols="2">COMP2016 run1-11</cell><cell>0.2565</cell><cell>0.2515</cell><cell>-0.0804</cell></row><row><cell cols="2">COMP2016 run2-12</cell><cell>0.2559</cell><cell>0.2483</cell><cell>-0.0585</cell></row><row><cell cols="2">COMP2016 run3-13</cell><cell>0.2698</cell><cell>0.2909</cell><cell>-0.3262</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,71.89,447.11,206.56,71.88"><head>Table 2 :</head><label>2</label><figDesc>Performance of submitted runs for Scenario A (evaluated by NIST assessors)</figDesc><table coords="4,71.89,478.55,202.06,40.44"><row><cell>Team</cell><cell>Run ID</cell><cell>nDCG-1</cell><cell>nDCG-0</cell></row><row><cell>COMP2016</cell><cell cols="2">PolyURunB1 0.2536</cell><cell>0.0215</cell></row><row><cell>COMP2016</cell><cell cols="2">PolyURunB2 0.2523</cell><cell>0.0184</cell></row><row><cell>COMP2016</cell><cell cols="2">PolyURunB3 0.2898</cell><cell>0.0684</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,80.35,521.99,197.87,18.12"><head>Table 3 :</head><label>3</label><figDesc>Performance of submitted runs for Scenario B (evaluated by NIST assessors)</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">ACKNOWLEDGMENTS</head><p>The work described in this paper was supported by <rs type="funder">Research Grants Council of Hong Kong</rs> (<rs type="grantNumber">PolyU 152094/14E</rs>) and <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">61272291</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CxcG7vn">
					<idno type="grant-number">PolyU 152094/14E</idno>
				</org>
				<org type="funding" xml:id="_gyMuKXY">
					<idno type="grant-number">61272291</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,312.55,75.68,88.18,10.54" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,326.05,94.79,196.78,7.80;4,326.05,105.35,28.71,7.80;4,502.40,105.35,20.47,7.80;4,326.05,115.83,196.15,8.11;4,326.05,126.87,58.33,8.11" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,419.88,94.79,102.95,7.80;4,326.05,105.35,25.52,7.80">Language detection library (slides)</title>
		<author>
			<persName coords=""><forename type="first">Shuyo</forename><surname>Nakatani</surname></persName>
		</author>
		<ptr target="http://www.slideshare.net/shuyo/language-detection-library-for-java" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,326.05,137.51,196.83,7.80;4,326.05,147.83,196.80,7.80;4,326.05,158.39,196.82,7.80;4,326.05,168.71,187.10,7.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,326.05,147.83,196.80,7.80;4,326.05,158.39,19.07,7.80">University of Waterloo at TREC 2015 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roegiest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,376.64,158.39,146.24,7.80;4,326.05,168.71,160.30,7.80">The Twenty-Fourth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>TREC 2015) Proceedings. NIST</note>
</biblStruct>

<biblStruct coords="4,326.05,179.03,196.79,7.80;4,326.05,189.35,196.79,7.80" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Feifan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<idno>PKUICST at TREC 2015</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,326.05,199.67,196.81,7.80;4,326.05,209.99,196.79,7.80;4,326.05,220.31,196.82,7.80;4,326.05,230.63,44.05,7.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,393.70,199.67,129.16,7.80;4,326.05,209.99,105.75,7.80">Query-biased Adaptive Filtering in Real-time Microblog Stream</title>
		<author>
			<persName coords=""><forename type="first">Microblog</forename><surname>Track</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,451.81,209.99,71.03,7.80;4,326.05,220.31,192.91,7.80">The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,326.05,241.19,196.82,7.80;4,326.05,251.51,173.58,7.80" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,326.05,251.51,169.76,7.80">POLYUCOMP at TREC 2014 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Tianyi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dehong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,326.05,261.83,196.78,7.80;4,326.05,272.15,196.70,7.80;4,326.05,282.47,196.80,7.80;4,326.05,292.79,20.22,7.80" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="4,350.51,272.15,172.24,7.80;4,326.05,282.47,43.71,7.80">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781v3[cs.CL]7</idno>
		<imprint>
			<date type="published" when="2013-09">2013. Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,326.05,303.11,196.80,7.80;4,326.05,313.59,194.69,8.11;4,326.05,324.63,8.91,8.11" xml:id="b7">
	<monogr>
		<ptr target="https://dev.twitter.com/streaming/overview/processing" />
		<title level="m" coord="4,326.05,303.11,166.21,7.80">Twitter Documentation of Streaming APIs</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
