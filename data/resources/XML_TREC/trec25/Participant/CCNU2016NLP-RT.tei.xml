<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,108.86,82.60,377.38,14.36">CCNU at TREC 2016 Real-Time Summarization Track</title>
				<funder>
					<orgName type="full">Specific Funding for Education Science Research by Self-determined Research Funds of CCNU</orgName>
				</funder>
				<funder ref="#_Z3UGwAz">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_mtFNkEj">
					<orgName type="full">Colleges&apos; Basic Research and Operation of MOE</orgName>
				</funder>
				<funder ref="#_pQ5PpBC">
					<orgName type="full">Thirteen Five-year Research Planning Project of National Language Committee</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,248.33,107.02,44.84,10.80"><forename type="first">Chao</forename><surname>Bei</surname></persName>
							<email>chaobei@mails.ccnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Central China Normal University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.51,107.02,30.37,10.80"><forename type="first">Po</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Central China Normal University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,108.86,82.60,377.38,14.36">CCNU at TREC 2016 Real-Time Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3D27CDDCF305F090C57E46C6D6F073E8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approach to real-time summarization track for push notification scenario and email digest scenario in TREC 2016. This track aims at monitoring a stream of twitter posts and pushing the most relevant tweets to the users according to their interest profiles. In the push notification scenario, we adopt a combined method by take into account several critical factors i.e., relevance, salience and redundancy to select some relevant but non-redundant tweets. In the email digest scenario, in addition to considering these factors, we additionally adopted a novel TF-IDF strategy to automatically rank tweets at the end of a day. The experimental results on both scenarios show the effectiveness of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Now there is a large amount of information shared by different social media platforms such as Twitter, Facebook, etc. We have been overwhelmed by big data and it is difficult for us to find useful information effectively and efficiently. Therefore, a system which can automatically monitor the stream of social media posts so that different users with diverse background knowledge may keep up with the latest development of the topics that they care about is of great need. In this case, the feedback information provided by such a kind of system is expected to be relevant, instant and diverse. This year's track consists of the following two scenarios:  Scenario A: Push Notifications. In this scenario, content that is identified as relevant by a system based on the user's interest profile will be pushed to the mobile phones of users. And the push notifications should be relevant, timely, and novel.  Scenario B: Email Digest. In this scenario, a system will identify a batch of up to 100 ranked tweets per day per interest profile and it is expected that systems will compute the results in a relatively short amount of time after the day ends. Each tweet post which is identified as relevant and novel is to be aggregated into an email digest, which will then be sent to the corresponding user periodically. In both scenarios, we focus on finding ranked lists of tweets which are both relevant and salient by the classic methods, such as TF-IDF and BM25 <ref type="bibr" coords="1,454.18,699.90,12.76,10.80" target="#b0">[1]</ref>. In the push notifications scenario, whenever a tweet comes, we immediately estimate its relevance and redundancy by the computation of JD-divergence, and estimate its salience by a hybrid TF-IDF strategy. In the scenario of email digest, a novel TF-IDF model <ref type="bibr" coords="2,123.50,75.82,14.06,10.80" target="#b1">[2]</ref> is adopted to re-rank the summaries at the end of each day. In addition, we also adopt adaptive thresholds in both scenarios to determine whether a tweet should be pushed or emailed to a specified user.</p><p>The rest of paper is organized as follows: we first describe preprocess for both scenarios in Section 2, and then introduce the implementation of our system in detail in Section 3. The parameter settings of our approach is described in Section 4. In Section 5， we present the evaluation performance of our system for both scenarios and analyze the experimental results. Section 6 concludes the whole technical report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preprocess</head><p>In this section, we introduce preprocess of our system for both scenarios. The interest profiles and tweet streams are both preprocessed.</p><p>Firstly, we obtain the top ten titles for each interest profile of a user by using Bing search API. Then we combine the titles and the original interest profile to get the top k keywords as the query for each profile. On the handling of twitter stream, our system monitors the twitter's live sample stream continuously by the official API. Once our system gets the tweets, the content of it will be preprocessed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>The preprocessing is conducted on both queries and tweet stream. We eliminate all the non-English tweets by a twitter's language detector and the links including a web address is eliminated via regular expressions. Besides, if the number of "#" occurs more than three times, we consider it as a meaningless tweet and eliminate it. All the tweets are tokenized and lowercased. Stop-words are removed through NLTK and other words are stemmed by porter stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>Traditionally, query expansion is often used to improve the retrieval effectiveness <ref type="bibr" coords="2,488.09,543.87,12.85,10.80" target="#b2">[3]</ref>. In our approach, we first get top five keywords as original keywords from each interest profile. Then, we submit these original keywords to Bing Search API and obtain top k keywords as expansion based on the contents from the top ten titles of retrieval result. The original keywords and expanded keywords are combined to be the new query for each interest profile. Lastly, we use these combined keywords to estimate the relevance between query and tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our System</head><p>This section describes the implementation of our system for two scenarios respectively in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System for Scenario A: Push Notifications</head><p>The aim of the push notifications scenario is to push the relevant and novel tweets to user as soon as possible after tweets are published. To achieve this goal, our system contains the following two components:  Offline Component: We get the top ten titles by submitting top five keywords, which we get from each interest profile, to Bing Search API. Getting the top k keywords from these titles as the expanded keywords, we combine the original keywords and expanded ones as the new query for each profile.  Online Component: The system monitors the tweet stream continuously and preprocesses the tweet as soon as the system obtains it. Then by take into account several critical factors (i.e., relevance, salience and redundancy), the system gets the relevant tweets for each interest profile. In order to meet the requirement of users, we update three thresholds of factors in different ways. If a tweet meets the three thresholds, it will be pushed to user and added into the pushed summary A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Relevance and Redundancy</head><p>We use JS-divergence to estimate relevance and redundancy. Relevance estimates the divergence between language model of tweets in stream and language model of queries, while redundancy estimates the divergence between language model of tweets in stream and language model of tweets in summaries. Therefore, the JS-divergence is as follows:</p><formula xml:id="formula_0" coords="3,242.45,441.69,257.49,29.16">W(w) = 𝑃(𝑤) + 𝑄(𝑤) 2<label>(1)</label></formula><formula xml:id="formula_1" coords="3,125.90,476.01,374.04,35.71">Relevance(P, Q) = 1 2 ∑ 𝑃(𝑤) 𝑤∈𝑃∩𝑄 log 𝑃(𝑤) 𝑊(𝑤) + 1 2 ∑ 𝑄(𝑤) log 𝑄(𝑤) 𝑊(𝑤) 𝑤∈𝑃∩𝑄<label>(2)</label></formula><p>where P and Q are unigram language models. And what is different from relevance is that in redundancy there are many summaries pushed, so the redundancy is the minimum of JSD between the tweet in a stream and the tweet in summaries. In our system, the redundancy estimation is as follows:</p><formula xml:id="formula_2" coords="3,194.21,601.56,305.73,20.36">Redundancy(𝑇 𝑛 ) = min ∀𝑇 𝑚 ∈𝑆 𝑅𝑠𝑐𝑜𝑟𝑒(𝑇 𝑛 , 𝑇 𝑚 )<label>(3)</label></formula><p>Here we use JM smoothing to avoid zero probability problem in both relevance and redundancy estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Salience</head><p>In our system, we compute the salience score based on a hybrid TF-IDF strategy <ref type="bibr" coords="3,488.38,723.32,12.85,10.80" target="#b3">[4]</ref>. As describing in <ref type="bibr" coords="3,171.57,738.92,12.87,10.80" target="#b4">[5]</ref>, we consider that a user may need the novel and salient tweets. So in order to adapt to the large number of tweets and the rapidly rising requirement, the hybrid TF-IDF is used to estimate salience as follows:</p><formula xml:id="formula_3" coords="4,203.81,116.44,296.13,81.00">Salience(𝑇 𝑖 ) = ∑ 𝑇𝐹(𝑤) × 𝐼𝐷𝐹(𝑤) 𝑤∈𝑇 𝑖 (4) TF(w) = #𝑜𝑓𝑤𝐼𝑛𝐴𝑙𝑙𝑇𝑤𝑒𝑒𝑡 #𝑊𝑜𝑟𝑑𝑠𝐼𝑛𝐴𝑙𝑙𝑇𝑤𝑒𝑒𝑡<label>(5)</label></formula><formula xml:id="formula_4" coords="4,222.53,214.84,277.41,29.19">𝐼𝐷𝐹(𝑤) = #𝑇𝑤𝑒𝑒𝑡𝑠 #𝑇𝑤𝑒𝑒𝑡𝑠 𝑤𝑂𝑐𝑐𝑢𝑟𝑠 (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Update Threshold</head><p>In our system, only the tweet that meets the thresholds of factors can be added into the pushed summaries. And in order to meet the rapidly increasing requirement of user, we update the thresholds in different ways according to different situations. We update the salience threshold δ 𝐴 everyday according the salience of the summaries yesterday, and then update the relevance threshold λ 𝐴 and the redundancy threshold γ 𝐴 when a tweet is pushed to a user.</p><formula xml:id="formula_5" coords="4,219.41,412.00,280.53,24.37">𝛿 𝐴 𝑑𝑎𝑦+1 = min 𝑇 𝑖 ∈𝑆 𝑑𝑎𝑦 (Salience(𝑇 𝑖 ))<label>(7)</label></formula><formula xml:id="formula_6" coords="4,229.25,461.61,270.69,68.24">𝜆 𝐴 = min 𝑇 𝑖 ∈𝑆 𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒(𝑇 𝑖 ) (8) γ 𝐴 ＝ max T 𝑖 ∈𝑆 𝑅𝑒𝑑𝑢𝑛𝑑𝑎𝑛𝑐𝑦(𝑇 𝑖 )<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System for Scenario B: Email Digest</head><p>The implementation detail of our system in this scenario is similar to that of the scenario A, and it also has two components:</p><p> Offline Component: Similarly with scenario A, we use expanded keywords as the new query by means of Bing Search API.  Online Component: Similarly with scenario A, the system monitors the tweet stream continuously and preprocesses the tweet as soon as the system obtains it. Then taking into account several critical factors (i.e., relevance, salience and redundancy), the system gets the relevant tweets for each interest profile. However, how to update the thresholds is different from scenario A. For this scenario, a novel TF-IDF model is used to re-rank the summaries at the end of each day. If a tweet meets the thresholds, we will add it to summary B and email it to the user periodically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Update Threshold</head><p>Although we still update the salience threshold δ 𝐵 in scenario B at the end of each day according the salience of the summaries yesterday and update the relevance threshold λ 𝐵 and the redundancy threshold γ 𝐵 when a tweet is added into summary B, we adopt different strategy due to the lower requirement compared with scenario A. For this scenario, our strategy of updating thresholds is as follows:</p><formula xml:id="formula_7" coords="5,219.41,248.18,275.54,24.37">𝛿 𝐵 𝑑𝑎𝑦+1 = min 𝑇 𝑖 ∈𝑆 𝑑𝑎𝑦 (Salience(𝑇 𝑖 )) (<label>10</label></formula><formula xml:id="formula_8" coords="5,494.95,255.25,4.99,10.80">)</formula><formula xml:id="formula_9" coords="5,230.57,296.47,269.37,70.76">𝜆 𝐵 = 𝑎𝑣𝑔 𝑇 𝑖 ∈𝑆 𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒(𝑇 𝑖 ) (11) γ 𝐵 ＝ avg T 𝑖 ∈𝑆 𝑅𝑒𝑑𝑢𝑛𝑑𝑎𝑛𝑐𝑦(𝑇 𝑖 ) (12)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">A Novel TF-IDF Model</head><p>At the end of each day, the relevance between queries and summaries may be changed with the development of the event. In order to estimate relevance better, we use a novel TF-IDF model to re-rank the summaries. The novel TF-IDF model is as follows:</p><formula xml:id="formula_10" coords="5,203.45,502.53,296.49,30.79">RITF(t, D) = log 2 (1 + 𝑇𝐹(𝑡, 𝐷)) log 2 (1 + 𝐴𝑣𝑔. 𝑇𝐹(𝑡, 𝐷))<label>(13)</label></formula><formula xml:id="formula_11" coords="5,189.89,549.33,310.05,29.19">LRTF(t, D) = TF(t, D) × log 2 (1 + 𝐴𝐷𝐿(𝐶) 𝑙𝑒𝑛(𝐷) )<label>(14)</label></formula><formula xml:id="formula_12" coords="5,224.45,596.64,275.49,29.16">BRITF(t, D) = RITF(t, D) 1 + RITF(t, D)<label>(15)</label></formula><formula xml:id="formula_13" coords="5,222.29,643.44,277.65,29.16">BLRTF(t, D) = LRTF(t, D) 1 + LRTF(t, D)<label>(16)</label></formula><formula xml:id="formula_14" coords="5,240.53,689.52,259.41,30.79">w = 2 1 + log 2 (1 + |𝑄|)<label>(17)</label></formula><formula xml:id="formula_15" coords="5,160.82,737.90,339.12,12.00">TTF(t, D) = w × BRITF(t, D) + (1 -𝑤) × BLRTF(t, D)<label>(18)</label></formula><formula xml:id="formula_16" coords="6,229.13,89.08,270.81,84.24">IDF(t, C) = ln ( 𝐶𝑆(𝐶) + 1 𝐷𝐹(𝑡, 𝐶) ) (19) AEF(t, C) = 𝐶𝑇𝐹(𝑡, 𝐶) 𝐷𝐹(𝑡, 𝐶)<label>(20)</label></formula><formula xml:id="formula_17" coords="6,204.29,190.96,295.65,29.16">TDF(t, C) = IDF(t, C) × AEF(t, C) 1 + AEF(t, C)<label>(21)</label></formula><formula xml:id="formula_18" coords="6,196.37,231.11,303.57,43.47">Sim(Q, D) = ∑ TTF(𝑞 𝑖 , D) × TDF(𝑞 𝑖 , C) |𝑄| 𝑖=1<label>(22)</label></formula><p>where Avg.TF(t, D), ADL(c), len(D), CS(C) and CTF(t, C) denote the average term frequency of D, the average document length of the collection, the length of the document D, the number of document in collection and the total occurrence of the term t in the entire collection respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Our Submissions with Parameter Settings</head><p>We submit two runs to compare the effectiveness of our system. In the run1, we use keywords matching to estimate relevance and a tweet containing at least two keywords is considered as a relevant candidate. Therefore, there is no relevance threshold in the run1 and we need more expanded keywords. Then, we set k as 10. On the contrary, JS-divergence is used to estimate relevance in the run2, so we set k as 5.</p><p>Here, in order to improve the speed of processing, before relevance assessment, we eliminate those tweets that don't contain any keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>Different from last year, a new evaluation is added in this year. It is live user-in-the-loop assessments to capture live user assessments. And the traditional post hoc batch evaluation methodology has been refined over the past few years and has been experimental validated. EG0 and nCG0 are added to estimate scores for silent days. Latency and GMP are added to estimate lateness of push notifications and synthesis score of gain and pain respectively. These evaluation is for scenario A, only nCG0 is added into scenario B. EG1 and nCG1 is still the major metrics in the scenario A and scenario B respectively. Table <ref type="table" coords="6,132.13,699.90,6.00,10.80" target="#tab_0">1</ref> and Table <ref type="table" coords="6,193.13,699.90,6.00,10.80" target="#tab_1">2</ref> show live user-in-the-loop assessment and the performance of our two runs on scenario A. Compared with the waterloo baseline, our system performed not so well. The salience assessment of our system is very simple so that it doesn't detect the real salient information and doesn't avoid the information appearing frequently. But GMP achieves a good performance on all of settings. It means that our system is not good at detecting salient information, but irrelevant tweets are in control because of the strict threshold updating strategies. Besides, there is no significant difference between keywords matching and relevance assessment according the performance for scenario A. They achieve about the same effectiveness.</p><p>Table <ref type="table" coords="7,132.13,153.82,6.00,10.80" target="#tab_2">3</ref> shows the performance of our runs for scenario B. Similarly with scenario A, our system performed not so well. The reason is same with scenario A. Particularly, our run1 is better than run2. It means that keywords matching approach is better than relevance assessment for scenario B. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we present our system for real-time summarization track in TREC 2016.</p><p>For scenario A, we expand query via Bing Search API. By taking into account of some factors (i.e. relevance, salience, redundancy), our system determines whether a tweet should be pushed to a user instantly. For the scenario B, we also detect the relevant tweets through the similar factors. But what is different from that of the scenario A is that a novel TF-IDF model is used to re-rank the summaries at the end of each day. Compared with the performance of some baselines, our system performed not so well. Since this is our first time to participate TREC, many further investigations and experiments are needed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,106.94,224.53,381.68,199.87"><head>Table 1 .</head><label>1</label><figDesc>Live user-in-the-loop assessments of our system for scenario A</figDesc><table coords="7,106.94,257.32,381.68,167.08"><row><cell></cell><cell>CCNU Run1</cell><cell>CCNU Run2</cell><cell>Waterloo Baseline</cell></row><row><cell>#rel</cell><cell>19</cell><cell>17</cell><cell>148</cell></row><row><cell>#redundant</cell><cell>0</cell><cell>3</cell><cell>12</cell></row><row><cell>#non_rel</cell><cell>95</cell><cell>89</cell><cell>286</cell></row><row><cell>#unjudged</cell><cell>728</cell><cell>763</cell><cell>1461</cell></row><row><cell>#total_length</cell><cell>842</cell><cell>870</cell><cell>1888</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,117.62,470.82,371.00,262.27"><head>Table 2 .</head><label>2</label><figDesc>Performance of our system for scenario A</figDesc><table coords="7,117.62,503.70,371.00,229.39"><row><cell></cell><cell>CCNU Run1</cell><cell>CCNU Run2</cell><cell>Waterloo Baseline</cell></row><row><cell>EG1</cell><cell>0.1699</cell><cell>0.1643</cell><cell>0.2289</cell></row><row><cell>EG0</cell><cell>0.0003</cell><cell>0.0000</cell><cell>0.0253</cell></row><row><cell>nCG1</cell><cell>0.1714</cell><cell>0.1643</cell><cell>0.2330</cell></row><row><cell>nCG0</cell><cell>0.0018</cell><cell>0.0000</cell><cell>0.0295</cell></row><row><cell>GMP.33</cell><cell>-0.1732</cell><cell>-0.2070</cell><cell>-0.6000</cell></row><row><cell>GMP.5</cell><cell>-0.1290</cell><cell>-0.1545</cell><cell>-0.4317</cell></row><row><cell>GMP.66</cell><cell>-0.0874</cell><cell>-0.1050</cell><cell>-0.2733</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,119.18,171.37,369.44,104.33"><head>Table 3 .</head><label>3</label><figDesc>Performance of our system for scenario B</figDesc><table coords="8,119.18,203.29,369.44,72.41"><row><cell></cell><cell>CCNU Run1</cell><cell>CCNU Run2</cell><cell>Waterloo Baseline</cell></row><row><cell>nDCG1</cell><cell>0.1732</cell><cell>0.1554</cell><cell>0.2352</cell></row><row><cell>nDCG0</cell><cell>0.0018</cell><cell>0.0000</cell><cell>0.0299</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">61402191</rs>), the <rs type="funder">Specific Funding for Education Science Research by Self-determined Research Funds of CCNU</rs> from the <rs type="funder">Colleges' Basic Research and Operation of MOE</rs> (No. <rs type="grantNumber">CCNU16JYKX15</rs>), and the <rs type="funder">Thirteen Five-year Research Planning Project of National Language Committee</rs> (No. <rs type="grantNumber">WT135-11</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Z3UGwAz">
					<idno type="grant-number">61402191</idno>
				</org>
				<org type="funding" xml:id="_mtFNkEj">
					<idno type="grant-number">CCNU16JYKX15</idno>
				</org>
				<org type="funding" xml:id="_pQ5PpBC">
					<idno type="grant-number">WT135-11</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,104.54,734.63,401.03,9.50;8,100.58,750.23,316.96,9.50" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,242.57,734.63,191.92,9.50">Overview of the TREC-2015 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,453.34,734.63,52.23,9.50;8,100.58,750.23,201.26,9.50">Proceedings of The Twenty-fourth Text REtrieval Conference</title>
		<meeting>The Twenty-fourth Text REtrieval Conference</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2015">2015. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.54,76.33,401.03,9.50;9,100.58,91.93,36.85,9.50;9,137.42,89.35,5.40,6.26;9,145.46,91.93,151.23,9.50" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,190.73,76.33,242.66,9.50">A Novel TF-IDF Weighting Scheme for Effective Ranking</title>
		<author>
			<persName coords=""><forename type="first">Jiaul</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paik</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,453.34,76.33,52.23,9.50;9,100.58,91.93,36.85,9.50;9,137.42,89.35,5.40,6.26;9,145.46,91.93,106.17,9.50">Proceedings of the 36 th international ACM SIGIR</title>
		<meeting>the 36 th international ACM SIGIR</meeting>
		<imprint>
			<biblScope unit="page" from="343" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.54,115.33,400.90,9.50;9,100.58,130.93,232.61,9.50" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,272.81,115.33,232.63,9.50;9,100.58,130.93,144.25,9.50">Model-based Feedback in the Language Modeling Approach to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,262.85,130.93,24.02,9.50">CIKM</title>
		<imprint>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.54,154.33,401.00,9.50;9,100.58,169.93,168.15,9.50" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,320.71,154.33,160.32,9.50">Summarization of Twitter Microblogs</title>
		<author>
			<persName coords=""><forename type="first">Beaux</forename><surname>Sharifi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Inouye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jugal</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,489.82,154.33,15.72,9.50;9,100.58,169.93,71.76,9.50">The computer journal</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="378" to="402" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.54,193.33,401.00,9.50;9,100.58,208.93,371.56,9.50" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,343.87,193.33,141.74,9.50">IRIT at TREC Microblog 2015</title>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lamjed</forename><surname>Ben Jabeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,100.58,208.93,256.00,9.50">Proceedings of The Twenty-fourth Text REtrieval Conference</title>
		<meeting>The Twenty-fourth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
