<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.67,116.95,328.01,12.62;1,287.90,134.89,39.56,12.62">IRIT @ TREC 2016 Clinical Decision Support Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.66,172.56,78.66,8.74"><forename type="first">Gia-Hung</forename><surname>Nguyen</surname></persName>
							<email>gia-hung.nguyen@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">IRIT</orgName>
								<orgName type="institution" key="instit1">Université de Toulouse</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">UPS</orgName>
								<address>
									<addrLine>118 Route Narbonne</addrLine>
									<settlement>Toulouse</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.88,172.56,58.32,8.74"><forename type="first">Laure</forename><surname>Soulier</surname></persName>
							<email>laure.soulier@lip6.frhttp</email>
							<affiliation key="aff1">
								<orgName type="department">Sorbonne Universités</orgName>
								<orgName type="laboratory">UMR 7606</orgName>
								<orgName type="institution" key="instit1">UPMC Univ Paris 06</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<addrLine>4 place Jussieu</addrLine>
									<postCode>LIP6, 75005</postCode>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.72,172.56,63.24,8.74"><forename type="first">Lynda</forename><surname>Tamine</surname></persName>
							<email>tamine@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">IRIT</orgName>
								<orgName type="institution" key="instit1">Université de Toulouse</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">UPS</orgName>
								<address>
									<addrLine>118 Route Narbonne</addrLine>
									<settlement>Toulouse</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,416.89,172.56,36.80,8.74;1,279.90,184.51,51.09,8.74"><forename type="first">Nathalie</forename><surname>Bricon-Souf</surname></persName>
							<email>nathalie.souf@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">IRIT</orgName>
								<orgName type="institution" key="instit1">Université de Toulouse</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">UPS</orgName>
								<address>
									<addrLine>118 Route Narbonne</addrLine>
									<settlement>Toulouse</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.67,116.95,328.01,12.62;1,287.90,134.89,39.56,12.62">IRIT @ TREC 2016 Clinical Decision Support Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F01534189F18B8313795B5452981BD99</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical Information Retrieval</term>
					<term>Neural Network</term>
					<term>Evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this document, we describe our participation of the IRIT lab to the TREC 2016 Clinical Decision Support track. The goal of the Clinical Decision Support track is to develop the efficient systems to retrieve relevant biomedical articles given a form of patient medical record. To address this task, we propose a neural approach to match the document and the query, with the help of the MeSH thesaurus.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC Clinical Decision Support track is designed to encourage the formalization of retrieval models in order to anticipate needs of physicians by connecting medical cases with relevant information. The objective of the task is to retrieve relevant biomedical articles to answer topics that are generic clinical questions related to patient medical records. In order to simulate the actual information needs of physicians, each topic is annotated with one of three following categories: Diagnosis, Test, and Treatment. Participants are required to retrieve the biomedical articles which are useful for answering each topic question.</p><p>To address this challenge, we propose an end-to-end neural approach that learns the similarity of documents and queries using a raw text-based representation enhanced by a concept extraction from MeSH thesaurus. We describe in the next section our neural network model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our approach</head><p>In order to match document query pairs, we rely on the neural network architecture presented in <ref type="bibr" coords="1,225.63,621.25,9.96,8.74" target="#b0">[1]</ref>. While a simple raw text-based matching could lead to a semantic gap, we propose to consider information provided by an external resource in order to add conceptual semantics in our vector representation. Indeed, our intuition here is that the document-query matching could be enhanced by exploiting the conceptual relations learned from an external resource through a hybrid representation of the distributional semantic (namely, plain text representation) and the symbolic semantic (namely, concept description).</p><p>Specifically, given a document or a query, our neural network aims to map the initial enhanced representation of the document/query into a low-dimensional feature in a semantic space. Then those latent semantic features are used to measure the relevance score between a query and a document. The architecture of the network is described in the following. Input. We call the input layer x input as the enhanced representation of a document or a query, which can be decomposed into two parts: the first part represents plain text in the document/query and the second part consists of the description of the concepts existing in the text:</p><p>-Plain text representation. This first part of input represents the textual content of the document or the query. We directly apply the ParagraphVector <ref type="bibr" coords="2,151.70,294.15,10.52,8.74" target="#b1">[2]</ref> model to learn the representation for each piece of text (document or query). -Description representation. We propose to add a layer to capture expressions of document/query via the external concepts. To form this vector, we first extract the MeSH concepts existing in the document/query by using Cxtractor 1 relying on MaxMatcher <ref type="bibr" coords="2,294.65,354.25,9.96,8.74" target="#b2">[3]</ref>. Then, the description of extracted concepts in each document/query is gathered to build a conceptual-document description vector. Similarly to the plain text representation, we apply the ParagraphVector algorithm.</p><p>Hidden layers. For each network branch, the input vector is projected into a latent space by the L hidden layers l i (i = 1, • • • , L) so as to obtain a latent semantic vector y. Each hidden layer l i and the latent semantic vector y are respectively obtained by the following non-linear transformations:</p><formula xml:id="formula_0" coords="2,219.98,463.80,260.62,24.60">l 0 = x input l i = f (W i-1 • l i-1 + b i-1 ) i = 1, ..., L<label>(1)</label></formula><formula xml:id="formula_1" coords="2,264.61,493.69,86.14,9.65">y = f (W L • l L + b L )</formula><p>where W i and b i are respectively the weight matrix and bias term at the i th layer. To perform the non-linear transformation, we use the ReLU activation function: f (x) = max(0, x). Similarity function. After obtaining the latent semantic vectors y D and y Q of document D and query Q through the non-linear transformation of hidden layers, the document-query cosine similarity score sim(D|Q) is estimated between vectors y D and y Q . Following <ref type="bibr" coords="2,271.34,589.09,9.96,8.74" target="#b0">[1]</ref>, the output of our model is calculated as a posterior probability of a document given a query, through a softmax function:</p><formula xml:id="formula_2" coords="2,229.80,622.07,246.55,24.72">P (D|Q) = exp(sim(Q, D)) D ∈C exp(sim(Q, D )) (<label>2</label></formula><formula xml:id="formula_3" coords="2,476.35,628.81,4.24,8.74">)</formula><p>1 https://sourceforge.net/projects/cxtractor/ where C is the set of candidate documents to be ranked for each query Q, approximated by including a relevant document D + and four random irrelevant documents D -. The network is trained to minimize the cross-entropy loss function on the relevant pairs:</p><formula xml:id="formula_4" coords="3,252.31,169.53,228.28,22.68">L = -log Q,D + P (D + |Q).<label>(3)</label></formula><p>We follow the configurations used in <ref type="bibr" coords="3,305.23,200.06,10.52,8.74" target="#b0">[1]</ref> to implement our network: two hidden layers of size 300 leading to an output layer of size 128. The model is trained using the stochastic gradient descent (SGD) regularized by a dropout layer before the output layer. The dropout value is set up to 0.4.</p><p>The training data is collected from previous TREC CDS tracks. We take the 60 topics and their relevant assessment provided in the 2014 and 2015 tracks to construct the set of relevant and irrelevant pairs for training and evaluating the neural network. To perform the retrieval result for this year track, we apply our trained model on the topics of this year, to obtain the ranked list of documents. For efficient computation reason, we perform a re-ranking technique over the preselected candidate documents. An initial candidate list is performed using the BM25 model to obtain the top 3,000 documents. Then we use our neural model to re-rank these candidates and retain the top 1,000 documents for submitting runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Runs and Results</head><p>We present in this section the results of our two runs submitted to the CDS track. d2vDescIrit represents the result obtained with our neural network scoring function, using topic description as query text. d2vCombIrit, also using the topic description as query text, is the result of a combination scoring between BM25 score and our neural score (where α = 0.4):</p><formula xml:id="formula_5" coords="3,160.90,460.08,315.45,9.65">score(Q, D) = α × score BM 25 (Q, D) + (1 -α) × score neural (Q, D). (<label>4</label></formula><formula xml:id="formula_6" coords="3,476.35,460.08,4.24,8.74">)</formula><p>Table <ref type="table" coords="3,220.39,495.40,4.13,7.89">1</ref>. Results averaged over the 30 topics of our runs.</p><p>Rprec infAP infNDCG P@10 d2vDescIrit 0.0206 0.0017 0.0442 0.0433 d2vCombIrit 0.0215 0.0018 0.0463 0.0533 best 0.1860 0.0397 0.2751 0.4767 median 0.0648 0.0065 0.1043 0.1533 worst 0.0019 0.0004 0.0148 0.0233</p><p>Table <ref type="table" coords="3,177.43,597.34,4.98,8.74">1</ref> shows results of our runs, poor results were obtained. One possible explanation may be that our model scenarios are not optimal since we did not perform the parameter tuning. Moreover, the small amount of document-query pairs seems to lead to overlearning, avoiding the model to be generalized to any dataset. Since this work is a preliminary model, additional experiments should be conducted to analyze the model parameters, peculiarities, and performance.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,149.47,143.58,331.12,7.86;4,149.47,154.54,331.12,7.86;4,149.47,165.50,63.61,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,149.47,154.54,327.02,7.86">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,160.99,165.50,22.42,7.86">CIKM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,149.47,176.46,331.12,7.86;4,149.47,187.42,97.93,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,282.17,176.46,198.42,7.86;4,149.47,187.42,27.03,7.86">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,196.62,187.42,21.38,7.86">ICML</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,149.47,198.38,331.12,7.86;4,149.47,209.34,270.38,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,351.64,198.38,128.95,7.86;4,149.47,209.34,190.43,7.86">Maxmatcher: Biological concept extraction using approximate dictionary lookup</title>
		<author>
			<persName coords=""><forename type="first">Xiaohua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaohua</forename><surname>Hu</surname></persName>
		</author>
		<editor>PRICAI</editor>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
