<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.95,164.80,315.34,15.15;1,171.85,186.72,267.55,15.15;1,197.99,208.63,208.81,15.15;1,413.25,206.03,5.98,10.48">Recommending Points-of-Interest via Weighted kNN, Rated Rocchio, and Borda Count Fusion *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,189.75,241.17,118.57,10.48"><forename type="first">Georgios</forename><surname>Kalamatianos</surname></persName>
							<email>georkalamatianos@gmail.com</email>
						</author>
						<author>
							<persName coords="1,340.47,241.17,81.02,10.48"><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Database &amp; Information Retrieval research unit</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">Democritus University of Thrace</orgName>
								<address>
									<postCode>67100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.95,164.80,315.34,15.15;1,171.85,186.72,267.55,15.15;1,197.99,208.63,208.81,15.15;1,413.25,206.03,5.98,10.48">Recommending Points-of-Interest via Weighted kNN, Rated Rocchio, and Borda Count Fusion *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3D98290DE65E492E8A1E4FA1530B90A8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the work of the Democritus University of Thrace (DUTH) team in TREC's 2016 Contextual Suggestion Track. The goal of the Contextual Suggestion Track is to build a system capable of proposing venues which a user might be interested to visit, using any available contextual and personal information. First, we enrich the TREC-provided dataset by collecting more information on venues from web-services like Foursquare and Yelp. Then, we address the task with two different content-based methods, namely, a Weighted kNN classifier and a Rated Rocchio personalized query. Last, we also explore the use of a voting system, namely Borda Count, as a means of fusing the results of several suggestion systems. Our runs provided very good results, achieving top or near-top TREC performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the efforts of Democritus University of Thrace (DUTH) put at the TREC 2016 Contextual Suggestion Track. This year's Track consisted of two phases. We participated in the batch experiment (Phase 2-the main task of the Track in 2016), where we dealt with the task of re-ranking a set of candidate venues (Points-Of-Interest or POIs) for each request provided. In total, we were provided with:</p><p>• A complete collection of 1,235,844 POIs, together with their titles, corresponding URLs, and a web-crawl of the URLs.</p><p>• A set of 442 requests made by 238 users. TREC eventually evaluated 58 requests made by 27 users.</p><p>Each provided request contained information about the user and the context in which the request was made. Specifically, each request was associated with:</p><p>• A user profile containing:</p><p>-The user's age and gender (both optional).</p><p>-A set of venues (either 30 or 60) that the user had rated at a scale of 0-4 (4=strongly interested, 3=interested, 2=neither interested or uninterested, 1=uninterested, 0=strongly uninterested) and also (optionally) assigned a set of tags from a controlled vocabulary (e.g. Bar-hopping, Desert, Live Music, etc.).<ref type="foot" coords="2,350.82,273.83,3.97,6.12" target="#foot_0">1</ref> </p><p>• A context containing:</p><p>-General location information about where the request was made (city, state, latitude and longitude).</p><p>-The type of trip (business, holiday, other).</p><p>-The intended duration of the trip (day trip, night out, weekend, longer).</p><p>-The type of group that the user is traveling with (alone, friends, family, other).</p><p>-The season in which the request was made (summer, winter, etc.).</p><p>• A set of candidates to re-rank, at the specified location of interest.</p><p>Taking all these under consideration, we were asked to re-rank the set of candidates to fit the user's preferences/profile and context. More information about the dataset and the Track's guidelines can be found online. <ref type="foot" coords="2,391.61,477.07,3.97,6.12" target="#foot_1">2</ref>We mainly focused on using the information from the users' preferences. First, we enriched the POI dataset with more information about each useful-forthe-experiments venue (i.e. all unique POIs in user-preferences and candidates) using both the TREC-provided web-crawl and the venue profiles we located in Foursquare<ref type="foot" coords="2,181.89,536.85,3.97,6.12" target="#foot_2">3</ref> and Yelp<ref type="foot" coords="2,229.44,536.85,3.97,6.12" target="#foot_3">4</ref> web services. We then built a suggestion model based on a Weighted kNN classifier, and another based on an adaptation of Rocchio's formula for relevance feedback, we call Rated Rocchio. Finally, we explored the use of the Borda Count voting system to combine the results of the two aforementioned models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset Enrichment</head><p>Firstly, we identified the venue IDs that are useful to the experiments, namely, the set of IDs that constitute the preferences of the users and the candidate suggestions for all requests. We then proceeded to collect data about this set of venues using both the provided URLs and searching for the corresponding profiles in the web services Yelp and Foursquare. The TREC-provided URLs correspond to either the official web-page of the venue or its profile in a related web service. For each case, we proceeded in a different way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">URLs</head><p>For participants' convenience, TREC provided a set of web-crawls relieving us from performing this task ourselves. Instead, we processed the provided dataset, searching for the set of useful URLs we identified earlier. We then collected the meta-tags description, title and keywords for each POI. We ignored any other text present for two reasons. First, we found that a significant percentage of home-pages consist of some type of multimedia (thus also setting these venues at a disadvantageous point), and second, we found that home-pages that do contain text, contain an inherently uninformative content such as slogans, directions, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Web-services</head><p>A significant percentage of the provided URLs correspond to a web-service profile, most of which are Yelp or Foursquare profiles. Some URLs are TripAdvisor links but the service explicitly prohibits the systematic data collection for research purposes, and the rest of the URLs which point to other similar services constitute a very small percentage so we treat them as simple URLs as explained above.</p><p>We attempted to match all venues to both Yelp and Foursquare profiles. Specifically:</p><p>• For URLs that corresponded to Yelp profiles, we used the exact coordinates provided by the web service's profile and the name of the venue, and submitted this information to Foursquare's search API to match the venue to a Foursquare profile. We then worked in the reverse way to match venues with Foursquare URLs to Yelp profiles.</p><p>• For the rest of the URLs, we attempted to match the venue to both Yelp and Foursquare profiles via the web services' search APIs using the name of the venue and the general location information.</p><p>For the venues that we successfully matched to any or both web-services' profiles, we collected and saved the complete profiles for later use.</p><p>Our final dataset of Foursquare and Yelp profiles is summarized in Table <ref type="table" coords="3,469.73,648.81,3.87,8.74" target="#tab_0">1</ref>. We see that for more than 85% of the useful-to-the-experiments POIs (i.e. the union of POIs in all user profiles and candidate POIs in all requests), we obtained at least a Yelp or Foursquare profile; that is a very good coverage. In the future, we will make these extra data available online, to accompany and enrich the TREC data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Suggestion Processing</head><p>In order to provide suggestions for each request, we revisited and revised the two methods we first used in DUTH's TREC 2013 participation <ref type="bibr" coords="4,413.27,362.20,9.96,8.74" target="#b1">[2]</ref>, which were also used in <ref type="bibr" coords="4,191.30,374.15,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="4,206.20,374.15,7.01,8.74" target="#b3">4]</ref>, while we also attempted to combine their results using a voting system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Suggestion Model based on a Weighted kNN Classifier</head><p>Based on the kNN Classification method <ref type="bibr" coords="4,311.07,432.39,9.96,8.74" target="#b0">[1]</ref>, we attempted to predict a user rating for each candidate venue based on the actual user ratings of the k neighbors semantically nearest to the candidate. We then ranked the candidate venues based on the predicted rating. Specifically, we proceeded as following:</p><p>• Indexing: We generated an index per user, containing the data collected for each user preference. This data consisted of a bag-of-words containing the metadata (description, title, keywords), the Foursquare profile data (description, title, tags, phrases), and the Yelp profile data (description, category, title). For indexing, we used Indri version 2.2<ref type="foot" coords="4,413.83,534.42,3.97,6.12" target="#foot_4">5</ref> with default settings, except that we enabled the Krovetz stemmer, as suggested in <ref type="bibr" coords="4,464.20,547.95,9.96,8.74" target="#b2">[3]</ref>.</p><p>• Query Generation: We generated a query for each candidate venue which consisted of a bag-of-words containing the meta-data, the Foursquare profile, and the Yelp profile data, as used in the index.</p><p>• Rating Candidates: For each candidate venue, we submitted its generated query to the corresponding user index which returned the list of the user's preferences scored for their semantical similarity to the candidate venue.</p><p>To compute a rating p for the candidate, we used a weighted average of the nearest neighbor ratings as proposed in <ref type="bibr" coords="5,350.79,139.92,9.96,8.74" target="#b1">[2]</ref>:</p><formula xml:id="formula_0" coords="5,283.30,158.86,189.94,29.74">p = k i=1 s i R i k i=1 s i , (<label>1</label></formula><formula xml:id="formula_1" coords="5,473.24,168.70,4.24,8.74">)</formula><p>where k is the number of the examined nearest neighbors, s i is the tf-idf similarity value between the candidate and its i-th neighbor (we enabled Indri's tf-idf retrieval model for that), and R i is the user's rating for the i-th neighbor.</p><p>We used k = 7, since for some candidates Indri returned no more than 7 similar venues. This is because Indri does not return listings that bare no similarity (i.e. no common keyword) to the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Suggestion Model based on a Rated Rocchio Method</head><p>In this model, we attempted to create a personalized query per user. This query consisted of terms weighted via a custom version of Rocchio's formula usually employed for relevance feedback <ref type="bibr" coords="5,276.65,345.48,9.96,8.74" target="#b5">[6]</ref>. The model is summarized in the following steps.</p><p>• Indexing: We generated an index per context, containing all available POIs in the area of interest (i.e. the general location where the request was made). As in the kNN-based model, these data consisted of a bag-of-words containing the metadata (description, title, keywords), the Foursquare profile data (description, title, tags, phrases), and the Yelp profile data (description, category, title).</p><p>• Query Generation:</p><formula xml:id="formula_2" coords="5,245.30,455.40,119.95,9.65">Let D i =&lt; d i,1 , d i,2 , ..., d i,M</formula><p>, &gt; be a training example (a rated venue), where M is the number of terms in the training set of all preferences of a user. The d i,j is the weight of j term in the D i .</p><p>The term weight was calculated as d i,j = 1 + log(f i,j ) where f i,j is the frequency of appearance of the j-th term in D i . We used a tf-only weight as the inclusion of an idf term did not improve our preliminary experiments with last year's dataset. We then used the following formula to calculate the personalized user query Q, where R j is the set of vectors (training examples) of the user's preferences rated as j:</p><formula xml:id="formula_3" coords="5,248.46,570.64,229.02,32.48">Q = 4 j=0 (j -2) 1 |R j | D∈Rj D .<label>(2)</label></formula><p>In this way, we regarded ratings of j = 2 as neutral, 3 and 4 as positive, and 0 and 1 as negative.</p><p>Finally, we generated the query by creating a list of the terms together with their calculated weights. For example, using the Indri Query Language notation:</p><p>#weight(1.5 restaurant 1.2 steak ... 0.2 good)</p><p>We also applied a cut-off threshold of 20 highest weighted terms for each query to achieve a more precise query.</p><p>• Rating Candidates: We submitted the generated query to the context index, that is, the index containing all the POIs in a context that the user is interested in. From the returned list of venues, ranked by similarity to the query (here, we used Indri's default Language Model for retrieval/ranking), we filtered out the venues that did not belong to the set of candidates of the request, and suggested the rest in their ranked order.</p><p>Note that while the Weighted kNN method of Section 3.1 predicts ratings, the Rated Rocchio method as defined here does not predict ratings but ranks the candidates-there are no guarantees that even the first ranked POI would correspond to a higher-than-neutral rating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Suggestion Fusion via Borda Count Election</head><p>We investigated the use of election methods as a means to fuse the results produced by the two separate suggestion methods. We employed the Borda Count election method, which originates from social theory in voting and has been previously used as a fusion method of separate retrieval systems, e.g. <ref type="bibr" coords="6,464.20,387.32,9.96,8.74" target="#b4">[5]</ref>.</p><p>For that purpose, we used the lists of suggestions as ballots and each model as a voter. Specifically, for each suggestion of rank r, we assigned a score p = n -r where n is the number of candidates. Although other formulas such as p = n -(r -1), and p = 1 r are frequently used, p = n -r provided the best results in preliminary experiments with last year's dataset. We then added the p scores of each candidate for both methods and re-ranked the list of suggestions based on the final score.</p><p>We can summarize the function of the Borda Count method in the following formula:</p><formula xml:id="formula_4" coords="6,265.69,513.91,211.79,30.32">s i = m j=1 (n -r i,j ) ,<label>(3)</label></formula><p>where s i is the final score of candidate i, m is the number of combined voters (two in our case), r i,j is the rank of candidate i according the j voter/method, and n is the number of candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments &amp; Results</head><p>In this section, we present the experimental evaluation of our proposed methods. First, we present the official evaluation measures, and then our official runs and results. Some extra runs are also presented, since we found a bug in our system which influenced two out of our three officially submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Measures</head><p>The suggestions were evaluated according to the NDCG@5, P@5, and MRR measures, macro-averaged over all the requests. The definitions of these measures are:</p><p>• Normalized Discounted Cumulative Gain at 5 (NDCG@5): A measure that employs a gain factor to take into account the position in which each relevant suggestion was returned, as well as its relevance score (rating) according to the qrel file (ground truth).</p><p>• Precision at Rank 5 (P@5): The fraction of relevant suggestions within the top-5 results.</p><p>• Mean Reciprocal Rank (MRR): Average, inverse rank of the first relevant suggestion.</p><p>Note that all the above measures are sensitive to early precision, due to the narrow rank cut-offs (5) in NDCG and Precision, and the rank position of only the first relevant result in MRR. Consequently, they model a user with a mobile device, with potentially limited screen space where only five suggestions can be displayed simultaneously (NDCG@5, P@5), or with available time to visit only single POI (MRR).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Official Runs &amp; Extras</head><p>In this year's Track, 13 teams participated in Phase 2 experiments with a total of 30 runs (including our team). We submitted three official runs:</p><p>• DUTH knn, with the Weighted kNN method described in Section 3.1.</p><p>• DUTH rocchio, with the Rated Rocchio method described in Section 3.2.</p><p>• DUTH bcf, a fusion of the two previous runs with the Borda Count method described in Section 3.3.</p><p>Unfortunately, we later found a bug in DUTH knn which hurt its effectiveness; this also invalidates the fused DUTH bcf run. The results of our official runs, as well as the de-bugged ones (with an asterisk), are presented in Table <ref type="table" coords="7,436.88,543.31,3.87,8.74" target="#tab_1">2</ref>.</p><p>Our best performing official run is DUTH rocchio, which came up as the 1st best run in NDCG@5 of all participants, while it also achieved the 2nd and 4th positions in MRR and P@5, respectively. Unfortunately for us, the bug we found in the official DUTH knn run was proved too costly; the de-bugged DUTH knn* run surpasses DUTH rocchio in NDCG@5, so it would have been another 1st best. Also, its P@5 and MRR are considerably better, now comparable to DUTH rocchio.</p><p>The official DUTH bcf is invalid, since it is based on the buggy DUTH knn; consequently, we see no value commenting on it. Concerning the de-bugged DUTH bcf*, which fuses DUTH knn* and DUTH rocchio, it achieves a slightly worse performance in NDCG@5 and P@5 than both runs it combines, and worse in MRR. Thus, ranked-based fusion does not seem like a promising method in this dataset and measures, although our preliminary experiments with last year's data had shown otherwise.</p><p>The TREC official evaluation provided also some additional measures beyond the above three. In these additional measures, DUTH rocchio achieved the 1st best NDCG, 5th MAP, 4th bpref, 2nd P@10, and 3nd Rprec. Thus, the Rated Rocchio method can also be effective under a variety of use cases beyond earlyprecision mobile applications. Ironically, the invalid DUTH bcf achieved the 1st best MAP, bpref, and Rprec, which may indicate that ranked-based fusion may be more suitable for use cases not too sensitive to early precision. We have not yet evaluated the de-bugged DUTH knn* and valid DUTH bcf* using the additional measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this year's Track, we further developed and built upon the two methods we first presented in Contextual Suggestion 2013. Specifically, we fine-tuned them using last year's data (2015), and made an attempt to combine/fuse their results as a third method.</p><p>The first method was based on a Weighted kNN classifier. We issued a candidate venue as a query to an index of all user's rated venues, and predicted its rating by taking the weighted average of the ratings for the 7 most semantically similar rated venues, weighted by their tf-idf score. The second method was based on a Rocchio-like method we developed for multi-graded relevance environments, called Rated Rocchio. Using a user's rated venues as training examples, we built a personalized query for the user. Specifically, we built a centroid per rating and combined/added those using their corresponding ratings as contributing factors, offset by 2 so as ratings 0 and 1 provided negative feedback with -2 and -1 weights, respectively. Rating 2 was eliminated as neutral. The Rated Rocchio query was run on an index with the POIs in the area of interest in order to rank the candidates. The third method fused the results produced by the first two suggestion methods. We employed the Borda Count election method, which originates from social theory in voting. In summary, we are satisfied again with our performance this year, since our runs achieved top or near-top TREC effectiveness.</p><p>In the future, further improvements could come from the following. In the Weighted kNN method, the tf-idf score, which is suitable for ranking, may not be the best choice as a semantical distance measure/weight-in this respect, other mechanisms could be explored. In the Rated Rocchio method, we assumed a linear behavior in user's ratings, e.g. a rating of 4 is taken as two times more relevant than a rating of 3, etc. Furthermore, we discarded all neutral ratings of 2, which may have helped with Recall. In this respect, alternative centroid weightings could be investigated. Combining several methods also merits further investigation. A procedure which selectively combines only good individual performances but falls back to an individual run otherwise, seems to make sense. Here, the query performance prediction literature may be of use. Additionally, note that the main reason we resorted to a ranked-based fusion method is that the Rated Rocchio method does not predict ratings (in contrast to Weighted kNN) but ranks the candidates. In this respect, ways that map the Rocchio retrieval scores to ratings could be investigated, so as to enable the use of ratingbased fusion by e.g. taking the average rating across systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,188.19,134.88,234.87,99.60"><head>Table 1 :</head><label>1</label><figDesc>Web-service collection statistics</figDesc><table coords="4,188.19,150.62,234.87,83.86"><row><cell>Unique Candidates</cell><cell>18,752</cell></row><row><cell>Unique Preferences</cell><cell>60</cell></row><row><cell>Union of the above</cell><cell>18,808</cell></row><row><cell>Yelp profiles</cell><cell>15,295</cell></row><row><cell>Foursquare profiles</cell><cell>15,741</cell></row><row><cell cols="2">POIs with at least 1 of 2 web service profiles 16,680</cell></row><row><cell>POIs with both profiles</cell><cell>10,100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,133.77,135.43,343.71,113.77"><head>Table 2 :</head><label>2</label><figDesc>Effectiveness of official and de-bugged (with an asterisk *) runs, and official run rank positions (in parentheses) within the 30 submitted runs by all participants. Best effectiveness per measure is in bold typeface.</figDesc><table coords="8,192.69,177.02,225.86,72.18"><row><cell></cell><cell cols="2">NDCG@5 P@5</cell><cell>MRR</cell></row><row><cell>DUTH knn</cell><cell>.3116 (7)</cell><cell>.4345 (8)</cell><cell>.6131 (10)</cell></row><row><cell>DUTH knn*</cell><cell>.3388</cell><cell>.4690</cell><cell>.6697</cell></row><row><cell cols="2">DUTH rocchio .3306 (1)</cell><cell cols="2">.4724 (4) .6801 (2)</cell></row><row><cell>DUTH bcf</cell><cell>.3259 (4)</cell><cell cols="2">.4724 (4) .5971 (13)</cell></row><row><cell>DUTH bcf*</cell><cell>.3232</cell><cell>.4552</cell><cell>.6165</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,149.01,603.23,328.47,7.21"><p>The full set of possible tags: https://github.com/akdh/csttools/blob/master/tags.csv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,149.01,613.31,216.44,6.64"><p>https://sites.google.com/site/treccontext/trec-2016</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,149.01,622.82,76.21,6.64"><p>www.foursquare.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,149.01,632.32,50.81,6.64"><p>www.yelp.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,149.01,655.13,84.68,6.64"><p>www.lemurproject.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank <rs type="person">Hadi Hashemi, PhD</rs> candidate at <rs type="institution">University of Amsterdam (UvA)</rs> and organizer of the Track, for providing some more insight and statistics on the dataset.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,149.27,149.78,328.22,8.74;10,149.27,161.74,328.21,8.74;10,149.27,173.69,328.21,9.02;10,149.27,186.36,180.60,8.30" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,213.77,149.78,263.71,8.74;10,149.27,161.74,57.03,8.74">An introduction to kernel and nearest-neighbor nonparametric regression</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Altman</surname></persName>
		</author>
		<idno type="DOI">10.1080/00031305.1992.10475879</idno>
		<ptr target="http://www.tandfonline.com/doi/abs/10.1080/00031305.1992.10475879" />
	</analytic>
	<monogr>
		<title level="j" coord="10,218.45,161.74,115.97,8.74">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.27,205.57,328.21,8.74;10,149.27,217.53,328.22,8.74;10,149.27,229.48,41.87,8.74;10,225.31,229.48,252.17,8.74;10,149.27,241.44,328.21,8.74;10,149.27,253.39,328.21,8.74;10,149.27,265.35,328.21,9.02;10,149.27,278.02,123.56,8.30" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,201.18,217.53,217.89,8.74">DUTH at TREC 2013 contextual suggestion track</title>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Drosatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giorgos</forename><surname>Stamatelatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pavlos</forename><forename type="middle">S</forename><surname>Efraimidis</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec22/papers/DUTH-context.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,440.01,217.53,37.48,8.74;10,149.27,229.48,41.87,8.74;10,225.31,229.48,252.17,8.74;10,149.27,241.44,17.52,8.74;10,185.00,253.39,292.48,8.74;10,149.27,265.35,84.10,8.74">Special Publication 500-302. National Institute of Standards and Technology (NIST)</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-11-19">2013. November 19-22, 2013. 2013</date>
		</imprint>
	</monogr>
	<note>Ellen M. Voorhees, Proceedings of The Twenty-Second Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="10,149.27,297.23,328.21,8.74;10,149.27,309.18,328.21,8.74;10,149.27,321.14,328.21,8.74;10,149.27,333.09,328.21,8.74;10,149.27,345.05,304.99,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,400.92,297.23,76.55,8.74;10,149.27,309.18,328.21,8.74;10,149.27,321.14,174.79,8.74">Giorgos Stamatelatos, and Ioannis N. Athanasiadis. Pythia: A privacy-enhanced personalized contextual suggestion system for tourism</title>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Drosatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pavlos</forename><forename type="middle">S</forename><surname>Efraimidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<idno type="DOI">10.1109/COMPSAC.2015.88</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,344.11,321.14,133.37,8.74;10,149.27,333.09,253.47,8.74">39th Annual IEEE Computers, Software and Applications Conference (COMPSAC 2015)</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015-07">july 2015</date>
			<biblScope unit="page" from="822" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.27,364.97,328.21,8.74;10,149.27,376.93,328.22,8.74;10,149.27,388.88,328.22,8.74;10,149.27,400.84,328.21,9.02;10,149.27,413.51,165.41,8.30" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,400.92,364.97,76.55,8.74;10,149.27,376.93,328.22,8.74;10,149.27,388.88,116.92,8.74">Giorgos Stamatelatos, and Ioannis N. Athanasiadis. A privacy-by-design contextual suggestion system for tourism</title>
		<author>
			<persName coords=""><forename type="first">Pavlos</forename><forename type="middle">S</forename><surname>Efraimidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Drosatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<idno type="DOI">10.3390/jsan5020010</idno>
		<ptr target="http://www.mdpi.com/2224-2708/5/2/10" />
	</analytic>
	<monogr>
		<title level="j" coord="10,278.35,388.88,184.74,8.74">Journal of Sensor and Actuator Networks</title>
		<idno type="ISSN">2224-2708</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.27,432.72,328.22,8.74;10,149.27,444.68,328.21,8.74;10,149.27,456.63,328.21,9.02;10,149.27,469.30,81.22,8.30" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,285.48,432.72,192.01,8.74;10,149.27,444.68,115.97,8.74">Automatic ranking of information retrieval systems using data fusion</title>
		<author>
			<persName coords=""><forename type="first">Rabia</forename><surname>Nuray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fazli</forename><surname>Can</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2005.03.023</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ipm.2005.03.023" />
	</analytic>
	<monogr>
		<title level="j" coord="10,279.45,444.68,95.84,8.74">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="595" to="614" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.27,488.51,328.21,8.74;10,149.27,500.47,328.21,8.74;10,149.27,512.42,301.60,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,217.51,488.51,190.69,8.74;10,182.65,500.47,294.83,8.74;10,149.27,512.42,41.98,8.74">The Smart retrieval system -experiments in automatic document processing</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
		<editor>G. Salton</editor>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>Prentice-Hall</publisher>
			<biblScope unit="page" from="313" to="323" />
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>Relevance feedback in information retrieval</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
