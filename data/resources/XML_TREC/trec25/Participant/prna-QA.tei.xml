<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,92.12,80.99,427.76,12.90;1,215.94,98.92,180.13,12.90">Open Domain Real-Time Question Answering Based on Semantic and Syntactic Question Similarity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,163.29,133.70,57.93,10.75"><forename type="first">Vivek</forename><surname>Datla</surname></persName>
							<email>vivek.datla@philips.com</email>
						</author>
						<author>
							<persName coords="1,229.36,133.70,76.46,10.75"><forename type="first">Sadid</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
							<email>sadid.hasan@philips.com</email>
						</author>
						<author>
							<persName coords="1,314.73,133.70,41.75,10.75"><forename type="first">Joey</forename><surname>Liu</surname></persName>
							<email>joey.liu@philips.com</email>
						</author>
						<author>
							<persName coords="1,364.70,133.70,87.00,10.75;1,451.70,132.17,1.41,6.99"><forename type="first">Yassine</forename><surname>Benajiba</surname></persName>
							<email>yassine@lukilabs.com</email>
						</author>
						<author>
							<persName coords="1,149.71,147.76,53.28,10.75;1,202.99,146.22,1.88,6.99"><forename type="first">Kathy</forename><surname>Lee</surname></persName>
							<email>kathy.lee1@philips.com</email>
						</author>
						<author>
							<persName coords="1,208.97,147.76,71.88,10.75"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
							<email>ashequl.qadir@philips.com</email>
						</author>
						<author>
							<persName coords="1,289.25,147.76,86.02,10.75;1,375.26,146.22,1.88,6.99"><forename type="first">Aaditya</forename><surname>Prakash</surname></persName>
							<email>aaditya.prakash@philips.com</email>
						</author>
						<author>
							<persName coords="1,381.24,147.76,81.06,10.75"><forename type="first">Oladimeji</forename><surname>Farri</surname></persName>
							<email>dimeji.farri@philips.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
								<orgName type="institution">Philips Research North America</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Brandeis University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,92.12,80.99,427.76,12.90;1,215.94,98.92,180.13,12.90">Open Domain Real-Time Question Answering Based on Semantic and Syntactic Question Similarity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F9ECEB0DFF633F68D01E9BAC1590F53A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our system and results of our participation in the Live-QA track of the Text Retrieval Conference(TREC) 2016. The Live-QA task involves real user questions, extracted from the stream of most recent questions submitted to the Yahoo Answers (YA) site, which have not yet been answered by humans. These questions are pushed to the participants via a socket connection, and the systems are needed to provide an answer which is less than 1000 characters length in less than 60 seconds. The answers given by the system are evaluated by human experts in terms of accuracy, readability, and preciseness. Our strategy for answering the questions include question decomposition, question relatedness identification, and answer generation. Evaluation results demonstrate that our system performed close to the average scores in question answering task. In the question focus generation task our system ranked fourth.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering(QA) is a well-studied research area in natural language processing (NLP). Since the early days of artificial intelligence in the 60's, researchers have been fascinated with answering natural language questions <ref type="bibr" coords="1,182.33,633.67,88.04,9.46" target="#b5">(Kwok et al., 2001)</ref>. Initial efforts for QA systems primarily focused on domain-specific expert systems. The domain specific factoid questions have been answered well and the systems have achieved similar performance as human experts, where as answering open-domain questions in natural language is still an open challenge. The open-domain real life questions amplify the challenge many folds as natural language is ambiguous, and constructing the answer requires an elaborate understanding of the question being asked, expert domain knowledge, as well as language generation models.</p><p>The open domain real-time question answering task increases the complexity even further as one has to address the issues as mentioned previously and in addition to producing human-like response in less than 60 seconds. The properties of humanlike response include structured grammatically correct sentences, which answer the question to the satisfaction of a human evaluator. Additionally, the answers need to be concise as they are restricted to a 1000 character limit. This is our first participation in the live-QA track and in the following sections we describe our model, results, and experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>The LiveQA track was first started in TREC 2015. The competition runs for 24 hrs during which questions being posted on Yahoo Answers site<ref type="foot" coords="1,511.90,608.39,3.99,6.91" target="#foot_0">1</ref> (after some preliminary cleaning) by the real users are posted on to the participating team's servers registered for the competition. The questions are selected from 7 distinct topics shown in Table <ref type="table" coords="1,477.81,664.63,5.45,9.46" target="#tab_0">1</ref> As Table <ref type="table" coords="1,365.01,678.57,5.45,9.46" target="#tab_0">1</ref> indicates, the topics are fairly different and have several sub-categories. The category of the question being asked is selected from a predefined list by the person asking the question. The user selects only one category for the question being asked.</p><p>The category of the question may overlap with other categories. For example "Why does Labor back this kind of behavior?" is identified by the user as in the topic category "Travel" and to the sub-topic category "Australia". However, from the question, we can understand that it belongs to the category "Politics and Government". Sometimes the questions belong to multiple categories and the user based on his interest/convenience picks only one topic.</p><p>The questions being asked in Yahoo Answers are mostly subjective and describe a human experience which are often personal and relevant to the topic. The ability for a machine to replicate human understanding of the topic(s) and biases in a subjective question is a challenge. Also, the fact that these questions can represent multiple events and potential causal relationships further complicates the Live-QA task. For example, the question "My fiance hates my dog. He ignores him and always complains. He started calling him names. Should I be worried?" posted in the Pets topic shows three parties (me, my fiance, and my dog) with a mix of interpersonal relationships represented as emotions and actions ("hates my dog", "ignores him", "always complains", "started calling him names", and "should I be worried"). The answers given by people for this question include suggestions on personal relationships, pet behaviors, and further questions like "Do you want to stay with the person who is cruel to animals?".</p><p>As the answers given to the question indicate that there is no one correct answer and answers provided by users indicate the different focus picked while answering the questions. To answer such questions one needs not only to know about the sentiment and the focus of the question, but also needs to know the interactions between various facets of the problem. Given these open-domain questions, the big challenge that we need to address is how to create huge domain knowledge to answer such questions.</p><p>In addition to the main question answering task, a new pilot subtask was introduced this year for identifying the focus of the question. The goal of the task is to test whether the system understood the question. The task focuses on identifying focus words of the question that indicate the most important phrases in the question. The focus words can be generated from the question title and the body of the question. We used a localized keyword extraction methodology to identify the important words in the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TREC 2016 Competition</head><p>During the TREC competition, a question is pushed every minute by the track organizers onto the server registered with the competition. The question posted on our server is a JSON object with fields shown in Table <ref type="table" coords="2,356.47,394.85,4.09,9.46">2</ref>. The category, sub-category and the question-title fields always have entries, while the other fields can sometimes be empty.</p><p>The questions from the topics shown in Table <ref type="table" coords="2,313.20,449.53,5.45,9.46" target="#tab_0">1</ref> sometimes relate to current events, and hence it becomes particularly challenging to address the questions on personal experiences related to current events, pandemics, or on going family issues like marriage, divorce, etc.</p><p>If, after 60 seconds there is no response provided from the server to the competition, then the response is assessed as negative, and would be penalized. The systems are ranked on two metrics 1) success: ratio of the aggregated scores of the answers to the total questions asked in the competition and 2) precision: ratio of the aggregated scores of the answers to the total number of the questions answered by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">System</head><p>Our LiveQA system comprises of the following modules:</p><p>• Question cleaning • Question Similarity based on latent semantic analysis (LSA) <ref type="bibr" coords="3,162.29,429.65,75.29,9.46" target="#b6">(Landauer, 2007)</ref> • Semantic Similarity based on WordNet (Fellbaum, 1998)</p><p>• Answer selection module</p><p>• Pushing the answer response</p><p>Figure <ref type="figure" coords="3,115.47,536.76,5.45,9.46">1</ref> shows the flow of the several modules used in our system. For question cleaning, we focused on the removal of noisy characters (emoticons, repeated characters, html tags etc.), correction of spellings, and sentence segmentation. The language used in the questions is informal, as expected in social media <ref type="bibr" coords="3,182.69,618.05,112.47,9.46">(Twitter, Facebook, etc.)</ref>. We used similar steps in cleaning the body and title of the question. After cleaning the question, we perform question decomposition by focusing on keyword extraction, sentiment analysis and focus word generation. Keyword extraction is done using a localized term frequency inverse document frequency(TF-IDF) based model <ref type="bibr" coords="3,216.35,712.90,77.75,9.46" target="#b9">(Rose et al., 2010)</ref>.</p><p>The keywords indicate the important words and the sentiment is identified with respect to these keywords. These keywords are used as our focus words while constructing the answer for the question. For identifying the sentiment we used Vader sentiment analysis tool (Hutto and Gilbert, 2014).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">LSA-based Question Similarity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Building LSA Space</head><p>Latent Semantic Analysis (LSA) is a statistical language algorithm that captures semantic relations by mapping initially meaningless words into a continuous high dimensional semantic space <ref type="bibr" coords="3,492.88,468.19,47.12,9.46;3,313.20,481.74,23.48,9.46" target="#b6">(Landauer, 2007)</ref>. More specifically, a first-order process associates stimuli (words) and the contexts they occur in (documents). Stimuli are paired based on their contiguity or co-occurrence in the document. These local associations are next transformed by means of Singular Value Decomposition (SVD) into a small number of dimensions (typically 300) yielding more unified knowledge representations by removing noise <ref type="bibr" coords="3,313.20,590.14,108.17,9.46" target="#b3">(Hutchinson et al., 2012;</ref><ref type="bibr" coords="3,424.10,590.14,76.50,9.46" target="#b0">Datla et al., 2012)</ref>.</p><p>For instance, if there are m terms in n documents, a matrix of A = (F ij ×G(j)×L(i, j)) m×n , was obtained. The value of f ij is a function of the integer that represents the number of times term i appears in document j : L(i; j) is a local weighting of term i in document j; and G(j) is the global weighting for term j. The matrix of A has, however, lots of redundant information. Singular Value Decomposition (SVD) reduces this noise by decomposing the matrix A into three matrices A = U ΣV ' ; where U is a m × m and V is a n × n square matrix, with Σ being an m × n diagonal matrix with singular values on the diagonal <ref type="bibr" coords="4,141.99,116.50,106.81,9.46" target="#b3">(Hutchinson et al., 2012)</ref>.</p><p>By removing dimensions corresponding to smaller singular values, the representation of each word is reduced as a smaller vector with each word now becomes a weighted vector on 300 dimensions, with only the most important dimensions that correspond to larger singular values being kept <ref type="bibr" coords="4,94.96,212.27,75.27,9.46" target="#b6">(Landauer, 2007)</ref>. The semantic relationship between characters can then be estimated by taking the cosine distance measure between the two feature vectors.</p><p>We built an LSA space using the Yahoo 4.4 million question answer corpus<ref type="foot" coords="4,200.65,278.90,3.99,6.91" target="#foot_1">2</ref> . We selected all the question titles from the corpus and cleaned them using stop-word removal and stemming. Each question represents a document in our model. Using gensim <ref type="bibr" coords="4,90.80,332.76,118.53,11.84" target="#b8">( Řehůřek and Sojka, 2010)</ref> we built the semantic space with 300 dimensions. We retrieve the semantically similar questions to a given question with the trained LSA model. We then set a threshold of 0.70 for the cosine similarity score such that all answers above this score are candidates. We selected this threshold value after experimentation and expert opinions.</p><p>The output of the LSA module is a ranked list of candidate questions which are semantically similar. Despite being semantically similar, the list of candidate questions may not be related in terms of polarity and subject-object relationship as LSA is a bag-ofwords model. In order to extract semantically and syntactically similar questions we filtered the candidate questions further based on similar keywords and word order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Keyword Extraction</head><p>Localized keyword extraction based on pre-trained term frequency inverse document frequency(TF-IDF) scores helped identify the important words in the question. These words are used to get the word overlap score and re-rank the questions obtained from the LSA model. We used the Rake software for keyword extraction <ref type="bibr" coords="4,174.15,679.03,78.32,9.46" target="#b9">(Rose et al., 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">WordNet based Semantic and Syntactic Similarity</head><p>We used the method proposed by <ref type="bibr" coords="4,467.95,108.52,72.05,9.46" target="#b7">(Li et al., 2006)</ref> to augment the similarity measure between the questions. The method is heavily dependent on the wordorder and uses WordNet to identify the strength of the relationship among the words. The words belonging to the same synset (synonymous words conveying the same sense) have a higher weight than the words belonging to different synsets. Also, if the words have a hypernymy or hyponymy relationships, then the weights are lower compared to the synonyms.</p><p>By computing the similarity of the words based on their meaning and maintaining the word order helps us augment the macro similarity obtained from the LSA module, with the micro similarity obtained in this module. The output of this module is a score indicating if the two questions are similar. This method is computationally expensive as it is sensitive to the word order as well as length of the questions. We used a caching mechanism to improve the computational speed of the algorithm. The scores of the word pairs are calculated only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Answer Generation</head><p>After getting the final ranked list of the questions from the previous step, we extract the answers from the Yahoo Answers corpus associated with each candidate question. We rank the answers based on the keyword overlap and alignment with the focus of the question. Since the answers cannot be longer than 1000 characters long, we select the sentences that are most representative of the focus and weighted keywords extracted from the question title and body. We pick the best answer for the highest ranked candidate question and greatest alignment with the question keyword and topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Knowledge Graph-based Question Answering</head><p>There are many questions(50%) that could be answered by our pipeline. The 4.4 million question answer corpus from Yahoo wouldn't account for all possible questions that can be asked. To answer the questions that our system found difficult to address, we used the Google knowledge graph <ref type="bibr" coords="5,100.89,75.86,66.32,9.46" target="#b2">(Google, 2016)</ref>. We used the keywords extracted from the question title and body as queries for the knowledge graph. We constructed the final answer based on the top three results retrieved from the knowledge graph application program interface (API).</p><p>If the knowledge graph could not give any results we responded by using a random response from a bag of 15 responses we prepared in advance. An example of such response "This is a profound question. Sorry I cannot answer this difficult question at this time". This approach hurt us badly as the answers given were not accurate and sometimes completely irrelevant. From a deeper analysis, we see that the questions being asked are subjective and answers expected are opinionated answers. Having a system that works for factoid based questions adapted to opinionated and subjective questions was not much helpful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>Results from our system were evaluated based on the scoring system shown below:</p><p>• avgScore(0-3): The average score over all questions. This is the main score used to rank the participating system runs.</p><p>• succ@i+: the number of questions with score i or above (i ∈ {2..4}) divided by the total number of questions. For example, succ@2+ measures the percent of questions with at least fair grade answered by the run.</p><p>• prec@i+: the number of questions with score i or above (i ∈ {2..4}) divided by number of questions answered by the system. This measures the precision of the run, designed not to penalize non-answered questions.</p><p>Our system attempted to answer 899 out of 1088 questions, which is much higher than the average number of questions answered. Our servers timed out on 117 questions for which 60 secs was not enough to construct an appropriate answer. Results from our system were comparable to the mean metrics of all systems in the competition as shown in Tables <ref type="table" coords="5,102.94,712.90,4.32,9.46" target="#tab_1">3</ref><ref type="table" coords="5,107.26,712.90,4.32,9.46" target="#tab_2">4</ref><ref type="table" coords="5,111.57,712.90,4.32,9.46">5</ref>.</p><p>We implemented two methods to answer the live questions. 1) Generate an answer from responses to similar questions asked in Yahoo question answer corpus; 2) The questions for which there was no answer in our LSA space and were answered using Google knowledge graph API to retrieve appropriate web links. Tables <ref type="table" coords="5,390.85,157.15,4.85,9.46" target="#tab_3">6</ref><ref type="table" coords="5,400.55,157.15,4.85,9.46" target="#tab_4">7</ref>show the breakup of the results after splitting the questions answered into the two methods explained above. The questions for which we answered confidently have prec@2+, prec@3+, and prec@4+ scores higher than the average scores as shown in Table <ref type="table" coords="5,393.86,224.90,4.09,9.46" target="#tab_4">7</ref>.</p><p>Our results show that leveraging knowledge graph to answer subjective questions adversely affected the performance of the system. Analysis of the questions answered based on the semantic similarity with questions in Yahoo corpus performed much better than the questions answered by the knowledge graph. This can be attributed to the systematic approach we adopted in identifying the questions which are similar not only semantically but also in focus and sentiment with respect to the main focus of the question. We computed the similarity by respecting the word-order, which was computationally very expensive for longer questions <ref type="bibr" coords="5,497.50,405.16,42.50,9.46;5,313.20,418.71,23.48,9.46" target="#b7">(Li et al., 2006)</ref>. We overcame this limitation by implementing a caching scheme where we greedily cached all the word-pairs for which we calculated the similarity score, and retrieved them efficiently when needed. This helped us to answer the questions in the prescribed time limit of 60 secs.</p><p>For the pilot task of identifying the focus of the question we submitted the output of the keyword extraction module discussed in the section 4.2. We used both question title and body to generate the keywords and since we used these words as the anchor words for identifying the similar questions, the same keywords are our focus words. Table <ref type="table" coords="5,504.55,585.42,5.45,9.46" target="#tab_5">8</ref> shows that our team ranked second among all the competing teams. Overall, our run ranked 4 th in the task.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The performance of our open domain real-time question answering system is close to the Avg. runs of the competition. We answered 899 questions out of 1088 questions posted by moderators. By analyzing the questions that we answered using our pipeline we performed close to the avg. scores of all the runs. By analyzing the answers given based on the method used, our semantic similarity method performed much better than the average across all the participants. The knowledge graph approach affected the scores adversely. In the pilot task of identifying the focus of the question being asked our system is the 4 th ranked system among all the participant systems.</p><p>In future, we would change our strategy to reduce the dependency on a knowledge graph and use more curated knowledge sources.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,245.52,265.41,120.97,8.64;3,72.00,72.00,467.99,176.39"><head>Figure</head><label></label><figDesc>Figure 1: System Architecture</figDesc><graphic coords="3,72.00,72.00,467.99,176.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,84.65,701.34,2.99,5.18;6,88.14,703.20,210.66,7.77;6,72.00,714.16,102.70,7.77"><head>3</head><label></label><figDesc>default response is based on Google Knowledge Graph API and random excuse response</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,84.07,82.27,202.66,117.12"><head>Table 1 :</head><label>1</label><figDesc>Topic categories and no. of sub categories</figDesc><table coords="2,113.21,94.69,144.38,104.70"><row><cell>Topic</cell><cell>#sub topics</cell></row><row><cell>Arts &amp; Humanities</cell><cell>10</cell></row><row><cell>Beauty &amp; Style</cell><cell>5</cell></row><row><cell>Health</cell><cell>10</cell></row><row><cell>Home &amp; Garden</cell><cell>6</cell></row><row><cell>Pets</cell><cell>8</cell></row><row><cell>Sports</cell><cell>30</cell></row><row><cell>Travel</cell><cell>27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,347.59,652.44,158.02,49.38"><head>Table 3 :</head><label>3</label><figDesc>Questions attempted by PRNA</figDesc><table coords="5,377.57,664.86,98.06,36.96"><row><cell>Run</cell><cell>#Answers</cell></row><row><cell>prna</cell><cell>899</cell></row><row><cell cols="2">avg score 771.0385</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,77.98,82.27,220.32,125.48"><head>Table 4 :</head><label>4</label><figDesc>Avg and succ scores</figDesc><table coords="6,77.98,94.69,220.32,113.07"><row><cell>Run avg</cell><cell cols="3">succ@2+ succ@3+ succ@4+</cell></row><row><cell cols="2">prna 0.4276 0.2749</cell><cell>0.1084</cell><cell>0.0443</cell></row><row><cell cols="2">avg 0.5766 0.3042</cell><cell>0.1898</cell><cell>0.0856</cell></row><row><cell></cell><cell cols="2">Table 5: Precision scores</cell><cell></cell></row><row><cell>Run</cell><cell cols="3">prec@2+ prec@3+ prec@4+</cell></row><row><cell>prna</cell><cell>0.3103</cell><cell>0.1224</cell><cell>0.0501</cell></row><row><cell cols="2">avg score 0.3919</cell><cell>0.2429</cell><cell>0.108</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,72.00,236.51,226.80,61.33"><head>Table 6 :</head><label>6</label><figDesc>Break up of Answered and avg. score according to answer strategy</figDesc><table coords="6,86.77,260.88,197.26,36.96"><row><cell>Run</cell><cell cols="2">#Answers avgScore(0-3)</cell></row><row><cell>prna(default 3 )</cell><cell>459</cell><cell>0.216</cell></row><row><cell cols="2">prna(lsa based) 439</cell><cell>0.763</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,72.00,327.27,230.66,61.33"><head>Table 7 :</head><label>7</label><figDesc>Break up of prec@{2-4} according to answer strategy</figDesc><table coords="6,77.98,351.64,224.68,36.96"><row><cell>Run</cell><cell cols="3">prec@2+ prec@3+ prec@4+</cell></row><row><cell>prna(default 3 )</cell><cell>0.310</cell><cell>0.122</cell><cell>0.05</cell></row><row><cell cols="2">prna(lsa based) 0.42</cell><cell>0.246</cell><cell>0.188</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,343.52,82.27,166.17,158.17"><head>Table 8 :</head><label>8</label><figDesc>Focus generation task results</figDesc><table coords="6,343.52,94.69,166.17,145.75"><row><cell>Run</cell><cell>Meteor Score</cell></row><row><cell>baseline: title+body</cell><cell>0.260</cell></row><row><cell>baseline: title</cell><cell>0.212</cell></row><row><cell>NUDT NUDT681</cell><cell>0.177</cell></row><row><cell>NUDT NUDT681 1</cell><cell>0.167</cell></row><row><cell>NUDT NUDT681 3</cell><cell>0.136</cell></row><row><cell>prna</cell><cell>0.116</cell></row><row><cell>ECNU ECNU</cell><cell>0.089</cell></row><row><cell>DFKI dfkiqa</cell><cell>0.065</cell></row><row><cell cols="2">NUDT NUDTMDP1 0.050</cell></row><row><cell cols="2">NUDT NUDTMDP2 0.048</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,329.34,714.16,162.22,7.77"><p>Yahoo Answers -https://answers.yahoo.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,88.14,703.20,210.66,7.77;4,72.00,714.16,106.45,7.77"><p>L6 -Yahoo! Answers Comprehensive Questions and Answers version 1.0 (multi-part)</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,313.20,282.37,226.80,8.64;6,324.11,294.33,215.89,8.64;6,324.11,306.11,215.89,8.81;6,324.11,318.07,215.89,8.58;6,324.11,330.03,198.86,8.81" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,324.11,294.33,215.89,8.64;6,324.11,306.28,128.19,8.64">Capturing disease-symptom relations using higherorder co-occurrence algorithms</title>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">King-Ip</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Louwerse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,480.77,306.11,59.23,8.58;6,324.11,318.07,215.89,8.58;6,324.11,330.03,103.13,8.58">Bioinformatics and Biomedicine Workshops (BIBMW), 2012 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="816" to="821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,342.23,226.80,8.64;6,324.11,354.02,215.89,8.81;6,324.11,366.14,45.11,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,431.23,342.23,108.77,8.64;6,324.11,354.19,42.09,8.64">A semantic network of english verbs</title>
		<author>
			<persName coords=""><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,374.70,354.02,161.03,8.58">WordNet: An electronic lexical database</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="153" to="178" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,378.18,179.03,8.64" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,374.61,378.18,113.95,8.64">Google knowledge graph api</title>
		<author>
			<persName coords=""><surname>Google</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,390.22,226.80,8.64;6,324.11,402.01,215.89,8.81;6,324.11,413.96,215.89,8.58;6,324.11,425.92,210.64,8.81" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,526.16,390.22,13.84,8.64;6,324.11,402.18,148.26,8.64">Social networks are encoded in language</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,490.65,402.01,49.35,8.58;6,324.11,413.96,215.89,8.58;6,324.11,425.92,47.62,8.58">Proceedings of the 34th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 34th Annual Conference of the Cognitive Science Society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,438.13,226.80,8.64;6,324.11,450.08,215.89,8.64;6,324.11,461.87,215.89,8.81;6,324.11,473.82,152.46,8.58" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,483.23,438.13,56.77,8.64;6,324.11,450.08,215.89,8.64;6,324.11,462.04,67.17,8.64">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,410.72,461.87,129.27,8.58;6,324.11,473.82,147.80,8.58">Eighth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,486.03,226.80,8.64;6,324.11,497.82,215.89,8.81;6,324.11,509.77,212.62,8.81" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,324.11,497.99,149.40,8.64">Scaling question answering to the web</title>
		<author>
			<persName coords=""><forename type="first">Cody</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,481.82,497.82,58.18,8.58;6,324.11,509.77,144.14,8.58">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="242" to="262" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,521.81,226.80,8.81;6,324.11,533.77,215.89,8.81;6,324.11,545.89,203.36,8.64" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,415.83,521.81,124.17,8.58;6,324.11,533.77,32.23,8.58">Handbook of Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
		<respStmt>
			<orgName>University of Colorado Institute of Cognitive Science Series</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,557.93,226.80,8.64;6,324.11,569.88,215.89,8.64;6,324.11,581.84,215.89,8.64;6,324.11,593.63,215.89,8.58;6,324.11,605.58,89.38,8.81" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,482.55,569.88,57.44,8.64;6,324.11,581.84,212.54,8.64">Sentence similarity based on semantic nets and corpus statistics</title>
		<author>
			<persName coords=""><forename type="first">Yuhua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Mclean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zuhair</forename><forename type="middle">A</forename><surname>Bandar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keeley</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Crockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,324.11,593.63,215.89,8.58;6,324.11,605.58,11.42,8.58">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1138" to="1150" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,615.62,226.80,10.81;6,324.11,629.74,215.89,8.64;6,324.11,641.53,215.89,8.58;6,324.11,653.49,215.89,8.81;6,324.11,665.61,215.89,8.64;6,324.11,678.50,128.02,7.01" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,472.51,617.79,67.49,8.64;6,324.11,629.74,193.62,8.64">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">Radim</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Petr</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m" coord="6,324.11,641.53,215.89,8.58;6,324.11,653.49,132.90,8.58">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05">2010. May</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,689.60,226.80,8.64;6,324.11,701.56,215.89,8.64;6,324.11,713.35,134.74,8.81" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,324.11,701.56,215.89,8.64;6,324.11,713.51,26.81,8.64">Automatic Keyword Extraction from Individual Documents</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,358.97,713.35,45.33,8.58">Text Mining</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
