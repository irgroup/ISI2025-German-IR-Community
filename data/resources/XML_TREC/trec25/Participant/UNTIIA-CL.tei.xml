<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,110.93,76.70,391.92,12.22">UNT MEDICAL INFORMATION RETRIEVAL AT TREC 2016</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,129.68,101.56,65.60,9.48"><forename type="first">Lokesh</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">College of Information Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">College of Engineering</orgName>
								<orgName type="laboratory">Intelligent Information Access Laboratory</orgName>
								<orgName type="institution">University of North Texas</orgName>
								<address>
									<postCode>76203</postCode>
									<settlement>Denton</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.89,101.56,68.67,9.48"><forename type="first">Jiangping</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Science</orgName>
								<orgName type="department" key="dep2">College of Information</orgName>
								<orgName type="institution">University of North Texas</orgName>
								<address>
									<postCode>76203</postCode>
									<settlement>Denton</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.63,101.56,65.59,9.48"><forename type="first">Ana</forename><surname>Cleveland</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Science</orgName>
								<orgName type="department" key="dep2">College of Information</orgName>
								<orgName type="institution">University of North Texas</orgName>
								<address>
									<postCode>76203</postCode>
									<settlement>Denton</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,419.31,101.56,61.35,9.48"><forename type="first">Jodi</forename><surname>Philbrick</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Information Science</orgName>
								<orgName type="department" key="dep2">College of Information</orgName>
								<orgName type="institution">University of North Texas</orgName>
								<address>
									<postCode>76203</postCode>
									<settlement>Denton</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,110.93,76.70,391.92,12.22">UNT MEDICAL INFORMATION RETRIEVAL AT TREC 2016</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EB74173F9096D491FF1FDF01061F0028</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Biomedical information retrieval</term>
					<term>clinical decision support</term>
					<term>open-source information retrieval platform</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides a description of a project to design and evaluate an information retrieval system for clinical decision support track. The target document collection for retrieval consisted of 1.25 million biomedical related documents taken from the Open Access Subset of PubMed Central. The topics provided by TREC for query construction consisted of 30 patient narrative cases, each of which includes a Note section, a Description section, and a Summary section. The PMCID, title, abstract, keywords, subheadings of article body, introduction and conclusion paragraphs were extracted from the documents. Terrier was used as the platform for indexing and retrieval. Several models, including the LemurTF_IDF weighting model with pseudo relevancy feedback, were applied to retrieve and rank relevant documents. Out of the five runs submitted, two runs were performed by merging the retrieval results of top five individual weighting models, and the remaining three runs were obtained through passing three types of queries constructed, manually and automatically, using the Note and the Summary sections. The automatic runs are observed to receive a better performance than the manual runs. The automatic run using the Note section for query construction performed better than other runs. Overall performance of the system is around the median when compared to all TREC 2016 CDS Track submissions .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>The growing reliance on biomedical information in a digital format for clinical decision-making is prompting research on novel methodologies for information retrieval. Text Retrieval Conference<ref type="foot" coords="1,499.19,568.98,3.48,6.11" target="#foot_0">1</ref> (TREC) Clinical Decision Support (CDS) track<ref type="foot" coords="1,245.03,582.66,3.48,6.11" target="#foot_1">2</ref> encourages and provides test collections for research in this area. The tasks in TREC CDS 2016 were more focused on retrieving results based on the Note section, which consisted of the History of Present Illness (HPI) of a patient, as it simulated a more realistic clinical decision-making scenario.</p><p>In this paper, we discuss our experimental design and methodologies implemented towards achieving our goal to develop a baseline medical information retrieval system. The target document collection for retrieval consisted of 1.25 million biomedical related articles taken from Open Access Subset of PubMed Central <ref type="bibr" coords="2,109.51,89.56,27.70,9.48">(PMC)</ref>. The topics provided by TREC for query construction consisted of 30 patient narrative cases which include a Note section (a note on the HPI of the patient); a Description section (a general description of the patient's problem); and a Summary section (a short summary of the patient's problem).</p><p>To retrieve relevant documents for the 30 topics, we developed an experimental system using an open source information retrieval (IR) platform Terrier v4.1 configured with pseudo relevancy feedback. We used the Note and Summary sections for query construction.</p><p>The remaining paper is organized as follows: Section 2 discusses the general structure of the document collection and the topics provided by TREC; Section 3 summarizes the literature from TREC CDS 2015 track; Section 4 presents the experimental design and the methodologies implemented; and Section 5 presents a description of the runs submitted and the evaluation results. The paper concludes with Sections 6 and 7, which include a discussion of our system performance, future research, and a summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE DOCUMENT COLLECTION AND THE TOPICS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Document Collection</head><p>The document collection for the task is the collection of biomedical related articles of various types, such as research articles, editorials, review articles, and meeting notes. Each article in the collection is an encoded xml file with a general hierarchical structure shown in Figure <ref type="figure" coords="2,384.82,377.80,4.41,9.48">1</ref>(a) and (b).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">REVIEW OF TREC 2015 TRACK METHODOLOGIES</head><p>The TREC CDS 2015 papers were reviewed to understand various methodologies implemented in developing biomedical information retrieval systems.</p><p>We observed that most systems had a document processing phase before indexing. In the majority of the methodologies, the title, abstract, and body of the article were extracted during the processing and passed on to indexing <ref type="bibr" coords="3,139.32,613.48,246.56,9.48" target="#b5">(Drosatos, Roumeliotis, Arampatzis, &amp; Kaldoudi, 2015;</ref><ref type="bibr" coords="3,388.70,613.48,84.79,9.48">Stöber, et al., 2015)</ref>. <ref type="bibr" coords="3,481.03,613.48,62.63,9.48;3,72.95,627.16,57.15,9.48" target="#b11">Song, He, Hu, &amp; He, 2015</ref> noted that an additional extraction of age, gender, captions of tables and figures and references of the article increase the performance of the system. In the document processing phase, some systems performed semantic type and synonyms annotations to the free text in the document using external knowledge sources such as Unified Medical Language System (UMLS) and Medical Subject Headings (MeSH) <ref type="bibr" coords="3,160.52,681.64,173.27,9.48" target="#b6">(Hu, Wu, Mei, &amp; Vydiswaran, 2015;</ref><ref type="bibr" coords="3,338.81,681.64,91.41,9.48">Stöber, et al., 2015)</ref>. Some other document processing techniques included applying language models such as SPUD language model <ref type="bibr" coords="3,491.81,695.32,49.16,9.48;4,72.95,75.88,23.64,9.48" target="#b2">(Cummins, 2015)</ref>, unigram and bigram models <ref type="bibr" coords="4,249.19,75.88,269.34,9.48" target="#b9">(Nikolentzos, Meladianos, Liakis, &amp; Vazirgiannis, 2015)</ref> and Himestra language model <ref type="bibr" coords="4,188.75,89.80,111.63,9.48" target="#b0">(Abacha &amp; Khelifi, 2015)</ref>.</p><p>For indexing and retrieval, it was observed that Apache Lucene, Indri, and Terrier were the most commonly used information retrieval (IR) platforms. By examining the retrieval configuration of 2015 TREC participants, BM25 and TF_IDF were noted to be the most commonly used weighting models. Whereas, some other models include TW-IDF, a retrieval model based on graph of words approach <ref type="bibr" coords="4,72.95,166.12,115.59,9.48" target="#b9">(Nikolentzos, et. al., 2015)</ref>, and Unigram query likelihood model <ref type="bibr" coords="4,361.96,166.12,142.47,9.48" target="#b14">(You, Zhou, Peng, &amp; Zhu, 2015)</ref>.</p><p>Some systems had implemented re-ranking mechanisms such as Learning-to-Rank <ref type="bibr" coords="4,457.55,187.48,83.34,9.48">(Hu, et. al., 2015;</ref><ref type="bibr" coords="4,72.95,201.16,186.53,9.48" target="#b7">Jiang, Guan, Su, Zhao, &amp; Yang, 2015;</ref><ref type="bibr" coords="4,265.22,201.16,92.16,9.48">Stöber et al., 2015;</ref><ref type="bibr" coords="4,363.12,201.16,84.51,9.48">Song, et.al., 2015)</ref>, ranking using cooccurrence network <ref type="bibr" coords="4,164.50,214.84,84.61,9.48">(Jiang, et.al., 2015)</ref>, time based re-ranking (D'hondt, <ref type="bibr" coords="4,405.46,214.84,135.41,9.48" target="#b4">Grau, &amp; Zweigenbaum, 2015)</ref> and CQT based re-ranking (D'hondt, <ref type="bibr" coords="4,249.45,228.28,137.40,9.48" target="#b4">Grau, &amp; Zweigenbaum, 2015)</ref>. Learning-to-rank is a machine learning application in ranking process. In this technique, a combination of multiple features, which are obtained from weighting models in case of query dependent systems (all systems developed to perform TREC CDS tasks), is used to minimize the loss function. An optimal loss function modeled after learning is used for ranking the relevant documents. The most popular used Learning-to-Rank machine learning algorithms were Support Vector Machines (SVM) <ref type="bibr" coords="4,304.88,296.68,87.03,9.48">(Jiang, et.al., 2015;</ref><ref type="bibr" coords="4,396.10,296.68,83.36,9.48">Song, et.al., 2015)</ref> and Random Forest algorithm <ref type="bibr" coords="4,148.73,310.60,82.29,9.48">(Song, et.al., 2015)</ref>.</p><p>Query construction and query expansion are two crucial functionalities of an IR system, which have a major impact on the system performance. These functionalities were implemented using various mathematical and intuitive approaches. Discriminative query model (DQM) <ref type="bibr" coords="4,411.10,359.32,77.69,9.48" target="#b2">(Cummins, 2015)</ref> is one such mathematical approach, which uses P´olya distribution for query modeling <ref type="bibr" coords="4,405.94,373.00,130.19,9.48" target="#b3">(Cummins, Paik, &amp; Lv, 2015)</ref>. The Summary section of the topics was used for query construction in most of the systems as this section contained relatively fewer and more precise terms in explaining the patient's health problem <ref type="bibr" coords="4,495.43,400.12,45.48,9.48;4,72.95,413.80,114.78,9.48">(Drosatos, Roumeliotis, et.al., 2015;</ref><ref type="bibr" coords="4,192.34,413.80,167.54,9.48" target="#b6">Hu, Wu, Mei, &amp; Vydiswaran, 2015;</ref><ref type="bibr" coords="4,364.49,413.80,84.22,9.48">Jiang, et.al., 2015;</ref><ref type="bibr" coords="4,453.32,413.80,87.60,9.48;4,72.95,427.72,23.64,9.48">Palotti &amp; Hanbury, 2015)</ref>.</p><p>Query expansion is a technique that enhances the free-text in the query with the domain specific terminology. From the review, Pseudo Relevancy Feedback (PRF) was the most commonly implemented query expansion technique. Along with PRF, query expansion using UMLS and MeSH were also more likely implemented <ref type="bibr" coords="4,163.59,490.12,102.82,9.48">(Drosatos, et.al., 2015;</ref><ref type="bibr" coords="4,270.53,490.12,73.48,9.48">Hu, et.al., 2015;</ref><ref type="bibr" coords="4,348.14,490.12,83.27,9.48">Jiang, et.al., 2015;</ref><ref type="bibr" coords="4,435.53,490.12,77.62,9.48">You, et.al., 2015)</ref>. Few innovative expansion techniques observed were expanding the terms using search results from Wikipedia and Google <ref type="bibr" coords="4,127.32,517.48,103.51,9.48" target="#b8">(Jo, Seol, &amp; Lee, 2015;</ref><ref type="bibr" coords="4,233.94,517.48,79.24,9.48">Song, et.al., 2015)</ref>, ontology based query terms annotation <ref type="bibr" coords="4,496.35,517.48,44.44,9.48;4,72.95,531.40,74.35,9.48" target="#b1">(Audeh &amp; Beigbeder, 2015)</ref>, and personalized page rank technique <ref type="bibr" coords="4,323.14,531.40,112.52,9.48" target="#b15">(Zhang, He, &amp; Fan, 2015)</ref>.</p><p>The review of papers published by 2015 participants of TREC CDS track enabled us to achieve a good understanding of methodologies and specific tools and platforms used in the implementation of a medical information retrieval system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL DESIGN</head><p>Based on the literature review, we developed our experimental design as a four-stage model that follows the flow of a typical information retrieval system for performing the assigned task. Figure <ref type="figure" coords="4,478.21,658.60,5.40,9.48" target="#fig_1">3</ref> presents our experimental design along with its functional flow. As illustrated in Figure <ref type="figure" coords="4,412.55,672.28,4.10,9.48" target="#fig_1">3</ref>, our system contained four stages: document processing, indexing, query construction and retrieval and ranking. Each stage is further explained below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Document Processing</head><p>The document processing stage extracted the most informative sections of the document, which included PMCID, title, abstract, keywords, subheadings in body of the document, introduction, and conclusion.</p><p>The document collection consists of 1.25 million articles, which was an Open Access Subset of PubMed Central (PMC).</p><p>To extract the desired sections of the document, Python script with regular expressions was used. The extracted fields were organized into TREC format to make them compatible with the indexing platform.</p><p>Figure <ref type="figure" coords="5,104.43,395.56,5.40,9.48">4</ref> provides the structure of the TREC documents.</p><p>The major challenge in this stage was the diverse format and structures of the documents in the collection. These increased the complexity of the document processing program. For example, the document type 'Meeting Notes' does not have an abstract, introduction, or conclusion sections in most of them.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Indexing</head><p>Indexing is a process of parsing the data in document collection to indices so that retrieval can be performed. We used Terrier v4.1 IR platform for both indexing and retrieval. Terrier tokenizes the free text in the target document collection to index tokens and passes through a term pipeline, which removes stop words and performs stemming to the indexing terms. A predefined list of stop words and stemming algorithm were configured in Terrier properties to perform the term pipeline. The tokens obtained after the term pipeline were used to generate indices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Query Construction</head><p>Queries were constructed from the TREC CDS topics. In our experiment, we followed three approaches in constructing queries, which included:</p><p>• Note Automatic: The note section used for query construction was extracted using Python regular expressions. Irrelevant information like hospital admission is discarded. • Note Manual: The key phrases in the note section were identified manually by a medical domain expert for query construction. • Summary Automatic: The summary section used for query construction was extracted using Python regular expressions.</p><p>Three runs are performed using the queries constructed from the above approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Retrieval and Ranking</head><p>In this stage, documents relevant to a given query were retrieved from the collection using a weighting model,which scored the degree of relevancy. For this task, we performed five retrieval runs; three out of which were obtained by passing the queries constructed using the three approaches described above. Two of the retrieval runs were obtained by merging the retrieval results from individual weighting models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Query Expansion using Pseudo Relevance Feedback</head><p>Pseudo relevance feedback is an automatic relevance feedback technique where the system assumes the top 'n' documents retrieved in the initial run to be highly relevant and fetches the terms in those documents for query expansion. Relevance feedback has been shown to improve retrieval performance.</p><p>In our system, query expansion with pseudo relevancy feedback was applied to all the runs using Bose-Einstein model (Bo1) in Terrier with configuration of 20 terms in each of the top 100 documents retrieved in the initial run for expanding the queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Merging from Different Models</head><p>We evaluated the performance of individual weighting models available in Terrier using TREC 2015 relevance judgment results (see Section 4.5) and found that a weighing model's performance was high with respect to a particular measure and comparatively low for remaining measures. Intuitively, it might increase the overall performance of the system if retrieval results from the top performing weighting models were merged in an appropriate way. Therefore, we conducted two runs by passing the Note automatic and Summary automatic queries to five different weighting models and merged their individual results. Merging the individual results was performed using a merging technique called the Shadow Document method <ref type="bibr" coords="6,163.09,701.08,108.13,9.48" target="#b13">(Wu &amp; Crestani, 2004)</ref>. This method was one of the merging algorithms that optimally performs overall better. The five weighting models used were LemurTF_IDF, DLH, IFB2, PL2, BM25. the scores obtained from the weighting models were normalized and made comparable.</p><p>After normalization and comparison of two or more results, the algorithm below was applied to obtain the global score for each retrieved document. <ref type="bibr" coords="7,441.95,189.80,92.15,8.64" target="#b13">(Wu &amp; Crestani, 2004)</ref> Where, 𝒌: A coefficient,which lies between 0 and 1. In our case k=0.5 then the global score of 𝒅 was calculated using the above formula.</p><formula xml:id="formula_0" coords="7,187.83,143.67,238.18,43.39">𝒈𝒍𝒐𝒃𝒂𝒍_𝒔𝒄𝒐𝒓𝒆 𝒅 = 𝒔 𝒊 (𝒅) + 𝒌 * (𝒏 -𝒎) 𝒎 𝒔 𝒊 (𝒅) 𝒎 𝒊!! 𝒎 𝒊!!</formula><formula xml:id="formula_1" coords="7,72.95,254.15,6.72,9.60">𝒅</formula><p>In a nutshell, if a document was present in more than one result, then all the scores of that document were added up to get the global score. In the case that the document was present in only one result, then the document's score was added to the coefficient value. The resulting merged result file was sorted in descending order of their scores and re-ranked 1-1000. The documents with rank greater than 1000 were discarded from the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Retrieval Model Evaluation with TREC 2015 Test Collection</head><p>To select a weighting model out of 16 models available in Terrier, we used TREC 2015 CDS track retrieval test collection to evaluate the individual weighting models performance with respect to the measures, infAP, infNDCG, R-Prec, and P@10. Since the document collection used for TREC 2016 was an expanded version of the one for TREC 2015, we assumed that the document collection would have a minimal effect of the performance evaluation. The evaluation results of these 16 weighting models with and without PRF are shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Five runs were submitted to TREC 2016. An overview of the runs is presented below:</p><p>i.</p><p>Note Automatic Run (Run ID: UNTIIANA): This run used the Note Automatic queries and a result file with the top 1000 relevant document IDs in the order of most relevant to least relevant was obtained. ii.</p><p>Note Manual Run (Run ID: UNTIIANM): This run used the Note Manual queries and a result file with the top 1000 relevant document IDs in the order of most relevant to least relevant was obtained. iii.</p><p>Summary Automatic Run (Run ID: UNTIIASA): This run was designed to use the Summary Automatic queries and the evaluation results were observed to be similar to the Note Automatic run. This run was performed with a configuration error, which invalidated the results. This would be further investigated in the future. iv.</p><p>Results Merge Run with Note Automatic (Run ID: UNTIIANMERGE): This run was generated by merging the results of the top five highest performing weighting models using the queries constructed from the Note section automatically. v.</p><p>Results Merge Run with Summary Automatic (Run ID: UNTIIASMERGE): This run was generated by merging the results of the top five highest performing weighting models using the queries constructed from the Summary section automatically.</p><p>The description and evaluation results of four runs are presented in Table <ref type="table" coords="9,397.96,466.60,5.40,9.48" target="#tab_5">2</ref> and<ref type="table" coords="9,424.84,466.60,31.89,9.48" target="#tab_6">Table 3</ref>   We present three of our runs as compared with the maximum, minimum, and median values of infNDCG for each topic in Figure <ref type="figure" coords="10,178.95,89.80,5.40,9.48" target="#fig_4">5</ref> (a), (b), and (c). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSION AND FUTURE RESEARCH</head><p>We successfully designed and implemented a baseline medical information retrieval system that could retrieve relevant medical documents for three types of topics within a short period of time. Processing was a complex automation challenge. At this stage, we extracted the PMCID, title, abstract, keywords, subheadings of body of the document, introduction and conclusion sections from the diverse document collection. For indexing and retrieval, Terrier IR platform was chosen, as it is one of the commonly used IR platforms and was used by many of the TREC 2015 participants.</p><p>Out of five runs submitted, automatic runs were observed to have a better performance than the manual runs and the Note Automatic run had a better performance with an overall inferred NDCG(infNDCG) of 0.1554 and steadily performed above or around the median for most of the 30 queries.</p><p>The two automatic runs, Note Merge and Summary Merge, generated by merging the individual results obtained from five different models were expected to perform better than the other runs as the models selected for merging were the best performing models for TREC 2015 evaluation but observed to be inverse.</p><p>In order to improve our current system, we are going to investigate the reasons that the merging method did not work well. A literature review shall be conducted to understand the applications of Shadow Document method in information retrieval systems and its limitations. Also, we would like to understand systematically Terrier's weighting models and their scoring functions using TREC 2016 relevance judgment results.</p><p>We would like to explore the following strategies: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,75.20,639.23,185.15,7.80;2,291.89,639.23,209.14,7.80;2,89.27,413.78,183.84,215.76"><head>Figure</head><label></label><figDesc>Figure 1 (a): General Structure of PMC Articles Figure 1(b): General XML Attributes of PMC Articles</figDesc><graphic coords="2,89.27,413.78,183.84,215.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,159.63,250.77,162.32,8.87"><head>Figure. 3 :</head><label>3</label><figDesc>Figure. 3: Information Retrieval System</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,79.67,254.15,229.08,9.60;7,72.95,275.99,5.42,9.60;7,78.47,280.07,2.94,7.04;7,81.90,276.04,209.47,9.48;7,75.70,298.07,151.98,9.60;7,72.95,319.91,265.49,9.60;7,72.95,341.51,345.38,9.60;7,418.43,345.59,2.94,7.04;7,421.86,341.51,114.60,9.60"><head>:</head><label></label><figDesc>The documents retrieved by any one of the models 𝒔 𝒊 : The score of the document in the ith result file 𝒏: Number of result files available 𝒎: Number of result files in which the document d occurred If the document 𝒅 occurred in 𝒎 result files out of 𝒏 result files with a score 𝒔 𝒊 (𝒅) (where 1≤ 𝒊 ≤ 𝒎 ≤ 𝒏)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,187.43,349.87,265.83,8.87;10,134.45,376.35,344.75,188.08"><head>Figure</head><label></label><figDesc>Figure 5(a): Box Plot of infNDCG for Note Automatic (UNTIIANA)</figDesc><graphic coords="10,134.45,376.35,344.75,188.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,172.79,349.62,267.99,8.87;11,146.45,72.95,320.98,255.65"><head>Figure 5 (</head><label>5</label><figDesc>Figure 5(c): Box Plot of infNDCG for Note Merge (UNTIIANMERG)</figDesc><graphic coords="11,146.45,72.95,320.98,255.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,310.88,417.28,195.68,197.65"><head>Figure 2. Sample "Diagnosis" Topic from TREC CDS 2016 Case Narratives</head><label></label><figDesc>TREC provided 30 case narratives of the patient's health problem, each containing three elements: note, description and summary. The topics of the case narratives were divided into three types: diagnosis, tests, and treatment, with 10 case narratives each. A sample topic of type diagnosis is show in Figure2.</figDesc><table coords="2,310.88,417.28,195.68,197.65"><row><cell>2.2</cell><cell>Topics</cell></row><row><cell cols="2">&lt;topic number="1" type="diagnosis"&gt;</cell></row><row><cell>&lt;note&gt;</cell><cell></cell></row><row><cell cols="3">78 M w/ pmh of CABG in early [**Month (only) 3**] at [**Hospital6 4406**] (transferred to nursing</cell></row><row><cell cols="3">home for rehab on [**12-8**] after several falls out of bed.) He was then readmitted to [**Hospital6</cell></row><row><cell cols="3">1749**] on [**3120-12-11**] after developing acute pulmonary edema/CHF/unresponsiveness?. There</cell></row><row><cell cols="3">was a question whether he had a small MI; he reportedly had a small NQWMI. He improved with diuresis</cell></row><row><cell cols="3">and was not intubated. . Yesterday, he was noted to have a melanotic stool earlier this evening and then</cell></row><row><cell cols="3">approximately 9 loose BM w/ some melena and some frank blood just prior to transfer, unclear quantity.</cell></row><row><cell>&lt;/note&gt;</cell><cell></cell></row><row><cell cols="2">&lt;description&gt;</cell></row><row><cell cols="3">78 M transferred to nursing home for rehab after CABG. Reportedly readmitted with a small NQWMI.</cell></row><row><cell cols="3">Yesterday, he was noted to have a melanotic stool and then today he had approximately 9 loose BM w/</cell></row><row><cell cols="3">some melena and some frank blood just prior to transfer, unclear quantity.</cell></row><row><cell cols="2">&lt;/description&gt;</cell></row><row><cell cols="2">&lt;summary&gt;</cell></row><row><cell cols="3">&lt;article&gt; A 78 year old male presents with frequent stools and melena.</cell></row><row><cell cols="2">&lt;/summary&gt;</cell><cell>&lt;article-type&gt;…&lt;/article-type&gt; &lt;pmcid&gt;…&lt;/pmcid&gt;</cell></row><row><cell cols="2">&lt;/topic&gt;</cell><cell>&lt;article-title&gt;…&lt;/article-title&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;authors&gt;…&lt;/authors&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;affiliations&gt;…&lt;/affiliations&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;abstract&gt;…&lt;/abstract&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;subsections&gt;…&lt;/subsections&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;body&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;introduction&gt;…&lt;/introduction&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;other-sections&gt;…&lt;/other-sections&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;conclusion&gt;…&lt;/conclusion&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;/body&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;references&gt;…&lt;/references&gt;</cell></row><row><cell></cell><cell></cell><cell>&lt;/article&gt;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,209.20,565.24,138.33,9.48"><head></head><label></label><figDesc>Table 1(a) and (b) respectively. It was observed that LemurTF_IDF weighting model performed consistently better for all the four</figDesc><table coords="8,115.91,119.80,381.90,546.36"><row><cell>Model</cell><cell>InfAP</cell><cell>infNDCG</cell><cell>R-Prec</cell><cell>P@10</cell></row><row><cell>LGD</cell><cell>0.0766</cell><cell>0.1546</cell><cell>0.0328</cell><cell>0.19</cell></row><row><cell>Hiemstra_LM</cell><cell>0.0854</cell><cell>0.1729</cell><cell>0.0396</cell><cell>0.2</cell></row><row><cell>BM25</cell><cell>0.0875</cell><cell>0.1766</cell><cell>0.0412</cell><cell>0.2067</cell></row><row><cell>DFRee</cell><cell>0.0773</cell><cell>0.1516</cell><cell>0.0329</cell><cell>0.2</cell></row><row><cell>BB2</cell><cell>0.0876</cell><cell>0.1802</cell><cell>0.0422</cell><cell>0.2133</cell></row><row><cell>InL2</cell><cell>0.0864</cell><cell>0.1708</cell><cell>0.0393</cell><cell>0.21</cell></row><row><cell>IFB2</cell><cell>0.0932</cell><cell>0.1871</cell><cell>0.0448</cell><cell>0.2033</cell></row><row><cell>PL2</cell><cell>0.0868</cell><cell>0.1785</cell><cell>0.0434</cell><cell>0.2267</cell></row><row><cell>DLH</cell><cell>0.0893</cell><cell>0.1814</cell><cell>0.0437</cell><cell>0.2267</cell></row><row><cell>DFR_BM25</cell><cell>0.0875</cell><cell>0.1766</cell><cell>0.0412</cell><cell>0.2067</cell></row><row><cell>TF_IDF</cell><cell>0.0865</cell><cell>0.1718</cell><cell>0.0399</cell><cell>0.2133</cell></row><row><cell>In_expB2</cell><cell>0.091</cell><cell>0.1859</cell><cell>0.0441</cell><cell>0.2067</cell></row><row><cell>DPH</cell><cell>0.0814</cell><cell>0.1623</cell><cell>0.0367</cell><cell>0.2133</cell></row><row><cell>DLH13</cell><cell>0.082</cell><cell>0.1649</cell><cell>0.0382</cell><cell>0.1967</cell></row><row><cell>LemurTF_IDF</cell><cell>0.0996</cell><cell>0.1889</cell><cell>0.0464</cell><cell>0.22</cell></row><row><cell>In_expC2</cell><cell>0.0944</cell><cell>0.1879</cell><cell>0.0455</cell><cell>0.2233</cell></row><row><cell>Model</cell><cell>InfAP</cell><cell>infNDCG</cell><cell>R-Prec</cell><cell>P@10</cell></row><row><cell>LGD</cell><cell>0.0464</cell><cell>0.187</cell><cell>0.1007</cell><cell>0.2067</cell></row><row><cell>Hiemstra_LM</cell><cell>0.0524</cell><cell>0.2133</cell><cell>0.1017</cell><cell>0.16</cell></row><row><cell>BM25</cell><cell>0.0599</cell><cell>0.2204</cell><cell>0.1103</cell><cell>0.2367</cell></row><row><cell>DFRee</cell><cell>0.0499</cell><cell>0.1942</cell><cell>0.0978</cell><cell>0.2267</cell></row><row><cell>BB2</cell><cell>0.0619</cell><cell>0.2241</cell><cell>0.1127</cell><cell>0.2233</cell></row><row><cell>InL2</cell><cell>0.0584</cell><cell>0.2152</cell><cell>0.1097</cell><cell>0.24</cell></row><row><cell>IFB2</cell><cell>0.0648</cell><cell>0.2297</cell><cell>0.1171</cell><cell>0.2233</cell></row><row><cell>PL2</cell><cell>0.0578</cell><cell>0.2077</cell><cell>0.1046</cell><cell>0.2467</cell></row><row><cell>DLH</cell><cell>0.0595</cell><cell>0.2175</cell><cell>0.1118</cell><cell>0.25</cell></row><row><cell>DFR_BM25</cell><cell>0.0583</cell><cell>0.2161</cell><cell>0.109</cell><cell>0.2333</cell></row><row><cell>TF_IDF</cell><cell>0.0583</cell><cell>0.2135</cell><cell>0.1094</cell><cell>0.2467</cell></row><row><cell>In_expB2</cell><cell>0.0638</cell><cell>0.2282</cell><cell>0.1161</cell><cell>0.2233</cell></row><row><cell>DPH</cell><cell>0.0517</cell><cell>0.1983</cell><cell>0.0994</cell><cell>0.2333</cell></row><row><cell>DLH13</cell><cell>0.0567</cell><cell>0.206</cell><cell>0.1068</cell><cell>0.2367</cell></row><row><cell>LemurTF_IDF</cell><cell>0.0643</cell><cell>0.2369</cell><cell>0.1149</cell><cell>0.1933</cell></row><row><cell>In_expC2</cell><cell>0.0647</cell><cell>0.2259</cell><cell>0.1183</cell><cell>0.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,188.35,381.62,265.90,305.37"><head>Table 1 (a): Evaluation Results of Weighting Models Without PRF Table 1(b): Evaluation Results of Weighting Models With PRF measures</head><label>1</label><figDesc>in case of queries without PRF (Table 1(a)), and the same model performed better with respect to infNDCG in case of queries with PRF (Table1(b)). Based on this observation, the LemurTF_IDF model was chosen for three out of our five runs.From the evaluation Table 1(b), it was observed that different models performed better with four different measures. Based on this observation, individual results of all the top performing models with respect to four measures were merged to obtain merged results.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,72.95,466.60,467.82,209.88"><head>. Run ID Topic Section Query Construction Weighting Model</head><label></label><figDesc></figDesc><table coords="9,72.95,514.36,467.82,162.12"><row><cell>UNTIIANA</cell><cell>Note</cell><cell>Automatic</cell><cell>LemurTF_IDF</cell><cell></cell></row><row><cell>UNTIIANM</cell><cell>Note</cell><cell>Manual</cell><cell>LemurTF_IDF</cell><cell></cell></row><row><cell>UNTIIANMERG</cell><cell>Note</cell><cell>Automatic</cell><cell cols="2">LemurTF_IDF+DLH+IFB2+PL2+BM25</cell></row><row><cell>UNTIIASMERG</cell><cell>Summary</cell><cell>Automatic</cell><cell cols="2">LemurTF_IDF+DLH+IFB2+PL2+BM25</cell></row><row><cell>Run ID</cell><cell>infAP</cell><cell>infNDCG</cell><cell>R-Prec</cell><cell>P@10</cell></row><row><cell>UNTIIANA</cell><cell>0.0153</cell><cell>0.1554</cell><cell>0.0951</cell><cell>0.2267</cell></row><row><cell>UNTIIANM</cell><cell>0.0144</cell><cell>0.1405</cell><cell>0.0880</cell><cell>0.1933</cell></row><row><cell>UNTIIANMERG</cell><cell>0.0132</cell><cell>0.1481</cell><cell>0.0819</cell><cell>0.2133</cell></row><row><cell>UNTIIASMERG</cell><cell>0.0113</cell><cell>0.1414</cell><cell>0.0841</cell><cell>0.1933</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,185.47,575.02,195.73,8.87"><head>Table 2 : Description of Runs Submitted to TREC</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,178.07,694.87,224.30,8.87"><head>Table 3 : Evaluation Results of Runs Submitted to TREC</head><label>3</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,79.20,698.68,81.85,9.48"><p>http://trec.nist.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,79.20,711.16,108.07,9.48;1,72.95,708.66,3.48,6.11;1,79.20,711.16,108.07,9.48"><p>http://www.trec-cds.org/ 2 http://www.trec-cds.org/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Query expansion using external knowledge sources: From the literature it was observed that both healthcare specific knowledge sources like UMLS, MeSH; and generic knowledge sources like Google, Wikipedia search results were used for enhancing the free-text with medical terminology. In our future research we would like to investigate the impact of these knowledge sources on the performance of an IR system.</p><p>Learning-to-Rank: Learning-to-rank is a machine learning application in ranking process. In our research, we would like to understand the feasibility of various 'Learning-to-Rank' models and the time and code complexities introduced into the system by those models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">SUMMARY</head><p>In this paper, we presented our approaches in performing the tasks required by TREC CDS 2016. We used a target document collection for retrieval consisting of 1.25 million biomedical related documents taken from the Open Access Subset of PubMed Central (PMC). In document processing we used regular expressions to extract the article tile, PMCID, abstract, keywords, subheadings of the document, introduction and conclusion paragraphs from the documents. Indexing and retrieval were performed by Terrier v4.1. We also experimented to merge individual results obtained by different weighting models and generated a new result. From the evaluation results received from TREC, the overall performance of our IR system is around the median when compared to all submissions of TREC 2016 CDS Track.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,72.95,418.60,442.87,9.48;12,90.95,432.28,396.82,9.48;12,90.95,445.72,412.97,9.48;12,90.95,459.40,348.49,9.48" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,235.49,418.60,280.33,9.48;12,90.95,432.28,170.70,9.48">LIST at TREC 2015 Clinical Decision Support Track: Question analysis and unsupervised result fusion</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khelifi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,430.07,432.28,57.70,9.48;12,90.95,445.72,412.97,9.48;12,90.95,459.40,257.52,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.95,473.08,442.95,9.48;12,90.95,486.76,448.08,9.48;12,90.95,500.44,412.38,9.48;12,90.95,514.12,83.37,9.48" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,235.47,473.08,239.03,9.48">EMSE at TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Audeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beigbeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,215.60,486.76,323.43,9.48;12,90.95,500.44,407.52,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.95,527.80,456.97,9.48;12,90.95,541.48,440.15,9.48;12,90.95,555.16,436.82,9.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,168.89,527.80,249.74,9.48">Clinical decision support with the SPUD language model</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,145.95,541.48,385.16,9.48;12,90.95,555.16,345.80,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.95,568.60,424.59,9.48;12,90.95,582.28,368.70,9.48" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,265.15,568.60,232.40,9.48;12,90.95,582.28,90.08,9.48">A Pólya urn document language model for improved information retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cummins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,187.78,582.28,221.26,9.48">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.95,595.96,451.16,9.48;12,90.95,609.64,445.99,9.48;12,90.95,623.32,412.97,9.48;12,90.95,637.00,348.54,9.48" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,299.38,595.96,224.74,9.48;12,90.95,609.64,219.48,9.48">Laval University at TREC Dynamic Domain 2015: Combination of techniques for subtopics coverage</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,479.24,609.64,57.70,9.48;12,90.95,623.32,412.97,9.48;12,90.95,637.00,257.52,9.48">TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Twenty-Fourth Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="12,72.95,650.68,445.91,9.48;12,90.95,664.36,444.75,9.48;12,90.95,677.80,441.63,9.48;12,90.95,691.48,207.33,9.48" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,384.51,650.68,134.35,9.48;12,90.95,664.36,103.09,9.48">DUTH at TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Drosatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roumeliotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kaldoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,362.85,664.36,172.85,9.48;12,90.95,677.80,441.63,9.48;12,90.95,691.48,116.35,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.95,75.88,428.84,9.48;13,90.95,89.56,446.84,9.48;13,90.95,103.24,417.24,9.48;13,90.95,116.92,436.82,9.48" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,327.14,75.88,174.65,9.48;13,90.95,89.56,312.99,9.48">Learning from medical summaries: The University of Michigan at TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">V</forename><surname>Vydiswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,123.03,103.24,385.16,9.48;13,90.95,116.92,345.80,9.48">TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Twenty-Fourth Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="13,72.95,130.60,464.66,9.48;13,90.95,144.04,417.56,9.48;13,90.95,157.72,409.60,9.48;13,90.95,171.40,184.47,9.48" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,318.30,130.60,219.32,9.48;13,90.95,144.04,23.63,9.48">HIT-WI at TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,283.41,144.04,225.11,9.48;13,90.95,157.72,409.60,9.48;13,90.95,171.40,93.47,9.48">TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Twenty-Fourth Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="13,72.95,185.08,446.58,9.48;13,90.95,198.76,419.41,9.48;13,90.95,212.44,409.59,9.48;13,90.95,226.12,139.55,9.48" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,262.69,185.08,240.27,9.48">CBNU at TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">H</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Seol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,240.35,198.76,270.01,9.48;13,90.95,212.44,409.59,9.48;13,90.95,226.12,48.55,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.95,239.80,455.18,9.48;13,90.95,253.24,444.75,9.48;13,90.95,266.92,441.63,9.48;13,90.95,280.60,207.33,9.48" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,391.30,239.80,136.84,9.48;13,90.95,253.24,103.09,9.48">AUEB at TREC 2015: Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Nikolentzos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Meladianos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Liakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vazirgiannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,362.85,253.24,172.85,9.48;13,90.95,266.92,441.63,9.48;13,90.95,280.60,116.35,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.95,294.28,425.87,9.48;13,90.95,307.96,448.08,9.48;13,90.95,321.64,412.38,9.48;13,90.95,335.32,83.37,9.48" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,223.28,294.28,234.01,9.48">TUW@ TREC Clinical Decision Support Track 2015</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,215.60,307.96,323.43,9.48;13,90.95,321.64,407.52,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.95,349.00,434.34,9.48;13,90.95,362.44,433.12,9.48;13,90.95,376.12,447.76,9.48;13,90.95,389.80,239.50,9.48" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,263.61,349.00,243.68,9.48;13,90.95,362.44,127.66,9.48">ECNU at 2015 CDS Track: Two re-ranking methods in medical information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,389.41,362.44,134.67,9.48;13,90.95,376.12,447.76,9.48;13,90.95,389.80,148.48,9.48">TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Twenty-Fourth Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="13,72.95,403.48,448.87,9.48;13,90.95,417.16,444.12,9.48;13,90.95,430.84,441.63,9.48;13,90.95,444.52,207.33,9.48" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,347.70,403.48,174.13,9.48;13,90.95,417.16,102.10,9.48">Concept based information retrieval for clinical case summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stober</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S E</forename><surname>Heale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Fulghum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Del Fiol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,362.22,417.16,172.86,9.48;13,90.95,430.84,441.63,9.48;13,90.95,444.52,116.35,9.48">TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Twenty-Fourth Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="13,72.95,458.20,421.83,9.48;13,494.87,455.70,5.42,6.11;13,503.07,458.20,23.05,9.48;13,90.95,471.64,414.51,9.48;13,90.95,485.32,197.33,9.48" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,242.78,458.20,202.22,9.48">Shadow document methods of results merging</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,464.62,458.20,30.16,9.48;13,494.87,455.70,5.42,6.11;13,503.07,458.20,23.05,9.48;13,90.95,471.64,150.00,9.48">The 19 th ACM Symposium on Applied Computing</title>
		<meeting><address><addrLine>Nicosia, Cyprus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-03">2004. March. 2004</date>
			<biblScope unit="page" from="1067" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.95,499.00,463.22,9.48;13,90.95,512.68,417.56,9.48;13,90.95,526.36,409.60,9.48;13,90.95,540.04,184.47,9.48" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,280.76,499.00,255.41,9.48;13,90.95,512.68,23.63,9.48">FDUMedSearch at TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,283.41,512.68,225.11,9.48;13,90.95,526.36,409.60,9.48;13,90.95,540.04,93.47,9.48">NIST Special Publication: The Twenty-Fourth Text REtrieval Conference (TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.95,553.72,424.90,9.48;13,90.95,567.40,421.46,9.48;13,90.95,580.84,448.08,9.48;13,90.95,594.52,412.38,9.48;13,90.95,608.20,83.37,9.48" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,238.85,553.72,259.00,9.48;13,90.95,567.40,380.88,9.48">CBIA VT at TREC 2015 Clinical Decision Support Track-Exploring relevance feedback and query expansion in biomedical information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,215.60,580.84,323.43,9.48;13,97.03,594.52,401.43,9.48">TREC 2015) Proceedings. Paper presented at the Twenty-Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: The Twenty-Fourth Text REtrieval Conference</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
