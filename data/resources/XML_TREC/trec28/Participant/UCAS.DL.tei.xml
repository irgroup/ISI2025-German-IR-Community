<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.17,115.96,307.01,12.62">UCAS at TREC-2019 Deep Learning Track</title>
				<funder>
					<orgName type="full">University of Chinese Academy of Sciences</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.91,153.63,65.03,8.74"><forename type="first">Xuanang</forename><surname>Chen</surname></persName>
							<email>chenxuanang19@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="laboratory">CIP Laboratory</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.83,153.63,40.83,8.74"><forename type="first">Canjia</forename><surname>Li</surname></persName>
							<email>licanjia17@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="laboratory">CIP Laboratory</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.55,153.63,32.25,8.74"><forename type="first">Ben</forename><surname>He</surname></persName>
							<email>benhe@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.06,153.63,50.92,8.74"><forename type="first">Yingfei</forename><surname>Sun</surname></persName>
							<email>yfsun@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="laboratory">CIP Laboratory</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.17,115.96,307.01,12.62">UCAS at TREC-2019 Deep Learning Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">65C7728CC23BDC1A8C7DED1360E39143</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the experiment conducted for our participation in the TREC-2019 Deep Learning track <ref type="bibr" coords="1,366.89,248.41,9.22,7.86" target="#b0">[1]</ref>. We test the effectiveness of two pre-trained language models, BERT [2] and XLNet [3], for the re-ranking subtask of the document ranking task, with an adoption of the passage-level document ranking approach as proposed in [4]. Our preliminary results indicate that the uses of BERT and XLNet lead to comparable performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The UCAS participation in the TREC 2019 Deep Learning track (DL2019) aims to study how to learn neural IR models out of large-scale training data. Specifically, a large set of human-generated training labels from the MS-MARCO dataset are used. In our experiments, we only focus on the re-ranking subtask of the document ranking task. Recently, neural models pre-trained on a language modeling task, such as BERT and XLNet, have advanced the state-of-the-art results on several ranking tasks <ref type="bibr" coords="1,264.62,431.63,7.75,8.74" target="#b3">[4]</ref><ref type="bibr" coords="1,272.37,431.63,3.87,8.74" target="#b4">[5]</ref><ref type="bibr" coords="1,272.37,431.63,3.87,8.74" target="#b5">[6]</ref><ref type="bibr" coords="1,272.37,431.63,3.87,8.74" target="#b6">[7]</ref><ref type="bibr" coords="1,276.24,431.63,7.75,8.74" target="#b7">[8]</ref>. Therefore, we re-purpose BERT and XLNet as document re-rankers to score or rank the candidate documents, in order to achieve competitive results.</p><p>The rest of the paper is organized as follows. Section 2 gives a detailed introduction to the approach used in our experiments. Section 3 presents the experimental settings, results. Finally, Section 4 concludes our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we give a detailed introduction to our approach for the document re-ranking subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Split</head><p>Due to the maximum sequence length limitation of BERT and XLNet, we adopt a recent passage level approach for document retrieval introduced in <ref type="bibr" coords="1,437.68,620.25,9.96,8.74" target="#b3">[4]</ref>. Documents are split into overlapping passages (up to 30 passages with 150 words for a document), and the title, if available, is added to the beginning of every passage. Simply, we consider all passages from a relevant document as being relevant, and passages from a irrelevant document as being irrelevant. The neural re-ranker predicts the relevance of each passage with a query independently, and the document score is given by the score of the best passage (MaxP) or the sum of all passage scores (SumP). In our experiments, the re-ranker with MaxP performs better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Re-ranker with BERT</head><p>In BERT re-ranker, we use the BERT-Large model (bert-large-uncased) to rerank the top-100 documents. We truncate the query to have at most 64 tokens and truncate the passage text such that the concatenation of query, passage, and separator tokens have the maximum length of 256 tokens. The input format of BERT re-ranker is [CLS] [query] [SEP] [passage] [SEP], and the final hidden vector of the [CLS] token is used as input to a single layer neural network to obtain the probability (score) of the passage being relevant. After that, we produce the score of a document according to the scores of its split passages, and eventually, all candidate documents are re-ranked by the document scores received.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Re-ranker with XLNet</head><p>In XLNet re-ranker, we use the XLNet-Large model (xlnet-large-cased) to rerank the top-100 documents. We only truncate the passage text such that the concatenation of query, passage, and separator tokens have the maximum length of 256 tokens. Different from BERT re-ranker, the input format of XLNet reranker is [query] [SEP] [passage] [SEP] [CLS]. Then, akin to the BERT re-ranker, we use the final hidden vector of the [CLS] token to re-rank all candidate documents.</p><p>We start training from a pre-trained BERT or XLNet model, and fine-tune them to our re-ranking subtask using the cross-entropy loss <ref type="bibr" coords="2,397.36,450.66,9.96,8.74" target="#b4">[5]</ref>:</p><formula xml:id="formula_0" coords="2,223.05,474.57,257.53,20.06">L = - j∈Jpos log(s j ) - j∈Jneg log(1 -s j )<label>(1)</label></formula><p>where J pos is the set of indexes of the relevant passages and J neg is the set of indexes of non-relevant passages split from top-100 documents provided.</p><p>3 Experimental Setting and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>The corpus has 3.2 million documents, up to about 22GB. The training dataset has 367,013 queries, the validation dataset has 5,193 queries, and the test dataset has 200 queries. Before experiment, we need to generate train triples and querypassage pairs. We use the top-100 result file in train dataset to generate the train triples. After splitting the documents, we preserve all positive passages in relevant documents and sample a negative passage in irrelevant documents for a query. Then we get about 4,343k train triples for model fine-tuning. We also use the top-100 results in validation and test dataset to generate query-passage pairs of validation and evaluation. Here, we preserve all passages in documents and get about 350k pairs for model evaluation.</p><p>We fine-tune the model using TPUs on Google Cloud<ref type="foot" coords="3,385.90,165.39,3.97,6.12" target="#foot_0">1</ref> with a batch size of 32 for both BERT and XLNet. The model is trained on the above train triples (about 8GB) for 400k iterations, and the model with the best MRR@10 metric on validation queries is chosen, and evaluated on test queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>We submitted three runs for the document re-ranking subtask, the differences among the three runs are summarized in Table <ref type="table" coords="3,341.98,266.09,4.98,8.74" target="#tab_0">1</ref> (PLM denotes the pre-trained language model, and Aggregation means the way to get the score of document from the scores of passages.): The evaluation results of our runs for document re-ranking are shown in Table <ref type="table" coords="3,161.88,531.84,3.87,8.74" target="#tab_1">2</ref>. The best values are highlighted in boldface. From the results above, we find no apparent winner between the uses of BERT and XLNet. A noticeable finding is that the run ucas runid2 based on XLNet has the best RR, but does not outperform the BERT re-rankers for other evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we describe the system based on BERT and XLNet for document re-ranking subtask of TREC-2019 Deep Learning track. Our pilot experiments show no significant difference between the uses of BERT and XLNet within the passage-level document ranking approach as in <ref type="bibr" coords="4,341.72,130.95,9.96,8.74" target="#b3">[4]</ref>. A likely cause is the missing next passage prediction (NSP) component for pre-training the cased XLNet-large used in our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,152.48,322.35,317.23,61.94"><head>Table 1 .</head><label>1</label><figDesc>Run submission summary</figDesc><table coords="3,152.48,343.15,317.23,41.14"><row><cell>RunID</cell><cell>PLM</cell><cell cols="2">Aggregation Train Steps</cell></row><row><cell>ucas runid1</cell><cell>BERT (bert-large-uncased)</cell><cell>MaxP</cell><cell>370k</cell></row><row><cell>ucas runid2</cell><cell>XLNet (xlnet-large-cased)</cell><cell>MaxP</cell><cell>360k</cell></row><row><cell>ucas runid3</cell><cell>BERT (bert-large-uncased)</cell><cell>MaxP</cell><cell>375k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,153.28,432.11,276.27,60.19"><head>Table 2 .</head><label>2</label><figDesc>Evaluation results</figDesc><table coords="3,153.28,451.16,276.27,41.14"><row><cell>runID</cell><cell>RR(MS)</cell><cell>RR</cell><cell>NDCG@10</cell><cell>AP</cell></row><row><cell>ucas runid1</cell><cell>0.442</cell><cell>0.911</cell><cell>0.644</cell><cell>0.264</cell></row><row><cell>ucas runid2</cell><cell>0.431</cell><cell>0.950</cell><cell>0.635</cell><cell>0.253</cell></row><row><cell>ucas runid3</cell><cell>0.435</cell><cell>0.899</cell><cell>0.642</cell><cell>0.268</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,656.80,119.35,7.86"><p>https://cloud.google.com/tpu</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work is supported by the <rs type="funder">University of Chinese Academy of Sciences</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,138.35,266.12,342.24,7.86;4,146.91,277.08,177.47,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,356.63,266.12,123.96,7.86;4,146.91,277.08,55.11,7.86">Overview of the trec 2019 deep learning track</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>in TREC (to appear</note>
</biblStruct>

<biblStruct coords="4,138.35,288.04,342.24,7.86;4,146.91,299.00,333.68,7.86;4,146.91,309.96,20.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,349.84,288.04,130.75,7.86;4,146.91,299.00,205.56,7.86">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
	</analytic>
	<monogr>
		<title level="j" coord="4,365.52,299.00,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,320.92,342.25,7.86;4,146.91,331.88,333.68,7.86;4,146.91,342.84,106.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,467.73,320.92,12.86,7.86;4,146.91,331.88,293.24,7.86">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,453.31,331.88,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="1906">1906.08237, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,353.80,342.24,7.86;4,146.91,364.75,221.63,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,244.76,353.80,235.83,7.86;4,146.91,364.75,73.42,7.86">Deeper text understanding for IR with contextual neural language modeling</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,232.16,364.75,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="1905">1905.09217, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,375.71,342.24,7.86;4,146.91,386.67,106.02,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,290.25,375.71,142.21,7.86">Passage re-ranking with BERT</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno>abs/1901.04085</idno>
	</analytic>
	<monogr>
		<title level="j" coord="4,453.31,375.71,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,397.63,342.24,7.86;4,146.91,408.59,179.69,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,279.92,397.63,200.67,7.86;4,146.91,408.59,32.92,7.86">Simple applications of BERT for ad hoc document retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,190.22,408.59,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="1903">1903.10972, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,419.55,342.24,7.86;4,146.91,430.51,177.10,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,312.43,419.55,168.16,7.86;4,146.91,430.51,29.28,7.86">Understanding the behaviors of BERT in ranking</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,187.64,430.51,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="1904">1904.07531, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,441.47,342.24,7.86;4,146.91,452.43,274.40,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,323.42,441.47,157.17,7.86;4,146.91,452.43,126.88,7.86">Investigating the successes and failures of BERT for passage re-ranking</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Padigela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,284.93,452.43,21.82,7.86">CoRR</title>
		<imprint>
			<date type="published" when="1758">1905.01758, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
