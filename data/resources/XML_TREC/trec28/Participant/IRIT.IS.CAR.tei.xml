<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,115.57,116.95,372.25,12.62;1,214.97,134.89,173.43,12.62">IRIT at TREC 2019: Incident Streams and Complex Answer Retrieval Tracks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,176.31,172.56,57.88,8.74"><forename type="first">Alexis</forename><surname>Dusart</surname></persName>
							<email>alexis.dusart@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Universite de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.17,172.56,56.76,8.74"><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
							<email>gilles.hubert@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Universite de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.45,172.56,100.63,8.74"><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
							<email>karen.sauvagnat@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Universite de Toulouse UPS-IRIT</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,115.57,116.95,372.25,12.62;1,214.97,134.89,173.43,12.62">IRIT at TREC 2019: Incident Streams and Complex Answer Retrieval Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0B0CB05FD190F8FAF5B23C67587157FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the approaches proposed by the IRIS team of the IRIT laboratory for the TREC Incident Streams and Complex Answer Retrieval tracks. The Incident Streams (IS) track aims to categorize and prioritize tweets in disaster situation to assist emergency service operators. In our participation, we applied supervised learning techniques based on features extracted from tweets. Then, the 2019 edition of the Complex Answer Retrieval (CAR) track aims to answer complex questions expressed as outlines using paragraphs from Wikipedia. In our participation, we used the Terrier retrieval system to rank paragraphs for each section of the outline and keep the most relevant according to three different strategies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In 2019, we participated in both the Incident Streams and Complex Answer Retrieval tracks. As these tracks are completely independent, we separately present our approaches for the two tracks in section 2 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Incident Streams</head><p>This year, the track was organized in two different parts, both having the same objective. Part A ran in June and Part B in September. The training test of Part B included the test set of Part A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview of the TREC IS task</head><p>Today, social media is full of information, including people trying to contact emergency services in crisis situations <ref type="bibr" coords="1,174.09,549.52,9.96,8.74" target="#b0">[1]</ref>.</p><p>The purpose of the TREC Incident Streams track is to use this social information to help emergency services, as shown in Figure <ref type="figure" coords="1,265.12,573.43,4.98,8.74" target="#fig_0">1</ref>  <ref type="bibr" coords="1,272.88,573.43,9.96,8.74" target="#b1">[2]</ref>. Tweets have to be classified according to predefined categories called Information types, as for instance "Information wanted" or "Request for Search and Rescue". The task also consists in giving a priority score to the tweets in order to return alerts if necessary. An alert is raised when the priority score is greater than 0.7. Particular attention is paid to information types named "Requests for Goods/Services", "Requests for Search and Rescue", "Calls to Action for Moving People", "Reports of Emerging Threats", "Reports of Significant Event Changes" and "Reports of Services" that are considered actionable, which means that they should lead to actions from emergency services. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Part A</head><p>As aforementioned, the Part A of the task ran in June 2019. The number of learning tweets was about 18,000 and the number of test tweets was about 7,000. In this section we present our system framework, the results, and the corresponding failure analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">System framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features extraction</head><p>In order to identify the different categories and priorities, we extracted some features related to tweets, which we categorized as follows. Community features show the impact of a given tweet in the Twitter community. Morphologic features aim at distinguishing between different nonverbal ways of conveying a message. Microblogging specific features consider the specific content of tweets such as emoticons or hashtags. Grammatical features convey the grammatical quality of a tweet. Entities features are used to find persons, organizations, and locations. Finally, the goal of sentiment features is to represent possible sentiments expressed in the tweet. These features are described in details below:</p><p>-Community features: number of retweets of the tweet and, for the tweet's author, number of friends, number of followers, number of statuses; -Morphologic features: number of upper case characters and upper case words, number of stopwords, number of exclamation and question marks, maximum number of consecutive exclamation and question marks, length of the tweet content (number of words), average word length of tweet content (number of characters); -Microblogging specific features: presence and number of emoticons, presence and number of hashtags, presence and number of URLs, number of phone numbers;</p><p>-Grammatical features: number of nouns, verbs, gerund verbs, adverbs, pronouns, WH question words in the content of the tweet; -Entities features: number of locations, persons and organizations; -Sentiment features: presence of positive, negative and compassion sentiment.</p><p>Emojis, emoticons, URLs, hashtags, phone numbers, upper case, exclamation, and question marks features are extracted before any text cleaning. For the other features, we applied a lowercase transformation, punctuation removal, and stopword removal using the nltk library <ref type="bibr" coords="3,477.47,203.65,9.96,8.74" target="#b2">[3]</ref>. The length of tweet content and number of stopwords features are extracted before stopwords removal.</p><p>For the sentiment features, we used pre-trained weights of DeepMoji <ref type="bibr" coords="3,415.63,227.88,9.96,8.74" target="#b3">[4]</ref>, as used in the architecture presented in <ref type="bibr" coords="3,194.34,239.84,10.52,8.74" target="#b4">[5]</ref> for the 2018 Incident Streams task. More precisely, we retrieved the 5 emojis that DeepMoji predicted for each tweet. We manually associated to each emoji one or several sentiment polarities among positive, negative, and compassion. If the majority of the emojis convey positive, negative or compassion sentiments, the tweet is labelled with the corresponding feeling.</p><p>For entities and grammatical features, we respectively used Stanford Named Entity Recognizer <ref type="bibr" coords="3,116.45,311.90,10.52,8.74" target="#b5">[6]</ref> and Stanford Part-Of-Speech Tagger <ref type="bibr" coords="3,293.95,311.90,9.96,8.74" target="#b6">[7]</ref>. Finally, the other features are extracted using regular expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information Type prediction</head><p>From the extracted features, we predicted the information types in the tweets using supervised learning algorithms. Inspired by the work in <ref type="bibr" coords="3,292.97,388.89,9.96,8.74" target="#b4">[5]</ref>, we combined two models of supervised learning. The combination that gave us the best results in the validation phase was Random Forest Classifier <ref type="bibr" coords="3,134.68,412.80,10.52,8.74" target="#b7">[8]</ref> and Gradient Tree Boosting Classifier <ref type="bibr" coords="3,316.68,412.80,9.96,8.74" target="#b8">[9]</ref>.</p><p>In the task, a tweet can be associated with one or more information types. To tackle this multi-label problem, we proposed three different strategies : (i) Binary Relevance<ref type="foot" coords="3,453.09,435.46,3.97,6.12" target="#foot_0">1</ref> , (ii) a fixed number of information types to return, (iii) a class membership threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Priority score evaluation</head><p>Each tweet in the training set was associated with an importance label among Low, Medium, High, and Critical. These labels are respectively associated to priority scores of 0.25, 0.5, 0.75, and 1.</p><p>To predict the priority scores in the test set, we performed a linear regression using the previously described features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Runs</head><p>Our runs for Part A were named IRIT run rf gb, IRIT run rf gb binary for the official submissions, IRIT run rf gb threshold and are respectively renamed A Fixed, A Binary Relevance and A Threshold in this notebook to be more expressive. The associated configurations are detailed in Tables <ref type="table" coords="3,162.55,639.17,4.98,8.74">3</ref> and<ref type="table" coords="3,190.22,639.17,3.87,8.74" target="#tab_2">4</ref>.</p><p>For run A Binary Relevance, we discretized the continuous features in order to improve our predictions, as done in <ref type="bibr" coords="4,195.14,131.95,15.50,8.74" target="#b9">[10]</ref> and <ref type="bibr" coords="4,232.73,131.95,14.61,8.74" target="#b10">[11]</ref>. Regarding the multi-label problem and as explained before, runs A Binary Relevance, A Fixed, A Threshold respectively implement the following strategies: (i) Binary Relevance, (ii) a fixed number (experimentally fixed to 5 according to preliminary experiments) of information types to return, (iii) a class membership threshold (experimentally fixed to 0.06).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Results</head><p>The results for Part A are presented in Table <ref type="table" coords="4,294.73,240.01,3.87,8.74" target="#tab_0">1</ref>. For Alerting metrics, the scores are between -1 and 1, 1 being the best score and -1 being the worst. Regarding now Information feed metrics, The higher the score is, the better it is. On the contrary, for priorization scores, the closer the score is to 0, the better it is.</p><p>We can notice that we were ranked first regarding Priorization metrics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Failure Analysis</head><p>Regarding the results, it can be seen that the prediction of the actionable information types is worse than the mean prediction for all information types (0.0387 for the best run vs 0.1716 for the worst run).</p><p>A detailed analysis led us to see that the information types that have fewer observations in the learning sample get lower F1 scores in the test set. We therefore hypothesized that to improve our predictions we need more data on these information types.</p><p>We can also see from the results that the priority scores of our runs are close to the best scores, while the alerting scores are close to the worst. Our failure analysis also revealed that very few alerts were returned by our model (a maximum of 14 out of 345 in the ground truth). We recall that an alert is raised when the priority score is greater than 0.7. An hypothesis is that using a linear regression to evaluate the priority scores does not effectively discriminate between alerting tweets and others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Part B</head><p>For this edition 2019-B run in September, the number of learning and test tweets was respectively about 25,000 and 14,000.</p><p>Our runs for Part B were named IRITrun1, IRITrun2, IRITrun3, IRITrun4 fot hte official submissions and are respectively renamed B R Resampled, B Binary Relevance, B T Resampled and B Threshold in this notebook to be more expressive. Tables <ref type="table" coords="5,381.70,197.90,4.98,8.74">3</ref> and<ref type="table" coords="5,413.10,197.90,4.98,8.74" target="#tab_2">4</ref> sum up the methods used for the different runs to classify the different information types as well as to predict priority scores.</p><p>The differences in our runs between Part A and Part B are the following:</p><p>-We used the POS-Tagger and NER from nltk<ref type="foot" coords="5,307.53,260.59,3.97,6.12" target="#foot_2">2</ref> which are faster than Stanford's ones.</p><p>-As proposed by the University College Dublin team in Part A of the task, we used SMOTE <ref type="bibr" coords="5,495.95,275.82,15.50,8.74" target="#b11">[12]</ref> to deal with the imbalanced types of information in the training set. SMOTE is a technique for adding observations to under-represented classes in a dataset. -To evaluate priority scores, unlike linear regression where we considered the variable to be explained quantitatively, we considered the variable to be explained qualitatively among the values Low, Medium, High, and Critical. For this purpose, we used Random Forest that gave us the best results in the validation phase.</p><p>The best run results for each metric as well as our scores for Part B are presented in Table <ref type="table" coords="5,503.71,374.25,3.87,8.74" target="#tab_1">2</ref>.</p><p>We tried resampling (SMOTE) for the imbalanced types of information and especially for actionable types of information without improving results. Random Forest gives us better results than linear regression to detect high priority tweets. 3 Complex Answer Retrieval</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of the TREC CAR track</head><p>Current retrieval systems provide good solutions towards phrase-level retrieval for simple fact and entity-centric needs. The Complex Answer Retrieval track aims to return complex information in a structured form, i.e., to answer open questions requiring several pieces of information.</p><p>The problem of the CAR 2019 task is to fill outlines structured in sections and given as queries with ordered paragraphs. For each outline, a maximum of 20 paragraphs should be returned, each related to one of the sections of the outline. The provided data are thus the outlines and the corpus of possible paragraphs to be returned:</p><p>-The outlines are based on the Textbook Question Answering dataset<ref type="foot" coords="6,400.02,503.96,3.97,6.12" target="#foot_3">3</ref> . The Textbook Question Answering dataset includes college-level lessons in the life, earth and physics sciences <ref type="bibr" coords="6,493.19,517.49,14.61,8.74" target="#b12">[13]</ref>.</p><p>There are 132 outlines, 726 sections of outlines, i.e., an average of 5.5 sections per outline. -The paragraphs to be returned are provided from Wikipedia, the collection has 29,794,697 paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System framework</head><p>Figure <ref type="figure" coords="6,122.78,602.76,4.98,8.74" target="#fig_2">2</ref> sums up our approach. We first indexed the corpus of paragraphs provided to answer the outlines. We then defined a query for each section of the outlines. For each query, we retrieved and ranked the relevant paragraphs using different IR models. Finally, we filled the outlines using these relevant paragraphs according to three different strategies.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Indexing</head><p>The TREC CAR 2019 track provided about 30 million paragraphs from Wikipedia. We indexed these paragraphs using the Terrier retrieval system <ref type="bibr" coords="7,323.91,469.46,14.61,8.74" target="#b13">[14]</ref>. We used the default Terrier indexing settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Retrieving relevant paragraphs</head><p>For each outline, the different sections to be answered are provided by the organizers. We built our queries from the outline and its different sections. For each section, we concatenated its title with the title of the corresponding outline in order to obtain the queries. At this point, we thus have the index of the corpus of paragraphs and our different queries for which we want to retrieve the most relevant paragraphs.</p><p>In order to retrieve the most relevant paragraphs, we used the models already implemented in Terrier : BB2, BM25, DFR BM25, DLH, DLH13, DPH, DFRee, Hiemstra LM, IFB2, In expB2, In expC2, InL2, LemurTF IDF, LGD, PL2, and TF IDF. Each of these models returned a ranking of relevant paragraphs to each query. We then used the CombMNZ function to keep only one ranking from all models. The CombMNZ function returns a ranking by combining the rankings from the different models <ref type="bibr" coords="7,205.50,657.11,14.61,8.74" target="#b14">[15]</ref>:</p><formula xml:id="formula_0" coords="8,189.12,127.03,322.33,30.20">ScoreCombMNZ s (p) = ( n m=1 Score ms (p)) • Count s (p) (1)</formula><p>where n is the number of weighting models, s is the concerned section, Score ms (p) is the score calculated by the model m for the paragraph p for the section s, and Count s (p) is the number of models that have retrieved the paragraph p for the section s.</p><p>As a result, we obtained a ranking of paragraphs for each query, i.e., for each section of an outline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Answer to the outline</head><p>Following the guidelines, we answered each outline using a maximum of 20 paragraphs. To choose these 20 paragraphs from the different rankings computed for all the sections, we applied three different strategies:</p><p>-The first strategy uses a classic Round-Robin algorithm. The best paragraph of each section is selected in an iterative way until the maximum of 20 paragraphs is reached with the constraint that one paragraph can only appear once in the outline. Figure <ref type="figure" coords="8,384.63,314.03,4.98,8.74" target="#fig_3">3</ref> is an exemplification of this strategy. For the outline "Word climates", the different sections of the outline are depicted.</p><p>For each section, the ranking is presented with the rank, the paragraph ID, and the CombMNZ score of the paragraph for the query corresponding to the section. Highlighted lines represent the paragraphs kept to answer the outline. This strategy has some limits, notably regarding the ranking across sections: one paragraph may have a higher score for section A than another one for section B but as it is less well ranked it will not be kept for filling the outline. To illustrate this limit, in Figure <ref type="figure" coords="8,239.79,397.72,3.87,8.74" target="#fig_3">3</ref>, the paragraph Para 4 of the "Tropical climates" section has a relevance score of 550 and is kept in the final result while the paragraph Para 18 of the "Continental climates" section has a relevance score of 950 and is not kept. -To overcome this problem, we took into account in strategies 2 and 3 the ranking but also the CombMNZ score of the paragraphs and the number of paragraphs of the section already recovered to answer the outline. For each section, a candidate paragraph is chosen (the one among the highest unrecovered paragraphs in the ranking for the section). For all the candidates (one per section), a function is applied, and the one that maximizes the score of the function is selected. This operation is repeated until the limit of 20 paragraphs is reached.</p><p>For our second strategy, we used the following formula:</p><formula xml:id="formula_1" coords="8,163.57,532.23,347.89,9.65">Function(candidate s ) = se s (candidate s ) -ce s (candidate s ) -nb s<label>(2)</label></formula><p>with candidate s the candidate paragraph for section s, se s the CombMNZ score of the paragraph for the section scaled between 0 and 1, ce s the ranking of the paragraph for the section scaled between 0 and 1, and nb s the number of already retrieved paragraphs for the section, scaled between 0 and 1.</p><p>To scale between 0 and 1, the MinMaxScaler function from sklearn <ref type="foot" coords="8,404.25,593.44,3.97,6.12" target="#foot_4">4</ref> was applied for all the selected candidates: with X a vector, x a value of X, min(X) the minimum value of X and max(X) the maximum value of X. At last, for our third strategy, we used the following formula: Function(candidate s ) = ln(ScoreCombMNZ s (candidate s )) -c s (candidate s ) -nb s (4)</p><formula xml:id="formula_2" coords="8,236.74,615.44,274.71,22.31">scale(x) = x -min(X) max(X) -min(X)<label>(3)</label></formula><p>with ScoreCombMNZ s the paragraph score for section s, c s the ranking of the paragraph for section s and nbr s the number of paragraphs in section s already retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Runs</head><p>We submitted three runs:</p><p>-Our run using the Round-Robin strategy is named IRIT run1.</p><p>-Our run that uses strategy 2 is named IRIT run2.</p><p>-Finally, our run that uses strategy 3 is named IRIT run3.</p><p>Figure <ref type="figure" coords="9,139.01,558.25,4.98,8.74">4</ref> shows the results of the track for 2019. These results do not consider the passage ordering task but the section-level ranking performance. This explains the similar scores for the three runs. In other words, only the approaches described up to section 3.2.3 are evaluated in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we presented our approach for the TREC IS 2019 task, which aims at categorizing tweets from streams in order to help emergency services in case of incidents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,91.93,296.99,419.53,9.88;2,91.93,308.62,17.71,7.47"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Incident Streams task, as shown on the task's website (http://dcs.gla.ac.uk/ ~richardm/TREC_ IS/)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,150.30,400.16,302.77,7.89"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. General approach used by the IRIS team for the TREC CAR track</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,98.36,350.81,406.65,7.89"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Illustration of the algorithm used to return paragraphs according to the outline and sections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="10,91.93,116.83,418.50,293.85"><head></head><label></label><figDesc></figDesc><graphic coords="10,91.93,116.83,418.50,293.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,91.93,327.51,419.53,139.18"><head>Table 1 .</head><label>1</label><figDesc>TREC IS 2019 Part A Results. Runs A Fixed, A Binary Relevance and A Threshold respectively correspond to the official runs IRIT run rf gb, IRIT run rf gb binary, IRIT run rf gb threshold.</figDesc><table coords="4,118.77,327.51,365.84,114.94"><row><cell></cell><cell cols="2">Alerting</cell><cell cols="2">Information Feed</cell><cell>Priorization</cell></row><row><cell>Run</cell><cell cols="2">Accumulated</cell><cell>Info. Type</cell><cell>Info. Type</cell><cell>Priority</cell></row><row><cell></cell><cell cols="2">Alert Worth</cell><cell>Positive F1</cell><cell>Accuracy</cell><cell>MSE</cell></row><row><cell></cell><cell cols="3">High Priority All Actionable All</cell><cell>All</cell><cell>Actionable All</cell></row><row><cell>A Fixed</cell><cell>-0.9867</cell><cell cols="3">-0.4935 0.0000 0.1735 0.8209</cell><cell>0.1170 0.0558</cell></row><row><cell>A Binary Relevance</cell><cell>-0.9942</cell><cell cols="3">-0.4971 0.0387 0.1716 0.8780</cell><cell>0.0751 0.0694</cell></row><row><cell>A Threshold</cell><cell>-0.9867</cell><cell cols="3">-0.4935 0.0117 0.1774 0.7840</cell><cell>0.1170 0.0558</cell></row><row><cell>Median Scores</cell><cell>-0.9680</cell><cell cols="3">-0.4869 0.0536 0.1622 0.8581</cell><cell>0.1615 0.0756</cell></row><row><cell>Best Scores</cell><cell>-0.1213</cell><cell cols="3">-0.1839 0.1969 0.2512 0.8829</cell><cell>0.0751 0.0558</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,91.93,451.75,419.53,183.01"><head>Table 2 .</head><label>2</label><figDesc>TREC IS 2019 Part B Results. Runs B B R Resampled, B Binary Relevance, B T Resampled and B Threshold respectively correspond to the official runs IRITrun1, IRITrun2, IRITrun3, IRITrun4.</figDesc><table coords="5,112.73,451.75,377.93,158.78"><row><cell></cell><cell cols="2">Alerting</cell><cell cols="3">Information Feed</cell><cell cols="2">Priorization</cell></row><row><cell>Run</cell><cell cols="2">Accumulated</cell><cell cols="2">Info. Type</cell><cell>Info. Type</cell><cell cols="2">Priority</cell></row><row><cell></cell><cell cols="2">Alert Worth</cell><cell cols="2">Positive F1</cell><cell>Accuracy</cell><cell>MSE</cell><cell></cell></row><row><cell></cell><cell cols="4">High Priority All Actionable All</cell><cell>All</cell><cell cols="2">Actionable All</cell></row><row><cell>Median Scores</cell><cell>-0.9197</cell><cell>-0.4609</cell><cell>0.0386</cell><cell>0.1055</cell><cell>0.8583</cell><cell>0.1767</cell><cell>0.1028</cell></row><row><cell>Informedia-nb</cell><cell>-0.9197</cell><cell>-0.4609</cell><cell>0.1321</cell><cell>0.0995</cell><cell>0.8605</cell><cell cols="2">0.0788 0.0544</cell></row><row><cell>Informedia-rf3</cell><cell cols="3">-0.0898 -0.1837 0.0592</cell><cell>0.0568</cell><cell>0.8434</cell><cell>0.1660</cell><cell>0.2063</cell></row><row><cell>B Threshold</cell><cell>-0.9744</cell><cell>-0.4872</cell><cell>0.0000</cell><cell>0.1583</cell><cell>0.7576</cell><cell>0.1461</cell><cell>0.0775</cell></row><row><cell>B T Resampled</cell><cell>-0.8482</cell><cell>-0.4351</cell><cell>0.0000</cell><cell>0.1388</cell><cell>0.8565</cell><cell>0.1771</cell><cell>0.1028</cell></row><row><cell>B Binary Relevance</cell><cell>-0.9794</cell><cell>-0.4897</cell><cell>0.0248</cell><cell>0.1734</cell><cell>0.8534</cell><cell>0.1175</cell><cell>0.0659</cell></row><row><cell>B B R Resampled</cell><cell>-0.5649</cell><cell>-0.3332</cell><cell cols="3">0.0151 0.1863 0.8418</cell><cell>0.1316</cell><cell>0.0911</cell></row><row><cell>nyu.fast.multi</cell><cell>-0.9287</cell><cell>-0.4679</cell><cell>0.0854</cell><cell cols="2">0.1253 0.8808</cell><cell>0.2153</cell><cell>0.1185</cell></row><row><cell>UCDbaseline</cell><cell>-0.7856</cell><cell cols="3">-0.4131 0.1355 0.1343</cell><cell>0.7495</cell><cell>0.0859</cell><cell>0.0668</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,160.57,355.46,282.24,7.89"><head>Table 4 .</head><label>4</label><figDesc>Runs Incident Streams Overview Priority Score Prediction.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,101.89,657.79,371.57,8.12"><p>http://scikit.ml/api/skmultilearn.problem_transform.br.html, last access on October</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="3,476.07,657.79,35.38,7.86"><p>22, 2019.   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="5,101.89,657.79,299.33,8.12"><p>https://www.nltk.org/book/ch07.html, last access on October 22, 2019.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="6,101.89,657.79,266.38,8.12"><p>http://data.allenai.org/tqa/, last access on October 22, 2019.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="8,101.89,647.48,400.62,7.47;8,101.89,657.79,153.40,8.12"><p>https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler. html, last access on October 22, 2019.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We also presented our approach for the TREC CAR 2019 task, which aims to answer complex questions.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,100.12,526.36,283.64,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,174.84,526.36,61.34,7.86">Big Crisis Data</title>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.12,537.30,411.34,7.86;10,108.68,548.26,167.50,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cody</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<title level="m" coord="10,338.56,537.30,172.90,7.86;10,108.68,548.26,110.32,7.86">Trec incident streams: Finding actionable information on social media</title>
		<imprint>
			<date type="published" when="2019-03">March 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.12,559.20,411.34,7.86;10,108.68,570.16,20.99,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,299.97,559.20,166.92,7.86">Natural Language Processing with Python</title>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>O&apos;Reilly</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.12,581.10,411.33,7.86;10,108.68,592.06,402.77,7.86;10,108.68,603.02,348.55,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,442.80,581.10,68.65,7.86;10,108.68,592.06,398.47,7.86">Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</title>
		<author>
			<persName coords=""><forename type="first">Bjarke</forename><surname>Felbo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iyad</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sune</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,120.20,603.02,266.23,7.86">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,100.12,613.96,411.34,7.86;10,108.68,624.92,402.77,7.86;10,108.68,635.88,402.77,7.86;10,108.68,646.84,402.77,7.86;10,108.68,657.79,388.59,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,373.38,613.96,138.07,7.86;10,108.68,624.92,402.77,7.86;10,108.68,635.88,50.20,7.86">Neural networks and support vector machine based approach for classifying tweets by information types at TREC 2018 incident streams task</title>
		<author>
			<persName coords=""><forename type="first">Abu</forename><surname>Nowshed Chy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Umme</forename><surname>Aymun Siddiqua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Masaki</forename><surname>Aono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,369.99,635.88,141.47,7.86;10,108.68,646.84,104.93,7.86">Proceedings of the Twenty-Seventh Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>the Twenty-Seventh Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-14">2018. November 14-16, 2018. 2018</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="11,100.12,120.67,411.34,7.86;11,108.68,131.63,402.77,7.86;11,108.68,142.59,402.77,7.86;11,108.68,153.55,402.77,7.86;11,108.68,164.51,233.58,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,390.52,120.67,120.94,7.86;11,108.68,131.63,256.52,7.86">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName coords=""><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,224.30,142.59,287.15,7.86;11,108.68,153.55,170.88,7.86">ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</editor>
		<meeting><address><addrLine>University of Michigan, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computer Linguistics</publisher>
			<date type="published" when="2005-06">June 2005. 2005</date>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
	<note>Proceedings of the Conference</note>
</biblStruct>

<biblStruct coords="11,100.12,175.46,411.33,7.86;11,108.68,186.42,402.77,7.86;11,108.68,197.38,402.77,7.86;11,108.68,208.34,402.77,7.86;11,108.68,219.30,196.69,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,428.89,175.46,82.56,7.86;11,108.68,186.42,203.23,7.86">Feature-rich part-ofspeech tagging with a cyclic dependency network</title>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,129.50,197.38,292.64,7.86;11,222.29,208.34,75.91,7.86">Human Language Technology Conference of the North American Chapter</title>
		<editor>
			<persName><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</editor>
		<editor>
			<persName><surname>Editors</surname></persName>
		</editor>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2003-06-01">May 27 -June 1, 2003. 2003</date>
		</imprint>
	</monogr>
	<note>HLT-NAACL 2003</note>
</biblStruct>

<biblStruct coords="11,100.12,230.26,283.28,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,167.07,230.26,61.96,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,236.68,230.26,70.86,7.86">Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,100.12,241.22,411.34,7.86;11,108.68,252.18,103.93,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,199.20,241.22,248.53,7.86">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName coords=""><forename type="first">Jerome</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,457.10,241.22,50.90,7.86">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">10 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,99.78,263.14,411.68,7.86;11,108.68,274.09,402.77,7.86;11,108.68,285.05,402.77,7.86;11,108.68,296.01,76.66,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,497.37,263.14,14.08,7.86;11,108.68,274.09,305.62,7.86;11,133.14,296.01,22.52,7.86">Improving classification performance with discretization on biomedical datasets</title>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Lustgarten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Himanshu</forename><surname>Vanathi Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shyam</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Visweswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,432.88,274.09,78.58,7.86;11,108.68,285.05,230.63,7.86">AMIA 2008, American Medical Informatics Association Annual Symposium</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">November 8-12, 2008. 2008</date>
		</imprint>
	</monogr>
	<note>AMIA</note>
</biblStruct>

<biblStruct coords="11,99.78,306.97,411.68,7.86;11,108.68,317.93,402.77,7.86;11,108.68,328.89,259.89,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,192.91,306.97,318.54,7.86;11,108.68,317.93,92.08,7.86">Influence of features discretization on accuracy of random forest classifier for web user identification</title>
		<author>
			<persName coords=""><forename type="first">Alisa</forename><forename type="middle">A</forename><surname>Vorobeva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,225.00,317.93,203.87,7.86">20th Conference of Open Innovations Association</title>
		<meeting><address><addrLine>St. Petersburg, Russia</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017-04-03">2017. April 3-7, 2017. 2017</date>
			<biblScope unit="page" from="498" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,99.78,339.85,411.68,7.86;11,108.68,350.81,337.52,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,475.24,339.85,36.22,7.86;11,108.68,350.81,172.44,7.86">SMOTE: synthetic minority over-sampling technique</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,289.30,350.81,79.26,7.86">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,99.78,361.77,411.68,7.86;11,108.68,372.73,402.77,7.86;11,108.68,383.68,402.77,7.86;11,108.68,394.64,351.94,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,152.92,372.73,358.53,7.86;11,108.68,383.68,57.60,7.86">Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension</title>
		<author>
			<persName coords=""><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min</forename><forename type="middle">Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dustin</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,183.94,383.68,270.49,7.86">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-07-21">2017. July 21-26, 2017. 2017</date>
			<biblScope unit="page" from="5376" to="5384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,99.78,405.60,411.68,7.86;11,108.68,416.56,317.46,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,412.36,405.60,99.09,7.86;11,108.68,416.56,131.46,7.86">From puppy to maturity: Experiences in developing terrier</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">T</forename><surname>Rodrygo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,247.70,416.56,95.79,7.86">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="60" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,99.78,427.52,411.68,7.86;11,108.68,438.48,402.77,7.86;11,108.68,449.44,402.77,7.86;11,108.68,460.40,165.70,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,271.64,427.52,136.24,7.86">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,138.27,438.48,211.56,7.86">Proceedings of The Third Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Donna</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>The Third Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11-02">1994. November 2-4, 1994. 1994</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
