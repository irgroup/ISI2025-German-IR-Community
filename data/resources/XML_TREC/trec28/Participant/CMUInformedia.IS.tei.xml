<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.08,71.79,347.38,12.90">CMU-Informedia at TREC 2019 Incident Streams Track</title>
				<funder ref="#_P3Pacby">
					<orgName type="full">U.S. Department of Commerce, National Institute of Standards and Technology</orgName>
				</funder>
				<funder ref="#_86VZQZ4">
					<orgName type="full">DARPA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,118.35,113.41,64.61,10.75"><forename type="first">Junpei</forename><surname>Zhou</surname></persName>
							<email>junpeiz@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,197.90,113.41,64.00,10.75;1,261.90,111.88,1.41,6.99"><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
							<email>xinyuw3@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.84,113.41,72.50,10.75;1,349.34,111.88,1.41,6.99"><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
							<email>poyaoh@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.28,113.41,117.90,10.75"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.08,71.79,347.38,12.90">CMU-Informedia at TREC 2019 Incident Streams Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">310DB3D3EA44D4DA7A61EED304409ED3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe CMU-Informedia's models for the TREC 2019 Incident Streams track. The goal of this track is classifying event/incident related tweets by High-level Information Types such as 'SearchAndRescue', 'InformationWanted' and so on. Each tweet should be assigned as many categories as are appropriate. What's more, this track requires predicting the Importance Scores, which is converted from the Importance Labels including 'Critical', 'High', 'Medium', 'Low' and 'Irrelevant'. For predicting the information types, we use feature extractors to extract features including meta-information, user entity, and textual embeddings, and then we build an information type predictor on those features. For predicting the importance scores, we build an importance score predictor which combines the scores derived from the predicted information types and the scores produced by a regression model. Evaluation results show that our models perform well on all metrics, and different models perform particularly well on different aspects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>People often turn to social media when an emergency happens to find out relevant information. Twitter, as a platform for microblogging, can be especially useful for this purpose because it is designed for networking "what's happening in the world and what people are talking about right now." Twitter information has already been used for monitoring disasters and public safety events as in <ref type="bibr" coords="1,101.08,709.53,89.98,9.46" target="#b7">(Earle et al., 2012;</ref><ref type="bibr" coords="1,196.81,709.53,93.46,9.46" target="#b12">Kumar et al., 2011;</ref><ref type="bibr" coords="1,72.00,723.08,90.74,9.46" target="#b20">Poblete et al., 2018)</ref>. Nevertheless, few studies have been done for filtering Twitter stream (Huang * equal contribution <ref type="bibr" coords="1,307.28,226.40,53.16,9.46">et al., 2018)</ref> down to actionable items, which can be particularly valuable to public safety personnel.</p><p>To bring more efforts on categorizing information and aid requests made on social media, the TREC-IS task is introduced. The task (2019 edition) focuses on producing a series of curated multimodal feeds from tweets. Specifically, there are twenty-five high-level information types to be classified from tweets related to six incident types: bombing, earthquake, flood, typhoon/hurricane, wildfire and shooting. Importance scores reporting the priority for each tweet also need to be calculated.</p><p>Here we present the CMU-Informedia system for the TREC-IS task. The paper is organized as follows: in Section 2 we introduce relevant work to this task; in Section 3 we present the features used, the predictors for classifying information types and the predictors for computing importance scores; in Section 4 we describe the experiment setup and show experimental results; in Section 5 we draw the conclusions and indicate our future direction of work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The TREC-IS task was first introduced in 2018 <ref type="bibr" coords="1,307.28,592.09,103.30,9.46" target="#b15">(Mccreadie et al., 2019)</ref> to help emergency service operators monitor social media effectively. Due to the large volume and various modalities of information feed, how to categorize and verify them remains a challenging problem. The introduction of TREC-IS task helps bring more research efforts to addressing these practical problems.</p><p>In the 2018 edition, there are 1,335 tweets for training and nearly 20k tweets for testing. The BJUT <ref type="bibr" coords="1,337.39,715.22,74.56,9.46" target="#b14">(Lu et al., 2018)</ref> used an expansion module to augment the training set, as in the first edition there is not much training data. Then they trained a Support Vector Machine (SVM) with TF-IDF word frequency features to classify the tweets. <ref type="bibr" coords="2,105.93,80.22,76.12,9.46" target="#b4">(Chy et al., 2018)</ref> built a rule-based classifier, an SVM classifier and a neural network classifier are ensembled for prediction. <ref type="bibr" coords="2,238.77,107.31,51.50,9.46;2,72.00,120.86,48.09,9.46" target="#b5">(Cumbreras et al., 2018</ref>) also used SVM and did topic expansion using either WordNet synonyms or word embeddings <ref type="bibr" coords="2,114.12,147.96,93.82,9.46" target="#b16">(Mikolov et al., 2013)</ref>. Additional metadata is used to overcome the small training data in <ref type="bibr" coords="2,84.47,175.06,101.46,9.46" target="#b17">(Miyazaki et al., 2018)</ref>. <ref type="bibr" coords="2,197.76,175.06,92.51,9.46" target="#b23">(Zahera et al., 2018)</ref> combined knowledge graph features and textual features and experimented with several traditional machine learning models. <ref type="bibr" coords="2,189.17,215.71,80.52,9.46" target="#b3">(Choi et al., 2018)</ref> represented the terms in tweets as conceptual entities such as event entities, category indicator entities, information type entities, URL entities, and user entities. Then they trained SVM models and deep learning models with class activation mapping for classification.</p><p>There are also other works using Twitter for disaster management. <ref type="bibr" coords="2,162.31,331.07,92.44,9.46" target="#b12">(Kumar et al., 2011)</ref> present a tool TweetTracker to monitoring and analyzing location and keyword specific tweets. <ref type="bibr" coords="2,241.19,358.16,49.08,9.46;2,72.00,371.71,55.10,9.46" target="#b0">(Ashktorab et al., 2014)</ref> build a Twitter-mining tool Tweedr to identify tweets reporting damage or casualties <ref type="bibr" coords="2,72.00,398.81,92.39,9.46" target="#b21">(Reitan et al., 2015)</ref> develop a method that can identify Japanese tweets refuting rumors which would hinder rescue activities during a natural disaster. <ref type="bibr" coords="2,98.60,439.46,88.04,9.46" target="#b8">(Huang et al., 2018)</ref> incorporate textual and visual information and learn visual-semantic embeddings <ref type="bibr" coords="2,114.89,466.56,89.86,9.46" target="#b9">(Huang et al., 2019)</ref> to monitor and filter out important tweets in public safety events. <ref type="bibr" coords="2,72.00,493.66,94.23,9.46" target="#b20">(Poblete et al., 2018)</ref> proposes an online method for detecting unusual bursts in discrete-time signals extracted from Twitter, which can be used for worldwide earthquake detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System</head><p>Our system has three parts: the feature extractor, the information types predictor, and the importance score predictor. The pipeline of our system is shown in Fig 1 . In this system, the feature extractor extracts a lot of features and also pre-processes those features, then the information type is predicted by the information types predictor. What's more, the importance score is generated by the importance score predictor, which combines scores derived from the predicted information type and scores predicted by a regressor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature Extractor</head><p>To get an informative representation for each tweet, we use several feature extractors. Some of them directly extract tweet-level features and some of them extract word-level features which are converted to tweet-level features later. There could be several choices in the implementation of each feature extractor. We will discuss the choices in this chapter and analyze our final choices with experimental results in Section 4.</p><p>Meta Information As we use the tweets extracted from the official Twitter API, the tweets we got contain a lot of meta-information, including some pre-processed entities and the count of some special actions such as 'retweet', 'favourite' and so on. Here are some features we used:</p><p>• The number of different entities (including 'hashtags', 'symbols', 'user mentions', 'urls' and 'media'). • The number of different actions (including 'retweet' and 'favorite'). • The polarity scores of sentiment analyzer from NLTK <ref type="bibr" coords="2,383.84,384.80,99.22,9.46" target="#b13">(Loper and Bird, 2002)</ref>. • The length of the tweet.</p><p>• Number of different characters.</p><p>• Number of words after tokenization.</p><p>• Number of words that have capitalized char, and the ratio of those words in this tweet. • Some indicator features including if the tweet has coordinates, if the user is verified. • Some user profiles including number of followers, friends, favourites, and statuses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Entity</head><p>We have manually annotated about 200 users with mentions frequency greater than 10 in the training data. We followed <ref type="bibr" coords="2,472.82,556.78,52.72,9.46;2,307.28,570.33,25.45,9.46" target="#b3">(Choi et al., 2018)</ref> to define the six user entities: &lt;UserNews&gt;, &lt;UserWeather&gt;, &lt;UserOrganization&gt;, &lt;UserDo-nation&gt;, &lt;UserDisasterInfo&gt; and &lt;UserMultime-dia&gt;. The user entities are annotated based on the user characterstics. For example, user @breakingstorm is annotated as &lt;UserWeather&gt; and user @NewEarthquake is annotated as &lt;UserDisaster-Info&gt;.</p><p>GloVe and FastText Apart from the meta information, we use the word embedding as a part of the feature for each word. There are two famous and popular word vector models: Global Vectors (GloVe) <ref type="bibr" coords="2,386.68,742.31,117.33,9.46" target="#b19">(Pennington et al., 2014)</ref> and FastText <ref type="bibr" coords="2,348.91,755.86,115.14,9.46" target="#b1">(Bojanowski et al., 2017;</ref><ref type="bibr" coords="2,468.59,755.86,56.96,9.46" target="#b10">Joulin et al.,</ref> Regressor Importance Score Predictor Type to Score Feature Extractor Tweet Embedding</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information Type Predictor</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicted Information Types</head><p>Predicted Importance Score</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweet</head><p>Figure 1: The Pipeline of our system which finally output the information types and importance scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2016</head><p>). GloVe uses a global co-occurrences matrix because the online scanning approach used by word2vec <ref type="bibr" coords="3,117.20,241.14,94.95,9.46" target="#b16">(Mikolov et al., 2013)</ref> does not fully exploit the global statistical information. FastText incorporates the subword information and it could be viewed as an extension of the word2vec model. We use the 200-dimension GloVe embedding pretrained on Twitter 27 Billion corpus, and the 200dimension pre-trained FastText model to extract the embedding for each word in the tweet. We also used a FastText model trained on emergency tweet corpus to overcome the out-of-domain issue. After extracting the features for each word, we tried two methods to derive the feature for the tweet, where the first is simple average, and the second is weighted average according to TF-IDF weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skip-Thought</head><p>The Skip-Thought <ref type="bibr" coords="3,233.27,439.82,57.00,9.46;3,72.00,453.36,25.45,9.46" target="#b11">(Kiros et al., 2015)</ref> model tries to extract a fixed-size embedding for a whole sentence. It similarly trains the model as word2vec, which means it uses the ordering of sentences in a natural language corpus as the training signal. We use the Skip-Thought model pre-trained on the BookCorpus <ref type="bibr" coords="3,241.76,521.11,48.51,9.46;3,72.00,534.66,25.45,9.46" target="#b24">(Zhu et al., 2015)</ref> dataset.</p><p>BERT In addition to training a context-free embedding as GloVe and word2vec, BERT <ref type="bibr" coords="3,257.21,570.74,33.05,9.46;3,72.00,584.29,51.55,9.46" target="#b6">(Devlin et al., 2018)</ref> trains a bi-directional language model as a feature extractor, which can distinguish the same word in different contexts. We use the pretrained BERT model (Large, uncased) released by Google Research. For extracting features from BERT, there are a lot of choices, including using features from different layers, using features by taking the average or directly use the feature of the CLS symbol.</p><p>Preprocessing As the feature extracted by different models have different lengths and different scales, we need to merge them. The simplest method is to concatenate all features to-gether, which is not the best choice because it ignores different scales and it leads to that the feature is too long to train in short time. So, we try to do some pre-processing for each feature, including the Principal Component Analysis (PCA) and normalization. Another choice is to do the late fusion, which means we don't concatenate those features in an early stage, but instead, we train models on each feature separately, and then merge the score predicted by different models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Information Types Predictor</head><p>There are several changes in 2019 edition, so we made some adoptions accordingly in our model.</p><p>Multi-Type Categorization One of the most important differences compared with the setting in 2018 is that we need to do a Multi-Type Categorization (multi-label classification) for each tweet.</p><p>It means we need to predict one or more Information Types for each tweet, and the ground truth also consists of several information types. Considering this setting, we use 'OneVsRestClassifier' wrapper in scikit-learn <ref type="bibr" coords="3,415.58,518.34,109.96,9.46" target="#b18">(Pedregosa et al., 2011)</ref> to train a classifier for each information type. In this task, we mainly focus on Naive Bayes, Linear SVM, Random Forest, and XGBoost <ref type="bibr" coords="3,498.88,558.99,26.66,9.46;3,307.28,572.54,87.43,9.46" target="#b2">(Chen and Guestrin, 2016)</ref>. After getting the predicted score for each information type, we can use different strategies to predict the final information types. The first strategy is setting a threshold and then predict all labels whose scores are above that threshold. The second strategy is setting a k and choose the top-k scores and predictions.</p><p>Actionable Information Type Another change is that some information types are defined as 'actionable', such as 'GoodsServices', 'SearchAn-dRescue', 'MovePeople' and so on. The evaluation result distinguishes between performance on 'actionable' and 'non-actionable' information types. Our strategy is trying to give an additional weight w a to those informative Information Types during training. The final weight w i for each information type t i is calculated by w i a +w i b where w i b is the base weight for each information type, which is calculated according to the importance score associated with the t i in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event-wise Prediction</head><p>We did some interesting explorations about using event-wise prediction. As all events fall into six incident types, there would be some traits for each event. For example, the tweets about wildfire should be different from the tweets about shooting. With this consideration, we train a model for each type of incident, and use the corresponding model during prediction.</p><p>Ensemble Another exploration we made is the ensemble, which combines the results predicted from different models. More specifically, after getting the prediction results from different models (such as Naive Bayes and Random Forest), we merge them to get the final result. However, the ensemble is not well-defined in the multi-label setting, so we try different methods for ensemble. The first method is voting, where we pick up the information types predicted by a majority of models. The second method is stacking, where we use the predicted score as new features, and train a new model on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Importance Score Predictor</head><p>The Importance Score is predicted by combining two methods. The first method is deriving the score from the information types we predicted, and the second method is trying to predict the score by a regression model directly.</p><p>Conversion from Information Type For each tweet, after getting the predicted information types from the Information Types Predictor, the score could be derived by averaging the score associated with each information type. The score for each information type is calculated from the training set (same as the base weight) as described in Section 3.2.</p><p>Regression The second method is using regression to predict the Importance Score. As the training data has a field of Importance Labels, it could be converted to the score according to the mapping as shown in Table <ref type="table" coords="4,156.02,728.77,4.09,9.46">1</ref>. Then predicting the importance score could be easily modeled as a regression task, and we choose to use Ridge regression. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>The size of each dataset is shown in Table <ref type="table" coords="4,498.17,606.54,4.09,9.46" target="#tab_4">5</ref>, and during each submission, we use all available data, which including the training data of this task and the training along with testing data in previous editions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Single-Label Experiments</head><p>When we participate in the 2019-A edition, we did experiments on 2018 labeled data for tuning hyperparameters. In the setting of 2018 edition, we only need to predict one label for each tweet, and it is much easier to implement those explorations we mentioned in Section 3.2 with the scikit-learn framework. As the dataset is a little bit skewed, we use stratified K-fold cross-validation.</p><p>There are a lot of features that could be used as described in Section 3.1, so we did an ablation study (Table <ref type="table" coords="5,131.87,688.12,4.54,9.46" target="#tab_6">6</ref>) to explore the influence of each feature by gradually adding features one by one. There are multiple candidates when it comes to choosing a model to do the classification, and we have explored the performance of them with different settings in PCA and event-wise prediction (Table <ref type="table" coords="5,338.71,489.32,3.94,9.46" target="#tab_5">7</ref>). The evolving procedure of our model (Table <ref type="table" coords="5,337.96,502.87,4.54,9.46" target="#tab_7">8</ref>) shows that tuning hyper-parameters and using event-wise prediction helps a lot, and the Random Forest is really powerful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-label Experiments</head><p>It is easy to implement stratified K-fold splitting in the one-label setting. However, it is not trivial to do so in the multi-label setting, and 'stratified-KFold' in scikit-learn doesn't support multi-label setting. To cope with it, we implement a stratified sampling algorithm for the multi-label data based on the work of Sechidis et al. <ref type="bibr" coords="5,454.61,659.49,70.93,9.46;5,307.28,673.03,23.48,9.46" target="#b22">(Sechidis et al., 2011)</ref>, which can achieve nearly perfect ratio of each label, such as 4:1 for 5-fold sampling. To get a comparable result, we use the official V3 evaluation script released for TREC-IS 2019-A task.</p><p>For the event-wise prediction, it is interesting that this strategy brings improvements as shown in in the multi-label prediction (as shown in Table <ref type="table" coords="6,278.45,659.17,3.94,9.46" target="#tab_8">9</ref>). It can be explained by the fact that for each type of event, the number of training data is much smaller, and some minor type of event even doesn't have all information types in its training set. The official evaluation results on 2019-B test data for those four runs we submitted could be found in Table <ref type="table" coords="6,140.26,755.86,4.09,9.46" target="#tab_2">3</ref>. The evaluation result on 2019-A test data for those four settings we submitted is shown in Table <ref type="table" coords="6,377.26,206.14,4.09,9.46" target="#tab_3">4</ref>. We also explored the influence of the additional weights for actionable information types, and the experimental results on 2019-A test data could be found in Table <ref type="table" coords="6,457.84,246.79,9.09,9.46" target="#tab_9">10</ref>, 11, and 12. 'Weight' means additional weight for the actionable information type during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We have described CMU-Informedia's models for the TREC 2019 Incident Streams track. Our models achieve good performance for information type classification and demonstrate strong potential to identify important tweet feeds. We observe that the generalizability remains a challenging issue as the model-wise performance is inconsistent among tasks. We consider incorporating multimodal information and building a generalizable model as our future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,84.62,67.49,428.31,226.56"><head>Table 2 :</head><label>2</label><figDesc>The configuration of different submissions.</figDesc><table coords="5,84.62,67.49,428.31,226.56"><row><cell>Submission Name</cell><cell></cell><cell></cell><cell>Model</cell><cell cols="2">Additional Weight</cell><cell></cell><cell cols="2">Importance Score</cell></row><row><cell cols="4">Informedia-rf1 (run1) Random Forest</cell><cell></cell><cell>0.2</cell><cell></cell><cell cols="2">Only Regression</cell></row><row><cell cols="4">Informedia-rf2 (run2) Random Forest</cell><cell></cell><cell>1.0</cell><cell cols="3">Half Prediction + Half Regression</cell></row><row><cell cols="4">Informedia-rf3 (run3) Random Forest</cell><cell></cell><cell>5.0</cell><cell cols="3">Half Prediction + Half Regression</cell></row><row><cell cols="2">Informedia-nb (run4)</cell><cell cols="2">Naive Bayes</cell><cell></cell><cell>NA</cell><cell></cell><cell cols="2">Only Regression</cell></row><row><cell>Run id</cell><cell cols="2">HIAW</cell><cell>AAW</cell><cell>HIITF1</cell><cell>ITF1</cell><cell>ITA</cell><cell>PEEHI</cell><cell>PEE</cell></row><row><cell>run1</cell><cell cols="8">-0.9794 -0.4897 0.0300 0.1370 0.8638 0.1192 0.0665</cell></row><row><cell cols="9">run1-fix -0.9197 -0.4609 0.0300 0.1390 0.8659 0.0815 0.0551</cell></row><row><cell>run2</cell><cell cols="8">-0.8323 -0.4224 0.0642 0.1283 0.8624 0.1025 0.0683</cell></row><row><cell>run3</cell><cell cols="8">-0.0898 -0.1837 0.0592 0.0568 0.8434 0.1660 0.2063</cell></row><row><cell>run4</cell><cell cols="8">-0.9197 -0.4609 0.1321 0.0995 0.8605 0.0788 0.0544</cell></row><row><cell cols="9">run4-fix -0.9197 -0.4609 0.1559 0.1012 0.8601 0.0788 0.0544</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,72.00,309.31,453.55,129.79"><head>Table 3 :</head><label>3</label><figDesc>Official evaluation result for the four runs we submitted. The run id with '-fix' suffix is the result of the new hyper-parameter after making the metric in the cross-validation consistent with the official metrics.</figDesc><table coords="5,130.09,364.21,337.37,74.89"><row><cell cols="2">Run id HIAW</cell><cell>AAW</cell><cell>HIITF1</cell><cell>ITF1</cell><cell>ITA</cell><cell>PEEHI</cell><cell>PEE</cell></row><row><cell>run1</cell><cell cols="2">-0.9905 -0.4953</cell><cell>0.057</cell><cell cols="4">0.1309 0.8518 0.0855 0.0647</cell></row><row><cell>run2</cell><cell cols="7">-0.6196 -0.3338 0.0402 0.1136 0.8445 0.1307 0.0775</cell></row><row><cell>run3</cell><cell cols="2">0.2533 -0.2159</cell><cell>0.061</cell><cell cols="4">0.0731 0.8268 0.243 0.3798</cell></row><row><cell>run4</cell><cell cols="7">-0.9905 -0.4953 0.0372 0.1752 0.8449 0.0856 0.0648</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,95.11,454.37,392.35,94.40"><head>Table 4 :</head><label>4</label><figDesc>Evaluation result on 2019-A test data with settings of four runs we submitted.</figDesc><table coords="5,95.11,490.14,172.05,58.63"><row><cell cols="3">Task Name Training Size Test Size</cell></row><row><cell>2018</cell><cell>1,335</cell><cell>22,216</cell></row><row><cell>2019-A</cell><cell>NA</cell><cell>6,134</cell></row><row><cell>2019-B</cell><cell>NA</cell><cell>13,916</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,72.00,564.04,218.27,23.01"><head>Table 5 :</head><label>5</label><figDesc>Number of tweets in each dataset after removing duplicates.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,307.28,755.86,218.27,9.46"><head>Table 7 ,</head><label>7</label><figDesc>but it hurts the performance significantly Feature Used Precision Recall F 1 score Accuracy</figDesc><table coords="6,166.27,84.14,259.18,58.24"><row><cell>MetaInfo</cell><cell>0.3875</cell><cell>0.6395 0.4825</cell><cell>0.3359</cell></row><row><cell>+ FastText</cell><cell>0.4057</cell><cell>0.6692 0.5051</cell><cell>0.3534</cell></row><row><cell>+ BERT</cell><cell>0.4144</cell><cell>0.6792 0.5147</cell><cell>0.3616</cell></row><row><cell>+ SkipThought</cell><cell>0.4257</cell><cell>0.6887 0.5261</cell><cell>0.3735</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,72.00,157.64,428.84,420.50"><head>Table 6 :</head><label>6</label><figDesc>Ablation Study for features on TREC-IS 2018 data for 'any valid type' and 'micro'.</figDesc><table coords="6,72.00,193.07,218.27,385.08"><row><cell>System</cell><cell>Event-wise</cell><cell>PCA</cell><cell>F 1 score</cell></row><row><cell>NB</cell><cell>no</cell><cell cols="2">without 0.6768</cell></row><row><cell>NB</cell><cell>no</cell><cell>with</cell><cell>0.6936</cell></row><row><cell>NB</cell><cell>yes</cell><cell cols="2">without 0.7047</cell></row><row><cell>NB</cell><cell>yes</cell><cell>with</cell><cell>0.8763</cell></row><row><cell>SVM</cell><cell>no</cell><cell>with</cell><cell>0.6934</cell></row><row><cell>SVM</cell><cell>no</cell><cell cols="2">without 0.7496</cell></row><row><cell>RF</cell><cell>no</cell><cell cols="2">without 0.7775</cell></row><row><cell>RF</cell><cell>no</cell><cell>with</cell><cell>0.7845</cell></row><row><cell>XGBoost</cell><cell>no</cell><cell cols="2">without 0.8032</cell></row><row><cell>XGBoost</cell><cell>no</cell><cell>with</cell><cell>0.8062</cell></row><row><cell cols="4">Table 7: Explore the performance for different</cell></row><row><cell cols="4">models with different settings. Here 'NB' means</cell></row><row><cell cols="4">Naive Bayes, 'SVM' means Linear SVM, 'RF'</cell></row><row><cell cols="2">means Random Forest.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>System</cell><cell></cell><cell>F 1 score</cell></row><row><cell cols="3">NB with MetaInfo (Baseline)</cell><cell>0.4825</cell></row><row><cell cols="2">Use all features</cell><cell></cell><cell>0.5609</cell></row><row><cell cols="2">Use Event-wise</cell><cell></cell><cell>0.6146</cell></row><row><cell cols="3">Tune params of NB</cell><cell>0.6709</cell></row><row><cell cols="4">Use Event-wise for new params 0.7047</cell></row><row><cell cols="3">Use Random Forest</cell><cell>0.7783</cell></row><row><cell cols="2">Use Event-wise</cell><cell></cell><cell>0.7961</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,72.00,593.41,218.27,36.56"><head>Table 8 :</head><label>8</label><figDesc>The evolve history of our model guided by the performance on TREC-IS 2018 data ('NB' means 'Naive Bayes Model').</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,80.75,67.49,436.05,209.51"><head>Table 9 :</head><label>9</label><figDesc>The influence of event-wise prediction in multi-label experiments.</figDesc><table coords="7,80.75,67.49,436.05,209.51"><row><cell></cell><cell cols="2">Event-wise HIAW</cell><cell>AAW</cell><cell>HIITF1</cell><cell>ITF1</cell><cell>ITA</cell><cell>PEEHI</cell><cell>PEE</cell></row><row><cell>Naive Bayes</cell><cell>No</cell><cell cols="6">-0.9197 -0.4609 0.1321 0.0995 0.8605 0.1773 0.0758</cell></row><row><cell>Naive Bayes</cell><cell>Yes</cell><cell cols="6">-0.9774 -0.4887 0.0907 0.1228 0.8560 0.1939 0.1092</cell></row><row><cell>Random Forest</cell><cell>No</cell><cell cols="6">-0.9905 -0.4953 0.0570 0.1309 0.8518 0.1836 0.0913</cell></row><row><cell>Random Forest</cell><cell>Yes</cell><cell cols="6">-0.9674 -0.4857 0.0032 0.0696 0.8435 0.1831 0.1040</cell></row><row><cell cols="2">Weight HIAW</cell><cell>AAW</cell><cell>HIITF1</cell><cell>ITF1</cell><cell>ITA</cell><cell>PEEHI</cell><cell>PEE</cell></row><row><cell>0.2</cell><cell cols="2">-0.9942 -0.4971</cell><cell>0.057</cell><cell cols="4">0.1309 0.8518 0.1836 0.0913</cell></row><row><cell>0.5</cell><cell cols="7">-0.7357 -0.4047 0.0404 0.1296 0.849 0.1556 0.0715</cell></row><row><cell>1.0</cell><cell cols="7">-0.466 -0.3201 0.0402 0.1136 0.8445 0.1393 0.0700</cell></row><row><cell>5.0</cell><cell cols="7">0.2533 -0.2197 0.0610 0.0731 0.8268 0.1565 0.1722</cell></row><row><cell>10.0</cell><cell cols="3">0.2795 -0.2412 0.0684</cell><cell cols="4">0.056 0.8213 0.1928 0.2500</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="7,72.00,292.26,453.55,116.24"><head>Table 10 :</head><label>10</label><figDesc>Evaluation results on 2019-A test data for Random Forest model with different additional weights using predicted information types to get importance scores.</figDesc><table coords="7,129.16,333.61,339.22,74.89"><row><cell cols="2">Weight HIAW</cell><cell>AAW</cell><cell>HIITF1</cell><cell>ITF1</cell><cell>ITA</cell><cell>PEEHI</cell><cell>PEE</cell></row><row><cell>0.2</cell><cell cols="2">-0.9942 -0.4971</cell><cell>0.057</cell><cell cols="4">0.1309 0.8518 0.1129 0.0615</cell></row><row><cell>0.5</cell><cell cols="7">-0.9942 -0.4972 0.0404 0.1296 0.849 0.1447 0.0642</cell></row><row><cell>1.0</cell><cell cols="7">-0.6196 -0.3338 0.0402 0.1136 0.8445 0.1307 0.0775</cell></row><row><cell>5.0</cell><cell cols="7">0.2533 -0.2159 0.0610 0.0731 0.8268 0.2430 0.3798</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="7,72.00,423.77,453.55,83.72"><head>Table 11 :</head><label>11</label><figDesc>Evaluation results on 2019-A test data for Random Forest model with different additional weights using predicted information types and regression scores to get importance scores.</figDesc><table coords="7,129.16,465.11,339.22,42.37"><row><cell cols="2">Weight HIAW</cell><cell>AAW</cell><cell>HIITF1</cell><cell>ITF1</cell><cell>ITA</cell><cell>PEEHI</cell><cell>PEE</cell></row><row><cell>0.2</cell><cell cols="2">-0.9905 -0.4953</cell><cell>0.057</cell><cell cols="4">0.1309 0.8518 0.0855 0.0647</cell></row><row><cell>0.5</cell><cell cols="7">-0.9905 -0.4953 0.0404 0.1296 0.8490 0.0855 0.0647</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="7,72.00,522.75,453.55,23.01"><head>Table 12 :</head><label>12</label><figDesc>Evaluation results on 2019-A test data for Random Forest model with different additional weights using regression scores to get importance scores.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>The work reported here was supported in part through the financial assistance award <rs type="grantNumber">60NANB17D156</rs> from <rs type="funder">U.S. Department of Commerce, National Institute of Standards and Technology</rs> and by <rs type="funder">DARPA</rs> grant <rs type="grantNumber">FA8750-18-2-0018</rs> funded under the <rs type="programName">AIDA program</rs>. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation herein. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of <rs type="affiliation">DARPA</rs>, <rs type="institution">DOI/IBC</rs>, or the <rs type="institution">U.S. Government</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_P3Pacby">
					<idno type="grant-number">60NANB17D156</idno>
				</org>
				<org type="funding" xml:id="_86VZQZ4">
					<idno type="grant-number">FA8750-18-2-0018</idno>
					<orgName type="program" subtype="full">AIDA program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,307.28,734.56,218.27,8.64;6,318.19,745.52,207.36,8.64;6,318.19,756.30,152.17,8.82" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,420.55,745.52,105.00,8.64;6,318.19,756.48,95.73,8.64">Tweedr: Mining twitter to inform disaster response</title>
		<author>
			<persName coords=""><forename type="first">Zahra</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manojit</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ISCRAM</note>
</biblStruct>

<biblStruct coords="7,72.00,571.87,218.27,8.64;7,82.91,582.83,207.36,8.64;7,82.91,593.61,207.36,8.82;7,82.91,604.57,188.21,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,176.55,582.83,113.72,8.64;7,82.91,593.79,82.74,8.64">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,175.35,593.61,114.92,8.59;7,82.91,604.57,136.76,8.59">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,626.10,218.27,8.64;7,82.91,636.88,207.36,8.82;7,82.91,647.84,207.36,8.59;7,82.91,658.80,207.36,8.82;7,82.91,669.94,24.79,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,241.67,626.10,48.60,8.64;7,82.91,637.06,114.53,8.64">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName coords=""><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,216.10,636.88,74.17,8.59;7,82.91,647.84,207.36,8.59;7,82.91,658.80,133.43,8.59">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd acm sigkdd international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,691.29,218.27,8.64;7,82.91,702.25,207.36,8.64;7,82.91,713.03,26.85,8.59" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,110.45,702.25,162.67,8.64">Cbnu at trec 2018 incident streams track</title>
		<author>
			<persName coords=""><forename type="first">Wongyu</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Seung-Hyeon</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyung-Soon</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="7,72.00,734.56,218.27,8.64;7,82.91,745.52,207.36,8.64;7,82.91,756.48,207.36,8.64;7,318.19,571.87,207.36,8.64;7,318.19,582.65,92.69,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,180.45,745.52,109.82,8.64;7,82.91,756.48,207.36,8.64;7,318.19,571.87,207.36,8.64;7,318.19,582.83,47.76,8.64">Neural networks and support vector machine based approach for classifying tweets by information types at trec 2018 incident streams task</title>
		<author>
			<persName coords=""><forename type="first">Abu</forename><surname>Nowshed Chy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Umme</forename><surname>Aymun Siddiqua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Masaki</forename><surname>Aono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,384.03,582.65,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,607.83,218.27,8.64;7,318.19,618.79,207.36,8.64;7,318.19,629.75,207.36,8.64;7,318.19,640.53,160.76,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,433.89,629.75,91.66,8.64;7,318.19,640.71,115.42,8.64">Sinai at trec 2018: Experiments in incident streams</title>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><surname>Ángel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">García</forename><surname>Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Carlos Díaz-Galiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><forename type="middle">García</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Salud</forename><surname>María</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiménez</forename><surname>Zafra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,452.10,640.53,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,665.72,218.27,8.64;7,318.19,676.68,207.36,8.64;7,318.19,687.64,207.36,8.64;7,318.19,698.42,153.48,8.82" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="7,424.19,676.68,101.36,8.64;7,318.19,687.64,207.36,8.64;7,318.19,698.60,11.42,8.64">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,307.28,723.60,218.27,8.64;7,318.19,734.56,207.36,8.64;7,318.19,745.34,207.36,8.82;7,318.19,756.48,24.07,8.64" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,352.30,734.56,173.25,8.64;7,318.19,745.52,110.79,8.64">Twitter earthquake detection: earthquake monitoring in a social world</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Paul S Earle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michelle</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Guy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,436.84,745.34,84.30,8.59">Annals of Geophysics</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,67.28,218.27,8.64;8,82.91,78.24,207.36,8.64;8,82.91,89.20,207.36,8.64;8,82.91,99.98,207.35,8.82;8,82.91,110.94,207.36,8.59;8,82.91,122.08,207.36,8.64;8,82.91,133.04,24.79,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,243.22,78.24,47.05,8.64;8,82.91,89.20,207.36,8.64;8,82.91,100.16,54.65,8.64">Multimodal filtering of social media for temporal monitoring and event analysis</title>
		<author>
			<persName coords=""><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Baptiste</forename><surname>Lamare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<idno type="DOI">10.1145/3206025.3206079</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,156.75,99.98,133.51,8.59;8,82.91,110.94,207.36,8.59;8,82.91,122.08,41.10,8.64">Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval, ICMR &apos;18</title>
		<meeting>the 2018 ACM on International Conference on Multimedia Retrieval, ICMR &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="450" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,154.84,218.27,8.64;8,82.91,165.80,207.36,8.64;8,82.91,176.76,207.36,8.64;8,82.91,187.54,207.36,8.82;8,82.91,198.50,207.36,8.59;8,82.91,209.46,207.36,8.82;8,82.91,220.60,113.18,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,197.18,165.80,93.09,8.64;8,82.91,176.76,207.36,8.64;8,82.91,187.72,166.15,8.64">Improving what crossmodal retrieval models learn through object-oriented inter-and intra-modal attention networks</title>
		<author>
			<persName coords=""><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaojun</forename><surname>Vaibhav</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hauptmann</surname></persName>
		</author>
		<idno type="DOI">10.1145/3323873.3325043</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,272.46,187.54,17.81,8.59;8,82.91,198.50,207.36,8.59;8,82.91,209.46,134.78,8.82">Proceedings of the 2019 on International Conference on Multimedia Retrieval, ICMR &apos;19</title>
		<meeting>the 2019 on International Conference on Multimedia Retrieval, ICMR &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="244" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,242.40,218.27,8.64;8,82.91,253.36,207.36,8.64;8,82.91,264.14,192.77,8.82" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,175.16,253.36,115.11,8.64;8,82.91,264.32,50.88,8.64">Bag of tricks for efficient text classification</title>
		<author>
			<persName coords=""><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,72.00,286.13,218.27,8.64;8,82.91,297.09,207.36,8.64;8,82.91,308.05,207.36,8.64;8,82.91,318.83,207.36,8.59;8,82.91,329.96,72.50,8.64" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,187.05,308.05,83.10,8.64">Skip-thought vectors</title>
		<author>
			<persName coords=""><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,82.91,318.83,203.24,8.59">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,351.77,218.27,8.64;8,82.91,362.73,207.36,8.64;8,82.91,373.69,207.36,8.64;8,82.91,384.47,207.36,8.59;8,82.91,395.43,53.13,8.59" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,216.63,362.73,73.64,8.64;8,82.91,373.69,191.97,8.64">Tweettracker: An analysis tool for humanitarian and disaster relief</title>
		<author>
			<persName coords=""><forename type="first">Shamanth</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Barbier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammad</forename><surname>Ali Abbasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,82.91,384.47,207.36,8.59;8,82.91,395.43,48.66,8.59">Fifth international AAAI conference on weblogs and social media</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,417.42,218.27,8.64;8,82.91,428.20,178.39,8.82" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<idno>arXiv preprint cs/0205028</idno>
		<title level="m" coord="8,224.86,417.42,65.41,8.64;8,82.91,428.37,63.40,8.64">Nltk: the natural language toolkit</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,450.18,218.27,8.64;8,82.91,460.96,174.90,8.82" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,263.36,450.18,26.91,8.64;8,82.91,461.14,129.94,8.64">Bjut at trec 2018: Incident streams track</title>
		<author>
			<persName coords=""><forename type="first">Ning</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hesong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="8,72.00,482.95,218.27,8.64;8,82.91,493.91,207.36,8.64;8,82.91,504.87,106.81,8.64" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cody</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<title level="m" coord="8,109.64,493.91,180.63,8.64;8,82.91,504.87,102.34,8.64">Trec incident streams: Finding actionable information on social media</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,526.67,218.27,8.64;8,82.91,537.63,207.36,8.64;8,82.91,548.59,207.36,8.64;8,82.91,559.37,207.36,8.82;8,82.91,570.33,107.91,8.82" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,198.04,537.63,92.23,8.64;8,82.91,548.59,207.36,8.64;8,82.91,559.55,9.27,8.64">Distributed representations words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,114.31,559.37,175.96,8.59;8,82.91,570.33,28.81,8.59">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,592.32,218.27,8.64;8,82.91,603.28,207.36,8.64;8,82.91,614.06,131.15,8.82" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,208.75,603.28,81.52,8.64;8,82.91,614.23,86.19,8.64">Nhk strl at trec 2018 incident streams track</title>
		<author>
			<persName coords=""><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kiminobu</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuka</forename><surname>Takei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hiroki</forename><surname>Okamoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,187.21,614.06,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,636.04,218.27,8.64;8,82.91,647.00,207.36,8.64;8,82.91,657.96,207.36,8.64;8,82.91,668.92,207.36,8.64;8,82.91,679.70,207.36,8.82;8,82.91,690.66,156.28,8.82" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,241.02,668.92,49.26,8.64;8,82.91,679.88,113.58,8.64">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,209.80,679.70,80.47,8.59;8,82.91,690.66,68.66,8.59">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">2011. Oct</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,712.64,218.27,8.64;8,82.91,723.60,207.36,8.64;8,82.91,734.38,207.36,8.82;8,82.91,745.34,207.36,8.59;8,82.91,756.30,148.59,8.82" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,156.85,723.60,133.42,8.64;8,82.91,734.56,55.00,8.64">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,159.45,734.38,130.82,8.59;8,82.91,745.34,207.36,8.59;8,82.91,756.30,68.38,8.59">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,307.28,67.28,218.27,8.64;8,318.19,78.24,207.36,8.64;8,318.19,89.20,207.36,8.64;8,318.19,99.98,207.36,8.82;8,318.19,110.94,94.37,8.82" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,455.75,78.24,69.80,8.64;8,318.19,89.20,207.36,8.64;8,318.19,100.16,69.25,8.64">Robust detection of extreme events using twitter: worldwide earthquake monitoring</title>
		<author>
			<persName coords=""><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jheser</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jazmine</forename><surname>Maldonado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Felipe</forename><surname>Tobar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,397.03,99.98,128.52,8.59;8,318.19,110.94,11.42,8.59">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2551" to="2561" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,307.28,131.04,218.27,8.64;8,318.19,142.00,207.36,8.64;8,318.19,152.78,207.36,8.82;8,318.19,163.74,207.36,8.59;8,318.19,174.70,207.35,8.82;8,318.19,185.84,32.38,8.64" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,386.63,142.00,138.92,8.64;8,318.19,152.96,88.17,8.64">Negation scope detection for twitter sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">Johan</forename><surname>Reitan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jørgen</forename><surname>Faret</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Björn</forename><surname>Gambäck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lars</forename><surname>Bungum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,431.28,152.78,94.27,8.59;8,318.19,163.74,207.36,8.59;8,318.19,174.70,176.81,8.59">Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,307.28,205.76,218.27,8.64;8,318.19,216.72,207.36,8.64;8,318.19,227.50,207.36,8.82;8,318.19,238.46,207.36,8.59;8,318.19,249.42,148.32,8.82" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="8,429.03,216.72,96.52,8.64;8,318.19,227.68,64.07,8.64">On the stratification of multi-label data</title>
		<author>
			<persName coords=""><forename type="first">Konstantinos</forename><surname>Sechidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,411.31,227.50,114.23,8.59;8,318.19,238.46,207.36,8.59;8,318.19,249.42,40.10,8.59">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="145" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,307.28,269.52,218.27,8.64;8,318.19,280.48,207.36,8.64;8,318.19,291.44,207.36,8.64;8,318.19,302.22,127.60,8.82" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="8,380.11,280.48,145.43,8.64;8,318.19,291.44,207.36,8.64;8,318.19,302.40,82.38,8.64">Dice @ trec-is 2018: Combining knowledge graphs and deep learning to identify crisis-relevant tweets</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hamada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rricha</forename><surname>Zahera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ricardo</forename><surname>Jalota</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Usbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,418.94,302.22,21.48,8.59">TREC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,307.28,322.33,218.27,8.64;8,318.19,333.28,207.36,8.64;8,318.19,344.24,207.36,8.64;8,318.19,355.20,207.36,8.64;8,318.19,365.98,207.36,8.82;8,318.19,376.94,207.36,8.82;8,318.19,388.08,27.40,8.64" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="8,457.50,322.33,68.04,8.64;8,318.19,333.28,207.36,8.64;8,318.19,344.24,22.07,8.64;8,374.17,344.24,151.37,8.64;8,318.19,355.20,207.36,8.64;8,318.19,366.16,75.31,8.64">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName coords=""><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,420.98,365.98,104.57,8.59;8,318.19,376.94,177.72,8.59">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
	<note>Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
