<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,218.88,115.96,177.60,12.62;1,221.93,133.89,171.50,12.62">The CLaC System at the TREC 2019 News Track</title>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council of Canada</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,229.86,171.56,72.37,8.74"><forename type="first">Pavel</forename><surname>Khloponin</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,324.92,171.56,60.58,8.74"><forename type="first">Leila</forename><surname>Kosseim</surname></persName>
							<email>leila.kosseim@concordia.ca</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ClaC Lab Department of Computer Science and Software Engineering</orgName>
								<orgName type="department" key="dep2">School of Engineering and Computer Science</orgName>
								<orgName type="institution">Gina Cody</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Concordia University Montreal QC</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,218.88,115.96,177.60,12.62;1,221.93,133.89,171.50,12.62">The CLaC System at the TREC 2019 News Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C2C33A1085410FBAF3E5D4936E255B24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>News TREC</term>
					<term>Doc2Vec</term>
					<term>Cosine similarity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approach to the TREC 2019 News Track. The goal of the News Track is to provide background links and entity linking to target news articles within a collection of articles. Our approach first represents all articles in the collection using Doc2Vec embeddings then computes the cosine similarity between the target article with all other articles in the collection and outputs the 100 closest ones. Although simple, this approach allows minimum pre-processing and is agnostic to the content of the documents. The overall results of the shared tasks are below the median with a nDCG@5 of 0.4298, however, for specific topics, the approach achieved the best scores among all participating teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Given the sheer number of electronic sources of news available today, it is important to develop approaches for the automatic recommendation of contextual information for users to better understand a news article.</p><p>In order to address this need, since 2018, the News Track at TREC has proposed two related shared tasks: background linking and entity ranking <ref type="bibr" coords="1,437.94,524.61,42.65,8.74;1,134.77,536.57,112.55,8.74" target="#b0">(Soboroff, Huang, and Harman 2018)</ref>. The goal of the background linking task is to provide relevant background information to news articles through the identification of related articles. On the other hand, entity ranking focuses on providing a list of names, concepts, artifacts, etc. mentioned in news articles, which will help readers better understand the news. For our first participation to the News Track, we only participated to the first task: background linking.</p><p>For the 2019 background linking task, the data set provided by NIST consists of a collection of about 600,000 news articles from the Washington Post. Given a search topic, which is itself an article from the corpus selected by TREC organizers, participants need to select up to 100 related articles from the corpus and output them from the most related to the least related. For evaluation purposes, only the top 5 articles from each list are considered. A 5 point rank is manually assigned by NIST assessors for each of the top 5 articles during the evaluation step, where rank is between 0 (little or no useful information) and 4 (must appear in recommendations or critical context will be missed). The total score is based on the nDCG@5 <ref type="bibr" coords="2,272.91,166.81,136.70,8.74" target="#b1">(Järvelin and Kekäläinen 2002)</ref> metric with the gain metric 2 rank .</p><p>One important criteria for judging related articles is diversity. Because we did not have a clear understanding of the notion of article diversity in the news recommendation context we did not specifically address this aspect of the task.</p><p>For the official evaluation, 60 search topics were used. Prior to the evaluation, the organizers also provided 50 search topics and their corresponding manually evaluated results (that is, all articles evaluated manually with a rank from 0 to 4) from the TREC News 2018, which used the same article collection. We used these 50 topics and 8508 evaluated backlinks for validation purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Preprocessing</head><p>The TREC News 2019 organisers provided a document collection of 595,037 news articles from The Washington Post published between 2012 and 2017. This document collection was the same provided at the 2018 edition of the task but with exact duplicate articles removed. Each news article is stored in "JSONlines" format and represented as a single line of JSON. Each document contains 8 types of meta-information:</p><p>1. id 2. article URL 3. title 4. author 5. publication date 6. type (blog post or article) 7. news source 8. content field Apart from the id (#1) field, which was used for identification purposes, only the article title (#3) and the text extracted from the content field (#8) were considered. The title was prepended to the content and processed as a single document. The content itself was stored in a form of content blocks, where each content block can be a text paragraph, an image, a video, a tweet, a citation, etc. Each content block itself may contain meta-information (up to 133 different fields), such as MIME-type, type, kicker (category), content, subtype, source, URLs, etc. Based on this meta-information we identified blocks with frequently appearing content types and checked if they have any useful text descriptions, and kept for further processing only blocks with paragraphs, image captions, headers, and quotes. Blocks were further cleaned from embeds, links, images, and other HTML tags, preserving only plain text. NIST required participants to ignore wire articles, editorial content and opinion posts, which have "Opinion", "Letters to the Editor", or "The Post's View" values in the content meta-information block with type "kicker". Due to this, the initial set of 595,037 articles was reduced by 23,074 to 571,963 items. This is shown in Table <ref type="table" coords="3,214.02,292.79,3.87,8.74" target="#tab_0">1</ref>. As shown in Table <ref type="table" coords="3,231.95,632.21,3.87,8.74" target="#tab_0">1</ref>, many draft articles (content preview or articles demonstrating website functionality) were discovered during data exploration: 873 articles with URL path starting with "/test/wp/", presumably indicating content taken from the section of the website not intended to be public (content playground), and 81 document with "Lorem ipsum..." (common placeholder text) content in the article text. They were preserved in the dataset.</p><p>As shown in Table <ref type="table" coords="4,239.07,155.89,3.87,8.74" target="#tab_0">1</ref>, the 571,963 documents considered have an average length of 11,417 characters, but only 4,458 after pre-processing. Figure <ref type="figure" coords="4,446.98,167.84,4.98,8.74" target="#fig_0">1</ref> shows the distribution of the article lengths before and after pre-processing. Some articles composed almost entirely of meta-information and have very little text inside (short statements, video players, cited tweets, etc.), while others have very long texts (transcripts of debates, conferences, testimony, crime reports). As Figure <ref type="figure" coords="4,180.93,227.62,4.98,8.74" target="#fig_0">1</ref> shows, the majority have between 1,000 and 10,000 characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Representation</head><p>After pre-processing, we used the Doc2Vec distributed representation <ref type="bibr" coords="4,446.02,318.76,34.58,8.74;4,134.77,330.72,63.24,8.74" target="#b2">(Le and Mikolov 2014)</ref> to represent each document. The rational for this choice was our expectation that related articles would be closer to each other in vector space than unrelated articles. Hence, document vector distance would be a good approximation of document content relatedness. Search topics and manually ranked documents from 2018 (see Section 1) were used as a validation set to select among different combinations of parameters for text processing and model parameters. For creating the document vectors: stopwords were filtered using the NLTK English stopwords list <ref type="bibr" coords="4,282.98,414.41,129.57,8.74" target="#b3">(Bird, Klein, and Loper 2009)</ref>, numbers were replaced with the "NUM" token, and the text was case folded. Embeddings were built using Doc2Vec PV-DM embedding with 10 epochs. Using a different size of embeddings significantly changed the produced backlinks and their position in the list. Two different sizes for embeddings were selected: 100 and 300.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proximity Measure</head><p>After obtaining the embedding weights for the articles, the proximity between two documents vectors was computed. Due to lack of time and resources only the cosine distance was used. Given two document vectors α and β, the cosine of the angle θ between α and β is computed as:</p><formula xml:id="formula_0" coords="4,215.09,579.22,183.47,29.23">cos(θ) = α • β ||α||||β|| = n i=1 α i β i n i=1 α 2 i n i=1 β 2 i</formula><p>where values close to -1 will, hopefully, correspond to documents with opposite meaning, close to 0 to documents on uncorrelated topics and close 1 to documents with similar topics. The cosine value is directly used as the relevancy score in the final output of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Validation</head><p>In order to set the values of the various hyperparameters, the models were evaluated on with the 2018 data given. To evaluate our models, we generated the top 5 backlinks for each topic and computed nDCG@5 when compared with 2018 dataset. If a generated backlink was not in the 2018 validation set, we assigned it a rank of 0 (not relevant backlink) to calculate nDCG@5. As shown in Table <ref type="table" coords="5,475.61,186.10,4.98,8.74">2</ref> the model with embedding size of 100 dimensions achieved average an nDCG@5 of 0.3378, and with an embedding size of 300 dimensions achieved average an nDCG@5 of 0.3032. The fact that about 30% of the returned links did not appear in the validation set makes these numbers only lower bounds to the total scores they would have achieved. It also does not give us confidence about which of the models will perform better on the 2019 search topics.</p><p>The organizers reported that the top team reached the median nDCG@5 across all topics of about 0.45 <ref type="bibr" coords="5,268.31,281.74,160.91,8.74" target="#b0">(Soboroff, Huang, and Harman 2018)</ref>. The exact value for the median nDCG@5 performance across all teams was not reported in the overview paper. However, two papers from TREC 2018 News Track proceedings mentioned it to be equal to 0.3448 <ref type="bibr" coords="5,308.78,317.61,97.76,8.74" target="#b4">(Bimantara et al. 2018</ref>) and 0.2792 <ref type="bibr" coords="5,464.95,317.61,15.64,8.74;5,134.77,329.56,66.15,8.74" target="#b5">(Lu and Fang 2018)</ref>. It is not clear how this was calculated. Nevertheless, it gives a rough estimate for our model performance with this year data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>nDCG@5 clac 100 cos 0.3378 clac 300 cos 0.3032 Table <ref type="table" coords="5,270.02,417.73,4.13,7.89">2</ref>. Results with 2018 data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Submitted Runs</head><p>Two runs were submitted: clac 100 cos and clac 300 cos; based on the models described in Section 3.1 and the proximity measure from Section 3.2 with embeddings sizes 100 and 300 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Performance and Model Size</head><p>The models were built in python 3 with the Gensim library on a desktop computer with Intel R Core TM i7-7800X CPU @ 3.50GHz with 6 cores and 12 threads.</p><p>One epoch of training the model takes about 14 min. Hence the total training time for 10 epochs is about 2.5 hours. The model size on the disk takes 1.2GB. Generating results for 60 topics took 9 sec including 6 sec for the reading model to memory. On documents with pre-computed embeddings, the model was able to generate predictions for 28 topics per second for documents with known embedding vector and 16 topics per second for new articles including the generation of dense vectors. These low resource requirements make the model applicable in a production environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Official Scores</head><p>As indicated in Section 3.4, we have submitted two runs: clac 100 cos and clac 300 cos. For each topic, NIST provided us with our official scores as well as the minimum, maximum and median scores across all submitted runs. Full judgment data was not available at the time of writing this paper, but we can compare our runs with hypothetical participants with maximum, minimum and median scores for each topic. As shown in Table <ref type="table" coords="6,351.78,222.00,3.87,8.74">3</ref>, overall, both our runs performed below the collective median with scores of 0.4057 and 0.4298 compared to 0.5295. This was to be expected given the simplicity of the approach and our performance on the validation data from 2018 (see Section 3.3). However, surprisingly clac 300 cos performed better than clac 100 cos where as the results with the 2018 dataset predicted the opposite (see Table <ref type="table" coords="6,468.57,608.30,4.43,8.74">2</ref>)</p><p>Figure <ref type="figure" coords="6,181.54,620.25,4.98,8.74">2</ref> shows the scores for each topic, in decreasing order of the median score. Difficult topics for all participants appear on the left hand side of Figure <ref type="figure" coords="6,472.84,632.21,3.87,8.74">2</ref>, while easier topics are on the right-hand side. For a few topics our approach had the lowest performance among all runs (8 topics for clac 100 cos and 9 topics for clac 300 cos), they are all situated on the minimum line. On the other hand, for a few other topics, all points are situated on the maximum line (8 topics for clac 100 cos and 6 topics for clac 300 cos) hence we achieved the best performance among all News TREC runs.  Figure <ref type="figure" coords="7,182.15,632.21,4.98,8.74" target="#fig_2">3</ref> shows the scores per topic in increasing order of nDCG@5. This figure helps to compare our runs with the collective median and seems to show that clac 300 cos, in general, performs better than clac 100 cos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis</head><p>As shown in Figure <ref type="figure" coords="8,223.55,144.87,3.87,8.74">2</ref>, one of our best performance is for topic 859 (663c2790): Lottery sales, casino revenue a billion-dollar boon for Maryland. For this topic we achieved an nDCG@5 of 0.7713 for clac 100 cos and 0.7490 for clac 300 cos whereas the median was only 0.3381. The model's outputs for topic 859 are listed in Figure <ref type="figure" coords="8,176.66,192.69,3.87,8.74" target="#fig_3">4</ref>. All retrieved articles discuss revenue and bushiness related activities of casinos in specific geographic location, share the same narrative and keyword.  On the other hand, one of our worst performance is for topic 833 (0e43fce6): Worried about MERS in South Korea? Visitors can (mostly) breathe easy. For this topic we achieved an nDCG@5 of only 0.0625 for clac 100 cos and 0.0716 for clac 300 cos with the median being 0.74075. The produced backlinks are listed in Figure <ref type="figure" coords="8,204.37,431.24,3.87,8.74" target="#fig_4">5</ref>. Even though the search topic and produced backlinks have a very similar narrative and are discussing some kind of danger (terrorist attack, Ebola or MERS 1 ) localized geographically in a frame of traveling (planes, tickets, insurance) with medical personal (a nurse, a doctor or CDC 2 ) involved in the context, our system failed to build an important relation between the articles, which is connected to MERS. Only the last of the top 5 backlinks mention ID Score Title 9bd541d2 0.7270 Is it safe to travel to Paris and other European cities? 65612ad2 0.7017 The travel industry is taking precaution, but is it calming anxiety about disease? 46af8ae8 0.7006 Tips for traveling to Africa in the age of Ebola 4050a3da 0.6801 The most pressing summer travel questions answered 528fe4f7 0.6669 Why youre not going to get Ebola in the U.S. MERS. The cosine considers all vector dimensions to have the same importance in the distance calculation but this example seems to show that all dimensions should not necessarily have the same weight.</p><p>We also analysed content from the playground described in Section 2. Only 4 draft articles got into the submission files well below the cutoff line. We additionally discovered that many articles with the same URLs differ only in the last segment which is usually a number. These articles are either identical or have minor modifications or more details are provided. We assumed these numbers represented different versions of the same article. Hence, 36,359 articles could be additionally eliminated as duplicates based on these criteria. Unfortunately, this fact was discovered after the submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>This paper presented our model developed for the TREC 2019 News Track. The model uses a simple Doc2Vec representation and cosine similarity measure which allows for a plug and play approach with minimal tuning required. The model exploits the assumption that related articles should have close document vectors. However, the results of our runs seem to indicate that this assumption may not always hold as the model missed significant connections for the sake of extrinsic factors. The model could be more appropriate to look for near-duplicates and similar articles than backlinks or as a part of a more advanced pipeline. On the other hand, our models are very light-weight and only require 1.2GB space on disk and can generate backlinks for the entire collection in just 8 hours making it usable in a production setting. During the analysis of the results, it became obvious that the model is missing clues that could be obtained by giving more priority to named entities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,190.05,596.45,235.27,7.89;3,134.77,322.30,345.84,259.38"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Length distribution of the articles in the collection</figDesc><graphic coords="3,134.77,322.30,345.84,259.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,134.77,577.34,345.83,7.89;7,134.77,588.33,116.40,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Results sorted by nDCG@5 plotted on top of aggregated results (see Figure2), topics not necessarily match.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,134.77,338.04,345.82,7.89;8,134.77,349.67,53.85,7.47"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Top 5 backlinks for topic 859 (663c2790) with calculated cosine similarity score clac 100 cos</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,134.77,613.46,345.82,7.89;8,134.77,624.44,67.95,8.12;8,137.50,644.07,3.65,5.24;8,144.73,645.84,142.49,7.86;8,137.50,655.03,3.65,5.24;8,144.73,656.80,175.35,7.86"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Top 5 backlinks for topic 833 (663c2790) with calculated cosine similarity score for clac 100 cos 1 Middle East Respiratory Syndrome 2 Centers for Disease Control and Prevention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,170.04,117.78,272.20,113.02"><head>Table 1 .</head><label>1</label><figDesc>Statistics of the TREC News document collection</figDesc><table coords="3,170.04,117.78,272.20,92.15"><row><cell>original number of articles</cell><cell>595,037</cell></row><row><cell>near-duplicates</cell><cell>36,359 preserved</cell></row><row><cell>sandbox content</cell><cell>873 preserved</cell></row><row><cell>"lorem ipsum" articles</cell><cell>81 preserved</cell></row><row><cell>wire and opinion articles</cell><cell>23,074 removed</cell></row><row><cell>articles used to build the models</cell><cell>571,963</cell></row><row><cell>average size of article (characters)</cell><cell>11,714</cell></row><row><cell>average size after pre-processing (characters)</cell><cell>4,458</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was financially supported by a grant from the <rs type="funder">Natural Sciences and Engineering Research Council of Canada (NSERC)</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,134.77,561.34,345.82,8.74;9,149.71,573.29,330.39,9.30;9,149.71,585.25,43.72,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,405.26,561.34,75.33,8.74;9,149.71,573.29,38.76,8.74">2018 News Track Overview</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec27/papers/Overview-News.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,134.77,597.20,345.82,8.74;9,149.71,609.16,330.88,8.74;9,149.71,621.11,188.23,9.30" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,354.13,597.20,126.46,8.74;9,149.71,609.16,106.29,8.74">Cumulated Gain-based Evaluation of IR Techniques</title>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaana</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,286.04,609.16,194.55,8.74;9,149.71,621.11,32.36,8.74">ACM Transactions on Information Systems (TOIS)</title>
		<idno type="ISSN">1046-8188</idno>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.77,118.99,345.83,8.74;10,149.71,130.95,330.88,8.74;10,149.71,142.90,330.88,8.74;10,149.71,154.86,330.88,9.30;10,149.71,166.81,192.31,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,302.70,118.99,177.89,8.74;10,149.71,130.95,66.82,8.74">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v32/le14.html" />
	</analytic>
	<monogr>
		<title level="m" coord="10,247.96,130.95,232.63,8.74;10,149.71,142.90,75.82,8.74;10,428.62,142.90,51.97,8.74;10,149.71,154.86,169.81,8.74">Proceedings of the 31st International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tony</forename><surname>Jebara</surname></persName>
		</editor>
		<meeting>the 31st International Conference on Machine Learning<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research 2. Bejing</note>
</biblStruct>

<biblStruct coords="10,134.77,178.77,345.82,8.74;10,149.71,190.72,330.89,9.30" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,366.02,178.77,114.57,8.74;10,149.71,190.72,155.78,8.74">Natural Language Processing with Python. 1st. O&apos;Reilly Media</title>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">9780596516499</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.77,202.68,345.83,9.30;10,149.71,214.64,249.90,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="10,276.43,202.68,156.24,8.74">htw saar @ TREC 2018 News Track</title>
		<author>
			<persName coords=""><forename type="first">Agra</forename><surname>Bimantara</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec27/papers/htwsaar-N.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,134.77,226.59,345.82,8.74;10,149.71,238.55,330.88,9.30;10,149.71,250.50,105.95,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,293.74,226.59,186.85,8.74;10,149.71,238.55,127.17,8.74">Paragraph as Lead -Finding Background Documents for News Articles</title>
		<author>
			<persName coords=""><forename type="first">Kuang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec27/papers/udelfang-N.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
