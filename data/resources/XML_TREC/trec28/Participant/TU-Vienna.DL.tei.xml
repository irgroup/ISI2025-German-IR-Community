<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.65,84.78,302.08,15.44;1,146.35,104.70,319.29,15.44">TU Wien @ TREC Deep Learning &apos;19 -Simple Contextualization for Re-ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,93.05,134.86,98.82,10.59"><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
							<email>s.hofstaetter@tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.97,134.86,87.28,10.59"><forename type="first">Markus</forename><surname>Zlabinger</surname></persName>
							<email>markus.zlabinger@tuwien.ac.at</email>
							<affiliation key="aff1">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,433.97,134.86,73.25,10.59"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
							<email>hanbury@ifs.tuwien.ac.at</email>
							<affiliation key="aff2">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.65,84.78,302.08,15.44;1,146.35,104.70,319.29,15.44">TU Wien @ TREC Deep Learning &apos;19 -Simple Contextualization for Re-ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">04DCD099D98E3CA6C1F157D287BAF3B9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The usage of neural network models puts multiple objectives in conflict with each other: Ideally we would like to create a neural model that is effective, efficient, and interpretable at the same time. However, in most instances we have to choose which property is most important to us. We used the opportunity of the TREC 2019 Deep Learning track to evaluate the effectiveness of a balanced neural re-ranking approach. We submitted results of the TK (Transformer-Kernel) model: a neural re-ranking model for ad-hoc search using an efficient contextualization mechanism. TK employs a very small number of lightweight Transformer layers to contextualize query and document word embeddings. To score individual term interactions, we use a document-length enhanced kernel-pooling, which enables users to gain insight into the model. Our best result for the passage ranking task is: 0.420 MAP, 0.671 nDCG, 0.598 P@10 (TUW19-p3 full). Our best result for the document ranking task is: 0.271 MAP, 0.465 nDCG, 0.730 P@10 (TUW19-d3 re-ranking).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Our aim in the TREC 2019 Deep Learning track was to evaluate a neural re-ranking model, which balances efficiency, effectiveness, and interpretability. We submitted runs for both the passage and document ranking tasks of the Deep Learning track. We present the TK (Transformer-Kernel) model -inspired by the success of the Transformer-based BERT model <ref type="bibr" coords="1,192.69,455.57,9.44,7.94" target="#b2">[3,</ref><ref type="bibr" coords="1,205.02,455.57,7.42,7.94" target="#b8">9]</ref> and the simplicity of KNRM (Kernel-based Neural Ranking Model) <ref type="bibr" coords="1,228.49,466.53,13.49,7.94" target="#b13">[14]</ref>. TK employs a small number of low-dimensional Transformer layers <ref type="bibr" coords="1,268.49,477.48,14.85,7.94" target="#b12">[13]</ref> to contextualize query and document word embeddings. TK scores the interactions of the contextualized representations with simple, yet effective soft-histograms based on the kernel-pooling technique <ref type="bibr" coords="1,75.63,521.32,13.22,7.94" target="#b13">[14]</ref>. Additionally, we enhance kernel-pooling with document length normalization (Section 2).</p><p>The main differences of TK in comparison to BERT are:</p><p>• TK's contextualization uses fewer and lower dimensional Transformer layers with less attention heads. This makes the query-time inference of TK with 2 layers 40 times faster than BERT-Base with 12 layers. • TK contextualizes query and document sequences independently; each contextualized term is represented by a single vector (available for analysis). BERT operates on a concatenated sequence of the query and the document, entangling the representations in each layer. • The network structure of TK makes it possible to analyze the model for interpretability and further studies. TK has an information bottleneck built in, through which all term information is distilled: the query and document term interactions happen in a single match matrix, containing exactly one cosine similarity value for each term pair. BERT on the other hand has a continuous stream of interactions in each layer and each attention head, making a focused analysis unfeasible.</p><p>The differences of TK to previous kernel-pooling methods are:</p><p>• KNRM uses only word embeddings, therefore a match does not have context or positional information. • CONV-KNRM <ref type="bibr" coords="1,395.02,263.73,10.42,7.94" target="#b1">[2]</ref> uses a local-contextualization with limited positional information in the form of n-gram learning with CNNs. It cross-matches all n-grams in n 2 match matrices, reducing the analyzability.</p><p>Naturally, better efficiency and a restricted information flow through the network comes at the cost of effectiveness. This brings us to our main research question for our participation at TREC'19: How effective is our balanced model? To investigate this question we submitted multiple configurations of the TK model. We evaluate a GloVe embedding vs. a FastText embedding, an ensemble of multiple model instances, and a windowed-kernel-pooling for the longer document ranking.</p><p>In addition to a presentation and discussion of our TREC run results (Section 3) we showcase the analysis and interpretation capabilities of the TK model. We focus on the scenario in which a user would like to understand, for a given query, why two documents are ranked differently. We start by visualizing the word-level similarities (the interaction features) and then we report a limited number of aggregated intermediate results of important kernels (Section 4).</p><p>We publish the source code of the TK model and various neural reranking baselines at github.com/sebastian-hofstaetter/transformerkernel-ranking. The repository contains all pre-processing and evaluation code, as well as clear and documented neural network implementations using PyTorch <ref type="bibr" coords="1,427.11,529.90,14.72,7.94" target="#b9">[10]</ref> and AllenNLP <ref type="bibr" coords="1,497.74,529.90,9.39,7.94" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TK: TRANSFORMER-KERNEL MODEL</head><p>In this section, we present TK, our Transformer-Kernel neural reranking model. In the following, we describe how we learn contextualized term representations (Section 2.1) and how we transparently score their interactions (Section 2.2). Figure <ref type="figure" coords="1,477.21,598.94,4.11,7.94" target="#fig_1">1</ref> gives an overview of TK's architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Contextualized Term Representation</head><p>TK uses a hybrid contextualization approach. The base representations are single-vector-per-word embeddings <ref type="bibr" coords="1,496.47,657.01,13.49,7.94" target="#b10">[11]</ref>. We chose a simple word embedding structure over more complex methodssuch as FastText <ref type="bibr" coords="1,379.13,678.93,10.46,7.94" target="#b0">[1]</ref> or ELMo <ref type="bibr" coords="1,425.52,678.93,14.63,7.94" target="#b11">[12]</ref> -as it offers the following benefits in practice: Word embeddings are easy to pre-train on domain specific data <ref type="bibr" coords="1,367.40,700.85,9.63,7.94" target="#b5">[6]</ref>; they require only one id per term, making the  ○ Each kernel creates a new feature matrix. Then, the document dimension is summed and we normalize each query-term feature by logarithm and document length. 4</p><p>○ We combine log-and length-normalized scores to form the final result score.</p><p>index consume less disk space, once prepared for re-ranking; most importantly, at query time, their selection is a fast memory lookup.</p><p>In the contextualization phase of the TK model, we process query q 1:m and document sequences d 1:n separately, however the learned parameters are shared. The input consists of two sequences of query and document ids. We employ the lookup based word embedding to select non-contextualized representations for each term. The hybrid-contextualized representation ti of a term with word embedding t i over its whole input sequence t 1:n is defined as:</p><formula xml:id="formula_0" coords="2,110.01,432.05,184.04,10.04">ti = t i * α + context(t 1:n ) i * (1 -α)<label>(1)</label></formula><p>We regulate the influence of the contextualization by the endto-end learned α parameter. This allows the model to decide the intensity of the contextualization. We calculate the context(t 1:n ) with a set of Transformer layers <ref type="bibr" coords="2,175.26,481.15,13.48,7.94" target="#b12">[13]</ref>. First, the input sequence is fused with a positional encoding to form p 1:n , followed by a set of l Transformer layers:</p><formula xml:id="formula_1" coords="2,78.74,517.28,215.31,10.35">Transformer l (p 1:n ) = MultiHead(FF(p 1:n )) + FF(p 1:n ) (2)</formula><p>Here, FF is a two-layer fully connected feed-forward layer including a non-linear activation function. The MultiHead module projects the input sequence (stored as a matrix) to query, key, and value inputs of the scaled dot-product attention for each attention head. Then the results of the attention heads are concatenated and projected to the output:</p><formula xml:id="formula_2" coords="2,62.20,601.07,223.45,44.59">MultiHead(p 1:n ) = Concat(head 1 , ..., head h )W O where head i = softmax (p 1:n W Q i )(p 1:n W K i ) T d k (p 1:n W V i )</formula><p>(3) We select Transformers for contextualization, because their positional encoding and sequence wide self-attention allows for local and global contextualization at the same time. This makes TK more powerful than previous local-only contextualization methods used in CONV-KNRM <ref type="bibr" coords="2,117.34,701.42,10.55,7.94" target="#b1">[2]</ref> and CO-PACRR <ref type="bibr" coords="2,189.80,701.42,9.39,7.94" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interaction Scoring</head><p>After the contextualization, we match the query sequence q1:m and document sequence d1:n together in a single match-matrix M ∈ R q len ×d len with pairwise cosine similarity as interaction extractor:</p><formula xml:id="formula_3" coords="2,406.21,389.09,151.99,11.27">M i, j = cos( qi , dj )<label>(4)</label></formula><p>Then, we transform each entry in M with a set of k RBF-kernels <ref type="bibr" coords="2,317.96,417.63,13.26,7.94" target="#b13">[14]</ref>. Each kernel focuses on a specific similarity range with center µ k . The size of all ranges is guided by σ . In contrast to Xiong et al. <ref type="bibr" coords="2,317.96,439.55,14.79,7.94" target="#b13">[14]</ref> we do not employ an exact match kernel -as contextualized representation are not producing exact matches. Each kernel results in a matrix K ∈ R q len ×d len :</p><formula xml:id="formula_4" coords="2,387.84,474.83,170.36,24.72">K k i, j = exp - M i j -µ k 2 2σ 2<label>(5)</label></formula><p>Now, we process each kernel matrix in parallel, and we begin by summing the document dimension j for each query term and kernel:</p><formula xml:id="formula_5" coords="2,413.04,542.13,145.16,20.71">K k i = j K k i, j<label>(6)</label></formula><p>At this point -as shown in Figure <ref type="figure" coords="2,453.25,569.01,4.09,7.94" target="#fig_1">1</ref> -the model flow splits into two paths: log normalization and length normalization. The log normalization applies a logarithm with base b to each query term before summing them up:</p><formula xml:id="formula_6" coords="2,400.78,618.91,157.42,20.71">s k log = i log b K k i (7)</formula><p>We enhance the pooling process with document length normalization. We dampen the magnitude of each query term signal by the document length:</p><formula xml:id="formula_7" coords="2,411.21,683.73,146.99,27.71">s k len = i K k i d len (8)</formula><p>Now, each kernel is represented by a single scalar, which is weighted with a simple linear layer to produce a scalar, for both the log-normalized and length normalized kernels:</p><formula xml:id="formula_8" coords="3,102.20,123.13,191.84,13.58">s log = s k log W 1 s len = s k len W 2 (9)</formula><p>Finally, we compute the final score of the query-document pair as a weighted sum of the log-normalized and the length-normalized scores: s = s log * β + s len * γ (10) We employ kernel-pooling, because it makes inspecting temporary scoring results more feasible compared to pattern based scoring methods. Each kernel is applied to the full document. The row-wise and the column-wise summing of the match-matrix allow to inspect individual matches independent from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TREC DEEP LEARNING TRACK</head><p>Now, we describe the details of our experimentation pipeline (Section 3.1), configuration settings of our different runs (Section 3.2) and the results of the TREC annotations (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiment Setup</head><p>Our experimentation pipeline has two parts: 1) A first stage index and retrieval and 2) neural re-ranking model training and inference. For the first part we use the Anserini toolkit <ref type="bibr" coords="3,211.39,346.18,14.59,7.94" target="#b14">[15]</ref> to compute the initial ranking lists, which we use to generate training and evaluation inputs for the neural models (only for the full task). As basis for our neural model library we use PyTorch <ref type="bibr" coords="3,194.68,379.05,14.85,7.94" target="#b9">[10]</ref> and AllenNLP <ref type="bibr" coords="3,266.88,379.05,9.52,7.94" target="#b3">[4]</ref>. We tokenize the text with the fast BlingFire library 1 . We train all neural models with a pairwise hinge loss. We use pre-trained GloVe <ref type="bibr" coords="3,279.27,400.97,14.77,7.94" target="#b10">[11]</ref> word embeddings with 300 dimensions 2 .</p><p>We cap the query length at 30 tokens and the document length at 200 tokens. For MSMARCO-Passage this only removes a modest amount of outliers, however, for the MSMARCO-Document collection a majority of documents is longer than 200 tokens. Increasing the cap to fully include most documents would render all evaluated neural IR models less effective. Only the TUW19-d3 model uses a larger cutoff of 800. We use the Adam <ref type="bibr" coords="3,190.45,488.64,10.43,7.94" target="#b7">[8]</ref> optimizer with a learning rate of 10 -4 for word embeddings and contextualization layers, 10 -3 for all other network layers. We employ early stopping, based on the best MRR@10 value of the validation set. We use a training batch size of 64. We use a vocabulary of all terms with a minimum collection occurrence of 5. Regarding model-specific parameters, for the Transformer layers in TK we use 2 layers, each with 16 attention heads with size 32 and a feed-forward dimension of 100. For log-normalization in TK we use a base of 2. For kernel-pooling we set the number of kernels to 11 with the mean values of the Gaussian kernels varying from -1 to +1 and standard deviation of 0.1 for all kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Run overview</head><p>Our runs are described in Table <ref type="table" coords="3,167.01,644.21,3.01,7.94" target="#tab_0">1</ref>. We used the same model instance for both the evaluation of the re-ranking task and the full ranking task. For the full task we generated initial rankings with Anserini using BM25 and utilized the validation sets to tune the re-ranking The TUW19-d3 model is the only submitted run diverging from the TK model description in Section 2. It caps documents at 800 tokens and contextualizes the sequences in one block. Then, after the kernel-transformation of the cosine interactions is computed, we apply multiple pooling windows of different window sizes to the soft-histogram features. After that, we sort the window-scores and weigh the position independent sorted scores to form the final score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Now, we present our results for our validation set (sparsely labeled MSMARCO-DEV set) and the TREC judgements in Table <ref type="table" coords="3,530.38,446.44,3.10,7.94" target="#tab_1">2</ref>. Additionally, we highlight qualitative examples of the best and worst queries for two runs in Tables <ref type="table" coords="3,429.61,468.35,4.17,7.94">3</ref> and<ref type="table" coords="3,451.76,468.35,3.07,7.94" target="#tab_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Passage Task.</head><p>For the passage task our results show that different configurations of TK have similar results. Especially, the difference between a GloVe embedding with a minimum threshold of 5 (p1) and a FastText embedding without out-of-vocabulary (OOV) terms (p2) is marginal. We assume this is due to the ability of the contextualization to overcome OOV and infrequent terms, which have been shown to negatively impact simpler neural models <ref type="bibr" coords="3,317.96,562.71,9.36,7.94" target="#b4">[5]</ref>. Ensembling a model (p3), does provide some benefit, however, the difference is stronger in the loosely judged DEV set and smaller in the thoroughly judged TREC annotations.</p><p>In addition to the evaluation metrics, we selected the best and worst performing queries from the TREC'19 set and show them in Table <ref type="table" coords="3,349.88,617.50,3.11,7.94">3</ref>. Due to the small amount of queries evaluated, there is no clear distinction in the types of information needs that perform better or worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Document Task.</head><p>For the document ranking the different configurations and network structures of TK seem very similar when looking at the DEV set in Table <ref type="table" coords="3,433.37,678.97,3.03,7.94" target="#tab_1">2</ref>. However, the TREC annotations reveal large differences between the full and re-Ranking task as well as the submitted configurations. We assume that a major factor for the differences between full and re-ranking tasks is that for the full task we tuned the re-ranking depth on the MRR@10 score of the validation set as proposed by Hofstätter et al. <ref type="bibr" coords="4,110.92,492.99,9.27,7.94" target="#b4">[5]</ref>. For the passage models we found the maximum evaluated depth (1000 documents per query) to be the best, but for the document task the tuned threshold (on the MSMARCO-DEV set) is much lower than the 100 documents of the full ranking task. The re-ranking depths are 29 for TUW19-d1, 60 for TUW19-d2 and 31 for TUW19-d3. For the sparsely judged DEV set this brings improvements, however for the thoroughly judged TREC queries we decrease the effectiveness substantially between 31 and 100 re-ranked documents. This shows the importance of evaluating thoroughly judged queries and the need to revisit the threshold parameter for the new dataset.</p><p>The best performing TK model (d3) is document-specific with windowed kernel-pooling and tuned re-ranking depth. This result shows that the pure passage ranking TK model (d1,d2) is unsuited for documents and we explored a first strategy on handling longer text, still we believe there is more potential for special network architectures for documents in the future.</p><p>Following the passage result, we also highlight the best and worst performing queries on the document task for the d3 run and the re-ranking task in Table <ref type="table" coords="4,157.75,701.21,3.07,7.94" target="#tab_2">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">INTERPRETABILITY</head><p>We now highlight the interpretation capabilities of the TK model with a qualitative example from the MSMARCO-Passage-DEV set. We focus on the following scenario: a user would like to know why the neural model replaced the first result (a non-relevant document) of the first stage ranking with an actual relevant document. For this, we offer a side-by-side comparison view of two documents.</p><p>Figure <ref type="figure" coords="4,353.26,546.87,4.14,7.94" target="#fig_2">2</ref> shows the comparison of two documents for the query "androgen receptor define". On the left side is a document judged as relevant, which is placed on the first position by TK. On the right side is the formerly first document (as determined by BM25), which is not the correct answer and only partially relevant to the query -TK moved it to a lower position.</p><p>We show each document with its full-text and a selection of temporary results of TK. We aim to identify and highlight the differences that result in different ranking scores. We color words according to their closest affiliation with a kernel. An important fact to consider is the soft-matching nature of the kernels: A term is counted in more than one kernel at a time. For example, this explains the difference in kernel µ = 1, even though no word is more closely associated with that kernel and therefore we omitted a color. Query (Id:2) androgen receptor define Rank: TK 1 ○, BM25 9 ○ (judged as relevant, Id: 4339068) Rank: TK 8 ○, BM25 1 ○ (not relevant, Id: 1782337)</p><p>The androgen receptor ( AR ) , also known as NR3C4 ( nuclear receptor subfamily 3 , group C , member 4 ) , is a type of nuclear receptor that is activated by binding either of the androgenic hormones , testosterone , or dihydrotestosterone in the cytoplasm and then translocating into the nucleus . in some cell types , testosterone interacts directly with androgen receptors , whereas , in others , testosterone is converted by 5 -alphareductase to dihydrotestosterone , an even more potent agonist for androgen receptor activation . Enzalutamide is an androgen receptor inhibitor that acts on different steps in the androgen receptor signaling pathway . Enzalutamide has been shown to competitively inhibit androgen binding to androgen receptors and inhibit androgen receptor nuclear translocation and interaction with DNA . From the highlighted kernel scores (s k log ) it is apparent that the left document has more stronger matches than the right one, leading to higher scores. If we look at the corresponding colored words we observe that the sentence containing the definition in the left is most relevant to the query: The androgen receptor ( AR ) , also known as NR3C4 ( nuclear receptor subfamily. Even though TK does not contain a mechanism for strictly categorizing a region as relevant, it does so indirectly by strongly matching most terms in this region. Of particular interest to us is the fact that the contextualization of TK learns to match the query term "define" with words and phrases that make up a definition: "also known as", "subfamily", "is a type" as well as the parentheses. This exceeds simple synonym mapping, suggesting once more the importance of training contextualized and relevance specific encoding models.</p><formula xml:id="formula_9" coords="5,246.53,119.86,42.58,23.52">µ k s k log 1 -<label>3</label></formula><p>This analysis demonstrates the potential for future work on keyword based search. When a collection is not queried with natural language questions, but only keywords, one could expand such keyword queries with terms like "definition" or "meaning" both during training and inference of neural models, to promote documents closer related to the core of the information need. We are aware that our approach does not enable full interpretability. We do not look deeper than the pairwise similarity values, and we currently cannot explain why certain words are similar and why some are not. Additionally, an interactive version as part of a search result page would allow more flexibility to explore different kernels and query terms. Nevertheless, we view this approach as a first step to open up the black-box of the neural re-ranking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Our aim in the TREC 2019 Deep Learning track was to evaluate a neural re-ranking model, which balances efficiency, effectiveness, and interpretability. We submitted results of our TK (Transformer-Kernel) model: a neural re-ranking model for ad-hoc search using an efficient contextualization mechanism. For the passage task our results show that different configurations of TK lead to similar results. Ensembling a model does provide some benefit, however the difference is stronger in the loosely judged DEV set and smaller in the thoroughly judged TREC annotations. For the document ranking the different configurations and network structures of TK seem very similar when looking at the DEV set. The TREC annotations however reveal large differences between the full and re-ranking task and the submitted configurations. The best performing TK model is document-length-specific with windowed kernel-pooling and tuned re-ranking depth. This shows the potential for specialized architectures for neural document re-ranking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,53.80,269.60,162.91,7.78;2,209.80,268.60,279.33,8.77;2,482.22,268.60,75.98,8.69;2,53.80,280.55,244.59,7.78;2,291.47,279.56,266.73,8.69;2,53.80,291.51,415.75,7.78;2,462.64,290.52,95.57,8.69;2,53.80,302.47,223.26,7.70"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The TK model architecture: 1 ○ We contextualize query and document sequences individually. 2 ○ The interaction match-matrix is created with pairwise cosine similarities. 3○ Each kernel creates a new feature matrix. Then, the document dimension is summed and we normalize each query-term feature by logarithm and document length. 4○ We combine log-and length-normalized scores to form the final result score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,53.80,255.69,504.40,7.70;5,53.80,266.65,504.40,7.70;5,53.80,277.60,478.73,7.70"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: TK's scoring results of two MSMARCO-Passage documents: We highlight two of the most distinct kernels -both indicating close similarities (0.9 &amp; 0.7). In the text words are colored and underlined if they are closest to the center of the highlighted kernel. Individual kernel results (model weights included) are displayed in the middle for each document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.67,85.73,504.53,623.18"><head>Table 1 :</head><label>1</label><figDesc>Summary of our submitted TK runs</figDesc><table coords="3,317.96,103.35,240.25,216.33"><row><cell>Run</cell><cell>Description</cell></row><row><cell></cell><cell>Passages</cell></row><row><cell cols="2">TUW19-p1 Using GloVe pre-trained (with min. 5</cell></row><row><cell></cell><cell>occurrence threshold), best validation run of</cell></row><row><cell></cell><cell>multiple inits</cell></row><row><cell cols="2">TUW19-p2 Using FastText vectors instead of a simple</cell></row><row><cell></cell><cell>word embedding</cell></row><row><cell cols="2">TUW19-p3 Ensemble of multiple TUW19-p1</cell></row><row><cell></cell><cell>configurations</cell></row><row><cell></cell><cell>Documents</cell></row><row><cell cols="2">TUW19-d1 Using GloVe and document training data</cell></row><row><cell cols="2">TUW19-d2 Using GloVe and passage training data</cell></row><row><cell cols="2">TUW19-d3 Using FasText embeddings &amp;</cell></row><row><cell></cell><cell>windowed-kernel-pooling of different sizes,</cell></row><row><cell></cell><cell>final score based on sorted window scores</cell></row><row><cell cols="2">depth. For the re-ranking task we used the entire provided initial</cell></row><row><cell>ranking list.</cell><cell></cell></row></table><note coords="3,53.67,692.64,113.14,7.84;3,53.80,701.06,203.46,7.85"><p>1 https://github.com/microsoft/BlingFire 2 42B CommonCrawl lower-cased: https://nlp.stanford.edu/projects/glove/</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,58.88,85.73,427.67,355.31"><head>Table 2 :</head><label>2</label><figDesc>Evaluation results of our runs for the passage and document tasks.</figDesc><table coords="4,58.88,103.35,427.67,337.69"><row><cell></cell><cell></cell><cell></cell><cell>Run</cell><cell>MSMARCO-DEV MAP nDCG MRR@10</cell><cell>TREC2019-Full MAP nDCG P@10 MAP nDCG P@10 TREC2019-ReRank</cell></row><row><cell></cell><cell></cell><cell>Passage</cell><cell>TUW19-p1 0.314 TUW19-p2 0.316 TUW19-p3 0.333 0.386 0.366 0.369</cell><cell>0.307 0.310 0.328 0.420 0.671 0.598 0.411 0.641 0.577 0.413 0.667 0.574 0.407 0.640 0.570 0.416 0.671 0.577 0.396 0.636 0.565</cell></row><row><cell></cell><cell></cell><cell>Doc.</cell><cell>TUW19-d1 0.311 TUW19-d2 0.312 TUW19-d3 0.314 0.369 0.366 0.365</cell><cell>0.306 0.303 0.205 0.382 0.633 0.239 0.165 0.314 0.626 0.252 0.309 0.184 0.333 0.626 0.271 0.465 0.730 0.445 0.688 0.445 0.681</cell></row><row><cell cols="4">Table 3: Best &amp; worst queries for TUW19-p3 full</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Best</cell></row><row><cell>Id</cell><cell>AP</cell><cell cols="2">Query Text</cell></row><row><cell>146187</cell><cell>0.851</cell><cell cols="2">difference between a mcdouble and a</cell></row><row><cell></cell><cell></cell><cell cols="2">double cheeseburger</cell></row><row><cell>156493</cell><cell cols="3">0.8225 do goldfish grow</cell></row><row><cell>168216</cell><cell cols="3">0.9495 does legionella pneumophila cause</cell></row><row><cell></cell><cell></cell><cell cols="2">pneumonia</cell></row><row><cell>359349</cell><cell>0.788</cell><cell cols="2">how to find the midsegment of a trapezoid</cell></row><row><cell>855410</cell><cell>1</cell><cell cols="2">what is theraderm used for</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Worst</cell></row><row><cell>Id</cell><cell>AP</cell><cell cols="2">Query Text</cell></row><row><cell cols="2">1063750 0.015</cell><cell cols="2">why did the us volunterilay enter ww1</cell></row><row><cell cols="4">1110199 0.0911 what is wifi vs bluetooth</cell></row><row><cell cols="4">1112341 0.1056 what is the daily life of thai people</cell></row><row><cell cols="2">1113437 0.095</cell><cell cols="2">what is physical description of spruce</cell></row><row><cell>19335</cell><cell>0</cell><cell cols="2">anthropological definition of environment</cell></row><row><cell>207786</cell><cell cols="3">0.0919 how are some sharks warm blooded</cell></row><row><cell>489204</cell><cell cols="3">0.0583 right pelvic pain causes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,323.04,217.20,227.79,223.84"><head>Table 4 :</head><label>4</label><figDesc>Best &amp; worst queries for TUW19-d3 re-rank</figDesc><table coords="4,428.31,234.83,17.29,7.70"><row><cell>Best</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,333.39,406.96,225.88,6.18;5,333.39,414.89,214.23,6.23" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,333.39,414.93,144.66,6.18">Enriching Word Vectors with Subword Information</title>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,483.55,414.89,38.68,6.23">Tr. of the ACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,422.90,224.81,6.18;5,333.39,430.83,223.63,6.23" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,518.33,422.90,39.87,6.18;5,333.39,430.87,171.20,6.18">Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search</title>
		<author>
			<persName coords=""><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,515.55,430.83,37.30,6.23">Proc. of WSDM</title>
		<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,438.85,225.63,6.18;5,333.39,446.82,225.89,6.18;5,333.39,454.74,45.27,6.23" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,541.50,438.85,17.53,6.18;5,333.39,446.82,222.70,6.18">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,333.39,454.74,41.41,6.23">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,462.76,225.58,6.18;5,333.39,470.73,225.88,6.18;5,333.39,478.70,225.88,6.18;5,333.39,486.67,65.49,6.18" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:arXiv:1803.07640</idno>
		<title level="m" coord="5,354.62,478.70,201.66,6.18">AllenNLP: A Deep Semantic Natural Language Processing Platform</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,494.64,225.88,6.18;5,333.39,502.56,221.67,6.23" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,333.39,502.61,169.94,6.18">On the Effect of Low-Frequency Terms on Neural-IR Models</title>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,515.84,502.56,36.37,6.23">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,510.58,224.81,6.18;5,333.39,518.55,224.81,6.18;5,333.39,526.47,71.00,6.23" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,379.91,518.55,178.29,6.18;5,333.39,526.52,21.20,6.18">Enriching Word Embeddings for Patent Retrieval with Global Context</title>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,366.96,526.47,34.37,6.23">Proc. of ECIR</title>
		<meeting>of ECIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,534.49,225.63,6.18;5,333.15,542.41,205.60,6.23" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,526.60,534.49,32.42,6.18;5,333.15,542.46,150.31,6.18">Co-PACRR: A context-aware neural IR model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Melo</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,495.34,542.41,39.15,6.23">Proc. of WSDM</title>
		<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,550.43,225.99,6.18;5,333.39,558.35,134.14,6.23" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m" coord="5,452.92,550.43,106.46,6.18;5,333.39,558.40,23.52,6.18">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,333.39,566.37,225.88,6.18;5,333.39,574.29,108.33,6.23" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="5,467.87,566.37,87.86,6.18">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,333.39,582.31,225.58,6.18;5,333.39,590.28,225.89,6.18;5,333.39,598.20,178.11,6.23" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,350.41,598.25,103.40,6.18">Automatic differentiation in PyTorch</title>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,466.29,598.20,41.91,6.23">Proc. of NIPS-W</title>
		<meeting>of NIPS-W</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,606.22,225.63,6.18;5,333.39,614.14,164.51,6.23" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,540.40,606.22,18.62,6.18;5,333.39,614.19,109.18,6.18">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,454.76,614.14,39.38,6.23">Proc of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,622.16,224.94,6.18;5,333.39,630.13,224.81,6.18;5,333.39,638.05,100.19,6.23" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,480.78,630.13,77.42,6.18;5,333.39,638.10,42.73,6.18">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,388.31,638.05,41.41,6.23">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,646.07,225.58,6.18;5,333.15,654.04,225.06,6.18;5,333.39,661.96,73.90,6.23" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,513.37,654.04,44.83,6.18;5,333.39,662.01,24.64,6.18">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,370.40,661.96,33.94,6.23">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,669.98,225.88,6.18;5,333.39,677.90,211.08,6.23" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="5,333.39,677.95,159.60,6.18">End-to-End Neural Ad-hoc Ranking with Kernel Pooling</title>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,505.25,677.90,36.37,6.23">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,333.39,685.92,224.81,6.18;5,333.39,693.84,145.48,6.23" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="5,456.35,685.92,101.85,6.18;5,333.39,693.89,94.09,6.18">Anserini: Enabling the use of Lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,439.65,693.84,36.37,6.23">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
