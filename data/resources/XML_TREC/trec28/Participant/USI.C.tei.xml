<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,153.14,115.96,309.07,12.62;1,187.68,133.89,239.99,12.62;1,229.46,151.82,156.44,12.62">Predicting Relevant Conversation Turns for Improved Retrieval in Multi-Turn Conversational Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.40,189.68,82.64,8.74"><forename type="first">Esteban</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Università della Svizzera italiana (USI)</orgName>
								<address>
									<settlement>Lugano</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.17,189.68,104.88,8.74"><forename type="first">Mohammad</forename><surname>Aliannejadi</surname></persName>
							<email>m.aliannejadi@uva.nl</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.43,201.63,93.60,8.74"><forename type="first">Manajit</forename><surname>Chakraborty</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Università della Svizzera italiana (USI)</orgName>
								<address>
									<settlement>Lugano</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.58,201.63,63.87,8.74"><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
							<email>fabio.crestani@usi.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">Università della Svizzera italiana (USI)</orgName>
								<address>
									<settlement>Lugano</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Università della Svizzera italiana (USI)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,153.14,115.96,309.07,12.62;1,187.68,133.89,239.99,12.62;1,229.46,151.82,156.44,12.62">Predicting Relevant Conversation Turns for Improved Retrieval in Multi-Turn Conversational Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1324BBC2E4CCCF5CEA6B5E4AF393A107</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Conversational Search</term>
					<term>Multi-turn Conversations</term>
					<term>Information-Seeking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This technical report presents the work of Università della Svizzera italiana in TREC CAsT 2019. TREC CAsT was set up to advance research on conversational search systems. The goal of the track is to create a reusable benchmark for open-domain information-centric conversational dialogues and to establish a concrete and standard collection of data with information needs to make systems directly comparable. Given the complexity of natural language and the evolution of user's information need in a conversation with multiple turns, finding relevant context is not always straightforward. We developed a neural model for identifying relevant turn(s) corresponding to the given turn. Our model reformulates the information need of the user to take into account the conversational context to enhance the ad-hoc passage retrieval performance. Two of our runs also employ neural re-ranking of the passages post-retrieval. One of our runs was able to achieve above-median performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Conversational Information Seeking (CIS) has been highlighted as an important emerging research area in the SWIRL 2018 workshop report 3 on future trends in Information Retrieval. CIS is timely and important with increased adoption of a new generation of conversational "assistant" systems, including Amazon Alexa, Cortana, Bixby, Google Assistant, and many others. The goal of the TREC CAsT track <ref type="bibr" coords="1,190.07,603.37,10.52,8.74" target="#b2">[3]</ref> is to pursue CIS research and create a large-scale reusable test collection for open-domain conversational search systems. The primary initial focus is targeted towards system understanding of information needs in a conversational format and finding relevant responses using contextual information. In particular, the track is motivated by long-running and complex tasks requiring multiple turns (possibly multiple sessions).</p><p>Although much work has been done on studying single-turn conversations, several challenges emerge for a conversational system in a multi-turn dialogue. Multiple turns in a conversation can be used to understand the user information need more effectively <ref type="bibr" coords="2,230.07,217.32,9.96,8.74" target="#b8">[9]</ref>. To understand the dependency of conversation turns, we have annotated each turn of the conversation with related turns in the conversation's context. The turn-relevance annotation enables us to understand and visualize the conversation evolution and dependencies. An utterance is relevant to the current one when:</p><p>it is needed to clarify the current utterance or it augments the information need for the current utterance or it entails the current utterance. As an example, consider the following conversation extracted from the TREC CAsT 2019 evaluation dataset in Figure <ref type="figure" coords="3,318.84,130.95,3.87,8.74" target="#fig_0">1</ref>. As can be observed, utterance u 4 cannot be answered unless additional information from previous utterances, i.e., the context, is included in the question. In this case, utterance u 3 provides the necessary context and thus, is considered relevant to u 4 <ref type="bibr" coords="3,389.77,166.81,9.96,8.74" target="#b0">[1]</ref>. In this work, we propose a simple yet effective neural model for predicting relevant and complementary conversation turns. The relevant utterances are then used to expand the current utterance to build a self-sufficient query, which is then passed to an ad-hoc Information Retrieval (IR) system to provide a ranked list of passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Modeling</head><p>We submitted four runs to the track. Two of those runs employed neural reranking after the ad-hoc retrieval stage. The retrieval step is preceded by a reformulation of utterances using the proposed relevance utterance prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset</head><p>The task was organized to focus on candidate information ranking in context with two main goals:</p><p>-Read the dialogue context: Track the evolution of the information need in the conversation, identifying salient information needed for the current turn in the conversation. -Retrieve Candidate Response Information: Perform retrieval over a large collection of paragraphs (or knowledge base content) to identify relevant information.</p><p>As part of the track dataset, organizers released three open-sourced collection namely MS MARCO (MAchine Reading COmprehension) Ranking passages <ref type="bibr" coords="3,467.31,468.68,9.96,8.74" target="#b6">[7]</ref>, TREC CAR 2018 <ref type="bibr" coords="3,217.68,480.63,10.52,8.74" target="#b4">[5]</ref> paragraph collection and News article from Washington Post (WAPO) <ref type="foot" coords="3,197.43,491.01,3.97,6.12" target="#foot_0">4</ref> . MS MARCO dataset was released by Microsoft in 2018 and comprises of 8,841,823 passages -extracted from 3,563,535 web documents retrieved by Bing. TREC-CAR (Complex Answer Retrieval) collection is a corpus of 20 million paragraphs harvested from a snapshot of Wikipedia. The TREC CAsT 2019 track came with its own set of 30 training conversations and 50 evaluation conversations<ref type="foot" coords="3,240.62,550.79,3.97,6.12" target="#foot_1">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relevant Utterance Prediction</head><p>For training the relevant utterance classifier, we needed a pre-labeled set of questions that were marked relevant to the current question. This labeling was done by three human annotators who were provided with the current utterance and all the previous utterances to that point. The annotators were supposed to select one or more utterance(s) that seemed relevant to or would help clarify the current question. After independent labeling, we computed the percentage agreement among the annotators, and if at least two of the three annotators agreed on the same set of relevant question(s) (i.e., the agreement score was greater than or equal to 66.67%) in the first round, we recorded them. In the second round, for questions that had an agreement score below 66.67%, the three annotators deliberated and arrived at an agreement on the relevance of questions.</p><p>Of the total 748 questions (from 80 conversations), there was an agreement on 625 questions after the first round. The rest 123 utterance annotations were resolved in the second round by rigorous discussion. This exercise was carried out for both the training and evaluation conversations.</p><p>We employed a high-dimensional language and position representation (pretrained BERT-Base) to predict the relevant utterances corresponding to the current utterance. We initialize the BERT parameters with the model that is pre-trained for the language modeling task on Wikipedia. BERT has recently outperformed state-of-the-art models in a number of language understanding and retrieval tasks <ref type="bibr" coords="4,216.57,322.64,9.96,8.74" target="#b3">[4]</ref>. Rectified linear unit (ReLU) is employed as the activation function in the hidden layers, and a softmax function is applied on the output layer to compute the probability of each label (i.e., relevant or non-relevant). To train our classifier, we used a cross-entropy loss function and followed the point-wise learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Retrieval and Re-ranking</head><p>Before feeding the utterances as queries to the document retrieval model, we performed two steps of query processing and reformulation, as follows:</p><p>1. We observed from the data that a large share of utterances was dependent on previous turns in the conversation. Hence, it is imperative to perform coreference resolutions on such utterances to make them a complete question in itself. To this end, we use AllenNLP <ref type="bibr" coords="4,329.49,493.80,10.52,8.74" target="#b5">[6]</ref> coreference resolution tool. For self-contained utterances and first utterances in the conversations, the output of the tool is the same as the original utterance. 2. On this modified query, we perform stopword removal, removal of special characters, and tokenization. 3. To this modified query, we added the relevant utterances selected by the relevance prediction model to make the query complete. Two of the runs also include adding the first utterance to the modified query since it is supposed to introduce the premise for the complete conversation.</p><p>After reformulating the utterances, we pass the resulting query set to various document retrieval models. For document (passage) retrieval, we employed Galago<ref type="foot" coords="4,165.28,633.77,3.97,6.12" target="#foot_2">6</ref> and indexed the MS MARCO collection. We used Okapi-BM25 <ref type="bibr" coords="4,442.22,635.34,15.50,8.74" target="#b9">[10]</ref> term matching retrieval model to retrieve the passages. Two of the runs that we submitted had an additional step of re-ranking the retrieved passages. For this, we employed the neural re-ranking model based on BERT, as proposed by Nogueira and Cho <ref type="bibr" coords="5,176.06,154.86,9.96,8.74" target="#b7">[8]</ref>. The job of the re-ranker is to estimate a score s i of how relevant a candidate passage d i is to a query q. The model is fed the query as sentence A and the passage text as sentence B. The query is truncated to have at most 64 tokens. The passage text is also truncated, such that the concatenation of query, passage, and separator tokens have a maximum length of 512 tokens. The implementation uses a BERT LARGE model as a binary classification model i.e., it uses the [CLS] vector as input to a single layer neural network to obtain the probability of the passage being relevant. We compute this probability for each passage independently and obtain the final list of passages by ranking them with respect to these probabilities. We start training from a pre-trained BERT model and fine-tune it to our reranking task using the cross-entropy loss:</p><formula xml:id="formula_0" coords="5,220.56,310.70,260.04,20.06">L = - j∈Jpos log(s j ) - j∈Jneg log(1 -s j ),<label>(1)</label></formula><p>where J pos is the set of indexes of the relevant passages and J neg is the set of indexes of non-relevant passages in top-1,000 documents retrieved with BM25. The four runs that were submitted to the track are listed below:</p><p>1. galago rel q: In this run, we only pass the reformulated query by expanding the current utterance with relevant utterance(s) to the retrieval system. 2. bertrr rel q: For this run, we pass the reformulated query by expanding the current utterance with relevant utterance(s) to the retrieval system. After this, the retrieval results are re-ranked using BERT. 3. galago rel 1st: In this run, the reformulation involves adding the relevant utterance(s) along with the first utterance in the conversation to the current one. The idea behind is that usually, the first turn in the conversation sets the context of the conversation and hence may be useful in clarifying the current utterance. 4. bertrr rel 1st: This is similar to galago rel 1st, with the only difference being that the retrieved results are re-ranked using BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Conclusion</head><p>Table <ref type="table" coords="5,163.10,584.39,4.98,8.74" target="#tab_0">1</ref> shows the overall average performance of our submitted runs against three metrics proposed by the track committee. We compare the results against the average median performance of all submitted runs to TREC CAsT. From the table, we can observe that the only run bertrr rel 1st supersedes the TREC median performance on two metrics, MAP@5 and NDCG@5. This highlights the importance of the first utterance in a conversation. On further analysis, we found that over 50% of the relevant utterances were found at the first position in a conversation, which corroborates our initial hypothesis that the first question sets the premise for the rest of the conversation. Another observation from the table is that the neural re-ranking approaches perform better than the simple ad-hoc retrieval systems reinstating our belief that neural models such as BERT are better at capturing the relevance of passages to queries than simple heuristic or IR models.</p><p>In this technical report, we presented the outcome of the participation of Università della Svizzera italiana in TREC CAsT 2019. The proposed model reformulates the information need of the user to take into account the conversational context to enhance the ad-hoc passage retrieval performance. To this end, conversations released by the TREC CAsT 2019 have been annotated to identify the relevant utterance from a conversation's context. Based on the labels obtained, we employed a high-dimensional language and position representation to predict the relevant utterances corresponding to the current utterance. Results showed that adding the predicted relevant utterance(s) along with the first utterance in the conversation to the current one in combination with neural passage re-ranking provided the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>In this paper, we presented a BERT fine-tuning model to predict the relevance of the utterances. Our proposed model outperformed competitive classification baselines. Also, we demonstrated its effectiveness in improving the performance of document retrieval models. As future work, we plan to perform a similar analysis on information-seeking conversational systems with the ability of asking clarifying questions <ref type="bibr" coords="6,222.59,556.22,9.96,8.74" target="#b1">[2]</ref>. The proposed task in the TREC CAsT track is aiming to evaluate systems that retrieve responses to the user's utterances. However, as indicatd by the organizers, one of the future plans is to include a subtask aiming to evaluate clarifying questions in a conversation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,203.34,654.53,208.67,7.89;2,134.77,373.28,345.82,266.48"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Identifying Relevant Utterances (Questions)</figDesc><graphic coords="2,134.77,373.28,345.82,266.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,115.91,345.83,105.86"><head>Table 1 .</head><label>1</label><figDesc>Passage retrieval performance of the submitted runs before and after the bug fix.</figDesc><table coords="6,159.44,149.09,293.40,72.69"><row><cell></cell><cell>MAP@5</cell><cell>NDCG@5</cell><cell>NDCG@10</cell></row><row><cell>galago rel q</cell><cell>0.0251</cell><cell>0.1823</cell><cell>0.1900</cell></row><row><cell>bertrr rel q</cell><cell>0.0406</cell><cell>0.2977</cell><cell>0.2977</cell></row><row><cell>galago rel 1st</cell><cell>0.0271</cell><cell>0.1952</cell><cell>0.1981</cell></row><row><cell>bertrr rel 1st</cell><cell>0.0432</cell><cell>0.3027</cell><cell>0.2994</cell></row><row><cell>TREC CAsT median</cell><cell>0.0337</cell><cell>0.2656</cell><cell>0.3622</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,645.84,102.78,7.86"><p>https://ir.nist.gov/wapo/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,656.80,259.03,7.86"><p>https://github.com/daltonj/treccastweb/tree/master/2019/data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="4,144.73,656.80,169.84,7.86"><p>https://www.lemurproject.org/galago.php</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,645.84,337.63,7.86;6,151.52,656.80,329.07,7.86;7,151.52,119.67,329.07,7.86;7,151.52,130.63,316.25,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,408.97,645.84,71.62,7.86;6,151.52,656.80,247.82,7.86">Harnessing evolution of multi-turn conversations for effective answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,421.37,656.80,59.23,7.86;7,151.52,119.67,325.19,7.86">Proceedings of the 2020 Conference on Conference Human Information Interaction and Retrieval</title>
		<meeting>the 2020 Conference on Conference Human Information Interaction and Retrieval<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">March 14-18, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,141.59,337.63,7.86;7,151.52,152.55,329.07,7.86;7,151.52,163.51,329.07,7.86;7,151.52,174.47,329.07,7.86;7,151.52,185.43,25.60,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,382.60,141.59,97.99,7.86;7,151.52,152.55,232.47,7.86">Asking Clarifying Questions in Open-Domain Information-Seeking Conversations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,405.73,152.55,74.86,7.86;7,151.52,163.51,329.07,7.86;7,151.52,174.47,133.95,7.86">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">July 21-25, 2019. 2019</date>
			<biblScope unit="page" from="475" to="484" />
		</imprint>
	</monogr>
	<note>SIGIR 2019</note>
</biblStruct>

<biblStruct coords="7,142.96,196.39,337.64,7.86;7,151.52,207.34,329.07,7.86;7,151.52,218.30,269.49,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,289.88,196.39,190.72,7.86;7,151.52,207.34,33.25,7.86">Cast 2019: The conversational assistance track overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,204.82,207.34,242.71,7.86">Proceedings of the Twenty-Eighth Text REtrieval Conference</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-13">2019. November 13-15, 2019 (2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,229.26,337.64,7.86;7,151.52,240.22,329.07,7.86;7,151.52,251.18,329.07,7.86;7,151.52,262.14,329.07,7.86;7,151.52,273.10,321.99,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,343.52,229.26,137.07,7.86;7,151.52,240.22,209.00,7.86">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,383.10,240.22,97.49,7.86;7,151.52,251.18,329.07,7.86;7,151.52,262.14,250.76,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s" coord="7,285.91,273.10,90.15,7.86">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,284.06,337.64,7.86;7,151.52,295.02,329.07,7.86;7,151.52,305.98,298.94,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,343.58,284.06,137.01,7.86;7,151.52,295.02,35.75,7.86">TREC Complex Answer Retrieval Overview</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gamari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,213.01,295.02,263.32,7.86">Proceedings of the Twenty-Seventh Text REtrieval Conference</title>
		<meeting>the Twenty-Seventh Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-14">2018. November 14-16, 2018 (2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,316.93,337.64,7.86;7,151.52,327.89,329.07,7.86;7,151.52,338.85,109.96,7.86" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m" coord="7,293.34,327.89,187.26,7.86;7,151.52,338.85,81.29,7.86">AllenNLP: A Deep Semantic Natural Language Processing Platform</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,349.81,337.64,7.86;7,151.52,360.77,329.07,7.86;7,151.52,371.73,329.07,7.86;7,151.52,382.69,329.07,7.86;7,151.52,393.65,329.07,7.86;7,151.52,404.61,25.60,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,151.52,360.77,311.52,7.86">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,151.52,371.73,329.07,7.86;7,151.52,382.69,329.07,7.86;7,151.52,393.65,177.80,7.86">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-09">December 9. 2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,415.56,337.63,7.86;7,151.52,426.52,177.16,8.11" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,252.00,415.56,126.82,7.86">Passage re-ranking with BERT</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno>CoRR abs/1901.04085</idno>
		<ptr target="http://arxiv.org/abs/1901.04085" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,437.48,337.63,7.86;7,151.52,448.44,329.07,7.86;7,151.52,459.40,329.07,7.86;7,151.52,470.36,25.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,265.93,437.48,210.52,7.86">A Theoretical Framework for Conversational Search</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.86,448.44,314.73,7.86;7,151.52,459.40,81.34,7.86">Proceedings of the 2017 Conference on Conference Human Information Interaction and Retrieval</title>
		<meeting>the 2017 Conference on Conference Human Information Interaction and Retrieval<address><addrLine>Oslo, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-03-07">2017. March 7-11, 2017. 2017</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,481.32,337.98,7.86;7,151.52,492.28,329.07,7.86;7,151.52,503.24,289.98,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,456.79,481.32,23.81,7.86;7,151.52,492.28,42.09,7.86">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,214.89,492.28,209.04,7.86">Proceedings of The Third Text REtrieval Conference</title>
		<meeting>The Third Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11-02">1994. November 2-4, 1994. 1994</date>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
