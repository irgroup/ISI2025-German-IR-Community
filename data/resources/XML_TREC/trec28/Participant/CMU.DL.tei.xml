<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,60.27,72.35,489.19,16.84;1,194.63,92.27,220.47,16.84">An Evaluation of Weakly-Supervised DeepCT in the TREC 2019 Deep Learning Track</title>
				<funder ref="#_x9MTn5X">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,226.58,137.97,61.13,11.06"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
							<email>zhuyund@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.29,137.97,68.85,11.06"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
							<email>callan@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,60.27,72.35,489.19,16.84;1,194.63,92.27,220.47,16.84">An Evaluation of Weakly-Supervised DeepCT in the TREC 2019 Deep Learning Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3A7FC06385F27CE1DA8CBB20219E52DE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the TREC 2019 Deep Learning Track document ranking task. We developed a deep learning based document term weighting approach based on our previous work of DeepCT. It used the contextualized token embeddings generated by BERT to estimate a term's importance in passages, and combines passage term weights into document-level term weights. The weighted document is stored in an ordinary inverted index and searched using a multi-field BM25, which is efficient. We tested two ways of training DeepCT: a query-based method using sparse relevant query-document pairs, and a weaklysupervised method using document title-body pairs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This paper describes our submissions to TREC 2019 Deep Learning (DL) Track document ranking task <ref type="bibr" coords="1,244.85,397.36,9.20,7.86" target="#b2">[2]</ref>. In this challenge, we took a simple BM25 retrieval approach, but we estimated document term weights using a deep neural network rather than using standard term frequency. The term weight estimation is an extension of our previous work on the deep contextual term weighting and indexing framework DeepCT <ref type="bibr" coords="1,113.04,460.13,9.20,7.86" target="#b4">[4]</ref>.</p><p>Standard term frequency based weighting schemes are widely used in Information Retrieval. They assume that a term is more important to a document if it is mentioned frequently in the document. However, this is not necessarily true -in some cases, term frequency distribution can be flat or noisy.</p><p>DeepCT is a term weighting and indexing framework aiming to generate indexing weights based on a term's meaning in a passage. It uses BERT <ref type="bibr" coords="1,163.56,543.81,9.72,7.86" target="#b5">[5]</ref> to extract contextual features of a term in a specific passage, and maps them to a contextaware term weight. The weights are stored in an ordinary inverted index, replacing the original term frequency (tf ) field. At query time, the resulting index, DeepCT-Index, can be efficiently searched using bag-of-words retrieval models such as BM25. In our previous research <ref type="bibr" coords="1,193.13,606.58,9.20,7.86" target="#b4">[4]</ref>, the new term weights improved standard bag-of-words retrieval models such as BM25 in two passage retrieval tasks as they better reflect essential concepts in the passages.</p><p>One contribution of this work is that we extended DeepCT to support long documents. Due to the input length limitation of BERT <ref type="bibr" coords="1,121.07,669.34,9.20,7.86" target="#b5">[5]</ref>, documents with more than 512 tokens can not be directly input into DeepCT. In this work, we first estimated a term's local importance in each passage using DeepCT. Then we combined the passage-specific term weights into a document bag-of-words representation. Fi-nally, we constructed a standard inverted index using the weighted document bag-of-words representation.</p><p>DeepCT-Index is built offline. At query time, documents are ranked by the standard BM25 algorithm. Multiple document fields, such as titles, URLs, and bodies, and combined by a simple ensemble approach that weighted-sums the retrieval scores on each field. This is a single stage, bag-ofwords retrieval, which is efficient.</p><p>Another contribution of this work is a title-based weaklysupervised approach of training DeepCT. We developed a title-based training strategy that solely uses document titlebody pairs. The title-based training method was designed for cold-start scenarios and low-resource domains. Our submissions compared the title-based training strategy with the query-based training strategy <ref type="bibr" coords="1,440.63,357.11,9.20,7.86" target="#b4">[4]</ref>, which requires relevance labels.</p><p>Evaluation results show that the title-trained DeepCT is more accurate than the query-trained version at the top of the ranking, but is less effective at deeper positions. The gap can be bridged by combining the relevance-trained DeepCT with the original tf weighted documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHOD</head><p>Our approach extended DeepCT from our previous work <ref type="bibr" coords="1,549.35,468.96,9.20,7.86" target="#b4">[4]</ref>. Given a document d, it first estimates passage-level term weights using DeepCT. Next, it combines the passage-level term weights into document-level term weights. The output is a document bag-of-words representation that can be stored in a standard inverted index and retrieved by common bag-of-words retrieval models like BM25 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Passage Term Weighting using DeepCT</head><p>We first estimated a term's importance in a passage. Instead of using standard term frequency based weighting, we used DeepCT to identify essential terms that are semantically important.</p><p>Given a document d, we split it into a sequence of passages. Passages consist of natural sentences of up to about 300 words. We applied DeepCT on the passages to weight their terms. This section briefly describes DeepCT; <ref type="bibr" coords="1,527.12,642.44,9.71,7.86" target="#b4">[4]</ref> provides more details.</p><p>Given a passage p, DeepCT generates contextual token embeddings using BERT <ref type="bibr" coords="1,419.11,673.83,9.20,7.86" target="#b7">[7]</ref>, and feeds these contextualized token embeddings into a linear layer. It maps a token's contextual embedding into a real-number weight: ŷt,p = wTBERT(t, p) + b, </p><formula xml:id="formula_1" coords="2,53.80,139.33,40.85,7.86">TBERT(t, p</formula><p>) is token t's contextualized embedding in passage p; w and b are the linear combination weights and bias; and, ŷt,p is the predicted weight for token t in the passage p. ŷt,p are mostly in the range of 0-1. This is because our training labels are in 0-1, so the model learns to generate predictions also in that range.</p><p>We scale the predictions into a tf -like integer that can be used with existing retrieval models. This weight is called tfDeepCT to convey that it is an alternate way of representing the importance of term t in document d using DeepCT:</p><formula xml:id="formula_2" coords="2,100.79,260.38,192.11,9.52">tf DeepCT (t, pi) = round(N * ŷt,p i ),<label>(2)</label></formula><p>ŷt,p is the predicted weight from Eq <ref type="bibr" coords="2,197.42,276.81,10.74,7.86" target="#b1">(1)</ref>. N scales the weight into a integer range. Our TREC submissions used N = 100, which keeps two digit precision. Different from the original DeepCT <ref type="bibr" coords="2,90.09,308.20,9.20,7.86" target="#b4">[4]</ref>, we add the square-root function for smoothing.</p><p>At the end of this step, for a document d, we generated a sequence of bag-of-words passage vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extended DeepCT for Document Retrieval</head><p>Due to the input length limitation of BERT <ref type="bibr" coords="2,243.83,368.47,9.20,7.86" target="#b5">[5]</ref>, DeepCT only supports short passages <ref type="bibr" coords="2,170.82,378.93,9.20,7.86" target="#b4">[4]</ref>. This work extended it also to support long documents.</p><p>The extended DeepCT generates a document bag-of-words representation from the passage-specific ones, and performs retrieval at the document level. A term's importance is a weighted sum of its DeepCT importance in each passage:</p><formula xml:id="formula_3" coords="2,53.80,439.48,176.35,12.55">tf DeepCT (t, d) = n i=1 1 i × tf DeepCT (t, pi). 1</formula><p>i discounts passages based on the position, following findings in prior research that passages at the beginning of a document tend to attract more attention from readers and are more important for relevance estimation <ref type="bibr" coords="2,152.59,483.54,9.72,7.86" target="#b8">[8,</ref><ref type="bibr" coords="2,165.37,483.54,6.48,7.86" target="#b1">1]</ref>.</p><p>We store the weighted documents into an inverted index, where the new term weights replace the standard term frequency fields in the inverted lists <ref type="bibr" coords="2,183.82,514.92,9.20,7.86" target="#b3">[3]</ref>. This new index is called DeepCT-Index. DeepCT-Index is expected to improve retrieval by identifying key terms in a document.</p><p>DeepCT-Index is retrieved using the out-of-the-box BM25 formula. During retrieval, the term frequency field in BM25 is replaced with the term weights stored in the DeepCT-Index. Multiple document fields, such as titles, URLs, and bodies are combined by a simple ensemble approach that weighted-sums the retrieval scores on each field (BM25E).</p><p>In terms of efficiency, DeepCT-Index does not introduce new words into documents, so the index does not become larger. Usually, DeepCT-Index reduces the index size as some terms' weight becomes 0 during the scaling in Eq (2), thus can be faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training DeepCT</head><p>As described in <ref type="bibr" coords="2,136.82,690.26,9.20,7.86" target="#b4">[4]</ref>, DeepCT is trained on a passagelevel per-token regression task. Assume we have the ground truth term weight for a term t in a passage p, denoted as yt,p. DeepCT minimizes the mean square error between the predicted weights ŷ and the target weights y:</p><formula xml:id="formula_4" coords="2,377.92,174.42,178.00,19.91">M SE = p t∈p (yt,p -ŷt,p) 2 .<label>(3)</label></formula><p>In this work, we explored two ways of generating ground truth labels yt,p, as described below.</p><p>Query-based Training. This approach follows the training strategy in our previous work <ref type="bibr" coords="2,453.59,233.78,9.20,7.86" target="#b4">[4]</ref>. Given a training document d, its passages P d = {p1, ..., pn}, and its relevant queries Q d = {q1, ..., q b }, we generate the query-based training labels for each passage using the query term-recall <ref type="bibr" coords="2,538.26,265.17,9.20,7.86" target="#b4">[4]</ref>: </p><formula xml:id="formula_5" coords="2,378.04,289.32,177.88,20.24">yt,p = |Q d,t | |Q d | , p ∈ {p1, ..., pn}.<label>(4)</label></formula><p>In this work, title-based training used randomly sampled documents from the TREC 2019 DL Track document ranking corpus. It does not require any labeled data, making it a good fit for low-resource domains and cold-start scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL SETUP</head><p>We trained all DeepCT models for 100K steps with a batch size of 16 and a learning rate of 2e-5. The BERT component was initialized with the official pre-trained BERT (uncased, base model) <ref type="bibr" coords="2,368.29,554.27,9.20,7.86" target="#b7">[7]</ref>. The max input length of BERT was set to 512 tokens. The scaling coefficient N in Eq (2) were set to 100.</p><p>The trained DeepCT models were used to weight all document bodies in the MS-MARCO document ranking collection. The whole collection consists of 4 million documents. We used Lucene to build the DeepCT-Indexes. Separate indexes were built for other documents fields, including the title and the URL.</p><p>We used the BM25 implementation from the Anserini [9] toolkit to retrieve documents from the indexes. BM25 scores on different document fields are combined through a simple ensemble approach that weighted-sums the scores (BM25E). The parameters of BM25E were tuned on the evaluation query sets, including the k1 and b parameters in BM25 and the field weights in the ensemble model. Per Topic P@10 Best P@10 Median P@10 Worst P@10 dct_qp_bm25e dct_tp_bm25e dct_tp_bm25e2</p><p>(c) Per Topic P@10. Topics are sorted by median scores.</p><p>Figure <ref type="figure" coords="3,84.99,516.70,3.58,7.86">1</ref>: Per Topic Score Distribution. The per-topic AP/NDCG/P@10 scores achieved by our 3 runs, and the minimum, maximum, and median scores achieved across the 38 submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SUBMITTED RUNS AND EVALUATION</head><p>We submitted three runs with different configurations. These runs differ in how DeepCT was trained, and which fields were used by the retrieval model BM25E.</p><p>• dct_qp_bm25e: This run used the query-based strategy to train DeepCT, relying on the sparse relevance labels provided by the TREC 2019 DL Track training set. Document bodies were indexed with the DeepCT term weights. At query time, documents were ranked by the ensemble of BM25 scores (BM25E) from the title, URL, and the DeepCT weighted body.</p><p>• dct_tp_bm25e: This run used the title-based strategy to train DeepCT, relying on the document title-body pairs from the TREC 2019 DL Track document collection. Document bodies were indexed with the DeepCT term weights. At query time, documents were ranked by the ensemble of BM25 scores (BM25E) from the title, URL, and the DeepCT weighted body.</p><p>• dct_tp_bm25e2: This run used the same title-trained DeepCT model as used in dct_tp_bm25e. At query time, documents were ranked by the ensemble of BM25 scores (BM25E) from the title, URL, the DeepCT weighted body, and the original term frequency (tf ) weighted body.</p><p>Table <ref type="table" coords="3,351.87,219.53,4.61,7.86" target="#tab_0">1</ref> lists the official overall evaluation results of the submitted runs.</p><p>Query-based Training vs. Title-based Training As can be seen from Table <ref type="table" coords="3,414.36,250.91,3.58,7.86" target="#tab_0">1</ref>, when the retrieval model is kept the same, the query-trained DeepCT (dct_qp_bm25e) performed better than the title-trained one (dct_qp_bm25e) at MAP@1000 and NDCG@1000, but was worse in terms of P@10.</p><p>It was to our surprise that the query-trained model had a lower P@10. This might be due to the differences between the training labels and the evaluation labels. The training used sparse relevance labels derived from user clicks <ref type="bibr" coords="3,543.65,334.60,9.20,7.86">[6]</ref>. The official TREC evaluation used manual, graded relevance judgments. The two types of labels might prefer different types of documents.</p><p>The title-trained DeepCT had a higher P@10. It confirmed our assumption that the titles provide a high-quality summary of the aboutness of the documents, and are helpful for determining term importance. It indicates that it is promising to train DeepCT solely based on the content and internal structures of documents, without using any manual relevance annotations or user data.</p><p>Ensemble of Multiple Document Representations. Comparing dct_qp_bm25e and dct_qp_bm25e2, we found that adding the original tf -weighted documents to the DeepCT weighted documents was beneficial. The precision at the top of the ranking (P@10) remained high, while the lower rankings were largely improved (MAP@1000 and NDCG@1000). tf and DeepCT provide two different representations of the same document text -one based on term frequency and one based on deep language modeling. Our results indicate that the two representations reflect different characteristics of the documents, and were both useful for document retrieval.</p><p>Per-Topic Evaluation. Figure <ref type="figure" coords="3,466.05,564.74,4.61,7.86">1</ref> shows the per-topic evaluation results. It compares the per-topic scores achieved by our runs to the min, max and median scores achieved across the 38 submitted runs in the TREC 2019 Deep Learning track document ranking task. First, our three runs had consistent behavior, indicating that the different training strategies do not lead to very different models. When compared to runs submitted from other teams, our runs are around the median in terms of MAP and NDCG (@1000). In terms of P@10, our runs had more topics lower than the median. Our runs are simple single-stage, bag-of-words retrieval from the entire collection. Hence their precision is likely to be lower than most re-ranking methods, such as learning-to-rank approaches. In general, our runs seem to be of low-risk -they were rarely near the min scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we present our methods in the TREC 2019 Deep Learning Track document ranking task. We took an efficient BM25 retrieval approach, but estimated the indexing term weights using the DeepCT framework based on our previous work <ref type="bibr" coords="4,111.75,112.43,9.20,7.86" target="#b4">[4]</ref>. Evaluation results suggest that the model can benefit from multiple document representations. The analysis also reveals a promising future direction of training DeepCT using the internal structures of documents without manual relevance annotations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,325.78,316.65,230.15,7.86;2,316.81,327.11,239.11,7.86;2,316.81,337.57,136.89,7.86;2,325.78,348.01,230.14,7.89;2,316.81,358.50,239.11,7.86;2,316.81,368.96,161.12,7.86;2,325.78,379.42,233.45,8.35;2,316.81,389.88,239.11,8.35;2,316.81,400.34,216.04,7.86;2,353.60,416.78,165.53,8.35"><head></head><label></label><figDesc>In this work, query-based training uses the sparse relevance labels provided by the training set of the TREC 2019 DL Track document ranking task. Title-based Training. Titles provide a short summary of what a document is about. A term is considered essential to the document if the title mentions it. Given a training document d, its passages P d = {p1, ..., pn}, and its title title d , the title-based weak-supervision approach generates passage level training data as the following: yt,p = 0 if t ∈ title d else 0, p ∈ {p1, ..., pn}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.36,150.48,3.28,5.84;3,67.44,134.29,8.32,5.84;3,67.44,118.09,8.32,5.84;3,67.44,101.89,8.32,5.84;3,67.44,86.06,8.32,5.84;3,72.36,69.86,3.28,5.84;3,82.12,159.12,182.53,5.84;3,147.34,59.23,39.01,7.13;3,98.25,169.56,19.91,5.84;3,151.58,169.56,28.55,5.84;3,204.91,169.56,24.58,5.84;3,98.25,179.64,148.82,5.84;3,66.51,195.58,200.53,6.99;3,72.36,301.39,3.28,5.84;3,67.44,285.20,8.32,5.84;3,67.44,269.00,8.32,5.84;3,67.44,252.81,8.32,5.84;3,67.44,236.97,8.32,5.84;3,72.36,220.77,3.28,5.84;3,82.12,310.03,182.53,5.84;3,141.94,210.14,49.63,7.13;3,98.25,320.47,28.56,5.84;3,151.58,320.47,37.21,5.84;3,204.91,320.47,33.24,5.84;3,98.25,330.55,148.82,5.84;3,59.19,346.49,215.17,6.99;3,72.36,452.31,3.28,5.84;3,67.44,436.11,8.32,5.84;3,67.44,419.91,8.32,5.84;3,67.44,403.72,8.32,5.84;3,67.44,387.88,8.32,5.84;3,72.36,371.68,3.28,5.84;3,82.12,460.94,182.53,5.84"><head></head><label></label><figDesc>Per Topic AP. Topics are sorted by median scores. Per Topic NDCG. Topics are sorted by median scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,65.42,55.00,478.88,60.92"><head>Table 1 :</head><label>1</label><figDesc>Submitted runs and evaluation results.</figDesc><table coords="2,65.42,75.92,478.88,40.00"><row><cell>Runs</cell><cell>Training Labels</cell><cell>BM25E Fields</cell><cell cols="3">MAP@1000 NDCG@1000 P@10</cell></row><row><cell>dct_qp_bm25e</cell><cell>Sparse Relevance Labels</cell><cell>title, URL, DeepCT body</cell><cell>0.2858</cell><cell>0.5477</cell><cell>0.6140</cell></row><row><cell>dct_tp_bm25e</cell><cell>Document Titles</cell><cell>title, URL, DeepCT body</cell><cell>0.2628</cell><cell>0.5240</cell><cell>0.6372</cell></row><row><cell>dct_tp_bm25e2</cell><cell>Document Titles</cell><cell>title, URL, tf body, DeepCT body</cell><cell>0.2852</cell><cell>0.5490</cell><cell>0.6349</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This research was supported by <rs type="funder">NSF</rs> grant <rs type="grantNumber">IIS-1815528</rs>. Any opinions, findings, and conclusions in this paper are the authors' and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_x9MTn5X">
					<idno type="grant-number">IIS-1815528</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,58.28,235.34,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.99,250.61,216.36,7.86;4,67.99,261.07,222.96,7.86;4,67.99,271.53,201.41,7.86;4,67.99,282.00,223.59,7.86;4,67.99,292.46,206.98,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,190.22,261.07,100.73,7.86;4,67.99,271.53,86.78,7.86">Enhanced news retrieval: Passages lead the way</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Catena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">I</forename><surname>Muntean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,174.90,271.53,94.51,7.86;4,67.99,282.00,223.59,7.86;4,67.99,292.46,151.77,7.86">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.99,303.91,204.30,7.86;4,67.99,314.37,198.26,7.86;4,67.99,324.83,100.51,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,67.99,314.37,182.92,7.86">Overview of the trec 2019 deep learning track</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In TREC (to appear</note>
</biblStruct>

<biblStruct coords="4,67.99,336.29,204.00,7.86;4,67.99,346.75,212.90,7.86;4,67.99,357.21,67.60,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,246.01,336.29,25.98,7.86;4,67.99,346.75,174.27,7.86">Search Engines -Information Retrieval in Practice</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Pearson Education</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.99,368.67,218.29,7.86;4,67.99,379.13,207.65,7.86;4,67.99,389.59,157.94,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,156.45,368.67,129.84,7.86;4,67.99,379.13,204.09,7.86">Context-aware sentence/passage term importance estimation for first stage retrieval</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10687</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,67.99,401.05,210.82,7.86;4,67.99,411.51,211.96,7.86;4,67.99,421.97,173.07,7.86;4,67.99,432.43,96.95,7.86" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="4,92.44,411.51,187.52,7.86;4,67.99,421.97,108.04,7.86">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,67.99,443.89,220.81,7.86;4,67.99,454.35,199.40,7.86;4,67.99,464.81,204.97,7.86;4,67.99,475.27,157.94,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<title level="m" coord="4,183.71,454.35,83.68,7.86;4,67.99,464.81,201.00,7.86">Ms marco: A human generated machine reading comprehension dataset</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,67.99,486.73,221.05,7.86;4,67.99,497.19,222.20,7.86;4,67.99,507.65,20.96,7.86" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05950</idno>
		<title level="m" coord="4,208.94,486.73,80.10,7.86;4,67.99,497.19,81.44,7.86">Bert rediscovers the classical nlp pipeline</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,67.99,519.11,184.83,7.86;4,67.99,529.57,205.05,7.86;4,67.99,540.03,214.71,7.86;4,67.99,550.49,224.29,7.86;4,67.99,560.95,224.91,7.86;4,67.99,571.41,20.96,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,67.99,529.57,205.05,7.86;4,67.99,540.03,139.00,7.86">Investigating passage-level relevance and its role in document-level relevance judgment</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,226.04,540.03,56.66,7.86;4,67.99,550.49,224.29,7.86;4,67.99,560.95,221.08,7.86">Proceedings of the 42nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.99,582.87,214.17,7.86;4,67.99,593.33,201.22,7.86;4,67.99,603.79,202.31,7.86;4,67.99,614.25,179.60,7.86;4,67.99,624.71,113.67,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,190.19,582.87,91.98,7.86;4,67.99,593.33,185.82,7.86">Anserini: Enabling the use of lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,67.99,603.79,202.31,7.86;4,67.99,614.25,179.60,7.86;4,67.99,624.71,85.82,7.86">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
