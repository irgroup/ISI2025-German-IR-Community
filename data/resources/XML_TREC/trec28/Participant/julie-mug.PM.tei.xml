<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.99,84.23,319.69,15.44;1,207.17,104.15,198.17,15.44">JULIE Lab &amp; Med Uni Graz @ TREC 2019 Precision Medicine Track</title>
				<funder ref="#_fmMVKqz">
					<orgName type="full">German Bundesministerium für Bildung und Forschung (BMBF)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,111.30,130.33,62.33,10.59"><forename type="first">Erik</forename><surname>Faessler</surname></persName>
							<email>erik.faessler@uni-jena.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Jena University Language &amp; Information Engineering (JULIE) Lab Friedrich-Schiller-Universität Jena Jena</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.10,130.33,75.11,10.59"><forename type="first">Michel</forename><surname>Oleynik</surname></persName>
							<email>michel.oleynik@stud.medunigraz.at</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for Medical Informatics, Statistics and Documentation</orgName>
								<orgName type="institution">Medical University of Graz Graz</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,445.61,130.33,50.07,10.59"><forename type="first">Udo</forename><surname>Hahn</surname></persName>
							<email>udo.hahn@uni-jena.de</email>
							<affiliation key="aff2">
								<orgName type="institution">Jena University Language &amp; Information Engineering (JULIE) Lab Friedrich-Schiller-Universität Jena Jena</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.99,84.23,319.69,15.44;1,207.17,104.15,198.17,15.44">JULIE Lab &amp; Med Uni Graz @ TREC 2019 Precision Medicine Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B66BA79DCB6696E3653BEC502635A38C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems → Information retrieval</term>
					<term>Content analysis and feature selection</term>
					<term>Retrieval effectiveness</term>
					<term>Specialized information retrieval</term>
					<term>• Applied computing → Health informatics information retrieval, precision medicine, search engine evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The 2019 Precision Medicine Track at TREC (TREC-PM) aimed at identifying relevant documents from two collections, namely PubMed (biomedical abstracts) and ClinicalTrials.gov (clinical trials), given 40 precision medicine topics representing (virtual) patients. The organizers also proposed a new subtask on treatment retrieval from PubMed. We describe our contributions based on five runs for each task, including two runs for the treatment subtask using a naïve strategy. Our approach builds upon carefully designed weighted queries based on our experience from last year's participation and explores the usefulness of Learning to Rank (LETOR), trained on either the previous official gold standards or an internal reference standard for the topics chosen for the 2019 challenge. Our best results culminated in infNDCG = 0.5783, P@10 = 0.6525, and R-Prec = 0.3572 for the biomedical abstracts task and infNDCG = 0.6451, P@10 = 0.5474, and R-Prec = 0.4814 for the clinical trials task, obtained with a baseline retrieval strategy. LETOR worsened our results, especially when using the internal reference standard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Driven by the decreasing costs of whole genome sequencing, the field of precision medicine has gained traction as a way to deliver optimal treatments for patients with specific biomarkers <ref type="bibr" coords="1,256.26,559.03,9.23,7.94" target="#b1">[2,</ref><ref type="bibr" coords="1,267.44,559.03,6.10,7.94" target="#b2">3,</ref><ref type="bibr" coords="1,275.49,559.03,6.15,7.94" target="#b4">5]</ref>. In this scenario, health professionals have to deal with an increasingly large amount of information available in scientific studies and clinical trials. In order to gain deeper insights into this poorly structured process, since 2017 the National Institute of Standards and Technology (NIST) has organized the TREC Precision Medicine (TREC-PM) challenge. TREC-PM aims at retrieving relevant documents from two collections, namely biomedical abstracts (BA) from PubMed and clinical trials (CT) from ClinicalTrials.org, given topics representing virtual patients (as an example, see Figure <ref type="figure" coords="1,245.89,657.66,2.94,7.94">1</ref>).</p><p>In 2019, TREC-PM for the first time did not only have topics exclusively about cancer, but additionally included ten topics on other health conditions such as "aortic aneurysm", "long QT syndrome", and "malignant hyperthermia". Furthermore, the organizers &lt; topic number = " 1 " &gt; &lt; disease &gt; melanoma &lt;/ disease &gt; &lt; gene &gt; BRAF ( E586K ) &lt;/ gene &gt; &lt; demographic &gt;64 -year -old female &lt;/ demographic &gt; &lt;/ topic &gt; Figure <ref type="figure" coords="1,380.50,276.18,3.45,7.70">1</ref>: An example of a TREC-PM topic.</p><p>of TREC-PM also proposed a subtask on treatment ranking for BA with the goal of maximizing recall of possible treatments. Finally, a newer snapshot of PubMed and ClinicalTrials.org was provided, incorporating the previously distinct collections from the American Association for Cancer Research (AACR) and the American Society of Clinical Oncology (ASCO).</p><p>In this paper, we describe our participation at the TREC-PM 2019 challenge (team labeled "julie-mug"). In Section 2, we detail the strategies underlying our experimental framework <ref type="bibr" coords="1,520.44,397.46,9.36,7.94" target="#b6">[7,</ref><ref type="bibr" coords="1,532.04,397.46,7.38,7.94" target="#b8">9]</ref> (Section 2.1) in order to obtain baseline results (Section 2.2) and then introduce the construction of an internal reference standard (Section 2.3) that allowed us to experiment with LETOR directly on the 2019 TREC-PM topics (Section 2.4). We also describe our approach to treatment ranking (Section 2.5) and indicate improvements for clinical trials (Section 2.6). We finally present the results of our approach in Section 3 and discuss their limitations in Section 4. Section 5 summarizes our findings to foster future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Experimental Framework</head><p>We built upon our previous work using the Free and Open-Source Software (FOSS) Java framework based on query templates and query decorators, described in detail in López-García et al. <ref type="bibr" coords="1,546.62,559.03,9.43,7.94" target="#b6">[7]</ref>, Oleynik et al. <ref type="bibr" coords="1,367.46,569.99,9.36,7.94" target="#b8">[9]</ref>. We further expanded this framework to allow the incorporation of manually-defined terminologies to better handle TREC-PM-specific query expansions. This allowed us to accommodate to topics not related to cancer (which should not boost keywords such as "cancer" like we do for cancer-related topics), specifically map solid tumors, and define additional mappings not found in terminologies (such as "colon" ↔ "colorectal"). Our source code is publicly available at https://github.com/JULIELab/trec-pm.</p><p>Upon manual inspection, we added 13 new terms into our list of domain stop words, a step that caused substantial benefit in experiments with preliminary data. We also streamlined the process for internal gold standard construction (see Section 2.3) by automating the upload of experimental results to an online spreadsheet used for shared annotation efforts and the download of newly generated annotations from the respective sheet in the .qrels format.</p><p>We leveraged the Unstructured Information Management Architecture (UIMA) to read, process, and index both the biomedical articles and the clinical trial documents following our successful experiments in 2018 (team labeled "hpi-dhc") <ref type="bibr" coords="2,194.91,142.59,9.27,7.94" target="#b8">[9]</ref>. We enriched documents with gene mention annotations produced by the Banner gene tagger as offered by the jcore-banner-ae-biomedical-english component which is part of the JCoRe projects<ref type="foot" coords="2,222.95,173.32,3.38,6.44" target="#foot_0">1</ref> component repository. The employed model was trained on data from the BioCreative II Gene Mention task. <ref type="foot" coords="2,135.56,195.23,3.38,6.44" target="#foot_1">2</ref> We integrated the JeDIS <ref type="bibr" coords="2,235.77,197.38,10.68,7.94" target="#b3">[4]</ref> architecture to store the annotated documents in a PostgreSQL database and thus speed up document access for LETOR and creation of different development versions of the the ElasticSearch (ES) indices without the need to run Banner multiple times. We created the ES 5.4 indices with the JCoRe ElasticSearch Consumer. <ref type="foot" coords="2,236.59,250.03,3.38,6.44" target="#foot_2">3</ref> Figure <ref type="figure" coords="2,268.54,252.18,4.22,7.94" target="#fig_0">2</ref> gives an overview of our experimental setup. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Baseline Retrieval Strategy</head><p>We here describe the baseline retrieval strategy for all of our runs.</p><p>Query structure. All queries created from the topics for document retrieval were ultimately formulated as ElasticSearch (ES) JSON queries and shared a common base structure. The main query for each topic consists of a compulsory clause that contains the disease and gene aspects of each topic. An optional clause adds general relevance signals to boost Precision Medicine (PM)-related documents and documents about cancer (for corresponding topics) that are described in <ref type="bibr" coords="2,101.15,639.89,9.51,7.94" target="#b8">[9]</ref>. Finally, a prohibitive clause matches documents on the term non-melanoma to reduce the number of false positives in our retrieval results.</p><p>Query expansion. We expanded the query topic fields disease and gene to boost the recall of our retrieval runs and feature creation for the LETOR approach. Following Oleynik et al. <ref type="bibr" coords="2,481.05,109.71,9.36,7.94" target="#b8">[9]</ref>, such aspects were formulated as dis_max queries of subquery clauses. The dis_max clauses are comprised of the original topic term -the disease or gene name -and one additional clause for each query expansion element. For disease query expansion, we leveraged the Lexigram API. <ref type="foot" coords="2,333.05,162.36,3.38,6.44" target="#foot_3">4</ref> We retrieved disease preferred names and synonyms and added them to separately weighted search clauses as described next. We also expanded gene symbols with the description and synonyms provided by the NCBI Gene database. <ref type="foot" coords="2,454.76,195.23,3.38,6.44" target="#foot_4">5</ref>Query boosting. A central element of our current and previous TREC-PM challenge contributions is the query clause weighting schema applied to the ES queries. The weights were chosen manually by experimenting on internal gold standard data and, for newer challenges, the official gold data from previous years. The most important query clauses -the disease and gene dis_max query parts -were boosted with a factor of 1.5 to elevate them above the optional relevance signals. The weighting and the specific query type of the nested disease and gene dis_max clauses also impact the final results. Table <ref type="table" coords="2,401.87,313.18,4.22,7.94" target="#tab_0">1</ref> depicts the exact values we used. Details about the query types can be found in the ES documentation. <ref type="foot" coords="2,540.37,321.99,3.38,6.44" target="#foot_5">6</ref> We additionally downgraded documents with empty abstracts, <ref type="foot" coords="2,533.41,332.95,3.38,6.44" target="#foot_6">7</ref> since their value for processing seemed to be be very limited. Hand-crafted rules. For the clinical trials task, we further expanded topics with the corresponding gene family using a regular expression and a mapping for solid tumors as described by Oleynik et al. <ref type="bibr" coords="2,339.53,536.59,9.43,7.94" target="#b8">[9]</ref>. Additionally, we expanded corresponding topics with colon ↔ colorectal for both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Reference Standard</head><p>Since topics in 2019 differed from the previous TREC-PM editions, we created an internal gold standard to evaluate our experiments in the interim. Two annotators (a medical student and a co-author) assessed in total 454 biomedical abstracts and 403 clinical trials. Out of those, 172 abstracts and 65 trials were annotated by both of them, with an agreement rate (Cohen's kappa) of 75,22% (disagreement in 27 abstracts) and 80,90% (disagreement in 7 trials). We used the internal gold standard to evaluate several experiments and also to train the LETOR algorithm (see Section 2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Learning to Rank</head><p>We implemented a Learning to Rank (LETOR) approach <ref type="bibr" coords="3,272.47,133.66,10.68,7.94" target="#b5">[6]</ref> to rerank documents as an additional step after document retrieval (see Figure <ref type="figure" coords="3,94.97,155.58,2.90,7.94" target="#fig_1">3</ref>). Overall, we trained four LETOR models, two for the BA and CT task, respectively. For each task, one model was trained on our internal TREC-PM 2019 gold standard and the other on the union of the two previous official gold standards (from the 2017 and 2018 editions). We used the LambdaMART <ref type="bibr" coords="3,224.57,199.42,10.43,7.94" target="#b0">[1]</ref> implementation of RankLib<ref type="foot" coords="3,96.78,208.23,3.38,6.44" target="#foot_7">8</ref> to train the LETOR models and rerank documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>We explored four main classes of features:</head><p>Binary vocabulary features. We created binary features for the 500 words with highest TF-IDF from the gold standard of each task indicating the word presence.</p><p>Matches of the topic with the document. We created features reflecting how well a document matches the query topic by recording string matches of the topic's disease (with its synonyms and hypernyms), gene (with its synonyms), gene variant, and only the variant in the document. For each match type, we set the feature value to the number of matches, i.e., if the gene name of a topic matched three times, the feature "gene name match" was set to 3.</p><p>BM25 scores of the topic matched with document fields. We added features for different Okapi BM25 scores between the topic and the document. The calculated BM25 scores originated from: (1) the complete topic baseline query score, including disease, gene, their synonyms, and other relevance signals (as described in Section 2.2);</p><p>(2) only the disease and its synonyms; (3) only the gene and its synonyms; (4) the optional relevance signal keywords also used in the baseline query.</p><p>FastText document embeddings of the document. Finally, we calculated the fastText document embedding <ref type="bibr" coords="3,213.48,633.91,10.42,7.94" target="#b7">[8]</ref> for the document. <ref type="foot" coords="3,290.17,631.76,3.38,6.44" target="#foot_8">9</ref>The embeddings were trained on a PubMed subset containing gene mentions as identified by the Banner annotator described in Section 2.1 with a dimension of 300. All other parameters were left unset, resulting in the default settings of the fastText program.  In parallel, we also explored the existence of any valid treatment (whitelisted semantic type and not in the term stoplist) as a ranking signal during document retrieval, even if not a treatment run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Clinical Trials Experiments</head><p>We experimented with two extra query variations for the CT task on top of the baseline retrieval strategy described in Section 2.2. First, in the run jlctgenes, we matched the topic gene not only with the document text, but also with a specific field filled only with gene names automatically extracted by the Banner gene tagger (see Section 2.1) following our previous successful experiments reported with biomedical abstracts. Second, in the run jlctprec, we refrained from matching all remaining documents to fill up the result list in order to improve precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>The following list enumerates the elements used for the run names:</p><p>(1) jl: JULIE Lab, (2) pm: PubMed, (3) ct: Clinical Trials, (4) tr: runs annotated with treatments, (5) letor/ltr: learning to rank,<ref type="foot" coords="3,436.35,559.18,6.76,6.44" target="#foot_11">11</ref> (6) in: internal reference standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Biomedical Abstracts</head><p>Table <ref type="table" coords="3,340.68,606.98,4.25,7.94" target="#tab_2">3</ref> depicts the different strategies implemented for the five runs submitted for the BA task, as well as the corresponding results. Two runs included treatment annotations and therefore also include the corresponding metrics. Figure <ref type="figure" coords="3,447.04,639.86,4.25,7.94">4</ref> depicts a visual overview of the official results, while detailed results per topic are shown in Figure <ref type="figure" coords="3,343.49,661.78,4.17,7.94">6</ref> in the Appendix.  The best performing run across all metrics was jlpmcommon2. This run closely resembles our top performing runs from last year with an additional check for existence of valid treatments as described in Section 2.5, including the treatment stop list.</p><p>The runs jlpmtrboost and jlpmtrcommon included treatment information and therefore documents were reranked as described in Section 2.5. While the former run is similar to the baseline run jlpmcommon2, the latter did not include a check for a valid treatment during retrieval using the stop list. The results also show that treatment re-ranking had a negative impact on the outcome of overall metrics, except for P@10, which reflects a smaller impact. Moreover, the additional check for a valid treatment during retrieval (in the run jlpmtrboost) improved not only overall metrics (e.g., +0.0150 P@10), but also treatment metrics (e.g., +0.0159 Recall@10). Additional experiments are required to test whether the same effect would be observed with a regular run.</p><p>Finally, the runs jlpmletor and jlpmltrin also used the baseline retrieval strategies to obtain documents from ES, on top of which LETOR was applied to re-rank documents. The LETOR model used for the jlpmletor run was trained on the union of TREC-PM 2017 and 2018 gold standards. The jlpmltrin run used a model trained on the internal reference data (see Section 2.3). The jlpmletor run performed similarly to jlpmcommon2 albeit with a smaller variance across topic scores, while the jlpmtrin run exhibited the worst score of our BA runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Clinical Trials</head><p>Table <ref type="table" coords="4,339.85,101.49,4.19,7.94" target="#tab_3">4</ref> shows the retrieval and re-ranking features applied to the CT runs, as well as the official evaluation results. As described in Section 2.6, we experimented with small query variations and LETOR on top of the baseline retrieval strategy. Figure <ref type="figure" coords="4,517.45,134.37,4.10,7.94">5</ref> compares CT results using boxplots across all topics, while detailed results per topic are shown in Figure <ref type="figure" coords="4,428.03,156.29,4.17,7.94">7</ref> in the Appendix. Run jlctphrase closely resembles our top performing run from last year and is thus considered our baseline here. It includes an exact (phrase) match on the disease topic for optimal precision and ranks best for P@10, in a tie with run jlctgenes.</p><p>The jlctprec run is similar to the above, but omitted a clause to retrieve all remaining documents (see Section 2.6). Even though the effect of this precision-optimization is minor, it is visible in the results as an increase of 0.0021 in R-Prec. Compared to the baseline, the jlctgenes run matches genes automatically extracted from text and obtained the best metrics across all runs.</p><p>The LETOR runs jlctletor and jlctltrin reveal decreased evaluation scores similarly to the BA task, in which the internal 2019 reference standard led to worse results than the union of previous official annotations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>Our optimal approaches described before led to the best metrics across all participating teams -except P@10 for CT, in which we ranked second. Nonetheless, future work is required to overcome some issues found, especially regarding the treatment subtask.</p><p>With respect to the treatment subtask, we would like to further explore techniques to refine the result list. Since only three treatments are accepted per document, we would like to better prioritize them using both a local and a global strategy. In a local context, we would like to explore syntactic features to, e.g., prioritize longer, more specific, candidates such as "monoclonal antibodies" instead of "adjuvant". Conversely, in a global context, we would like to try to optimize the result list using, e.g., LETOR methods to reorder the list. An automatic "treatment tagger" taking into account semantic information like word embeddings could be helpful to make the manual filtering of treatment terms obsolete. This would save manual labor and, hopefully, generalize to terms not in the list. We finally believe treatment runs could be further refined in ways different than regular runs, e.g., by boosting documents about treatment, cross-referencing DGIdb data on drugs, <ref type="foot" coords="5,240.37,239.07,6.76,6.44" target="#foot_12">12</ref> and looking further down on the result list for potential matches.</p><p>Moreover, our LETOR approaches surprisingly decreased evaluation scores for both tasks. Since one LETOR feature is the BM25 score of the underlying run, this result comes completely unexpected. Future work is needed to measure how many documents need to be annotated so that an internal reference standard can produce better results than a baseline run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In our previous appearance at TREC-PM, we showed that dis_max queries proved useful to expand queries without a drop in precision and successfully associated it with ranking signals related to precision medicine. Our current work further expanded that with Learning to Rank and a baseline strategy for treatment ranking, as well as additional minor query enhancements. Our LETOR approach surprisingly worsened all performance scores in both tasks, especially when using the internal reference standard.</p><p>In the biomedical abstracts task, checking for valid treatments during retrieval improved treatment runs, but it is unclear whether the same effect would be seen on regular runs. In the clinical trials task, matching all documents as a failover slightly worsened results, whereas matching extracted genes had a positive effect. The latter corroborates our conclusions from last year, where we showed a A RESULTS PER TOPIC  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,80.93,490.09,185.99,7.70"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of our experimental setup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,85.78,366.67,176.29,7.70"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Features used for training LETOR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,340.64,276.58,18.15,6.18;3,405.90,276.58,57.88,6.18;3,340.64,289.07,31.63,6.18;3,406.32,289.07,129.20,6.18;3,340.64,297.04,162.50,6.18;3,340.64,305.01,128.28,6.18"><head></head><label></label><figDesc>Preventive Procedure Chemicals &amp; Drugs T121 Pharmacologic Substance Chemicals &amp; Drugs T200 Clinical Drug</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,53.80,390.42,240.25,7.70;4,53.80,401.38,157.25,7.70"><head>Figure</head><label></label><figDesc>Figure Biomedical abstracts: boxplots comparing our runs to the average best and median results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="4,317.96,603.94,240.25,7.70;4,317.96,614.90,131.47,7.70"><head>Figure</head><label></label><figDesc>Figure Clinical Trials: boxplots comparing our runs to the average best and median results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,159.69,687.03,292.62,7.70"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Biomedical Abstracts: metrics per topic for the submitted runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,317.66,370.22,240.54,107.10"><head>Table 1 :</head><label>1</label><figDesc>Weight values and query types for diseases and genes for both tasks.</figDesc><table coords="2,322.94,406.32,230.89,71.00"><row><cell></cell><cell></cell><cell cols="2">Biomedical Abstracts</cell><cell cols="2">Clinical Trials</cell></row><row><cell cols="2">Expansion Type</cell><cell>Query Type</cell><cell cols="2">Weight Query Type</cell><cell>Weight</cell></row><row><cell cols="2">Disease Original</cell><cell>best_fields</cell><cell>1.0</cell><cell>phrase, slop=0</cell><cell>1.0</cell></row><row><cell></cell><cell>Preferred</cell><cell>best_fields</cell><cell>0.1</cell><cell>phrase, slop=0</cell><cell>0.1</cell></row><row><cell></cell><cell>Synonyms</cell><cell>phrase, slop=0</cell><cell>0.1</cell><cell>phrase, slop=0</cell><cell>0.1</cell></row><row><cell>Gene</cell><cell>Original</cell><cell>best_fields</cell><cell>1.0</cell><cell>best_fields</cell><cell>1.0</cell></row><row><cell></cell><cell cols="2">Description phrase, slop=10</cell><cell>0.1</cell><cell>phrase, slop=0</cell><cell>0.1</cell></row><row><cell></cell><cell>Synonyms</cell><cell>phrase, slop=0</cell><cell>0.7</cell><cell>phrase, slop=0</cell><cell>0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,332.77,251.44,210.32,7.70"><head>Table 2 :</head><label>2</label><figDesc>Semantic types used for treatment filtering.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,53.50,85.73,240.54,148.48"><head>Table 3 :</head><label>3</label><figDesc>Biomedical Articles: description and results of runs.</figDesc><table coords="4,59.36,110.87,229.13,123.33"><row><cell></cell><cell></cell><cell></cell><cell>jlpm</cell><cell></cell><cell></cell></row><row><cell>Strategy</cell><cell>common2</cell><cell>letor</cell><cell>ltrin</cell><cell cols="2">trboost trcommon</cell></row><row><cell>Baseline strategies</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>Valid treatment exists</cell><cell>Y</cell><cell>N</cell><cell>N</cell><cell>Y</cell><cell>N</cell></row><row><cell>LETOR training data</cell><cell>-</cell><cell>2017/18</cell><cell>2019</cell><cell>-</cell><cell>-</cell></row><row><cell>treatments filter</cell><cell>Y</cell><cell>N</cell><cell>N</cell><cell>Y</cell><cell>N</cell></row><row><cell># Treatments</cell><cell></cell><cell></cell><cell></cell><cell>11,128</cell><cell>9,443</cell></row><row><cell>Recall@10</cell><cell></cell><cell></cell><cell></cell><cell>0.2857</cell><cell>0.2698</cell></row><row><cell>F 1 @10</cell><cell></cell><cell></cell><cell></cell><cell>0.3118</cell><cell>0.3019</cell></row><row><cell>Recall@25</cell><cell></cell><cell></cell><cell></cell><cell>0.4603</cell><cell>0.4469</cell></row><row><cell>F 1 @25</cell><cell></cell><cell></cell><cell></cell><cell>0.3793</cell><cell>0.3716</cell></row><row><cell>infNDCG</cell><cell>0.5783</cell><cell>0.5740</cell><cell>0.2014</cell><cell>0.3876</cell><cell>0.3745</cell></row><row><cell>P@10</cell><cell>0.6525</cell><cell>0.6050</cell><cell>0.0650</cell><cell>0.5925</cell><cell>0.5775</cell></row><row><cell>R-Prec</cell><cell>0.3572</cell><cell>0.3527</cell><cell>0.1137</cell><cell>0.1639</cell><cell>0.1615</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,326.74,181.20,222.38,104.11"><head>Table 4 :</head><label>4</label><figDesc>Clinical Trials: description and results of runs.</figDesc><table coords="4,470.62,206.35,8.93,6.18"><row><cell>jlct</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,56.72,685.97,123.38,6.18"><p>https://github.com/JULIELab/jcore-projects</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,56.84,694.38,162.20,6.18"><p>http://biocreative.sourceforge.net/biocreative_2_gm.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,56.84,702.79,234.24,6.18"><p>https://github.com/JULIELab/jcore-base/tree/master/jcore-elasticsearch-consumer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,320.88,669.34,69.54,6.18"><p>https://www.lexigram.io</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,321.00,677.75,101.03,6.18"><p>https://www.ncbi.nlm.nih.gov/gene</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="2,321.00,686.16,235.90,6.18;2,317.96,694.38,108.57,6.18"><p>https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-multimatch-query.html#multi-match-types</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="2,317.83,701.13,169.02,7.84"><p><ref type="bibr" coords="2,317.83,701.13,2.55,4.85" target="#b6">7</ref> See, e.g., https://www.ncbi.nlm.nih.gov/pubmed/16521281.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="3,56.84,694.38,132.52,6.18"><p>https://sourceforge.net/p/lemur/wiki/RankLib/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="3,56.84,702.79,129.87,6.18;3,317.96,86.80,118.29,9.37;3,317.53,101.49,242.19,7.94;3,317.73,112.45,174.65,7.94"><p>https://fasttext.cc/docs/en/crawl-vectors.html2.5 Treatment SubtaskWe participated in the treatment subtask using the officially provided treatment list extracted with MetaMapLite</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="3,492.38,110.30,65.82,10.09;3,317.96,123.41,241.76,7.94;3,317.96,134.37,240.42,7.94;3,317.69,145.33,241.05,7.94;3,317.96,156.29,240.24,7.94;3,317.96,167.25,240.25,7.94;3,317.96,178.20,240.25,7.94;3,317.96,189.16,240.25,7.94;3,317.96,200.12,241.23,7.94;3,317.96,211.08,240.25,7.94;3,317.96,222.04,240.25,7.94;3,317.96,233.00,104.75,7.94"><p>.10  We filtered the list for the semantic types depicted in Table2. Upon closer inspection, we noticed that several of the extracted concepts were either (a) not a real treatment (e.g., "duration", "basis", "medicine"), (b) not drug-related (e.g., "potassium", "yeast", "glucose"), or (c) amino acids (e.g., "leu", "leucine"). We thus experimented with filtering the treatments with a manually curated stop list of 230 entries. For each document of a topic result list, we removed treatments mentioned in higher-ranking positions (in order to maximize recall) and then, for each document, ranked remaining treatments by frequency (we kept only the top-3 most frequent). We lastly removed documents not matching any treatment.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_10" coords="3,323.42,678.19,140.14,6.18"><p>https://metamap.nlm.nih.gov/MetaMapLite.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_11" coords="3,323.42,686.60,234.78,6.18;3,317.96,694.57,240.24,6.18;3,317.96,702.79,40.94,6.18"><p>Note that our officially submitted LETOR runs contained a code bug that prevented proper ranking. Meanwhile, this bug has been fixed and the updated results are provided here.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_12" coords="5,59.27,702.79,64.01,6.18;5,317.96,87.79,241.76,7.94;5,317.96,98.75,240.25,7.94;5,317.96,109.71,203.93,7.94"><p>http://www.dgidb.org/ similar effect in the BA task. However, we still perform comparatively worse when evaluated by P@10 in this task, which opens possibilities for further experiments and improvements.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank <rs type="person">Juan Carlos Niño Rodriguez</rs> for the internal gold standard construction.</p><p>The contributions of the first and third author were funded by the <rs type="funder">German Bundesministerium für Bildung und Forschung (BMBF)</rs> under grant no. <rs type="grantNumber">01ZZ1803G</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fmMVKqz">
					<idno type="grant-number">01ZZ1803G</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,330.15,220.92,228.51,6.97;5,330.15,228.89,228.05,6.97;5,330.15,237.54,27.04,6.18" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,420.57,220.92,138.09,6.97;5,330.15,228.89,33.27,6.97">From RankNet to LambdaRank to LambdaMART: an overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2010-82</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report Technical Report</note>
</biblStruct>

<biblStruct coords="5,330.15,245.51,229.13,6.18;5,330.15,252.80,158.28,6.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,450.86,245.51,105.44,6.18">A new initiative on precision medicine</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harold</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Varmus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,330.15,252.80,93.16,6.97">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="page" from="793" to="795" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.15,260.77,228.75,6.97;5,330.15,268.74,228.05,6.97;5,329.90,277.39,190.34,6.18" xml:id="b2">
	<monogr>
		<idno type="DOI">10.17226/13284</idno>
		<ptr target="https://doi.org/10.17226/13284" />
		<title level="m" coord="5,435.38,260.77,123.52,6.97;5,330.15,268.74,187.45,6.97">Toward Precision Medicine: Building a Knowledge Network for Biomedical Research and a New Taxonomy of Disease</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>The National Academies Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.15,285.36,228.06,6.18;5,330.15,292.65,228.81,6.97;5,330.15,300.62,228.06,6.97;5,330.15,309.27,109.14,6.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,428.29,285.36,119.57,6.18">Annotation data mmanagement with JeDIS</title>
		<author>
			<persName coords=""><forename type="first">Erik</forename><surname>Faessler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Udo</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,330.15,292.65,225.97,6.97">DocEng 2018 -Proceedings of the 18th ACM Symposium on Document Engineering</title>
		<meeting><address><addrLine>Halifax, Nova Scotia, Canada; New York/NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-08-28">2018. August 28-31, 2018</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.15,317.24,228.06,6.18;5,330.15,325.21,34.15,6.18" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elmer</forename><forename type="middle">V</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joshua</forename><forename type="middle">C</forename><surname>Bernstam</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Denny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Precision Medicine Informatics</note>
</biblStruct>

<biblStruct coords="5,330.15,332.50,228.05,6.97;5,330.15,340.47,162.00,6.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,398.25,333.18,120.53,6.18">Learning to rank for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,523.92,332.50,34.28,6.97;5,330.15,340.47,103.22,6.97">Foundations and Trends® in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.15,349.12,228.05,6.18;5,330.15,356.41,228.05,6.97;5,330.15,364.38,228.81,6.97;5,330.15,372.35,228.24,6.97;5,329.94,381.00,90.64,6.18" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,541.89,349.12,16.31,6.18;5,330.15,357.09,146.82,6.18">TREC 2017 Precision Medicine -Medical University of Graz</title>
		<author>
			<persName coords=""><forename type="first">Pablo</forename><surname>López-García</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michel</forename><surname>Oleynik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zdenko</forename><surname>Kasáč</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,489.04,356.41,69.16,6.97;5,330.15,364.38,96.87,6.97">TREC 2017 -Proceedings of the 26th Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA; Gaithersburg/MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="2017-11-15">2017. November 15-17, 2017</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.15,388.97,229.23,6.18;5,330.15,396.94,229.13,6.18;5,330.15,404.23,228.75,6.97;5,330.15,412.20,228.05,6.97;5,330.15,420.85,228.06,6.18;5,330.15,428.82,229.13,6.18;5,330.04,436.79,228.16,6.18;5,330.15,444.76,124.84,6.18" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,387.41,396.94,168.96,6.18">Advances in pre-training distributed word representations</title>
		<author>
			<persName coords=""><forename type="first">Tomáš</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Nicoletta Calzolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sara</forename><surname>Goggi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Koiti</forename><surname>Hasida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hélène</forename><surname>Mazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,337.80,404.23,221.10,6.97;5,330.15,412.20,60.30,6.97">LREC 2018 -Proceedings of the 11th International Conference on Language Resources and Evaluation</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stelios</forename><surname>Piperidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Takenobu</forename><surname>Tokunaga</surname></persName>
		</editor>
		<meeting><address><addrLine>Miyazaki, Japan; Asunción Moreno; Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-01-12">2018. May 7-12, 2018. Jan</date>
			<biblScope unit="page" from="52" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.15,452.73,229.23,6.18;5,330.15,460.70,228.05,6.18;5,330.15,467.99,228.05,6.97;5,329.37,475.97,229.59,6.97;5,330.15,483.94,228.06,6.97;5,330.15,492.58,134.74,6.18" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,376.64,468.67,139.73,6.18">HPI-DHC at TREC 2018 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">Michel</forename><surname>Oleynik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erik</forename><surname>Faessler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ariane</forename><forename type="middle">Morassi</forename><surname>Sasso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arpita</forename><surname>Kappattanavar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Bergner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harry</forename><surname>Freitas Da Cruz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan-Philipp</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suparno</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erwin</forename><surname>Böttinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,528.64,467.99,29.56,6.97;5,329.37,475.97,140.29,6.97">TREC 2018 -Proceedings of the 27h Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA; Gaithersburg/MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="2018-11-14">2018. November 14-16, 2018</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.38,287.28,14.33,5.70;6,107.31,176.12,5.70,24.66" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,307.38,287.28,14.33,5.70;6,107.31,176.12,5.70,24.66">Topic infNDCG</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.38,475.73,14.33,5.70;6,107.31,369.71,5.70,14.40" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="6,307.38,475.73,14.33,5.70;6,107.31,369.71,5.70,14.40">Topic P_10</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.38,262.87,14.33,5.70;7,107.31,151.71,5.70,24.66" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,307.38,262.87,14.33,5.70;7,107.31,151.71,5.70,24.66">Topic infNDCG</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.38,451.32,14.33,5.70;7,107.31,345.30,5.70,14.40" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="7,307.38,451.32,14.33,5.70;7,107.31,345.30,5.70,14.40">Topic P_10</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
