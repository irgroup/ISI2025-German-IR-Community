<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,51.14,55.67,509.72,20.73;1,146.99,83.56,318.03,20.73">Classification of Incident-related Tweets: Exploiting Word and Sentence Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.51,123.38,59.22,9.50;1,256.73,121.11,1.41,6.99"><forename type="first">Anna</forename><surname>Kruspe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR) Institute of Data Science</orgName>
								<address>
									<settlement>Jena</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.03,123.38,56.52,9.50;1,324.55,121.11,1.41,6.99"><forename type="first">Jens</forename><surname>Kersten</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR) Institute of Data Science</orgName>
								<address>
									<settlement>Jena</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.86,123.38,70.07,9.50;1,405.93,121.11,1.41,6.99"><forename type="first">Friederike</forename><surname>Klan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR) Institute of Data Science</orgName>
								<address>
									<settlement>Jena</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,51.14,55.67,509.72,20.73;1,146.99,83.56,318.03,20.73">Classification of Incident-related Tweets: Exploiting Word and Sentence Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">63FE08E34D20B44AFDF8C80CE56DFED8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present our five approaches submitted to the Text REtrieval Conference (TREC) Incident Streams (IS) 2019B edition. The goal is to classify crisis-related tweets into a variable set of information classes and to provide an importance score. This multi-class, multi-label and multitask problem turns out to be even more challenging because of extremely unbalanced training data available. We use recently proposed, publicy available word and sentence embeddings and deep neural network models for this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The 2019B Text REtrieval Conference (TREC) Incident Streams (IS) track serves as an evaluation for the classification of tweets into 25 incident-related classes. The first edition in 2018 was focusing on assigning a single class to each tweet. However, the complexity of message contents forced a change to a multi-label task. Similar to the preceding two editions, a class ontology, an annotated training data set, and a test data set without annotations were provided. The ontology comprises 25 classes describing a variety of topics during an incident, such as "Report-ServiceAvailable", "Other-Sentiment", "Request-SearchAndRescue", or "CallToAction-Donations". Additionally, importance labels are defined by four classes: "low", "medium", "high" and "critical".</p><p>For training, we used the 2019A edition data that was provided for training and testing. This composed set contains around 24,800 tweets from 21 different crisis events. Due to slight adjustments and improvements of the class ontology over editions, parts of the training data had to be mapped accordingly. Submissions were expected to assign a set of n classes as well as an importance score to each tweet. Furthermore, an incident-wise ranking according to the estimated importance was requested. We focused on training fully automatic deep neural network (DNN) models in order to contribute to these tasks. This paper describes our five submissions to the challenge. In the next section, a description of our classification approaches is provided. Furthermore, we present an analysis of the results and finish with a small conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED MODELS</head><p>In this section, we describe our five proposed models. The first one is the same as last year for comparison. As a new approach, we tested a DNN with pre-trained BERT word embeddings. We then turned to strategies for embedding the whole tweet (qua sentence) instead of separate words. Along these lines, we first tested the commonly used Smooth Inverse Frequency (SIF) approach. Finally, we built two models with pre-trained sentence embeddings, one with Google's Universal Sentence Encoder (USE), and one with mean-max attention autoencoder (Mean-Max AAE) embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Previous year's model: Fusion CNN</head><p>In the 2018 TREC-IS edition, we submitted a model based on Kim's CNN structure <ref type="bibr" coords="1,414.03,345.33,10.58,8.64" target="#b5">[6]</ref>, which is being successfully used in other crisis-related tweet analysis tasks <ref type="bibr" coords="1,497.71,357.28,10.58,8.64" target="#b1">[2]</ref>. The model showed good performance, but suffered from a lack of training data for several classes in the TREC-IS 2018 data set. For this reason, we trained similar models on the CrisisNLP <ref type="bibr" coords="1,532.97,393.15,11.62,8.64" target="#b4">[5]</ref> and CrisisLexT26 <ref type="bibr" coords="1,369.97,405.10,10.58,8.64" target="#b7">[8]</ref>, <ref type="bibr" coords="1,388.36,405.10,11.62,8.64" target="#b8">[9]</ref> data sets, and combined all three into a fusion model. The concatenated outputs of all three models are fed into a dense layer with 128 nodes and ReLu activation, followed by the output layer. For this year's challenge, we did the same with the new training set. In order to perform multiclass labeling, the original softmax output was replaced with 25 independent sigmoid layers. For importance scoring, the concatenated outputs are additionally passed to a sequence of two dense layers with ReLu activation (128 and 64 nodes), followed by a linear regression output node. For this, the importance annotations were mapped to numerical values ("low" = 0.0, "medium" =0.33, "high" = 0.66, "critical" = 1.0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DNN with BERT word embeddings</head><p>For the fusion CNN model, a pre-trained word embedding specifically trained with crisis-related tweets <ref type="bibr" coords="1,503.04,602.36,11.62,8.64" target="#b4">[5]</ref> is utilized. This enables an immediate translation of each individual word in a document or tweet into a fixed numeric vector, capturing the semantic meaning of the word. However, depending on the context, words can have different semantic meanings. Google's Bidirectional Encoder Representations from Transformer (BERT) <ref type="bibr" coords="1,376.59,674.09,11.62,8.64" target="#b3">[4]</ref> not only captures the semantic meaning of single words, but also the contextualized meaning. Here, deep bidirectional representations are learned by masking some percentage of the input tokens randomly, and then predict those masked tokens. We used a pre-trained TensorFlow Hub model<ref type="foot" coords="2,296.04,50.76,3.49,6.05" target="#foot_0">1</ref> to obtain a 768-element vector representation for each tweet. Since this representation has shown to make a CNN obsolete in our experiments, we attached three dense layers (512, 256 and 128 nodes) with ReLu activation to the embedding layer, followed by 25 sub-networks for the information type classification, and one for the importance scoring. Each subnetwork consists of a 64-dimensional fully-connected ReLU layer with a consecutive output layer. This output is a sigmoid for the 25 information type classes each, and a 1-dimensional linear node for the importance scoring (regression).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. DNN with SIF sentence embeddings</head><p>The fusion model was focused on embedding each word in a tweet separately, and treating these embeddings independently (bag-of-words). Besides the contextual BERT embedding, several approaches for embedding whole sentences have been developed successfully in the past years. Li et al. give a nice overview over using those for crisis-related tweets in <ref type="bibr" coords="2,269.69,266.48,10.58,8.64" target="#b6">[7]</ref>. One such approach that does not require a dedicated pretraining is called Smooth Inverse Frequency (SIF) <ref type="bibr" coords="2,265.76,290.39,10.58,8.64" target="#b0">[1]</ref>. The sentence's words are encoded with an arbitrary embedding, on which an average weighted by word frequencies is calculated to represent the sentence. Then, a Principal Component Analysis (PCA) is performed on the sentence vectors, and the projection of the first principal component is subtracted. This method has been shown to beat several more elaborate approaches <ref type="bibr" coords="2,97.26,374.07,10.58,8.64" target="#b0">[1]</ref>. We utilized the authors' own Python implementation <ref type="foot" coords="2,267.76,384.36,3.49,6.05" target="#foot_1">2</ref> . Word embeddings are generated using the CrisisNLP weights <ref type="bibr" coords="2,285.92,397.98,10.58,8.64" target="#b4">[5]</ref>. Word frequencies for English-language Twitter were obtained from Lexique<ref type="foot" coords="2,102.04,420.23,3.49,6.05" target="#foot_2">3</ref> . Starting with a 256-node ReLu activation dense layer attached to the embdedding layer, the model is completed in the same manner as our BERT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. DNNs with pre-trained sentence embeddings</head><p>In contrast with SIF, many other sentence embeddings function by training a specific sub-model for this task. This requires a large suitable data set from which the model can infer a latent representation. In the TREC-IS context, even the new, bigger data set is somewhat on the small side for this, especially due to the lack of training data for particular classes. Fortunately, several such sentence embeddings that have been pre-trained on very large data sets are available online. We tested two such pre-trained models. The first one is the socalled Mean-Max Attention Autoencoder (Mean-Max AAE) presented by Zhang et al. <ref type="bibr" coords="2,163.10,600.08,15.27,8.64" target="#b9">[10]</ref>. It is based on an encoderdecoder structure with a MultiHead self-attention mechanism. A TensorFlow implementation including a model pre-trained on the Toronto Books Corpus by the authors is available online <ref type="foot" coords="2,73.87,646.23,3.49,6.05" target="#foot_3">4</ref> . Second, we employed the Universal Sentence Encoder (USE) published by Cer et al. <ref type="bibr" coords="2,417.49,52.42,10.58,8.64" target="#b2">[3]</ref>. They show two versions, one using a Transformer structure and one using Deep Averaging Networks, and train them on a large set of combined data sources. The Transformer version is available from the authors on TensorFlow Hub <ref type="foot" coords="2,393.27,98.58,3.49,6.05" target="#foot_4">5</ref> . In both cases, we attach the same post-network as with the SIF models to adapt the models for information type classification and importance scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULTS AND DISCUSSION</head><p>Our approaches' results on the validation set are shown in figures 1, 2, and 3. Over-all, these are roughly in the range of those submitted to the 2019A challenge. In general, the information type classification task has become more difficult than least year due to the change to multilabeling. As figure <ref type="figure" coords="2,415.40,234.30,4.98,8.64" target="#fig_0">1</ref> shows, our model from last year performs disappointingly in terms of F 1 measure. Fortunately, both the new BERT and USE approaches produce much better results. The other two sentence embedding models, SIF and MeanMaxAAE, are not as useful. We presume that this happens because they were not developed with Twitter data in mind. SIF was designed for other types of text, and the pretrained MeanMaxAAE model was trained on text from books. For these reasons, they may not adapt well to tweets. On the other hand, USE was trained on a much larger variety of text, and as such seems to be more robust to Twitter text. A logical next step consists of developing dedicated tweet embedding models. Even though the pre-trained BERT model was trained on Wikipedia and Book Corpus <ref type="bibr" coords="2,439.55,401.67,15.27,8.64" target="#b10">[11]</ref>, i.e., data that tends to be quite different compared to tweets, the bidirectional pretraining shows up to be rather task-unspecific.</p><p>When comparing the result for all classes to that for only the high importance classes, we see that the high importance classification performs much worse in general. As we saw last year, these tweets occur much less frequently than other classes, and are therefore not highly represented in the training material, leading to difficulties in training models for these classes. Figure <ref type="figure" coords="2,343.47,533.50,9.40,8.64" target="#fig_2">2a</ref> shows the mean squared errors for the priority estimation task. We observe the same trends here: BERT and USE are the best-performing models, and the estimation is more difficult for the high-importance classes. Over-all, the errors are relatively low, but somewhat higher than those achieved by other models in the 2019A iteration of the task. We note that the multi-task approach (i.e. using the same model for both tasks) generally works, but perhaps a refined model for the priority estimation is more suitable. The Accumulated Alert Worth (AAW) results are shown in figure <ref type="figure" coords="2,340.96,653.05,8.30,8.64" target="#fig_2">2b</ref>. We observe a strange effect here: The models that performed better at both the classification and priority estimation tasks produce lower AAW values, and vice versa. A similar trend can be seen in some of the 2019A results;   we will look more closely into this. We are not sure why this happens; one possible explanation might be that the models performing worse at the priority estimation task may designate fewer tweets as high-importance, which leads to fewer tweets being taken into account for the AAW calculation.</p><p>A class-wise analysis of the positive results returned by the models is shown in figure <ref type="figure" coords="3,162.90,459.84,3.74,8.64" target="#fig_4">3</ref> BERT and USE are a bit more robust to imbalanced training data than the other approaches. For both models, the reason is probably that they are already pre-trained on a lot of semantic knowledge, and therefore are able to generalize even with few training examples on this task. However, there is still a lot of room for improvement. The easiest solution to this problem would be a collection of more training data for these underrepresented classes. Exploiting models trained on a wide variety of other material also seems to be a promising direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>For the 2019B TREC-IS track, we submitted the results of five fully automatic text classification approaches. Our proposed DNNs with state-of-the-art pre-trained word and sentence embdeddings have shown to provide similar or even better results compared to our 2018 CNN fusion model. SIF and MeanMax AAE were not developed in context of Twitter data analysis. To obtain better results here, the development of dedicated sentence embeddings is required. In contrast, our BERT and USE models produced significantly better results, demonstrating the applicabilty of the involved pretrained embeddings to a variety of applications and data. However, this task still remains challenging and offers much room for improvements. One of the main and persistent challenges of this track is the inbalanced availability of training data. The easiest solution for this might be to manually collect additional training data from other sources. Our data augmentation approach from 2018 based on automatic roundtrip translation might help to a certain degree. However, the obtained tweets might contain only slight variations and therefore are potentially redundant. A possible future research direction is the development of dedicated pre-trained tweet embdeddings. Furthermore, taking into account the class ontology hierarchy as well as the inherent dependency of class labels might help to further improve tweet classification and prioritization. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,147.76,193.04,316.49,8.64;3,177.48,50.54,257.03,134.64"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Overall positive F1 scores for all (a) and high importance classes (b).</figDesc><graphic coords="3,177.48,50.54,257.03,134.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,135.78,337.35,131.34,7.77;3,318.15,337.35,184.82,7.77"><head></head><label></label><figDesc>(a) Priority estimation error (MSE). (b) High importance and accumulated alert worth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,108.91,354.03,394.19,8.64;3,98.63,216.85,205.63,113.38"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Priority estimation error (a) as well as high importance and accumulated alert worth (b).</figDesc><graphic coords="3,98.63,216.85,205.63,113.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="3,166.63,459.84,133.39,8.64;3,48.96,471.79,251.06,8.64;3,48.96,483.75,251.06,8.64;3,48.96,495.70,251.06,8.64;3,48.96,507.66,251.06,8.64;3,48.96,519.61,251.06,8.64;3,48.96,531.57,251.06,8.64;3,48.96,543.52,144.03,8.64"><head></head><label></label><figDesc>, combined with the number of training examples per class given. We observe the same effect as last year: Classes with very little training data are commonly difficult to classify. This is particularly critical because those are often the most important classes. Tweets describing thirdand first party observations are represented by a large number of training data, but obviously are hard to classify due to large possible variations of their content.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="4,48.96,500.44,514.07,8.64;4,48.96,512.39,326.81,8.64;4,131.22,50.54,349.56,442.04"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Class-wise positive F1 scores for the five approaches (colored bars) and numbers of training samples per class (transparent gray bars); actionable (or high importance) classes are marked with an asterisk.</figDesc><graphic coords="4,131.22,50.54,349.56,442.04" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,60.42,681.67,192.01,6.91"><p>https://tfhub.dev/google/bert uncased L-12 H-768 A-12/1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,60.42,691.53,116.37,6.91"><p>https://github.com/PrincetonML/SIF</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,60.42,701.39,121.04,6.91"><p>http://www.lexique.org/?page id=250</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,60.42,711.26,139.84,6.91"><p>https://github.com/Zminghua/SentEncoding</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,323.44,711.26,190.93,6.91"><p>https://tfhub.dev/google/universal-sentence-encoder-large/3</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,330.24,693.32,232.80,6.91;3,330.24,702.15,232.80,7.05;3,330.24,711.11,169.52,7.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,442.62,693.32,120.42,6.91;3,330.24,702.29,81.92,6.91">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,434.78,702.15,128.25,6.87;3,330.24,711.11,74.92,6.87">International Conference on Learning Representations (ICLR)</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04">Apr. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.22,547.76,232.80,6.91;4,67.22,556.73,232.80,6.91;4,67.22,565.55,232.80,7.05;4,67.22,574.52,232.80,7.05;4,67.22,583.63,35.33,6.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,153.94,547.76,146.08,6.91;4,67.22,556.73,232.80,6.91;4,67.22,565.70,40.96,6.91">Crisis Event Extraction Service (CREES) -Automatic Detection and Classification of Crisis-related Content on Social Media</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Burel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,124.02,565.55,176.00,6.87;4,67.22,574.52,156.88,6.87">15th International Conference on Information Systems for Crisis Response and Management (ISCRAM)</title>
		<meeting><address><addrLine>Rochester, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.22,593.01,232.80,6.91;4,67.22,601.98,232.80,6.91;4,67.22,610.95,207.35,6.91" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L U</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guajardo-Cspedes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Universal sentence encoder</note>
</biblStruct>

<biblStruct coords="4,67.22,620.33,232.80,6.91;4,67.22,629.16,232.80,7.05;4,67.22,638.27,73.41,6.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,237.23,620.33,62.80,6.91;4,67.22,629.30,203.38,6.91">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR, abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.22,647.65,232.80,6.91;4,67.22,656.48,232.80,7.05;4,67.22,665.44,232.80,6.87;4,67.22,674.55,100.00,6.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,199.99,647.65,100.03,6.91;4,67.22,656.62,188.27,6.91">Twitter as a lifeline: Humanannotated twitter corpora for nlp of crisis-related messages</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,270.98,656.48,29.05,6.87;4,67.22,665.44,228.97,6.87">Tenth International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting><address><addrLine>Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.22,683.94,232.80,6.91;4,67.22,692.76,232.80,6.87;4,67.22,701.73,114.65,7.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,98.15,683.94,187.46,6.91">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,67.22,692.76,232.80,6.87;4,67.22,701.73,29.25,6.87">2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting><address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,67.22,711.26,232.80,6.91;4,330.24,547.76,232.80,6.91;4,330.24,556.59,232.80,7.05;4,330.24,565.70,122.32,6.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,229.06,711.26,70.96,6.91;4,330.24,547.76,232.80,6.91;4,330.24,556.73,99.87,6.91">Comparison of word embeddings and sentence encodings as generalized representations for crisis tweet classification tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Caragea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,447.39,556.59,112.15,6.87">ISCRAM Asian Pacific Conference</title>
		<meeting><address><addrLine>Wellington, New Zealand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10">Oct. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.24,574.66,232.80,6.91;4,330.24,583.63,232.80,6.91;4,330.24,592.45,232.80,7.05;4,330.24,601.56,70.57,6.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,497.03,574.66,66.01,6.91;4,330.24,583.63,218.93,6.91">Crisislex: A lexicon for collecting and filtering microblogged communications in crises</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vieweg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,330.24,592.45,188.68,6.87">AAAI Conference on Weblogs and Social Media (ICWSM)</title>
		<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">June 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.24,610.53,232.80,6.91;4,330.24,619.49,232.80,6.91;4,330.24,628.32,232.80,6.87;4,330.24,637.28,191.96,7.05" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,475.55,610.53,87.49,6.91;4,330.24,619.49,216.45,6.91">What to expect when the unexpected happens: Social media communications across crises</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vieweg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,330.24,628.32,232.80,6.87;4,330.24,637.28,66.78,6.87">Conference on Computer Supported Cooperative Work and Social Computing (ACM CSCW)</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.24,646.39,232.80,6.91;4,330.24,655.22,232.80,7.05;4,330.24,664.18,232.80,7.05;4,330.24,673.29,66.46,6.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,469.67,646.39,93.36,6.91;4,330.24,655.36,170.60,6.91">Learning universal sentence representations with mean-max attention autoencoder</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,516.24,655.22,46.79,6.87;4,330.24,664.18,197.71,6.87">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting><address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10">Oct. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.24,682.26,232.80,6.91;4,330.24,691.23,232.80,6.91;4,330.24,700.05,232.80,7.05;4,330.24,709.16,73.41,6.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="4,403.66,691.23,159.38,6.91;4,330.24,700.19,200.54,6.91">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<idno>CoRR, abs/1506.06724</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
