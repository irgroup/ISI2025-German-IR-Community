<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,74.25,75.55,463.08,14.84;1,288.00,97.30,35.55,14.84">SIB Text Mining at TREC 2019 Deep Learning Track: Working Note</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,90.00,130.16,72.72,11.13"><forename type="first">Julien</forename><surname>Knafou</surname></persName>
							<email>julien.knafou@hesge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences</orgName>
								<orgName type="institution">HES-SO / HEG Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">SIB Text Mining</orgName>
								<orgName type="institution" key="instit2">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,178.99,130.16,68.68,11.13"><forename type="first">Matt</forename><surname>Jeffryes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences</orgName>
								<orgName type="institution">HES-SO / HEG Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">SIB Text Mining</orgName>
								<orgName type="institution" key="instit2">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.94,130.16,55.36,11.13"><forename type="first">Luc</forename><surname>Mottin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences</orgName>
								<orgName type="institution">HES-SO / HEG Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">SIB Text Mining</orgName>
								<orgName type="institution" key="instit2">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.56,130.16,92.06,11.13"><forename type="first">Douglas</forename><surname>Teodoro</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">HES-SO / HEG Geneva</orgName>
								<orgName type="institution" key="instit2">Business Information Systems</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">SIB Text Mining</orgName>
								<orgName type="institution" key="instit2">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,443.89,130.16,68.02,11.13"><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences</orgName>
								<orgName type="institution">HES-SO / HEG Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">SIB Text Mining</orgName>
								<orgName type="institution" key="instit2">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,74.25,75.55,463.08,14.84;1,288.00,97.30,35.55,14.84">SIB Text Mining at TREC 2019 Deep Learning Track: Working Note</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">39F47E1788A4FA039CDC81C2468CAAAC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC 2019 Deep Learning task aims at studying information retrieval in a large training data regime. It includes two tasks: the document ranking task (1) and the passage ranking task (2). Both of these tasks had a full ranking (a) and reranking (b) subtasks. The SIB Text Mining group participated at the full document ranking subtask (1a). In order to retrieve pertinent documents in the 3.2 million documents corpus, our strategy was two-fold. At first, we used a BM25 model to retrieve a subset of documents relevant to a query. We also tried to improve recall by using query expansion. The second step consisted in reranking the retrieved subset using an original model, so-called query2doc. This model, which has been designed to predict if a query-document pair was a good candidate to be ranked in position #1, was trained using the training dataset provided for the task. Our baseline, which is basically a BM25 ranking performed the best and achieve a MAP of 0.2892. Results of the query2doc run clearly indicates that the query2doc model could not learn any meaningful relationship. More precisely, to explain such a failure, we hypothesize that using documents returned by our baseline model as negative items confused our model. As future steps, it will be interesting to take into account features such as the document's BM25 score as well as the number of times a document's URL is mentioned in the corpus and use them along with learning to rank algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The SIB Text Mining group <ref type="bibr" coords="1,213.27,575.63,11.46,10.20">[1]</ref>, at the Swiss Institute of Bioinformatics in Geneva, has a long history of participation in TREC campaigns, including TREC Genomics <ref type="bibr" coords="1,444.72,590.63,11.46,10.20" target="#b0">[2]</ref>, TREC Medical Records <ref type="bibr" coords="1,117.48,605.63,11.46,10.20" target="#b1">[3]</ref>, TREC Chemical IR <ref type="bibr" coords="1,237.67,605.63,12.22,10.20" target="#b2">[4]</ref> and TREC Clinical Decision Support <ref type="bibr" coords="1,437.77,605.63,12.83,10.20" target="#b3">[5,</ref><ref type="bibr" coords="1,450.60,605.63,8.56,10.20" target="#b4">6]</ref> tracks. The first iteration of the Deep Learning track was an opportunity for us to evaluate some machine learning tools on a real-world scenario.</p><p>Since the turn of the millennium, Information Retrieval (IR) systems had to face an influx of available information. The question arises of how to efficiently and accurately find the right answer through billions of documents when the users' queries may contain only a few words. In very specific domains, the context may be used to support the search engine (e.g. by implementing related features in the IR component or by adding constraints to the initial query). However, with no context definition, machine learning strategies appears as a good alternative to the traditional approaches. This year, the TREC 2019 Deep Learning track proposed an extensive amount of query-document mappings for the training of search engines. Such a dataset was a challenge for the development of various models from scratch, and this year we focused on the document ranking task with a preeminent strategy based on recurrent neural networks (RNN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Data</head><p>The full ranking (retrieval) subtask of the deep learning track's document ranking task provides the MS-MARCO dataset which gathers about 3.2 million documents <ref type="bibr" coords="2,438.05,251.63,11.46,10.20" target="#b5">[7]</ref>. Each document contains a URL, a title and a body. Along with these documents, three sets of queries were provided. A training and development set which map 367,013 and 5,193 queries respectively to a MS-MARCO document and a testing set of 200 queries (without mapping), which was provided later in the campaign.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Strategies</head><p>To deal with the large number of documents, our strategy was two-fold. We first used traditional methods to create subsets of relevant documents (1) which allowed us to use computationally intensive methods to refine the retrieved documents selection <ref type="bibr" coords="2,376.78,403.13,12.37,10.20" target="#b0">(2)</ref>. In other words, in (1) our idea is to return a thousand documents while maximizing the recall score, while in (2), we use a document reranking model to improve the precision of our predictions on the subset returned in (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 Strategies graphical representation</head><p>Methods used to create the first subset (1) are detailed in the next section under Document Retrieval, while the methods used to refine subsets (2) will be described later in the Document Reranking section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">BM25 retrieval</head><p>For the initial retrieval, the documents were inserted into an Elasticsearch cluster <ref type="bibr" coords="3,500.20,197.63,11.46,10.20">[8]</ref>. The document ID, URL, title and body text of the documents were indexed. Retrieval from Elasticsearch can be adjusted with various options and parameters. We tested the performance BM25 retrieval module across a range of parameters (see figure <ref type="figure" coords="3,386.65,242.63,4.28,10.20" target="#fig_0">2</ref>). The k 1 variable affects how much a single query term can contribute to the score <ref type="bibr" coords="3,483.37,508.88,11.46,10.20" target="#b6">[9]</ref>. That is, how many occurrences in the document maximises the possible score for a term. The b variable affects how much the document length is penalised, with 0 not penalising long documents at all, and 1 being the maximum. In addition, we tested whether it was beneficial in this task to score documents using only the title text or to use all fields. Using this performance tuning, we identified the optimal parameters for the BM25 module to be b=0.95 and k 1 =1.2 . With these parameters, recall at 1000 was 0.913.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Query Expansion</head><p>As the preselection was an important starting point for the second part of our strategy, we tried to boost the BM25 performances by using query expansion <ref type="bibr" coords="3,362.93,673.88,17.11,10.20" target="#b7">[10]</ref>. Unfortunately, query expansion did not improve the recall score in our development (at least for the size of the subset we were returning) and was not used for the first step for our two runs. We tried two ways of expanding queries. The first method replaces words in a query with other words, which are related in a language model, the second method translates queries in a foreign language and translate it back to the original language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.1">Word2Vec similarity replacement</head><p>We used different pre-trained Word2Vec models <ref type="bibr" coords="4,313.23,164.63,18.34,10.20" target="#b8">[11]</ref> found in <ref type="bibr" coords="4,376.77,164.63,18.34,10.20">[12]</ref> and replace words in a query that where exceeding a certain threshold of similarity using the cosine distances as a metric. This method allows us to retrieve documents <ref type="bibr" coords="4,313.50,194.63,18.34,10.20" target="#b9">[13]</ref> which does not necessarily contain the query's words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.1">Back-Translation</head><p>Back-translation is a way to paraphrase entire sentences without having to look for monolingual parallel corpora <ref type="bibr" coords="4,152.30,284.63,17.11,10.20" target="#b10">[14]</ref>. Unlike the previous method using Word2Vec similarities, where words are replaced one by one, this method generates a paraphrase from a translation of the original sentence. We used the pretrained model described in <ref type="bibr" coords="4,356.30,314.63,18.34,10.20">[15]</ref> to generate translations in both German and Russian and translate them back to English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Query to documents distances</head><p>We used doc2vec <ref type="bibr" coords="4,164.66,389.63,18.34,10.20" target="#b11">[16]</ref> and computed the vector representation for both the queries and each of the 3.2 million documents. We then computed, for each query, the cosine distances between the query vector and the document vector. The 1,000 closest documents were used as candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document reranking</head><p>This part details the two methods we used in order to narrow the 1,000 document selection down to 100 documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Classification (query2doc RNN)</head><p>We developed a model which takes a query followed by a document's content (see figure <ref type="figure" coords="4,514.91,569.63,4.89,10.20">3</ref>) as an input and trained it over the 367,013 queries in the training set. We thought it would be more appropriate to encode the queries and documents in two different recurrent neural networks (RNN) because of the amount of words which is quite different in average between documents and queries. Both of these RNNs output a vector that is concatenated in order to feed a neural network (NN). Thanks to gradient optimization methods, this architecture allows us to train the model at once instead of creating three different models (i.e. one for encoding queries, one for encoding documents and one for predicting if the query-document pair encoding is a good candidate) and training them separately. We used Nestrov Momentum in our optimization process, more precisely an approximation of <ref type="bibr" coords="4,290.72,704.63,18.34,10.20" target="#b12">[17]</ref> which is implemented in TensorFlow <ref type="bibr" coords="4,492.33,704.63,17.11,10.20">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3 Model graphical representation</head><p>Documents that were retrieved according to our initial retrieval methods were used as negative observations when they were not labelled as positive in the dataset. For the inference, we took documents that were returned in the initial retrieval part and take the score that our model would allocate to each query-document pair. For each query, the 100 documents with the highest scores were then returned. We called this model the query2doc RNN which corresponds to our first submitted run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Word Mover Distance (WMD)</head><p>Even if we submit only the previous method in our runs (apart from the baseline), we also used WMD <ref type="bibr" coords="5,103.27,455.63,18.34,10.20" target="#b13">[19]</ref> to refine the selection. We were unable to complete our testing of this method by the deadline and will aim to test the results of this method once the qrel of the testing set is released.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results &amp; Discussion</head><p>In table 1, we can see results for our two runs. The baseline model used the BM25 retrieval method returning 1,000 documents (2.1.1) whereas the query2doc run was a baseline subset of 100 documents using query2doc method (2.2.1). It is obvious that the query2doc method worked poorly. Our hypothesis for this poor performance lies in the fact that we were using documents returned by our baseline model that were not labeled in the dataset as negative observations which confused the discriminative power of our model. Indeed, some of the documents labelled as negative could have been as pertinent as a positive one content-wise. In other words, the relationship between the negative observation and the query-document pair was ambiguous and thus, our model could not make sense of it. This is why it would be interesting to see if the WMD (2.2.2) method, which is unsupervised, would have worked better. We also think that the aggregation of other features would have significantly improved the reranking (e.g. the document's BM25 score, the number of times a document's URL is mentioned in the corpus, etc.) and in future editions, we will test the efficiency of learning to rank algorithms in such a task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Finally, we did not try to change the size of our subsets, which could have had an impact on our metrics. In our next experiments, we will use our best performing methods of document retrieval on larger sets (e.g. 2,000; 5,000; 10,000) and use learning to rank methods to refine the selection. As query expansion has not been used in our runs, it would also be interesting to see how it performs for retrieving a larger set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Our experiment allowed us to step into the first iteration of the TREC Deep Learning track.</p><p>Although the results of our main run are quite poor, it has given us insights about how to approach these problems in the future. Some aspects of our approach were more successful than the final results would imply. Our initial retrieval using Elasticsearch was very simple but effective, and drastically reduced the number of candidates which needed to be processed using the RNN. As noted in the previous section, we think that reranking should have been tackled differently and we will certainly rethink our strategy for the next iteration of this track.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,85.50,451.88,440.50,10.20;3,74.25,466.88,462.57,10.20;3,144.75,481.88,50.71,10.20;3,195.46,488.03,3.67,6.12;3,202.18,481.88,264.57,10.20;3,73.50,256.50,475.07,182.25"><head>Figure 2</head><label>2</label><figDesc>Figure 2 BM25 fine tuning using MAP as metric. In the left panel are the results for scoring based on the title only and in the right panel are the results using all fields. Along the x axis, the value for k 1 is varied, and along the y axis the value for b is varied.</figDesc><graphic coords="3,73.50,256.50,475.07,182.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,73.50,492.00,468.00,145.50"><head></head><label></label><figDesc></figDesc><graphic coords="2,73.50,492.00,468.00,145.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,73.50,103.50,468.00,147.00"><head></head><label></label><figDesc></figDesc><graphic coords="5,73.50,103.50,468.00,147.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,77.25,202.13,384.62,100.20"><head>Table 1</head><label>1</label><figDesc>Principal metrics for our two runs</figDesc><table coords="6,77.25,202.13,384.62,59.70"><row><cell>name</cell><cell>MAP</cell><cell>recall_1000</cell><cell>NDCG</cell></row><row><cell>Baseline</cell><cell>0.2892</cell><cell>0.6383</cell><cell>0.5563</cell></row><row><cell>query2doc</cell><cell>0.0111</cell><cell>0.0697</cell><cell>0.0643</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,87.28,181.13,452.09,10.20;7,72.00,196.13,244.99,10.20" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,340.81,181.13,198.56,10.20;7,72.00,196.13,160.34,10.20">Vocabulary-Driven Passage Retrieval for Question-Answering in Genomics</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tbahriti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ehrler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,253.45,196.13,26.38,10.20">TREC</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.28,211.13,449.07,10.20;7,72.00,226.13,340.28,10.20" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,504.58,211.13,31.76,10.20;7,72.00,226.13,255.97,10.20">BiTeM Group Report for TREC Medical Records Track 2011</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaudinat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vishnyakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<idno>TREC. 2011</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.28,241.13,446.01,10.20;7,72.00,256.13,311.57,10.20" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,501.53,241.13,31.76,10.20;7,72.00,256.13,227.25,10.20">BiTeM group report for TREC Chemical IR Track 2011</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaudinat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vishnyakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<idno>TREC. 2011</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.28,271.13,452.12,10.20;7,72.00,286.13,467.39,10.20;7,72.00,301.13,150.90,10.20" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,357.95,271.13,181.45,10.20;7,72.00,286.13,467.39,10.20;7,72.00,301.13,67.00,10.20">Full-texts representation with Medical Subject Headings and co-citations network reranking strategies for TREC 2014 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaudinat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,159.36,301.13,26.38,10.20">TREC</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.28,316.13,416.72,10.20;7,72.00,331.13,449.63,10.20;7,72.00,346.13,27.51,10.20" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,283.40,316.13,220.59,10.20;7,72.00,331.13,396.29,10.20">Exploiting incoming and outgoing citations for improving Information Retrieval in the TREC 2015 Clinical Decision Support Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaudinat</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ruch</surname></persName>
		</author>
		<idno>TREC. 2015</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.28,361.13,439.24,10.20;7,72.00,376.13,260.31,10.20" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,313.31,361.13,213.21,10.20;7,72.00,376.13,162.91,10.20">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,87.28,406.13,450.87,10.20;7,72.00,421.13,347.57,10.20" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,497.21,406.13,40.94,10.20;7,72.00,421.13,36.64,10.20">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,130.03,421.13,236.43,10.20">Overview of the Third Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note>TREC-3</note>
</biblStruct>

<biblStruct coords="7,93.39,436.13,422.22,10.20;7,72.00,451.13,460.11,10.20;7,72.00,466.13,349.53,10.20" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,219.26,436.13,196.75,10.20">Studying Query Expansion Effectiveness</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Iadh</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-00958-7_57</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,423.95,436.13,91.66,10.20;7,72.00,451.13,392.53,10.20;7,483.83,451.13,48.27,10.20;7,72.00,466.13,111.44,10.20">Proceedings of the 31th European Conference on IR Research on Advances in Information Retrieval</title>
		<meeting>the 31th European Conference on IR Research on Advances in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="611" to="619" />
		</imprint>
	</monogr>
	<note>Advances in Information Retrieval</note>
</biblStruct>

<biblStruct coords="7,93.39,481.13,413.61,10.20;7,72.00,496.13,271.90,10.20" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,208.24,481.13,298.77,10.20">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="https://github.com/RaRe-Technologies/gensim-data" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.39,511.13,439.94,10.20;7,72.00,526.13,139.92,10.20" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,325.58,511.13,207.75,10.20;7,72.00,526.13,58.33,10.20">Query Expansion based on NLP and Word Embeddings</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Aklouche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bounhas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Slimani</surname></persName>
		</author>
		<idno>TREC 2018</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.39,541.13,432.59,10.20;7,72.00,556.13,393.51,10.20" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,296.85,541.13,211.56,10.20">Paraphrasing with bilingual Parallel Corpora</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bannard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,72.00,556.13,388.98,10.20">ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.39,586.13,438.70,10.20" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,249.18,586.13,282.91,10.20">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.39,601.13,430.12,10.20;7,72.00,616.13,463.19,10.20;7,72.00,631.13,197.38,10.20" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,360.98,601.13,162.53,10.20;7,72.00,616.13,156.02,10.20">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,235.76,616.13,299.43,10.20;7,72.00,631.13,40.74,10.20">Proceedings of the 30th International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.39,661.13,428.88,10.20;7,72.00,676.13,405.40,10.20;7,72.00,691.13,293.94,10.20" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,394.58,661.13,127.69,10.20;7,72.00,676.13,95.87,10.20">From word embeddings to document distances</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">I</forename><surname>Kolkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,175.87,676.13,301.53,10.20;7,72.00,691.13,224.06,10.20">ICML&apos;15 Proceedings of the 32nd International Conference on International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
