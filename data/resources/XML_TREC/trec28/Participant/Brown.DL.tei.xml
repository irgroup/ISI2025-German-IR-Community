<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.61,101.17,352.78,15.48">Brown University at TREC Deep Learning 2019</title>
				<funder ref="#_A5jA6Ws">
					<orgName type="full">Intelligence Advanced Research Projects Activity</orgName>
					<orgName type="abbreviated">IARPA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,173.32,161.93,64.91,8.96"><forename type="first">George</forename><surname>Zerveas</surname></persName>
							<email>george_zerveas@brown.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.23,161.93,65.28,8.96"><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.03,161.93,40.06,8.96"><forename type="first">Leila</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.91,161.93,72.78,8.96"><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
							<email>carsten_eickhoff@brown.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.61,101.17,352.78,15.48">Brown University at TREC Deep Learning 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9021227BC314476AEF90ECBF24CABA1B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes Brown University's submission to the TREC 2019 Deep Learning track. We followed a 2-phase method for producing a ranking of passages for a given input query: In the the first phase, the user's query is expanded by appending 3 queries generated by a transformer model which was trained to rephrase an input query into semantically similar queries. The expanded query can exhibit greater similarity in surface form and vocabulary overlap with the passages of interest and can therefore serve as enriched input to any downstream information retrieval method. In the second phase, we use a BERT-based model pre-trained for language modeling but fine-tuned for query -document relevance prediction to compute relevance scores for a set of 1000 candidate passages per query and subsequently obtain a ranking of passages by sorting them based on the predicted relevance scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, deep learning methods have become the standard for solving information retrieval tasks <ref type="bibr" coords="1,131.01,437.82,10.72,8.64" target="#b3">[4]</ref>. These methods can effectively map words and phrases to vector representations. These representations can facilitate better matching between phrases that have similar meanings <ref type="bibr" coords="1,457.24,448.73,10.45,8.64" target="#b5">[6]</ref>. Phrases closer in meaning will be represented closer to each other in a vector space. In information retrieval, many ways to develop relevance scores have been used, such as counting word overlap between query and document. Recently, more complex machine learning models use human-verified datasets to train models to assign similarity scores used for rankings. Applying deep learning to Natural Language Processing problems has given rise to new approaches that can better represent a sentence's meaning using neural networks. For instance, Long Short Term Memory models <ref type="bibr" coords="1,424.02,514.18,11.51,8.64" target="#b1">[2]</ref> with an attention mechanism allow for word relationships to be constructed between different sentences and thus for words to be better placed in context, rather than just by examining the words closest to them. A breakthrough development in Natural Language Processing, the BERT architecture <ref type="bibr" coords="1,434.88,546.91,10.44,8.64" target="#b0">[1]</ref>, extracts word and consequently sentence representations by masking words throughout a sentence and predicting the omitted words, using self-attention to encode the entire sentence at once. Within the BERT framework, the model can also be trained to predict the next sentence out of a few choices, given an input sentence.</p><p>Even with these advances, deep learning methods still struggle with some inherent difficulties in IR tasks. These challenges result from discrepancies in query and document vocabulary <ref type="bibr" coords="1,442.09,617.84,10.46,8.64" target="#b2">[3]</ref>, limited size of data used for training, and weaknesses in a given human-generated query. In an effort to mitigate these effects, our team's approach was inspired by an existing method, doc2query <ref type="bibr" coords="1,447.21,639.66,10.72,8.64" target="#b8">[9]</ref>, which for a given input document uses a transformer model architecture to predict plausible queries leading to that document. Although it was shown that the expanded documents indeed allowed improved retrieval performance by a downstream ranking model, this approach requires that all documents in the collection of interest are first "pre-indexed" by feeding them as input to the transformer model, which is not practical. Instead, we propose a query2query method that takes a given query as input and generates several queries similar in meaning. The hope is to create a more powerful query by augmenting the generated queries and the given query into a single representation, which is used to match a desired passage. To complete our architecture, we then feed the expanded queries to a pre-trained BERT model which can predict similarity scores between queries and documents and produce a final ranking. The goal of our approach is to reduce surface form "noise" within a certain query by generating other queries that ask for the same information, but in different ways. By having different representations of the "same" query, we hope to create more holistic queries and as a result obtain an end-to-end method which can generalize better and potentially reduce the problems which modern IR faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural query expansion</head><p>The data used to train and evaluate our model originated from the publicly available MS MARCO dataset <ref type="bibr" coords="2,139.81,236.48,10.72,8.64" target="#b6">[7]</ref>. In the frames of the TREC Deep Learning Track competition, the training dataset included 532,761 query -passage pairs labeled as positive for relevance (qrels file). Although the vast majority of passages (97.4%) are matched only with a single query, for the remaining 2.6% more than one relevant queries exist (see Table <ref type="table" coords="2,277.05,269.20,3.67,8.64" target="#tab_0">1</ref>). These are enough to generate 21,582 unique pairs of related queries.</p><p>We subsequently regarded the first query of each such pair as a source sentence and the second query as a target sentence for a neural machine translation task. Essentially, this task can be seen as equivalent to paraphrasing an input query into an equivalent query. For this purpose, we trained a transformer model <ref type="bibr" coords="2,192.62,329.23,16.72,8.64" target="#b10">[11]</ref> using the OpenNMT <ref type="bibr" coords="2,298.15,329.23,11.74,8.64" target="#b4">[5]</ref> implementation, following a similar pipeline as in <ref type="bibr" coords="2,118.24,340.14,10.58,8.64" target="#b8">[9]</ref>.</p><p>To expand the original (source) query, we can then append to the end of the original query the top 3 beams (in terms of estimated log-likelihood) used for the beam search when generating the query2query model's output. The result is an augmented query which consists of 4 approximately equivalent wordings of the same query. Table <ref type="table" coords="2,293.77,389.25,5.05,8.64" target="#tab_1">2</ref> shows several examples were the model rephrased the input query into equivalent formulations.</p><p>We found that the quality of the "equivalent query pairs" used for training the query2query model is of decisive importance for generating semantically similar queries. Despite its vastly superior size, using a dataset of pairs of queries which yielded the same passages from the top1000 data file of the competition (where each query is matched with an unranked set of 1000 potentially relevant candidate passages, and therefore each passage is matched with several queries) often resulted in irrelevant queries being generated by the query2query model, which could easily confound subsequent information retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Re-ranking with BERT</head><p>After expanded queries have been obtained, one can in principle use them as input to any IR method of choice. Due to its proven effectiveness both in other Natural Language Processing tasks as well as document retrieval in particular <ref type="bibr" coords="2,253.32,549.83,10.72,8.64" target="#b7">[8]</ref>, we opted for using a BERT model, which has been first pre-trained as part of an unsupervised language modeling objective through input masking (i.e. the original BERT Large model, with a hidden state size of 1024).</p><p>Because of the significant computational cost of using a BERT model even for inference, one can use as a first step a fast, scalable IR method such as BM25 <ref type="bibr" coords="2,322.95,598.94,16.47,8.64" target="#b9">[10]</ref> for pre-fetching a limited set of candidate relevant documents from a large collection (e.g. the world wide web). Since we only submitted results for the passage re-ranking task of the competition, this input (an unranked set of the top 1000 potentially relevant passages per query) was already available to us in the top1000 data file.</p><p>As described in the original BERT paper <ref type="bibr" coords="2,274.67,648.06,10.70,8.64" target="#b0">[1]</ref>, a pre-trained BERT model can be easily re-purposed to predict an objective of choice by replacing the final (output) layer of the language model with a dense neural layer and a loss function corresponding to the desired objective. The input for this dense layer is the embedding corresponding to the first token (i.e. [CLS]) in the input sequence. In our case, the objective is calculating a relevance score between a given input query (which, as described, has been previously expanded), and a candidate passage or document from the set of top 1000 candidate documents/passages. To obtain such a score, we can simply cast document relevance estimation as a binary classification objective, in which case the score is the estimated (output) probability of relevance. For training the model, the positive (i.e. related) query-passage pairs are contained inside the aforementioned qrels file of ground truth relevance pairs, while negative pairs can be generated by treating any other query-passage pair as unrelated.</p><p>Following <ref type="bibr" coords="3,150.29,520.35,10.45,8.64" target="#b7">[8]</ref>, we feed the query as sentence A and the passage text as sentence B (using the original notation of <ref type="bibr" coords="3,154.93,531.26,11.35,8.64" target="#b0">[1]</ref>) after truncating the query to have at most 64 tokens and truncating or padding the passage text such that the concatenation of query, passage and separator tokens have the maximum length of 512 tokens. We fine-tune the model to our re-ranking task using the standard binary cross-entropy loss.</p><p>After training the model, one can run it on unseen queries and compute a relevance score for each candidate document/passage, and afterwards simply sort them in order to obtain a final ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Table <ref type="table" coords="3,132.44,648.06,5.07,8.64" target="#tab_1">2</ref> displays several examples of equivalent queries generated by the query2query transformer decoder. We have observed that the model is able to reliably rephrase the input for queries pertaining to popular subjects, however queries related to more specialized topics or containing exotic terms often yielded semantically unrelated expansions, which could potentially confound subsequent retrieval steps. Moreover, generated expansions sometimes were both grammatically correct as well as aligned with the query thematic, but introduced topical drift, which could at times prove beneficial but potentially also detrimental for downstream retrieval. We believe that a method allowing for better reordering or filtering of the beam output, alongside careful parameter tuning and input pair sampling can improve query expansions in future iterations of the model.</p><p>Next, we present the end-to-end performance of our method.</p><p>We submitted a single official run for evaluation. Table <ref type="table" coords="4,326.36,119.16,4.91,8.64" target="#tab_2">3</ref> shows the detailed performance breakdown in terms of Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (nDCG) and Precision at 10 retrieved documents (P@10). The per-topic maximum, median and minimum scores are computed across all 37 submissions and provided by the committee. The categories in the leftmost column indicate the ranges that our topic predictions fall into. For example, in terms of MAP, 2 of our ranking predictions achieve the best score and 29 of them range between the maximum and median scores. From the results, we observe that 72.1%, 69.8% and 93.0% of our the ranking predictions fall into the median to best region in terms of the three metrics, respectively. It is worth noting that our model achieved top performance for 17 out of 43 test queries in total for the P@10 metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This report describes Brown University's entry to the TREC 2019 Deep Learning Track, in which we produced the final ranking of a set of 1000 candidate passages for given queries. Our method aims at enriching the meaning and surface form of a query by expanding it with similar queries, in the hopes that during the subsequent ranking process, the expanded query would provide extra semantic information or vocabulary overlap that would facilitate the retrieval of more relevant documents.</p><p>We found this retrieval method to be promising in terms of retrieval results, albeit with significant margins for future improvement. A natural focus point of future work is improving the semantic similarity between generated queries and the original query. In this work, we simply use the top 3 output beams in terms of estimated log-likelihood. However, different metrics could be used to re-order and prioritize a larger number of generated outputs. In addition, further investigation can be carried out in terms of various ways of synthesizing the query information or condensing the documents' representation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,107.69,72.27,396.31,147.20"><head>Table 1 :</head><label>1</label><figDesc>Number of passages versus the number of queries with which they were matched in the training set ground truth relevance pairings.</figDesc><table coords="3,224.58,101.34,162.84,118.13"><row><cell cols="2">Num. passages Num. matched queries</cell></row><row><cell>503187</cell><cell>1</cell></row><row><cell>11328</cell><cell>2</cell></row><row><cell>1396</cell><cell>3</cell></row><row><cell>343</cell><cell>4</cell></row><row><cell>115</cell><cell>5</cell></row><row><cell>42</cell><cell>6</cell></row><row><cell>27</cell><cell>7</cell></row><row><cell>14</cell><cell>8</cell></row><row><cell>7</cell><cell>9</cell></row><row><cell>13</cell><cell>≥ 10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,107.69,241.71,396.31,197.42"><head>Table 2 :</head><label>2</label><figDesc>Top 3 beam search outputs generated by the query2qury transformer decoder model for an example set of original queries.</figDesc><table coords="3,112.86,270.18,384.25,168.96"><row><cell>Original query</cell><cell>Generated queries</cell></row><row><cell>how long can cooked chicken last in fridge</cell><cell>how long keep refrigerated chicken</cell></row><row><cell></cell><cell>how long will cooked chicken keep</cell></row><row><cell></cell><cell>how long keep chicken</cell></row><row><cell cols="2">what processes occur during cellular photosynthesis what is not a waste product of cellular respiration</cell></row><row><cell></cell><cell>what is oxidized during cellular respiration</cell></row><row><cell></cell><cell>what is not a waste product of cellular respiration</cell></row><row><cell>what can be done for leg cramps</cell><cell>where do leg cramps usually occur</cell></row><row><cell></cell><cell>what would cause leg cramps</cell></row><row><cell></cell><cell>what would cause cramps</cell></row><row><cell>how early can i take a pregnancy test</cell><cell>how soon can a pregnancy test pick up pregnancy</cell></row><row><cell></cell><cell>when to take a pregnancy test</cell></row><row><cell></cell><cell>when can a pregnancy test pick up pregnancy</cell></row><row><cell>average salary structural engineer</cell><cell>what is the average salary for a google employee</cell></row><row><cell></cell><cell>what is the average salary for a mechanical engineering</cell></row><row><cell></cell><cell>what is the average starting salary for a mechanical engineering</cell></row><row><cell>average tesla cost</cell><cell>what is the cost of the new tesla</cell></row><row><cell></cell><cell>how much money do you save purchasing a tesla</cell></row><row><cell></cell><cell>how much do you have to pay for a tesla</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,210.56,215.73,190.89,84.16"><head>Table 3 :</head><label>3</label><figDesc>Experiment results of query2query</figDesc><table coords="4,210.56,233.76,190.89,66.14"><row><cell cols="4">Number of Topics mAP N DCG P @10</cell></row><row><cell>At Best</cell><cell>2</cell><cell>1</cell><cell>17</cell></row><row><cell>Best to Median</cell><cell>29</cell><cell>26</cell><cell>10</cell></row><row><cell>At Median</cell><cell>5</cell><cell>3</cell><cell>13</cell></row><row><cell>Median to Worst</cell><cell>6</cell><cell>13</cell><cell>2</cell></row><row><cell>At Worst</cell><cell>1</cell><cell>0</cell><cell>1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,108.00,734.38,203.24,7.77"><p>28th Text Retrieval Conference (TREC) Notebook 2019.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgements</head><p>This research is supported by the <rs type="funder">Intelligence Advanced Research Projects Activity (IARPA)</rs> under grant agreement number <rs type="grantNumber">IARPA-BAA-18-05</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_A5jA6Ws">
					<idno type="grant-number">IARPA-BAA-18-05</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,129.58,629.40,374.42,8.64;4,129.58,640.13,361.63,8.82" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,415.24,629.40,88.76,8.64;4,129.58,640.31,234.28,8.64">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR, abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,129.58,660.37,376.81,8.82;4,128.83,671.46,91.57,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,294.63,660.55,94.50,8.64">Long short-term memory</title>
		<author>
			<persName coords=""><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,396.32,660.37,60.19,8.59">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11">November 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,129.58,691.70,374.42,8.64;4,129.58,702.43,374.42,8.82;4,129.33,713.34,376.41,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,439.61,691.70,64.39,8.64;4,129.58,702.61,178.20,8.64">On the Effect of Low-Frequency Terms on Neural-IR Models</title>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,326.94,702.43,177.07,8.59;4,129.33,713.34,321.21,8.59">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,75.48,376.16,8.64;5,129.58,86.21,374.42,8.82;5,129.33,97.12,304.95,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,129.58,86.39,280.65,8.64">Enriching Word Embeddings for Patent Retrieval with Global Context</title>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,428.97,86.21,75.03,8.59;5,129.33,97.12,236.69,8.59">Proceedings of the 41st European Conference on Information Retrieval (ECIR)</title>
		<meeting>the 41st European Conference on Information Retrieval (ECIR)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,116.17,375.80,8.64;5,129.58,126.90,287.84,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,459.82,116.17,45.56,8.64;5,129.58,127.08,200.48,8.64">OpenNMT: Open-source toolkit for neural machine translation</title>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,348.15,126.90,39.25,8.59">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,145.96,376.08,8.64;5,129.58,156.69,333.58,8.82" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,216.49,145.96,289.16,8.64;5,129.58,156.87,9.27,8.64">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,156.32,156.69,202.83,8.59">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,175.75,374.42,8.64;5,129.58,186.48,375.67,8.82;5,129.58,197.57,90.77,8.64" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="5,169.12,186.66,302.00,8.64">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>CoRR, abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,216.27,375.67,8.82;5,129.58,227.36,22.42,8.64" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,287.94,216.45,116.65,8.64">Passage re-ranking with BERT</title>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno>CoRR, abs/1901.04085</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,246.24,374.76,8.64;5,129.58,256.97,166.03,8.82" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="5,384.22,246.24,120.12,8.64;5,129.58,257.15,38.99,8.64">Document expansion by query prediction</title>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno>CoRR, abs/1904.08375</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,276.03,374.42,8.64;5,129.58,286.76,239.03,8.82" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,297.47,276.03,206.53,8.64;5,129.58,286.93,27.15,8.64">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,164.84,286.76,92.62,8.59">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009-04">April 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.58,305.81,375.66,8.64;5,129.58,316.72,375.66,8.64;5,129.58,327.45,374.42,8.82;5,129.41,338.36,340.73,8.82" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,284.48,316.72,98.63,8.64">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ł Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,427.30,327.45,76.70,8.59;5,129.41,338.36,127.95,8.59">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
