<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,54.17,84.23,503.65,15.44;1,66.37,104.15,478.55,15.44;1,228.01,124.08,155.99,15.44">IDST at TREC 2019 Deep Learning Track: Deep Cascade Ranking with Generation-based Document Expansion and Pre-trained Language Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,124.47,154.25,44.26,10.60"><forename type="first">Ming</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,176.90,154.25,61.41,10.60"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.36,154.25,42.34,10.60"><forename type="first">Chen</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.38,154.25,28.34,10.60"><forename type="first">Bin</forename><surname>Bi</surname></persName>
							<email>b.bi@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.00,154.25,46.95,10.60"><forename type="first">Wei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,389.18,154.25,60.84,10.60"><forename type="first">Jiangnan</forename><surname>Xia</surname></persName>
							<email>jiangnan.xjn@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,457.82,154.25,30.71,10.60"><forename type="first">Luo</forename><surname>Si</surname></persName>
							<email>luo.si@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.33,448.49,12.71,7.07"><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,54.17,84.23,503.65,15.44;1,66.37,104.15,478.55,15.44;1,228.01,124.08,155.99,15.44">IDST at TREC 2019 Deep Learning Track: Deep Cascade Ranking with Generation-based Document Expansion and Pre-trained Language Modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9C238371CF32F8621309401A2D201C06</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cascade ranking</term>
					<term>pre-trained language model</term>
					<term>document expansion</term>
					<term>sequence-to-sequence generation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the passage and document ranking tasks of TREC 2019 Deep Learning Track. We propose a two-stage cascade ranking pipeline by taking the advantages of sequence-to-sequence generation and pre-trained language modeling. Firstly, we use a simple and effective index-based method to retrieve a collection of candidate passages. To overcome the vocabulary mismatch problem, we propose a query generation method for document expansion based on the pointer-generator model, where each passage is expanded with a set of generated queries for higher recall in the retrieval of candidate passages. Then we pre-train a BERT language model with a new sentence prediction objective, and adopt a pointwise ranking strategy for re-ranking the remained candidate passages. Our cascade ranking method achieves the best results among all participants on both the passage ranking and document ranking tasks, according to the official evaluation metric NDCG@10.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The Deep Learning Track is a new track first run in TREC 2019, which aims at studying information retrieval in a large training data regime. It consists of two tasks: passage ranking and document ranking. Both tasks use a large human-generated set of training labels, from the MS-MARCO 1 dataset. The passage ranking task focuses on ranking passages, where it contains 1,010,916 queries on a collection of 8,841,823 passages. The document ranking task is 1 http://www.msmarco.org/ Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference'17, July 2017, Washington, DC, USA © 2020 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn based on source documents, which contains passages in the passage ranking task. The full corpus is 3,213,835 documents and the training set has 367,013 queries. For both tasks, there are two subtasks related to this: full ranking and top-k re-ranking. In the full ranking subtask, the aim is to rank passages/documents directly from the full document collection provided, while in the re-ranking subtask we re-rank given an initial ranking set of top-k passages/documents. For the official evaluation, it will be using depth pooling and construct separate pools for the passage ranking and document ranking tasks. Passages/documents in these pools will then be labelled by NIST assessors using multi-graded judgments, allowing to measure the NDCG metric.</p><p>Our approach is mainly based on the BERT language model <ref type="bibr" coords="1,546.73,331.60,9.35,7.95" target="#b1">[2]</ref>, which is a state-of-the-art model in various natural language understanding tasks. Different from many other ranking methods which directly finetune the original BERT model in downstream task, we modify the next sentence prediction task in BERT to a 3-class sentence classification as in StructBERT <ref type="bibr" coords="1,451.73,386.40,10.46,7.95" target="#b8">[9]</ref> and pre-train a new BERT language model from scratch. Based on the new pre-trained BERT model, we further finetune it with pointwise ranking strategy on the labeled query-passage data for re-ranking. Moreover, for full ranking subtask, we use a simple and effective BM25 method <ref type="bibr" coords="1,547.52,430.23,10.68,7.95" target="#b5">[6]</ref> to retrieve a collection of candidate passages, by leveraging the document expansion technique. Prior to indexing, we propose a query generation method for document expansion based on the pointer-generator model, where each document is expanded with a set of generated queries for improved retrieval. For both the passage and document ranking tasks, we train with the passage-level labeled data. For evaluating on document ranking, we split a document into overlapping passages. The BERT ranker predicts the relevance of each passage independently, and the document score is calculated as the maximum score of all the passages within the document. We tested and submitted runs for both the passage ranking and document ranking tasks, by combining the advantages of pre-trained language model and document expansion technique. The results shows that our method outperforms all the submission runs of other participants on both tasks, in terms of the official evaluation metric NDCG@10, which validates the effectiveness of our cascade ranking framework.</p><p>The remainder of the paper is organized as follows. Section 2 outlines our approach. The experiment results and analysis are given in Section 3. Finally, Section 4 concludes the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">OUR APPROACH</head><p>This section presents our two-stage cascade ranking pipeline. An off-the-shelf BM25 retriever is first used to efficiently retrieve a collection of candidate passages/documents. To overcome the vocabulary mismatch problem, prior to indexing, we generate a set of queries for each passage/document to conduct document expansion. In the second stage, we further leverage the state-of-the-art BERT language model to re-rank the candidate passages/documents. Besides, The BERT model is pre-trained with a new sentence prediction objective for better modeling the sentence structure information. Since the passage ranking and document ranking tasks share the same collection of text data with passage-level training labels, we address both tasks in a passage level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Expansion-based Retriever</head><p>For the retriever stage, we first expand each passage with a set of generated queries using sequence-to-sequence generation method. Then we build index on the collection of expanded passages, and use a simple and effective BM25 method to retrieve the top-k candidate passages.</p><p>As for document expansion, for each passage</p><formula xml:id="formula_0" coords="2,54.02,277.21,239.84,23.21">p = {x 1 , • • • , x N } ∈ P, we aim to predict a set of queries Q дen = {q дen 1 , • • • , q дen L</formula><p>} for which that passage will be relevant, where q дen = {q 1 , • • • , q M } and M is the total number of generated query words. We first extract a total collection of query-relevant passage pairs from the labeled training corpus, and use them to train an encoder-decoder network for query generation from the passage. The proposed model is based on the pointer-generator model <ref type="bibr" coords="2,193.56,355.10,9.35,7.95" target="#b6">[7]</ref>, which is widely used in abstractive text summarization. The tokens of the input passage p = {x 1 , • • • , x N } are fed into the passage encoder, which maps the text into a sequence of encoder hidden states {h 1 , • • • , h N }. At decoding time, the decoder will sequentially generate query words by attending on the passage hidden states. At each decoding step, the attention distributions e t i of encoder states and the context vector c t are given as:</p><formula xml:id="formula_1" coords="2,108.64,447.74,185.40,12.83">e t i = v T tanh(W h h i + W s s t )<label>(1)</label></formula><formula xml:id="formula_2" coords="2,108.55,464.61,185.49,28.67">c t = N i=1 α e t i h i , α e t = so f tmax (e t )<label>(2)</label></formula><p>where v,W h ,W s are trainable parameters, s t is the decoder hidden state at time step t.</p><p>Traditional attention mechanism just calculates the attention distribution of the encoder hidden states but ignores the decoder hidden states. To better distinguish among generated words in the query, we propose a novel Attention Over Attention (AOA) mechanism to consider both the attention distributions of encoder hidden states and the previous decoder hidden states. Specifically, at each decoding time step t, we further calculate a new decoder hidden state st by attending on the previous decoder hidden states as:</p><formula xml:id="formula_3" coords="2,108.78,626.47,185.27,44.83">d t i = u T tanh(W d s i + W c c t ) (3) st = t i=1 α d t i s i , α d t = so f tmax (d t )<label>(4)</label></formula><p>where u,W d ,W c are trainable parameters. Then, the new decoder state st is concatenated with the context vector c t , and further fed through two linear layers to produce the vocabulary distribution P vocab (w ) over all words in the vocabulary:</p><formula xml:id="formula_4" coords="2,375.45,102.18,182.76,10.40">P vocab (w ) = so f tmax ( f ([s t , c t ]))<label>(5)</label></formula><p>where f (•) is two linear layers. Following <ref type="bibr" coords="2,366.50,129.26,9.36,7.95" target="#b6">[7]</ref>, we also use a soft switch to choose between generating a word from the vocabulary or copying a word from the input sequence, and calculate the final probability distribution over the extended vocabulary as:</p><formula xml:id="formula_5" coords="2,352.73,175.36,205.47,22.04">P (w ) = p дen P vocab (w ) + (1 -p дen ) i:w i =w α e t i (6)</formula><p>where p дen is a soft switch used in <ref type="bibr" coords="2,447.37,202.71,9.39,7.95" target="#b6">[7]</ref>.</p><p>During training, we minimize a maximum-likelihood loss, which is most widely used in generation tasks. We define q * t as the target word for the decoding time step t and the overall loss is:</p><formula xml:id="formula_6" coords="2,374.18,249.04,184.02,28.78">L = - 1 T T t =0 loдP (q * t |q * 1 , ..., q * t -1 , p)<label>(7)</label></formula><p>After the query generation model is trained, for each passage in P, we generate the top-L queries <ref type="bibr" coords="2,365.67,304.74,13.36,7.95" target="#b9">[10]</ref>, which are used for passage expansion.</p><formula xml:id="formula_7" coords="2,317.96,289.30,240.25,23.39">Q дen = {q дen 1 , • • • , q дen L } using beam search</formula><p>Next, we append the generated top-L queries Q дen to each original passage, respectively. The expanded passages are then indexed and we adopt the simple and effective term-based BM25 method <ref type="bibr" coords="2,547.77,337.62,10.43,7.95" target="#b5">[6]</ref> for retrieval by considering the term weight. For the BM25 search engine, we use the off-the-shelf Anserini open-source IR toolkit <ref type="bibr" coords="2,542.93,359.54,13.32,7.95" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">BERT-based Re-ranker</head><p>With the top-k candidate passages from retriever stage, we further take the BERT language model to re-rank the candidate passages for final ranking. The pre-trained BERT model is expected to capture certain semantic relevance between query and passage. Inspired from StructBERT <ref type="bibr" coords="2,385.83,438.48,9.52,7.95" target="#b8">[9]</ref>, we first modify the next sentence prediction task of original BERT into a more difficult previous sentence and next sentence prediction task, and pre-train a modified BERT language model from scratch using the new sentence prediction task. Then, we finetune the pre-trained BERT model on labeled query-passage data with a point-wise ranking strategy.</p><p>BERT <ref type="bibr" coords="2,351.39,504.23,10.65,7.95" target="#b1">[2]</ref> is a self-supervised approach for pre-training a deep transformer encoder <ref type="bibr" coords="2,393.20,515.19,9.27,7.95" target="#b7">[8]</ref>, before fine-tuning it for a particular downstream task. Given a single text sentence or a pair of text sentences, BERT packs them in one token sequence and learns a contextualized vector representation for each token. The input representations are fed into a stack of multi-layer bidirectional Transformer blocks, which uses self-attention to compute the text representations by considering the whole input sequence.</p><p>There are two training objectives in the original BERT modelmasked language modeling (MLM) and next sentence prediction (NSP), where one is at token level and the other at sentence level. One of the key points of BERT lies in how to design more appropriate pre-training objectives with the unlabeled text. Recently, some variants <ref type="bibr" coords="2,350.08,646.70,9.43,7.95" target="#b3">[4,</ref><ref type="bibr" coords="2,361.76,646.70,11.58,7.95" target="#b11">12]</ref> of BERT language model found that the NSP task may be harmful to learn a effective language model compared with MLM task. They remove the NSP task when pre-training the language model. Some others found it beneficial to modify the NSP task and design a more difficult NSP task for pre-training the language model <ref type="bibr" coords="2,343.13,701.49,9.42,7.95" target="#b2">[3,</ref><ref type="bibr" coords="2,354.78,701.49,6.28,7.95" target="#b8">9]</ref>. In our search scenario which involves modeling the relevance between the query and passage, we think it is beneficial to keep the NSP task and design a more difficult one to capture certain sentence structure information. Therefore, we follow the line of StructBERT and adopt the more difficult previous sentence and next sentence prediction task. Specifically, given a segment S 1 from the unlabeled corpus as segment 1, 1  3 of the time we choose the actual next text span S 2 as segment 2, 1  3 of the time we switch the positions of S 1 and S 2 as input, and the final 1  3 of the time we randomly sample a segment S r and from the other documents as segment 2. The new task is to distinguish among the three situations with a three-class classification problem. The MLM task is kept the same as in the original BERT. We jointly train the token-level MLM task and new NSP task on the unlabeled data, which is the same data as in the original BERT pre-training.</p><p>After the new BERT language model is pre-trained from scratch, we follow the method in <ref type="bibr" coords="3,141.05,254.79,10.42,7.95" target="#b4">[5]</ref> and treat the re-ranking task as a binary classification problem and use the [CLS] vector in the final layer of new BERT to compute a score s i for each passage. The final list of passages are ranked by the score s i . In both the BERT pretraining and fine-tuning, we use the 12-layer BERT base architecture (L = 12, H = 768, A = 12), the max sequence length is set at 384.</p><p>We start training from the pre-trained BERT base model, and fine-tune it with the pointwise objective as:</p><formula xml:id="formula_8" coords="3,94.85,344.49,199.19,28.67">L = - N i=1 y i • loд(s i ) + (1 -y i ) • loд(1 -s i )<label>(8)</label></formula><p>where</p><formula xml:id="formula_9" coords="3,77.66,376.56,126.01,13.94">s i = siдmoid (w • h L C LS ), y i ∈ {0, 1}</formula><p>is the ground-truth label of the query-passage pair, w is a trainable parameter and h C LS is the hidden state of [CLS] token in the final layer of BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Re-ranker Ensemble</head><p>Since the test set is rather small which contains no more than 200 examples, we train multiple BERT re-rankers for ensemble learning. For each BERT re-ranker, we output a probability score s i for each query-candidate passage pair. The probability score is accumulated with different BERT re-rankers, and the sum of the probability scores is used to calculate the final rankings. For the ensemble method, we just use a simple ensemble of the same model training with 4∼8 different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Document Ranking</head><p>Applying BERT to long documents causes increasing memory usage and run time due to the complexity in interacting every pair of tokens. Therefore, we adopt a simple passage-level approach for document retrieval. Since the document ranking and passage ranking tasks share the same text corpus, we directly use the model trained on the passage ranking task for document retrieval. When evaluating and predicting, we split the document into overlapping passages with the same maximum length of 384 and doc stride of 192. The BERT re-ranker predicts the relevance of each passage with respect to the query independently, and the document score is calculated as the maximum relevance of all the passages within the document. Besides, the title information is important in document retrieval. Therefore, during the retriever and re-ranker stages, we both add the title to the beginning of every splitted passage to provide context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENT</head><p>This section we presents the results of our runs in both the passage ranking and document ranking tasks. In total, there are 37 passage task runs and 38 document task runs from all the 15 teams. In each task, there are two subtasks: full ranking and re-ranking. The main official metric in both tasks is NDCG@10, since it makes use of the 4-level judgments and focuses on the first results that users will see. The details of task construction, evaluation methods and result analysis can be found in the overview paper of the TREC 2019 Deep Learning Track <ref type="bibr" coords="3,376.34,189.16,9.40,7.95" target="#b0">[1]</ref>. From the statistics, we can see that in most of our runs, our results can obtain the best performance among all the runs, especially for passage ranking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Passage Ranking Task Performance</head><p>Table <ref type="table" coords="3,339.20,251.42,4.09,7.95" target="#tab_0">1</ref> presents the results of our submitted runs and several other top competitive runs in passage ranking task. The last four runs listed are top performing runs of other groups and the two runs without run tags are single model ones which are self-evaluated with official tools without submitting. We can see that:</p><p>• Our submitted runs can obtain superior performance compared with other competitive runs, which shows the effectiveness of our deep cascade ranking framework by leveraging BERT pre-trained language model. • Our results of full ranking style are much higher than the reranking style on all metrics, which demonstrates the effectiveness of our document expansion-based retriever by leveraging sequence-to-sequence modeling. • Model ensembling can help improve the ranking performance, but not that significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Document Ranking Task Performance</head><p>Table <ref type="table" coords="3,341.30,448.02,4.25,7.95" target="#tab_1">2</ref> presents the results of our submitted runs and several other top competitive runs in document ranking task. To test the effectiveness of different components in our method, we submit the first three full ranking runs with different settings, i.e. 1) the method without adding generation-based document expansion, 2) the method with generation-based document expansion, and 3) the method with generation-based document expansion, but only recall half amount of passages in the first document expansion-based retriever stage. For comparison, the last four runs listed are top performing runs of other groups and the two runs without run tags are single model ones which are self-evaluated with official tools without submitting. We can see that:</p><p>• By directly adopting a passage-level approach for document retrieval, our method can still obtain superior performance compared with other competitive runs, which also shows the effectiveness of our method to deal with the ranking of long documents. • Our full ranking method can largely improve the results of metrics AP and Recall@100 than the re-ranking method, but can bring little improvement in terms of metric NDCG@10. It may be due to that NDCG@10 focuses on the top-ranked results, but the revised retriever (passage-level) in full ranking method of document ranking task mainly helps to improve the recall of "wider" document candidates. Besides, the generation-based </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,53.50,85.73,504.70,152.39"><head>Table 1 :</head><label>1</label><figDesc>Overall ranking performance of submitted runs of our group and other top competitive runs in passage ranking task.</figDesc><table coords="4,115.49,109.04,381.02,129.07"><row><cell>Run Tag</cell><cell>Group</cell><cell>Run Description</cell><cell>Subtask</cell><cell>NDCG@10</cell><cell>AP</cell><cell>R@1000</cell></row><row><cell>idst_bert_p1</cell><cell>IDST</cell><cell cols="2">Ensemble 6 models Full Ranking</cell><cell>0.764</cell><cell>0.503</cell><cell>0.835</cell></row><row><cell>idst_bert_p2</cell><cell>IDST</cell><cell cols="2">Ensemble 4 models Full Ranking</cell><cell>0.763</cell><cell>0.504</cell><cell>0.844</cell></row><row><cell>idst_bert_p3</cell><cell>IDST</cell><cell cols="2">Ensemble 8 models Full Ranking</cell><cell>0.759</cell><cell>0.505</cell><cell>0.844</cell></row><row><cell>idst_bert_pr1</cell><cell>IDST</cell><cell cols="2">Ensemble 6 models Re-Ranking</cell><cell>0.738</cell><cell>0.457</cell><cell>0.694</cell></row><row><cell>idst_bert_pr2</cell><cell>IDST</cell><cell cols="2">Ensemble 8 models Re-Ranking</cell><cell>0.738</cell><cell>0.457</cell><cell>0.694</cell></row><row><cell>-</cell><cell>IDST</cell><cell>Single model</cell><cell>Full Ranking</cell><cell>0.750</cell><cell>0.501</cell><cell>0.838</cell></row><row><cell>-</cell><cell>IDST</cell><cell>Single model</cell><cell>Re-Ranking</cell><cell>0.725</cell><cell>0.453</cell><cell>0.690</cell></row><row><cell>p_exp_rm3_bert</cell><cell>h2oloo</cell><cell>-</cell><cell>Full Ranking</cell><cell>0.742</cell><cell>0.505</cell><cell>0.806</cell></row><row><cell>test1</cell><cell>Brown</cell><cell>-</cell><cell>Re-Ranking</cell><cell>0.731</cell><cell>0.457</cell><cell>0.694</cell></row><row><cell>TUA1-1</cell><cell>TUA1</cell><cell>-</cell><cell>Re-Ranking</cell><cell>0.731</cell><cell>0.457</cell><cell>0.694</cell></row><row><cell>TUW19-p3-f</cell><cell>TU-Vienna</cell><cell>-</cell><cell>Full Ranking</cell><cell>0.688</cell><cell>0.420</cell><cell>0.739</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,53.50,253.70,504.70,259.11"><head>Table 2 :</head><label>2</label><figDesc>Overall ranking performance of submitted runs of our group and other top competitive runs in document ranking task. Recalling less passages/documents in retriever stage gives the best result in terms of NDCG@10, but decreases the AP and Recall@100 metrics slightly. In this setting, more possible positive candidates are discarded with less passages/documents remained in retriever stage.</figDesc><table coords="4,59.03,287.97,479.62,180.25"><row><cell>Run Tag</cell><cell>Group</cell><cell>Run Description</cell><cell>Subtask</cell><cell>NDCG@10</cell><cell>AP</cell><cell>R@100</cell></row><row><cell>idst_bert_v1</cell><cell>IDST</cell><cell>No document expansion (8 ensemble)</cell><cell>Full Ranking</cell><cell>0.718</cell><cell>0.383</cell><cell>0.419</cell></row><row><cell>idst_bert_v2</cell><cell>IDST</cell><cell cols="2">With document expansion (8 ensemble) Full Ranking</cell><cell>0.718</cell><cell>0.385</cell><cell>0.430</cell></row><row><cell>idst_bert_v3</cell><cell>IDST</cell><cell>Only recall half amount (8 ensemble)</cell><cell>Full Ranking</cell><cell>0.726</cell><cell>0.368</cell><cell>0.422</cell></row><row><cell>idst_bert_r1</cell><cell>IDST</cell><cell>Ensemble 8 models</cell><cell>Re-Ranking</cell><cell>0.719</cell><cell>0.291</cell><cell>0.387</cell></row><row><cell>idst_bert_r2</cell><cell>IDST</cell><cell>Ensemble 4 models</cell><cell>Re-Ranking</cell><cell>0.714</cell><cell>0.291</cell><cell>0.387</cell></row><row><cell>-</cell><cell>IDST</cell><cell cols="2">Single model (w/ document expansion) Full Ranking</cell><cell>0.706</cell><cell>0.378</cell><cell>0.423</cell></row><row><cell>-</cell><cell>IDST</cell><cell cols="2">Single model (w/ document expansion) Re-Ranking</cell><cell>0.704</cell><cell>0.284</cell><cell>0.382</cell></row><row><cell>bm25exp_marcomb</cell><cell>h2oloo</cell><cell>-</cell><cell>Full Ranking</cell><cell>0.646</cell><cell>0.424</cell><cell>0.467</cell></row><row><cell>TUW19-d3-re</cell><cell>TU-Vienna</cell><cell>-</cell><cell>Re-Ranking</cell><cell>0.644</cell><cell>0.271</cell><cell>0.387</cell></row><row><cell>ucas_runid1</cell><cell>UCAS</cell><cell>-</cell><cell>Re-Ranking</cell><cell>0.644</cell><cell>0.264</cell><cell>0.387</cell></row><row><cell>ms_ensemble</cell><cell>Microsoft</cell><cell>-</cell><cell>Full Ranking</cell><cell>0.578</cell><cell>0.237</cell><cell>0.368</cell></row><row><cell cols="3">document expansion makes not that much difference compared</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">with passage task (idst_bert_v1 v.s. idst_bert_v2).</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="4,70.31,528.70,71.26,9.37;4,53.80,543.40,240.48,7.95;4,53.80,554.36,240.25,7.95;4,53.80,565.31,240.25,7.95;4,53.80,576.27,240.25,7.95;4,53.80,587.23,240.25,7.95;4,53.80,598.19,240.48,7.95;4,53.80,609.15,241.63,7.95;4,53.53,620.11,240.69,7.95;4,53.80,631.07,240.25,7.95;4,53.80,642.03,200.17,7.95"><p>CONCLUSIONIn this paper, we propose an effective cascade ranking framework for ad-hoc passage and document retrieval. Firstly, we propose to leverage a sequence-to-sequence generation method to conduct document expansion, which helps to retain a higher recall of the candidate passages from the whole passage collection. Then, we design a new pre-trained BERT language model for re-ranking, by enriched with more fine-grained sentence structure information. The experiment results show that our method can obtain superior performance compared with other competitive submission runs on both the passage ranking and document ranking tasks.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,69.23,678.88,225.07,6.19;4,69.23,686.18,166.39,6.97" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,267.03,678.88,27.27,6.19;4,69.23,686.85,105.33,6.19">Overview of the TREC 2019 deep learning track</title>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In TREC (to appear</note>
</biblStruct>

<biblStruct coords="4,69.23,694.82,225.63,6.19;4,69.23,702.12,224.81,6.97;4,333.39,438.31,91.11,6.97" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,281.34,694.82,13.53,6.19;4,69.23,702.79,205.00,6.19">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,446.95,224.81,6.19;4,333.39,454.92,224.81,6.19;4,333.39,462.22,216.74,6.97" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,435.44,454.92,122.76,6.19;4,333.39,462.89,103.10,6.19">ALBERT: A lite BERT for self-supervised learning of language representations</title>
		<author>
			<persName coords=""><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,470.86,224.94,6.19;4,333.39,478.83,225.06,6.19;4,333.39,486.13,224.81,6.97;4,333.18,494.77,18.66,6.19" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="4,527.16,478.83,31.29,6.19;4,333.39,486.80,129.68,6.19">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,502.74,225.88,6.19;4,333.39,510.04,108.33,6.97" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="4,467.87,502.74,87.86,6.19">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,518.68,224.81,6.19;4,333.39,525.98,224.81,6.97;4,333.39,534.62,56.72,6.19" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,478.66,518.68,79.54,6.19;4,333.39,526.65,82.93,6.19">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,422.00,525.98,136.20,6.97">Foundations and Trends® in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,542.59,225.63,6.19;4,333.39,549.89,224.81,6.97;4,333.18,558.53,18.66,6.19" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="4,510.27,542.59,48.75,6.19;4,333.39,550.56,134.12,6.19">Get to the point: Summarization with pointer-generator networks</title>
		<author>
			<persName coords=""><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04368</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,566.50,225.58,6.19;4,333.15,574.48,225.06,6.19;4,333.39,581.77,212.44,6.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,513.37,574.48,44.83,6.19;4,333.39,582.45,24.64,6.19">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,370.40,581.77,139.53,6.97">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,590.42,225.88,6.19;4,333.39,598.39,224.81,6.19;4,333.39,605.68,184.29,6.97" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zuyi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liwei</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.04577</idno>
		<title level="m" coord="4,350.08,598.39,208.12,6.19;4,333.39,606.36,69.99,6.19">StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,614.33,224.81,6.19;4,333.39,621.62,186.18,6.97" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="4,461.58,614.33,96.62,6.19;4,333.39,622.30,72.51,6.19">Sequence-to-sequence learning as beam-search optimization</title>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02960</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,333.39,630.27,224.81,6.19;4,333.39,637.56,224.81,6.97;4,333.39,645.53,100.50,6.97" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,456.35,630.27,101.85,6.19;4,333.39,638.24,94.71,6.19">Anserini: Enabling the use of Lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,440.34,637.56,117.87,6.97;4,333.39,645.53,46.31,6.97">Proceedings of the 40th International ACM SIGIR Conference</title>
		<meeting>the 40th International ACM SIGIR Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,654.18,225.58,6.19;4,333.39,662.15,225.99,6.19;4,333.39,669.44,173.64,6.97" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<title level="m" coord="4,397.18,662.15,162.20,6.19;4,333.39,670.12,59.34,6.19">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
