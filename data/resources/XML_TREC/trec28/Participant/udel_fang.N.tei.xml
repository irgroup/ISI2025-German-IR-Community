<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,76.71,118.16,458.58,18.14;1,234.80,143.07,142.41,18.14">Leveraging Entities in Background Document Retrieval for News Articles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,225.22,182.87,61.83,12.58"><forename type="first">Kuang</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.53,182.87,56.77,12.58"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,76.71,118.16,458.58,18.14;1,234.80,143.07,142.41,18.14">Leveraging Entities in Background Document Retrieval for News Articles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B401211D555DD9CC0096C506928A85C7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this year's News Track, we focus on effectively estimating entity weights by using the words surrounding the entities for background linking task. Analyses on the results reveal the inconsistency of our methods as well as the temporal characteristics of the queries. These observations lead to several interesting research questions about the background document retrieval task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The News track is designed with the goal of identifying the search needs of readers and journalists 1 . Two potential needs are identified. The first need is, for a news article, to link a list of other articles that a user should read next in order to get the context and background information of the article. This would help readers better understand the story and evaluate the trustworthiness it. The second need is identified as ranking the entities in a news piece based on whether the external information, such as Wikipedia pages, would help readers better understand the piece.</p><p>Based on these needs, two tasks are introduced for the news track, which are background linking and entity ranking. In this year's News Track, we tackle the first task and focus on leveraging entities in the query article to identify background articles. We first define entities as the things and concepts that have their own Wikipedia page, which is similar to that of Daiber et al. <ref type="bibr" coords="1,142.08,566.97,11.71,10.48" target="#b1">[2]</ref>. We call these entities Wiki entities. Wiki entities are more specific than non-entity words. Moreover, the existence of their Wikipedia pages may suggest that the appearances of Wiki entities are more informative and can be used as strong signals when retrieving background documents. We implemented a method that focuses on correctly estimating the entity weights based on the context (e.g. the words surrounding the entities) of the entities. Although our proposed method does not perform as well as a simple baseline that uses all terms in the query document in this year's data, our method outperforms the baseline significantly in last year's data. Moreover, further analyses reveal some interesting insights such as the effect of a time filter. Based on them, several research questions are proposed. These research questions are not investigated fully in this paper due to time limit, but we believe that they are worth answering and could lead to better understanding of the problem of background article linking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Processing</head><p>The collection is the same as last year's Washington Post news collection. We followed the document cleaning process of the top team of last year <ref type="bibr" coords="2,357.98,185.35,12.36,10.48" target="#b0">[1]</ref> to remove unwanted documents. More specifically, files were processed according to the lexical order of the file names. When a document in a file was being processed, a 3-tuple (document title, author name, published date) was extracted and saved. If the tuple was the same as that of a previously processed document, the current document was considered a duplicate and was discarded. Otherwise, its document type in "kicker" the field was checked. If it was "Opinion", "Letters to the Editor", or "The Post View", it was discarded as well since, according to the guideline, the document is considered to be none-background. If a document was not removed by the previous filtering steps, its id, title, timestamp, and the text of each paragraph as well as title were kept.</p><p>In order to leverage Wiki entities, they have to be identified in the documents. We followed our approach last year <ref type="bibr" coords="2,193.11,351.47,12.34,10.48" target="#b2">[3]</ref> and used DBpedia Spotlight <ref type="bibr" coords="2,361.29,351.47,11.71,10.48" target="#b1">[2]</ref>. DBpedia<ref type="foot" coords="2,428.73,349.86,4.23,6.99" target="#foot_0">2</ref> is a knowledge base that contains structured information about Wiki entities. There is a unique DBpedia entity corresponding to a Wiki entity. DBpedia Spotlight can automatically annotate DBpedia entities from text which accomplishes our entity annotation goal. The entities were subsequently replaced by their canonical forms (e.g. the form appears in DBpedia), which are also provided by the toolkit. For example, "the Red Planet" and "Mars" were all mapped to the canonical form "Mars". We hope that this would help us to more accurately match the entities in the query articles and other articles. The parameter "Confidence" of the tool was set to 0.5. We treat the identified entities, either single-term or multi-term, as single words and used the Indri <ref type="bibr" coords="2,204.14,481.48,12.36,10.48" target="#b3">[4]</ref> toolkit to index the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>As mentioned before, we focused on using entities to identify background documents. More specifically, we tried to estimate the weights of entities more accurately. If a simple baseline that uses all words in the query document, such as one of the top runs of last year <ref type="bibr" coords="2,524.39,576.60,11.71,10.48" target="#b0">[1]</ref>, the weights of the words are decided by their occurrences in the document. However, we hypothesize that the importance of an entity is also related to the context that it is used in. Given an article, it usually reports an event or discusses a topic. Besides that, some minor aspects of the event or topic are also mentioned in the document. If an entity is often used for describing the event or discussing the main topic, the entity might be more important compared to those for describing minor topics. In order to measure such differences, given an entity, we combine the words before and after each occurrence of the entity (e.g. context words), generate a language model based on the words, and compute the KL-divergence between this context language model and the document language model. Low divergence might indicate that the entity is frequently used to discuss the core event or topic. On the contrary, if the divergence is high, the entity tends to be about the minor topics. Based on this, we generate a weight distribution of words and entities P (D) for a query document D from its entity weight distribution P (E) and word weight distribution P (W ):</p><formula xml:id="formula_0" coords="3,225.85,184.13,314.15,10.48">P (D) = λP (W ) + (1 -λ)P (E)<label>(1)</label></formula><p>in which λ is a regulator that balances the weights between the word weight model and the entity weight model. P (E) is generated by computing the entity weights based on their context words whereas P (W ) is generated by using the word occurrences. Both of them are normalized so that the weights within each model sum up to 1. P (D) then can be used to retrieve background documents for D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Run Results and Analysis</head><p>We submitted two runs. First run UDInfolab ent is created following the method described in the previous section. We picked the context window size to be 10. Moreover, we tuned the λ in Equation 1 from 0.1 to 1.0 with a step size of 0.1 on last year's data and chose the one with the best performance, which is 0.7. A time-based filtered was employed so that only the documents with a publication date earlier than that of the query documents can be retrieved. The filter was included since it improves the effectiveness significantly based on our experiments on last year's data. The effect of the filter will be investigated and discussed later. Besides this run, we also implemented a baseline run UDInfolab all in which we simply use all words and entities in the query document for retrieval.</p><p>The effectiveness of the submitted runs as well as the TREC median of this year are reported in Table <ref type="table" coords="3,118.23,487.92,5.85,10.48">1</ref> as NDCG@5. Additionally, performances of the methods on last year's data are included. When comparing the baseline UDInfolab all with the TREC medians, it is clear that even the simple method is reasonably effective for the task and is better than the TREC medians statistically significantly with p value less than 0.05 according to paired t-test in both years. However, although the performance of UDInfolab ent is higher than the baseline in 2018, it is worse in 2019 and the difference is statistically significant with a p value lower than 0.05. This is a very interesting phenomenon. In order to further investigate this, we tune λ on 2019's queries, which shows that 0.7 is also the optimal value on 2019. It suggests two things. First, our method is stable in that the optimal parameter setting is the same on both years. However it seems to be not a robust solution compared to the baseline since it improves on some queries (e.g those in 2018) but fails on others (e.g. those in 2019). More detailed analysis is required to discover what are those queries, and how our method can be altered for those queries. We did not conduct the analysis due to time limit but we plan to investigate the problem further in the future.</p><p>Another line of analyses we did is about the effect of the time filter. We implemented a method called UDInfolab nf (nf stands for no filter) which removes the time filter of Table <ref type="table" coords="4,155.32,82.10,4.55,10.48">1</ref>: NDCG@5 for our methods and TREC medians on Both Years Method 2018 2019 UDInfolab ent 0.467 0.575 UDInfolab all 0.438 0.606 TREC Median 0.345 0.530 UDInfolab all. It is applied to both years' data and we compare its performances against that of UDInfolab all in Figure <ref type="figure" coords="4,239.97,197.70,4.55,10.48" target="#fig_0">1</ref>. As can be see, queries in 2019 seem to be easier than that in 2018 as the performances of both methods are considerably better in 2019. However, the performance discrepancy between the methods is significant in 2018 (with a p value lower than 0.05), but is virtually nonexistent in 2019. The usage of the time filter seems to guarantee a better performance nonetheless. To better understand the impact of the time filter, a box plot of the percentages of the differences of top 5 documents between the methods of the same queries are shown in Figure <ref type="figure" coords="4,338.09,284.38,4.55,10.48" target="#fig_1">2</ref>. Unsurprisingly, we observe that, in 2019, the simple baseline method tends to retrieve the same set of documents regardless of the existence of the time filter (and the set of documents were published before the time of the query document). As can be seen, there are no differences among 25% of the queries and 75% of the queries have less than or equal to 40% (or 2) documents that are different in the top 5 documents. However, the time filter has a significant impact on what documents are retrieved in 2018. As can be seen, half of the queries observe at least 40% differences and 25% of the queries have at least 60% of (or 3) documents changed in the top 5. To attain more insights about this phenomenon, from the judgement files we compute the percentages of background documents that were published before the query documents in the two years, and show a box plot of them in Figure <ref type="figure" coords="4,381.03,428.83,4.55,10.48" target="#fig_2">3</ref>. As can be seen, in general the relevant documents are more likely to be published before the query document. For all queries in the two years, only 5 out of 116 queries<ref type="foot" coords="4,336.61,456.11,4.23,6.99" target="#foot_1">3</ref> have more than half of their relevant documents published after the query documents. We believe this fits the general intuition of background information. Moreover, it explains why methods with the time filter is better or at least the same. Nevertheless, the distribution is slightly more skewed in 2019 than in 2018. In 2019, the bottom whisker is marginally higher than that in 2018. More than 75% of the queries in 2019 have at least 80% of their background documents published before query documents. While in 2018, although it is more top-heavy as the median is around 90%, the third quartile is about 75%, which is lower than that of 2019. Moreover, around 25% of the queries have a difference percentages in the top 5 document between 75% and 50%. According to our conversation with the organizers, this seem to be due to the fact that in 2019, they tried to choose queries that were later in the corpus epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year's News Track, we investigated how to leverage entities in retrieving background articles. Although our methods can not consistently outperform our baseline, the usefulness   of it is exhibited in 2018's data. Moreover, time filter seems to be useful in that it would benefit queries published earlier in the collection whereas would not hurt the queries published latter. We plan to more thoroughly investigate the temporal characteristics of queries in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,203.33,368.26,205.34,10.48;5,77.27,74.21,453.57,283.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Effect of The Time Filter</figDesc><graphic coords="5,77.27,74.21,453.57,283.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,72.00,692.85,51.80,10.48;5,140.59,692.85,360.27,10.48;5,500.86,697.37,9.21,6.99;5,521.14,692.85,18.86,10.48;5,72.00,707.30,59.88,10.48;5,131.88,711.82,9.65,6.99;5,146.02,707.30,37.36,10.48;5,77.27,398.80,453.57,283.48"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Percentages of Different Top-5 Documents between U DInf olab nf and U DInf olab all Results</figDesc><graphic coords="5,77.27,398.80,453.57,283.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,87.85,360.38,436.30,10.48;6,77.27,66.33,453.57,283.48"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Percentages of Background Documents Published before Query Documents</figDesc><graphic coords="6,77.27,66.33,453.57,283.48" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,89.93,701.19,112.17,8.74"><p>https://wiki.dbpedia.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,89.93,699.99,450.07,8.74;4,72.00,711.95,158.08,8.74"><p>We include the 59 queries in 2018 that have at least one background document, and the 57 queries in 2019 that have judgements available</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,90.21,498.47,449.79,10.48;6,90.21,512.92,449.79,10.48;6,90.21,527.37,278.99,10.48" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,252.34,512.92,182.52,10.48">htw saar @ TREC 2018 news track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bimantara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gerwert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gottschalk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lukosz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Piri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Shaft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,464.93,512.92,75.06,10.48;6,90.21,527.37,242.57,10.48">Proceedings of the Twenty-Seventh Text REtrieval Conference</title>
		<meeting>the Twenty-Seventh Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.21,549.03,449.78,10.48;6,90.21,563.48,449.79,10.48;6,90.21,577.93,128.24,10.48" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,352.20,549.03,187.80,10.48;6,90.21,563.48,148.50,10.48">Improving efficiency and accuracy in multilingual entity extraction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daiber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,266.57,563.48,273.43,10.48;6,90.21,577.93,91.83,10.48">Proceedings of the Ninth International Conference on Semantic Systems</title>
		<meeting>the Ninth International Conference on Semantic Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.21,599.60,449.79,10.48;6,90.21,614.04,376.44,10.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,185.48,599.60,350.11,10.48">Paragraph as lead -finding background documents for news articles</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,109.39,614.04,320.84,10.48">Proceedings of the Twenty-Seventh Text REtrieval Conference</title>
		<meeting>the Twenty-Seventh Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.21,635.71,449.79,10.48;6,90.21,650.16,449.79,10.48;6,90.21,664.60,151.32,10.48" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,375.41,635.71,164.60,10.48;6,90.21,650.16,169.60,10.48">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,287.74,650.16,252.26,10.48;6,90.21,664.60,114.90,10.48">Proceedings of the 2005 International Conference on Intelligent Analysis</title>
		<meeting>the 2005 International Conference on Intelligent Analysis</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
