<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,92.67,156.18,423.54,17.91;1,219.22,181.09,170.44,17.91">Exploring Query Reformulation for Conversational Information Seeking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,237.19,221.07,66.41,12.44"><forename type="first">Disen</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.53,221.07,50.76,12.44"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,92.67,156.18,423.54,17.91;1,219.22,181.09,170.44,17.91">Exploring Query Reformulation for Conversational Information Seeking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">95F368E0D1B2E5A09A003117067FDF27</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few tasks have been designed for conversational information seeking. To fill this gap, this year's TREC Conversation Assistance Track (CAsT) is proposed to advance research on conversational search systems. We built a model that first read the dialogue context, then retrieved candidate response information from a large collection of paragraphs. In order to perform passage retrieval task, we first applied the coreference resolution method to format questions into queries, and we use Indri to retrieve top 100 relevant passages. During the second phrase, we applied fine-tuned BERT model to rerank retrieved passage.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC conversational assistance track (CAsT) <ref type="bibr" coords="1,319.11,570.56,3.99,6.91" target="#b0">1</ref> is introduced with the primary initial focus on understanding information needs in a conversational format and finding relevant responses with contextual information. This year the track focus on retrieval of relevant result content in context. Specifically, the task is retrieval-based candidate response ranking in context. Given the current dialogue turns up to the given turn, the model is asked to retrieve candidate text pas- sages from a fixed text collection for the current turn. Figure <ref type="figure" coords="2,371.31,444.73,5.98,10.37" target="#fig_0">1</ref> shows example of sequentiallyrelated turns under certain topic.</p><p>Based on the task, we proposed a method that consists of two key steps: query formatting and passage re-ranking. More specifically, we first applied the coreference resolution to formulate each turn into a query, and then we use Indri search engine to retrieve top 100 relevant passages. After that, we applied fine-tuned BERT (2) model to re-rank retrieved passages and choose top 30 passages as outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>The corpus is a combination of three standard TREC collections: MARCO Ranking passages (1), Wikipedia (TREC CAR) (3), and News (Washington Post). Because the corpus contains a large amount of passages, we chose to use two-phase retrieval: first retrieval top 100 relevant passages with Indri, and then re-rank retrieved passages with fine-tuned BERT model. The key step in the first phase is to format query, and the key step in the second step is to fine-tune the BERT model based on labeled dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query Formatting</head><p>The original questions under each topic are written in natural language. In order to retrieve relevant passages we need to format each question into a query. It is worth noting that the questions are sequentially related, several consecutive questions might be asking about same item, and later questions will tend to use pronouns to refer to the nouns shown in previous question.</p><p>In order to generate queries with high quality, it is essential to replace those pronouns with the nouns they are referring to. We applied the NeuralCoref model<ref type="foot" coords="3,392.11,369.97,3.99,6.91" target="#foot_1">2</ref> to compute the probability between each pronoun in current question and each nouns in previous question, and replace the pronouns with the corresponding nouns with highest probability. After coreference resolution step, we will remove stop words to form a temporary query. Please note that for each question, we can only leverage information from previous questions. Therefore, we can not use any information from later questions.</p><p>Besides, we noticed that for each topic, the organizers also provide the title and description.</p><p>We believe the title and description could help us to narrow down the area of current question.</p><p>However, the description is too specific that it can be misleading if we directly extend each query with description. Dut to the time constraint, we decided to extend each query with topic title to improve the information retrieval performance, especially when original query contains few words. Specifically, when formatting the final query, we assigned the words from original query with weight equals to 0.8 and the words from title with weight equals to 0.2. After formatting queries, we retrieved top 100 relevant passages with Indri (4), and re-rank retrieved passages in next phrase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fine-tuning BERT Model</head><p>BERT model is the state of the art language model for many NLP tasks, including MSMARCO passage re-ranking task <ref type="bibr" coords="4,191.23,226.51,3.99,6.91" target="#b2">3</ref> which is very similar to this task. Besides, it is powerful when adapting to new tasks by fine-tuning parameters. Therefore, we choose to fine-tune the BERT model with labeled data and use fine-tuned BERT model to re-rank retrieved passages in first phrase. The organizers provide labels for 5 topics (approximately 50 question and 500 passages in total).</p><p>The judgements are graded on a three point scale (2 very relevant, 1 relevant and 0 not relevant).</p><p>We first regularize the points into 1 scale: 1 very relevant, 0.5 relevant and 0 not relevant, then we fine-tuned the pre-trained BERT model based on training labels. After getting fine-tuned model, we applied BERT model to re-rank retrieved passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submitted Runs</head><p>We submitted 2 runs for this year's track. The details of each submitted run is introduced as below:</p><p>UDInfoC BL: The baseline run where we applied the NeuralCoref model for coreference resolution and use Indri to retireve relevant passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UDInfoC TS:</head><p>The run where we applied the NeuralCoref model for coreference resolution and use Indri to retireve relevant passages, then we re-ranked the retrieved passages witn finetuned BERT model. Because running BERT requires huge amount of compute resource, we only re-ranked passages from first 30 topics in test set. Therefore, in the final submitted run only first 30 topics were re-ranked, and other topics are the ranking results from Indri. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Table <ref type="table" coords="5,106.46,262.87,5.98,10.37" target="#tab_0">1</ref> shows the performance of the baseline method, transfer learning method and the median results for the mean across all turns assessed. As can be seen from Table <ref type="table" coords="5,439.48,286.78,4.48,10.37" target="#tab_0">1</ref>, baseline method performs better than the median system on both MAP and DNCG evaluation metrics, which illustrates the effectiveness of the query formatting strategy we proposed. However, the transfer learning method performs worse than the baseline method, which may be the result of limited amount of available labeled training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year's conversational assistant track, we first applied coreference resolution method to format questions into queries, then we use Indri to retrieve top 100 relevant passages. During the second phrase, we use fine-tuned BERT model to re-rank retrieved passage. Evaluation results</p><p>show that the baseline method performs better than the median results of the challenge, which illustrates the effectiveness of our query format strategy. On the other hand, with limited labeled training data available, the performance of transfer learning method is worse than the baseline method. We anticipate that with more training data available the transfer learning method would yield to better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,154.11,418.77,300.66,10.37;2,77.67,108.86,453.55,293.28"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of questions under topic "forms of energy".</figDesc><graphic coords="2,77.67,108.86,453.55,293.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,202.50,111.59,203.88,77.95"><head>Table 1 :</head><label>1</label><figDesc>Performance Comparison</figDesc><table coords="5,202.50,111.59,203.88,54.10"><row><cell></cell><cell cols="2">MAP@5 DNCG@5</cell></row><row><cell>Median System</cell><cell>0.042</cell><cell>0.296</cell></row><row><cell>Baseline Method</cell><cell>0.075</cell><cell>0.311</cell></row><row><cell>Transfer Learning</cell><cell>0.061</cell><cell>0.259</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,95.60,690.96,87.34,8.64"><p>http://www.treccast.ai</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,95.60,681.65,172.44,8.64"><p>https://github.com/huggingface/neuralcoref</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,95.60,686.95,99.35,8.64"><p>http://www.msmarco.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,82.15,149.32,448.76,10.37;6,92.79,173.23,438.13,10.37;6,92.79,197.14,438.42,10.37;6,92.49,221.05,88.99,10.37" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,238.30,197.14,292.91,10.37;6,92.49,221.05,54.58,10.37">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.15,254.92,449.06,10.37;6,92.49,278.63,438.73,10.57;6,92.49,302.74,34.86,10.37" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="6,434.74,254.92,96.48,10.37;6,92.49,278.83,262.17,10.37">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,82.15,336.62,449.06,10.37;6,92.49,360.32,172.86,10.57" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,425.72,336.62,105.49,10.37;6,92.49,360.53,83.15,10.37">Trec complex answer retrieval overview</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,198.00,360.32,29.23,10.29">TREC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.15,394.40,449.06,10.37;6,92.49,418.11,438.72,10.57;6,92.49,442.02,302.55,10.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,474.83,394.40,56.38,10.37;6,92.49,418.31,229.42,10.37">A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Indri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,346.54,418.11,184.67,10.29;6,92.49,442.02,178.08,10.57">Proceedings of the International Conference on Intelligent Analysis (2005)</title>
		<meeting>the International Conference on Intelligent Analysis (2005)</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
