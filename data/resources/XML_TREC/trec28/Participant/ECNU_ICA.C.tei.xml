<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.92,151.06,292.15,8.77;1,165.16,165.01,281.68,8.77">LINBER: A RETRIEVAL-BASED CONVERSATIONAL ASSISTANT USING ENTITY LINKING AND BERT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,127.19,208.97,63.39,8.74"><forename type="first">Yucheng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<addrLine>3663 N. Zhongshan Rd</addrLine>
									<postCode>200062</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,198.11,208.97,69.53,8.74"><forename type="first">Yuxiang</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<addrLine>3663 N. Zhongshan Rd</addrLine>
									<postCode>200062</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.77,208.97,55.97,8.74"><forename type="first">Jun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<addrLine>3663 N. Zhongshan Rd</addrLine>
									<postCode>200062</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.56,208.97,39.57,8.74"><forename type="first">Pei</forename><surname>Huo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<addrLine>3663 N. Zhongshan Rd</addrLine>
									<postCode>200062</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.83,208.97,50.64,8.74"><forename type="first">Yan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<addrLine>3663 N. Zhongshan Rd</addrLine>
									<postCode>200062</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.92,151.06,292.15,8.77;1,165.16,165.01,281.68,8.77">LINBER: A RETRIEVAL-BASED CONVERSATIONAL ASSISTANT USING ENTITY LINKING AND BERT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F5353AB41EF6CB1771F98FCEBF302414</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We developed a retrieval-based conversational assistant named linber. linber was featured by entity linking module and Bert re-ranking process. linber perform Conversational Assistance Track (CAsT) by the fellowing five modules:</p><p>(1) Coreference resolution module (2) Keywords extraction module (3) Entity linking module (4) Retrieval module (5) BERT re-ranking module 1.1. Coreference Resolution. Our coreference resolution procesure is done by AllenNLP<ref type="foot" coords="1,170.12,427.91,3.65,5.24" target="#foot_0">1</ref> coreference resolution model. This model is a end-to-end neural model which consists of a word embedding layer, a bi-lstm layer and a feed-forward layer.</p><p>Experiments shows that this model access the state-of-the-art performance on many benchmark.</p><p>1.2. Keywords. Finding keywords of utterances is a crucial part in our retrieval. We produce retrieval query by combining keywords extracted in the whole dialogue history. Rather than use all words in dialogue, use keywords may involve less noise in our query. We realize keywords extraction module by three keywords algorithms: Tf-idf, TextRank and RAKE. Tf-idf calculate term frequency and inverse document frequency which is used to obtain the importance of words. Term Frequency refers to the number of times a word appears in the document, and inverse document frequency means that the fewer documents the keyword W is contained, the better categorization ability the keyword W has. Tf-idf can be obtained by multiplying B and C. Term Frequency tf and inverse document frequency idf is given by:</p><p>(1)</p><formula xml:id="formula_0" coords="1,126.67,623.82,229.14,56.62">tf ij = n i,j k n k,j (2) idf i = log |D| |{j : t i âˆˆ d j }| (3) tf -idf = tf * idf</formula><p>TextRank is a graph-based sorting algorithm for text. It uses co-occurrence information between words within a document to extract keywords. It can extract the key words and phrases of a given text, and obtain the key sentences of the text with the automatic abstracting method.</p><p>RAKE is a very efficient algorithm. The keywords extracted by RAKE are not single words, but also possible phrases or professional terms. Therefore, RAKE can extract more relevant result which is useful for searching answers.</p><p>1.3. Entities Linking. It is important to link mentions to entities in order to find precise entity names in dialogue. Due to the dataset we used is TREC CAR which is a copy of English wikipedia, link mentions in dialogue to wikipedia entities is a good choices. We chose tagme<ref type="foot" coords="2,267.19,259.06,3.97,6.12" target="#foot_1">2</ref> to achieve this goal. The fast speed, on-the-fly searching and the good performance are the three main advantages of tagme.</p><p>1.4. Retrieval. We use elasticsearch<ref type="foot" coords="2,291.01,288.95,3.97,6.12" target="#foot_2">3</ref> as our base retrieval tools. Each retrieval query is based on keywords and linked entities in the former dialogue history. What's more, each retrieval step will produce a tf-idf based similarity score which indicate how similar the query and each response are.</p><p>1.5. BERT Re-ranking. After getting the candidate responses, we use a BERT model to compute the relevance score between the question and response. BERT has shown its powerful performance in NLP tasks. We use a pre-trained BERT base model<ref type="foot" coords="2,174.85,378.61,3.97,6.12" target="#foot_3">4</ref> , and fine-tuned it on MSRP dataset<ref type="foot" coords="2,337.02,378.61,3.97,6.12" target="#foot_4">5</ref> . The final re-ranking is based on the mix of tf-idf based similarity score (see section 1.4) and BERT relevance score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Result</head><p>We inspect the result of our approach mainly on four metrics: NDCG@5, NDCG@1000, MAP@5 and MAP@1000.</p><p>Statistics are shown in the fellowing table : 

NDCG@5 NDCG@1000 MAP@5 MAP@100 linber 0.2447 0.4116 0.0397 0.1907 Table <ref type="table" coords="2,269.84,503.15,4.34,7.61">1</ref>. The result of linber</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,142.28,693.25,77.44,6.99"><p>https://allennlp.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,142.60,660.71,134.41,6.99"><p>https://tagme.d4science.org/tagme/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,142.60,671.28,88.30,6.99"><p>https://www.elastic.co/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,142.60,681.85,150.90,6.99"><p>https://github.com/google-research/bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,142.60,692.42,251.00,6.99"><p>https://www.microsoft.com/en-us/download/details.aspx?id=52398</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
