<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.09,115.96,325.17,12.62;1,195.94,133.89,223.47,12.62">CROWN: Conversational Passage Ranking by Reasoning over Word Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.25,171.56,119.30,8.74"><roleName>Rishiraj</roleName><forename type="first">Magdalena</forename><surname>Kaiser</surname></persName>
							<email>mkaiser@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<orgName type="institution">Saarland Informatics Campus</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.87,171.56,39.41,8.74"><forename type="first">Saha</forename><surname>Roy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<orgName type="institution">Saarland Informatics Campus</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.98,171.56,75.12,8.74"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
							<email>weikum@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<orgName type="institution">Saarland Informatics Campus</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.09,115.96,325.17,12.62;1,195.94,133.89,223.47,12.62">CROWN: Conversational Passage Ranking by Reasoning over Word Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">90CAA94E7199173A7B86775C3D9B1534</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Conversations</term>
					<term>Passage Ranking</term>
					<term>Word Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Information needs around a topic often cannot be satisfied in a single turn; users typically ask follow-up questions referring to the same theme. A system must be capable of understanding the conversational context of a request to retrieve correct answers. In this paper, we present our submission to the TREC Conversational Assistance Track (CAsT) 2019, in which such a conversational setting is explored. We propose an unsupervised method for conversational passage ranking by formulating the passage score for a query as a combination of similarity and coherence. To be specific, passages are preferred that contain words semantically similar to the words used in the question, and where such words appear close by. We built a word proximity network (WPN) from a large corpus, where words are nodes and there is an edge between two nodes if they co-occur in the same passages in a statistically significant way, within a context window. Our approach, named CROWN, achieved above-average performance on the TREC CAsT data with respect to AP@5 and nDCG@1000.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information needs are usually not one-off: a user who searches for information regarding a specific topic usually asks several questions in a row. Previous turns have an impact on later turns and the system's answer affects subsequent user queries as well. As a result, questions are often not well-formed and selfcontained, but incomplete with ungrammatical phrases and references to previous turns. Thus, a key challenge is to be able to understand context left implicit by the user in their current utterance. However, today's systems are not capable of answering such questions and there are no resources appropriate for training and evaluating models for such conversational search. The Conversational Assistance Track (CAsT) <ref type="foot" coords="1,234.55,588.17,3.97,6.12" target="#foot_0">1</ref> was organized at TREC 2019. The goal was to create a reusable benchmark for open-domain conversational search where answers are passages from large text corpora.</p><p>In this work, we describe our submission to TREC CAsT 2019. We propose an unsupervised method called CROWN (Conversational Passage Ranking by Reasoning Over Word Networks), in which the passage score for a query is formulated as a combination of similarity and coherence. Similarity between query terms and words in a passage is measured in terms of the cosine similarity of their word embedding vectors. In order to estimate passage coherence, we built a word proximity network (WPN) over a large corpus. At query time, the WPN is used to rank passages preferring those with semantically similar words to the ones appearing in the question and those containing query-relevant term pairs that have an edge in the network. Our CROWN method was able to outperform an Indri baseline on the provided training data and achieved aboveaverage results with respect to AP@5 and nDCG@1000 on the evaluation data. Our code is available on GitHub at https://github.com/magkai/CROWN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Conversations in search. Conversational questions are often posed to voice assistants. However, current commercial systems cannot handle conversations with incomplete context well. First steps to formalizing conversational search can be found in <ref type="bibr" coords="2,206.35,333.33,14.61,8.74" target="#b14">[15]</ref>. Furthermore, a query reformulation approach is described in <ref type="bibr" coords="2,146.07,345.28,14.60,8.74" target="#b17">[18]</ref>: an incomplete query is reformulated taking into account the information of previous turns in order to obtain a full-fledged query a standard search engine can deal with. Apart from that, work on search sessions <ref type="bibr" coords="2,385.16,369.19,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,397.17,369.19,12.73,8.74" target="#b21">22,</ref><ref type="bibr" coords="2,411.40,369.19,12.73,8.74" target="#b23">24]</ref> is related to conversational search: information from previous queries from the same session and from click logs is used to better recognize the user's information need and to improve document ranking. Further works on search sessions focus on query suggestion by using auto-completion logs in addition to click logs <ref type="bibr" coords="2,426.59,417.01,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,438.65,417.01,11.62,8.74" target="#b11">12]</ref>. However, in previous works, a ranked list of documents is usually considered as a result for a conversational query, whereas passage-level retrieval, as proposed in TREC CAsT, has not been explored yet. Conversations in reading comprehension. In machine reading comprehension, answers to questions are text spans in provided paragraphs, like in the SQuAD benchmark <ref type="bibr" coords="2,222.97,488.75,14.61,8.74" target="#b15">[16]</ref>. There are several benchmarks available regarding conversational reading comprehension, like QBLink <ref type="bibr" coords="2,349.01,500.70,9.96,8.74" target="#b7">[8]</ref>, CoQA <ref type="bibr" coords="2,397.05,500.70,14.61,8.74" target="#b16">[17]</ref>, QuAC <ref type="bibr" coords="2,450.35,500.70,10.52,8.74" target="#b4">[5]</ref> and ShARC <ref type="bibr" coords="2,170.58,512.66,14.61,8.74" target="#b18">[19]</ref>. A conversational machine reading model is presented, for example, in <ref type="bibr" coords="2,146.65,524.61,14.61,8.74" target="#b24">[25]</ref>. Decision rules are extracted from procedural text and reasoning is performed on whether these rules are already entailed by the conversational history or whether the information must be requested from the user. In <ref type="bibr" coords="2,425.71,548.52,15.50,8.74" target="#b13">[14]</ref> the pretrained language model BERT <ref type="bibr" coords="2,272.14,560.48,10.52,8.74" target="#b6">[7]</ref> is used to encode a paragraph together with each question and answer in the conversational context and the model predicts an answer based on this paragraph representation. However, these works differ from conversational search, since candidate paragraphs or candidate documents are given upfront. Conversations over knowledge graphs. Initial attempts in answering conversational questions are also being made in the area of question answering over knowledge graphs (KGs). In <ref type="bibr" coords="2,259.18,644.16,14.61,8.74" target="#b19">[20]</ref>, the paradigm of sequential question answering over KGs is introduced and a large benchmark, called CSQA, was created for this task. An unsupervised approach, CONVEX, that uses a graph exploration algorithm is presented in <ref type="bibr" coords="3,246.75,130.95,10.52,8.74" target="#b5">[6]</ref> along with another benchmark, named ConvQuestions. Furthermore, approaches based on semantic parsing are presented in <ref type="bibr" coords="3,470.08,142.90,10.52,8.74" target="#b8">[9]</ref> and in <ref type="bibr" coords="3,167.16,154.86,14.61,8.74" target="#b20">[21]</ref>. These works differ from ours since a knowledge graph is searched for an answer, whereas in TREC CAsT large textual corpora are used as source of answer. Questions over knowledge graphs are mainly objective and factoid, while questions over text corpora have a broader scope. Moreover, answers cannot always be found in KGs due to their incompleteness, whereas the required information can often be located readily in web or news corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Description</head><p>This is the first year of the Conversational Assistance Track in TREC. In this track, conversational search is defined as a retrieval task considering the conversational context. The goal of the task is to satisfy a user's information need, which is expressed through a sequence of conversational queries (usually ranging from seven to twelve turns in the provided data). Additionally, the topic of the conversation and a description of its content is given. In this year, the conversational topics and turns have been specified in advance. Here is an example for such a conversation taken from the TREC CAsT training data:  As can be seen in the example, subsequent questions contain references to previously mentioned entities and concepts. References like "it" in Turn 3, which refer to "pansy" or "What about ... " in the last turn referring to "hardiness rating' ' cannot be resolved easily. The response from the retrieval system is a ranked list of passages. The passages are short texts (roughly 1-3 sentences each) and thus also suitable for voice interfaces or mobile screens. They are retrieved from a combination of three standard TREC collections: MS MARCO Passage Ranking, Wikipedia (TREC CAR) and news (Washington Post). Thirty example training topics, that have been created manually, are provided by the organizers, as well as relevance judgments on a three-point scale (2: very relevant, 1: relevant, and 0: not relevant) are given for a limited subset. In total, judgments for around 120 questions are specified. The evaluation is performed over 50 different provided topics. Additionally, an Indri baseline using query likelihood is provided. For the baseline run, AllenNLP coreference resolution <ref type="bibr" coords="4,180.99,421.19,15.50,8.74" target="#b10">[11]</ref> is performed on the query and stopwords are removed using the Indri stopword list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>We now describe CROWN, our unsupervised method for conversational passage ranking. We maximized the passage score for a query that is defined as a combination of similarity and coherence. Intuitively, passages are preferred that contain words semantically similar to the words used in the question and that have such words close to each other. Table <ref type="table" coords="4,320.62,535.66,4.98,8.74" target="#tab_1">1</ref> gives an overview of notations used for describing our method. Our code as well as some technical details are publicly available at https://github.com/magkai/CROWN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Building the Word Proximity Network</head><p>Word proximity networks have widely been studied in previous literature, for example in <ref type="bibr" coords="4,184.55,620.25,9.96,8.74" target="#b1">[2]</ref>, where links in a network are defined as significant co-occurrences between words in the same sentence. We chose the MS MARCO Passage Ranking collection as a representative to build the word proximity network for CROWN. We build the graph G(N, E), where nodes N are all words appearing in the Fig. <ref type="figure" coords="5,201.95,385.07,3.87,8.74">2</ref>: Sample conversation and word proximity network. collection (excluding stopwords) and there is an edge e ∈ E between two nodes if they co-occur in the same passage within a context window W in a statistically significant way. We use NPMI (normalized pointwise mutual information) as a measure of this word association significance, as defined below:</p><formula xml:id="formula_0" coords="5,134.77,480.87,229.24,68.90">npmi(x, y) = pmi(x, y) -log 2 p(x, y) where pmi(x, y) = log p(x, y) p(x) • p(y)</formula><p>and p(x, y) is the joint probability distribution and p(x), p(y) are the individual distributions over random variables x and y.</p><p>While these parts of the network are static and query-agnostic, the network's nodes and edge weights depend on the user input. The NPMI value is used as edge weight between the nodes that are similar to conversational query tokens, whereas node weights are a measure of similarity between conversational query tokens and tokens in the network. In the following sections we will explain the exact weight and score calculations in more detail.</p><p>Figure <ref type="figure" coords="6,166.69,118.99,4.98,8.74">2</ref> shows a sample conversation, consisting of three turns, together with an excerpt from the word proximity network. In Turn 3 of the conversation "UK hardiness rating" is referring to "pansies" mentioned in Turn 2. In the sample WPN, nodes consisting of non-stopwords from three candidate passages are displayed. The numeric value in each node is the node weight where the respective color indicates which of the query words is closest to the corresponding word in the passage. For example, the term "hardiness" appearing in Passage 2 has a direct match in Turn 3 of the conversation. Therefore, its node weight equals 1. If the similarity is below a threshold, then the corresponding node weight will not be considered further, like "winter " or "Europe", marked in grey in the network. The values at the connection of two nodes indicate the edge weights. The edge weights are also only considered if they are above a certain threshold. In our example, only the pairs ("cold ", "climate"), ("flowering","plants") and ("hardiness","rating") appear very frequently together, with an NPMI value of 0.7 or greater, and are therefore considered. They are highlighted in orange in the figure. There are some edge weights which are not considered even though their NPMI values are high. One example for this type is the edge between the pair ("winter ", "cold "). It is not considered because "winter " is not close enough to any query word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Formulating the Conversational Query</head><p>The three query expansion strategies that worked best in CROWN are described in the following. The conversational query (cq) consists of several queries q t from different turns t. In the weighted versions, each considered query has a turn weight w t . When calculating the node weights, the resulting similarity scores are multiplied with the respective turn weight. The conversational query also influences the calculation of the edge weights which we will describe later. The conversational query set cq 1 consists of the current query (q T ) and the first (q 1 ). No weights are used; therefore, the set of conversational query weights cqw 1 is empty. The second option uses a weighted version (cq 2 ). It consists of the current, the previous and the first turn, where each turn has a weight in cqw 2 , which is decayed for the previous turn. The last option we consider (cq 3 ) contains all previous turns, where decaying weights are used for each turn, except for the first and the current one, which receive full weights (cqw 3 ).</p><formula xml:id="formula_1" coords="6,141.74,546.00,338.85,60.79">• cq 1 = {q T , q 1 }, cqw 1 = {} • cq 2 = {q T , q T -1 , q 1 }, cqw 2 = {w T , w T -1 , w 1 }, where: w 1 , w T = 1.0 and w T -1 = (T -1) T • cq 3 = {q T , q T -1 , q T -2 , ..., q 1 }, cqw 3 = {w T , w T -1 , w T -2 , ..., w 1 }, where t ∈ [1, .., T ] if (t == 1 ∨ t == T ) {w t = 1} else {w t = t T }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Retrieving Candidate Passages</head><p>We used the Indri search engine <ref type="bibr" coords="6,281.69,644.16,15.50,8.74" target="#b22">[23]</ref> in CROWN to obtain a set of candidate passages P . Our Indri query (iq) also consists of a combination of queries from different turns. Furthermore, Indri supports weighting of query terms. Here is an example how the weighting of certain words can be done in an Indri query:</p><p>#weight( 1.0 #combine (survive frost) 0.8 #combine (pansy types) )</p><p>We were able to produce the best results with the following expansions: In iq 1 , the Indri query consists of the current, the previous and the first turn and no weights are used; iq 2 consists of the current turn, turn T-1, turn T-2 and the first turn, again without using weights. The weighted version iq 3 uses all previous turns and the corresponding decayed weights can be seen in iqw 3 . Finally, iq union means that three different queries (built from iq 1 , iq 2 and iq 3 ) are issued to Indri and the union of the resulting passages is used for re-ranking.</p><formula xml:id="formula_2" coords="7,141.74,265.97,312.04,58.43">• iq 1 = {q T , q T -1 , q 1 }, iqw 1 = {} • iq 2 = {q T , q T -1 , q T -2 , q 1 }, iqw 2 = {} • iq 3 = {q T , q T -1 , q T -2 , ..., q 1 }, iqw 3 = {w T , w T -1 , w T -2 , ..., w 1 }, where t ∈ [1, .., T ] in w t ; if (t == 1 ∨ t == T ) {w t = 1} else {w t = t T } • iq union = {iq 1 ∪ iq 2 ∪ iq 3 }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Scoring Candidate Passages</head><p>In CROWN, the final score of a passage P i consists of several components that will be described in the following.</p><p>Estimating similarity. The similarity score that is built upon the node weights is calculated in the following way:</p><formula xml:id="formula_3" coords="7,231.61,435.15,150.94,30.32">score node (P i ) = n j=1 N W (p ij ) n j=1 1 C1 (p ij )</formula><p>where the node weight N W of a token p ij and the condition C 1 will be defined next.</p><formula xml:id="formula_4" coords="7,184.75,503.06,245.37,14.66">N W (p ij ) := 1 C1 (p ij ) • max k∈qt∈cq sim(vec(p ij ), vec(cq k )) • w t</formula><p>where 1 C1 (p ij ) maps to 1 if the condition C 1 (p ij ) is fulfilled, otherwise to 0; vec(p ij ) is the word embedding vector of the j th token in the i th passage; vec(cq k ) is the word embedding vector of the k th token in the conversational query cq and w t is the weight of the turn in which cq k appeared; sim denotes the cosine similarity between the passage token and the query token embeddings. C 1 (p ij ) is defined as</p><formula xml:id="formula_5" coords="7,200.48,609.65,214.35,9.65">C 1 (p ij ) := ∃cq k ∈ cq : sim(vec(p ij ), vec(cq k )) &gt; α</formula><p>which means that condition C 1 is only fulfilled if the similarity between a query word and a word in the passage is above a certain threshold α.</p><p>Estimating coherence. Coherence is expressed by term proximity which is reflected in the edge weights. The corresponding score is calculated as follows:</p><formula xml:id="formula_6" coords="8,192.31,148.37,229.54,30.55">score edge (P i ) = n j=1 W k=j+1 EW (p ij , p ik ) n j=1 W k=j+1 1 C2 (p ij , p ik )</formula><p>The indicator function 1 C2 (p ij , p ik ) maps to 1 if condition C 2 (p ij , p ik ) is fulfilled otherwise to 0. The edge weight EW is defined as:</p><formula xml:id="formula_7" coords="8,207.08,218.88,201.20,9.65">EW (p ij , p ik ) := 1 C2 (p ij , p ik ) • N P M I(p ij , p ik )</formula><p>The NPMI value between the tokens is calculated from MS MARCO Passage Ranking as a representative corpus. Condition C 2 (p ij , p ik ) is defined as</p><formula xml:id="formula_8" coords="8,217.35,268.12,180.65,9.65">C 2 (p ij , p ik ) := C 21 (p ij , p ik ) ∧ C 22 (p ij , p ik )</formula><p>where</p><formula xml:id="formula_9" coords="8,169.36,305.41,264.47,99.32">C 21 (p ij , p ik ) := hasEdge(p ij , p ik ) ∧ N P M I(p ij , p ik ) &gt; β C 22 (p ij , p ik ) := ∃cq r , cq s ∈ cq : sim(vec(p ij ), vec(cq r )) &gt; α ∧ sim(vec(p ik ), vec(cq s )) &gt; α ∧ cq r = cq s ∧ ∃cq r , cq s ∈ cq : sim(vec(p ij ), vec(cq r )) &gt; sim(vec(p ij ), vec(cq r ))</formula><p>∨ sim(vec(p ik ), vec(cq s )) &gt; sim(vec(p ik ), vec(cq s ))</p><p>Condition C 21 assures that there is an edge between the two tokens in the graph and that the edge weight is above a certain threshold β. The second condition, C 22 , states that there are two non-identical words in the conversational query where one of them is the one that is most similar to p ij (more than any other query token and with similarity above threshold α) and the other word is most similar to p ik .</p><p>Estimating priors. We also consider the original ranking received from Indri. In CROWN, this score is defined as:</p><formula xml:id="formula_10" coords="8,250.45,540.34,113.26,23.23">score indri (P i ) = 1 rank(P i )</formula><p>where rank is the rank the passage P i received from Indri.</p><p>Putting it together. The final score for a passage P i consists of a weighted sum of these three individual scores. More formally:</p><formula xml:id="formula_11" coords="8,155.02,625.52,305.33,9.65">score(P i ) = h 1 • score indri (P i ) + h 2 • score node (P i ) + h 3 • score edge (P i )</formula><p>where h 1 , h 2 and h 3 are hyperparameters that are tuned using the provided training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baseline and Metrics</head><p>The provided Indri retrieval model mentioned in Section 3 has been used as the baseline in our experiments. Since responses are assessed using graded relevance, we used nDCG <ref type="bibr" coords="9,231.19,196.24,15.50,8.74" target="#b9">[10]</ref> (normalized discounted cumulative gain) and ERR <ref type="bibr" coords="9,470.08,196.24,10.52,8.74" target="#b3">[4]</ref> (expected reciprocal rank) as metrics. Furthermore, AP (average precision) is reported on the evaluation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Configuration</head><p>Dataset. As mentioned in Section 3, the underlying document collection consists of a combination of three standard TREC collections: MS MARCO, TREC CAR and Washington Post.</p><p>Initialization. We used word2vec embeddings <ref type="bibr" coords="9,347.56,338.00,15.50,8.74" target="#b12">[13]</ref> pre-trained on the Google News dataset and obtained via the python library gensim<ref type="foot" coords="9,393.89,348.38,3.97,6.12" target="#foot_1">2</ref> . Furthermore, the python library spaCy<ref type="foot" coords="9,226.86,360.34,3.97,6.12" target="#foot_2">3</ref> has been used for tokenization and stopword removal. As already mentioned, Indri has been used for candidate passage retrieval. We set the number of retrieved passages from Indri to 1000, so as not to lose any relevant documents. For graph processing, we used the NetworkX<ref type="foot" coords="9,386.36,396.20,3.97,6.12" target="#foot_3">4</ref> python library. The window size W for which word co-occurrences are taken into account is set to three in our graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Submitted Runs</head><p>We submitted four runs for the TREC CAsT track. These are described below.</p><p>Run 1: mpi-d5 igraph (indri + graph). For our first run, we used the unweighted conversational query cq 1 and the first unweighted option iq 1 for the Indri query. These options performed best in our experiments. For definitions of cq and iq, refer to Section 4.2 and Section 4.3 respectively. The node threshold α is set to 0.7, which means that nodes require having a word embedding similarity to a query token that is greater than 0.7 in order to influence the score calculation. The edge threshold β is set to 0.0 to exclude negative NPMI values. The three hyperparameters are chosen as follows: h 1 = 0.6 (indri score), h 2 = 0.3 (node score), h 3 = 0.1 (edge score).   Run 2: mpi-d5 intu (indri-tuned). In our second run, we vary the set of hyperparameters, while the rest stays the same as in Run 1: h 1 = 0.9 (indri score), h 2 = 0.1 (node score), h 3 = 0.0 (edge score). This run gives most emphasis towards the indri score, while coherence in our graph is not considered by giving no weight to the edge score.</p><p>Run 3: mpi-d5 union (union of indri queries). Here we use iq union which means that we issue three separate queries to Indri and take the union of all returned passages. However, this leads to three separate Indri rankings which are incomparable. Therefore, we do not consider the indri score in our final score calculation by setting h 1 to 0. Setting h 2 = 0.6 (node score) and h 3 = 0.4 (edge score) worked best on the training data in this setting. The conversational query and the node threshold are the same as for the previous runs.</p><p>Run 4: mpi-d5 cqw (weighted conversational query). In our final run, the conversational query is varied as follows: option cq 2 is used and the node threshold is a bit more restrictive with α = 0.85. Apart from that, the parameters are set to the same values as in Run 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Insights</head><p>We present the results of our four runs on the training and the evaluation data.   Training data. We compared our runs to the Indri baseline provided by the organizers (see Table <ref type="table" coords="11,229.46,485.27,3.87,8.74" target="#tab_2">2</ref>). Note that for calculating the nDCG and ERR metrics for the training data, only the limited relevance judgements from the manually created conversations have been used. Three of our runs were able to outperform the Indri baseline with respect to nDCG@1000.</p><p>Evaluation data. In Tables <ref type="table" coords="11,263.64,546.78,4.98,8.74" target="#tab_4">3</ref> and<ref type="table" coords="11,291.06,546.78,3.87,8.74" target="#tab_5">4</ref>, the results on the evaluation data for the metrics AP@5 and nDCG@1000 are reported. Average values for each turn (up to Turn 8) and over all turns are displayed. The results for our four runs are reported as well as the median and best turn-wise results over all submissions to the track. Additionally, in Figure <ref type="figure" coords="11,293.80,594.60,4.98,8.74" target="#fig_2">3</ref> the results of our four runs are visualized over eight turns for AP@5 and nDCG@1000. There seems to be the tendency that the results increase for later turns (up to Turn 6 for AP@5) or do not vary much (up to Turn 7 for nDCG@1000). This means that our method is robust with respect to turn depth and that later turns successfully exploit the information available from previous turns. Three Turn Query Passage Snippet</p><p>4 "What makes it so addictive?" ("it": "smoking", Turn 1)</p><p>"Nicotine, the primary psychoactive chemical in cigarettes, is highly addictive." 2 "What makes it so unusual?" ("it": "Uranus", Turn 1)</p><p>"One fact that is not only unusual, but also makes Uranus markedly different from earth is the angle of its spin axis." 3 "How much do Holsteins produce?" ("Holsteins": "cattle", Turn 1) ("produce": "milk", Turn 2) of our runs, namely mpi-d5 igraph, mpi-d5 intu and mpi-d5 cqw achieve aboveaverage performance with respect to both metrics. Our mpi-d5 union run does not achieve competitive results probably because the candidate passages which are taken from the union of the three separate Indri retrievals create a pool which is too large for effective re-ranking. Furthermore, Table <ref type="table" coords="12,239.07,414.71,4.98,8.74" target="#tab_6">5</ref> shows some exemplary queries taken from the training data, that appear at different turns in the respective conversation, together with passage snippets taken from top-ranked passages by CROWN (rank 1-5). Information from previous turns is required to be able to correctly answer the questions. For example, the query "What about in the US? ", asked at Turn 5, needs the additional information "physician assistants" and "starting salary", given at Turn 1 and Turn 4 respectively. These are directly matched in the correct answer, resulting in a high node score, and additionally appear next to each other (high edge score).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we presented our unsupervised method CROWN. We showed that using a combination of similarity and coherence for scoring relevant passages is a simple estimate but works quite well in practice. A context window of size three seems to successfully capture significant word co-occurrences. In general, it seemed that giving greater influence to the Indri ranking and giving a higher preference to node weights than edge weights improves results. Regarding query expansion strategies we observed that including only the previous and the first turns proved to be most beneficial. Weighted turns did not improve the results significantly.</p><p>In the future, we would also consider the positions of query terms in passages following the intuition that passages are more relevant in which the query terms appear earlier. Furthermore, we could use contextualized embeddings, like a pretrained BERT model <ref type="bibr" coords="13,227.38,178.93,9.96,8.74" target="#b6">[7]</ref>, to deal with polysemy. Yet another possibility would be to use BERT for re-ranking by introducing its ranking results as an additional score.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,173.17,571.10,269.02,8.74"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1: Sample conversation from the TREC CAsT 2019 data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,198.78,117.78,272.62,7.86;10,143.95,131.53,51.64,7.86;10,216.83,131.53,20.99,7.86;10,270.78,131.50,24.17,7.89;10,326.36,131.53,20.99,7.86;10,380.10,131.53,20.99,7.86;10,433.87,131.53,20.99,7.86;10,147.06,142.89,45.44,7.86;10,216.83,142.89,20.99,7.86;10,272.37,142.89,20.99,7.86;10,326.36,142.89,20.99,7.86;10,380.10,142.89,20.99,7.86;10,432.28,142.86,24.17,7.89"><head></head><label></label><figDesc>mpi-d5 igraph mpi-d5 intu mpi-d5 union mpi-d5 cqw indri baseline nDCG</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,173.89,328.45,267.58,8.74;10,134.77,187.24,172.91,129.68"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Turn-wise results for our four runs on evaluation data.</figDesc><graphic coords="10,134.77,187.24,172.91,129.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,186.64,165.57,242.07,207.97"><head></head><label></label><figDesc></figDesc><graphic coords="5,186.64,165.57,242.07,207.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,138.47,120.07,340.98,182.13"><head>Table 1 :</head><label>1</label><figDesc>Set of candidate passages, i th passage, j th token in i th passage vec(•) Normalized point-wise mutual information between two passage tokens hasEdge(pij, pik)Returns true if there is an edge between two tokens in the graph scorenode, scoreedge, scoreindri Similarity score, coherence score, score based on Indri rank α, βThreshold for node weights, threshold for edge weights W Notation for key concepts in CROWN.</figDesc><table coords="4,138.47,120.07,286.15,168.46"><row><cell>Notation</cell><cell>Concept</cell></row><row><cell>t, T</cell><cell>Conversational turn t, current turn T</cell></row><row><cell>qt, wt</cell><cell>Query at turn t (without stopwords), weight for turn t</cell></row><row><cell>cq1, cq2, cq3</cell><cell>Conversational query sets</cell></row><row><cell>cqw1, cqw2, cqw3</cell><cell>Sets with conversational query weights</cell></row><row><cell>iq1, iq2, iq3, iqunion</cell><cell>Indri query sets</cell></row><row><cell>iqw1, iqw2, iqw3</cell><cell>Sets with indri query weights</cell></row><row><cell>G(N, E)</cell><cell>Word proximity network with nodes N and edges E</cell></row><row><cell>N W, EW</cell><cell>Node weights, edge weights</cell></row><row><cell>P, Pi, pij</cell><cell></cell></row><row><cell></cell><cell>Word embedding</cell></row><row><cell>sim(vec(•), vec(•))</cell><cell>Cosine similarity between word embedding vectors</cell></row><row><cell>N P M I(pij, pik)</cell><cell></cell></row><row><cell></cell><cell>Context window size</cell></row><row><cell>h1, h2, h3</cell><cell>Hyperparameters for final score calculation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,234.07,154.26,147.22,8.74"><head>Table 2 :</head><label>2</label><figDesc>Results on training data.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,134.77,247.11,345.83,161.07"><head>Table 3 :</head><label>3</label><figDesc>Turn-wise results on evaluation data for AP@5. Above-median values for our submissions are in bold.</figDesc><table coords="11,136.56,282.36,328.88,125.82"><row><cell></cell><cell cols="2">mpi-d5 igraph mpi-d5 intu</cell><cell>mpi-</cell><cell cols="2">mpi-d5 cqw median</cell><cell>best</cell></row><row><cell></cell><cell></cell><cell></cell><cell>d5 union</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Turn 1</cell><cell>0.497</cell><cell>0.518</cell><cell>0.444</cell><cell>0.497</cell><cell>0.472</cell><cell>0.761</cell></row><row><cell>Turn 2</cell><cell>0.448</cell><cell>0.480</cell><cell>0.330</cell><cell>0.446</cell><cell>0.367</cell><cell>0.759</cell></row><row><cell>Turn 3</cell><cell>0.486</cell><cell>0.504</cell><cell>0.399</cell><cell>0.479</cell><cell>0.417</cell><cell>0.779</cell></row><row><cell>Turn 4</cell><cell>0.438</cell><cell>0.456</cell><cell>0.350</cell><cell>0.436</cell><cell>0.382</cell><cell>0.778</cell></row><row><cell>Turn 5</cell><cell>0.425</cell><cell>0.453</cell><cell>0.353</cell><cell>0.410</cell><cell>0.374</cell><cell>0.777</cell></row><row><cell>Turn 6</cell><cell>0.454</cell><cell>0.494</cell><cell>0.329</cell><cell>0.458</cell><cell>0.364</cell><cell>0.821</cell></row><row><cell>Turn 7</cell><cell>0.463</cell><cell>0.499</cell><cell>0.352</cell><cell>0.456</cell><cell>0.404</cell><cell>0.841</cell></row><row><cell>Turn 8</cell><cell>0.374</cell><cell>0.420</cell><cell>0.296</cell><cell>0.376</cell><cell>0.309</cell><cell>0.810</cell></row><row><cell>All</cell><cell>0.441</cell><cell>0.470</cell><cell>0.352</cell><cell>0.437</cell><cell>0.362</cell><cell>0.754</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,134.77,411.70,345.82,20.69"><head>Table 4 :</head><label>4</label><figDesc>Turn-wise results on evaluation data for nDCG@1000. Above-median values for our submissions are in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,134.77,198.08,345.83,120.54"><head>Table 5 :</head><label>5</label><figDesc>Examples for correct answer snippets (rank 1 -5 in CROWN) for queries from different turns taken from training conversations.</figDesc><table coords="12,322.20,198.08,156.60,29.78"><row><cell>"The Holstein-Friesian is the breed of</cell></row><row><cell>dairy cow most common in [...], around</cell></row><row><cell>22 litres per day is average."</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.44,108.27,7.47"><p>http://www.treccast.ai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="9,144.73,634.88,175.58,7.86"><p>gensim: https://radimrehurek.com/gensim/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="9,144.73,645.84,98.96,7.86"><p>spaCy: https://spacy.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="9,144.73,656.80,158.55,7.86"><p>NetworkX: https://networkx.github.io/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,259.97,337.64,7.86;13,151.52,270.93,25.60,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="13,264.06,259.97,164.02,7.86">Context-sensitive query auto-completion</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Bar-Yossef</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kraus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,282.05,337.63,7.86;13,151.52,292.98,307.10,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,266.16,282.05,147.01,7.86">The small world of human language</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F I</forename><surname>Cancho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">V</forename><surname>Solé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,310.19,293.01,75.19,7.86">Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<date type="published" when="1482">1482. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,304.13,337.64,7.86;13,151.52,315.09,329.07,7.86;13,151.52,326.05,57.08,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="13,343.77,304.13,136.83,7.86;13,151.52,315.09,310.70,7.86">Towards context-aware search by learning a very large variable length hidden markov model from search logs</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,337.18,337.64,7.86;13,151.52,348.13,329.07,7.86;13,151.52,359.09,124.17,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,364.25,337.18,116.34,7.86;13,151.52,348.13,65.15,7.86">Expected reciprocal rank for graded relevance</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metlzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Grinspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,237.00,348.13,243.59,7.86;13,151.52,359.09,95.49,7.86">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,370.22,337.64,7.86;13,151.52,381.18,249.45,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,165.48,381.18,151.99,7.86">QuAC: Question answering in context</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,338.65,381.18,33.66,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,392.30,337.63,7.86;13,151.52,403.26,329.07,7.86;13,151.52,414.22,146.47,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="13,432.56,392.30,48.03,7.86;13,151.52,403.26,329.07,7.86;13,151.52,414.22,70.83,7.86">Look before you hop: Conversational question answering over knowledge graphs using judicious context expansion</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Christmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>CIKM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,425.34,337.63,7.86;13,151.52,436.30,304.39,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="13,354.85,425.34,125.74,7.86;13,151.52,436.30,199.77,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,447.42,337.64,7.86;13,151.52,458.38,213.49,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,323.88,447.42,156.72,7.86;13,151.52,458.38,129.78,7.86">A dataset and baselines for sequential open-domain question answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,302.68,458.38,33.66,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,469.51,337.63,7.86;13,151.52,480.47,296.36,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="13,352.55,469.51,128.04,7.86;13,151.52,480.47,212.09,7.86">Dialog-to-action: conversational question answering over a large-scale knowledge base</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,491.59,337.98,7.86;13,151.52,502.52,261.71,7.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,272.75,491.59,203.78,7.86">Cumulated gain-based evaluation of ir techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,151.52,502.55,207.59,7.86">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,513.67,337.98,7.86;13,151.52,524.63,97.90,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,329.90,513.67,150.70,7.86;13,151.52,524.63,14.75,7.86">End-to-end neural coreference resolution</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,187.10,524.63,33.66,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,535.76,337.98,7.86;13,151.52,546.71,329.07,7.86;13,151.52,557.67,92.66,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="13,415.66,535.76,64.93,7.86;13,151.52,546.71,329.07,7.86;13,151.52,557.67,14.75,7.86">Exploring query auto-completion and click logs for contextual-aware web search and query suggestion</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,568.80,337.97,7.86;13,151.52,579.76,329.07,7.86;13,151.52,590.71,154.15,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,407.41,568.80,73.17,7.86;13,151.52,579.76,232.55,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,404.48,579.76,76.12,7.86;13,151.52,590.71,125.48,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,601.84,337.98,7.86;13,151.52,612.80,329.07,7.86;13,151.52,623.76,329.07,7.86;13,151.52,634.72,38.90,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,390.21,601.84,90.38,7.86;13,151.52,612.80,329.07,7.86;13,151.52,623.76,57.60,7.86">A simple but effective method to incorporate multi-turn context with BERT for conversational machine comprehension</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ohsugi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,230.29,623.76,250.31,7.86;13,151.52,634.72,10.24,7.86">Proceedings of the First Workshop on NLP for Conversational AI</title>
		<meeting>the First Workshop on NLP for Conversational AI</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,645.84,337.98,7.86;13,151.52,656.80,55.93,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,263.93,645.84,198.68,7.86">A theoretical framework for conversational search</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,151.52,656.80,27.25,7.86">CHIIR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,119.67,337.98,7.86;14,151.52,130.63,207.29,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,356.42,119.67,124.17,7.86;14,151.52,130.63,124.08,7.86">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,296.49,130.63,33.66,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,141.59,337.98,7.86;14,151.52,152.52,104.25,7.89" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,305.69,141.59,174.91,7.86;14,151.52,152.55,35.25,7.86">Coqa: A conversational question answering challenge</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,193.77,152.55,24.96,7.86">TACL</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,163.51,337.98,7.86;14,151.52,174.47,201.07,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="14,306.75,163.51,173.85,7.86;14,151.52,174.47,122.49,7.86">Conversational query understanding using sequence to sequence modeling</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,185.43,337.98,7.86;14,151.52,196.39,329.07,7.86;14,151.52,207.34,147.85,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="14,253.16,196.39,227.43,7.86;14,151.52,207.34,64.34,7.86">Interpretation of natural language rules in conversational machine reading</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saeidi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sheldon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,218.30,337.97,7.86;14,151.52,229.26,329.07,7.86;14,151.52,240.22,221.85,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,445.00,218.30,35.59,7.86;14,151.52,229.26,329.07,7.86;14,151.52,240.22,147.70,7.86">Complex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pahuja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chandar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,320.65,240.22,24.06,7.86">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,251.18,337.98,7.86;14,151.52,262.14,329.07,7.86;14,151.52,273.10,157.23,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,151.52,262.14,329.07,7.86;14,151.52,273.10,37.01,7.86">Multi-task learning for conversational question answering over a large-scale knowledge base</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,209.69,273.10,70.38,7.86">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,284.06,337.97,7.86;14,151.52,295.02,108.73,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,266.85,284.06,213.73,7.86;14,151.52,295.02,33.00,7.86">Context-sensitive information retrieval using implicit feedback</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,205.80,295.02,25.78,7.86">SIGIR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,305.98,337.98,7.86;14,151.52,316.93,275.41,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,355.80,305.98,124.80,7.86;14,151.52,316.93,133.58,7.86">Indri: A language-model based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,291.98,316.93,106.28,7.86">Information Retrieval -IR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,327.89,337.97,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,229.25,327.89,179.17,7.86">Towards context-aware search with right click</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Lou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,427.09,327.89,25.79,7.86">SIGIR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,338.85,337.98,7.86;14,151.52,349.81,179.93,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="14,264.78,338.85,215.81,7.86;14,151.52,349.81,111.01,7.86">E3: Entailment-driven extracting and editing for conversational machine reading</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,283.71,349.81,19.07,7.86">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
