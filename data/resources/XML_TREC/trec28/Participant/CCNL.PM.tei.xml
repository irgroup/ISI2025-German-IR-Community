<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,115.58,86.92,375.04,14.36">SCUT-CCNL at TREC 2019 Precision Medicine Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.14,112.54,64.19,10.80"><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Communication and Computer Network Key Laboratory of Guangdong</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.93,112.54,27.00,10.80"><forename type="first">Lu</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Communication and Computer Network Key Laboratory of Guangdong</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Communication and Computer Network Key Laboratory of Guangdong</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.01,112.54,57.60,10.80"><forename type="first">Zuoxi</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Communication and Computer Network Key Laboratory of Guangdong</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,350.71,112.54,69.59,10.80"><forename type="first">Shoubin</forename><surname>Dong</surname></persName>
							<email>sbdong@scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Communication and Computer Network Key Laboratory of Guangdong</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,115.58,86.92,375.04,14.36">SCUT-CCNL at TREC 2019 Precision Medicine Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">29CB595D5C0535CF52C6B4364EE3D1CD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Precision Medicine, Re-ranking model</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a retrieval system developed for the TREC 2019 Precision Medicine Track. For two tasks of Scientific Abstracts and Clinical Trials, we applied the same structure, including the retrieval model, the query expansion and the reranking model, to generate the final retrieval results. The experiment results show that the re-ranking model based on SciBERT is of great benefit for retrieval tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There are two tasks, the Scientific Abstracts and the Clinical Trials, released by the TREC 2019 Precision Medicine Track. For the task of Scientific Abstracts, it focuses on extracting the abstracts of biomedical articles from PubMed Central and providing patients with related treatments, prevention and prognosis. For the task of Clinical Trials, it addresses experiment treatments from ClinicalTrials.gov website for patients if the existing treatments are invalid. In addition, unlike the TREC 2017 and 2018 Precision Medicine Track <ref type="bibr" coords="1,263.56,553.83,9.05,10.80" target="#b0">[1]</ref><ref type="bibr" coords="1,277.15,553.83,9.05,10.80" target="#b1">[2]</ref>, this year adds a sub-task to the scientific abstracts task to find out the particular treatment recommendation for biomedical articles. This sub-task is optional and we have not done it. The 2019 track provides 50 topics related to the patient's disease, genetic variants and demographics.</p><p>In this paper, we first indexed the document set and process the query, and then used the BM25 model to extract the relevant document based on the given patient information to form a candidate document set. Finally, we applied SciBERT to rerank the candidate document set to get the final results. The rest of the paper is organized as follows. Section 2 gives a detailed description of our approach. Section 3 is the result of our approach on two tasks. In Section 4, we make a conclusion about our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collection Indexing</head><p>The collections of scientific abstracts and clinical trials are respectively indexed by Apache Luence <ref type="bibr" coords="2,188.25,107.38,12.69,10.91" target="#b2">[3]</ref>. For scientific abstract, the indexed fields are "PMID", "ArticleTitle", "AbstractText", "MeshHeadingList", "ChemicalList", while for clinical trials, the indexed fields are "NCT ID", "Title", "Brief Title", "Brief Summary", "Detailed Description", "Study Type", "Intervention Type", "Inclusion Criteria", "Exclusion Criteria", "Healthy Volunteers", "Keywords" and "MeSH Terms". Before indexed scientific abstracts and clinical trials, we applied standard processing including tokenization, stemming and stop word removal to these indexed fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>Referring to <ref type="bibr" coords="2,162.33,260.29,12.75,10.80" target="#b2">[3]</ref>, we use the same tools to expand disease fields and gene fields. The diseases are enriched into preferred term and synonyms by Lexigram<ref type="foot" coords="2,434.74,274.04,4.02,7.24" target="#foot_0">1</ref> a proprietary API based on the Systematic Nomenclature of Medicine-Clinical Terms (SNOMED CT), the Medical Subject Headings (MeSH) and the International Classification of Diseases (ICD). And the genes are expanded with its synonyms and hyponym by the National Center for Biotechnology Information (NCBI) gene list <ref type="foot" coords="2,437.62,336.44,4.02,7.24" target="#foot_1">2</ref> . The query expansions are used by re-ranking model. Table <ref type="table" coords="2,335.04,353.89,6.00,10.80" target="#tab_0">1</ref> and Table <ref type="table" coords="2,394.89,353.89,6.00,10.80" target="#tab_1">2</ref> shows an example of the expansion of disease and gene variant. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Retrieval</head><p>In this section, we will introduce our retrieval model applied for the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Query Generation</head><p>We employed the topics of disease and gene variant to generate a disjunctive Boolean query and a conjunctive Boolean query, respectively noted as ùëÑ ùëë ‚à™ ùëÑ ùëî and ùëÑ ùëë ‚à© ùëÑ ùëî , where disease is denoted as ùëÑ ùëë and gene variant is denoted as ùëÑ ùëî .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Retrieval Model</head><p>To retrieve relevant clinical trials and scientific abstracts, we used BM25 <ref type="bibr" coords="3,477.72,134.14,12.97,10.80" target="#b3">[4]</ref>, a language model with Jelinek-Mercer smoothing and one with Dirichlet smoothing, with two Boolean queries. In each query, we reserved the top 20,000 results for each topic, noted as ùëÖ 0 and ùëÖ 1 . Finally, we combined ùëÖ 0 and ùëÖ 1 with corresponding weights, which are set by grid searching on TERC 2017 and 2018 Precision Medicine Track according to the highest recall. We reserved the top 2000 results for each topic as candidate documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Re-ranking Method</head><p>In this section, we will describe our re-ranking method in detail. In TREC 2017 and 2018 Precision Medicine Track, a list of related documents is provided for each topic. Some of the related documents are marked as 2, which is definitely relevant to "Precision Medicine" and some of them are marked as 1, which is partially relevant to "Precision Medicine". The rest of them are marked as 0, which is not relevant to "Precision Medicine".</p><p>With the annotation information, we considered document ranking as a twocategory problem-given a document, by judging whether it is related to PM. Documents, definitely relevant and partially relevant to given topics, are considered as positive examples. The irrelevant documents are considered as negative examples.</p><p>The 2017 Track has qrels on 30 topics, and the 2018 Track has qrels on 50 topics. The data set used for model training consists of a list of related documents about 80 topics. According to the ratio of 9 to 1, we randomly selected 72 topic related documents as the training set and 8 topic related documents as the verification set. The candidate document set is a test set described in Section 2.3.2.</p><p>For this classification problem, we selected SciBERT <ref type="bibr" coords="3,372.27,520.95,13.99,10.80" target="#b4">[5]</ref> as the re-ranking model. SciBERT is a self-attention model pre-trained on a large-scale biomedical literature corpus and is one of the best models for classification problems. SciBERT is rarely used to document retrieval, however its own self-contained structure (Transformer) <ref type="bibr" coords="3,101.06,583.38,13.99,10.80" target="#b5">[6]</ref> can learn the complex semantic information from long articles, which can improve the performance of the document retrieval. In addition, by pre-training on biomedical data sets, the model can learn plenty of additional biomedical knowledge.</p><p>The SciBERT applied to the re-ranking step needs to process two parts of input, one of which is the input of the topic and the other is the input of the candidate retrieval documents. Therefore, for the input of the model, we need to follow the steps described as below.</p><p>a) For the processing of the topic, we only use the disease field and the gene variant field of topics for the document re-ranking, and then we expanding these fields. We arrange them in order of "disease, the preferred term of disease, the synonyms of disease, gene variant, the synonyms of gene variant, the hyponym of gene variant" and form the input A. b) Due to the difference of contents of the documents in the two tasks, they are processed separately. For Scientific abstracts, we select "AbstractTitle" and "AbstractText" as input B in a document. For Clinical Trials, we select "Brief Title" and "Brief Summary" as input C in a document. c) Finally, according to qrels of TREC 2017 and 2018 Precision Medicine, a query statement, input A, corresponds to a document, input B or input C. We combined input A and input B or input A and input C as shown in Figure <ref type="figure" coords="4,399.74,240.34,4.50,10.80" target="#fig_0">1</ref>. Finally, the number of samples generated by each task is shown in Table <ref type="table" coords="4,355.56,255.97,4.50,10.80" target="#tab_2">3</ref>. After the re-ranking model is trained on the training set, the candidate documents are classified and got a score, and then the top 1000 documents for each topic are reserved as final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Run description</head><p>For Scientific Abstracts, our team submitted five runs. For the first four runs, we used the retrieval model and the re-ranking model, and the last run we only used the retrieval model. The runs of the first four times are also slightly different. Some of them only extended the synonym or has no extension when expanding the topic. There are also some results in which 4,000 candidate documents are built for each topic. The specific differences are shown in Table <ref type="table" coords="4,343.98,542.91,4.67,10.80" target="#tab_3">4</ref>: For the Clinical Trials, our team submitted two runs. Both runs used a retrieval model, a re-ranking model, and the same topic extension. The difference is in the number of final re-ranked documents, shown in Table <ref type="table" coords="4,362.58,742.02,4.50,10.80">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5: The differences of two runs for Clinical Trials</head><p>The number of re-ranking document ccnl_trials1 80,000 ccnl_trials2 160,000</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Results</head><p>The evaluation of Scientific Abstracts and Clinical Trials are given in Table <ref type="table" coords="5,478.00,168.34,6.00,10.80" target="#tab_4">6</ref> and Table <ref type="table" coords="5,133.69,183.94,4.50,10.80">7</ref>, respectively. The best results are all marked in bold. In the Scientific Abstracts task, the run "ccnl_sa1" is optimal for infNDCG. The run "ccnl_sa2" is optimal for P@10 and R-prec. In the Clinical Trials task, the run ccnl_trials1 is optimal for infNDCG and P@10, and the run "ccnl_trials2" is optimal for R-prec. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this paper, we described the method used on the TREC 2019 Precision Medicine. We performed standard processing including tokenization, stemming and stop word removal and indexing on the document set of the two tasks. Then we used BM25 to retrieve the document sets to generate candidate document sets, and finally we used SciBERT to re-rank the candidate document sets. The experimental results show that SciBERT can be used to improve the optimal ranking of the search results. In addition, the expansion of diseases and genetic variants has an important role in ranking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,207.17,150.34,191.98,10.80;4,204.85,174.10,27.55,9.92;4,248.90,174.10,153.16,9.92"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The re-ranking model of input [CLS] A [SEP] B or C [SEP]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,131.06,400.99,345.81,73.80"><head>Table 1 :</head><label>1</label><figDesc>An example of disease expansion</figDesc><table coords="2,131.06,417.09,345.81,57.70"><row><cell>Disease</cell><cell>dilated cardiomyopathy</cell></row><row><cell>Preferred term</cell><cell>primary dilated cardiomyopathy</cell></row><row><cell>Synonyms</cell><cell>congestive cardiomyopathy, cocm, ccm, dilated</cell></row><row><cell></cell><cell>cardiomyopathy, congestive dilated cardiomyopathy, dcm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,127.82,492.93,348.28,120.73"><head>Table 2 :</head><label>2</label><figDesc>An example of gene expansion</figDesc><table coords="2,127.82,509.13,348.28,73.30"><row><cell>Gene</cell><cell>LMNA</cell></row><row><cell>Synonyms</cell><cell>CDCD1, CDDC, CMD1A, CMT2B1, EMD2, FPL,</cell></row><row><cell></cell><cell>FPLD, FPLD2, HGPS, IDC, LDP1, LFP, LGMD1B,</cell></row><row><cell></cell><cell>LMN1, LMNC, LMNL1, MADA, PRO1</cell></row><row><cell>Hyponyms</cell><cell>lamin, 70 kDa lamin, epididymis secretory sperm binding</cell></row></table><note coords="2,223.85,588.12,250.64,9.94;2,226.85,603.72,244.73,9.94"><p>protein, lamin A/C-like 1, mandibuloacral dysplasia type A, prelamin-A/C, renal carcinoma antigen NY-REN-32</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,138.38,283.57,310.49,59.04"><head>Table 3 :</head><label>3</label><figDesc>The number of samples generated by two tasks</figDesc><table coords="4,138.38,299.65,310.49,42.96"><row><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>Scientific Abstracts</cell><cell>37,361</cell><cell>4,025</cell><cell>80,000</cell></row><row><cell>Clinical Trials</cell><cell>24,810</cell><cell>2,397</cell><cell>80,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,129.14,570.51,345.12,123.03"><head>Table 4 :</head><label>4</label><figDesc>The differences of five runs for Scientific Abstracts</figDesc><table coords="4,129.14,586.62,345.12,106.92"><row><cell></cell><cell>Re-ranking</cell><cell>Topic Expansion</cell><cell>The number of re-</cell></row><row><cell></cell><cell>model</cell><cell></cell><cell>ranking document</cell></row><row><cell>ccnl_sa1</cell><cell>Yes</cell><cell>All expansion</cell><cell>80,000</cell></row><row><cell>ccnl_sa2</cell><cell>Yes</cell><cell>All expansion</cell><cell>160,000</cell></row><row><cell>ccnl_sa3</cell><cell>Yes</cell><cell>Only Synonyms</cell><cell>80,000</cell></row><row><cell>ccnl_sa4</cell><cell>Yes</cell><cell>No expansion</cell><cell>80,000</cell></row><row><cell>ccnl_sa5</cell><cell>No</cell><cell>No expansion</cell><cell>80,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,159.74,258.37,286.72,183.74"><head>Table 6</head><label>6</label><figDesc></figDesc><table coords="5,163.34,258.37,283.12,183.74"><row><cell cols="4">: The evaluation of five runs for Scientific Abstracts</cell></row><row><cell></cell><cell>infNDCG</cell><cell>P@10</cell><cell>R-prec</cell></row><row><cell>ccnl_sa1</cell><cell>0.5309</cell><cell>0.6450</cell><cell>0.3032</cell></row><row><cell>ccnl_sa2</cell><cell>0.5222</cell><cell>0.6500</cell><cell>0.3066</cell></row><row><cell>ccnl_sa3</cell><cell>0.4569</cell><cell>0.5475</cell><cell>0.2858</cell></row><row><cell>ccnl_sa4</cell><cell>0.4571</cell><cell>0.5775</cell><cell>0.2886</cell></row><row><cell>ccnl_sa5</cell><cell>0.4463</cell><cell>0.5025</cell><cell>0.2770</cell></row><row><cell cols="4">Table 7: The evaluation of two runs for Clinical Trials</cell></row><row><cell></cell><cell>infNDCG</cell><cell>P@10</cell><cell>R-prec</cell></row><row><cell>ccnl_trials1</cell><cell>0.4862</cell><cell>0.5947</cell><cell>0.3414</cell></row><row><cell>ccnl_trials2</cell><cell>0.4845</cell><cell>0.5789</cell><cell>0.3440</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,97.94,734.76,107.58,9.94"><p>https://www.lexigram.io</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,97.94,747.36,201.05,9.94;2,90.02,759.98,204.61,9.94"><p>ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE INFO/Mammalia/Homo_sapiens.gene_info.gz</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.56,642.42,399.79,10.80;5,122.06,658.02,383.27,10.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,319.51,642.42,185.84,10.80;5,122.06,658.02,73.67,10.80">Overview of the TREC 2017 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,216.13,658.02,283.91,10.80">Proceedings of the Twenty-Sixth Text Retrieval Conference</title>
		<meeting>the Twenty-Sixth Text Retrieval Conference</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.56,673.62,399.76,10.80;5,122.06,689.22,383.25,10.80;5,122.06,704.82,58.18,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,319.48,673.62,185.84,10.80;5,122.06,689.22,79.54,10.80">Overview of the TREC 2018 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,233.85,689.22,271.45,10.80;5,122.06,704.82,52.89,10.80">Proceedings of the Twenty-Seventh Text Retrieval Conference</title>
		<meeting>the Twenty-Seventh Text Retrieval Conference</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.56,720.42,399.82,10.80;5,122.06,736.02,383.36,10.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,284.44,720.42,220.94,10.80;5,122.06,736.02,25.70,10.80">HPI-DHC at TREC 2018: Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oleynik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Faessler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
		<idno>TREC 2018</idno>
	</analytic>
	<monogr>
		<title level="m" coord="5,168.85,736.02,267.62,10.80">Proc. of the Twenty-Seventh Text REtrieval Conference</title>
		<meeting>of the Twenty-Seventh Text REtrieval Conference</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.56,75.92,399.78,10.80;6,122.06,91.54,383.21,10.80;6,122.06,107.14,72.34,10.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,279.39,91.54,75.03,10.80">Okapi at trec-3</title>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Stephen E Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,364.14,91.54,135.90,10.80">Nist Special Publication Sp</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page">109</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.56,122.74,399.84,10.80;6,122.06,138.34,217.94,10.80" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Scibert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10676</idno>
		<title level="m" coord="6,298.86,122.74,206.55,10.80;6,122.06,138.34,16.80,10.80">A Pretrained Language Model for scientific text</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,105.56,153.94,399.90,10.80;6,122.06,169.54,338.16,10.80" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,308.98,153.94,196.48,10.80;6,122.06,169.54,202.82,10.80">Why self-attention? a targeted evaluation of neural machine translation architectures</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Annette</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,345.57,169.54,77.38,10.80">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
