<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,82.50,84.23,447.46,15.44">Query and Answer Expansion from Conversation History</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.46,124.44,86.40,11.96"><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.45,124.44,82.26,11.96"><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,395.31,124.44,51.16,11.96;1,446.47,122.90,2.19,7.50"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">David R. Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">David R. Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.50,138.53,76.27,11.96;1,286.77,137.00,2.19,7.50"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.55,138.53,78.25,11.96"><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.15,400.63,20.24,7.97;1,53.80,409.34,33.92,9.23"><forename type="first">Ming- Feng</forename><surname>Tsai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,82.50,84.23,447.46,15.44">Query and Answer Expansion from Conversation History</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8EDAAB148238E8E7B99DCE2B6F12B034</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present our methods, experimental analysis, and final submissions for the Conversational Assistance Track (CAsT) at TREC 2019. In addition to language understanding, extracting knowledge from historical dialogues (e.g., previous queries, searching results) is a key to the conversational IR task. However, limited annotated data in the CAsT task makes machine learning or other data-driven approaches infeasible. Along this line, we propose two ad hoc and intuitive approaches: Historical Query Expansion and Historical Answer Expansion, to improve the performance of the conversational IR system with limited training data. Our empirical result on the CAsT training set shows that the proposed methods significantly improve the quality of conversational search in terms of retrieval (recall@1000: 0.774 → 0.844) and ranking (mAP: 0.187 → 0.197) compared to our strong baseline. As a result, our submitted entries outperform the median performance of all the 21 teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>we propose to extract key words from historical queries to expand current query for subsequent search tasks.</p><p>Suppose we have a set of documents d j ∈ D and a session S with N turns of conversational queries, S = {Q i } N i=1 . Each query Q i has n(i) tokens, represented as a tuple (q i 0 , q i 1 , . . . , q i n(i) ). Algorithm 1 details our historical query expansion method: keyword extraction (line 3 -8) and expansion (line 9 -13). Here F represents the BM25 score function between the document d i and the query Q i ; r Q (r S ) is the hyperparameter to judge whether a word is a key word related to current query (session, respectively); θ is the hyperparameter to judge whether a query is specific enough; W Q (W S ) is the query (session, respectively) keyword list extracted from historical queries.</p><p>Intuitively, we assume that a precise query includes keywords specifying the topic of the session and the query itself. For example, as shown in Figure <ref type="figure" coords="1,391.28,511.11,3.13,8.97" target="#fig_0">1</ref>, the topic of the session is related to "Nursing and Physician's Assistant, " which is specified by Turn1. Turn2 and Turn3 only have keywords related to each query and are still ambiguous. Specifically, Turn2 is related to "educational requirements" but not specific enough without the session keywords while Turn3 is more ambiguous and needs to be clarified by adding both "Physician's Assistant" and "education requirement", the session and historical query keywords respectively. This reflects our design (line 9-13 in Algorithm 1) that adding session keywords to all the queries except for the first one and further clarifying the ambiguous queries by adding query keywords from their last three queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Historical Answer Expansion</head><p>This work proposes to facilitate the pretrained passage re-ranking BERT model to solve the issues regarding data sparsity and transfer the gap between conversational QA tasks and conversationalinformation-seeking (CIS) problem. Incorporating historical answers in conversational QA tasks had been proposed to expand the Algorithm 1: Historical Query Expansion</p><formula xml:id="formula_0" coords="2,53.59,101.55,217.69,201.20">Input: S = { Q i } N i =1 , D Output: S 1 W S ← (); W Q ← () 2 for i = 1 to N do 3 for k = 1 to n(i) do 4 r i k = max d j ∈D F(d j , (q i k )) 5 if r i k &gt; r S then 6 W S .insert(q i k ) 7 if r i k &gt; r Q then 8 W Q .insert(q i k ) 9 if i &gt; 1 then 10 R i = max d j ∈D F(d j , Q i ) = max d j ∈D F(d j , (q i 0 , q i 1 , • • •, q i n(i ) )) 11 Q i .insert(q n k ) for all q n k ∈ W S 12 if R i &lt; θ then 13 Q i .insert(q n k ) for all q n k ∈ W Q ∧ n ≥ i -3 14 return S</formula><p>answers in each turn <ref type="bibr" coords="2,131.52,335.05,9.31,8.97" target="#b7">[8]</ref>. In the previous work, inserting historical answers with additional tokens into query-answer pairs makes the proposed method fuse with the state-of-the-art BERT model and its variants easily <ref type="bibr" coords="2,138.99,367.93,7.45,8.97" target="#b2">[3]</ref><ref type="bibr" coords="2,146.44,367.93,3.72,8.97" target="#b3">[4]</ref><ref type="bibr" coords="2,150.16,367.93,7.45,8.97" target="#b4">[5]</ref><ref type="bibr" coords="2,160.33,367.93,10.21,8.97" target="#b10">11]</ref>. However, the data sparsity and unique CIS setting in the CAsT make training complicated models infeasible, neither directly training a conversational QA model (e.g., BERT with historical answer embedding <ref type="bibr" coords="2,219.39,400.81,9.78,8.97" target="#b7">[8]</ref>) on CAsT dataset nor jointly training with other conversational QA tasks that focus on finding fine-grained answer span within passages. Hence, the historical answer expansion (HAE) is proposed to solve the issues mentioned above. Specifically, we use a pretrained BERT model, which is trained for passage re-ranking on MS MARCO dataset <ref type="bibr" coords="2,282.67,455.60,9.27,8.97" target="#b5">[6]</ref>, to estimate query-passage log-likelihood scores and directly mix the scores from the current i-th turn and the previous (i -l)-th turns. The negative log-likelihood scores from previous turns are multiplied by a constant factor λ, which serves as a decay factor to lower the weight of historical answers. In this work, we only consider the pairs from previous one turn (l = 1):</p><formula xml:id="formula_1" coords="2,220.85,521.36,46.12,9.78">(Q i-1 , D i-1 )</formula><p>, where</p><formula xml:id="formula_2" coords="2,53.98,530.86,42.11,13.42">D i = d j k</formula><p>j=1 stands for the top-k passages of each i-th turn. The final candidate list for each conversational turn is the re-ranked list cut off at top-k (k = 1000 in our experiments) passages according to the mixed negative log-likelihood scores of query-passages pairs:</p><formula xml:id="formula_3" coords="2,53.80,579.44,88.78,9.78">((Q i , D i ), (Q i-1 , D i-1 )).</formula><p>We further illustrate the idea of HAE in Algorithm 2. In HAE, we define a collection of our query-passage pairs:</p><formula xml:id="formula_4" coords="2,224.27,600.05,64.30,11.72">A = {(Q i , D i )} N</formula><p>i=1 . Our goal is to insert the passage candidates D i for each query Q i from its previous previous passage candidates D i-1 . A hyperparameter λ is introduced to modify the log-likelihood L i j from the pretrained BERT model for each pair of (Q i , d i j ), where d i j ∈ D i ; j = 1, 2, . . . , k. Besides, we keep d i j for the corresponding i-th turn but drop d (i-1)j , if d (i-1)j is a duplicated passage from the previous (i -1)-th turn. Note that the HAE method only involves λ tuning, which is not only a "training"-free method but can be easily integrated with HQE or other query expansion techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: Historical Answer Expansion</head><formula xml:id="formula_5" coords="2,317.75,101.55,159.21,168.28">Input: A = {(Q i , D i )} N i =1 , λ Output: A 1 Initialize P[N][k ]; P t emp [k] 2 for i = 1 to N do 3 for j = 1 to k do 4 Estimate log-likelihood: L i j (Q i , d i j ) 5 P[i][j] ← (d i j , L i j ) 6 for i = 1 to N do 7 Append P t emp with P[i] 8 Sort P t emp by L 9 for j = 1 to k do 10 n i j = d i j ∈ P t emp [j] 11 Update D i with n j k j =1 12 for j = 1 to k do 13 P t emp [j] ← (d i j , λ • L i j ) ∈ P[i][j]</formula><p>14 return A    of relevance to queries are provided for 120 turns among the 269 turns. The judgements are graded with three levels (2 for very relevant, 1 for relevant, and 0 for not relevant). For simplicity, in our experiments, we consider the query-passage pairs with the grade higher than 0 as positive and remove all the pairs graded 0, resulting in 108 turns with 640 positive pairs in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">EMPIRICAL ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation and Settings</head><p>We use the CAsT training set to evaluate model performance in terms of recall (R@1000), mean average precision (mAP) and mean reciprocal rank (mRR@10). At the stage of document retrieval, we use the Anserini toolkit <ref type="bibr" coords="3,146.81,521.15,14.85,8.97" target="#b9">[10]</ref> to index and retrieve the top-1000 relevant passages for each query with BM25 plus fine-tuned RM3.</p><p>As for reranking, we use the BERT-Large model fine tuned on the MS MARCO dataset <ref type="bibr" coords="3,126.94,554.03,9.27,8.97" target="#b5">[6]</ref>, the queries of which are similar to the ones in CAsT, as our reranker.</p><p>As shown in Table <ref type="table" coords="3,134.55,575.94,3.11,8.97" target="#tab_0">1</ref>, in order to find the optimal condition for CAsT, we try different methods to rewrite input queries at both the stages of document retrieval and reranking. The three methods are described as follows:</p><p>• Title: adding the title of the current session to the input query • Historical Query Expansion (HQExp): an automatic keyword expansion method proposed in Section 1.1. • Coreference: the manually annotated queries with coreference resolution provided by the organizer. In addition, for each condition, we also perform our proposed Historical Answer Expansion (HAExp) described in Section 1.2. Note that since the annotated queries are provided only for the first two sessions in the training set, we conduct another experiment on the training subset to see the effect of coreference resolution, the results of which are shown in Table <ref type="table" coords="3,450.59,271.84,3.07,8.97" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Quantitative Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Results on</head><p>CAsT training set. The results using queries' raw texts with different kinds of query expansion techniques are shown in Table <ref type="table" coords="3,351.97,336.54,3.13,8.97" target="#tab_0">1</ref>. An observation from the table, the ad-hoc methods perform well both in recall and ranking metrics. The proposed HQExp method boosts mAP and mRR@10 by 3.7% and 3.3%, by comparing with conditions: 1 and 2, respectively. In addition, with the HQExp method involved in the retrieval stage, the proposed method further gains 5.7% in R@1000 by comparing conditions: 1 and 4. The combination that involves the HQExp method both in retrieval and re-ranking stage -condition 5 -does not win over the method that HQExp only involved in re-ranking stagecondition 2. However, the ranking metrics: mAP and mRR@10, still follows an increasing trend, comparing the pair of condition 1 and 2 (and the other one, condition 4 and 5, respectively).</p><p>As for the proposed post-processing HAExp method, it also performs well. HAExp method boosts the recall metric from all conditions (1, 2, 4, and 5) and both ranking metrics by 2.1% and 2.6% in mAP (4.3% and 4.9% in mRR@10), comparing condition 4 and 5. Albeit the HAExp method does not seems to make a positive impact on the ranking metrics with only title query expansion scenario (conditions: 1 and 2), the combination of HQExp plus HAExp has the best entry on CAsT training set in terms of R@1000 and mAP.</p><p>We experiment to check the effectiveness of coreference in passage re-ranking as records shown in Table <ref type="table" coords="3,480.01,566.68,3.13,8.97" target="#tab_1">2</ref>. Observed from Table 2, not surprisingly, the result of the coreference resolved queries achieves the best performance. Among other query expansion techniques, the coreference resolved query has the best ranking metrics: 0.392 in terms of mAP and 0.525 in terms of mRR@10. It seems that the positive impact of the proposed methods in full training set disappears in the annotated subset, albeit the HAExp method still boosts R@1000. However, the amount of data may be too few for us to judge the effectiveness of the combination of HQExp, HAExp, and the coreference resolved queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.3</head><p>.2 Systems submitted to TREC. We submitted a total of eight runs for CAsT this year with the techniques we mentioned in the previous section. In addition, we further consider two baselines described as follows:</p><p>• MARCO: a baseline that only conducts inverted indexing and retrieves paragraphs from the collections of the MS MARCO dataset only. • Document2Query (D2Q): a query expansion method that expands a paragraph with its relevant queries <ref type="bibr" coords="4,253.72,156.34,9.52,8.97" target="#b6">[7]</ref>. Which model is trained on the MS MARCO dataset, and we only use the model to expand the paragraphs in the MS MARCO collections before inverted indexing.</p><p>The results of the evaluation are demonstrated in Table <ref type="table" coords="4,271.17,203.84,3.12,8.97" target="#tab_2">3</ref>. The columns indicated the conditions of our final submissions regarding the proposed ad-hoc methods and the two baselines mentioned above. Comparing to the statistics of total the 21 teams' submission provided by TREC, it appears that the simplest baseline, which only uses inverted indexing and BERT re-ranker with MS MARCO corpus, outperforms 50% of submissions. We observed an interesting phenomenon among our submissions; the most straightforward method takes all. With coreference resolution involved in both document retrieval and re-ranking stages, the best entry is CFDA_CLIP_Run6, which scores 0.812 in R@1000, 0.395 in mAP, 0.101 in mAP@5, and 0.576 in NDCG@5. Without involving coreference resolution in the retrieval stage, the full combination of HQExp and HAExp with coreference resolved queries performs worse than the best run. However, which combination still deliver the best performance among other baselines. The effectiveness of the proposed methods needs a detail examination since the data distribution could be different from the training set. To be more specific, the difference comes from the issue that the WAPO collection is removed from the evaluation set due to its problem in removing duplicated paragraph.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,317.96,288.98,240.24,7.70;1,317.96,299.94,240.50,7.70;1,317.96,310.90,50.52,7.70"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: CAsT example. Bold and underlying words denote the keywords specifying the topic of the session and query respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,317.96,689.66,240.25,8.97;2,317.96,700.62,240.25,8.97"><head>Figure 2</head><label>2</label><figDesc>Figure 2 shows the statistics of CAsT training set, including 30 sessions with 269 turns in total. Passages with graded judgements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,97.67,370.74,152.51,7.70"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: CAsT training data statistics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,322.94,336.42,235.26,140.81"><head>Table 1 :</head><label>1</label><figDesc>Performance comparison on CAsT training set</figDesc><table coords="2,322.94,361.54,235.26,115.69"><row><cell>Condition</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>Retrieval</cell><cell>Title</cell><cell>Title</cell><cell cols="4">Title HQexp HQexp HQexp</cell></row><row><cell cols="3">Re-ranking Title HQExp</cell><cell>Coref</cell><cell cols="2">Title HQExp</cell><cell>Coref</cell></row><row><cell>R@1000</cell><cell>0.774</cell><cell>0.774</cell><cell></cell><cell>0.818</cell><cell>0.818</cell><cell></cell></row><row><cell>mAP</cell><cell>0.187</cell><cell>0.194</cell><cell>-</cell><cell>0.189</cell><cell>0.192</cell><cell>-</cell></row><row><cell>mRR@10</cell><cell>0.273</cell><cell>0.282</cell><cell></cell><cell>0.257</cell><cell>0.264</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>+HAExp</cell><cell></cell><cell></cell><cell></cell></row><row><cell>R@1000</cell><cell>0.790</cell><cell>0.790</cell><cell></cell><cell>0.844</cell><cell>0.844</cell><cell></cell></row><row><cell>mAP</cell><cell>0.187</cell><cell>0.192</cell><cell>-</cell><cell>0.193</cell><cell>0.197</cell><cell>-</cell></row><row><cell>mRR@10</cell><cell>0.273</cell><cell>0.279</cell><cell></cell><cell>0.268</cell><cell>0.277</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,317.96,505.92,240.25,179.29"><head>Table 2 :</head><label>2</label><figDesc>Co-reference effect on CAsT training subset</figDesc><table coords="2,317.96,531.03,240.25,154.18"><row><cell>Condition</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>Retrieval</cell><cell>Title</cell><cell>Title</cell><cell cols="4">Title HQexp HQexp HQexp</cell></row><row><cell cols="3">Re-ranking Title HQExp</cell><cell>Coref</cell><cell cols="2">Title HQExp</cell><cell>Coref</cell></row><row><cell>R@1000</cell><cell>0.897</cell><cell>0.897</cell><cell>0.897</cell><cell>0.859</cell><cell>0.859</cell><cell>0.859</cell></row><row><cell>mAP</cell><cell>0.258</cell><cell>0.291</cell><cell>0.392</cell><cell>0.261</cell><cell>0.274</cell><cell>0.374</cell></row><row><cell>mRR@10</cell><cell>0.358</cell><cell>0.442</cell><cell>0.525</cell><cell>0.377</cell><cell>0.433</cell><cell>0.544</cell></row><row><cell></cell><cell></cell><cell></cell><cell>+HAExp</cell><cell></cell><cell></cell><cell></cell></row><row><cell>R@1000</cell><cell>0.910</cell><cell>0.910</cell><cell>0.910</cell><cell>0.863</cell><cell>0.863</cell><cell>0.863</cell></row><row><cell>mAP</cell><cell>0.257</cell><cell>0.285</cell><cell>0.388</cell><cell>0.261</cell><cell>0.272</cell><cell>0.371</cell></row><row><cell>mRR@10</cell><cell>0.358</cell><cell>0.440</cell><cell>0.524</cell><cell>0.377</cell><cell>0.431</cell><cell>0.520</cell></row><row><cell cols="5">2.1 Datasets and Preprocessing</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,58.78,85.73,499.42,264.79"><head>Table 3 :</head><label>3</label><figDesc>Overall performance of submitted runs on CAsT evaluation set</figDesc><table coords="3,58.78,110.84,499.42,239.67"><row><cell cols="3">Team Run Entry</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">median</cell><cell></cell><cell cols="6">CFDA_CLIP 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">h2oloo 2</cell><cell></cell><cell></cell><cell></cell><cell cols="2">h2oloo 3</cell><cell>h2oloo 4</cell><cell>h2oloo CFDA_CLIP CFDA_CLIP CFDA_CLIP 5 6 7 8</cell></row><row><cell cols="6">Indexed corpus</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">MARCO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">CAsT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CAsT</cell><cell>CAsT</cell><cell>CAsT</cell><cell>CAsT</cell><cell>CAsT+D2Q</cell><cell>CAsT+D2Q</cell></row><row><cell cols="3">Retrieval</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Title</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Title</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Title</cell><cell>Title+RM3</cell><cell>HQExp</cell><cell>Coref+RM3</cell><cell>Title</cell><cell>HQExp</cell></row><row><cell cols="4">Re-ranking</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Coref</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">HQExp</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Coref</cell><cell>Coref</cell><cell>Coref</cell><cell>Coref</cell><cell>HQExp</cell><cell>Coref</cell></row><row><cell cols="3">+HAExp</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell></row><row><cell cols="2">R@1000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.412</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.632</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.632</cell><cell>0.639</cell><cell>0.689</cell><cell>0.812</cell><cell>0.611</cell><cell>0.695</cell></row><row><cell>mAP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.174</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.226</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.274</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.324</cell><cell>0.321</cell><cell>0.354</cell><cell>0.395</cell><cell>0.269</cell><cell>0.363</cell></row><row><cell cols="2">mAP@5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.042</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.071</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.066</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.082</cell><cell>0.081</cell><cell>0.096</cell><cell>0.101</cell><cell>0.068</cell><cell>0.099</cell></row><row><cell cols="3">NDCG@5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.296</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.459</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.427</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.530</cell><cell>0.532</cell><cell>0.564</cell><cell>0.576</cell><cell>0.427</cell><cell>0.568</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Total Turn</cell><cell></cell><cell cols="4">With Positive</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>12</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Turn number</cell><cell>4 6 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>14</cell><cell>15</cell><cell>16</cell><cell>17</cell><cell>18</cell><cell>19</cell><cell>20</cell><cell>21</cell><cell>22</cell><cell>23</cell><cell>24</cell><cell>25</cell><cell>26</cell><cell>27</cell><cell>28</cell><cell>29</cell><cell>30</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Session</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>Especially thanks to <rs type="person">Jimmy Lin</rs> for the instructions and ideas.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="4,69.23,494.89,224.81,6.97;4,68.90,502.86,225.14,6.97;4,69.23,511.46,225.88,6.23;4,68.99,518.80,121.86,6.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,270.50,494.89,23.54,6.97;4,68.90,502.86,129.34,6.97">Reading Wikipedia to Answer Open-Domain Questions</title>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,210.34,503.49,83.70,6.23;4,69.23,511.46,156.44,6.23">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers). Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,69.23,526.77,224.99,6.97;4,69.23,534.74,224.81,6.97;4,69.23,542.71,90.96,6.97" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07036</idno>
		<title level="m" coord="4,170.22,534.74,103.21,6.97">Quac: Question answering in context</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,69.23,550.68,225.64,6.97;4,69.23,558.65,225.89,6.97;4,69.23,566.63,108.33,6.97" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,277.34,550.68,17.53,6.97;4,69.23,558.65,222.70,6.97">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,69.23,574.60,224.81,6.97;4,69.23,582.57,224.81,6.97;4,69.23,590.54,221.97,6.97" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,169.74,582.57,124.30,6.97;4,69.23,590.54,108.24,6.97">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</title>
		<author>
			<persName coords=""><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,69.23,598.51,224.94,6.97;4,69.23,606.48,225.06,6.97;4,69.23,614.45,224.81,6.97;4,69.03,622.42,18.66,6.97" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="4,263.00,606.48,31.29,6.97;4,69.23,614.45,129.68,6.97">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,69.23,630.39,225.88,6.97;4,69.23,638.36,108.33,6.97" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="4,203.72,630.39,87.86,6.97">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,69.23,646.33,224.81,6.97;4,69.23,654.30,201.70,6.97" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08375</idno>
		<title level="m" coord="4,264.53,646.33,29.51,6.97;4,69.23,654.30,88.06,6.97">Document Expansion by Query Prediction</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,69.23,662.27,224.81,6.97;4,69.23,670.24,224.81,6.97;4,68.49,678.83,9.60,6.23" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,262.24,662.27,31.80,6.97;4,69.23,670.24,196.24,6.97">BERT with History Answer Embedding for Conversational Question Answering</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,278.25,670.86,15.79,6.23;4,68.49,678.83,7.20,6.23">SIGIR &apos;19</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,69.23,686.18,225.99,6.97;4,69.23,694.15,225.51,6.97;4,69.23,702.12,105.17,6.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,242.62,686.18,52.60,6.97;4,69.23,694.15,101.31,6.97">Coqa: A conversational question answering challenge</title>
		<author>
			<persName coords=""><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,175.91,694.77,118.84,6.23;4,69.23,702.74,53.06,6.23">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,88.42,224.81,6.97;4,333.39,96.39,224.97,6.97;4,333.18,104.36,28.42,6.97" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,466.36,88.42,91.84,6.97;4,333.39,96.39,65.27,6.97">Anserini: Reproducible ranking baselines using Lucene</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,405.19,97.02,137.59,6.23">Journal of Data and Information Quality (JDIQ)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,333.39,112.33,225.58,6.97;4,333.39,120.30,225.99,6.97;4,333.39,128.27,173.64,6.97" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<title level="m" coord="4,397.18,120.30,162.20,6.97;4,333.39,128.27,59.34,6.97">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
