<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.13,115.96,345.10,12.62;1,287.90,133.89,39.56,12.62">UMass at TREC 2019 Conversational Assistance Track</title>
				<funder ref="#_9YNDYmm">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.76,171.56,63.15,8.74"><forename type="first">Helia</forename><surname>Hashemi</surname></persName>
							<email>hhashemi@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval College of information and Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst Amherst</orgName>
								<address>
									<postCode>01003</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.60,171.56,68.00,8.74"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
							<email>croft@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval College of information and Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst Amherst</orgName>
								<address>
									<postCode>01003</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.13,115.96,345.10,12.62;1,287.90,133.89,39.56,12.62">UMass at TREC 2019 Conversational Assistance Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">309A9A973EBD3783C25356D8640AC002</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is an overview of University of Massachusetts efforts in providing passage retrieval run submissions for the TREC 2019 Conversational Assistance Track (CAsT). We adopted recent neural approaches for the task. The goal is to retrieve passages that are different from what traditional methods retrieve, in order to enrich the candidates pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>We formalize the TREC CAsT problem as follows. We are given an information seeking conversation dataset</p><formula xml:id="formula_0" coords="1,134.77,411.47,360.95,25.86">D = {(U i , R i , Y i )} N i=1 , where U i = {u 1 i , u 2 i , • • •, u t-1 i , u t i } in which {u 1 i , u 2 i , • • •, u t-1 i</formula><p>} is the dialog context and u t i is the input utterance in the t-th turn. R i and Y i are a set of response candidates</p><formula xml:id="formula_1" coords="1,398.70,436.97,78.62,15.20">{r 1 i , r 2 i , • • •, r k i } M k=1</formula><p>, and the corresponding binary labels {y 1 i , y 2 i , • • •, y k i }, where y k i = 1 means r k i is a relevant response to U i . For any given U i , the goal is to learn a ranking model f (•) to retrieve relevant responses.</p><p>In our submissions, the candidate responses and dialog contexts are modeled by a deep neural matching network. We used the approach recently proposed by Yang et al. <ref type="bibr" coords="1,203.87,512.66,10.52,8.74" target="#b4">[5]</ref> in our submissions. Given a candidate response r k and an utterance u t i in the context U i , the model firstly looks up a global embedding dictionary to represent r k and u t i as two sequences of embedding vectors</p><formula xml:id="formula_2" coords="1,134.77,534.99,345.83,24.28">E(r k i ) = [e r,1 , e r,2 , •••, e r,lr ] and E(u t i ) = [e u,1 , e u,2 , •••, e u,lu ]</formula><p>, where e r,i ∈ R d and e u,i ∈ R d are the embedding vectors of the i -th word in r k i and u t i , respectively. Here, we adopt an interaction-focused method to learn the matching patterns. Specifically, with E(r k i ) ∈ R d×lr and E(u t i ) ∈ R d×lu , we build two interaction matrices M 1 and M 2 , such that M 1 is a word pairwise similarity matrix and M 2 is a sequence hidden representation similarity matrix. Later, these two matrices will be the two input channels of a convolutional neural network (CNN) to learn important matching features.</p><p>To be more precise, M 1 models the word pairwise similarity between r k i and u t i via the dot product similarity between the embedding representations. On the other hand, for making the matrix M 2 , we use BiGRU <ref type="bibr" coords="2,376.79,118.99,10.52,8.74" target="#b0">[1]</ref> to obtain the hidden representation of the whole text for both u t i and r k i . Each cell of M 2 will be the similarity of different parts of these two hidden representation.</p><p>These matrices are fed to a CNN followed by max pooling, and then a BiGRU layer to model the dependency and temporal relationship of utterances in the conversation according the previous works <ref type="bibr" coords="2,318.75,178.77,9.96,8.74" target="#b3">[4]</ref>. We finally concatenate the output hidden states, and feed the learned representation to a multi-layer perceptron (MLP) network to generate the matching score.</p><p>We train the model in the pairwise setting, and for loss function we use a pairwise hinge loss. The parameters of the deep matching network are optimized using back-propagation with Adam optimizer <ref type="bibr" coords="2,336.07,238.55,9.96,8.74" target="#b1">[2]</ref>.</p><p>For more information on the model design, refer to <ref type="bibr" coords="2,375.58,250.50,9.96,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>We used the TREC-CAsT Tools for processing and parsing all the collections, including MS MARCO Passage Ranking collection, TREC CAR paragraph collection v2.0, and TREC Washington Post Corpus version 2. We also cleaned the collection text by omitting HTML tags. We train our model on MS MARCO Conversational Search Sessions. Each session starts with one utterance at the beginning, then, as the conversation goes further the conversation history increases. MS MARCO Conversational Search Session data has single turn relevance judgement annotation. We use these judgements as weak labels, since it enables us to train the model on large amount of the data provided by Microsoft. Therefore, the label of each passage for any sequence of utterances depends on label of that passage for the last utterance. By doing so, we were able to train our model on 1091553 instances. For negative samples of the training set, we use, on average, the top 10 retrieved passages provided in the MS MARCO collection.</p><p>The maximum length of utterances and each responses was set to 90 and 150, respectively. The initial learning rate was set to 0.001. The parameters of Adam, β 1 and β 2 were set to 0.9 and 0.999, respectively. The dropout rate is 0.6. We set the window size of the convolution and pooling kernels as <ref type="bibr" coords="2,457.35,503.64,11.62,8.74" target="#b2">(3,</ref><ref type="bibr" coords="2,468.97,503.64,7.75,8.74" target="#b2">3)</ref>. The number of convolution kernels was 2. The dimension of the hidden states of BiGRU layer was set to 100. The maximum conversation context length was 13. We padded short contexts with zero. For the pre-trained embeddings used in our experiments, we picked the vectors learned by the Word2Vec tool <ref type="bibr" coords="2,447.79,551.46,10.52,8.74" target="#b2">[3]</ref> with the Skip-gram model. The max skip length between words and the number of negative examples is set as 5 and 10, respectively. The dimension of word vectors is 200. Word embeddings are updated during the training process.</p><p>UMass Submissions: Finally, we re-rank the top 300 passages retrieved by the Query Likelihood model using Indri. We used the Indri runs provided by the track organizers. For co-reference resolution, the AllenNLP toolkit was used. Stopwords were removed using the Indri stopword list. Two different runs were submitted to the TREC CAsT track this year, which are as follows:</p><p>-The first run is a result list of the described model computed based on the original file of the Evaluation topics year 1 V1.0. -The Second run is a result list of the described model computed based on the Resolved Topic Annotations.</p></div>		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4">Acknowledgements</head><p>We would like to thank <rs type="person">Liu Yang</rs> for open-sourcing the deep matching model [5] and for his invaluable comments on the model. This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs> and in part by <rs type="funder">NSF</rs> <rs type="grantNumber">IIS-1715095</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9YNDYmm">
					<idno type="grant-number">IIS-1715095</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,138.35,325.90,342.24,7.86;3,146.91,336.86,213.65,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,325.90,325.90,154.68,7.86;3,146.91,336.86,152.73,7.86">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">̧</forename><surname>Gu ̈lçehre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,347.82,338.90,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="3,237.27,347.82,179.31,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,358.78,342.25,7.86;3,146.91,369.74,294.06,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,395.31,358.78,85.28,7.86;3,146.91,369.74,222.60,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,390.68,369.74,21.63,7.86">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,380.70,342.24,7.86;3,146.91,391.65,299.63,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="3,291.90,380.70,188.69,7.86;3,146.91,391.65,238.96,7.86">Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,402.61,342.25,7.86;3,146.91,413.57,333.67,7.86;3,146.91,424.53,175.38,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="3,466.64,402.61,13.95,7.86;3,146.91,413.57,333.67,7.86;3,146.91,424.53,114.60,7.86">Response ranking with deep matching networks and external knowledge in informationseeking conversation systems</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
