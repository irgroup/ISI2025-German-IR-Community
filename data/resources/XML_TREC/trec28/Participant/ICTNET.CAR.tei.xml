<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.60,71.15,363.41,15.08">ICTNET at TREC 2019 Complex Answer Retrieval Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,48.96,113.10,61.22,11.49"><forename type="first">Hongfei</forename><surname>Ren</surname></persName>
							<email>renhongfei18s@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,128.76,113.10,62.42,11.49"><forename type="first">Ruibin</forename><surname>Xiong</surname></persName>
							<email>xiongruibin18s@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.36,113.10,56.90,11.49"><forename type="first">Yutao</forename><surname>Zeng</surname></persName>
							<email>zengyutao18s@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.44,113.10,64.22,11.49"><forename type="first">Jiangui</forename><surname>Chen</surname></persName>
							<email>chenjiangui18z@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,369.84,113.10,62.33,11.49"><forename type="first">Yinqiong</forename><surname>Cai</surname></persName>
							<email>caiyinqiong18s@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,451.32,113.10,74.06,11.49"><forename type="first">Haoquan</forename><surname>Jiang</surname></persName>
							<email>jianghaoquan18g@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.60,71.15,363.41,15.08">ICTNET at TREC 2019 Complex Answer Retrieval Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">05FB869A30421F0AD0DB56B940748501</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 Model Description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>We participate in the Complex Answer Retrieval(CAR) track at TREC 2019. We applied several useful models in this work. In the rough ranking, we applied doc2query model to predict queries and retrieve using BM25. In the re-ranking, we submitted 5 different runs which use 5 different models, include BM25, DRMMTKS, Bert-DRMMTKS, Bert-ConvKNRM and Bert-ConvKNRM-50, to try to get the best result.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="841.9"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="841.9"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="841.9"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of the TREC 2019 Complex Answer Retrieval is decribed as following: given a outline of a page (may be the title or hierarchical section headings), then we retrieve a ranking paragraphs for each section so that we can give a smooth passage. The complex query have many aspects, so we should give all related paragraph. For exam-ple, when we give a query 'Effects of Water Pol-lution', we should give the paragraph about fertil-izers, ocean acidification, and aquatic debris and the effects. In terms of dataset, it is based on the assumption that each Wikipedia page represents a complex topic, with further details under each sections. Over time, many different types of retrieval models have been proposed and tested. For rough sort, We have read many retrieval model, such as BM25-like method and the recently proposed language modeling approach. But the "vocabulary mismatch" problem has not been solved very well. So we used doc2query model. For precise sort,we hope to find the best model to solve this problem, so we used 4 model which are bert+convknrm, bert+drmmtks, bm25, drmmtks and gave 5 runs.</p><p>In regard to rough sort, we used the doc2query model to predict the 5 most likely queries. we concate the predicted queries and the paragraph so that we can raise the recall. In the respect of precise sort, there are several different attempts. We give 5 runs which used different models. We want to select a best model from them. The first run used only bert, the second run used drmmts, the third run used bert+drmmtks, the forth run used bert+convknrm, the fifth run is a contradistinction to forth one. The last run set the return number of paragraphs of a section to 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Rough Ranking</head><p>For each document, our task is to predict several queries and then concate them. We use a Transformer model to produce the queries. For the optimizer, we choose Adam. The input is documents and target queries. The document and target query are tokenized with tokenizer and to avoid excessive memory usage, we truncate each document to 400 tokens and queries to 100 tokens. Our implementation use the OpenNMT framework. After the training, we use model to predict 5 most rele-vant query and concate them together. At the last, we use BM25 to retrieval a ranked list document for queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Re-ranking</head><p>After rough ranking, we obtains a list documents that may be relevant to the given query. We applied three main strategies to re-rank the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">DRMMTKS</head><p>DRMM was proposed by <ref type="bibr" coords="1,418.20,714.09,75.33,9.88" target="#b3">(Guo et al., 2016)</ref>. It employs a joint deep architecture at the query term level for relevance matching. Its contains three main parts, which are matching histogram mapping, a feed forward matching network, and a term gating network. By utilizing those networks, DRMM can effectively deal with the exact match-ing signals, query term importance, and diverse matching requirements. DRMMTKS <ref type="bibr" coords="2,133.73,158.97,88.62,9.88" target="#b6">(Yang et al., 2018</ref>) is an variant ver-sion of DRMM. In DRMMTKS, the matching his-togram layer is replaced by a sorted top-k pooling layer. Hence each query term is able to interacted with all the document terms to produce the query term-level interaction vector. Then, the model picks out the top-k signals by a sorted top-k pooling layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">BERT</head><p>Because the effectiveness of BERT <ref type="bibr" coords="2,232.44,302.49,58.79,9.88;2,72.00,315.57,22.39,9.88" target="#b1">(Devlin et al., 2018)</ref>, we use it to re-rank the documents. We first regards query and document as sentence A and sentence B, respectively. And then the concatentated representation is fed into BERT model. A learning-to-rank layer is added on the the representation of '[CLS]' in last layer to generate the finally matching score.</p><p>For every query and document pair in the dataset, we can gain a score that stands for the matching information between them. The document which has highest score is selected as the best relevant document to the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Conv-KNRM</head><p>Convolutional Kernel-based Neural Ranking Model (Conv-KNRM) was proposed by <ref type="bibr" coords="2,214.20,526.89,72.43,9.88" target="#b0">(Dai et al., 2018)</ref>. Conv-KNRM outperformed prior neural IR methods and feature-based methods because of its precise design. Conv-KNRM first embed words into continuous vectors. Then a convolutional neural network is applied to compose embeddings of adjacent word. to n-gram embeddings. Softmatching n-gram is subsequently utilized by the kernel pooling and learning-to-rank layers to genearte the final score.</p><p>Conv-KNRM is an end-to-end model and can be optimized from user feedback. Same to Section 2.3.2, Conv-KNRM generates a list of ranking scores. And the scores are sorted by descent order to pick out the most relevant document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>We conducted a series of experiments on TREC-Deep Complex Answer Retrieval datasets.</p><p>Data. The query is the concatenation of a Wikipedia article title with the title of one of its sections. The ground-truth documents are the paragraphs in that section. We removed repeated queries. For the dataset, we use "benchmarkY1train.v2.0" to expand queries and retrieval.</p><p>Evaluate Metrics. We adopt two evaluation measures, i.e. MRR and NDCG, to evluate the performance of our proposed system.</p><p>Experimental Details. We first expand the documents using the proposed Doc2query method. Then we index the expanded documents. At the last, we use BM25 to retrieve top 1000 relevant passages for each query in train dataset. At training time, we construct the training set in the following way. The passages from qrels file are positive samples and negative samples are sampled from results of BM25. Concretely, each query has 100 negative samples, which are consisted of top 50 relevant passages of BM25 and 50 passages randomly sampled from the remaining 950 rele-vant passages. Because each query has 1.04 pos-itive samples on average, we will duplicate each positive sample twice for making full use of neg-ative samples. All our experiments are carried out using MatchZoo-py <ref type="bibr" coords="2,366.24,451.89,31.31,9.88">(Fan et</ref>  BM25 directly uses the top 1000 relevant passages retrieved for each query in test dataset. The parameter of BM25 is set to b1=0.8, k=0.6.</p><p>DRMMTKS uses Glove (Pennington et al., 2014) as word embedding, and set to trainable during training time. We set top-k is 10, layers of MLP is 1, and hidden size is 6. The model is trained using Adadelta optimizer on a typical GPU, and batch size is 32. Initial learning rate is set to 1e-3.</p><p>The lr will decay with factor 0.9 after every three epoches.</p><p>Bert-DRMMTKS uses the sequence output of last layer in BERT as input. BERT will be fine-tuned with DRMMTKS end-to-end. The setting of DRMMTKS part is same as DRMMTKS run.</p><p>Bert-ConvKNRM uses the sequence output of last layer in BERT as input. BERT will be fine-tuned with Conv-KNRM end-to-end. For Conv-KNRM, we set max n-gram is 3, the number of Gaussian kernels is 11 and use 128 filters in each convolution layer. The model is trained using Adam optimizer on a typical GPU, and batch size is 64. Initial learning rate is set to 1e-3. The lr will decay with factor 0.9 after every three epoches.</p><p>Bert-ConvKNRM-50 uses the same model as Bert-ConvKNRM, but only use top 50 relevant passages of BM25 at prediction time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we presented a query expansion approach, the expansion approach is better than baseline. Then we tried five approaches to improve Re-rank results.We did five comparison experiments and five results were submitted. The next step is to make further improvements based on the results returned.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,306.96,447.99,220.55,177.46"><head></head><label></label><figDesc>al., 2017; Guo et al., 2019) 1 .</figDesc><table coords="2,306.96,467.01,220.39,158.44"><row><cell cols="6">With MatchZoo-py, we can easily use pairwise</cell></row><row><cell cols="6">method for model training. A training pair is</cell></row><row><cell cols="6">consisted of a query, a positive sample and four</cell></row><row><cell cols="6">negative samples. For each training epoch, we will</cell></row><row><cell cols="6">set to resample four negative samples for each</cell></row><row><cell cols="6">positive sample. At prediction time, for im-proving</cell></row><row><cell cols="6">performance, we only use top 50 or 100 relevant</cell></row><row><cell cols="4">passages of BM25 to rerank.</cell><cell></cell></row><row><cell cols="6">We conducted five experiments on required</cell></row><row><cell>dataset,</cell><cell cols="2">named</cell><cell>BM25,</cell><cell cols="2">DRMMTKS,</cell><cell>Bert-</cell></row><row><cell cols="2">DRMMTKS,</cell><cell cols="3">Bert-ConvKNRM</cell><cell>and</cell><cell>Bert-</cell></row><row><cell cols="4">ConvKNRM-50 respectively.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,323.04,750.68,146.52,6.76"><p>https://github.com/NTMC-Community/MatchZoo-py</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,86.76,458.49,204.48,9.88;3,83.04,469.05,207.91,9.88;3,83.04,479.61,208.03,9.88;3,83.04,490.05,208.07,9.88;3,83.04,500.61,208.08,9.88;3,83.04,511.17,151.43,9.88" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,194.28,469.05,96.67,9.88;3,83.04,479.61,208.03,9.88;3,83.04,490.05,26.73,9.88">Convolutional neural networks for soft-matching n-grams in ad-hoc search</title>
		<author>
			<persName coords=""><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,133.68,490.05,157.43,9.88;3,83.04,500.61,208.08,9.88;3,83.04,511.17,47.22,9.88">Pro-ceedings of the eleventh ACM international confer-ence on web search and data mining</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,88.44,530.49,202.79,9.88;3,83.04,541.77,208.32,9.88;3,83.04,553.05,208.32,9.88;3,83.04,564.33,204.71,9.88" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="3,218.16,541.77,73.20,9.88;3,83.04,553.05,208.32,9.88;3,83.04,564.33,61.59,9.88">Bert: Pre-training of deep bidirectional transformers for language understand-ing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="3,86.88,583.77,204.60,9.88;3,83.04,594.57,208.19,9.88;3,83.04,605.25,179.39,9.88" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianpeng</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<title level="m" coord="3,129.48,605.25,128.38,9.88">A toolkit for deep text matching</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,87.24,624.57,203.96,9.88;3,83.04,636.45,208.20,9.88;3,83.04,648.45,208.32,9.88;3,83.04,660.33,208.08,9.88;3,83.04,672.21,208.27,9.88;3,83.04,684.09,55.19,9.88" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,169.44,636.45,121.80,9.88;3,83.04,648.45,108.91,9.88">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,210.60,648.45,80.76,9.88;3,83.04,660.33,208.08,9.88;3,83.04,672.21,173.52,9.88">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,86.88,703.65,204.31,9.88;3,83.04,715.53,208.31,9.88;3,83.04,727.41,208.19,9.88;3,83.04,739.41,208.31,9.88;3,83.04,751.29,25.82,9.88;3,124.44,751.29,52.32,9.88;3,192.48,751.29,10.56,9.88;3,218.64,751.29,40.68,9.88;3,275.04,751.29,15.84,9.88;3,83.04,763.29,116.04,9.88;3,318.00,66.69,186.86,9.88;3,318.00,77.49,91.67,9.88" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,147.00,715.53,144.35,9.88;3,83.04,727.41,203.62,9.88">Matchzoo: A learning, practicing, and devel-oping system for neural text matching</title>
		<author>
			<persName coords=""><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331403</idno>
	</analytic>
	<monogr>
		<title level="m" coord="3,95.40,739.41,195.95,9.88;3,83.04,751.29,25.82,9.88;3,124.44,751.29,52.32,9.88;3,192.48,751.29,10.56,9.88;3,218.64,751.29,40.68,9.88;3,275.04,751.29,15.84,9.88;3,83.04,763.29,116.04,9.88;3,318.00,66.69,79.30,9.88">Proceed-ings of the 42Nd International ACM SIGIR Confer-ence on Research and Development in Information Retrieval, SIGIR&apos;19</title>
		<meeting>eed-ings of the 42Nd International ACM SIGIR Confer-ence on Research and Development in Information Retrieval, SIGIR&apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1297" to="1300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,329.40,96.57,197.64,9.88;3,318.00,108.45,209.11,9.88;3,318.00,120.45,209.23,9.88;3,318.00,132.33,209.28,9.88;3,318.00,144.33,209.11,9.88;3,318.00,156.21,50.15,9.88" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,461.64,108.45,65.47,9.88;3,318.00,120.45,135.08,9.88">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,474.36,120.45,52.87,9.88;3,318.00,132.33,209.28,9.88;3,318.00,144.33,171.90,9.88">Proceedings of the 2014 confer-ence on empirical methods in natural language pro-cessing (EMNLP)</title>
		<meeting>the 2014 confer-ence on empirical methods in natural language pro-cessing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,321.84,175.41,205.68,9.88;3,318.00,186.57,209.28,9.88;3,318.00,197.73,209.16,9.88;3,318.00,208.89,209.16,9.88;3,318.00,220.05,209.28,9.88;3,318.00,231.09,54.35,9.88" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,417.00,197.73,110.16,9.88;3,318.00,208.89,160.87,9.88">A deep top-k relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">Zhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qingfeng</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaofei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,502.32,208.89,24.84,9.88;3,318.00,220.05,155.46,9.88">China Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
