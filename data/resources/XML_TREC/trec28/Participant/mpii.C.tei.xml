<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,208.77,114.94,194.46,15.12;1,124.62,136.85,362.77,15.12">MPII at TREC CAsT 2019: Incoporating Query Context into a BERT Re-ranker</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,148.83,170.76,95.27,10.48"><forename type="first">Samarth</forename><surname>Mehrotra</surname></persName>
							<email>samarth.mehrotra@tum.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.16,170.76,71.92,10.48"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
							<email>ayates@mpi-inf.mpg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,208.77,114.94,194.46,15.12;1,124.62,136.85,362.77,15.12">MPII at TREC CAsT 2019: Incoporating Query Context into a BERT Re-ranker</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ED2DBD53259D6FF0E2BEBAEF6276F3C7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>MPII participated in the Conversational Assistance Track (CAsT) at TREC 2019. Our approach consists of an initial stage ranker followed by a BERT-based [3] neural document re-ranking model. BM25 with query expansion based on external knowledge (i.e., Wikipedia and ConceptNet) serves as the first stage ranking method, while the neural model uses BERT embeddings and a kernel-based ranking module (KNRM) to predict a document-query relevance score. We repurpose and modify subtopics from the TREC Web Track's diversity task to train the neural module. We find that the neural re-ranking module substantially improves upon the initial ranking approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Conversational Assistance Track (CAsT) is a new track introduced by TREC 2019, which focuses on information seeking in a conversational setting. MPII participated in CAsT with an approach based on paragraph retrieval: a first stage ranker with query expansion identified a set of candidate documents that were then re-ranked with a BERT-based re-ranking model. <ref type="bibr" coords="1,517.58,441.03,8.97,9.57" target="#b2">[3]</ref><ref type="bibr" coords="1,526.55,441.03,4.48,9.57" target="#b3">[4]</ref><ref type="bibr" coords="1,531.03,441.03,8.97,9.57" target="#b4">[5]</ref> Following <ref type="bibr" coords="1,121.48,454.58,10.91,9.57" target="#b3">[4]</ref>, we used a BERT-KNRM variant <ref type="bibr" coords="1,302.25,454.58,11.52,9.57" target="#b8">[9]</ref> combining BERT's embeddings with KNRM's kernel pooling technique. The current utterance and n previous utterances serve as the query, which we concatenate before processing with an attention module. In this short paper, we present our methodology and preliminary results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In this section, we describe in detail the CAsT task and our approach. Given a sequence of questions, q 1 , q 2 , ...q n , the objective of the CAsT task is to return a relevant list of documents for each step of the conversation. At each step i, the previously seen questions (i.e., q 1 to q i-1 ) can be considered part of the conversation history. Documents were retrieved from a collection of three corpora: MS Marco, TREC CAR, and the Washington Post corpus from the TREC News Track. Given that this is a conversational search task, nDCG@3 is used as the main evaluation metric.</p><p>Our approach consisted of a two-stage retrieval method, as is common when employing a neural ranking method. The first stage consisted of a recall-focused approach (i.e., BM25 with query expansion). The second stage consisted of a BERT-based neural re-ranking module that re-ranks the documents retrieved by the initial ranker. Both stages are described in the following sections. Given that this was the first time the CAsT track appeared at TREC, only a small amount of human judgments were available. <ref type="foot" coords="2,195.21,73.56,4.23,6.99" target="#foot_0">1</ref> Rather than training our neural model with a mixture of these judgments and judgments from other tasks, we rewrote existing TREC queries and used the associated judgments provided by TREC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query Expansion and Initial Retrieval</head><p>Given the challenges posed by conversational queries, we opted for a recall-focused first stage ranking approach using query expansion via Wikipedia and ConceptNet <ref type="bibr" coords="2,422.71,165.19,10.91,9.57" target="#b5">[6]</ref>. In pilot experiments we found that performance on TREC Sessions data and the TREC Web Track's diversity task data (with queries rewritten to be conversational) improved over BM25 with this approach.</p><p>To retrieve a set of documents for query q i , we begin by concatenating all of the previous queries in the conversation history and the current query, i.e. from q 1 to q i , to form a new query called q c . Inspired by <ref type="bibr" coords="2,180.72,232.94,10.91,9.57" target="#b7">[8]</ref>, we then expand q c using a query expansion module that uses external knowledge. We use a combination of ConceptNet and Wikipedia to expand the queries with relevant terms which can potentially improve the quality of the initial retrieval. As illustrated in Figure <ref type="figure" coords="2,531.52,260.04,4.24,9.57" target="#fig_0">1</ref>, Wikipedia was used for queries that contained entities (according to Spotlight), while ConceptNet was used for queries that did not. We use DBPedia Spotlight <ref type="bibr" coords="2,371.36,287.14,11.52,9.57" target="#b0">[1]</ref> to perform entity linking on the concatenated query q c . Related Wikipedia pages were then identified using Wikipedia's Search API. Relevant terms from these pages were then scored using a TF-IDF heuristic similar to that used in <ref type="bibr" coords="2,109.64,327.78,10.91,9.57" target="#b7">[8]</ref>. For each entity returned by Spotlight, we expand the query using terms from Wikipedia as follows. First, we query Wikipedia's search API and retrieve a list of snippets from relevant pages. Let o 1 , ..., o n be the list of snippets returned. For each unique term t i in these snippets, we compute a score for the term as follows:</p><formula xml:id="formula_0" coords="2,224.38,623.66,241.86,15.96">score t i = on o 1 (tf (o j , t i )/|o j |) * r(o j ) * log(1/df (t i ))</formula><p>; where r(o j ) is the reciprocal rank of o j in the results, df is the document frequency of a term, |o j | is the length of the summary and tf (o j , t i ) is the term frequency of the term in the o th j summary. Up to 10 of the highest scored terms are added to the query. If no entities are identified in the query, it is instead expanded using ConceptNet. To do so, n-grams comprised of nouns and adjectives from the query are used to query for relevant nodes. Terms from the connecting nodes are then added to the query.</p><p>The concatenated query q c is expanded to form the expanded query q e , which we then use to identify candidate documents with BM25. This set of potentially relevant documents are then re-ranked as described in the next section. Note that this is a recall-oriented first stage retrieval and our second stage re-ranking method does not consider BM25's scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Re-Ranking with BERT and KNRM</head><p>Given a potentially relevant document D, our goal is to predict a relevance score between query q i and D that takes the conversation context (i.e., queries q 1 , ...q i-1 ) into account. We use an approach based on the BERT-KNRM neural re-ranker <ref type="bibr" coords="3,282.16,193.06,10.91,9.57" target="#b3">[4]</ref>, but use an additional attention module to re-weight embeddings from the document and query sequence before consuming them with KNRM. <ref type="bibr" coords="3,503.93,206.61,11.52,9.57" target="#b8">[9]</ref> We incorporate past queries by concatenating the previous queries with the current query. However, at greater depths of the conversation, this can lead to long concatenated queries. Hence, we define a sliding window heuristic to not consider all the previous queries in the conversation history. We first resolve any coreference mentions in the sequence of queries. We then consider only the previous five queries and concatenate them with the i th query. Important terms from distant queries (i.e., more than 5 turns back) may be incorporated due to coreference resolution, while coreference resolution failures are mitigated due to the inclusion of recent queries.</p><p>Consider the concatenated query (after coreference resolution and the sliding window heuristic) q c and the document D. Let D consist of a sequence of terms p 1 , p 2 , ....p m and q c consist of a sequence of terms q 1 , q 2 , ....q n . We use a pre-trained BERT model to extract contextual word embeddings for each of the words in q c and D.</p><p>Let the extracted embeddings be e p1 , e p2 , .....e pm and e q1 , e q2 , .....e qn . These extracted contextual embeddings are now passed through an attention module that is used to re-weight parts of the query as well as the document. This attention module used is identical to the attention module described in the paper by <ref type="bibr" coords="3,194.74,409.85,10.91,9.57" target="#b6">[7]</ref>. As in <ref type="bibr" coords="3,241.66,409.85,10.91,9.57" target="#b6">[7]</ref>, the module uses scaled dot-product attention:</p><formula xml:id="formula_1" coords="3,72.00,409.85,468.00,27.37">Att(Q, K) = [sof tmax(Q[i] * K T / √ d] n Q -1 i=0 and V att = Att(Q, K) * V .</formula><p>Let the term embeddings of query and document tokens extracted using a BERT model be: </p><formula xml:id="formula_2" coords="3,233.50,487.93,91.77,10.77">doc embeddings = e p1 ,</formula><p>After using the attention module, these become:</p><formula xml:id="formula_4" coords="3,134.31,556.97,401.05,14.27">query new embeddings = Attention(query embeddings , doc embeddings , doc embeddings ) (<label>3</label></formula><formula xml:id="formula_5" coords="3,535.36,559.46,4.65,9.57">)</formula><p>doc new embeddings = Attention(doc embeddings , query embeddings , query embeddings ) (4)</p><p>The new embeddings, query new embeddings and doc new embeddings are passed as input to the embedding layer of the KNRM model. KNRM uses multiple kernels to consider different levels of embedding similarity in order to predict a relevance score; see <ref type="bibr" coords="3,319.53,628.87,11.52,9.57" target="#b8">[9]</ref> for further details. The only change which was made to the KNRM model was the loss function: we used binary cross entropy (as in <ref type="bibr" coords="3,521.21,642.41,11.27,9.57" target="#b4">[5]</ref>), because the training data which we artificially created was binary (relevant/non-relevant). This re-ranking approach is then used to re-rank the candidate documents returned by the first stage retrieval method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>As this was the first year of the track, the amount of labeled training data available was limited. However, we required training data for a number of reasons: to fine-tune the BERT embeddings, to learn the weights of the new attention layer which was added, and to learn the weights of the KNRM module.</p><p>In order to generate training data, we made use of previous collections of the TREC Web Track (diversification subtask) data. <ref type="foot" coords="4,215.18,165.65,4.23,6.99" target="#foot_1">2</ref> The task was similar to the TREC CAsT track in the sense that it involved multiple information seeking queries which were based on a broad topic. Unlike CAsT, the queries were not very conversational and did not consist of co-references between queries. To resolve this problem and create a more appropriate training set, we manually identified the key entities being mentioned in each sequence of queries and randomly replaced certain occurrences of these entities with appropriate pronouns. This gave us a new training set which was more similar to TREC CaST. <ref type="foot" coords="4,150.49,246.95,4.23,6.99" target="#foot_2">3</ref> For example, the following queries were part of the Web Track data:</p><p>• Find the homepage for the Kansas City Southern railroad • I'm looking for a job with the Kansas City Southern railroad.</p><p>After replacing entities with co-references, the queries might become:</p><p>• Find the homepage for the Kansas City Southern railroad • I'm looking for a job with them.</p><p>We used Anserini <ref type="bibr" coords="4,158.14,381.51,16.97,9.57" target="#b9">[10]</ref> to index the three collections. In the initial stage retrieval step, we retrieved 500 documents from TREC CAR, 500 from MSMarco and 200 from WaPo. In the next step, we used spaCy <ref type="foot" coords="4,126.97,406.66,4.23,6.99" target="#foot_3">4</ref> as the tool to perform co-reference resolution. To fine-tune the BERT embeddings, we first used the fine-tuned and pre-trained embeddings which have been made available by <ref type="bibr" coords="4,525.45,422.16,10.91,9.57" target="#b4">[5]</ref>. We then fine-tuned these embeddings using data from the Sessions Track. Finally, we fine-tuned the embeddings while training the KNRM module end-to-end with the Web Track Diversity data which we converted to conversational queries.</p><p>We submitted two runs to CAsT. The first run, mpi base, was a simple run which comprised only of the stage one results, i.e. query expansion and retrieval using BM25. The second run, mpi bert, was comprised of the entire pipeline: initial retrieval followed by re-ranking using the neural model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Conclusion</head><p>The results of our approaches are shown in the top half of Table <ref type="table" coords="4,400.19,575.63,4.24,9.57" target="#tab_1">1</ref>. The BERT-KNRM-based re-ranking model substantially improved MRR and nDCG@3 over our recall-focused first stage retrieval. The first stage retrieval method did not perform well in terms of MAP when compared to other participants, though it did outperform the BERT-based model here (due to the limited number of documents re-ranked).</p><p>In the second half of Table <ref type="table" coords="4,213.24,643.38,4.24,9.57" target="#tab_1">1</ref>, we show results from a similar BERT-based method: ug cedr rerank. While this approach used a similar CEDR-KNRM architecture, it performed substantially better across metrics. There are at least three possible contributing factors: <ref type="bibr" coords="4,405.36,670.48,14.50,9.57" target="#b0">(1)</ref>  CEDR-KNRM outperforms BERT-KNRM, so CEDR's inclusion of BERT's CLS token may be improving performance; and (2) CEDR-KNRM used a different first stage retrieval method, which may have better recall; and (3) different training data was used. Given these differences, it is difficult to assess the impact of our first stage query expansion and our added attention module. The inclusion of BERT's CLS token does outweigh the combined impact of these differences, though we remark that all three differences may not have contributed positively to mpi bert's performance. We leave experiments assessing the impact of each individual change with respect to CEDR-KNRM for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,167.38,562.77,277.25,9.57;2,206.79,348.28,198.42,198.42"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of resources used for query expansion.</figDesc><graphic coords="2,206.79,348.28,198.42,198.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,423.79,670.48,116.21,9.57"><head>Table 1 :</head><label>1</label><figDesc>prior work has indicated Selected results from the CAsT 2019 overview paper.<ref type="bibr" coords="5,450.69,153.83,11.52,9.57" target="#b1">[2]</ref> </figDesc><table coords="5,196.64,74.43,218.72,53.40"><row><cell>Run</cell><cell cols="2">MAP MRR nDCG@3</cell></row><row><cell>mpi base</cell><cell>0.173 0.508</cell><cell>0.234</cell></row><row><cell>mpi bert</cell><cell>0.166 0.597</cell><cell>0.319</cell></row><row><cell cols="2">ug cedr rerank [2] 0.216 0.643</cell><cell>0.356</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,88.59,713.88,444.83,7.86"><p>CAsT organizers provided thirty training topics; incomplete manual judgments were provided by five of these.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,88.59,692.60,183.59,7.47"><p>https://trec.nist.gov/data/webmain.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,88.59,703.56,444.98,7.47"><p>https://mpi-inf.mpg.de/departments/databases-and-information-systems/research/neural-ir/cast19</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,88.59,714.52,183.59,7.47"><p>https://trec.nist.gov/data/webmain.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,94.42,338.22,445.57,10.18;5,94.42,351.77,445.58,9.57;5,94.42,365.32,207.74,9.57" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,419.74,338.22,120.25,9.57;5,94.42,351.77,196.31,9.57">Improving efficiency and accuracy in multilingual entity extraction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daiber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,313.66,351.77,226.34,9.57;5,94.42,365.32,165.34,9.57">Proceedings of the 9th International Conference on Semantic Systems (I-Semantics</title>
		<meeting>the 9th International Conference on Semantic Systems (I-Semantics</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.42,386.70,445.58,10.18;5,94.42,400.25,445.57,9.57;5,94.42,413.80,294.83,9.57" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,312.58,386.70,227.42,9.57;5,94.42,400.25,39.35,9.57">Cast 2019: The conversational assistance track overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,166.60,400.25,298.99,9.57">Proceedings of The Twenty-Eight Text REtrieval Conference</title>
		<meeting>The Twenty-Eight Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-13">2019. November 13-15, 2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.42,435.19,445.58,10.18;5,94.42,448.74,440.75,9.57" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,421.10,435.19,118.90,9.57;5,94.42,448.74,236.51,9.57">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,94.42,470.12,445.58,10.18;5,94.42,483.67,238.75,9.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,414.62,470.12,125.38,9.57;5,94.42,483.67,147.05,9.57">Cedr: Contextualized embeddings for document ranking</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,264.84,483.67,30.94,9.57">SIGIR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.42,505.06,445.58,10.18;5,94.42,518.61,33.33,9.57" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="5,242.50,505.06,134.31,9.57">Passage re-ranking with bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,94.42,540.00,445.57,10.18;5,94.42,553.54,283.46,9.57" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,283.52,540.00,256.47,9.57;5,94.42,553.54,46.91,9.57">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName coords=""><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,165.02,553.54,110.79,9.57">Proceedings of AAAI31</title>
		<meeting>AAAI31</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.42,574.93,445.58,10.18;5,94.42,588.48,445.58,9.57;5,94.42,602.03,445.58,9.57;5,94.42,615.58,137.54,9.57" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,510.00,574.93,30.00,9.57;5,94.42,588.48,354.63,9.57">Multiturn response selection for chatbots with deep attention matching network</title>
		<author>
			<persName coords=""><forename type="first">Xiangyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D Y L Y C W X Z D Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,472.77,588.48,67.23,9.57;5,94.42,602.03,358.85,9.57">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.42,636.97,445.58,10.18;5,94.42,650.52,445.58,9.57;5,94.42,664.06,148.33,9.57" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,249.61,636.97,148.35,9.57">Query expansion with freebase</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,425.41,636.97,114.59,9.57;5,94.42,650.52,306.77,9.57;5,94.42,664.06,77.50,9.57">Proceedings of the 2015 International Conference on The Theory of Information Retrieval</title>
		<meeting>the 2015 International Conference on The Theory of Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
	<note>ICTIR &apos;15, ACM</note>
</biblStruct>

<biblStruct coords="5,94.42,685.45,445.58,10.18;5,94.42,699.00,445.58,9.57;5,94.42,712.55,325.39,9.57" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,408.33,685.45,131.68,9.57;5,94.42,699.00,134.66,9.57">End-to-End Neural Ad-hoc Ranking with Kernel Pooling</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,249.86,699.00,290.15,9.57;5,94.42,712.55,254.87,9.57">Proceedings of the 40th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,94.42,75.51,445.57,10.18;6,94.42,89.06,445.58,9.57;6,94.42,102.61,445.57,9.57;6,94.42,116.16,70.91,9.57" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,319.56,75.51,220.43,9.57;6,94.42,89.06,70.20,9.57">Enabling the use of lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Anserini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,186.46,89.06,353.54,9.57;6,94.42,102.61,206.12,9.57;6,454.36,102.61,78.44,9.57">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;17, ACM</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
