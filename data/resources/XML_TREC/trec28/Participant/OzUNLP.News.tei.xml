<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.79,172.49,354.67,15.20">OzU-NLP at TREC NEWS 2019: Entity Ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,183.84,206.34,80.45,10.56"><forename type="first">Kenan</forename><surname>Fayoumi</surname></persName>
							<email>kenan.fayoumi@ozu.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">Özyeğin University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Reyyan Yeniterzi Sabancı University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.79,172.49,354.67,15.20">OzU-NLP at TREC NEWS 2019: Entity Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B67986497BDB9DF42E2A29D0833691B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our work and submission for TREC 2019 News Track: Entity Ranking Task. Our approach utilizes Doc2Vec's ability to represent documents as fixed sized numerical vectors. Applied on news articles and wiki-pages of the entities, Doc2Vec provides us with vector representations for these two that we can utilize to perform ranking on entities. We also investigate whether background linked articles can be useful for entity ranking task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>TREC News Track is intended to encourage the use of IR systems to improve the news reading experience of the users. TREC 2019 News Track offers two tasks: Background Linking and Entity Ranking. Background Linking task is concerned with linking a news article with a list of other news articles that provide the reader with context or background information. As for the second task, Entity Ranking, each news article mention a number of namedentities. Some of these entities are of high importance to the article, some are not. For each article, the task is to rank the list of named-entities mentioned in that article, in terms of importance to the article and usefulness to the reader.</p><p>This paper investigates two different aspects for entity ranking task. The first is whether representing news articles and entities with distributed vectors can be useful in finding the relation between them. Secondly, to analyze whether background linking articles can be utilized to improve the entity ranking.</p><p>The structure of this paper is as follows: Section 2 explains the data collections, Section 3 summarizes the prior work on entity linking from last year's track, Section 4 describes our approach; experiments and results are presented in Section 5 and finally Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>In cooperation with the Washington Post, TREC has provided a collection of 595,037 news articles. Originally the dataset had more than 600,000 articles, but these included some duplicates. TREC organizers have removed many of the duplicate articles, but still a number of duplicates remains in the dataset <ref type="foot" coords="2,160.21,209.84,4.23,7.04" target="#foot_0">1</ref> . TREC has also provided a Wikipedia dump dated from August 2017 for this task.</p><p>The subset of articles used for TREC 2019 News Track Entity Ranking task submission contains 52 articles<ref type="foot" coords="2,298.17,250.49,4.23,7.04" target="#foot_1">2</ref> . Entities mentioned in each of those articles were manually linked into the corresponding Wikipedia article from the Wikipedia dump. We also used last year's (TREC 2018 News Track Entity Ranking) testing set (50 articles) for running experiments and tuning our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Prior Work on Entity Ranking</head><p>TREC News Track Entity Ranking task was started in 2018 and this is the second time TREC is organizing this task. There were 2 participants in last year's task: Team Signal and TREMA-UNH.</p><p>Team Signal <ref type="bibr" coords="2,207.17,405.98,11.44,9.63" target="#b0">[1]</ref> proposed a supervised approach using Salience Entity Linking (SEL) algorithm <ref type="bibr" coords="2,249.27,419.53,10.85,9.63" target="#b1">[2]</ref>. SEL is a unified algorithm for entity linking and salience detection. The authors focused on the salience component of SEL to rank the provided entities.</p><p>TREMA-UNH's <ref type="bibr" coords="2,222.70,460.18,11.45,9.63" target="#b2">[3]</ref> approach was based on BM25 retrieval model. They experimented with different combinations of article title and paragraphs to rank the entities represented by their Wikipedia pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>In this section we give a brief description of Doc2Vec model and how we use these vectors for our task of ranking entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Doc2Vec</head><p>Doc2Vec or document distributed representations is an unsupervised model used to learn a vector representation for sentences, paragraphs, or documents <ref type="bibr" coords="3,157.52,180.92,10.85,9.63" target="#b3">[4]</ref>. Since it's unsupervised, it can be trained on large unlabeled text corpora. It is applicable to documents of different lengths as it generates vectors of fixed size for all documents. This is an advantage over other similar approaches which requires input padding or cutting off documents to a certain length. Summarizing documents in one-dimensional vectors, these paragraph vectors encapsulate contextual information along with semantic and syntactic structure.</p><p>Doc2Vec was introduced as an extension to Word2Vec <ref type="bibr" coords="3,413.43,275.76,10.85,9.63" target="#b4">[5]</ref>. Word2Vec is a model that learns a representation of words and phrases. Word2Vec uses two different approaches to learn the word representations: Continuous Bag-of-Words (CBOW) predicts a target word given its context, and Skip-Gram, given a word, predicts the context of that word. Doc2Vec extends Word2Vec's learning of word representation for the purpose of learning document representation.</p><p>As described by Le and Mikolov <ref type="bibr" coords="3,304.40,370.61,10.84,9.63" target="#b3">[4]</ref>, there are two main algorithms to learn paragraph vectors, either with Distributed Memory (PV-DM) as shown in Figure <ref type="figure" coords="3,170.66,397.70,4.97,9.63" target="#fig_0">1</ref>(b) or with distributed Bag-Of-Words (dBOW) as shown in Figure <ref type="figure" coords="3,125.80,411.25,17.84,9.63" target="#fig_0">1(a)</ref>. The main difference between these two algorithms is that PV-DM uses the context words to predict the next word in the context, while dBOW forces the model to predict randomly sampled words from a sentence without using the context or word-ordering information. In that sense, dBOW is similar to Skip-Gram model in Word2Vec <ref type="bibr" coords="3,321.52,465.45,10.85,9.63" target="#b4">[5]</ref>. Since dBOW does not consider word ordering, it's conceptually simpler than PV-DM model and it stores less information. Therefore, from the memory perspective, dBOW has an advantage over PV-DM. Our task is basically to find ranking R D e for each e in E using the similarity between vectors V (D) and V (e i ). Cosine similarity is used as the measure to calculate the distance between these vectors. This process is depicted in Figure <ref type="figure" coords="4,159.99,438.35,4.22,9.63" target="#fig_1">2</ref>. Other news articles, which are related to the current news article, can be useful in ranking the entities as well. Therefore, in addition to using only the topic news article itself, we explore using background linked articles in ranking entities. In a realistic setting, since we don't have those background linked articles given explicitly, we again use Doc2Vec vector similarity to fetch the similar articles given a news (topic) article. Based on this we use the followings: SIM D 1 : article from Washington News corpus that is most similar to D SIM D 2 : article from Washington News corpus that is the second most similar to D SIM D n : article from Washington News corpus that is the nth most similar to D Below is the list of submitted runs and their descriptions of how we utilize Doc2Vec in both finding similar articles and using those articles (including the topic article itself) for ranking entities. Our first run only uses the topic article itself to rank the entities while the other four runs also use the other similar news articles given the topic article.</p><p>For an article D we would like to evaluate:</p><p>1) OzU_wiki: This is the approach shown in Figure <ref type="figure" coords="5,392.26,331.51,4.22,9.63" target="#fig_1">2</ref>. Get the Doc2Vec representations of the (topic) news article and entity's Wikipedia page, and calculate the cosine similarity between them to estimate the ranking score of the entity.</p><formula xml:id="formula_0" coords="5,249.62,393.78,234.83,15.02">R D e i = cos_sim(V (D), V (e i ))<label>(1)</label></formula><p>2) OzU_wiki_top1: We fetch the most similar article to D which is (SIM D 1 ), and then compute cosine similarity between this similar article and entities of the original queried article D.</p><formula xml:id="formula_1" coords="5,238.08,473.41,246.37,15.02">R D e i = cos_sim(V (SIM D 1 ), V (e i ))<label>(2)</label></formula><p>This submission shows the effect of using the most similar news article instead of the query article.</p><p>3) OzU_wiki_top5: We first fetch the vectors of the 5 most similar articles (SIM D 1 , SIM D 2 ...SIM D 5 ) to article D and then calculate cosine similarity between each similar article and the entities. R D e i is the average of these similarities.</p><formula xml:id="formula_2" coords="5,224.36,598.39,260.09,33.58">R D e i = 1 5 5 n=1 cos_sim(V (SIM D n ), V (e i ))<label>(3)</label></formula><p>4) OzU_wiki_1_ws: This is a combination of OzU_wiki and OzU_ wiki_top1. We use similarity scores from these approaches to calculate R D e i in a weighted sum fashion using the following formula:</p><formula xml:id="formula_3" coords="6,153.33,156.61,331.12,25.61">R D e i = 0.9 * cos_sim(V (D), V (e i )) + 0.1 * cos_sim(V (SIM D 1 ), V (e i ))<label>(4)</label></formula><p>5) OzU_wiki_5_ws: This is a combination of OzU_wiki and OzU_ wiki_top5. We perform a weighted sum to calculate R D e i giving higher weights to articles that are more similar.</p><formula xml:id="formula_4" coords="6,163.03,247.27,321.42,104.19">R D e i = 0.8 * cos_sim(V (D), V (e i )) + 0.05 * cos_sim(V (SIM D 1 ), V (e i )) + 0.05 * cos_sim(V (SIM D 2 ), V (e i )) + 0.04 * cos_sim(V (SIM D 3 ), V (e i )) + 0.03 * cos_sim(V (SIM D 4 ), V (e i )) + 0.03 * cos_sim(V (SIM D 5 ), V (e i ))<label>(5)</label></formula><p>Weights used in Equation 4 and 5 are optimized through experiments on TREC 2018 Entity Ranking testing dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>The primary metric for evaluating entity ranking task is nDCG@5. MAP is also being used as an additional metric. Table <ref type="table" coords="6,368.41,454.51,5.42,9.63" target="#tab_0">1</ref> presents the results of our first run (OzU_wiki) on both TREC 2018 and 2019 entity ranking task topics together with the results of the other submitted runs from TREC 2018, more specifically the runs from Team Signal and TREMA-UNH.  <ref type="table" coords="7,234.92,133.23,4.22,9.63" target="#tab_0">1</ref>, our proposed approach of using Doc2Vec similarity to rank entities outperform all approaches from last year. This indicates that distributed representation of documents is effective for ranking entities in general.</p><p>Two submissions from TREC 2018 have different strengths. One performed better in MAP while its performance on NDCG@5 is much lower. On the other hand, the other performed better in NDCG@5 but not so well in MAP. Compared to these two, Doc2Vec based Ozu_wiki approach outperform both systems in both metrics which shows the generality of the approach.</p><p>Table <ref type="table" coords="7,173.22,268.72,5.42,9.63" target="#tab_1">2</ref> summarizes all of our runs including the ones in which similar news articles to the given news article are also used for ranking the entities. According to Table <ref type="table" coords="7,239.55,442.79,4.22,9.63" target="#tab_1">2</ref>, using similar news articles either alone or interpolated together does not provide any significant gains or loses. There is not any single approach that consistently outperforms others in both TREC 2018 and 2019. This may be due to our approach on finding similar articles. Since both document similarity and entity similarity is using the same Doc2Vec model, identified similar news articles may not provide additional useful information to the entity ranking. Therefore, comparing entity vectors with vectors from similar articles return similar results.</p><p>The motivation behind using these similar news articles was to see whether background linking can be useful in entity ranking task. However, Doc2Vec may not be the ideal way to identify background linked articles. One way to understand this is to see how Doc2Vec performs on background linking task. Therefore, we evaluate the similar news articles identified through Doc2Vec with background linking articles' gold standard qrels. The performance is not very high and even lower than some other experimented approaches from TREC 2018. Doc2Vec is not the best way to identify background linking articles and that may be the reason why we do not get any improvements with entity ranking as well.</p><p>In order to test whether using actual background linked articles (from qrels) can be useful in entity ranking, we apply the same four approaches (topn or n_ws) with those articles' vectors. The results do not change significantly. This shows that even using the actual background linking articles in entity ranking through Doc2Vec is not effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we present our work and experiments for the entity ranking task. We train a Doc2Vec model and use it to generate vector representation for news articles and their entities' wikipages. Our original approach OzU_wiki, where we rank entities using the cosine similarity between their wiki-page vector and the query article's vector, return promising results by surpassing all of last year's approaches. Furthermore, we investigate whether the use of similar articles can help boost our model. Through many experiments, we conclude that using similar or background-linked articles through Doc2Vec doesn't bring any noticeable improvements to our original model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,173.39,656.28,263.49,9.63;3,125.80,527.69,143.45,98.73"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Doc2Vec different frameworks reused from<ref type="bibr" coords="3,425.42,656.28,11.45,9.63" target="#b3">[4]</ref> </figDesc><graphic coords="3,125.80,527.69,143.45,98.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,217.41,580.42,175.44,9.63;4,125.80,459.52,358.65,108.96"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pipeline of ranking entities</figDesc><graphic coords="4,125.80,459.52,358.65,108.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,157.10,520.12,296.06,143.53"><head>Table 1 :</head><label>1</label><figDesc>Results of OzU_wiki runAccording to Table</figDesc><table coords="6,157.10,520.12,296.06,119.62"><row><cell></cell><cell cols="2">TREC 2018</cell><cell cols="2">TREC 2019</cell></row><row><cell>Run</cell><cell cols="4">MAP nDCG@5 MAP nDCG@5</cell></row><row><cell>OzU_wiki</cell><cell>0.8184</cell><cell>0.7232</cell><cell>0.7906</cell><cell>0.7579</cell></row><row><cell>signal-ucl-slst</cell><cell>0.6894</cell><cell>0.5772</cell><cell>-</cell><cell>-</cell></row><row><cell>signal-ucl-sel</cell><cell>0.7158</cell><cell>0.6071</cell><cell>-</cell><cell>-</cell></row><row><cell>signal-ucl-eff</cell><cell>0.7144</cell><cell>0.6084</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">UNH-ParaBm25Ecm 0.6828</cell><cell>0.3261</cell><cell>-</cell><cell>-</cell></row><row><cell>UNH-ParaBm25</cell><cell>0.7859</cell><cell>0.4278</cell><cell>-</cell><cell>-</cell></row><row><cell>UNH-TitleBm25</cell><cell>0.7741</cell><cell>0.4220</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,164.67,307.22,280.92,115.64"><head>Table 2 :</head><label>2</label><figDesc>Results of all of our runs</figDesc><table coords="7,164.67,307.22,280.92,91.72"><row><cell></cell><cell cols="2">TREC 2018</cell><cell cols="2">TREC 2019</cell></row><row><cell>Run</cell><cell cols="4">MAP nDCG@5 MAP nDCG@5</cell></row><row><cell>OzU_wiki</cell><cell>0.8184</cell><cell>0.7232</cell><cell>0.7906</cell><cell>0.7579</cell></row><row><cell cols="2">OzU_wiki_top1 0.8023</cell><cell>0.6913</cell><cell>0.7812</cell><cell>0.7509</cell></row><row><cell cols="2">OzU_wiki_top5 0.8154</cell><cell>0.6954</cell><cell>0.7785</cell><cell>0.7426</cell></row><row><cell cols="2">OzU_wiki_1_ws 0.8143</cell><cell>0.7161</cell><cell>0.7551</cell><cell>0.7287</cell></row><row><cell cols="2">OzU_wiki_5_ws 0.8199</cell><cell>0.7234</cell><cell>0.7561</cell><cell>0.7319</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,142.38,580.64,163.69,7.92"><p>http://trec-news.org/guidelines-2019.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,142.38,591.60,342.07,7.92;2,125.80,602.56,358.65,7.92;2,125.80,613.51,358.65,7.92;2,125.80,624.47,93.45,7.92"><p>Originally 2019 Entity Ranking testing dataset contained 60 topics/articles. We've been informed by TREC organizers that 8 articles out of these 60 were dropped from the testing set because the entities mentioned in these do not provide any background information or context.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.71,426.48,341.75,9.63;8,142.71,440.03,139.56,9.63" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,392.95,426.48,91.50,9.63;8,142.71,440.03,47.67,9.63">Signal at trec 2018 news track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Van Der Sluis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,220.21,440.03,26.99,9.63">TREC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.71,462.21,341.75,9.63;8,142.71,475.76,341.74,9.63;8,142.71,489.31,341.74,9.63;8,142.71,502.86,109.38,9.63" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,454.99,462.21,29.47,9.63;8,142.71,475.76,263.51,9.63">Sel: A unified algorithm for entity linking and saliency detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Trani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ceccarelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lucchese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,430.50,475.76,53.94,9.63;8,142.71,489.31,272.14,9.63">Proceedings of the 2016 ACM Symposium on Document Engineering</title>
		<meeting>the 2016 ACM Symposium on Document Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.71,525.04,341.74,9.63;8,142.71,538.59,335.79,9.63" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,419.94,525.04,64.51,9.63;8,142.71,538.59,243.90,9.63">Trema-unh at trec 2018: Complex answer retrieval and news track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kashyapi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ramsdell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,416.44,538.59,26.99,9.63">TREC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.71,560.77,341.75,9.63;8,142.71,574.32,341.74,9.63;8,142.71,587.87,24.71,9.63" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,254.72,560.77,229.74,9.63;8,142.71,574.32,30.55,9.63">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,198.61,574.32,209.19,9.63">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.71,610.05,341.75,9.63;8,142.71,623.60,341.75,9.63;8,142.71,637.15,341.75,9.63;8,142.71,650.70,53.03,9.63" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,466.20,610.05,18.25,9.63;8,142.71,623.60,341.75,9.63;8,142.71,637.15,11.03,9.63">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,181.61,637.15,245.21,9.63">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
