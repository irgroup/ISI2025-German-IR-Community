<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,206.67,164.85,197.91,15.12">TREMA-UNH at CAR 2019</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.90,197.33,83.89,10.48"><forename type="first">Jordan</forename><surname>Ramsdell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shubham Chatterjee</orgName>
								<address>
									<addrLine>Pooja Oza</addrLine>
									<settlement>Laura Dietz</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,246.28,197.33,93.96,10.48"><forename type="first">Sumanta</forename><surname>Kashyapi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shubham Chatterjee</orgName>
								<address>
									<addrLine>Pooja Oza</addrLine>
									<settlement>Laura Dietz</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,206.67,164.85,197.91,15.12">TREMA-UNH at CAR 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3CF5209447811B1BCC8E9190FC52B908</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This notebook describes the submissions of team TREMA-UNH to the TREC Complex Answer Retrieval, TREC News, TREC Conversational Assistance, and TREC Deep Learning tracks in 2019. We explore passage retrieval systems, passage similarity metrics, and neural network methods that address the task statements of these tracks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year, team TREMA-UNH from the University of New Hampshire, USA, participated in the following TREC tracks described as follows:</p><p>• Complex Answer Retrieval: Retrieval of passages that are relevant to a given topic, and then ordering these passages into a comprehensive article.</p><p>• Conversational Assistance: Using dialogue and its context, retrieve and rank passages from a large corpus that satisfy the informational needs of the dialogue.</p><p>• News: Given a news article and a corpus of entities, retrieve and rank entities that are relevant to the content of the news article.</p><p>• Deep Learning: Information retrieval with a large training data set. Primarily focused on neural network methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Complex Answer Retrieval</head><p>Answers to difficult questions can be complex, requiring that the user understands multiple topics addressed by the answer. The information needs of a user may not be by traditional retrieval methods: giving a user a ranked list of documents relevant to their question does not mean that the user will understand the answer. For example, some documents may logically precede others, such as those that introduce a topic that is expanded on by later documents. If a user reads these documents out of order, then the answer can be difficult to comprehend. There is a need, then, for answers structured in a way that is easy for a user to understand.</p><p>Wikipedia pages provide a good example of structured information: the page is divided into multiple sections that address topics relevant to understanding the subject of the page. Passages are logically ordered in each section such that they intro and then expand on the topic of the section. Using structured information can make the task of finding relevant information easier for the user to determine which topics are relevant to their question, and only read documents pertaining to these topics.</p><p>Our work in the Complex Answer Retrieval track uses structured information to address the following task.</p><p>Task. Given a topic and an outline consisting of section headings, retrieve up to 20 passages and organize them in a topically coherent way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">UNH-bm25-ecmpsg</head><p>For each topic, T , we retrieve the top 1000 passages, PT , that are relevant to the topic with respect to the Lucene's<ref type="foot" coords="2,353.90,301.62,3.65,5.24" target="#foot_0">1</ref> implementation of the BM25 metric. These passages contain entities (links to Wikipedia), and we denote EP T as the set of all entities contained in passages retrieved for the given topic. We measure the relevance of an entity ei ∈ EP T to the topic T using the set of passages, Pe i in PT that link to entity ei, and the following formula:</p><formula xml:id="formula_0" coords="2,233.60,380.10,144.04,20.20">RelevanceT (ei) = p j ∈Pe i BM25T (pj)</formula><p>Where BM25T (pj) is the relevance score of a passage with respect to a topic using BM25. Therefore, an entity's relevance score is equal to the sum of the BM25 scores of all the passages in the candidate set that link to the entity.</p><p>We take the top 100 entities with respect to their relevance to a topic and expand the initial BM25 passage query with the names of these entities. Using the expanded query and BM25, produce a ranking of passages given a topic. We convert this ranking to an ordering of 20 passages using the conversion script<ref type="foot" coords="2,242.02,491.82,3.65,5.24" target="#foot_1">2</ref> provided by TREC CAR Y3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reordering Passage Rankings Based on Similarity</head><p>In this section, we describe methods of reordering a candidate set of passages retrieved from section path queries. We reorder candidate sets of passages based on a passage similarity metric, such that passages that are similar to each other are grouped together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Generating Candidate Passage Sets</head><p>We form each section path query by concatenating the name of the topic to each section header present in the outlines. In TREC CAR Y3, we are limited to retrieving up to 20 passages per topic, and so our candidate sets of passages consist of the top n passages from each section query, where n = 20 # of sections . When this results in fewer than 20 passages, we randomly pick the remaining passages from the section path queries</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Reordering Candidate Passages</head><p>For each candidate set of passages, we begin by randomly picking a passage from the candidate set, which we denote the seed passage. Using a passage similarity metric, we then find the passage in the remaining candidate set that is most similar to the seed passage and place it next in the ordering, where it becomes the new seed passage. We repeat this process, retrieving the next passage that is most similar to the current seed passage, until we have ordered all 20 passages from the candidate set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Passage Similarity Metrics</head><p>We use the following passage similarity metrics to reorder the candidate passage sets. These metrics are named according to the names of the runs submitted to TREC CAR Y3 that utilize them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">UNH-tfidf-[stem/lem/ptsim]</head><p>The UNH-tfidf passage similarity metric represents passages as vectors using the bag-of-words model. Each component of the vector is a unique term contained in the passage, the coefficients of which are equal to the term-frequency-inverse document frequency of each unique term. We then calculate the similarity between a pair of passages using cosine similarity based on their vector representations:</p><formula xml:id="formula_1" coords="3,261.72,484.78,81.16,19.74">cos(pi, pj) = pi • pj pi pj</formula><p>We evaluate the TFIDF cosine similarity metric with respect to three methods of pre-processing paragraph text:</p><p>• stem: Passages in the corpus are first stemmed using Lucene's English Analyzer.</p><p>• lem: Passages in the corpus are first lemmatized.</p><p>• ptsim: Passages in the corpus are not pre-processed: only the raw terms are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5">UNH-bm25-[stem/lem]</head><p>Our UNH-bm25 method uses Lucene's implementation of BM25 as a passage similarity metric. Let (pi, pj) be a pair of passages from the paragraph corpus. Then BM25(pi, pj) is the BM25 score of passage pj with respect to treating the text contained in pi as the query. Note however that BM25 is not a symmetric metric. We construct the BM25 passage similarity metric by making BM25 symmetrical: BM25sim(pi, pj) =</p><formula xml:id="formula_2" coords="4,159.87,160.32,88.58,13.32">BM25(p i ,p j )+BM25(p j ,p i ) 2</formula><p>We evaluate the UNH-bm25 similarity metric with respect to two methods of pre-processing paragraph text:</p><p>• stem: Passages in the corpus are first stemmed using Lucene's English Analyzer.</p><p>• lem: Passages in the corpus are first lemmatized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.6">UNH-dl[layer size]</head><p>We use the similarity score obtained from Section 3.1.1 to reorder the passages. Based on the layer size of the dense layers used in the model we have two variants: dl100 and dl300.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">UNH-ecn</head><p>We start with an entity and passage run. For every query-entity pair, we create an Entity Context Document(ECD). To construct this ECD, we filter all passages which mention the entity and "stitch" them together into one "document" about the entity. All entities which occur in this ECD co-occur with the target entity (the entity the ECD is about). We derive a distribution over these co-occurring entities by using the frequency of these entities, that is, the number of times the entity occurs in the ECD. For every passage in an ECD, its score is equal to the sum of the frequency scores of the entities in the passage. We rank the passages using this score. This gives us a passage ranking for every query-entity pair. We call this ranking as a support passage ranking. We obtain a passage ranking from this support passage ranking by marginalizing over the entities. We convert this ranking to an ordering of 20 passages using the conversion script provided by TREC CAR Y3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">UNH-qee</head><p>As in Section 2.3, we obtain a distribution over the co-occurring entities with a given entity using the frequency of occurrence of these entities. In this method, we rank the co-occurring entities using this score. We use the top 20 entities from this ranking to expand the query and retrieve passages with the expanded query using BM25. As in Section 2.3, this gives us a support passage ranking. We obtain a passage ranking from this support passage ranking by marginalizing over the entities. We convert this ranking to an ordering of 20 passage using the conversion script provided by TREC CAR Y3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">UNH-neural</head><p>In this method, we construct a neural network to score the relevance of passages with respect to a query. We construct an embedding of each  <ref type="bibr" coords="5,246.12,374.82,9.22,7.86" target="#b0">[1]</ref>. ELMo produces an embedded word vector for each word in a sentence based on the word's context in the sentence. We construct a sentence embedding by taking the mean of the word vectors in a sentence, and a passage embedding by taking the mean of the sentence embeddings contained in the passage. We also embed each query via ELMo by treating it as a sentence. In addition to passage and query embeddings, we create a passage relevance vector for each passage that represents the relevance of the passage given the query. Each element of the passage relevance vector corresponds to the inverse rank score of the paragraph, with respect to the query, under a particular passage retrieval system (for example, BM25). The input layer of our neural network is a fully connected linear layer, in which the passage embedding, passage relevance, and query embedding vectors are mapped onto three vectors of length 100. We use tanh as the activation function for this layer. This is used as the input of the second layer, which is a weighted trilinear product between the three vectors. We then apply the logistic function to the output of the trilinear function.</p><p>We train the neural network using logistic regression: passages are labeled with a 1 if they are relevant with respect to a query, or 0 otherwise, according to the TREC CAR Y1 train section-level passage qrels. Once trained, we use the neural network to rank a candidate set of passage for each query (retrieved using BM25). We convert these rankings to an ordering of 20 passages using the conversion script provided by TREC CAR Y3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Results from the CAR Evaluation</head><p>We use the following two metrics to evaluate the performance of our TREC CAR Y3 submissions.</p><p>Facet Overlap. For an ordering of 20 passages retrieved for a topic and a section outline, we define facet overlap as the number of transitions between passages that are in the same section over the total number of transitions between passages. We obtain the final score by averaging over the facet overlap scores across all topics in Trec Car Y3 Test.</p><p>Relevance. We define relevance as the number of relevant passages retrieved over the total number of passages retrieved for a topic. We determine relevance of a passage to a topic by using the Trec Car Y3 Test qrels. We obtain the final score by averaging over the relevance scores across all topics in Trec Car Y3 Test.</p><p>Table <ref type="table" coords="6,199.23,276.90,4.61,7.86" target="#tab_0">1</ref> shows our results for TREC CAR Y3 with respect to the facet overlap and relevance evaluation metrics. We see that UNH-tfidfptsim performs best with respect to the facet overlap metric, and that UNH-bm25-rm is the best method with respect to the relevance metric. However, these methods are not significantly better than many of the other methods (marked with asterisks in Table <ref type="table" coords="6,359.59,331.69,4.10,7.86" target="#tab_0">1</ref>) with respect to the standard deviation of the metrics. This discrepancy is most likely due to the small number of topics (55 in total from Y3 Test) used for evaluation.</p><p>We also see that UNH-tfidf-ptsim is significantly better than UNH-bm25-ecmpsg with respect to facet overlap. This is noteworthy because the UNH-tfidf-ptsim method uses UNH-bm25-ecmpsg to retrieve a candidate set of passage, and then reorders the passages based on the TFIDF cosine similarity metric (see sections 2.2.2 and 2.2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Conclusion</head><p>Retrieving and rankings passages based on relevance to a topic does not necessarily produce an understandable summary. We assume that if a topic has multiple aspects (such those described by section headers in a page), that passages of the same aspect should be grouped together, making it easier for the user to identify what aspects are relevant to their question. Our passage similarity methods address this by reordering retrieved passages in such a way that similar passages are grouped together, under the assumption that similar passages belong to the same aspect. We demonstrate that this can directly improve an existing passage retrieval system (in particular, UNH-bm25-ecmpsg) with respect to our facet overlap and relevance evaluation metrics. Furthermore, these methods can work with any passage retrieval system, implying that they can improve other passage retrieval systems. In the future, we hope to find better passage similarity metrics for use in reordering passages: we expect that such metrics would drastically improve the results seen in our paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Deep Learning</head><p>This track studies how Information Retrieval can benefit from large training data and which methods in particular perform well in this setting. The track has two different tasks each with two different subtasks: Document ranking and Passage ranking and their corresponding full-ranking and re-ranking subtask. However, we only participate in passage re-ranking task.</p><p>Task Given an initial ranking of 1000 passages, we have to re-rank these passages based on their likelihood of containing an answer to the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Siamese neural model with ELMo embeddings</head><p>Siamese neural architecture is a family of neural architecture for which there exists at least one pair of layer which are identical or in other words share the same parameter values. Our intuition is if two passages are similar in the context of belonging to the same Wikipedia section, then there exists an embedding space where their corresponding representation will be closer than other passage pairs which are not similar. The job of any model that attempts to learn the similarity metric discussed here has to learn this embedding space. Siamese network allows us to look at both passage representation in a pair of input data sample at once. Hence for any kind of pairwise similarity modeling, it is natural for a siamese network to learn an embedding space which projects similar data points close by and dissimilar data points far apart. Also as both of the input layer in a siamese network share the learned parameters the resulting model will be symmetric which means it will produce the same output even if the order of two passages in a pair is switched.</p><p>Detailed architecture Figure <ref type="figure" coords="7,201.17,430.73,4.61,7.86" target="#fig_0">1</ref> depicts the detailed architecture which is used for our experiments. The model accepts a pair of passages from the training set in form of ELMo vectors. They are fed to two siamese dense layers (share learned parameters), DL1a, DL1 b and DL2a, DL2 b . The output from these layers are concatenated and fed to another dense layer, DL3. Finally its output is fed to DL4 which yields the output for the model. Table ?? gives the details of each layers in terms of tunable parameters. We tried various combinations of layer numbers and sizes but found the setting described here to be most effective in terms of validation loss and convergence time.</p><p>Training For training we use passage representations of 80% samples of balanced y1 train parapair dataset and use rest of it as validation set. For passage representation we use concatenated ELMo vectors. For example let a sample in our training dataset is the passage pair (p1, p2). We obtain 3 layers of ELMo vectors for each passage ([</p><formula xml:id="formula_3" coords="7,348.81,571.42,116.25,11.59">E 1 p 1 , E 2 p 1 , E 3 p 1 ], [E 1 p 2 , E 2 p 2 , E 3 p 2 ]</formula><p>) each of length 1024 and concatenate for each passage to obtain (Ep 1 , Ep 2 ) where E is the concatenation of the three ELMo layer vectors E 1 , E 2 , E 3 . Hence each passage representation is a vector of length 3072.</p><p>Reducing overfitting To reduce overfitting in training we use regularization, dropout and early stopping. The regularization for each layer in the model is set to 0.0001 and one dropout layer is introduced for each input layer with a dropout rate of 0.5 to prevent overfitting. We also employ early stopping to stop the training some iterations after the vali-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Query expansion using Siamese DL model</head><p>As discussed in the previous section, we model a similarity metric using siamese neural model. We use this similarity metric to find the most similar passage from the TRECCAR benchmark Y1 dataset and use it to expand the query. Then we use the expanded query to retrieve passage ranking. We refer to this method as UNH-exDL-bm25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>We submit runs obtained from two of our methods: UNH-bm25 (BM25 baseline method) and UNH-exDL-bm25. Results obtained for our methods are described in Table ??. The average of the median of all the submissions are the following: AP 0.3864, NDCG 0.6457 and P@10 0.5651.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conclusion</head><p>We observe that our query expansion model performs poorly on the reranking task. This suggests that our choice of knowledge base for the query expansion (TRECCAR benchmark Y1) is not suitable for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conversational Assistance</head><p>Task. The task of Conversational Assistance is to retrieve the passages using contextual information provided by series of queries on a given topic. Three automatic runs were submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UNH-trema-rel</head><p>For each query, we retrieve feedback passages P by using BM25. We then generate a candidate entity list E which consists of all the entity mentions present in the feedback passages. For every entity ei of the candidate entity list E, we create an entity-pair (ei, ej) with every other entity of the candidate list. For every entity-pair (ei, ej) we check the presence of both entities ei and ej in passage. If the entity-pair is present in the passage, then the score of the entity-pair is:</p><formula xml:id="formula_4" coords="9,227.92,366.49,154.90,24.73">fecr(ei, ej) = ∀P :e i ,e j ∈P 1 rank(P ) , i = j</formula><p>The score of each entity ei is calculated as:</p><formula xml:id="formula_5" coords="9,227.56,419.12,155.62,23.63">fe i = E j=1 (f (ei, ej) + f (ej, ei)) |E| , i = j</formula><p>We rank the entities based on the above score and select top 100 entities. For every passage in the feedback passages P , we check the existence of the top 100 entities and if the entity exists we add the score the entity with the initial BM25 score. We re-rank the passages based on the new score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UNH-trema-ecn</head><p>We start with an entity and passage run. For every query-entity pair, we create an Entity Context Document(ECD). To construct this ECD, we filter all passages which mention the entity and "stitch" them together into one "document" about the entity. All entities which occur in this ECD co-occur with the target entity (the entity the ECD is about). We derive a distribution over these co-occurring entities by using the frequency of these entities, that is, the number of times the entity occurs in the ECD. For every passage in an ECD, its score is equal to the sum of the frequency scores of the entities in the passage. We rank the passages using this score. This gives us a passage ranking for every query-entity pair. We call this ranking as a support passage ranking. We obtain a passage ranking from this support passage ranking by marginalizing over the entities.</p><p>MAP P@R MRR UNH-trema-rel 0.07 0.14 0.53 UNH-trema-ecn 0.07 0.14 0.51 UNH-trema-ent 0.08 0.14 0.54</p><p>Table <ref type="table" coords="10,254.29,195.25,3.87,8.74">3</ref>: Results from TREC CAST UNH-trema-ent We rank passages for a query-entity pair by the number of relevant entities in the passage. For example, if a passage p contains entities {e1, e2} and the entities {e1, e2, e3, e4} have been retrieved for the query q, then the score of p for each of the query-entity pairs is fqe 1 (p) = fqe 2 (p) = 2 because the passage has two entities in common with the list retrieved for q. This gives us a passage ranking for every query-entity pair. We call this ranking as a support passage ranking. We obtain a passage ranking from this support passage ranking by marginalizing over the entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">News</head><p>Entity-Ranking Task. In the news track, participants were given news articles and list of referenced entities in articles. The task is to rank the list of referenced entities according to the relevance of each entity to each article.</p><p>We submitted 1 automatic run UNH-Trema-News.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">UNH-Trema-News</head><p>As a pre-processing step for every passage in every article, we first annotate the passages with DBpedia Spotlight and store it in the index.</p><p>In the method, we first retrieve query-relevant feedback passages using BM25. We create a candidate entity list which consists of all the entities present in the feedback passages. For every entity in the candidate list, we generate an entity-pair, with every other entity in the candidate list.</p><p>We check the existence of the entity pair i.e. whether both entities of the entity-pair exists in the feedback passage. In simpler terms, we check the co-occurrence of entities in the feedback passages. If the entity-pair cooccurs in a passage, then we propagate the retrieval score of the passage as the entity-pair score.</p><p>To calculate the score of each entity, we accumulate the score of every entity-pair and average it with the length of the entity candidate list.</p><p>We take the given input list of entities of each query and check the existence of the each input entity in the ranked entities list, if the input entity exists then we take the entity score as the score of the input entity else 0 is assigned as the score. We rank the entities based on these scores. The results are given in ??.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,239.07,364.65,133.11,8.74;8,185.33,124.80,240.60,228.33"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Siamese architecture</figDesc><graphic coords="8,185.33,124.80,240.60,228.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,158.68,126.37,285.44,256.31"><head>Table 1 :</head><label>1</label><figDesc>Results of TREC CAR Y3 methods, where facet overlap and relevance are the evaluations metrics measured using for evaluating submissions. Bold values indicate the method with the best performance with respect to an evaluation metric. Asterisks indicate methods where there is no statistically significant difference to the best method with respect to standard deviation.</figDesc><table coords="5,158.68,208.73,285.44,173.95"><row><cell>Method</cell><cell>Facet Overlap</cell><cell>Relevance</cell></row><row><cell cols="2">UNH-bm25-ecmpsg 0.0295 ± 0.0065*</cell><cell>0.0931 ± 0.0175</cell></row><row><cell>UNH-bm25-rm</cell><cell>0.0658 ± 0.0114*</cell><cell>0.1297 ± 0.0170*</cell></row><row><cell>UNH-bm25-stem</cell><cell>0.0622 ± 0.0096*</cell><cell>0.1141 ± 0.0165</cell></row><row><cell>UNH-dl100</cell><cell>0.0403 ± 0.0072</cell><cell>0.1134 ± 0.0165*</cell></row><row><cell>UNH-dl300</cell><cell>0.0335 ± 0.0065</cell><cell>0.1093 ± 0.0159*</cell></row><row><cell>UNH-ecn</cell><cell>0.0016 ± 0.0010</cell><cell>0.0188 ± 0.0040</cell></row><row><cell>UNH-neural</cell><cell>0.0295 ± 0.0065</cell><cell>0.0931 ± 0.0139</cell></row><row><cell>UNH-qee</cell><cell>0.0427 ± 0.0079</cell><cell>0.1201 ± 0.0162*</cell></row><row><cell>UNH-tfidf-lem</cell><cell>0.0686 ± 0.0105*</cell><cell>0.1150 ± 0.0165*</cell></row><row><cell>UNH-tfidf-ptsim</cell><cell cols="2">0.0756 ± 0.0115* 0.1230 ± 0.0174*</cell></row><row><cell>UNH-tfidf-stem</cell><cell>0.0674 ± 0.0105*</cell><cell>0.1168 ± 0.0165*</cell></row><row><cell>passage using ELMo</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,133.77,388.56,349.74,115.84"><head>Table 2 :</head><label>2</label><figDesc>Results of the methods submitted for DL track</figDesc><table coords="8,133.77,416.13,349.74,88.27"><row><cell>Method</cell><cell>AP</cell><cell>mean NDCG</cell><cell>mean P@10</cell></row><row><cell>UNH-bm25</cell><cell>0.2565</cell><cell>0.5546</cell><cell>0.3465</cell></row><row><cell>UNH-exDL-bm25</cell><cell>0.0364</cell><cell>0.14</cell><cell>0.0605</cell></row><row><cell cols="4">dation f1 score stops increasing. The performance of the resulting model</cell></row><row><cell cols="4">is measured in terms of AUC score and the resulting best model is used</cell></row><row><cell cols="2">for the TRECCAR task.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,149.01,601.71,188.82,6.99"><p>Lucene can be found at https://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,149.01,611.22,328.47,6.99;2,133.77,620.68,30.59,6.99"><p>The script can be found at https://github.com/TREMA-UNH/car-convert-ranking-toordering</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>MAP P@R MRR UNH-trema-news 0.547 0.424 0.647</p><p>Table <ref type="table" coords="11,204.10,171.34,3.87,8.74">4</ref>: Results from TREC NEWS -EntityRanking Task</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,173.39,225.33,279.19,7.86;11,173.38,236.29,279.19,7.86;11,173.38,247.25,94.33,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,263.75,236.29,169.10,7.86">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,173.38,247.25,64.40,7.86">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
