<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,164.83,83.74,281.95,15.10">Webis at TREC 2019: Decision Track</title>
				<funder ref="#_RCBThHZ">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_tF7mQHs">
					<orgName type="full">DFG</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,79.62,128.96,112.73,10.59"><forename type="first">Alexander</forename><surname>Bondarenko</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wi enberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.07,128.96,55.47,10.59"><forename type="first">Maik</forename><surname>Fröbe</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wi enberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,317.26,128.96,83.34,10.59"><forename type="first">Vaibhav</forename><surname>Kasturia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wi enberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,435.32,128.96,74.87,10.59"><forename type="first">Michael</forename><surname>Völske</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.77,145.47,58.99,10.59"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.29,145.47,77.61,10.59"><forename type="first">Ma</forename><surname>Hias Hagen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wi enberg</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,164.83,83.74,281.95,15.10">Webis at TREC 2019: Decision Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E4261A2FFA56C34372F337E6BE4726B2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>is paper gives an overview of the Webis group's participation in the TREC 2019 Decision Track. Our idea is to axiomatically re-rank the top-k results of BM25F for those topics that seem to be argumentative. For the re-ranking, we use ve axioms that capture signals of argumentativeness and information credibility.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Our approach to the scenario of the TREC 2019 Decision Track focuses on two requirements that search results in a decision support scenario should ful ll: <ref type="bibr" coords="1,138.79,336.17,9.64,7.94" target="#b0">(1)</ref> the results should express a preference or state pros and cons in the area to be decided, and <ref type="bibr" coords="1,244.51,347.13,9.44,7.94" target="#b1">(2)</ref> the results should do so in a well-founded manner. ese requirements are particularly important for "high-stakes" decisions such as this year's Decision Track's medical topics. We address the rst requirement by trying to favor results that are more argumentative, and the second by trying to favor results that are more credible.</p><p>All our runs follow the same basic process of rst retrieving an initial top-k ranking using BM25F, and then potentially re-ranking these results using an axiomatic result re-ranking framework <ref type="bibr" coords="1,282.78,434.80,9.49,7.94" target="#b5">[6]</ref>. In particular, the re-ranking is addressing those queries that seem to ask for argumentative results. We thus combine three axioms focusing on the argumentativeness of the initial top-k search resultsalready employed in our last year's Common Core runs <ref type="bibr" coords="1,259.93,478.64,12.79,7.94" target="#b2">[3]</ref>-with two new axioms targeting search result credibility. With the judgments for our runs, we want to explore di erent weighting schemes for aggregating the axioms' ranking preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">WEBIS DECISION TRACK RUNS</head><p>We describe our approach to identify argumentative queries and introduce the axioms and the weighting schemes used to re-rank the top-k BM25F results of argumentative queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Identifying Argumentative eries</head><p>We manually inspected the titles of the topics used in this year's Decision Track and concluded that all of them could be labeled as argumentative queries (i.e., relevant results should contain some form of argumentation). Moreover, since all topics are medical topics, information credibility is of particular concern. us, our proposed approach employs an axiomatic re-ranking which tries to favor argumentative and credible results. is di ers from our last year's TREC Common Core Track runs where we did not consider the information credibility aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Obtaining Search Results</head><p>For each topic, we submit the title as a query to an Elasticsearch index that contains four elds per document: (1) title, (2) main content, (3) meta description, and (4) keywords extracted from the meta description. All elds are extracted during the indexing pipeline of Elastic ChatNoir <ref type="bibr" coords="1,380.94,319.19,9.43,7.94" target="#b1">[2]</ref>. We use the default BM25F similarity of Elasticsearch and assign equal weight to all four elds, but manipulate this initial ranking with respect to credibility as follows.</p><p>By manual assessment of the OpenDNS categories, <ref type="foot" coords="1,520.27,349.92,3.38,6.44" target="#foot_0">1</ref> we identi ed the following as credible or at least related to the Decision Track guidelines: : Research/Reference, Educational Institutions, Government, Health and Fitness, News/Media, and Non-Profits. In the original BM25F ranking, we thus move to the top the documents that belong to any of those "credible" categories (the OpenDNS service assigns some categories to each URL) while keeping the relative order of these "credible" documents according to their scores. In e ect, results with URLs not mapped to any of the "credible" OpenDNS categories are ranked below the ones from "credible" hosts independent of their original BM25F score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Argumentative Unit Detection</head><p>Our idea is to include information about argumentativeness and credibility in a re-ranking pipeline. To this end we try to identify argumentative units in result documents by using the two sequence tagging models TARGER <ref type="bibr" coords="1,408.42,529.40,10.42,7.94" target="#b3">[4]</ref> (available as an API) and MARGOT <ref type="bibr" coords="1,547.77,529.40,10.43,7.94" target="#b7">[8]</ref> (available as a library).</p><p>ese models take a raw text as input and return the text tagged with the information where argument premises and claims start and end. e taggers' detections could be either combined, intersected, or just the detections of an individual tagger could be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Identifying Medical Entities</head><p>To identify argumentative units mentioning more "credible" sources of medical information, we want to identify "medical sources" in the form of named entities related to medicine. As the basis of a simple rule-based system, we create a list of keywords commonly used in the names of medical institutions (e.g., hospital, institute, research center) and medical professions / degrees (e.g., Dr., MBBS, PhD). In addition to medical institutions and professions, we also add to the list the names of news channels and newspapers found on Wikipedia since the track guidelines state that information coming from news sources should be considered as credible. Any match of the medical keywords or a newspaper / news channel will thus be viewed as a mention of a credible "medical entity". e underlying idea of using credibility in the re-ranking then is to favor documents from the initial BM25F results that contain argumentative units mentioning medical entities as sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Re-Ranking Axioms</head><p>We use ve axioms to re-rank the top-50 baseline results (BM25F + re-ranking according to "credible" OpenDNS domains). For every pair of documents in the top-50 results, the re-ranking computes a ranking preference based on a collaborative voting of the axioms.</p><p>e basic idea of axiomatic thinking in information retrieval [1] is to identify axioms (i.e., constraints) that good retrieval models should ful ll. Employing an axiomatic re-ranking approach <ref type="bibr" coords="2,267.50,264.13,9.27,7.94" target="#b5">[6]</ref>, our last year's TREC Common Core Track runs showed some promising improvements for some argumentative queries <ref type="bibr" coords="2,233.63,286.05,9.52,7.94" target="#b2">[3]</ref>.</p><p>e axioms compare argumentative units (cf. Section 2.3) in the initial baseline results. We extend this axiom set by two credibility axioms and directly embed them in the axiomatic re-ranking pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Axioms Capturing Argumentativeness.</head><p>Axiom ArgUC (Argumentative Units Count). e general idea of the ArgUC axiom is to favor documents that contain more argumentative units.</p><p>Formalization. Let q be an argumentative query, d 1 and d 2 be two retrieved documents, count Arg (d) be the number of argumentative units in document d, and let ≈ 10% indicate "equality" up to a 10% di erence. If length(d</p><formula xml:id="formula_0" coords="2,53.80,419.33,240.05,20.97">1 ) ≈ 10% length(d 2 ) and if count Arg (d 1 ) &gt; count Arg (d 2 ), then d 1 &gt; ArgUC d 2 .</formula><p>Axiom QTArg ( ery Term Occurrence in Argumentative Units). Retrieved documents usually consist of argumentative and nonargumentative units or text passages.</p><p>e general idea of the QTArg axiom is to favor documents where the query terms appear closer to (or be er: in) argumentative units.</p><p>Formalization. Let q = {t } be an argumentative single-term query, d 1 and d 2 be two retrieved documents, and let Ar d be the set of argumentative units of a document d.</p><formula xml:id="formula_1" coords="2,53.53,526.51,240.51,32.55">If length(d 1 ) ≈ 10% length(d 2 ) and if t ∈ A for some A ∈ Ar d 1 but q A for all A ∈ Ar d 2 , then d 1 &gt; QTArg d 2 .</formula><p>Axiom QTPArg ( ery Term Position in Argumentative Units). Following the general observation that in relevant documents the query terms occur closer to the beginning <ref type="bibr" coords="2,207.38,587.23,13.42,7.94" target="#b9">[10,</ref><ref type="bibr" coords="2,223.05,587.23,10.07,7.94" target="#b11">12]</ref>, the QTPArg axiom will favor documents where the rst appearance of a query term in an argumentative unit is closer to the beginning of the document.</p><p>Formalization. Let q = {t } be an argumentative single-term query, d 1 and d 2 be two retrieved documents, and let the rst position in an argumentative unit of a document d where the term t appears be denoted by</p><formula xml:id="formula_2" coords="2,53.35,664.45,240.70,33.20">1 st position(t, Ar d ). If length(d 1 ) ≈ 10% length(d 2 ) and if 1 st position(t, Ar d 1 ) &lt; 1 st position(t, Ar d 2 ), then d 1 &gt; QTPArg d 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Axioms Capturing Credibility.</head><p>Axiom MEArg (Medical Entities in Argumentative Units). Following the heuristic that the source of an argument ma ers, the MEArg axiom will favor documents in which argumentative units contain "medical entities" (cf. Section 2.4).</p><p>Formalization. Let q be an argumentative query, d 1 and d 2 be two retrieved documents, and let the number of identi ed medical entities in the argumentative units of a document d be denoted by numberME(Ar d ).</p><formula xml:id="formula_3" coords="2,317.96,182.14,240.24,21.59">If length(d 1 ) ≈ 10% length(d 2 ) and if numberME(Ar d 1 ) &gt; numberME(Ar d 2 ), then d 1 &gt; MEArg d 2 .</formula><p>Axiom aSLDoc (Average Sentence Length in Document). Following the observations that bad readability is one component of bad information quality and thus reduced credibility <ref type="bibr" coords="2,505.25,231.91,10.68,7.94" target="#b4">[5]</ref> and that a simple measure for readability is the average sentence length <ref type="bibr" coords="2,546.56,242.87,9.47,7.94" target="#b4">[5]</ref>, the aSLDoc axiom will favor documents with average sentence length between 12-20 words since this is viewed as a simplistic indicator of good readability <ref type="bibr" coords="2,424.39,275.74,9.33,7.94" target="#b8">[9,</ref><ref type="bibr" coords="2,435.96,275.74,10.13,7.94" target="#b10">11]</ref>.</p><p>Formalization. Let q be an argumentative query, </p><formula xml:id="formula_4" coords="2,499.34,288.48,4.38,8.83">d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Axiom Weights</head><p>In addition to the ve argumentativeness and credibility axioms, we also employ an axiom ORIG <ref type="bibr" coords="2,430.69,379.01,9.27,7.94" target="#b5">[6]</ref>. e ORIG axiom simply returns the preferences corresponding to the baseline retrieval system's ranking-BM25F + OpenDNS re-ranking in our case (which is different to our previous year's baseline <ref type="bibr" coords="2,454.23,411.89,9.01,7.94" target="#b2">[3]</ref>). e six di erent axioms (including ORIG) are weighted to linearly combine the respective preference matrices analog to the original axiomatic re-ranking pipeline <ref type="bibr" coords="2,350.56,444.76,9.52,7.94" target="#b5">[6]</ref>. e weight of an axiom then directly in uences its impact on the document re-ranking-the more weight one axiom has compared to the others, and the more o en its precondition is ful lled for document pairs, the more impact it has on the nal re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WEBIS RUNS</head><p>Our runs were simply created to get as many votes as possible for the baseline retrieval system's top-50 results (BM25F + OpenDNS reranking). e goal is to compare di erent weighting schemes in the re-ranking which could even be schemes not imagined at the time of taking part in the Decision Track. To this end, every run tried to include in its top-10 and top-20 results some results from the baseline's top-50 that were not already included in another run. Based on the judgments obtained for the baseline system's top-50 results, we wanted to examine the following three axiom weighting schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Axiom Weighting Schemes</head><p>e six di erent axioms (including ORIG) are weighted to linearly combine the respective preference matrices analog to the original axiomatic re-ranking pipeline, where the weight then in uences the axiom's impact on the document re-ranking. A weighting scheme may be combined with the argumentative units detected by TARGER or MARGOT <ref type="bibr" coords="3,154.49,86.80,9.44,7.94" target="#b3">[4,</ref><ref type="bibr" coords="3,167.05,86.80,6.29,7.94" target="#b7">8]</ref>. We apply the following three weighting schemes.</p><p>Equal Weights (EW). All axioms get the same weight. is way, any agreement of the preferences of a pair of the new axioms may overrule the ORIG axiom preference when the no other axiom "supports" the ORIG preference.</p><p>Majority Voting (MV). e axioms are assigned weights such that document pairs are re-ranked i the majority of the new axioms (at least 3 out of 5 axioms) agree to overrule the ORIG preference.</p><p>Total Agreement (TA). e axioms are assigned weights such that document pairs are re-ranked only when all the new axioms agree. It is not necessary for all axioms to have the same weight, although all of them have to be in agreement to overrule the ORIG axiom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>We compare the di erent axiomatic re-rankings to the baseline ranking (BM25F+OpenDNS ranking) using three di erent metrics: nDCG@3, Precision@1 and NLRE@all (NLRE <ref type="bibr" coords="3,219.57,291.53,10.42,7.94" target="#b6">[7]</ref> combines aspects of relevance and credibility).</p><p>Table <ref type="table" coords="3,87.30,313.45,4.25,7.94">1</ref> shows the results for each topic and an average for all topics-grouped by weighting scheme and argumentative unit tagger. e axiomatic re-ranking with any weighting scheme and any tagger somewhat improves the NLRE scores (slight exception: topic 27). Argument unit tagging with MARGOT yields slightly be er NLRE scores than TARGER.</p><p>e nDCG and precision metrics are compared at lower depths to emphasize the importance of the top-most results in web search scenarios and since precision@1 also corresponds to the case of building a medical question answering system. Using the TA weighting scheme (total agreement) with both argument taggers shows a slight improvement in precision. In contrast, nDCG@3 substantially decreases a er axiomatic re-ranking.</p><p>e TA weighting scheme (total agreement) seems to be er suited than the MV (majority voting) and the EW (equal weights) schemes. A reason could be that TA (total agreement) re-ranking decisions come with a higher "con dence" to change the original document ordering, while less agreement is needed in the other schemes. Some more thorough investigations and weighting ne tuning might help to improve the ranking quality further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We have used an axiomatic re-ranking based on ve axioms that aim to capture basic ideas about a search result's argumentativeness and credibility for queries that address decision making in a medical context. Our underlying hypothesis is that such queries will bene t from search results coming from trustworthy sources that argumentatively compare pros and cons of di erent options.</p><p>e evaluation of our re-ranking approach using the judgments gathered for the baseline retrieval systems' top results (spli ed over our runs) show that our current set of axioms is not really su cient to improve standard scores of nDCG@3 or Precision@1 over a BM25F baseline but that some improvements in terms of NLRE are possible.</p><p>Interesting steps for future work include: (1) query expansion with synonyms and aliases of the query terms, (2) be er medical entity identi cation via a more sophisticated medical entity recognizer, (3) improved weighting schemes based on learning axiom weights, (4) be er detection of argumentative queries by deeper investigation of the relevance judgments, and (5) formulation of more sophisticated ideas to capture argumentativeness and credibility of documents.</p><p>Table <ref type="table" coords="4,78.04,84.49,3.45,7.94">1</ref>: Evaluation results on the individual topics and averaged for BM25F+OpenDNS ltering as the baseline retrieval system (B) and our re-ranking approaches with di erent weighting schemes: total agreement (TA), majority voting (MV) and equal weights (EW) using the two di erent argument taggers MARGOT and TARGER. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,317.96,288.48,240.41,53.84"><head></head><label></label><figDesc>1 and d 2 be two retrieved documents, and let sentLength(d) be the average sentence length (in words) of a document d. If length(d 1 ) ≈ 10% length(d 2 ) and if 12 ≤ sentLength(d 1 ) ≤ 20 and sentLength(d 2 ) &lt; 12 or sentLength(d 2 ) &gt; 20, then d 1 &gt; aSLDoc d 2 .</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,320.88,701.19,139.42,6.18"><p>h ps://community.opendns.com/domaintagging/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>is work has been partially supported by the <rs type="funder">DFG</rs> through the project "<rs type="projectName">AC A: Answering Comparative estions with Arguments</rs>" (grant <rs type="grantNumber">HA 5851/2-1</rs>) as part of the <rs type="programName">priority program</rs> "<rs type="projectName">RATIO: Robust Argumentation Machines</rs>" (<rs type="grantNumber">SPP 1999</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_tF7mQHs">
					<idno type="grant-number">HA 5851/2-1</idno>
					<orgName type="project" subtype="full">AC A: Answering Comparative estions with Arguments</orgName>
					<orgName type="program" subtype="full">priority program</orgName>
				</org>
				<org type="funded-project" xml:id="_RCBThHZ">
					<idno type="grant-number">SPP 1999</idno>
					<orgName type="project" subtype="full">RATIO: Robust Argumentation Machines</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,334.39,242.52,224.99,6.18;3,334.39,250.49,223.81,6.18;3,334.39,258.46,64.28,6.18" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,548.55,242.52,10.83,6.18;3,334.39,250.49,173.38,6.18">Axiomatic inking for Information Retrieval: And Related Tasks</title>
		<author>
			<persName coords=""><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefano</forename><surname>Mizzaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,519.76,250.50,38.44,6.16;3,334.39,258.47,28.45,6.16">Proceedings of SIGIR 2017</title>
		<meeting>SIGIR 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1419" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,266.43,224.89,6.18;3,334.39,274.40,223.81,6.18;3,334.39,282.37,97.02,6.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,334.39,274.40,212.79,6.18">Elastic ChatNoir: Search Engine for the ClueWeb and the Common Crawl</title>
		<author>
			<persName coords=""><forename type="first">Janek</forename><surname>Bevendor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ma</forename><surname>Hias Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Po Hast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,334.39,282.38,67.68,6.16">Proceedings of ECIR 2018</title>
		<meeting>ECIR 2018</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="820" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,290.34,224.58,6.18;3,334.39,298.31,223.81,6.18;3,334.18,306.28,99.54,6.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,452.82,298.31,105.38,6.18;3,334.18,306.28,14.91,6.18">Webis at TREC 2018: Common Core Track</title>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ma</forename><surname>Hias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hagen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,361.41,306.29,69.52,6.16">Proceedings of TREC 2018</title>
		<meeting>TREC 2018</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,314.25,224.58,6.18;3,334.39,322.22,224.64,6.18;3,334.39,330.19,224.89,6.18;3,334.23,338.16,24.81,6.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,531.31,322.22,27.71,6.18;3,334.39,330.19,121.52,6.18">TARGER: Neural Argument Mining at Your Fingertips</title>
		<author>
			<persName coords=""><forename type="first">Artem</forename><surname>Chernodub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oleksiy</forename><surname>Oliynyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philipp</forename><surname>Heidenreich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Ma Hias Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Panchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,467.70,330.20,85.61,6.16">Proceedings of ACL 2019 (Demos</title>
		<meeting>ACL 2019 (Demos</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,346.13,224.99,6.18;3,334.39,354.10,223.82,6.18;3,334.05,362.07,208.55,6.18" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,539.92,346.13,19.46,6.18;3,334.39,354.10,223.82,6.18;3,334.05,362.07,110.43,6.18">Empirical Studies Assessing the ality of Health Information for Consumers on the World Wide Web: A Systematic Review</title>
		<author>
			<persName coords=""><forename type="first">Gunther</forename><surname>Eysenbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oliver</forename><surname>Kuss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eun-Ryoung</forename><surname>Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,450.12,362.08,17.80,6.16">JAMA</title>
		<imprint>
			<biblScope unit="volume">287</biblScope>
			<biblScope unit="page" from="2691" to="2700" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,370.04,223.82,6.18;3,334.39,378.01,163.18,6.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,529.35,370.04,28.85,6.18;3,334.39,378.01,51.14,6.18">Axiomatic Result Re-Ranking</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Ma Hias Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Göring</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,398.04,378.02,70.19,6.16">Proceedings of CIKM 2016</title>
		<meeting>CIKM 2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="721" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,385.98,224.99,6.18;3,334.39,393.95,224.89,6.18;3,334.39,401.92,18.33,6.18" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,513.63,385.98,45.75,6.18;3,334.39,393.95,141.87,6.18">Evaluation Measures for Relevance and Credibility in Ranked Lists</title>
		<author>
			<persName coords=""><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Birger</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,487.92,393.96,68.62,6.16">Proceedings of ICTIR 2017</title>
		<meeting>ICTIR 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,409.89,223.81,6.18;3,334.39,417.86,128.58,6.18" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="3,436.53,409.89,121.67,6.18;3,334.39,417.86,19.04,6.18">MARGOT: A Web Server for Argumentation Mining</title>
		<author>
			<persName coords=""><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,359.11,417.87,48.66,6.16">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="292" to="303" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,425.83,210.14,6.18" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Markel</surname></persName>
		</author>
		<title level="m" coord="3,391.01,425.83,132.94,6.18">Technical Communication. Bedford/St Martin&apos;s</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,433.80,223.81,6.18;3,334.39,441.77,223.81,6.18;3,334.39,449.74,68.06,6.18" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="3,489.66,433.80,68.54,6.18;3,334.39,441.77,172.90,6.18">Learning to Match Using Local and Distributed Representations of Text for Web Search</title>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,519.45,441.78,38.75,6.16;3,334.39,449.75,32.23,6.16">Proceedings of WWW 2017</title>
		<meeting>WWW 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,334.39,457.71,224.25,6.18;3,334.39,465.68,161.51,6.18" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Casi</forename><surname>Newell</surname></persName>
		</author>
		<ptr target="//www.aje.com/en/arc/editing-tip-sentence-length/" />
		<title level="m" coord="3,393.07,457.71,127.90,6.18">Editing Tip: Sentence Length. AJE Scholar</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>online post) h ps</note>
</biblStruct>

<biblStruct coords="3,334.39,473.65,223.81,6.18;3,334.39,481.62,183.53,6.18" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="3,459.85,473.65,98.35,6.18;3,334.39,481.62,72.15,6.18">Enhancing Relevance Scoring with Chronological Term Rank</title>
		<author>
			<persName coords=""><forename type="first">Adam</forename><forename type="middle">D</forename><surname>Troy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guo-Qiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,419.11,481.63,69.46,6.16">Proceedings of SIGIR 2007</title>
		<meeting>SIGIR 2007</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="599" to="606" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
