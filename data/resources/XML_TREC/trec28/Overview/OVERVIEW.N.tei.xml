<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,186.61,164.85,238.03,15.12">TREC 2019 News Track Overview</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-03">March 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,187.03,197.33,60.94,10.48"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
						</author>
						<author>
							<persName coords="1,256.94,197.33,78.42,10.48"><forename type="first">Shudong</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName coords="1,345.37,197.33,78.84,10.48;1,291.65,211.28,27.96,10.48"><forename type="first">Donna</forename><forename type="middle">Harman</forename><surname>Nist</surname></persName>
						</author>
						<title level="a" type="main" coord="1,186.61,164.85,238.03,15.12">TREC 2019 News Track Overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-03">March 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">D96A113BEEEA9A8A3E13ED549565C055</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The News track focuses on information retrieval in the service of helping people read the news. In 2018, in cooperation with the Washington Post 1 , we released a new collection of nearly 600,000 news articles, and crafted two tasks related to how news is presented on the web: background linking and entity ranking. This second iteration of the track continues these two tasks with minor updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>While news content has been a common genre in IR experimentation for a very long time, the evaluation tasks in IR have rarely if ever supported the "news user" -a consumer of news that is not an analyst. According to Pew Research studies, in 2016, roughly 38% of Americans got their news online, with the fraction increasing for younger consumers, 2 and in 2018 93% of American adults get at least some of their news online. 3 Pew further found in 2017 that at least two-thirds of Americans get news at least occasionally through social media. 4  Moreover, since online delivery of news has shifted the focus away from the provider or publisher towards the story, news production has been dramatically democratized. If everyone can produce professional looking news, then understanding the context and background of information becomes a harder task for the consumer. In conjunction with The Washington Post, we are developing tasks around how news is presented on the web and thinking about how to enhance that learning experience.</p><p>The initial run of the track in TREC 2018 introduced two tasks: recommending articles to read as background in the context of the article a user is 1 Certain companies and/or products are identified in this paper in order to specify the experimental procedure adequately. Such identification is not intended to imply recommendation or endorsement by NIST, nor is it intended to imply that the company or product identified are necessarily the best available for the purpose.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The data for the News track is the TREC Washington Post Collection. <ref type="foot" coords="2,448.08,228.97,3.97,6.12" target="#foot_0">5</ref> This collection contains five years of articles, from 2012 to 2017. The 595,037 documents in the collection comprise all Washington Post content published in that interval: articles, columns, and blogs.</p><p>The documents are stored in "JSON-lines" format, that is, each document is a single long line of JSON. The articles are broken into content paragraphs, with interspersed media such as images and videos referenced by URL. Those URLs point back to the Washington Post website and according to the Post should persist at those URLs for the foreseeable future. This unique multimedia article format is novel for TREC but this track is not yet exploring it.</p><p>There are quite a few duplicate documents in the collection, because at times the Post will republish an article, and the provenance history is not represented in the data. We cleaned the collection to remove documents with identical content (including the document identifier). There are numerous other nearduplicates, and the overview this year considers their impact.</p><p>With thanks due to Laura Dietz, we provided a CAR-track formatted dump of Wikipedia articles as of August 2017, the end of the collection epoch. The Wikipedia dump was primarily intended for the entity ranking task but participants were free to use it however they liked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background Linking task</head><p>The goal of the background linking task is to develop evaluation data to support researchers in developing systems that can help users contextualize news articles as they are reading them. News websites nearly always link to related articles in a sidebar, at the end of an article, from within the text of the article, or all three. We want to look at a particular case for linking: given that the user is reading a specific article (the query article), algorithms should recommend articles that this person should read next that are the most useful for providing context and background for the query article. The background article can be dated before or after the query article, because we are considering the use case where the user is reading the query article now, irrespective of when it was published, and the system is recommending background reading live at the time when the user is reading the query article. Sometimes the Post will develop a link block in the context of a large story, for example the block shown in Figure <ref type="figure" coords="3,302.07,310.78,4.98,8.74" target="#fig_0">1</ref> for a story during the Trump impeachment inquiry, a significant news event with many details and sub-events. This task imagines automatically providing links like these, for any article the user might be reading.</p><p>It's important to note that links present in the Washington Post article collection are not training data for this task. In our conversations with the Post, their current practice is largely driven by the author of the article and does not follow any fixed guidelines or goal. Hence, we are designing this task as a specific kind of news recommendation task that would be useful in any news reading context, including the Post's website.</p><p>From our conversations with Post journalists about linking for background and context, every author has their own guidelines in their head, but three common rules emerged:</p><p>1. No wire service articles. (That is, from Associated Press (AP), AFP, etc) 2. No opinion or editorials.</p><p>3. The list of links should be diverse.</p><p>The corpus should not contain any wire service articles, so (1) is taken care of for free.<ref type="foot" coords="3,178.19,548.31,3.97,6.12" target="#foot_1">6</ref> For (2), we decree that articles from the "Opinion", "Letters to the Editor", or "The Post's View" sections, as labeled in the "kicker" field, are not relevant. (3) is complicated as we are not sure we yet have a good understanding of diversity in the news recommendation context.</p><p>The assessors following NIST's standard adhoc topic development process, which involves scouting the collection for a topic, loosely estimating the number of relevant articles that might exist, and crafting a title, description, and narrative statement. As a final step, the assessor selected a relevant article that they had found during the development process as the query article for the topic. A total of sixty topics were developed and released for the evaluation. &lt;top&gt; &lt;num&gt; Number: 826 &lt;/num&gt; &lt;docid&gt;96ab542e-6a07-11e6-ba32-5a4bf5aad4fa&lt;/docid&gt; &lt;url&gt;https://www.washingtonpost.com/sports/nationals/the-minorleagues-life-in-pro-baseballs-shadowy-corner/2016/08/26/96ab542e-6a07-11e6-ba32-5a4bf5aad4fa_story.html&lt;/url&gt; &lt;/top&gt; The topic field "Docid" references the "id" field in the Washington Post corpus documents. "Url" references the "article url" field in the documents. Both indicate the query article. In the first running of the track last year, the topics were shared with the Common Core track and some of those were re-used from previous TRECs, but this year all topics are new.</p><p>The relevance scale used by the NIST assessors was: 0. The linked document provides little or no useful background information.</p><p>1. The linked document provides some useful background or contextual information that would help the user understand the broader story context of the query article.</p><p>2. The document provides significantly useful background . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>The document provides essential useful background . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>The document MUST appear in the sidebar otherwise critical context is missing.</p><p>Systems retrieved up to 100 documents per topic and returned results in the standard trec eval format. The top 50 documents from each run were pooled for assessment. Three topics, 868, 877, and 881, were not fully judged in the allotted assessment period, so the evaluation is computed over 57 topics.</p><p>The primary metric for the background linking task is nDCG@5, with the gain value as 2 r where r is the relevance level from the scale above, and the zero relevance level contributing no gain. This is implemented for trec eval by having the relevance levels in the qrels file be the gain values for nDCG. The evaluation reported all the standard trec eval measures to a depth of 100. Figure <ref type="figure" coords="4,447.78,566.32,4.98,8.74" target="#fig_1">2</ref> plots the nDCG@5 scores.</p><p>Nine teams participated in the background linking task:</p><p>• cityuni (City University of London)</p><p>• CLAC NEWS 2019 (Computational Linguistics at Concordia)</p><p>• ICTNET (Institute of Computing Technology, Chinese Academy of Sciences) q q q 0.00  Runs with overlapping boxes may not be statistically significantly different from one another.</p><p>• QU (Qatar University)</p><p>• QUARTZ ITN (University of Padova)</p><p>• RUIR (Radboud University Data Science)</p><p>• Smith (Smith College)</p><p>• udel fang (University of Delaware (InfoLab)).</p><p>• UNC SILS (University of North Carolina at Chapel Hill)</p><p>• YQW2018CGroup (Big Data and Information Retrieval Group, Wuhan University)</p><p>28 runs were submitted for the background linking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Duplicate Documents</head><p>The Washington Post collection has many duplicate documents, covering a wide range of duplication from exact byte-match entries down to the document identifier up to copies and insertions. In 2018, NIST released an updated "v2" of the collection that removed exact duplicates, shrinking the collection from 608,180 documents to 595,037. The 2019 Conversational Assistance track published a list of near-duplicate paragraphs in the collection, as measured by Jaccard similarity of tokens.<ref type="foot" coords="6,219.97,387.29,3.97,6.12" target="#foot_2">7</ref> Duplicate documents can be problematic for evaluation: systems index multiple copies of the content, and may return duplicate results in the ranking, which can in turn lead to inconsistencies in relevance assessments if those documents are not cross-checked. In the case of near-duplicates, where the content may not exactly match due to edits, containment, copying, or other reasons, near-duplicate clusters need to be checked manually to ensure that the relevance judgment given is appropriate to all members of the cluster.</p><p>To investigate this phenomenon in the Post collection, we implemented document fingerprinting using minhashing, and fast similarity search using localitysensitive hashing, following the work of Broder and colleagues as described by Leskovec et al. <ref type="bibr" coords="6,199.69,520.37,9.96,8.74" target="#b0">[1]</ref>. Our implementation uses overlapping nine-token n-grams as shingles, where tokens are taken from the "content" blocks of the documents only, separated by whitespace with nonword characters and HTML tags removed with simple regular expressions. We declare documents to be near-duplicates if their Jaccard similarity exceeds 0.84. We found that including metadata such as authors, titles, and kickers in the content hashing increased false positives, because of empty documents and very short documents in the collection. Manual inspection of true positives and true negatives showed that we found duplicate articles effectively, without mistakenly combining articles that were not duplicates but were very similar, like weekly lists of local events. Our set of 517,530 equivalence classes is posted on the TREC website.</p><p>We first resolved any relevance judgment conflicts within a near-duplicate class. We did this by manually reviewing all possible conflicts and resolving them as consistently as possible within the judgment of the assessor. In future years, we plan to sort documents in the pool according to near-duplicate class, so that near-duplicates are judged together in clumps. These resolved judgments were reported as "final" results to participants. The Kendall's tau rank correlation of the system ranking before and after duplicate resolution was 0.95 for nDCG and 0.99 for MAP.</p><p>We then ran an experimental evaluation where we removed near-duplicates from both the relevance judgments and the runs. Near duplicates in an equivalence class were dropped except for a single "cluster representative", and the runs were modified such that the first occurrence of any document in a cluster was replaced by the representative, and later occurrences of documents in that cluster were dropped. The tau correlation between the final official evaluation and this "deduplicated" evaluation was 0.96 for nDCG and 0.87 for MAP.</p><p>This is what would happen if all participants had our near-duplicate cluster list and removed duplicates after retrieval, but actual results from systems could be different if deduplication happens at indexing time since corpus statistics could change. In any event, the evaluation script needs to know the mapping to compute scores because we don't know which member of a class a system will retrieve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Entity Ranking Task</head><p>In addition to providing links to articles that give the reader background or contextual information, journalists sometimes link mentions of concepts, artifacts, and entities to internal or external pages with in depth information that will help the reader better understand the article. For this second task, entity ranking, we automatically extracted named entities from query articles using Stanford's CoreNLP web service<ref type="foot" coords="7,278.77,480.03,3.97,6.12" target="#foot_3">8</ref> , and manually linked those entities to the provided Wikipedia dump. The task for systems was to rank the entities in order of importance -if providing a link to that entity would support the reader's understanding of the article or its broader context.</p><p>Part of the entity ranking task version of topic 826 from above is as follows: Systems returned a ranking of the entity IDs in the topic, using whatever resources they chose. The NIST assessors judged the entire set of entities for each topic on the following scale: 0. The linked entity provides little or no useful background information.</p><formula xml:id="formula_0" coords="7,133.77,550.07,26.15,8.30">&lt;top&gt;</formula><p>1. The linked entity provides some useful background or contextual information that would help the user understand the broader story context of the query article.</p><p>2. The entity link provides significantly useful background ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>The entity link provides essential useful background ... 4. The entity link MUST appear in the sidebar otherwise critical context is missing.</p><p>For eight of the 60 topics, no entities were judged to be useful, and so the evaluation is reported over 52 topics. Eight groups submitted 22 entity ranking runs:</p><p>• CMU (Carnegie Mellon University (Callan))</p><p>• ICTNET (Institute of Computing Technology, Chinese Academy of Sciences)</p><p>• OzUNLP (Ozyegin University)</p><p>• RUIR (Radboud University Data Science) q q q q q q q q q 0.25  The plot illiustrates the median and interquartile distance across topics. Runs with overlapping boxes may not be statistically significantly different from one another.</p><p>• TREMA-UNH (University of New Hampshire)</p><p>• UQ (University of Queensland)</p><p>• cityuni (City University of London)</p><p>Figure <ref type="figure" coords="10,180.29,187.74,4.98,8.74" target="#fig_2">3</ref> shows scores for the runs ordered by average nDCG@r, where r is the number of relevant entities.</p><p>While last year's entity ranking evaluation reported average precision as the primary metric, this year we are reporting nDCG@r so as to take into account the different gain values for different entities. The Kendall's correlation τ = 0.91 between nDCG@5 and nDCG@r, and τ = 0.88 between nDCG@r and average precision. The lower correlation with MAP is an indication that there is an effect from the gain values on the scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The second year of the News track continued the background linking and entity ranking tasks to complete a combined set of more than 100 topics for these tasks. Last year we felt that the relevance assessment scale was somewhat experimental, but at this point the scale feels appropriate for the task and the assessors understand it.</p><p>Unfortunately, this year we were not able to include an adhoc task. The assessors composed adhoc topics, but we felt it was too confusing to judge according to both the adhoc and background linking criteria at the same time, and we did not have resources for two assessment passes over the pools. Thus whether the background linking task requires something beyond good adhoc ranking is an outstanding question for research.</p><p>The track will continue in TREC 2020, and plans for the track will be discussed in the planning workshop.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,133.77,254.49,343.71,8.74;3,133.77,266.44,205.06,8.74;3,176.73,124.80,257.79,114.57"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A set of manually-curated background links from the Washington Post website (image taken on March 16, 2020).</figDesc><graphic coords="3,176.73,124.80,257.79,114.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,133.77,556.85,343.71,8.74;5,133.77,568.81,343.71,8.74;5,133.77,580.76,343.71,8.74;5,133.77,592.72,54.27,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Boxplots for nDCG@5 score for each run in the background linking task. The plot illiustrates the median and interquartile distance across topics. Runs with overlapping boxes may not be statistically significantly different from one another.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,133.77,556.85,343.71,8.74;9,133.77,568.81,343.71,8.74;9,133.77,580.76,343.71,8.74;9,133.77,592.72,36.00,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Boxplots for nDCG@r score for each run in the entity ranking task. The plot illiustrates the median and interquartile distance across topics. Runs with overlapping boxes may not be statistically significantly different from one another.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,133.77,562.02,339.97,91.98"><head></head><label></label><figDesc>Note the "docid" and "url" sections are identical to those in the background linking task. Following those sections is a list of entities, linked to Wikipedia if the link is present in the dump. Every topic has at least three entities. Topic 826 has 35. Topic 838 has the most with 38 entities. This is somewhat smaller than last year, where the largest topic had 54 entities mentioned as identified by Stanford CoreNLP.</figDesc><table coords="7,133.77,562.02,339.97,91.98"><row><cell>&lt;mention&gt;Richmond&lt;/mention&gt;</cell></row><row><cell>&lt;link&gt;enwiki:Richmond,%20Virginia&lt;/link&gt;</cell></row><row><cell>&lt;/entity&gt;</cell></row><row><cell>&lt;entity&gt;</cell></row><row><cell>&lt;id&gt; 826.2 &lt;/id&gt;</cell></row><row><cell>&lt;mention&gt;Boston College&lt;/mention&gt;</cell></row><row><cell>&lt;link&gt;enwiki:Boston%20College&lt;/link&gt;</cell></row><row><cell>&lt;/entity&gt;</cell></row><row><cell>&lt;entity&gt;</cell></row><row><cell>&lt;id&gt; 826.3 &lt;/id&gt;</cell></row><row><cell>&lt;mention&gt;Connecticut&lt;/mention&gt;</cell></row><row><cell>&lt;link&gt;enwiki:Connecticut&lt;/link&gt;</cell></row><row><cell>&lt;/entity&gt;</cell></row><row><cell>...</cell></row><row><cell>&lt;num&gt; Number: 826 &lt;/num&gt;</cell></row><row><cell>&lt;docid&gt;96ab542e-6a07-11e6-ba32-5a4bf5aad4fa&lt;/docid&gt;</cell></row><row><cell>&lt;url&gt;https://www.washingtonpost.com/sports/nationals/the-minor-</cell></row><row><cell>leagues-life-in-pro-baseballs-shadowy-corner/2016/08/26/96ab542e-</cell></row><row><cell>6a07-11e6-ba32-5a4bf5aad4fa_story.html&lt;/url&gt;</cell></row><row><cell>&lt;entities&gt;</cell></row><row><cell>&lt;entity&gt;</cell></row><row><cell>&lt;id&gt; 826.1 &lt;/id&gt;</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="2,149.01,651.52,143.97,6.64"><p>https://trec.nist.gov/data/wapost/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="3,149.01,652.50,328.46,6.99;3,133.77,661.96,88.74,6.99"><p>There are actually some wire service articles, and we plan to cull them out in a future release of the collection.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2" coords="6,149.01,657.84,328.47,7.21;6,133.77,667.30,54.34,6.99"><p>http://boston.lti.cs.cmu.edu/Services/treccast19/duplicate_description.txt, as of 10/29/2019.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3" coords="7,149.01,663.39,80.45,6.64"><p>http://corenlp.run/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,149.27,524.42,328.22,8.74;10,149.27,536.37,328.22,8.74;10,149.27,549.05,107.37,8.30" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,396.41,524.42,81.07,8.74;10,149.27,536.37,35.40,8.74">Mining of Massive Datasets</title>
		<author>
			<persName coords=""><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anand</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Ullman</surname></persName>
		</author>
		<ptr target="http://www.mmds.org/" />
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct coords="10,149.27,568.25,328.22,8.74;10,149.27,580.21,328.21,8.74;10,149.27,592.16,186.41,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,376.40,568.25,101.08,8.74;10,149.27,580.21,35.94,8.74">TREC 2018 news track overview</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,212.67,580.21,264.81,8.74;10,149.27,592.16,22.67,8.74">Proceedings of the 27th Text REtrieval Conference (TREC 2018)</title>
		<meeting>the 27th Text REtrieval Conference (TREC 2018)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11">November 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
