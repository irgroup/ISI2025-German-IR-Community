<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,113.45,111.94,385.11,15.20">TREC CAR Y3: Complex Answer Retrieval Overview</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,243.91,144.45,61.11,10.56;1,305.03,142.91,1.41,6.99"><forename type="first">Laura</forename><surname>Dietz</surname></persName>
							<email>dietz@cs.unh.edu</email>
						</author>
						<author>
							<persName coords="1,312.17,144.45,55.91,10.56"><forename type="first">John</forename><surname>Foley</surname></persName>
						</author>
						<title level="a" type="main" coord="1,113.45,111.94,385.11,15.20">TREC CAR Y3: Complex Answer Retrieval Overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D89A9E49D118FE396086A46CD16D1630</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Introduction</p><p>The vision of TREC Complex Answer Retrieval is to create complex long-form answers in response to a wide-variety information needs. In general, we aspire to create answers that are reminiscent to Wikipedia articles or school text books (e.g. TQA). However, while the vast majority of Wikipedia articles are about people, in TREC CAR we aim at information needs that are off the beaten path, covering topics in popular science, technology, and illnesses.</p><p>The first two years of TREC CAR, we aimed to reproduce Wikipedia articles. This provided a very large-scale automated benchmark, which had significant impact on neural ranking research <ref type="bibr" coords="1,480.62,333.08,10.51,8.80">[7,</ref><ref type="bibr" coords="1,495.25,333.08,7.01,8.80">6]</ref>, as well as feature-based ranking models <ref type="bibr" coords="1,219.37,345.04,10.51,8.80" target="#b0">[1,</ref><ref type="bibr" coords="1,234.23,345.04,7.01,8.80" target="#b3">4]</ref>. The downside was that we had to prohibit access to Wikipedia, collections that could include Wikipedia (e.g. ClueWeb), and knowledge bases derived from Wikipedia (we provided the part of Wikipedia from which a knowledge graph can be built that excludes the benchmark topics, called "allButBenchmark"). Technically this would even affect resources that are trained on Wikipedia, such as most word embeddings and BERT <ref type="bibr" coords="1,265.26,392.86,9.96,8.80" target="#b2">[3]</ref>. To avoid this difficulty, in this year, our test topics come exclusively from an collection of school text book chapters, which are provided along with the TQA dataset <ref type="bibr" coords="1,72.00,416.77,9.96,8.80" target="#b4">[5]</ref>. These chapters have a similar length as Wikipedia articles, but are written for a younger audience. We derive outlines from TQA chapters, and ask participants to populate these outlines with paragraphs from Wikipedia, using the paragraphCorpus from previous years. We manually cleaned and rewrote the outlines so that they are suitable to be treated like search queries. This test collection is called benchmarkY3test.</p><p>A downside of this decision is that no automatic evaluation can be conducted. We recommend to train data-hungry methods on the "train" collection provided in the first year (Y1). Since previous year's test data (benchmarkY2test ) contained both contained Wikipedia topics and TQA topics, we re-released manually assessed TQA topics as training data for this year, released as benchmarkY3train.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Worked Example</head><p>To motivate a brief example, consider a user interested in learning about water pollution through fertilizers, ocean acidification, and aquatic debris and the effects it has. There is no short and simple answer to this information need. Instead we need to retrieve a complex answer that covers the topic with its different facets and elaborates pertinent connections between entities/concepts. A suitable answer would cover the following:</p><p>Through photosynthesis algae provide food and nutrients for the marine ecosystem. However, through rain storms, fertilizers used in agriculture and lawn care are swept into the rivers and coastal sea. Fertilizers contain nitrogen and phosphorys, these stimulate algae growth so that the alae population will grow large very quickly, called algal blooms. The problem is that these algae do not live long, when they die and decompose oxygen is removed from the water. As a result fish and shell fish die. Furthermore, some algal blooms release toxins into the water, which are consumed by shell fish. Humans that consume toxins though shell fish can suffer neurological damage.</p><p>A different source of water pollution is through high levels of carbon dioxide in the athmosphere. Oceans absorb carbon dioxide, but it will lower the PH level of the water, meaning that oceans to become acidic. As a result, corals and shell fish are killed and other marine organisms reproduce less. This leads to issues in the food chain, and thereby less fish and shell fish for humans to consume.</p><p>Finally, trash and other debris that gets in the waterways through shipping accidents, landfill erosion, or by directly dumping trash in the ocean. This debris is dangerous for aquatic wildlife in two ways. Animals may mistake debris for food swallow plastic bags which kills them. Other aquatic animals are tangled in nets and strangled by trash like plastic six-pack rings.</p><p>This example was taken from the TQA collection, "Effects of Water Pollution", and many similar examples can be found on Wikipedia. Nevertheless, such articles are not available for any imaginable kind of of information needs, which is why we aim to generate such comprehensive summaries automatically from Web sources through passage retrieval, consolidation, and organization. Of course, one might envision other responses that would satisfy the information need equally well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Description</head><p>While in the first two years, the task setup followed a standard ad hoc IR fashion, where given a title and an outline of headings, a ranking of paragraphs is to be produced for every section. However, the long-term vision of CAR is to produce comprehensive articles. Articles are much different from rankings: Instead of ordering paragraphs by relevance, paragraphs should be ordered so that when read from top to bottom would would make logical sense in order to inform the user.</p><p>Y3 Passage Ordering Task Given an outline Q, retrieve, select, and arrange a sequence of k passages P from the provided passage corpus, with ideally:</p><p>1. High relevance of all passages 2. Balanced coverage of all query facets as defined through headings H i in the outline 3. Maximizing topical coherence, minimizing topic switches, i.e., first all passages about one topic, then all passages of the next topic while avoiding to interleave multiple topics.</p><p>The number of passages k is given with the topic.</p><p>We are aware that this is a major departure from ad hoc retrieval. To facilitate the transition, organizers provided a script that would take the top ranked passages for Y1/Y2-style task (one ranking for each title+heading query), and would use them to populate the article (in order of relevance) so that exactly k passages are contained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Topic Coordination with CAsT</head><p>Since the nature of topics for TREC CAR is similar to a subset of topics in TREC Conversational Assistance (CAsT) <ref type="bibr" coords="2,100.09,622.97,14.04,8.80" target="#b1">[2]</ref>, both track's organizers coordinated the set of topics for assessment to prefer similar domains. We hope that this leads to interesting further research improving information access as (non-interactive) long-form response as well as a conversation. See Table <ref type="table" coords="2,316.39,646.88,4.98,8.80" target="#tab_0">1</ref> for a list of CAR and CAsT topics that share the topic. 5 Assessment of the Manual Ground Truth</p><p>For 55 topics, we fully assessed three runs (i.e., generated articles) from each team. To study inter-annotator agreement, we selected three runs, and asked all six judges to annotate a separate topic (tqa2:L_0257) for each of these runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Assessment Interface</head><p>A screenshot of the assessment interface is given in Figure <ref type="figure" coords="3,329.36,327.05,3.87,8.80">1</ref>.</p><p>After reading the gold article for the query the judges were asked to assess the page from top to bottom by 1. reading the passage 2. taking notes about if and why this passage is relevant for the query in the notes field.</p><p>3. detemining the best fitting facet for the passage and assigning a relevance label for how relevant this passage is for the selected facet, i.e., whether the passage MUST, SHOULD, or CAN be included on the generated article.</p><p>4. if the passage is not relevant for any facet, but should be displayed on the article (i.e., fitting the overarching theme), then judges were asked to select OTHER RELVANT FACET; if the passage a very relevant description of the topic, the judges were asked to select GENERAL/INTRODUCTION.</p><p>5. if the passage is not relevant for the article at all (i.e., the judge would have preferred to be shown this passage), the judges are asked to click the "Remove" button. -In this case the passage is hidden from the page view (In the screenshot, passage number 10 was removed) 6. For every pair of consecutive passages (skipping removed passages), the judged are asked to judge the smoothness of the transition. Possible choices are SAME TOPIC / COHERENT TRANSITION / TOPIC SWITCH. (In the screenshot the transition from passage number 9 to 11 was assessed, because 10 was removed.)</p><p>Detailed results of the assessments are provided in JSON format, see Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qrels</head><p>As the fast majority of submitted runs were directly derived from an ad hoc passage ranking, we also provide a qrels file for rank quality evaluation. We use the same scale as in previous years.</p><p>• 3: MUST be mentioned • 2: SHOULD be mentioned • 1: CAN be mentioned • 0: Removed, non-relevant Figure <ref type="figure" coords="4,238.27,735.05,3.87,8.80">1</ref>: Screenshot of Assessment Interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submission</head><p>Every team was allowed to submit up to 10 runs of different assessment priorities. Three runs from each team were fully assessed (priority HIGH and MEDIUM). Runs needed to be submitted in a JSON format that at the minimum needed to specify the paragraph ids in topically coherent order. The file was allowed to also include rankscore information for a more traditional ad hoc retrieval assessment. We provided a script for converting Y2-style rankings into the new format, simply by taking the highest ranked passages in order of relevance for each section, then concatenating resulting paragraphs.</p><p>Unfortunately, all submitted runs (except a single submitted run) were created with this script. Hence a detailed evaluation of topical coherence would not make sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>Teams DANGNT-NLP, ECNU, IRIT, Smith, ICTNET, TREMA-UNH, and UAmsterdam participated this year. The results are presented in Figure <ref type="figure" coords="5,253.94,247.32,3.87,8.80" target="#fig_0">2</ref>. More detailed results will be available online. <ref type="foot" coords="5,463.27,245.76,3.97,6.16" target="#foot_0">1</ref>The three top ranked systems all make use of BERT and anserini, following Nogueira et al <ref type="bibr" coords="5,482.98,259.27,9.96,8.80">[8]</ref>. The next three methods are based on Terroer with a CombMNZ combination. Many remaining runs include different variation of BM25, RM3, and reranking. However, just using BERT is not a guarantee for good retrieval performance. This is a lesson learned at last year's TREC meeting, where Nogueira's submission did not use an English stemmer when retrieving candidate pools with BM25, which severely impacted the performance of team NYU. This year, the community successfully employed Nogureira's BERT-based method [8] for the CAR passage ranking task. [6] Sean MacAvaney, Andrew Yates, Kai Hui, and Ophir Frieder. Content-based weak supervision for adhoc re-ranking. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 993-996. ACM, 2019.</p><p>[7] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with bert. arXiv preprint arXiv:1901.04085, 2019.</p><p>[8] Rodrigo Nogueira, Wei Yang, Jimmy Lin, and Kyunghyun Cho. Document expansion by query prediction. arXiv preprint arXiv:1904.08375, 2019.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Format for Detailed Relevance Assessments</head><p>Relevance data is provided in JSON format describe below. There is a separate file for each query/judge. Each JSON file has the following entries (each representing a keyed on the pair query_id, paragraph_id):</p><p>• notes_state : notes for each paragraph from assessment step 2)</p><p>• facet_state : facet/relevance assessment from assessment step 3). Lists the most relevant facet with heading and heading_id (technically this is a section path in the form of title/heading) and the assessed relevance ranging over values MustLabel, ShouldLabel, CanLabel; special facet ids from step 4) are indicated by the heading_ids: NONE_OF_THESE and GENERAL/INTRODUCTION.</p><p>• nonrelevant_state : not used.</p><p>• nonrelevant_state2 : contains query_id, paragraph_id that are marked as "REMOVE" in assessment step 5)</p><p>• transition_label_state: contains transition judgments from Step 6). Entries are keyed on query_id, paragraph_id1, paragraph_id2, and contain values SameTransition, AppropriateTransition, or SwitchTransition. -Paragraphs that were marked as "REMOVED" are skipped in transition assessments.</p><p>Each of these entries are represented as association maps from a pair of query_id, paragraph_id to a list of wrapped value. The wrapper also contains metadata of the assessment ( annotator_id, time_stamp, session_id, run_ids). Since JSON does not support maps of complex keys, we represent each key-value pair in the map a list of length 2.</p><p>Example of notes_state and facet_state for passage number 9 (see Figure <ref type="figure" coords="7,428.77,496.48,3.87,8.80">1</ref>).</p><p>{ "notes_state": [ [ { "query_id": "tqa2:L_0257", "paragraph_id": "2a967f3f17c026dedb2733adf90ffca35c124384" }, [ { "annotator_id": "NIST", "time_stamp": "2019-10-11T21:02:58.354696907Z", "session_id": "CAR-Y3", "run_ids": [], "value": "examples of toxic chemicals and their sources..." } ] ], ... ], "facet_state": [ [ { "query_id": "tqa2:L_0257", "paragraph_id": "2a967f3f17c026dedb2733adf90ffca35c124384" }, [ { "annotator_id": "NIST", "time_stamp": "2019-10-11T21:02:58.354696907Z", "session_id": "CAR-Y3", "run_ids": [], "value": { "facet": { "heading": "toxic chemicals", "heading_id": "tqa2:L_0257/T_1512" }, "relevance": "MustLabel" } } ] ],... ],</p><p>Example of non-relevant_state2 for passage number 10 "nonrelevant_state2": [ [ { "query_id": "tqa2:L_0257", "paragraph_id": "f1dec26869a4c7d00c9acee595d1dfa8afa69ffe" }, { "annotator_id": "NIST", "time_stamp": "2019-10-11T21:02:58.354696907Z", "session_id": "CAR-Y3", "run_ids": [], "value": true } ], ... ],</p><p>Example of transition assessmend between passage number 9 and number 11 "transition_label_state": [ [ { "query_id": "tqa2:L_0257", "paragraph_id1": "2a967f3f17c026dedb2733adf90ffca35c124384", "paragraph_id2": "9f2f8743e626136344df4dce07e5c4166ab3e113" }, { "annotator_id": "NIST", "time_stamp": "2019-10-11T21:02:58.354696907Z", "session_id": "CAR-Y3", "run_ids": [], "value": "SameTransition" } ], ... ] }</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,184.87,562.21,238.95,8.80;6,72.00,220.98,468.00,326.18"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Section-level ranking performance in NDCG.</figDesc><graphic coords="6,72.00,220.98,468.00,326.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,77.98,82.57,430.90,128.25"><head>Table 1 :</head><label>1</label><figDesc>Related CAR and CAsT topics (many more CAR topics were assessed).</figDesc><table coords="3,77.98,94.42,430.90,116.39"><row><cell></cell><cell>CAsT</cell><cell>CAR</cell></row><row><cell>Cancer and non-infectuous diseases</cell><cell>cast2019:31</cell><cell>tqa2:L_0402</cell></row><row><cell>Sharks</cell><cell>cast2019:32</cell><cell>tqa2:L_0474</cell></row><row><cell>Lyme disease</cell><cell>cast2019:38</cell><cell>tqa2:L_0502, tqa2:L_0398</cell></row><row><cell>Satellites and space</cell><cell>cast2019:50</cell><cell>tqa2:L_0040, tqa2:L_0051, tqa2:L_0052</cell></row><row><cell>Evolution</cell><cell>cast2019:56</cell><cell>tqa2:L_0432</cell></row><row><cell>Injuries</cell><cell>cast2019:59</cell><cell>tqa2:L_0385, tqa2:L_0398</cell></row><row><cell>Blood cells</cell><cell>cast2019:67</cell><cell>tqa2:L_0402, tqa2:L_0385</cell></row><row><cell>Solar energy</cell><cell>cast2019:70</cell><cell>tqa2:L_0074, tqa2:L_311</cell></row><row><cell>Diet and health</cell><cell>cast2019:78</cell><cell>tqa2:L_0402</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,87.24,699.21,161.86,6.64"><p>http://trec-car.cs.unh.edu/results-Y3/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>We express our gratitude for many suggestions of several experts in the field, who helped to make this track successful. We thank the <rs type="institution">University of New Hampshire</rs> for providing computational resources and web servers. We are deeply thankful for Ellen Voorhees' experience, patience, and persistence in running the assessment process. Finally we thank all our participants.</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>http://trec-car.cs.unh.edu Google group mailinglist: TREC-CAR</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="5,87.49,479.86,452.51,8.80;5,87.50,491.81,452.51,8.80;5,87.50,503.77,22.69,8.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,376.27,479.86,163.73,8.80;5,87.50,491.81,116.23,8.80">Local and global query expansion for hierarchical complex topics</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shahrzad</forename><surname>Naseri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,224.03,491.81,201.69,8.80">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="290" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.49,523.70,452.51,8.80;5,87.50,535.65,241.41,8.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,326.67,523.70,213.33,8.80;5,87.50,535.65,35.93,8.80">Cast 2019: The conversational assistance track overview</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,144.78,535.65,152.52,8.80">Text REtrieval Conference (TREC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.49,555.58,452.51,8.80;5,87.50,567.53,452.51,8.80;5,87.50,579.49,452.51,8.80;5,87.50,591.44,259.62,8.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,401.35,555.58,138.65,8.80;5,87.50,567.53,217.27,8.80">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,327.58,567.53,212.43,8.80;5,87.50,579.49,81.10,8.80">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s" coord="5,137.08,591.44,96.92,8.80">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.49,611.37,452.51,8.80;5,87.50,623.32,452.51,8.80;5,87.50,635.28,233.05,8.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,148.10,611.37,391.90,8.80;5,87.50,623.32,35.93,8.80">ENT rank: Retrieving entities for topical information needs through entity-neighbor-text relations</title>
		<author>
			<persName coords=""><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,141.91,623.32,398.09,8.80;5,87.50,635.28,105.18,8.80">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,87.49,655.20,452.50,8.80;5,87.50,667.16,452.51,8.80;5,87.50,679.11,402.56,8.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,126.72,667.16,413.29,8.80;5,87.50,679.11,62.25,8.80">Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension</title>
		<author>
			<persName coords=""><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dustin</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,171.40,679.11,287.01,8.80">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
