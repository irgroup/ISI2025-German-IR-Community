<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.02,76.45,286.01,16.20">TREC 2007 Genomics Track Overview</title>
				<funder>
					<orgName type="full">Lori Buckland of NIST</orgName>
				</funder>
				<funder ref="#_wG3xuXY">
					<orgName type="full">U.S. National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.70,109.34,70.99,10.80"><forename type="first">William</forename><surname>Hersh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics &amp; Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,233.67,109.34,64.29,10.80"><forename type="first">Aaron</forename><surname>Cohen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics &amp; Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.98,109.34,61.69,10.80"><forename type="first">Lynn</forename><surname>Ruslen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics &amp; Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.68,109.34,75.60,10.80"><forename type="first">Phoebe</forename><surname>Roberts</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Pfizer Corp</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.02,76.45,286.01,16.20">TREC 2007 Genomics Track Overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B3B74E979A21514CEB06A22E32816B1E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC 2007 Genomics Track employed an entity-based question-answering task. Runs were required to nominate passages of text from a collection of full-text biomedical journal articles to answer the topic questions. Systems were assessed not only for the relevance of passages retrieved, but also how many aspects (entities) of the topic were covered and how many relevant documents were retrieved. We also classified the features of runs to explore which ones were associated with better performance, although the diversity of approaches and the quality of their reporting prevented definitive conclusions from being drawn.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For the TREC 2007 Genomics Track, we undertook a modification of the question answering extraction task used in the 2006 track <ref type="bibr" coords="1,254.30,316.34,12.74,10.80" target="#b0">[1]</ref>. We continued to task systems with extracting out relevant passages of text that answer topic questions. However for this year, instead of categorizing questions by generic topic type (GTT), we derived questions based on biologists' information needs where the answers were, in part, lists of named entities of a given type. Systems were required to return a passage of text, which provided one or more relevant list items within the context of supporting text.</p><p>Similar to 2006, systems were tasked to return passages of text. Relevance judges with expertise in biological research assigned the relevant passage "answers," or items belonging to a single named entity class, analogous to the assignment of MeSH aspects in 2006. After pooling the top nominated passages as in past years, judges selected relevant passages and then assigned one or more answer entities to each relevant passage. Passages had to contain one or more named entities of the given type with supporting text that answered the given question in order to be marked relevant. Judges created their own entity list for each topic, based on the passages they judged as relevant. Passages were given credit for each relevant and supported answer. This was required because it was assumed that the passage would not answer the list entity question unless it contains an entity of the type for which the judges were looking. The experts were instructed to perform their relevance judgments in this manner.</p><p>The evaluation measures for 2007 were a refinement of the measures used in 2006. We added a new character-based mean average precision (MAP) measure (called Passage2 MAP) to compare the accuracy of the extracted answers, modified from the original measure in 2006 (called Passage MAP). Passage2 MAP treated each individually retrieved character in published order as relevant or not, in a sort of "every character is a mini relevance-judged document" approach. This was done to increase the stability of the Passage MAP measure against arbitrary passage splitting techniques. We included the 2006 passage retrieval measure as well. The Aspect MAP measure remained the same, except that instead of using assigned MeSH aspects we used the answer entities assigned by the relevance judges. We continued to use Document MAP as is, i.e., a document that contained a passage judged relevant was deemed relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Documents</head><p>We used the same full-text document corpus that we assembled for the TREC 2006 Genomics Track. The documents in this corpus came from the Highwire Press (www.highwire.org) electronic distribution of journals and were in HTML format. There were about 160,000 documents in the corpus from about 49 genomics-related journals. Highwire Press agreed to allow us to include their full text in HTML format, which preserved formatting, structure, table and figure legends, etc.. In 2006, we found some known issues with the document collection:</p><p>• The collection was not complete from the standpoint of each journal. That is, there were many journals where some articles appeared in the journal but did not make it into our collection. (Neither the article nor the MEDLINE record.) This was not an issue to us, since we viewed the corpus as a closed and fixed collection. • Some of the PMIDs in the source data from Highwire Press were inconsistent with PubMed PMIDs (see next paragraph for an explanation). • Some of the HTML files were empty or nearly empty (i.e., only contained a small amount of meaningless text). Some of this was due to errors in our processing, but some was also related to the incorrect PMID problem of Highwire. We froze the corpus for the test collection and, since these files were small, they were unlikely to have any relevant passages or even be retrieved by most systems.</p><p>Also discovered in 2006 were some errors between the PMIDs designated by Highwire and the actual PMIDs from NLM in MEDLINE. We identified 1,767 instances (about 1% of the 162K documents) where the Highwire file PMID was invalid, in the sense that it returned zero hits when searching for it on PubMed. Some invalid PMIDs are due to the fact that the corresponding documents represented errata and author responses to comments (e.g., author replies to letters). These were assigned PMIDs in publisher-supplied data, but NLM generally does not cite them separately in PubMed, and therefore deleted the PMIDs, although they remained in publisher data. There were documents already assigned a PMID submitted by Highwire that NLM, by policy, decided not to index at all, in which case, again, NLM deleted the PMID, but it was retained in Highwire data. We also found instances of invalid PMIDs in Highwire data for documents that were cited in PubMed but with a different PMID which is absent from Highwire data; such instances could be characterized as errors. In any case, we investigated the problem of invalid PMIDs and found that for all instances we checked, the problem was the original Highwire file having an invalid PMID. In other words, invalid PMIDs were in the Highwire data, not a result of our processing. For this reason, we decided not to delete these files from the collection. They represented, in our view, normal dirty data, whether due to errors or policy differences between NLM and publishers, and should be part of what real-world systems need to be able to handle.</p><p>Since the goal of the task was passage retrieval, we developed some additional data sources that aided researchers in managing and evaluating runs. As noted below, retrieved passages could contain any span of text that did not include any part of an HTML paragraph tag (i.e., one starting with &lt;P or &lt;/P). We also used these delimiters to extract text that was assessed by the relevance judges. Because there was much confusion in the discussion about the different types of passages, we defined the following terms:</p><p>• Nominated passage -This is the passage that systems nominated in their runs and was scored in the passage retrieval evaluation. • Maximum-length legal span -These were all the passages obtained by the delimited text of each document by the HTML paragraph tags. As noted below, nominated passages could not cross an HTML paragraph boundary. So these spans represented the longest possible passage that could be designated as relevant. As also noted below, we built pools of these spans for the relevance judges. The judges were given the entire span if any system nominated any part of the maximum-length legal span, even if no system nominated the entire span. However, the judges did not need to designate the entire span as relevant, and could select just a part of the span to be relevant. • Relevant passage -These were the spans that the judges designated as definitely or possibly relevant, had to contain at least one answering entity of the given type, and had entities assign to them by the expert judges. A relevant passage must consist of all or part of a maximum-length legal span.</p><p>We note some other things about the maximum-length legal spans:</p><p>• The first and last spans were delimited at the beginning and end of the file respectively.</p><p>• Other HTML tags (e.g., &lt;b&gt;) could occur within the spans.</p><p>• "Empty" (zero character) spans were not included.</p><p>In order to facilitate our management of the data, and perhaps be of use to participants, we created a 215-megabyte file, legalspans.txt, which included all of the maximum-length legal spans for the collection. The first span for each document included all of the HTML prior to the first &lt;p&gt;, which contained the HTML header information and usually was not part of any relevant passage. This file identified all of the maximum-length legal spans in all of the documents, which consisted of all spans &gt;0 bytes delimited by HTML paragraph tags. These spans were identified by the byte character offset and length in the HTML file. The index number of the first character of the file was 0.</p><p>These span definitions can be illustrated with the example in   Let us consider the span 8-29 further. This is a maximum-length legal span because there is an HTML paragraph tag on either side of it. If a system nominates a passage that exceeds these boundaries, it will be disqualified for further analysis or judgment. But anything within the maximum-length legal span, e.g. 8-19, 18-19, or 18-28, could be nominated or relevant passages. We note that it would be possible for there to be more than one relevant passage in a maximumlength legal span. While this will be unlikely, our character-based scoring approach (see below) would handle it fine. However, this was a problem for the judges as the judging interface did not support an easy way to split a judged maximum-length span into multiple relevant passages. In this case judges were instructed to include all of the relevant text within a span in the relevant passage, even if that required the inclusion of some text that the judge thought not relevant. This was most likely to be an issue in spans originating in the references section of the original documents, where two references with informative titles are separated by one or more nonrelevant references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topics</head><p>There were 36 official topics for the track in 2007, which were in the form of questions asking for lists of specific entities. The definitions for these entity types were based on controlled terminologies from different sources, with the source of the terms depending on the entity type.</p><p>We gathered new information needs from working biologists. This was done by modifying the questionnaire used in 2004 to survey biologists about recent information needs. In addition to asking about information needs, biologists were asked if their desired answer was a list of a certain type of entity, such as genes, proteins, diseases, mutations, etc., and if so, to designate that entity type. Fifty information needs statements were selected after screening them against the corpus to ensure that relevant paragraphs with named entities were present, of which 36 were used as official topics and 14 used as sample topics. Table <ref type="table" coords="4,354.59,440.00,6.00,10.80" target="#tab_4">2</ref> lists the 36 topics and Table <ref type="table" coords="4,500.97,440.00,6.00,10.80" target="#tab_5">3</ref> shows the entities and the number of topics in which they occurred.</p><p>An example of our topic development process is as follows. Suppose that the information need was: What is the genetic component of alcoholism? This is transformed into a list question of the form: What [GENES] are genetically linked to alcoholism? Answers to this question are passages that relate one or more entities of type GENE to alcoholism. For example, a valid and relevant answer to the above question would be: The DRD4 VNTR polymorphism moderates craving after alcohol consumption. (from PMID 11950104 for those who want to know) And the GENE entity supported by this statement would be DRD4.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Type Definition Potential Source of Terms</head><p>Topics With Entity Type ANTIBODIES Immunoglobulin molecules having a specific amino acid sequence by virtue of which they interact only with the antigen (or a very similar shape) that induced their synthesis in cells of the lymphoid series (especially plasma cells).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH BIOLOGICAL SUBSTANCES</head><p>Chemical compounds that are produced by a living organism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH CELL OR TISSUE TYPES</head><p>A distinct morphological or functional form of cell, or the name of a collection of interconnected cells that perform a similar function within an organism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH DISEASES</head><p>A definite pathologic process with a characteristic set of signs and symptoms. It may affect the whole body or any of its parts, and its etiology, pathology, and prognosis may be known or unknown. BioCarta, KEGG PROTEINS Linear polypeptides that are synthesized on ribosomes and may be further modified, crosslinked, cleaved, or assembled into complex proteins with several subunits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STRAINS</head><p>A genetic subtype or variant of a virus or bacterium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ad hoc SIGNS OR SYMPTOMS</head><p>A sensation or subjective change in health function experienced by a patient, or an objective indication of some medical fact or quality that is detected by a physician during a physical examination of a patient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOXICITIES</head><p>A measure of the degree and the manner in which which something is toxic or poisonous to a living organism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH</head><p>TUMOR TYPES An abnormal growth of tissue, originating from a specific tissue of origin or cell type, and having defined characteristic properties, such as a recognized histology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submissions</head><p>Submitted runs could contain up to 1000 passages per topic in ranked order that were predicted to be relevant to answering the topic question. Passages had to be identified by the PMID, the start offset into the text file in characters, and the length of the passage in characters.</p><p>Passages were required to be contiguous and not longer than one paragraph. This was operationalized by prohibiting any passage from containing HTML markup tags, i.e., those starting with &lt;P or &lt;/P. Any passage that included those tags was ignored in the relevance judgment process but not omitted from the scoring process. (In other words, they were not including in the pooling and judgment for creating the gold standard, but they could be scored and may include some relevant characters.) Each participating group was be allowed to submit up to three official runs, each of which was used for building the judgement pools. Each passage also needed to be assigned a corresponding rank number and value, which was used to order nominated passages for rank-based performance computations. Rank values could be integers or floating point numbers, such as confidence values.</p><p>Each submitted run had to be submitted in a separate file, with each line defining one nominated passage using the following format based loosely on trec_eval. Each line in the file had to contain the following data elements, separated by white space (spaces or a tab characters):</p><p>• Topic ID -from 200 to 235.</p><p>• Doc ID -name of the HTML file minus the .html extension. This is the PMID that has been designated by Highwire, even though we now know that this may not be the true PMID assigned by the NLM (i.e., used in MEDLINE). But this is the official identifier for the document. • Rank number -rank of the passage for the topic, starting with 1 for the top-ranked passage and preceding down to as high as 1000. • Rank value -system-assigned score for the rank of the passage, an internal number that should descend in value from passages ranked higher. • Passage start -the byte offset in the Doc ID file where the passage begins, where the first character of the file is offset 0. • Passage length -the length of the passage in bytes, in 8-bit ASCII, not Unicode.</p><p>• Run tag -a tag assigned by the submitting group that should be distinct from all the group's other runs (and ideally any other group's runs, so it should probably have the group name, e.g., OHSUbaseline).</p><p>Here is an example of the submission file format: A Perl script that checked runs to insure that the submission file was in the proper format was available (check_genomics.pl). Runs also needed to include a "dummy" passage for any topic for which no passages were retrieved. It was recommended that the dummy passage use "0" as a docid, "0" as the passage start, and "1" as the passage length. This worked for the Perl script and did not correspond to a document in the collection.</p><p>Runs were also classified based on amount of intervention in converting topics to queries. We adopted the "usual" TREC rules (detailed at http://trec.nist.gov/act_part/guidelines/trec8_guides.html) for categorizing runs:</p><p>• Automatic -no human modification of topics into queries for your system whatsoever • Manual -human modification of queries entered into your system (or any other system) but no modification based on results obtained (i.e., you cannot look at the output from your runs to modify the queries) • Interactive -human interaction with the system, including modification of the queries or the system after viewing the output from your system or any other system (i.e., you look at the output from the topics and corpus and adjust your system to produce different output)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance Judgments</head><p>The expert judging for this evaluation used the pooling method, with passages corresponding to the same topic ID pooled together. The judges were presented with the text of the maximumlength legal span containing each pooled passage, with pool composed of the top ranked 1000 passages for each topic. They then evaluated the text of the maximum-length legal span for relevance, and identified the portion of this text that contains an answer. This could be all of the text of the maximum legal span, or any contiguous substring. If a maximum legal span contained more than one relevant passage, judges were instructed to select the minimum contiguous passage that contained all relevant passages, even if the passages were separated by irrelevant text. Maximum legal spans comprised of the journal article bibliography frequently generated multiple relevant sub-passages that needed to all be included in the singe designated passage.</p><p>Judges were recruited from the institutions of track participants and other academic or research centers. They were required to have significant domain knowledge, typically in the form of a PhD in a life science. They were trained using a 12-page manual and a one-hour videoconference, with the option of testing out of the videoconference by successfully judging a mini-topic based on a practice topic from 2006 made up of an equal mix of definitely, possibly, and not relevant maximum-length legal spans. The self-training option had the unexpected benefit of highlighting and correcting potential problems with the judging tool or ambiguous guidelines before judging began in earnest. The training manual is on the track Web site at: http://ir.ohsu.edu/genomics/2007judgeguidelines.pdf</p><p>In summary, judges were given the following instructions: 1. Review the topic question and identify key concepts. 2. Identify relevant paragraphs and select minimum complete and correct excerpts.</p><p>3. Develop controlled vocabulary for entities based on the relevant passages and code entities for each relevant passage based on this vocabulary.</p><p>Judgments were made using database files created and accessed via the OpenOffice Base application. As shown in Figure <ref type="figure" coords="8,228.70,684.56,4.50,10.80" target="#fig_1">1</ref>, judges were presented passages as a form view of individual records in the database with the topic, question, and text of the full-text legal passage. If part or all of the passage was relevant, the judges then:</p><p>1. Selected the level of relevance ("Definitely Relevant" or "Possibly Relevant").</p><p>2. Copied the relevant portion of the passage from the passage plain text field into the answer text box. 3. Selected entities (ENTITY1, ENTITY2, etc.) they had added using the Add Entities form (not shown).</p><p>A gold standard was created by extracting out the relevance passages and entities from the database file for each topic. Selected relevant text was transformed into file character offset and length using a text alignment algorithm. A summary of the gold standard developed from the results of the judging process is shown in Table <ref type="table" coords="9,303.59,226.64,4.50,10.80" target="#tab_7">4</ref>. Topics ranged from a low of 1 relevant passage to a high of 377. Individual topics had a range of 1 to 300 relevant entities, with an average ranging between 1.0 to 3.5 entities assigned per relevant passage.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Measures</head><p>For this year's track, there were three levels of retrieval performance measured: passage retrieval, aspect retrieval, and document retrieval. Each of these provides insight into the overall performance for a user trying to answer the given topic questions. Each was measured by some variant of MAP. We again measured the three types of performance separately. There was not any summary metric to grade overall performance. A Python program to calculate these measures (http://ir.ohsu.edu/genomics/trecgen2007_score.py) with the appropriate gold standard data files is available.</p><p>Passage-level retrieval performance -character-based MAP</p><p>The original passage retrieval measure for the 2006 track was found to be problematic in that non-content manipulations of passages had substantial effects on Passage MAP, with one group claiming that breaking passages in half with no other changes doubled their (otherwise low) score. To this end, we defined an alternative measure (Passage2 MAP) that calculated MAP as if each character in each passage were a ranked document. In essence, the output of passages was concatenated, with each character being from a relevant passage or not. We used Passage2 MAP as the primary passage retrieval evaluation measure in 2007.</p><p>The original Passage MAP measure was also calculated. This measure computed individual precision scores for passages based on character-level precision, using a variant of a similar approach used for the TREC 2004 HARD Track <ref type="bibr" coords="11,307.21,281.84,12.74,10.80" target="#b1">[2]</ref>. For each nominated passage, a fraction of characters overlaps with those deemed relevant by the judges in the gold standard. At each relevant retrieved passage, precision was computed as the fraction of characters overlapping with the gold standard passages divided by the total number of characters included in all nominated passages from this system for the topic up until that point. Similar to regular MAP, remaining relevant passages that were not retrieved at all were added into the calculation as well, with precision set to 0 for relevant passages not retrieved. Then the mean of these average precisions over all topics was calculated to compute the mean average passage precision.</p><p>Aspect-level retrieval performance -aspect-based MAP Aspect retrieval was measured using the average precision for the aspects of a topic, averaged across all topics. For 2007, the aspects were the different named entities of the given type for each question. To compute this, for each submitted run, the ranked passages were transformed to two types of values, either:</p><p>• the aspects of the gold standard passage that the submitted passage overlaps with, or</p><p>• not relevant This resulted in an ordered list, for each run and each topic, of aspects and not-relevant. Because we were uncertain of the utility for a user of a repeated aspect (e.g., same aspect occurring again further down the list), we discarded them from the output to be analyzed and only kept the first appearance of an aspect. For these remaining aspects of a topic, we calculated Aspect MAP similar to how it was calculated for documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document-level retrieval performance -document-based MAP</head><p>For the purposes of this measure, any PMID that had a passage associated with a topic ID in the set of gold standard passages was considered a relevant document for that topic. All other documents were considered nonrelevant for that topic. System run outputs were similarly collapsed, with the documents appearing in the same order as the first time the corresponding PMID appears in a nominated passage for that topic. For a given system run, average precision was measured at each point of correct (relevant) recall for a topic, with Document MAP being the mean of the average precision values across topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>A total of 66 runs were submitted by 27 groups. Of the submitted runs, 49 were classified as automatic, 8 as manual, and 9 as interactive. Appendix 1 lists the type and description of each submitted run. Table <ref type="table" coords="12,174.67,171.44,6.00,10.80" target="#tab_8">5</ref> lists the performance statistics for all of the runs and for the runs subdivided by categories. Appendix 2 shows the overall scores for each run, sorted by each measure.</p><p>We also measured correlation of the four measures (Passage2 MAP, Passage MAP, Aspect MAP, and Document MAP) for each run. As is seen in Table <ref type="table" coords="12,368.66,240.44,4.50,10.80" target="#tab_9">6</ref>, the new Passage2 MAP measure was highly correlated with Aspect MAP and Document MAP (R 2 &gt; 0.8), with the older Passage MAP measure less correlated. We attempted to analyze the automatic runs to discern whether there was any association between individual methods used (as reported in conference notebook papers and not final proceedings papers) and overall performance as measured by Passage2 MAP. The task was challenging since groups approached entity-based question answering with a myriad of methods. Submissions employed multiple approaches for query expansion, various levels of passage retrieval granularity, varying IR models with many different scoring schemes, and several methods of post-processing. In all, these runs exercised over 70 different features, any of which could have impacted Passage2 MAP separately or in combination. With so many features and a limited number of runs (43) having a corresponding notebook paper describing methods, data sparseness was an issue. We therefore distilled the features into high-level categories, or metafeatures shown in Table <ref type="table" coords="13,189.96,337.04,4.50,10.80">7</ref>.</p><p>If retrieval was done in two steps, e.g., to pare down results for secondary concept-based retrieval, and each step uses a different level of granularity for passage retrieval, we chose the granularity level of the second one in order to focus on features of the core strategy rather than a filtering step designed to reduce computer processing burdens. This only affected runs from ASU and Tsinghua. Each run was represented as a vector of meta-features deemed either present (1) or absent (0). The decision was binary since there is no uniform way to say something was partially done, such as in the case of fusion runs, or to weigh the impact of a paring step for concept-based retrieval. If fusion was done, the union of features used by the individual component runs was chosen since they presumably all contributed to the ultimate result. All meta-features were given the same weight. A hierarchical clustering algorithm using a centroid similarity metric grouped runs based on their meta-features, as shown in Figure <ref type="figure" coords="13,331.28,502.58,4.50,10.80" target="#fig_2">2</ref>. Runs were clustered as a "group" when their correlation was &gt; 70%. Clustering using Dice's coefficient similarity measure produced similar results.</p><p>Originally, we had also clustered by statistical rank group. This simply revealed that many different paths lead to roughly the same performance, and was less informative as far as whether individual meta-features had an overall positive or negative impact. Although not used for clustering, the rank group is included in the heat map to indicate how a run performed. Given that the MAP measures were highly correlated (see Table <ref type="table" coords="13,350.90,612.98,4.33,10.80" target="#tab_9">6</ref>), only Passage2 MAP rank is shown for clarity.</p><p>Table <ref type="table" coords="14,102.34,74.84,6.00,10.80">7</ref> -Meta-features of runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-Feature Name Description</head><p>SynExp query expansion with synonyms OrthExp query expansion with orthographic variants using any source or method ParGranularity passage retrieval by paragraph SentGranularity passage retrieval by sentence BlckGranularity passage retrieval by block, including blocks of words or sentences greater than a single sentence yet smaller than a paragraph ConcptIR concept-based retrieval -a general retrieval strategy attempting to align concepts and, for some runs, relationships between a topic and a passage; uses external knowledge sources such as UMLS as a source of "concepts"; and finds concepts in the results as an inherent part of the retrieval process rather than a post-processing step to "trim" a passage TermIR term-based retrieval -a general retrieval strategy focusing on terms rather than concepts FusionIR fusion -combining results from 2 or more systems regardless of fusion operator used TfIdfIR passage retrieval using a vector space model with any variant of TF-IDF OkapiIR passage retrieval using a vector space model with any variant of Okapi DfrIR passage retrieval using a vector space model with any variant of divergence from randomness (DFR) LatentSemIR passage retrieval using a vector space model with any variant of latent semantic analysis LmIR passage retrieval using any language model Feedback feedback using pseudo-relevance feedback or a custom method FilterPostProc filter post-processing -removing passages for any reason TrimPostProc passage trimming -post-processing of passages by removing sentences from the ends regardless of method Focusing on groups which "on average" used similar methods allowed us to make generalizations about some of the strategies used. Inevitably, abstracting out features in this manner does not precisely identify sources of changes in performance. Furthermore, important details such as corpus pre-processing was not included since papers often lacked details on how this was done. In spite of these limitations, however, we could make some general observations and identify potential causes for performance differences.</p><p>Group A runs expanded queries with synonyms and orthographic variants, defined passages by paragraph, and used vector space models for retrieval. Feedback, trimming, and passage removal all changed Passage2 MAP, but by no more than 10%. The greatest performance decline occurred between MuMshNfdRsc and OHSUQA. The most prominent difference between the runs was the use of Okapi (MuMshNfdRsc) versus TF-IDF (OHSUQA), though OHSU added some words related to the entity types to their queries. Furthermore, it was not clear that some aspect of corpus preprocessing contributed significantly to the decline.</p><p>Group B runs used various language models for retrieval and filtering passages. Group C runs used no query expansion, defined passages by paragraph, and retrieved them using a TF-IDF based vector space model. In spite of the differences in the approaches used in groups B and C, they performed similarly with the exception of AIDRun2, which defined passages by sentence, and the Kyoto runs. Kyoto1, the only run in group B belonging to a low rank group, used a different scoring scheme than the pivoted-document normalization used by the others. Unlike the runs in group A, not all runs in groups B and C performed above the mean and median on Passage2.</p><p>Group E included those runs defining passages by block. With one exception, all runs performed below the mean on Passage2 even though each used methods employed by higher scoring runs.</p><p>Additionally, experiments conducted by Neuchatel, IIT, and Amsterdam suggest that defining passages by units other than paragraphs hurt performance.</p><p>Groups D and F represented the concept-based retrieval runs. The former used methods such as synonym query expansion, defined passages by paragraph and, for subgroup D', trimming of passages to ensure high concept density. Group F differed from Group D primarily in that passages were defined by block rather than paragraph. If submissions defining passages at the paragraph level (since any other seems to degrade performance, see Group E), are compared by those examining concepts (Group D) and those simply using terms (every other group besides Groups D and F), the mean and median dropped on all metrics though most significantly for Passage 2 (31% decline for the mean, 15% for the median). At best, the extra processing required for concept-based retrieval did not seem to help as a general approach. Only LHNCBC and the two UIC runs performed above both the TREC mean and median on all metrics. The exact impact of concept retrieval was difficult to ascertain as most runs did not compare it against a baseline; only NLM and EBI attempted to do so (with no difference and a decline, respectively). SUNY Buffalo, although not submitting an automatic run using concept retrieval, submitted a manual one representing each passage as a list of concepts to be compared to those of the topic. All three metrics dropped significantly.</p><p>According to NLM, the effect of trimming was neutral. The other runs in Group D' did not examine the effects of removing it, but there were runs outside this group that did so. Like them, OHSU and Geneva used external knowledge to identify the part of a passage with the highest density of "concepts" matching the topic. However, the ordering of passages returned from the retrieval step was unchanged. OHSU reported a small improvement (6%) on Passage2 MAP, but Geneva's dropped 41% for the same metric. This was a surprising result in that both methods employed NER, albeit differently. Other runs that trim using only word matches had results more in line with NLM's and OHSU's. Melbourne improved slightly by 4% and EBI improved by 7%, both for Passage2 MAP.</p><p>Across groups, synonym expansion was a popular method. Ostensibly, submissions using it scored about 20% higher on Passage2 MAP and Aspect MAP with no significant difference on Document MAP. But those groups conducting runs with and without synonym expansion differed in their results. Some, like OHSU, Melbourne, and Neuchatel, improved on all metrics (up to 40% for Passage2 MAP, 51% for Aspect MAP, 44% for Document MAP). However, some like EBI and York did worse (up to 39% decrease for Passage2 MAP, 40% for Aspect MAP, 19% for Document MAP). Yet others like UIUC only improved marginally on Document MAP (10%). Such an equivocal outcome may have been due to the fact that groups used different knowledge sources for synonyms and/or processed those knowledge sources in different ways that resulted in different precision/recall tradeoffs for synonym expansion.</p><p>The performance of NLMFusion, the top scoring automatic run for all three metrics, suggested that combining results from different IR models may improve score. But other runs using fusion (UniNE3, EBI2Fusion, and kyoto3) showed slight declines in performance from their baseline non-fusion runs. Each used a different method, however, for fusing the individual runs, and this may have contributed to the differences in performance. Divergence from randomness (DFR) was another approach used in the NLMFusion run by its highest scoring subcomponent run.</p><p>Neuchatel also reported success in using it. However, with only two groups using it in any form, it is hard to say in general that it is a superior method to other lexical-statistical methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Although our analysis is incomplete and difficult to interpret due to incomplete experimentation and reporting, we can draw some conclusions from the results. In terms of the overall results, the level of performance of the top systems was somewhat lower than the TREC 2006 Genomics Track. This may imply that the list-entity type question was more difficult than the GTT question. This would not be unexpected since list entity questions are more open-ended, involve more different entity types, and are closer to natural language than the GTT question used last year. The top systems did consistently well on all measures. The measures were highly correlated.</p><p>We can also conclude that, unlike last year, Aspect MAP was a meaningful measure of system topic coverage in the 2007 track. While the range of the average number of aspects per relevant passages was low (1-3), the number of aspects per topic was relatively high (could be over 300). Therefore for a system to do well on the Aspect MAP measure, a number of passages with complementary aspect information had to be retrieved and ranked highly, since for most topics, almost no single passages would cover all of the required entities.</p><p>We are able to draw some conclusions from our extraction of meta-features and their comparison with results of runs as reported in conference notebook papers. First, we conclude that no single strategy or combination of strategies was clearly superior, as indicated by both the diversity of methods used by runs clustering in the same rank group and the diversity of scores within the same methods cluster group. Second, concept-based retrieval using external knowledge sources, as used by the runs in the competition, at the very least did not help results in spite of the extra processing. Third, results with synonym query expansion, once again with external knowledge sources, were mixed but tended to improve results. Finally, passage retrieval by sentence or block-level was detrimental to performance compared to paragraph-level. Clearly, further experimentation as well as descriptions of runs must be provided by participating groups to reach conclusions about performance of features with more confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p>The 2007 track is the last year of the TREC Genomics Track. We are exploring future challenge evaluations in biomedicine, probably in concert with the ImageCLEF medical image retrieval task <ref type="bibr" coords="18,94.35,130.04,12.75,10.80" target="#b2">[3]</ref>. We hope that the test collections created over the years of the track will be used for further research in biomedical information retrieval and related areas. We will continue to maintain the track Web site for the foreseeable future, with the resources posted there as well as instructions for accessing them.</p><p>Appendix 1 -Type and description of submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Type Description AIDrun1</head><p>A Baseline AIDrun2 A Same as baseline (AIDrun1), but with more elaborate passage identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AIDrun3</head><p>A baseline, re-ranked according to a language model of the entity-type assiciated with the topic. asubaral1 A Finding relatedness between words in the passages and keywords in the corresponding questionkeyword expansion by utilizing the terms appearing in the definitions of the keywords of the questions asubaral2 A Using both Lucene and Indri indexing systems for retrieval -passage length is as minimal as possible -finding relatedness between words in the passages and keywords in the corresponding question -keyword expansion by utilizing the terms appearing in the definitions of the keywords of the questions A System based on a Lucene index that considers the spans as documents. The Lucene scoring function has been modified to better deal with large and small documents based on the article by Singhal about pivoted cosine normalization. A postprocessing of the spans has been done removing HTML without any content and by finding the zone with relevant information based on the similarity of the query and the sentences in the spans. EBI2Fusion A This run is the fusion of two configurations of our system. Our system is based on a Lucene index that considers the spans as documents (configuration 1); in addition, query expansion and boosting of some spans based on the entities matched between the query and the spans can be done (configuration 2). The Lucene scoring function has been modified to better deal with large and small documents based on the article by Singhal about pivoted cosine normalization. In addition, the spans have been processed by removing HTML without any content and by finding the zone with relevant information based on the similarity of the query and the sentences in the spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EBI3Boosting</head><p>A System based on a Lucene index that considers the spans as documents. The Lucene scoring function has been modified to better deal with large and small documents based on the article by Singhal about pivoted cosine normalization. A postprocessing of the spans has been done analyzing the entities in the query and in the span and boosting the spans based on the entities that are matched. In addition, the spans have been processed by removing HTML without any content and by finding the zone with relevant information based on the similarity of the query and the sentences in the spans. A Automatic runs generated with Indri. Queries were build automatically by expanding them with MetaMap and discarding common terms. Gene and proteins names were expanded using Gene Ontology. Query formulated using synonyms to represent the expanded terms and multiword phrases when appropriate. Reference sections were discarded by restricting results to those passages that did not have the word "Medline". UBHFmanual M Queries were expanded using publicly available resources. This list was manually filtered to discard ambiguous names of gene and proteins. uchsc1 M Queries were manually expanded and individual terms were assigned weights. Lists of terms matching keyword classes were included in the queries; those terms recieved equal weights. The queries were submitted to the Indri search engine of the Lemur toolkit. Post-processing included filtering out passages that did not contain genes, mutations or biological substances, according to query type. uchsc2 I Queries were manually expanded and individual terms were assigned weights based on MeSH distance. Additionally, salient biomedical predicates were also expanded for 5 of the queries. Lists of terms matching keyword classes were included in the queries; those terms recieved equal weights. The queries were submitted to the Indri search engine of the Lemur toolkit. Postprocessing included filtering out passages that did not contain genes, mutations or biological substances, according to query type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UICGenRun1</head><p>A Utilize UMLS to get some of the entities. A UMLS-based thesaurus in combination with language-modeling. Run optimized for aspectretrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UTEMC2</head><p>A UMLS-based thesaurus in combination with language-modeling. Run optimized for precision. york07ga1 A No query expansion. Use only terms extracted from the raw topics for retrieval. Use BM25 for term weighting in structured queries. Use Okapi to build word-based index. york07ga2 A Expand query terms for 11 gene-related topics by using Entrez Gene. Use BM25 for term weighting in structured queries. Use Okapi to build sentence-based index. york07ga3 A Expand query terms for all the topics by using UMLS. Use BM25 for term weighting in structured queries. Use Okapi to build word-based index.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,72.00,299.70,33.99,9.02;6,167.32,299.70,210.54,9.02;6,167.28,311.22,58.92,9.02;6,401.40,299.70,61.69,9.02;6,72.00,322.74,32.27,9.02;6,167.27,322.74,216.35,9.02;6,167.28,334.20,204.72,9.02;6,167.28,345.72,150.31,9.02;6,401.40,322.74,64.47,9.02;6,72.00,357.24,62.23,9.02;6,72.00,368.70,56.15,9.02;6,167.28,357.24,196.70,9.02;6,167.28,368.70,209.45,9.02;6,167.28,380.22,130.32,9.02;6,401.40,357.24,14.49,9.02;6,72.00,391.74,58.89,9.02;6,167.27,391.74,201.90,9.02;6,167.28,403.19,197.91,9.02;6,167.28,414.71,176.99,9.02;6,167.28,426.23,93.09,9.02;6,401.41,391.74,26.14,9.02;6,72.01,437.69,55.57,9.02;6,167.24,437.69,209.26,9.02;6,167.29,449.21,206.68,9.02;6,167.29,460.67,78.96,9.02"><head></head><label></label><figDesc>DRUGSA pharmaceutical preparation intended for human or veterinary use.MEDLINEplusGENESSpecific sequences of nucleotides along a molecule of DNA (or, in the case of some viruses, RNA) which represent functional units of heredity. iHoP, Harvester MOLECULAR FUNCTIONS Elemental activities, such as catalysis or binding, describing the actions of a gene product or bioactive substance at the molecular level. GO MUTATIONS Any detectable and heritable change in the genetic material that causes a change in the genotype and which is transmitted to daughter cells and to succeeding generations MeSH PATHWAYS A series of biochemical reactions occurring within a cell to modify a chemical substance or transduce an extracellular signal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,72.00,670.04,166.00,10.80;9,72.00,361.80,462.00,291.30"><head>Figure 1 -</head><label>1</label><figDesc>Figure 1 -Passage judgment form.</figDesc><graphic coords="9,72.00,361.80,462.00,291.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="15,72.00,498.80,396.94,10.80;15,168.00,254.40,365.28,204.00"><head>Figure 2 -</head><label>2</label><figDesc>Figure 2 -Heat map for meta-features, their use in runs, and rank group clustering.</figDesc><graphic coords="15,168.00,254.40,365.28,204.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="21,50.40,292.80,55.52,9.02;21,127.73,292.80,7.23,9.02;21,163.69,292.80,367.71,9.02;21,163.80,304.32,37.51,9.02;21,50.40,315.84,86.41,9.02;21,163.91,315.84,237.91,9.02;21,50.40,327.30,41.69,9.02;21,127.82,327.30,7.23,9.02;21,163.81,327.30,55.36,9.02;21,50.40,338.82,43.37,9.02;21,127.80,338.82,3.34,9.02;21,163.79,338.82,158.26,9.02;21,50.40,350.34,38.38,9.02;21,127.80,350.34,7.23,9.02;21,163.80,350.34,157.86,9.02;21,50.40,361.80,33.31,9.02;21,127.78,361.80,7.23,9.02;21,163.77,361.80,381.73,9.02;21,163.80,373.32,261.89,9.02;21,50.40,384.84,33.31,9.02;21,127.78,384.84,7.23,9.02;21,163.78,384.84,383.04,9.02;21,163.80,396.30,378.24,9.02;21,163.80,407.82,365.89,9.02;21,163.80,419.34,381.69,9.02;21,163.80,430.79,166.22,9.02;21,50.40,442.31,33.31,9.02;21,127.78,442.31,7.23,9.02;21,163.77,442.31,367.51,9.02;21,163.80,453.77,377.54,9.02;21,163.80,465.29,371.34,9.02;21,163.80,476.81,379.11,9.02;21,163.80,488.27,366.98,9.02;21,163.80,499.79,244.41,9.02;21,50.40,511.31,40.08,9.02"><head></head><label></label><figDesc>UICGenRun2A Do not differentiate the importance of entities in passages as long as some entity presents in passages. UIowa07Gen01 M title of reference identified from logical document structure UIUCconj Divergence from randomness. Query expansion using forms generated from query words. The length of a passage is delimited by the &lt;p&gt; tag. UniNE2 A Data fusion of three IR systems. 1 Retrieval based on Okapi model with query expansion using forms generated from query words. 2 Retrieval based on Okapi model, using only the original query words. Re-ranking based on distance between query words and entity in the query. 3 Retrieval based on Divergence from randomness. Query expansion using forms generated from query words. Each passage is a sentence. UniNE3 A Data fusion of three IR systems 1-Retrieval based on Divergence from randomness. Query expansion using forms generated from query words and word variant generation for entity and query terms. 2 Retrieval based on Okapi model with query expansion using forms generated from query words. 3 Retrieval based on Divergence from randomness. Query expansion using forms generated from query words. Re-ranking based on distance between query words and entity in the query. Each passage is delimited by the &lt;p&gt; tag. UTEMC1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,365.91,480.20,27.37,10.80"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,72.00,74.84,305.96,57.53"><head>Table 1 -</head><label>1</label><figDesc>Example text for span definitions.</figDesc><table coords="4,72.00,101.82,305.96,30.55"><row><cell>000000000011111111112222222222333333333344444444445</cell></row><row><cell>012345678901234567890123456789012345678901234567890</cell></row><row><cell>Aaa. &lt;p&gt; Bbbbb &lt;b&gt;cc&lt;/b&gt; ddd. &lt;p&gt;&lt;p&gt;&lt;p&gt; Eee ff ggg.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,72.00,74.84,464.52,617.94"><head>Table 2 -</head><label>2</label><figDesc>TREC 2007 Genomics Track official topics.</figDesc><table coords="5,72.00,102.44,464.52,562.74"><row><cell>&lt;200&gt;What serum [PROTEINS] change expression in association with high disease activity in</cell></row><row><cell>lupus?</cell></row><row><cell>&lt;201&gt;What [MUTATIONS] in the Raf gene are associated with cancer?</cell></row><row><cell>&lt;202&gt;What [DRUGS] are associated with lysosomal abnormalities in the nervous system?</cell></row><row><cell>&lt;203&gt;What [CELL OR TISSUE TYPES] express receptor binding sites for vasoactive intestinal</cell></row><row><cell>peptide (VIP) on their cell surface?</cell></row><row><cell>&lt;204&gt;What nervous system [CELL OR TISSUE TYPES] synthesize neurosteroids in the brain?</cell></row><row><cell>&lt;205&gt;What [SIGNS OR SYMPTOMS] of anxiety disorder are related to coronary artery</cell></row><row><cell>disease?</cell></row><row><cell>&lt;206&gt;What [TOXICITIES] are associated with zoledronic acid?</cell></row><row><cell>&lt;207&gt;What [TOXICITIES] are associated with etidronate?</cell></row><row><cell>&lt;208&gt;What [BIOLOGICAL SUBSTANCES] have been used to measure toxicity in response to</cell></row><row><cell>zoledronic acid?</cell></row><row><cell>&lt;209&gt;What [BIOLOGICAL SUBSTANCES] have been used to measure toxicity in response to</cell></row><row><cell>etidronate?</cell></row><row><cell>&lt;210&gt;What [MOLECULAR FUNCTIONS] are attributed to glycan modification?</cell></row><row><cell>&lt;211&gt;What [ANTIBODIES] have been used to detect protein PSD-95?</cell></row><row><cell>&lt;212&gt;What [GENES] are involved in insect segmentation?</cell></row><row><cell>&lt;213&gt;What [GENES] are involved in Drosophila neuroblast development?</cell></row><row><cell>&lt;214&gt;What [GENES] are involved axon guidance in C.elegans?</cell></row><row><cell>&lt;215&gt;What [PROTEINS] are involved in actin polymerization in smooth muscle?</cell></row><row><cell>&lt;216&gt;What [GENES] regulate puberty in humans?</cell></row><row><cell>&lt;217&gt;What [PROTEINS] in rats perform functions different from those of their human</cell></row><row><cell>homologs?</cell></row><row><cell>&lt;218&gt;What [GENES] are implicated in regulating alcohol preference?</cell></row><row><cell>&lt;219&gt;In what [DISEASES] of brain development do centrosomal genes play a role?</cell></row><row><cell>&lt;220&gt;What [PROTEINS] are involved in the activation or recognition mechanism for PmrD?</cell></row><row><cell>&lt;221&gt;Which [PATHWAYS] are mediated by CD44?</cell></row><row><cell>&lt;222&gt;What [MOLECULAR FUNCTIONS] is LITAF involved in?</cell></row><row><cell>&lt;223&gt;Which anaerobic bacterial [STRAINS] are resistant to Vancomycin?</cell></row><row><cell>&lt;224&gt;What [GENES] are involved in the melanogenesis of human lung cancers?</cell></row><row><cell>&lt;225&gt;What [BIOLOGICAL SUBSTANCES] induce clpQ expression?</cell></row><row><cell>&lt;226&gt;What [PROTEINS] make up the murine signal recognition particle?</cell></row><row><cell>&lt;227&gt;What [GENES] are induced by LPS in diabetic mice?</cell></row><row><cell>&lt;228&gt;What [GENES] when altered in the host genome improve solubility of heterologously</cell></row><row><cell>expressed proteins?</cell></row><row><cell>&lt;229&gt;What [SIGNS OR SYMPTOMS] are caused by human parvovirus infection?</cell></row><row><cell>&lt;230&gt;What [PATHWAYS] are involved in Ewing's sarcoma?</cell></row><row><cell>&lt;231&gt;What [TUMOR TYPES] are found in zebrafish?</cell></row><row><cell>&lt;232&gt;What [DRUGS] inhibit HIV type 1 infection?</cell></row><row><cell>&lt;233&gt;What viral [GENES] affect membrane fusion during HIV infection?</cell></row></table><note coords="5,72.00,668.18,319.80,10.80;5,72.00,681.98,349.74,10.80"><p>&lt;234&gt;What [GENES] make up the NFkappaB signaling pathway? &lt;235&gt;Which [GENES] involved in NFkappaB signaling regulate iNOS?</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,72.00,74.84,465.91,24.60"><head>Table 3 -</head><label>3</label><figDesc>TREC 2007 Genomics Track entities, definitions, sources of term, and topics with each entity.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,72.00,74.84,461.35,509.87"><head>Table 4 -</head><label>4</label><figDesc>Relevant passages, relevant documents, mean and standard deviation (SD) of relevant passage length, number of aspects, and mean number of aspects per relevant passage.</figDesc><table coords="10,76.38,115.86,456.97,468.86"><row><cell>Topic</cell><cell>Relevant</cell><cell>Relevant</cell><cell>Mean</cell><cell>SD of</cell><cell>Aspects</cell><cell>Mean</cell></row><row><cell></cell><cell>Passages</cell><cell>Documents</cell><cell>Relevant</cell><cell>Relevant</cell><cell></cell><cell>Aspects Per</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Passage</cell><cell>Passage</cell><cell></cell><cell>Relevant</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Length</cell><cell>Length</cell><cell></cell><cell>Passage</cell></row><row><cell>200</cell><cell>320</cell><cell>193</cell><cell>2380.58</cell><cell>5387.02</cell><cell>300</cell><cell>2.15</cell></row><row><cell>201</cell><cell>37</cell><cell>12</cell><cell>1701.86</cell><cell>2894.64</cell><cell>7</cell><cell>1.16</cell></row><row><cell>202</cell><cell>53</cell><cell>43</cell><cell>522.77</cell><cell>293.60</cell><cell>28</cell><cell>1.45</cell></row><row><cell>203</cell><cell>321</cell><cell>147</cell><cell>2163.60</cell><cell>4237.72</cell><cell>245</cell><cell>1.91</cell></row><row><cell>204</cell><cell>164</cell><cell>74</cell><cell>1989.90</cell><cell>4670.61</cell><cell>36</cell><cell>1.79</cell></row><row><cell>205</cell><cell>93</cell><cell>65</cell><cell>788.67</cell><cell>1277.35</cell><cell>17</cell><cell>1.23</cell></row><row><cell>206</cell><cell>38</cell><cell>19</cell><cell>363.79</cell><cell>362.85</cell><cell>24</cell><cell>1.87</cell></row><row><cell>207</cell><cell>15</cell><cell>12</cell><cell>357.60</cell><cell>671.28</cell><cell>8</cell><cell>1.07</cell></row><row><cell>208</cell><cell>22</cell><cell>16</cell><cell>615.36</cell><cell>317.50</cell><cell>13</cell><cell>1.23</cell></row><row><cell>209</cell><cell>78</cell><cell>11</cell><cell>1239.63</cell><cell>720.81</cell><cell>15</cell><cell>1.50</cell></row><row><cell>210</cell><cell>71</cell><cell>57</cell><cell>669.79</cell><cell>623.70</cell><cell>21</cell><cell>1.10</cell></row><row><cell>211</cell><cell>57</cell><cell>42</cell><cell>191.68</cell><cell>217.10</cell><cell>29</cell><cell>1.14</cell></row><row><cell>212</cell><cell>358</cell><cell>133</cell><cell>1165.97</cell><cell>969.94</cell><cell>142</cell><cell>2.16</cell></row><row><cell>213</cell><cell>377</cell><cell>185</cell><cell>456.94</cell><cell>594.39</cell><cell>165</cell><cell>1.88</cell></row><row><cell>214</cell><cell>209</cell><cell>98</cell><cell>414.91</cell><cell>1095.21</cell><cell>54</cell><cell>1.42</cell></row><row><cell>215</cell><cell>137</cell><cell>73</cell><cell>750.96</cell><cell>580.54</cell><cell>80</cell><cell>1.66</cell></row><row><cell>216</cell><cell>42</cell><cell>34</cell><cell>1058.12</cell><cell>3141.51</cell><cell>13</cell><cell>1.12</cell></row><row><cell>217</cell><cell>38</cell><cell>34</cell><cell>1491.18</cell><cell>1019.48</cell><cell>34</cell><cell>1.03</cell></row><row><cell>218</cell><cell>163</cell><cell>74</cell><cell>632.23</cell><cell>635.55</cell><cell>80</cell><cell>1.28</cell></row><row><cell>219</cell><cell>22</cell><cell>16</cell><cell>623.64</cell><cell>503.66</cell><cell>43</cell><cell>3.41</cell></row><row><cell>220</cell><cell>16</cell><cell>6</cell><cell>425.75</cell><cell>218.10</cell><cell>6</cell><cell>1.75</cell></row><row><cell>221</cell><cell>183</cell><cell>87</cell><cell>1373.32</cell><cell>1705.58</cell><cell>108</cell><cell>1.44</cell></row><row><cell>222</cell><cell>57</cell><cell>42</cell><cell>1249.51</cell><cell>914.23</cell><cell>72</cell><cell>2.18</cell></row><row><cell>223</cell><cell>18</cell><cell>8</cell><cell>269.72</cell><cell>138.24</cell><cell>12</cell><cell>1.17</cell></row><row><cell>224</cell><cell>3</cell><cell>3</cell><cell>1009.33</cell><cell>666.59</cell><cell>1</cell><cell>1.00</cell></row><row><cell>225</cell><cell>1</cell><cell>1</cell><cell>745.00</cell><cell>0.00</cell><cell>1</cell><cell>1.00</cell></row><row><cell>226</cell><cell>152</cell><cell>57</cell><cell>753.82</cell><cell>1648.91</cell><cell>18</cell><cell>2.25</cell></row><row><cell>227</cell><cell>281</cell><cell>172</cell><cell>1307.02</cell><cell>863.14</cell><cell>183</cell><cell>2.25</cell></row><row><cell>228</cell><cell>15</cell><cell>14</cell><cell>632.20</cell><cell>413.79</cell><cell>13</cell><cell>1.87</cell></row><row><cell>229</cell><cell>150</cell><cell>57</cell><cell>528.81</cell><cell>978.41</cell><cell>34</cell><cell>1.79</cell></row><row><cell>230</cell><cell>82</cell><cell>29</cell><cell>1186.65</cell><cell>933.99</cell><cell>25</cell><cell>1.30</cell></row><row><cell>231</cell><cell>16</cell><cell>13</cell><cell>472.00</cell><cell>406.56</cell><cell>7</cell><cell>1.06</cell></row><row><cell>232</cell><cell>93</cell><cell>57</cell><cell>388.57</cell><cell>907.63</cell><cell>49</cell><cell>1.12</cell></row><row><cell>233</cell><cell>19</cell><cell>16</cell><cell>1186.68</cell><cell>1070.54</cell><cell>1</cell><cell>1.00</cell></row><row><cell>234</cell><cell>609</cell><cell>483</cell><cell>1777.02</cell><cell>3124.85</cell><cell>577</cell><cell>3.24</cell></row><row><cell>235</cell><cell>182</cell><cell>107</cell><cell>1963.25</cell><cell>1737.40</cell><cell>141</cell><cell>2.54</cell></row><row><cell>Mean</cell><cell>124.8</cell><cell>69.2</cell><cell>968.0</cell><cell>1276.2</cell><cell>72.3</cell><cell>1.63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,72.00,364.64,466.97,300.54"><head>Table 5 -</head><label>5</label><figDesc>Descriptive statistics for all runs and subdivided by categories.</figDesc><table coords="12,72.00,392.36,466.97,272.82"><row><cell>All</cell><cell>Passage2 MAP</cell><cell>Passage MAP</cell><cell>Aspect MAP</cell><cell>Document MAP</cell></row><row><cell>Min</cell><cell>0.0008</cell><cell>0.0029</cell><cell>0.0197</cell><cell>0.0329</cell></row><row><cell>Median</cell><cell>0.0377</cell><cell>0.0565</cell><cell>0.1311</cell><cell>0.1897</cell></row><row><cell>Mean</cell><cell>0.0398</cell><cell>0.0560</cell><cell>0.1326</cell><cell>0.1862</cell></row><row><cell>Max</cell><cell>0.1148</cell><cell>0.0976</cell><cell>0.2631</cell><cell>0.3286</cell></row><row><cell>Automatic</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Min</cell><cell>0.0008</cell><cell>0.0029</cell><cell>0.0197</cell><cell>0.0329</cell></row><row><cell>Median</cell><cell>0.0391</cell><cell>0.0587</cell><cell>0.1272</cell><cell>0.1954</cell></row><row><cell>Mean</cell><cell>0.0421</cell><cell>0.0582</cell><cell>0.1286</cell><cell>0.1891</cell></row><row><cell>Max</cell><cell>0.1097</cell><cell>0.0976</cell><cell>0.2494</cell><cell>0.3105</cell></row><row><cell>Manual</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Min</cell><cell>0.0032</cell><cell>0.0177</cell><cell>0.0204</cell><cell>0.0541</cell></row><row><cell>Median</cell><cell>0.0149</cell><cell>0.0276</cell><cell>0.1136</cell><cell>0.1696</cell></row><row><cell>Mean</cell><cell>0.0169</cell><cell>0.0328</cell><cell>0.0964</cell><cell>0.1526</cell></row><row><cell>Max</cell><cell>0.0458</cell><cell>0.0654</cell><cell>0.1503</cell><cell>0.2309</cell></row><row><cell>Interactive</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Min</cell><cell>0.0268</cell><cell>0.0394</cell><cell>0.1411</cell><cell>0.0892</cell></row><row><cell>Median</cell><cell>0.0384</cell><cell>0.0620</cell><cell>0.1865</cell><cell>0.1940</cell></row><row><cell>Mean</cell><cell>0.0475</cell><cell>0.0648</cell><cell>0.1868</cell><cell>0.2007</cell></row><row><cell>Max</cell><cell>0.1148</cell><cell>0.0968</cell><cell>0.2631</cell><cell>0.3286</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="13,72.00,74.84,436.61,107.52"><head>Table 6 -</head><label>6</label><figDesc>MAP measure correlation matrix using Pearson correlation coefficient (all values significantly different from 0 with a significance level p &lt; .05).</figDesc><table coords="13,72.00,116.36,435.62,66.00"><row><cell>MAP</cell><cell>Passage2</cell><cell>Passage</cell><cell>Aspect</cell><cell>Document</cell></row><row><cell>Passage2</cell><cell>1</cell><cell>0.656</cell><cell>0.845</cell><cell>0.812</cell></row><row><cell>Passage</cell><cell>0.656</cell><cell>1</cell><cell>0.591</cell><cell>0.830</cell></row><row><cell>Aspect</cell><cell>0.845</cell><cell>0.591</cell><cell>1</cell><cell>0.775</cell></row><row><cell>Document</cell><cell>0.812</cell><cell>0.830</cell><cell>0.775</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="19,50.40,582.59,496.33,135.50"><head></head><label></label><figDesc>based on an interactively created filter applied to the NLMfusion run. OHSUQA A Two stage query generation with MESH and gene synonym expansion, and entity-specific keywords. Lucene maximal passage index, TF*IDF. MMTX based sentence entity count passage trimming. OHSUQASUB A Two stage query generation with MESH and substances expansion, and entity-specific keywords. Lucene maximal passage index, TF*IDF. MMTX based sentence entity count passage trimming. OHSUQASUB EX A Two stage query generation with MESH and substances expansion, and entity-specific keywords. Lucene maximal passage index, TF*IDF. MMTX based sentence entity count passage trimming.</figDesc><table coords="19,50.40,582.59,496.33,135.50"><row><cell>icbdoc UBexp1</cell><cell>M</cell><cell>Rank fusion of seven different search techniques implemented in Twease (includes both</cell></row><row><cell></cell><cell></cell><cell>automatic and manual runs). Optimized for document MAP.</cell></row><row><cell>icbpassage</cell><cell>M</cell><cell>Rank fusion of seven different search techniques implemented in Twease (includes both</cell></row><row><cell></cell><cell></cell><cell>automatic and manual runs). Passages are marked as a post-processing step after document</cell></row><row><cell></cell><cell></cell><cell>retrieval and fusion. At most, ten passages are included per document. Optimized for passage</cell></row><row><cell></cell><cell></cell><cell>MAP.</cell></row><row><cell>icbtwease</cell><cell>M</cell><cell>Manual run with minimal interval semantics performed with Twease using a slider value of 80.</cell></row><row><cell></cell><cell></cell><cell>This run was performed with the same Twease software version deployed at Twease.org as of</cell></row><row><cell></cell><cell></cell><cell>July 2007.</cell></row><row><cell>iitx1r2</cell><cell>A</cell><cell>MST passage extraction by concept sc = (1.0*result.getPassConceptSCNorm() +</cell></row><row><cell></cell><cell></cell><cell>0.1*result.getSentConceptSCNorm() + 1.0*result.getPassConceptIdfSumNorm() +</cell></row><row><cell></cell><cell></cell><cell>0.1*result.getSentConceptIdfSumNorm())</cell></row><row><cell>iitx2r2</cell><cell>A</cell><cell>MST passage extraction by concept sc = (1.0*result.getPassConceptSCNorm() +</cell></row><row><cell></cell><cell></cell><cell>0.1*result.getSentConceptSCNorm() + 1.0*result.getPassConceptIdfSumNorm() +</cell></row><row><cell></cell><cell></cell><cell>0.1*result.getSentConceptIdfSumNorm()) With sentence boosting dependency grammar,</cell></row><row><cell></cell><cell></cell><cell>sumidf, nconcepts</cell></row><row><cell>iitx3r2</cell><cell>A</cell><cell>MST passage extraction by concept sc</cell></row><row><cell></cell><cell></cell><cell>=((passConceptSCNorm+sentConceptSCNorm+passConceptIdfSumNorm+sentConceptIdfSumN</cell></row><row><cell></cell><cell></cell><cell>orm)/4)</cell></row><row><cell>IRn</cell><cell>A</cell><cell>This run has been performed by applying the Information Retrieval technique based on passages.</cell></row><row><cell></cell><cell></cell><cell>The passages are composed of four sentences. The indexing of the document collection applies</cell></row><row><cell></cell><cell></cell><cell>the Okapi measure.</cell></row><row><cell>kyoto1</cell><cell>A</cell><cell>Paragraph-level impact-based retrieval combined with a probabilistic model for term co-</cell></row><row><cell></cell><cell></cell><cell>occurrence. Passages scored using a variant of TF/IDF, but results are ranked using only the IR</cell></row><row><cell></cell><cell></cell><cell>system's scores.</cell></row><row><cell>kyoto2</cell><cell>A</cell><cell>Paragraph-level impact-based retrieval combined with a probabilistic model for term co-</cell></row><row><cell></cell><cell></cell><cell>occurrence. Passages scored using a variant of TF/IDF, but more results were used and then</cell></row><row><cell></cell><cell></cell><cell>ranked using only the PM's scores.</cell></row><row><cell>kyoto3</cell><cell>A</cell><cell>Paragraph-level impact-based retrieval combined with a probabilistic model for term co-</cell></row><row><cell></cell><cell></cell><cell>occurrence. Passages scored using only the probabilistic model and final ranking determined</cell></row><row><cell></cell><cell></cell><cell>using equal weight on both systems.</cell></row><row><cell>LHNCBC</cell><cell>A</cell><cell>An automatic run based on LHC's Essie search engine and for which results are reranked based</cell></row><row><cell></cell><cell></cell><cell>on relationships extracted from Essie results using MetaMap and SemRep.</cell></row><row><cell>MuMshFd</cell><cell>A</cell><cell>Automatic query expansion with entities and ontological terms, but without passage reduction</cell></row><row><cell></cell><cell></cell><cell>and reranking.</cell></row><row><cell>MuMshFdRsc</cell><cell>A</cell><cell>Automatic query expansion with entities and ontological terms, followed by passage reduction</cell></row><row><cell></cell><cell></cell><cell>and reranking.</cell></row><row><cell>MuMshNfdRsc</cell><cell>A</cell><cell>Automatic query expansion with ontological terms only, followed by passage reduction and</cell></row><row><cell></cell><cell></cell><cell>reranking.</cell></row><row><cell>ncbi2007a</cell><cell>A</cell><cell>Reranked Essie hits from NCBI</cell></row><row><cell>ncbi2007b</cell><cell>A</cell><cell>generated by Larry</cell></row><row><cell>NLMfusion</cell><cell>A</cell><cell>An automatic run obtained by applying fusion to the LHNCBC run, a Terrier run, an NCBI</cell></row><row><cell></cell><cell></cell><cell>Themes run, an INDRI run and an easyIR run.</cell></row><row><cell cols="3">fdgerun1 fdgerun2 fdgerun3 GenTeaBB GenTeam1 GenTeaPA NLMinter An interactive run TsingHua3 A Automatically extract the relevant concepts of each topic, retrieval sentences according to those concepts. A Automatically extract relevant concepts of each topic, combine the result of sentence retrieval and the one of context retrieval. M Score each sentence according to the concurrency of concept terms from different groups. A Same as GenTeam1 but with Boolean boosting. A Basic run using easyIR as IR engine (dtu.dtn, Porter). A Same run as GenTeaBB, but with passage selection based on assesing the density of semantic I A (run3)Machine learning and dictionary based NE recognition, BM2500, Treble passage retrieval.</cell></row><row><cell>TsingHua4</cell><cell>A</cell><cell>targets. (run4) Machine learning and dictionary based NE, sigma local df for weighting, Treble passage</cell></row><row><cell>HFmanual</cell><cell>M</cell><cell>Hongfang's run retrieval</cell></row><row><cell>hltcairo1 TsingHua5</cell><cell>A A</cell><cell>First 25 results from the search engine (run5_new) strictly generated dictionary for NE, max local df for weighting, Treble passage</cell></row><row><cell>hltcairo2</cell><cell>A</cell><cell>First 50 results from the search engine retrieval, reduction</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The <rs type="institution">TREC Genomics Track</rs> was funded by grant <rs type="grantNumber">ITR-0325160</rs> from the <rs type="funder">U.S. National Science Foundation</rs>. The track thanks <rs type="person">Ellen Voorhees</rs>, <rs type="person">Ian Soboroff</rs>, and <rs type="funder">Lori Buckland of NIST</rs> for their help in various ways. We also thank <rs type="person">John Sack</rs> and <rs type="person">Highwire Press</rs> for facilitating the use of documents from the respective publishers as well as the <rs type="institution">U.S. National Library of Medicine</rs> for their use of MEDLINE data.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_wG3xuXY">
					<idno type="grant-number">ITR-0325160</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="18,76.50,337.04,4.50,10.80;18,108.02,337.04,401.02,10.80;18,108.00,350.84,416.34,10.80;18,108.00,364.64,396.24,10.80" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec15/papers/GEO.OVERVIEW.pdf" />
		<title level="m" coord="18,242.71,337.04,266.33,10.80;18,108.00,350.84,55.35,10.80">Genomics Track overview. The Fifteenth Text Retrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006. 2006</date>
			<biblScope unit="page" from="52" to="78" />
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards &amp; Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,76.50,378.44,4.50,10.80;18,108.01,378.44,426.95,10.80;18,108.00,392.24,394.63,10.80;18,108.00,406.04,230.69,10.80;18,108.00,419.84,308.16,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="18,148.38,378.44,381.15,10.80">HARD Track overview in TREC 2004 -high accuracy retrieval from documents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec13/papers/HARD.OVERVIEW.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="18,108.00,392.24,200.02,10.80">The Thirteenth Text Retrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,76.50,433.58,4.50,10.80;18,108.00,433.58,422.92,10.80;18,108.00,447.38,425.89,10.80;18,108.00,461.18,21.00,10.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="18,194.40,433.58,336.52,10.80;18,108.00,447.38,65.41,10.80">Advancing biomedical image retrieval: development and analysis of a test collection</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,180.96,447.38,274.65,10.80">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="488" to="496" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
