<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.64,113.49,295.78,16.19;1,169.68,140.43,255.83,16.19">IR-Specific Searches at TREC 2007: Genomics &amp; Blog Experiments</title>
				<funder ref="#_8kvfkTj">
					<orgName type="full">Swiss NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,217.20,171.74,72.74,10.79"><forename type="first">Claire</forename><surname>Fautsch</surname></persName>
							<email>claire.fautsch@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel Rue Emile-Argand</orgName>
								<address>
									<addrLine>11</addrLine>
									<postCode>CH-2009</postCode>
									<settlement>Neuchatel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.83,171.74,79.12,10.79"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel Rue Emile-Argand</orgName>
								<address>
									<addrLine>11</addrLine>
									<postCode>CH-2009</postCode>
									<settlement>Neuchatel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.64,113.49,295.78,16.19;1,169.68,140.43,255.83,16.19">IR-Specific Searches at TREC 2007: Genomics &amp; Blog Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7A118D50BFCA4110DC6EE653830109E8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the TREC 2007 Genomics and Blog evaluation campaigns. Within these two tracks, our main intent is to go beyond simple document retrieval, using different search and filtering strategies to obtain more specific answers to user information needs. In the Genomics track, the dedicated IR system has to extract relevant text passages in support of precise user questions. This task may also be viewed as the first stage of a Question/Answering system. In the Blog track we explore various strategies for retrieving opinions from the blogsphere, which in this case involves subjective opinions about various targets entities (e.g., person, location, organization, event, product or technology). This task can be subdivided in two parts: 1) retrieve relevant information (facts) and 2) extract positive, negative or mixed opinions about the specific entity being targeted.</p><p>To achieve these objectives we evaluate retrieval effectiveness using the Okapi (BM25) and various other models derived from the Divergence from Randomness (DFR) paradigm, as well as a language model (LM). Through our experiments with the Genomics corpus we find that the DFR models perform clearly better than the Okapi model (relative difference of 70%) in terms of mean average precision (MAP). Using the blog corpus, we found the opposite; the Okapi model performs slightly better than both DFR models (relative difference around 5%) and LM (relative difference 7%) model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The biomedical domain presents the information retrieval (IR) community with a number of challenging problems. For the first Genomics campaign <ref type="bibr" coords="1,183.11,658.71,11.41,8.50" target="#b1">[1]</ref> for example the main objective was to retrieve bibliographic references (composed mainly of title, author names and abstract) from a large subset of the MEDLINE repository, in order to meet real user needs. Last year <ref type="bibr" coords="1,180.67,704.25,10.38,8.50" target="#b2">[2]</ref>, the main goal was to retrieve text fragments or passages rather than the entire scientific article. From an IR point of view, this task lies somewhere between classical text retrieval in which search responses consists of documents (or references to these documents) and question/answering where responses consist of very short passages extracted from documents. The term "passage" is in fact not very precise, given it could refer to a paragraph, sentence, or a short window of n characters.</p><p>For the Blog track <ref type="bibr" coords="1,399.68,333.03,10.33,8.50" target="#b3">[3]</ref>, the IR system has to retrieve relevant information from different permalink documents (URLs pointing to a specific blogging entry), representing various points of view on various domains. Unlike traditional document collections used in the IR domain, a blog is more subjective, while also being characterized by more diverse document structures and writing styles. Even though the blogsphere may contain objective information (facts), the objective of the Blog track is to find answers based on opinions rather than relevant factual information. As such, relevant answers to the request "IPhone" may include factual and technological information (relevant but unopinioned answers) but also more personalized (and subjective) aspects of the product (why it is useful, complaints about this new tool, drawbacks of using a specific function, personal experiences concerning new product, etc.). Thus, in a first step the answer would contain a ranked list of relevant documents, but in a second stage a classification procedure would subdivide them into documents not based on opinion (factual information or descriptions), or documents expressing positive, mixed or negative opinion about the target entity.</p><p>The rest of this paper is organized as follows. Section 2 depicts the main characteristics of the Genomics testcollection and how passages are derived from an article according to our definition while Section 3 describes the main features of the Blog test-collection. Section 4 describes the indexing approach and Section 5 briefly presents the three probabilistic models used to search the genomics or blogsphere. Section 6 evaluates the three IR models by applying different conditions. Finally, the main findings of this paper are presented in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">GENOMICS TEST-COLLECTION</head><p>The document collection used this year contains approximately 12 GB of uncompressed data, made up of 162,259 full-text publications extracted from 49 biomedical journals (for more details, see the Web site at http://ir.ohsu.edu/genomics/2006data.html). To facilitate the effective retrieval of relevant passages and not documents, the IR literature <ref type="bibr" coords="2,188.95,200.19,11.40,8.50" target="#b4">[4]</ref> defines passages according to their various types, based mainly on delimiters such as text, window or semantic markers.</p><p>In a first approach to defining passages, we processed each article in order to generate its corresponding passages.</p><p>As passage delimiters, we assigned the following HTML tags: H1, H2, H3, H4, H5, H6, P, BR, HR, Proteome Caused by Huntington's disease &lt;TX&gt; In addition to the cytoplasmic brain fraction that was used in the above experiments, proteins solubilized by urea and detergent treatment, yielding an extract enriched in membrane proteins, as well as DNA-binding proteins released by DNase, were screened to expand the range of protein classes studied. In both fractions no additional proteins were consistently different between R6/2 and control mice (data not shown). AAT was present at low amounts in the membrane fraction and undetectable in the fraction of proteins released by DNase in control mice, arguing for a mainly cytoplasmic localization of the protein (data not shown). ABC was found in all three fractions. A consistently lower expression of ABC and AAT expression below the detection limit were detected in R6/2 samples in all three fractions (data not shown).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;/PASSAGE&gt;</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Example of generated passage</head><p>Figure <ref type="figure" coords="2,82.09,570.39,4.87,8.50">1</ref> shows an example of a passage that might be generated. All our passages are structured according to the following set of fields.</p><p>FN (article filename path), ID (passage identifier), SO (start offset), L (passage length in bytes), TGN (tag name from which the passage was extracted), R (indicates whether or not the passage is identified as a reference), TITLE (title of article), TX (passage contents).</p><p>Following the filtering of all passages containing fewer than 10 words, the resulting collection contained exactly 10,700,925 passages from which 1,275,132 (11.9%) were marked as references.</p><p>For a second passage definition we used the sentence level and reused the subdivision structure applied  Based on opinion-based relevance assessments (2 ≤ relevance value ≤ 4), we found 7,000 correct opinions.</p><p>The mean number of relevant web pages per topic is 140.0 (median: 109.5; standard deviation: 123.456). Topic #910 ("Aperto Networks") and Topic #950 ("Hitachi Data Systems") returned a minimal number of pertinent passages (4) while Topic #903 ("Steve jobs") produced the most relevant passages (496).</p><p>The polarity of opinions pertaining to target entities could be divided into three groups: negative (relevance value = 2), mixed (relevance value = 3) or positive (relevance value = 4) opinion. From an analysis of negative opinions only (relevance value = 2), we found 1,844 correct answers (mean: 40.087, median: 22.5, min: 1 (Topic #909 "Barilla", #934 "cointreau", #948 "sorbonne" or #950 "Hitachi Data Systems"), max: 189 (Topic #912, "nasa"), standard deviation: 45.12). Topic #901 ("jstor"), #910 ("Aperto Networks"), #914 ("northernvoice") and #925 ("mashup camp") obtained no positive opinions.</p><p>For positive opinions only (relevance value = 4), we found 2,960 correct answers (mean: 59.2, median: 49.5, min: 1 (Topic #950, "Hitachi Data Systems"), max: 234 (Topic #903, "Steve jobs"), standard deviation: 53.98).</p><p>Finally for mixed opinions only (relevance value = 3), we found 2,196 correct answers (mean: 47.74, median: 22, min: 1 (Topic #901, "jstor", and Topic #925, "mashup camp"), max: 196 (Topic #946, "tivo"), standard deviation: 50.74).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">INDEXING APPROACHES</head><p>To index documents or queries, we applied the indexing method described in Section 4.1. To derive orthographic variations of protein or gene names that could be included in topics, we used the algorithm described in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Document Indexing</head><p>As a natural approach to indexing and searching both corpora, we chose words as the indexing units. As such our lexical analyzer applies the followings steps to process the input. First, the text is tokenized (using spaces or punctuation marks), simple acronyms are normalized (e.g., D.N.A. is converted into DNA) and hyphenated terms are also broken up into their components. For example, a word such as "COUP-TF1" generates three different forms, namely "COUP", "TF1" and the original form "COUP-TF1". Second, uppercase letters are transformed into their lowercase forms. Third, stopwords are filtered out using the SMART list (571 entries). Fourth, with the S-stemmer algorithm <ref type="bibr" coords="4,243.31,489.15,11.46,8.50" target="#b5">[5]</ref> based on three rules, we remove the final '-s' (the most common plural suffix for the English language). This choice is based on the experiments we did over previous years <ref type="bibr" coords="4,266.36,523.29,10.33,8.50" target="#b6">[6]</ref>, <ref type="bibr" coords="4,52.38,534.69,11.40,8.50" target="#b7">[7]</ref> which demonstrate that out of the four evaluated stemmers (Lovins, S-stemmer, Porter and SMART) the Sstemmer provided the best retrieval effectiveness.</p><p>For the Blog task we also considered a second tokenization procedure. For example we noticed that in certain blogs there are rather long sequences of identical letters such as "aaaaah" and thus we retained only the first three letters, transforming it into "aaah".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generation of Orthographic Variants</head><p>As is known, in biomedical literature there can be several orthographic variants <ref type="bibr" coords="4,145.80,670.23,11.40,8.50">[8]</ref> representing a given name, generally introduced for a variety of reasons:</p><p>1) Typographic errors and misspellings (e.g. "retreival" and "retrieval") or cognitive (e.g., "ecstasy", "extasy", or "ecstacy"; "occurence" or "occurrence");</p><p>2) Alternative punctuation and tokenization, mainly due to the lack of a naming convention (e.g. "Nur77", "Nurr-77" or "Nurr 77");</p><p>3) Regional language variations, such as British and American English (e.g. "colour" or "color", "grey" or "gray", etc.) 4) Transliteration of foreign names (e.g., "Crohn" and "Krohn" or "Creutzfeld-Jakob" and "Creutzfeldt-Jacob");</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Morphological variations (inflections or derivations)</head><p>which could be resolved by using a stemmer.</p><p>During previous TREC campaigns, many methods were proposed for resolving problems with orthographic variations, as for example <ref type="bibr" coords="4,422.39,272.07,10.37,8.50" target="#b9">[9]</ref>. The algorithms proposed were usually rule-based and were essentially concerned with secondary causes such as those described above (e.g., see <ref type="bibr" coords="4,352.33,306.21,14.67,8.50" target="#b10">[10]</ref>).</p><p>In order to automatically find a ranked list of alternative spellings for each search word, we modified the Lucene <ref type="bibr" coords="4,315.18,344.25,16.27,8.50" target="#b11">[11]</ref> Spell Checker<ref type="foot" coords="4,388.86,342.85,2.92,5.09" target="#foot_0">1</ref> . In its initial stage this tool required a lexicon containing the correct spelling, so in our case we used the words extracted from the TREC 2005 corpus, a large subset of the MEDLINE collection. We then introduced a single term or a short sequence of words, limited in the current case to two terms. The spellchecker thus responded by returning a ranked list of the top 100 hits extracted from the given lexicon. In our case we used the following formula to re-ranked this list according to the minimal edit-distance measure and its length, calculated for each candidate considered a variant of the original (misspelled) term submitted:</p><formula xml:id="formula_0" coords="4,322.50,484.65,169.74,8.50">Score = 1 -[ edit-distance / length(term) ]</formula><p>When the two similar candidates were deemed to be equal (which occurred relatively frequently), they were ordered according to popularity (or df, document frequency), ranging from most to less frequent.</p><p>For each topic available in this TREC campaign, we submitted each search word or group of two successive words to the spellchecker engine. As shown in Figure <ref type="figure" coords="4,535.62,572.13,3.65,8.50" target="#fig_1">6</ref>, the spelling candidates were then re-sequenced by the edit and df measure and automatically added to the topic following the &lt;BISPLELL-n&gt; tag (followed by the alternative number).</p><p>In Figure <ref type="figure" coords="4,358.99,632.97,3.68,8.50" target="#fig_1">6</ref>, the input attribute describes the term submitted to the spellchecker. The score attribute refers to the final score achieved by the alternative term.</p><p>We then used the WordNet thesaurus to automatically enlarge the query. As shown in Figure <ref type="figure" coords="4,472.99,682.35,4.87,8.50" target="#fig_1">6</ref> for the entity in question and the tag &lt;ENTITY-EXPANSION&gt; we could add synonyms (e.g. "dna" for Topic #214) or morphologically related terms (e.g., "signal signaling signalize singnalise" to the term "signal"), and modifications such as these were made for 30 out of 50 queries. Finally for the tag &lt;MEDICAL-TERM&gt; we added synonyms from the question words extracted from the WordNet thesaurus. The number of added synonyms is relatively low (e.g., 20 words for the 50 queries under the tag &lt;MEDICAL-TERM&gt;).</p><p>&lt;ID&gt;  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RETRIEVAL MODELS</head><p>In our evaluations we conducted experiments by applying the single IR models described in Section 5.1 or by merging the result lists computed by various single IR models as explained in Section 5.2 (data fusion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Single IR Models</head><p>To begin our evaluation we considered three probabilistic retrieval models. As a first approach, we used the Okapi (BM25) model <ref type="bibr" coords="5,113.55,562.71,14.96,8.50" target="#b12">[12]</ref>, evaluating the document D i score for the current query Q using the following formula:</p><p>[ ]</p><formula xml:id="formula_1" coords="5,52.56,590.58,222.72,45.75">) / ( ) 1 ( where , ) 1 ( log ) , ( 1 1 avdl l b b k K tf K tf k df df n qtf Q D Score i q t ij ij j j i j ⋅ + - ⋅ = + ⋅ + ⋅ ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ - ⋅ = ∑ ∈ (1)</formula><p>in which the constant advl was fixed at 839 for the Blog corpus and 14 with sentences (Genomics) or 63 with our passage delimitation (Genomics), b was set to either 0.4 (Blog), 0.55 (Genomics, passages), or 0.35 (Genomics, sentences) and k 1 = 1.4 (Blog) or 1.2 (Genomics).</p><p>As a second approach, we implemented various models derived from the Divergence from Randomness (DFR) paradigm <ref type="bibr" coords="5,356.97,108.52,14.96,8.48" target="#b13">[13]</ref>. In this case, the document score was evaluated as:</p><formula xml:id="formula_2" coords="5,315.30,133.32,220.98,21.64">∑ ∈ ⋅ = q t ij i j w qtf Q D Score ) , (<label>(2)</label></formula><p>where qtf denotes the frequency of term t j in query Q, and the weight w ij of term t j in document D i is based on combining two information measures as follows:</p><formula xml:id="formula_3" coords="5,320.64,201.19,205.49,11.32">w ij = Inf 1 ij • Inf 2 ij = -log 2 [Prob 1 ij (tf)] • (1 -Prob 2 ij (tf))</formula><p>As a first model, we implemented the PB2 scheme, defined by the following equations:</p><formula xml:id="formula_4" coords="5,320.64,244.43,223.32,43.13">Inf 1 ij = -log 2 [(e -λ j • λ j tf ij )/tf ij !] with λ j = tc j / n (3) Prob 2 ij = 1 -[(tc j +1) / (df j • (tfn ij + 1))] with tfn ij = tf ij • log 2 [1 + ((c•mean dl) / l i )]</formula><p>(4) where tc j indicates the number of occurrences of term t j in the collection, l i the length (number of indexing terms) of document D i , mean dl is the average document length (fixed at 839 for the Blog, or 63 for the Genomics), n the number of documents in the corpus, and c a constant (= 5 for the Blog or the Genomics sentences or to 9.5 for the Genomics passages).</p><p>For the second model PL2, the implementation of Prob 1 ij is given by Equation <ref type="formula" coords="5,406.73,393.40,3.67,8.48">3</ref>, and Prob 2 ij by Equation <ref type="formula" coords="5,522.12,393.40,3.67,8.48" target="#formula_5">4</ref>, as shown below:</p><formula xml:id="formula_5" coords="5,320.64,416.95,223.34,11.38">Prob 2 ij = tfn ij / (tfn ij + 1)<label>(4)</label></formula><p>where λ j and tfn ij were defined previously.</p><p>For the third model called IneC2, the implementation is given by the following two equations:</p><formula xml:id="formula_6" coords="5,320.64,478.69,133.91,28.47">Inf 1 ij = tfn ij • log 2 [(n+1) / (n e +0,5)] with n e = n • [1 -[(n-1)/n] tc j ]</formula><p>(5)</p><formula xml:id="formula_7" coords="5,320.64,513.85,223.32,11.31">Prob 2 ij = 1 -[(tc j +1) / (df j • (tfn ij +1))]<label>(6)</label></formula><p>where n, tc j and tfn ij were defined previously, and df j indicates the number of documents in which the term t j occurs.</p><p>A third approach we considered was based on a statistical language model (LM) <ref type="bibr" coords="5,417.34,586.18,15.01,8.48" target="#b14">[14]</ref>, <ref type="bibr" coords="5,443.24,586.18,14.95,8.48" target="#b15">[15]</ref>, where probability estimates would be estimated directly, based on occurrence frequencies in document D i or corpus C.</p><p>According to this language model paradigm, various implementation and smoothing methods could be considered, although in this study we adopted the model proposed by Hiemstra <ref type="bibr" coords="5,410.22,654.40,16.32,8.48" target="#b15">[15]</ref> as described in Equation <ref type="formula" coords="5,535.58,654.40,3.65,8.48">7</ref>, combining an estimate based on document (P[t j | D i ]) and on corpus (P[t j | C]).</p><formula xml:id="formula_8" coords="5,320.64,690.01,215.82,13.24">P[D i | Q] = P[D i ] . ∏ t j ∈Q [λ j . P[t j | D i ] + (1-λ j ) . P[t j | C]]</formula><p>with P[t j | D i ] = tf ij /l i and P[t j | C] = df j /lc and with lc = ∑ k df k <ref type="bibr" coords="5,532.56,716.80,11.41,8.48" target="#b7">(7)</ref> where λ j is a smoothing factor (constant for all indexing terms t j , and usually fixed at 0.35) and lc an estimate of the size of the corpus C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Combining Different IR Models</head><p>It is assumed that combining different search models would improve retrieval effectiveness, due to the fact that each document representation might retrieve pertinent items not retrieved by others and thus increase overall recall <ref type="bibr" coords="6,79.27,218.02,14.95,8.48" target="#b16">[16]</ref>. In this current study we combined three probabilistic models representing both the parametric (Okapi and DFR) and non-parametric (language model or LM) approaches. Various fusion operators have been suggested to perform these combinations, such as the "Sum RSV" operator, where the combined document score (or the final retrieval status value) is simply the sum of the retrieval status value (RSV k ) for the corresponding document D k computed by each single indexing scheme <ref type="bibr" coords="6,52.38,320.44,15.00,8.48" target="#b17">[17]</ref>.</p><formula xml:id="formula_9" coords="6,57.90,331.97,223.32,23.93">Z-score RSV k = [((RSV k -Mean i ) / Stdev i )+ δ i ], δ i = ((Mean i -Min i ) / Stdev i )<label>( 8 )</label></formula><p>This year, we only used the Z-Score operator (shown in Eq. 8) to combine two or more single runs. To do this we needed to compute the average RSV value (denoted Mean i ) and the standard deviation (denoted Stdev i ) for each ith result list. These values could then be used to normalize the retrieval status for each document D k found in the ith result list through computing the deviation for RSV k with respect to the mean (Mean i ). Of course another method would be to weight the relative contribution of each retrieval scheme by assigning a different α i value to each retrieval model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EVALUATION</head><p>To evaluate our various search strategies, we used the tool provided by the organizers, based on the TREC_EVAL method to measure retrieval effectiveness. Based on the retrieval of 1,000 passages per query, this program computed different performance measures (e.g., the MAP).</p><p>For the Blog collection, we limited our investigation to the opinion-finding task, namely the retrieval of information on the target entities without classifying them as positive, negative or mixed. For the Genomics task, the MAP was used in three different types of granularity at the document, passage and passage2 levels, and also at the feature level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Genomics Official Runs</head><p>Table <ref type="table" coords="6,77.05,680.56,4.86,8.48" target="#tab_4">1</ref> provides a description of our three official runs within the Genomics task. These runs were based on the two probabilistic models (Okapi &amp; I(n)B2) and include some of the search features described previously. First we listed the I(n)B2 model with the WordNet expansions (see Figure <ref type="figure" coords="6,361.89,108.52,4.86,8.48" target="#fig_1">6</ref> for an example). In our second official run we applied WordNet thesaurus expansions and for our third we considered orthographic variants resulting from WordNet expansions. and then these same models with the WordNet (WN) query expansion option (lines 5 to 8). In lines 9 and 12 we used the Okapi and I(n)B2 models along with spelling variations of the search terms, and finally we evaluated the Okapi and I(n)B2 approaches with both WordNet and orthographic variant expansions (lines 13 and 16). Our three official runs thus combined IR models based on the Z-score approach (see Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>The results listed in Table <ref type="table" coords="7,159.61,108.52,4.86,8.48">2</ref> show that through using the WordNet thesaurus, we could enlarge the query (both with synonyms and morphological related terms) and improve the MAP results (from 9.6% to 31.2% in relative values). For example, with the I(n)B2 model, the MAP increases from 0.2533 to 0.2777 (+9.6%). Including orthographic variants tend to hurt slightly the MAP values (from -5.4% to 2%). When compared to the use of passage segmentation (denoted &lt;P &lt;/P in Table <ref type="table" coords="7,253.69,199.66,3.55,8.48">2</ref>), the use of sentences as passages was clearly not a good idea. Applying the document-based MAP, our best run (UniNE1) produced performances that were 30 times better than the median of all submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Opinion-Finding Official Runs</head><p>To search information in the blogsphere, we based our official runs on three IR systems, namely the probabilistic Okapi model, the language model (LM) and models derived from the Divergence from Randomness (DFR) paradigm. See Table <ref type="table" coords="7,151.10,325.42,4.86,8.48" target="#tab_6">3</ref> for an evaluation of these different IR approaches and three query formulations (T, TD and TDN). In this case we considered all factorial web pages to be relevant (relevance value, rv=1) and all documents comprising various opinions (negative rv=2, mixed rv=3 or positive rv=4) concerning the specified target entity.  Because this search model does not account for noun phrases, there was a decrease in retrieval effectiveness due to our inability to impose the presence of two (or more) search terms. With title-only queries such as Topic #929 ("Brand manager"), Topic #921 ("Christianity Today") or Topic #928 ("Big Love") for example, the presence of both terms in the web page should be imposed and thus ensure their retrieval. Our IR models tend to extract many documents because one of the search terms has a high term frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Difficult Topics in the Blog Track</head><p>A second problem is our extended stopword list. In order to ignore HTML-tags (which may have passed the parsing step) and also to remove very frequent blog words, we added a few terms to our stopword list (e.g., big, com). In Topic #928 ("Big Love") or Topic #916 ("dice.com") however this reduced the underling query to the single term "love" or "dice", meaning that such a query would not effectively retrieve and rank highly relevant web pages.</p><p>For Topic #916 ("dice.com"), our IR systems encountered a problem related to spam. Given that "dice.com" was reduced to "dice", most retrieved documents at the top of the result list assigned very high term frequency to the term "dice". Most of the spam blogs retrieved thus had the same content, being a list of popular internet searches containing terms such as "dice game", "dodecahedron dice" or "Dice Games and Rules", all of which originate from the same server (newgreatblogs.com).</p><p>For Topic #937 ("LexisNexis") most of the highly ranked yet non-relevant web pages were retrieved from the same blog (lawprofessors.typepad.com/law_librarian_blog), which contains numerous links to the LexisNexis web site. The outcome was an increase in the tf component for those pages, providing them with higher ranks. Unfortunately we cannot simply ignore these pages because they originate from a blog that also contains some relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>During this TREC 2007 Genomic evaluation campaign we evaluated various indexing and search strategies. The empirical evidence collected shows that the DFR-I(n)B2 model tends to perform better than the Okapi probabilistic model (0.2533 vs. 0.1486, document-based MAP). The inclusion of orthographic variants for search words (or two-word query sequences) does not really improve retrieval effectiveness, at least as implemented in our system (e.g., with the I(n)B2 model, from 0.2533 to 0.2510).</p><p>Enlarging query formulations by adding synonyms or morphological related words extracted from the WordNet thesaurus results in better MAP (e.g., from 0.2533 to 2777 using the I(n)B2 model). Our passage segmentation approach was clearly more efficient than an approach based on sentences.</p><p>In the Blog track (limited in our case to retrieving opinions on a target entity), we find that the Okapi or the DFR-PL2 search models tend to produce the best MAP for certain query formulations. For example with the T query formulation we obtained a MAP of 0.3585 for the Okapi model compared to 0.3331 for the language model (-7.1%). By including the topic's descriptive part, this formulation increases the MAP by around 12% in mean (e.g., Okapi 0.3585 vs. 0.4003). Including the narrative part however tends to hurt the MAP (mean decrease around -2%). Moreover, simple IR models tend to produce retrieval performance similar to that of more complex IR strategies, such as those combining two ranked lists. When using TD queries for example the DFR-PL2 produces a MAP of 0.4033 while with a combined run (DFR-PB2 and Okapi plus pseudorelevance feedback) a similar MAP (0.4034) resulted. In an effort to improve the MAP, we analyzed various difficult topics and their result lists. From an analysis of these resultant ranked lists we concluded that accounting for noun phrases (e.g., "Brand manager", "Big Love") or at least accounting for the presence of the two (or more) search terms in the retrieved web page may improve the MAP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,333.42,428.40,191.33,8.77;3,315.18,447.75,227.73,8.50;3,315.18,459.09,227.72,8.50;3,315.18,470.49,227.70,8.50;3,315.18,481.89,227.75,8.50;3,315.18,493.23,227.75,8.50;3,315.18,504.63,227.76,8.50;3,315.18,516.03,227.73,8.50;3,315.18,527.37,222.97,8.50"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Three examples of Blog track topicsBased on relevance assessments (relevant facts &amp; opinions, or relevance value ≥ 1) made on this test collection, we listed 12,187 correct answers. The mean number of relevant web pages per topic is 243.74 (median: 208; standard deviation: 186.0). Topic #939 ("Beggin' Strips") returned the minimal number of pertinent passages<ref type="bibr" coords="3,391.20,516.03,16.33,8.50" target="#b16">(16)</ref> while Topic #903 ("Steve jobs") produced the greatest number of relevant passages (710).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,58.38,420.78,215.86,8.77;5,84.30,432.18,163.94,8.77"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Example of two topics, their orthographic variants and their WordNet expansions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,52.38,283.71,191.66,87.17"><head></head><label></label><figDesc>TABLE, TD, TH, TR, OL, and UL.</figDesc><table coords="2,52.38,303.10,191.66,67.78"><row><cell>&lt;PASSAGE&gt;</cell></row><row><cell>&lt;FN&gt; /raid/Genomics/peds/12118078.html</cell></row><row><cell>&lt;ID&gt; 12118078.23</cell></row><row><cell>&lt;SO&gt; 28541</cell></row><row><cell>&lt;L&gt; 978</cell></row><row><cell>&lt;TGN&gt; p</cell></row><row><cell>&lt;R&gt; false</cell></row><row><cell>&lt;TITLE&gt; Alterations in the Mouse and Human</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,315.18,169.28,227.76,520.36"><head>Figure 2. Examples of three topics (genomics corpus) 3. BLOG TEST-COLLECTION</head><label></label><figDesc></figDesc><table coords="2,315.18,169.28,227.76,520.36"><row><cell>&lt;DOC&gt;</cell><cell></cell></row><row><cell>&lt;DOCNO&gt; BLOG06-20051212-051-0007599288</cell><cell></cell></row><row><cell>&lt;DATE_XML&gt; 2005-10-06T14:33:40+0000</cell><cell></cell></row><row><cell>&lt;FEEDNO&gt; BLOG06-feed-063542</cell><cell></cell></row><row><cell>&lt;FEEDURL&gt; http://</cell><cell></cell></row><row><cell>contentcentricblog.typepad.com/ecourts/index.rdf</cell><cell></cell></row><row><cell>&lt;PERMALINK&gt; http://contentcentricblog.typepad.com/ecourts/20 05/10/efiling_launche.html#</cell><cell>at Erasmus MC -University Medical Center Rotterdam (the</cell></row><row><cell>&lt;DOCHDR&gt; …</cell><cell>Netherlands) (see the Web site www.biosemantics.org).</cell></row><row><cell>Date: Fri, 30 Dec 2005 06:23:55 GMT Accept-Ranges: bytes</cell><cell>This collection consisted also of 36 topics (numbered</cell></row><row><cell>Server: Apache</cell><cell>#200 to #235) corresponding to the real information</cell></row><row><cell>Vary: Accept-Encoding,User-Agent Content-Type: text/html; charset=utf-8 …</cell><cell>needs commonly expressed by biologists (see Figure 2 for examples). Each topic relates to one of the 14 possible</cell></row><row><cell>&lt;DATA&gt; electronic Filing &amp;amp; Service for Courts … October 06, 2005</cell><cell>biological entity types (e.g., antibodies, diseases, mutations, pathways, tumor types, signs or symptoms). This information could thus be used to automatically</cell></row><row><cell>eFiling Launches in Canada Toronto, Ontario, Oct.03 /CCNMatthews/ -</cell><cell>enlarge the submitted query.</cell></row><row><cell>LexisNexis Canada Inc., a leading provider of comprehensive and authoritative legal, news, and business information and tailored applications to legal and corporate researchers, today</cell><cell>&lt;ID&gt; 200 &lt;QUESTION&gt; What serum [PROTEINS] change expression in association with high disease</cell></row><row><cell>announced the launch of an electronic filing</cell><cell>activity in lupus?</cell></row><row><cell>pilot project with the Courts</cell><cell></cell></row><row><cell>…</cell><cell>&lt;ID&gt; 214</cell></row><row><cell></cell><cell>&lt;QUESTION&gt; What [GENES] are involved axon</cell></row><row><cell></cell><cell>guidance in C.elegans</cell></row><row><cell></cell><cell>&lt;ID&gt; 232</cell></row><row><cell></cell><cell>&lt;QUESTION&gt; What [DRUGS] inhibit HIV type 1</cell></row><row><cell></cell><cell>infection?</cell></row><row><cell></cell><cell>The Blog test collection contains approximately 148 GB</cell></row><row><cell></cell><cell>of uncompressed data, made up of 4,293,732 documents</cell></row><row><cell></cell><cell>extracted from three sources: 753,681 feeds (or 17.6%),</cell></row><row><cell></cell><cell>3,215,171 permalinks (74.9%) and 324,880 homepages</cell></row><row><cell></cell><cell>(7.6%). Their size is as follows; 38.6 GB for feeds (or</cell></row><row><cell></cell><cell>26.1%), 88.8 GB for permalinks (60%) and 20.8 GB for</cell></row><row><cell></cell><cell>the homepages (14.1%). In this evaluation campaign only</cell></row><row><cell></cell><cell>the permalink part is used. This corpus was crawled</cell></row><row><cell></cell><cell>between Dec. 2005 and Feb. 2006 (for more information</cell></row><row><cell></cell><cell>see: http://ir.dcs.gla.ac.uk/test_collections/).</cell></row><row><cell></cell><cell>Figure 3 depicts two examples of blog documents,</cell></row><row><cell></cell><cell>showing their date, URL source and permalink structure at</cell></row><row><cell></cell><cell>the beginning of each document. Some information</cell></row><row><cell></cell><cell>extracted during the crawl is placed after the &lt;DOCHDR&gt;</cell></row><row><cell></cell><cell>tag. Additional pertinent information follows after the</cell></row><row><cell></cell><cell>&lt;DATA&gt; tag, along with ad links, name sequences (e.g.,</cell></row><row><cell></cell><cell>authors, countries, cities) plus various menu or site map</cell></row><row><cell></cell><cell>items. Finally there is some factual information, such</cell></row><row><cell></cell><cell>some of the locations where various different opinions</cell></row><row><cell></cell><cell>can be found.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,52.38,108.51,490.55,622.96"><head>Figure 3. Example of LexisNexis blog page</head><label></label><figDesc>Topics #851 to #900) they express user information needs extracted from a commercial search engine blog log, such as the examples shown in Figure5.</figDesc><table coords="3,52.38,150.43,485.65,536.88"><row><cell></cell><cell>&lt;ID&gt; 916</cell></row><row><cell></cell><cell>&lt;TITLE&gt; dice.com</cell></row><row><cell></cell><cell>&lt;DESC&gt; Find opinions concerning dice.com,</cell></row><row><cell></cell><cell>an on-line job search site.</cell></row><row><cell></cell><cell>&lt;NARR&gt; Opinions on dice.com's effectiveness</cell></row><row><cell></cell><cell>are relevant. Mention of its problems is</cell></row><row><cell></cell><cell>relevant. Recounting an experience using</cell></row><row><cell></cell><cell>dice.com is relevant. Simply mentioning it</cell></row><row><cell></cell><cell>as a possible tool is not relevant.</cell></row><row><cell></cell><cell>&lt;ID&gt; 928</cell></row><row><cell></cell><cell>&lt;TITLE&gt; "big love"</cell></row><row><cell></cell><cell>&lt;DESC&gt; Find opinions regarding the HBO</cell></row><row><cell></cell><cell>television show "Big Love".</cell></row><row><cell>&lt;DOC&gt;</cell><cell></cell></row><row><cell cols="2">&lt;DOCNO&gt; BLOG06-20060212-023-0012022784</cell></row><row><cell cols="2">&lt;DATE_XML&gt; 2006-02-10T19:08:00+0000</cell></row><row><cell cols="2">&lt;FEEDNO&gt; BLOG06-feed-055676</cell></row><row><cell>&lt;FEEDURL&gt; http://</cell><cell></cell></row><row><cell cols="2">lawprofessors.typepad.com/law_librarian_blog/ind</cell></row><row><cell>ex.rdf#</cell><cell></cell></row><row><cell>&lt;PERMALINK&gt;</cell><cell></cell></row><row><cell cols="2">http://lawprofessors.typepad.com/law_librarian_b</cell></row><row><cell cols="2">log/2006/02/free_district_c.html#</cell></row><row><cell>&lt;DOCHDR&gt; …</cell><cell></cell></row><row><cell>Connection: close</cell><cell></cell></row><row><cell cols="2">Date: Wed, 08 Mar 2006 14:33:59 GMT …</cell></row><row><cell>&lt;DATA&gt;</cell><cell></cell></row><row><cell>Law Librarian Blog</cell><cell></cell></row><row><cell>Blog Editor</cell><cell></cell></row><row><cell>Joe Hodnicki</cell><cell></cell></row><row><cell cols="2">Associate Director for Library Operations</cell></row><row><cell cols="2">Univ. of Cincinnati Law Library</cell></row><row><cell>…</cell><cell></cell></row><row><cell>News from PACER</cell><cell>:</cell></row><row><cell cols="2">&amp;amp;quot;In the spirit of the E-Government Act</cell></row><row><cell cols="2">of 2002, modifications have been made to the</cell></row><row><cell cols="2">District Court CM/ECF system to provide PACER</cell></row><row><cell cols="2">customers with access to written opinions free</cell></row><row><cell>of charge</cell><cell></cell></row><row><cell cols="2">The modifications also allow PACER customers to</cell></row><row><cell cols="2">search for written opinions using a new report</cell></row><row><cell cols="2">that is free of charge. Written opinions have</cell></row><row><cell cols="2">been defined by the Judicial Conference as</cell></row><row><cell cols="2">&amp;amp;quot;any document issued by a judge or</cell></row><row><cell cols="2">judges of the court sitting in that capacity,</cell></row><row><cell cols="2">that sets forth a reasoned explanation for a</cell></row><row><cell cols="2">court's decision.&amp;amp;quot; …</cell></row></table><note coords="3,89.64,692.22,153.27,8.77;3,52.38,711.57,227.80,8.50;3,52.38,722.97,227.79,8.50;3,315.18,108.51,48.36,8.50;3,315.18,279.07,217.57,6.88;3,315.18,288.37,225.78,6.88;3,315.18,297.73,215.28,6.88;3,315.18,307.09,225.78,6.88;3,315.18,316.39,99.74,6.88;3,315.18,334.03,41.97,6.88;3,315.18,343.54,84.27,6.10;3,315.18,352.15,213.49,6.88;3,315.18,361.51,99.74,6.88;3,315.18,370.81,191.95,6.88;3,315.18,380.17,199.51,6.88;3,315.18,389.53,210.00,6.88;3,315.18,398.83,215.28,6.88;3,315.18,408.19,131.23,6.88"><p><p><p><p>Figure 4. Example of blog document</p>During this evaluation campaign a set of 50 topics (Topics #901 to #950) was created from this corpus. Like last year (&lt;NARR&gt; All statements of opinion regarding the HBO production "Big Love" are relevant. Statements of opinion about HBO or actors in the show are relevant provided that "Big Love" is mentioned.</p>&lt;ID&gt; 937 &lt;TITLE&gt; LexisNexis</p>&lt;DESC&gt; Find opinions about the information service LexisNexis. &lt;NARR&gt; Relevant documents will provide opinions about the information service LexisNexis. Documents that are obviously sponsored by LexisNexis are considered to be spam and not relevant.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,315.00,160.66,229.64,410.00"><head>Table 1 . Description of official runs (Genomics track)</head><label>1</label><figDesc></figDesc><table coords="6,315.00,160.66,229.64,410.00"><row><cell>name</cell><cell cols="2">IR model</cell><cell cols="3">Passage defined by</cell></row><row><cell>UniNE1</cell><cell cols="3">I(n)B2 + WordNet Exp.</cell><cell cols="2">&lt;P &lt;/P</cell></row><row><cell></cell><cell cols="2">Okapi + WordNet</cell><cell></cell><cell></cell></row><row><cell>UniNE2</cell><cell cols="2">Okapi + reranking</cell><cell cols="3">sentence</cell></row><row><cell></cell><cell cols="2">I(n)B2 + WordNet</cell><cell></cell><cell></cell></row><row><cell cols="4">I(n)B2 + WordNet + Spell.</cell><cell></cell></row><row><cell>UniNE3</cell><cell cols="2">Okapi + WordNet</cell><cell></cell><cell cols="2">&lt;P &lt;/P</cell></row><row><cell></cell><cell cols="2">I(n)B2 + WordNet</cell><cell></cell><cell></cell></row><row><cell>Run name</cell><cell>MAP document</cell><cell>MAP passage2</cell><cell>MAP aspect</cell><cell></cell><cell>Passage defined by</cell></row><row><cell>Okapi</cell><cell cols="4">0.1486 0.0190 0.0633</cell><cell>&lt;P &lt;/P</cell></row><row><cell>Okapi</cell><cell cols="5">0.1289 0.0089 0.0740 sentence</cell></row><row><cell>I(n)B2</cell><cell cols="4">0.2533 0.0907 0.2036</cell><cell>&lt;P &lt;/P</cell></row><row><cell>I(n)B2</cell><cell cols="5">0.1508 0.0193 0.0952 sentence</cell></row><row><cell>Okapi+WN</cell><cell cols="4">0.1690 0.0287 0.0388</cell><cell>&lt;P &lt;/P</cell></row><row><cell>Okapi+WN</cell><cell cols="5">0.1566 0.0166 0.0896 sentence</cell></row><row><cell>I(n)B2+WN</cell><cell cols="4">0.2777 0.0998 0.2177</cell><cell>&lt;P &lt;/P</cell></row><row><cell>I(n)B2+WN</cell><cell cols="5">0.1978 0.0347 0.1227 sentence</cell></row><row><cell>Okapi+Spell</cell><cell cols="4">0.1462 0.01883 0.0602</cell><cell>&lt;P &lt;/P</cell></row><row><cell>Okapi+Spell</cell><cell cols="5">0.1219 0.0084 0.0683 sentence</cell></row><row><cell>I(n)B2+Spell</cell><cell cols="4">0.2510 0.0902 0.2019</cell><cell>&lt;P &lt;/P</cell></row><row><cell>I(n)B2+Spell</cell><cell cols="5">0.1538 0.0179 0.0850 sentence</cell></row><row><cell cols="5">Okapi+WN+Sp 0.1671 0.02819 0.0707</cell><cell>&lt;P &lt;/P</cell></row><row><cell cols="6">Okapi+WN+Sp 0.1509 0.0159 0.0875 sentence</cell></row><row><cell>I(n)B2+WN+S p I(n)B2+WN+S p UniNE1</cell><cell cols="5">&lt;P &lt;/P 0.1961 0.0328 0.1188 sentence 0.2765 0.0983 0.2177 0.2777 0.0988 0.2189 &lt;P &lt;/P</cell></row><row><cell>UniNE2</cell><cell cols="5">0.1903 0.0278 0.1102 sentence</cell></row><row><cell>UniNE3</cell><cell cols="4">0.2710 0.0978 0.2043</cell><cell>&lt;P &lt;/P</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,315.18,575.28,227.73,61.98"><head>Table 2 . Official Genomic track results and their componentsTable 2</head><label>22</label><figDesc>lists the evaluation results for our three official runs, together with their various components. Listed first in this table are the single IR models (Okapi &amp; I(n)B2),</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,52.38,109.42,463.15,614.36"><head>Table 3 . Fact and opinion evaluations of the single IR models (Blog, three query formulations)</head><label>3</label><figDesc>This table illustrates how the Okapi or the DFR-PL2 approaches produced the best results, albeit with rather small differences. Through adding the descriptive part in the query formulation we might improve the MAP by 12.5% in mean. Also worth noting is that increasing the query from TD to TDN does not necessarily improve the MAP values (mean decrease of -2.2%). Table4lists our six official runs for the Blog track Table 5 lists our official results.</figDesc><table coords="7,52.38,413.80,227.79,309.98"><row><cell>Model</cell><cell>T</cell><cell>TD</cell><cell>TDN</cell></row><row><cell>Okapi</cell><cell>0.3585</cell><cell>0.4003</cell><cell>0.3965</cell></row><row><cell>DFR-PL2</cell><cell>0.3568</cell><cell>0.4033</cell><cell>0.3942</cell></row><row><cell>DFR-IneC2</cell><cell>0.3398</cell><cell>0.3849</cell><cell>0.3771</cell></row><row><cell>DFR-I(n)B2</cell><cell>0.3397</cell><cell>0.3770</cell><cell>0.3606</cell></row><row><cell>DFR-PB2</cell><cell>0.3365</cell><cell>0.3767</cell><cell>0.3617</cell></row><row><cell>LM</cell><cell>0.3331</cell><cell>0.3808</cell><cell>0.3812</cell></row><row><cell cols="4">Our official results for the Blog track tend to indicate that</cell></row><row><cell cols="4">simple IR models perform better than more complex</cell></row><row><cell cols="4">search strategies. With the TD query formulation for</cell></row><row><cell cols="4">example, combining two IR models for the UniNEblog3</cell></row><row><cell cols="4">run produced an MAP of 0.4034, while under the same</cell></row><row><cell cols="4">conditions the DFR-PB2 by itself model achieved an</cell></row><row><cell cols="2">MAP of 0.4033 (see Table 3).</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,326.94,247.20,204.20,115.74"><head>Table 4 . Description of official Blog track results</head><label>4</label><figDesc></figDesc><table coords="7,327.30,271.36,203.53,91.58"><row><cell>Run name</cell><cell cols="3">QUERY RELEVANT POLARITY</cell></row><row><cell>UniNEblog1</cell><cell>T</cell><cell>0.3585</cell><cell>0.2770</cell></row><row><cell>UniNEblog2</cell><cell>TDN</cell><cell>0.3942</cell><cell>0.2898</cell></row><row><cell>UniNEblog3</cell><cell>TD</cell><cell>0.4034</cell><cell>0.3049</cell></row><row><cell>UniNEblog4</cell><cell>T</cell><cell>0.3467</cell><cell>0.2659</cell></row><row><cell>UniNEblog5</cell><cell>TD</cell><cell>0.3892</cell><cell>0.2972</cell></row><row><cell>UniNEblog6</cell><cell>TD</cell><cell>0.3808</cell><cell>0.3016</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,328.08,367.56,201.93,8.77"><head>Table 5 . Official results of the Blog track results</head><label>5</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="7,315.18,406.36,227.74,131.96"><head>Table 6</head><label>6</label><figDesc>lists the top five most difficult topics of our best performing runs and also provides a better picture of the problems encountered when our systems searched the Blog track (UniNEblog3).</figDesc><table coords="7,323.70,460.60,193.00,77.72"><row><cell>Topic ID</cell><cell>AP</cell><cell>Main explanation</cell></row><row><cell>#916</cell><cell>0.0005</cell><cell>Too many spam</cell></row><row><cell>#937</cell><cell>0.0049</cell><cell>Discrimination fails</cell></row><row><cell>#928</cell><cell>0.0177</cell><cell>Stopword list too large</cell></row><row><cell>#921</cell><cell>0.0373</cell><cell>Discrimination fails</cell></row><row><cell>#929</cell><cell>0.0571</cell><cell>Discrimination fails</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="7,325.20,542.94,207.80,20.11"><head>Table 6 . The most difficult topics in our best runs (UniNEblog3)</head><label>6</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,320.28,728.06,179.06,7.63"><p>http://wiki.apache.org/jakarta-lucene/SpellChecker</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by the <rs type="funder">Swiss NSF</rs> under Grant #<rs type="grantNumber">200021-113273</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8kvfkTj">
					<idno type="grant-number">200021-113273</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,319.55,274.33,89.62,10.50" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,291.46,210.27,8.48;8,332.64,302.86,210.25,8.48;8,332.64,314.00,210.25,8.75;8,332.64,325.34,127.07,8.75" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,491.47,302.86,51.43,8.48;8,332.64,314.26,98.97,8.48">TREC 2005 genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">T</forename><surname>Bhuptiraju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.74,314.00,91.15,8.75;8,332.64,325.34,17.64,8.75">Proceedings of TREC-2005</title>
		<meeting>TREC-2005<address><addrLine>Gaithersburg (MA)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,340.90,210.23,8.48;8,332.64,352.30,210.28,8.48;8,332.64,363.38,210.19,8.75;8,332.64,375.04,135.53,8.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,364.04,352.30,160.24,8.48">TREC 2006 genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">K</forename><surname>Rekapalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,332.64,363.38,115.19,8.75">Proceedings of TREC-2006</title>
		<meeting>TREC-2006<address><addrLine>Gaithersburg (MA), NIST</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Publication #500-272</note>
</biblStruct>

<biblStruct coords="8,332.64,390.28,210.37,8.48;8,332.64,401.62,210.29,8.48;8,332.64,412.70,210.18,8.75;8,332.64,424.36,162.65,8.48" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,408.57,401.62,134.35,8.48;8,332.64,412.96,18.31,8.48">Overview of the TREC-2006 blog track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gilad Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<idno>NIST Publication #500-272</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,374.64,412.70,108.41,8.75">Proceedings of TREC-2006</title>
		<meeting>TREC-2006<address><addrLine>Gaithersburg (MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,439.66,210.26,8.48;8,332.64,450.74,210.25,8.75;8,332.64,462.14,210.19,8.75;8,332.64,473.80,59.60,8.48" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,450.50,439.66,92.40,8.48;8,332.64,451.00,70.13,8.48">Effective ranking with arbitrary passages</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kaszkiel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,410.82,450.74,132.07,8.75;8,332.64,462.14,175.00,8.75">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="344" to="364" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,488.78,210.24,8.75;8,332.64,500.18,210.19,8.75;8,332.64,511.84,44.87,8.48" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,387.00,489.04,106.31,8.48">How effective is suffixing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,501.18,488.78,41.70,8.75;8,332.64,500.18,179.43,8.75">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,527.08,210.25,8.48;8,332.64,538.48,210.25,8.48;8,332.64,549.62,210.25,8.75;8,332.64,560.96,191.76,8.75" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,487.37,527.08,55.53,8.48;8,332.64,538.48,210.25,8.48;8,332.64,549.88,134.99,8.48">Evaluation of stemming, query expansion and manual indexing approaches for the genomic task</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,494.10,549.62,48.79,8.75;8,332.64,560.96,44.20,8.75">Proceedings TREC-2005</title>
		<meeting>TREC-2005<address><addrLine>Gaithersburg (MA)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="863" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,576.52,210.20,8.48;8,332.64,587.66,210.21,8.75;8,332.64,599.26,210.19,8.48;8,332.64,610.66,22.03,8.48" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,436.06,576.52,106.77,8.48;8,332.64,587.92,83.43,8.48">Report on the TREC 2006 genomics experiment</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,440.88,587.66,97.06,8.75;8,422.58,599.26,115.81,8.48">NIST Publication #500-272</title>
		<meeting><address><addrLine>Gaithersburg (MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Proceedings TREC-2006</note>
</biblStruct>

<biblStruct coords="8,332.64,625.96,210.27,8.48;8,332.64,637.30,210.22,8.48;8,332.64,648.44,153.95,8.75" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,447.80,625.96,95.11,8.48;8,332.64,637.30,206.80,8.48">Extracting synonymous gene and protein terms from biological literature</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,332.64,648.44,56.36,8.75">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="340" to="349" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,664.00,210.24,8.48;8,332.64,675.14,210.24,8.75;8,332.64,686.48,156.66,8.75" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,491.37,664.00,51.51,8.48;8,332.64,675.40,123.45,8.48">University at TREC 2005: Genomics track</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>York</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,480.36,675.14,62.52,8.75;8,332.64,686.48,44.20,8.75">Proceedings of TREC-2005</title>
		<meeting>TREC-2005<address><addrLine>Gaithersburg (MA)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,332.64,702.04,210.25,8.48;8,332.64,713.44,210.29,8.48;9,69.90,108.26,210.20,8.75;9,69.90,119.86,49.79,8.48" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,401.16,702.04,141.73,8.48;8,332.64,713.44,210.29,8.48;9,69.90,108.52,44.22,8.48">Unsupervised gene/protein named entity normalization using automatically extracted dictionaries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,133.32,108.26,88.19,8.75">Proceeding ACL-ISMB</title>
		<meeting>eeding ACL-ISMB<address><addrLine>Detroit (MI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.90,134.90,210.21,8.75;9,69.90,146.56,110.35,8.48" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Gospodnetic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hatcher</surname></persName>
		</author>
		<title level="m" coord="9,208.20,134.90,67.93,8.75">Lucene in Action</title>
		<imprint>
			<publisher>Manning Publications</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.90,161.86,210.31,8.48;9,69.90,173.20,210.21,8.48;9,69.90,184.34,210.19,8.75;9,69.90,195.94,30.18,8.48" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,69.90,173.20,204.75,8.48">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,69.90,184.34,154.11,8.75">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.90,211.24,210.26,8.48;9,69.90,222.64,210.21,8.48;9,69.90,233.78,210.24,8.75;9,69.90,245.12,182.88,8.75" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,230.92,211.24,49.24,8.48;9,69.90,222.64,210.21,8.48;9,69.90,234.04,125.87,8.48">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,205.32,233.78,74.82,8.75;9,69.90,245.12,90.55,8.75">ACM-Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,332.64,108.52,210.21,8.48;9,332.64,119.86,141.07,8.48" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="9,388.11,108.52,154.75,8.48;9,332.64,119.86,31.51,8.48">Using language models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">CTIT Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="9,332.64,135.16,210.26,8.48;9,332.64,146.56,210.23,8.48;9,332.64,157.64,189.18,8.75" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,402.15,135.16,140.75,8.48;9,332.64,146.56,206.75,8.48">Term-specific smoothing for the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,343.26,157.64,121.27,8.75">Proceedings of the ACM-SIGIR</title>
		<meeting>the ACM-SIGIR</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,332.64,173.20,210.26,8.48;9,332.64,184.34,210.23,8.75;9,332.64,195.94,17.11,8.48" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,463.23,173.20,79.68,8.48;9,332.64,184.60,86.29,8.48">Fusion via a linear combination of scores</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,429.18,184.34,41.16,8.75">IR Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="173" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,332.64,211.24,210.24,8.48;9,332.64,222.38,210.18,8.75;9,332.64,234.04,200.19,8.48" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,442.62,211.24,100.26,8.48;9,332.64,222.64,31.58,8.48">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,395.76,222.38,84.70,8.75;9,359.77,234.04,106.53,8.48">NIST Publication #500-215</title>
		<meeting><address><addrLine>Gaithersburg (MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="243" to="249" />
		</imprint>
	</monogr>
	<note>Proceedings TREC-2</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
