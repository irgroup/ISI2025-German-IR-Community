<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,133.80,114.65,343.93,12.36;1,219.24,136.50,172.80,12.36">Information Retrieval and Information Extraction in TREC Genomics 2007</title>
				<funder ref="#_ADZteAx">
					<orgName type="full">Network of Excellence</orgName>
				</funder>
				<funder ref="#_3JxKDNe #_qnZSHba">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,206.88,168.96,81.35,10.99"><forename type="first">Antonio</forename><surname>Jimeno</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">European Bioinformatics Institute</orgName>
								<orgName type="institution">Wellcome Trust Genome Campus</orgName>
								<address>
									<postCode>CB10 1SD</postCode>
									<settlement>Hinxton, Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,335.40,168.96,57.30,10.99"><forename type="first">Piotr</forename><surname>Pezik</surname></persName>
							<email>pezik@ebi.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">European Bioinformatics Institute</orgName>
								<orgName type="institution">Wellcome Trust Genome Campus</orgName>
								<address>
									<postCode>CB10 1SD</postCode>
									<settlement>Hinxton, Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,133.80,114.65,343.93,12.36;1,219.24,136.50,172.80,12.36">Information Retrieval and Information Extraction in TREC Genomics 2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A5ADE35917D6CE22BE8C1CFA56FE2DD3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC Genomics a question/answering task has been proposed. A set of questions with a specific entity of interest is proposed and a set of passages from a collection of full text documents has to be selected from the document collection provided. We have used a two step approach: the first one is recall-oriented retrieval, and the second is an information extraction system that is intended to provide higher precision. We rely on well known techniques like query expansion and resources like MeSH and UMLS. The information extraction techniques are part of the infrastructure of the Text Mining Group at European Bioinformatics Institute.</p><p>Using standard information retrieval techniques has been found more beneficial than using more complex processing. Having analyzed the results we find that the performance of query expansion varies for different topics. There are several reasons. Terminological resources may contain ambiguous synonyms or synonyms whose textual usage patterns differ from the usage of the original query terms. On the whole our performance was similar to the mean results from the three performance measures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In TREC Genomics a question/answering task has been proposed. A set of questions with a specific entity of interest is proposed and a set of passages from a collection of full text documents has to be selected from the document collection provided. Query/answering systems have been evaluated using different strategies. In TREC Genomics the strategy is closer to a retrieval system since we have been asked to retrieve specific passages from the document collection. The specific answer to the question is not required to be extracted from the spans. We used a two step approach: the first step is a recall oriented retrieval and the second is an information extraction approach that is intended to increase the precision of the retrieved set. In the following section we introduce the different techniques used, then we present the results and an analysis of the different factors in our system and finally we draw some conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The documents are provided by Highwire Press<ref type="foot" coords="2,351.48,199.56,3.97,4.84" target="#foot_0">1</ref> and are in HTML format. The documents have been divided into spans of text. These spans are identified by the p tag. Since there are several sections in the documents that are not interesting (e.g. references or authors list) or passages that are too short to contain any interesting information; we have filtered spans based on regular expressions and spans under 300 characters. The remaining spans are indexed.</p><p>Our index is based on Lucene<ref type="foot" coords="2,281.76,271.20,3.97,4.84" target="#foot_1">2</ref> . We have proposed an improvement on the scoring function of Lucene<ref type="foot" coords="2,251.40,283.20,3.97,4.84" target="#foot_2">3</ref> based on Singhal et al. <ref type="bibr" coords="2,357.81,284.03,10.51,9.96" target="#b6">[4]</ref> because we realized that Lucene gives more relevance to very frequent terms in the documents. This lead to the undesired effect that some spans where ranked higher because they contained frequently the occurrence of one specific term from the topic; as in the case of cancer. We introduced modifications to the tf (term frequency) function and the lengthNorm function in the DefaultSimilarity class of Lucene. The slope and pivot are 0.2 and 300 repectively. The other variables like f req and numT erms are provided by Lucene.</p><formula xml:id="formula_0" coords="2,261.24,391.67,216.28,9.96">tf = 1.0 + log(f req)<label>(1)</label></formula><formula xml:id="formula_1" coords="2,179.52,416.99,298.00,23.52">lengthN orm = 1 (1.0 -slope) * pivot + slope * numT erms<label>(2)</label></formula><p>Even though the integration of Lucene into an IT solution is easy, the possible improvements to the score function are limited by the information made available to the functions in the Similarity abstract class. For instance, if we implement or override the tf function the only information is the term frequency. It is not possible to know any other information from the document or any other statistic from the Lucene index. An assessment of the default similarity function provided by Lucene and the modified scoring function can be found in the Results section. The spans have been split into word tokens and these tokens are converted into their singular form and filtered using standard stop word list. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval</head><p>In our approach we combine information retrieval and information extraction.</p><p>In the retrieval part we used an entity recognizer to link the topic with the query expansion procedure. The recognized entity is identified in a datasource and is used to expand the topic with the synonyms. The retrieved spans are postprocessed with an entity recognizer to identify the entities. These entities are matched with the entities in the topic and a boosting factor depending on the matching with the topic is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Entity Recognizer</head><p>The entity recognizer allowed us to identity specific entities occurring in text from a diverse set of entity types. The output of the recognizer is used by the query expansion mechanism and by the boosting of the documents. Table <ref type="table" coords="3,472.44,463.19,4.98,9.96" target="#tab_0">1</ref> shows that although we considered several terminological resources we have not been able to cover the full range of entity types due to time constraints. The set of terms provided by the different sources has been processed to avoid different types of ambiguities. We have removed terms from a stop word list, terms with less than two characters or only numbers and very common English terms identified from the Brown Corpus. This processing does not require domain knowledge and removes very ambiguous cases.</p><p>We have built the named entity recognizers based on a dictionary look-up approach<ref type="foot" coords="3,173.64,569.88,3.97,4.84" target="#foot_3">4</ref> that offers quite flexibility since we only require the terminology for each semantic type. Ambiguity between the entity types is solved based by prioritizing terms <ref type="bibr" coords="3,206.24,594.71,12.56,9.96" target="#b3">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Query Expansion</head><p>In order to increase the recall of the set of retrieved passages, we have experimented with three different query expansion techniques. The lexical resource used for this purpose was a term repository developed as part of the Bootstrep project. It currently contains terms denoting genes, protein, chemicals, species as well as other semantic types imported from several bio-ontologies. Some initial filtering and normalisation of terms was applied on the repository 56 . We compare the results obtained with the different query expansion techniques and their combinations in the Results section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Staightforward Expansion</head><p>The first technique is based on simply fetching synonymous terms from the term repository and translating them into sets of variants joined with the boolean operator OR. The synonymy relationship between the query terms and variants found in the repository is taken at face value. In other words, if a variant is recognized as a synonym of a query term in the repository, it is appended to the query term with an OR operator.</p><p>Filters In the second technique, we apply some restrictions on certain types of terms that can be used to expand queries. In particular we filter out some gene and protein names, largely due to the fact that these terms tend to be polysemous. The following restrictions were applied:</p><p>1. Very short and potentially polysemous or irrelevant gene/protein names matching patterns such as "[a-zA-Z0-9]{1,2}-[0-9]{1,2}" were discarded altogether.</p><p>2. Only synonyms which were likely to be expanded or abbreviated forms of original query terms were selected. This was decided on the basis of string similarity based on <ref type="bibr" coords="4,246.01,416.51,10.00,9.96" target="#b5">[3]</ref>. Thus, arbitrary synonyms which are more likely to coincide with terms with other meanings were not included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Boosting</head><p>The third technique is meant to depress the significance of big synsets based on the intuition that a large set of synonyms for one of the query terms might bias the whole query towards that term. Thus, we have attached a boosting factor to each term which we obtained with the following formula:</p><formula xml:id="formula_2" coords="4,262.80,521.63,210.46,23.52">1 (log(n) * alpha) + 1 (<label>3</label></formula><formula xml:id="formula_3" coords="4,473.26,528.35,4.25,9.96">)</formula><p>where n is the number of synonyms obtained for a given topic term and alpha = 0.5. Thus, if a protein name such as 'PSD-95' gets expanded into the following set of potentially synonymous sets: (Dlg4 OR "Discs large homolog 4" OR Sap90 OR Psd95 OR PSD95 OR "Synapse-associated protein 90" OR DLG4 OR "Postsynaptic density protein 95" OR "SYNAPSE-ASSOCIATED PROTEIN 90" OR dlg4 OR "postsynaptic density protein 95" OR "discs large homolog 4" OR PSD-95 OR SAP90 OR Dlgh4)0.42</p><p>The set of expanded synonyms gets a relatively low boosting factor of 0.42, as it might contain polysemous terms which could affect the precision of the results retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Document Boosting</head><p>The document retrieval is expected to provide a ranked list of documents with high recall. Due to the term ambiguity some documents are ranked higher even if the words are not relevant to the topic. This has been covered partially in the query expansion, where some abbreviations for proteins have been correctly identified and expanded to the long form.</p><p>We propose to analyze the documents and boost the passages that make an explicit reference to the entities identified in the topic. The first 3000 documents are retrieved and annotated. Then the matching entities in the topic and the document are counted and this count (boosting f actor) is combined with the score provided by the retrieval system using a linear combination.</p><formula xml:id="formula_4" coords="5,191.16,336.83,286.36,9.96">span score = α * lucene score + β * boosting f actor<label>(4)</label></formula><p>The factors α = 1.0 and β = 0.2 have been tuned using 2006 TREC Genomics Gold Standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Minimum Span locator</head><p>The spans retrieved may contain information irrelevant to topic. To identify the interesting pieces of text in a given span we propose to look for the sentences that are more similar to the topic and keep them. We use a bag-of-words representation of the topic and the span sentences. Then the first sentence for which the similarity was higher from a given threshold is collected. The same technique is used to identify the last sentence that may contain interesting results. The approach is quite conservative since we want to avoid removing interesting parts of the text. The similarity is based on the cosine similarity. The values of the vectors for the sentences and the topic are based on the term frequency and the inverted document frequency obtained from the index built for the spans. The threshold is estimated based on the 2006 TREC Genomics Gold Standard. </p><formula xml:id="formula_5" coords="5,254.52,561.71,223.00,23.52">cos(v 1 , v 2 ) = v 1 • v 2 |v 1 | × |v 2 |<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We submitted three runs. EBI1Lucene used the modified Lucene index and the minimum span locator (no query expansion or boosting has been applied). EBI3Boosting used the modified Lucene index with query expansion, boosting and the minimum span locator. EBI2Fusion combines EBI1Lucene and EBI3Boosting by doing the sum of the scores for each span, reranking with the new score and taking the first 1000 spans. In table 2 we see the performance of each of our three runs and the maximum, mean and median of the automatic runs in the TREC Genomics. EBI1Lucene provided the best performance for the three runs that we have submitted. Our runs have a performance comparable with the average of the other participants in TREC. In table <ref type="table" coords="6,295.23,371.63,4.98,9.96">3</ref> we can compare the different approaches with the maximum and median for each one of the individual topics from the automatic runs. As we can see for some topics EBI3Boosting outperformed EBI1Lucene but globally the performance is either the same or worst. In the following sections we will identify the issues for which query expansion and boosting did not have the expected performance.</p><p>We have proposed some improvements on Lucene's Similarity class (ref.</p><p>Indexing section). On table <ref type="table" coords="6,246.38,455.39,4.98,9.96" target="#tab_1">2</ref> we can find the performance of the standard Lucene and our modified version (EBI1Lucene). The modified version outperforms the standard Lucene in almost all the topics.</p><p>We have evaluated the minimum span Locator with the PASSAGE2 measure and EBI11Lucene run with and without the minimum span locator. We found and increase of 7.23% in the PASSAGE2 measure. In most of the cases our approach improved the performance based on just delivering the span without any further processing. On the other hand the PASSAGE2 measure is dependent on the span ranking. This means that PASSAGE2 has a dependency on the DOCUMENT measure and it is difficult to compare the behaviour of the different algorithms provided by the participants.  <ref type="figure" coords="8,150.96,217.55,4.98,9.96">1</ref> shows the biggest increments and decrements in the document per query score after applying query expansion. The biggest depression of performance was noted for topic 201. This could be due to the fact that one of the query terms cancer was expanded into several apparent synonyms such as tumor or neoplasm. Although their denotative meaning is similar from the point of view of an abstracted lexical resource (MESH in this case), in real textual usage cancer, tumor and neoplasm may have a complementary distribution. As an example, the term tumor could denote any increase of the size of a tissue or an organ, such as the enlargement of a gland. Neoplasm typically refers to the generation of new tissue, whereas cancer has the additional characteristics of invading surrounding tissues, dislocating and forming neoplasms elsewhere (metastasis). Because all these different senses are bundled together under one MESH entry and thus the expansion of the term cancer leads to a very dispersed query. Topic 200 is an example of a successful expansion. The term lupus was expanded with its rarer full form lupus vulgaris, whose exact occurrences in some of the passages produced a better idf score than could have been obtained if only the occurrences of the more frequent short form lupus were considered.</p><p>We have applied boosting in EBI3Boosting after query expansion. As we can see in figure <ref type="figure" coords="8,188.40,432.71,4.98,9.96">1</ref> boosting increased slightly the DOCUMENT measure for a large number of topics but decreased the performance from some of the topics like 204. In this topic, the term neurosteroids has not been recognized so documents that were more specific to nervous system and brain have been given more relevance. The effectiveness of the method requires high precision and recall information extraction and a high coverage of the biomedical terminology. The variety of topics does not allow further tuning as proposed in <ref type="bibr" coords="8,381.89,504.47,10.57,9.96" target="#b4">[2]</ref> where a templatedependent selection of entities provided higher effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Modification of Lucene has provided our best run, although the Lucene scoring function can be further improved. These improvements are limited by the way the Lucene package is designed. We expected this run to be the baseline for our other two runs. We have found that query expansion and boosting had Figure <ref type="figure" coords="9,165.37,250.31,3.90,9.96">1</ref>: Increment of DOCUMENT per query using the query expansion applying filtering and no term boosting and document boosting versus the modified Lucene Figure <ref type="figure" coords="9,164.53,488.27,3.90,9.96">2</ref>: Increment of DOCUMENT per query using document boosting versus the query expansion applying filtering and no term boosting very different behaviour for the different topics and this may indicate that it is difficult to use a unified technique for different topics <ref type="bibr" coords="9,387.63,543.95,10.00,9.96" target="#b7">[5]</ref>. In addition, expanded terms can have a different distribution of usage as in the case of MeSH synonyms for cancer. The document boosting suffered from the coverage of the entity recognizer since in some cases a relevant entity was not detected and the spans containing the other recognized entities were prefered. The fusion run (EBI2Fusion) did not provide the desired effect and this may be due to the fact that the two runs used for the fusion were based on the same retrieval engine and the variations like query expansion and boosting applied in one of the runs did not provide a positive effect thus decreasing the performance of the combined run.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,191.28,76.19,228.74,206.76"><head>Table 1 :</head><label>1</label><figDesc>Entity types and knowledge source selected</figDesc><table coords="3,199.92,76.19,211.59,184.92"><row><cell>Entity Type</cell><cell>Source</cell></row><row><cell>ANTIBODIES</cell><cell>MeSH</cell></row><row><cell cols="2">BIOLOGICAL SUBSTANCES Not considered</cell></row><row><cell>CELL OR TISSUE TYPES</cell><cell>MeSH</cell></row><row><cell>DISEASES</cell><cell>MeSH</cell></row><row><cell>DRUGS</cell><cell>DrugBank</cell></row><row><cell>GENES</cell><cell>SwissProt</cell></row><row><cell>MOLECULAR FUNCTIONS</cell><cell>GO</cell></row><row><cell>MUTATIONS</cell><cell>MeSH</cell></row><row><cell>PATHWAYS</cell><cell>Not considered</cell></row><row><cell>PROTEINS</cell><cell>SwissProt</cell></row><row><cell>STRAINS</cell><cell>Not considered</cell></row><row><cell>SIGNS OR SYMPTOMS</cell><cell>MeSH</cell></row><row><cell>TOXICITIES</cell><cell>UMLS</cell></row><row><cell>TUMOR TYPES</cell><cell>MeSH</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,133.80,76.19,343.69,132.24"><head>Table 2 :</head><label>2</label><figDesc>Average DOCUMENT, ASPECT and PASSAGE2 for the Maximum, Median, Mean and our official runs</figDesc><table coords="6,180.84,76.19,249.68,98.40"><row><cell>RUN</cell><cell cols="3">DOCUMENT ASPECT PASSAGE2</cell></row><row><cell>Maximum</cell><cell>.3286</cell><cell>.2631</cell><cell>.1148</cell></row><row><cell>Median</cell><cell>.1897</cell><cell>.1311</cell><cell>.0377</cell></row><row><cell>Mean</cell><cell>.1862</cell><cell>.1326</cell><cell>.0398</cell></row><row><cell>EBI1Lucene</cell><cell>.1799</cell><cell>.1513</cell><cell>.0404</cell></row><row><cell>EBI2Fusion</cell><cell>.1768</cell><cell>.1470</cell><cell>.0401</cell></row><row><cell>EBI3Boosting</cell><cell>.1522</cell><cell>.1247</cell><cell>.0339</cell></row><row><cell>Lucene</cell><cell>.1634</cell><cell>.1340</cell><cell>.0386</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,133.80,586.91,343.83,33.84"><head>Table 4</head><label>4</label><figDesc>summarizes the results obtained for the abovementioned query expansion techniques and their combinations. Filtering out potentially polysemous gene and protein names without term boosting gave the best results, although</figDesc><table coords="8,146.04,76.19,319.41,73.68"><row><cell>Expansion</cell><cell cols="3">DOCUMENT ASPECT PASSAGE2</cell></row><row><cell>EBI1Lucene (no expansion)</cell><cell>.1799</cell><cell>.1513</cell><cell>.0404</cell></row><row><cell>No filtering, no term boosting</cell><cell>.1455</cell><cell>.1162</cell><cell>.0293</cell></row><row><cell>Filtering, no term boosting</cell><cell>.1511</cell><cell>.1242</cell><cell>.0337</cell></row><row><cell>No filtering, term boosting</cell><cell>.1352</cell><cell>.1130</cell><cell>.0290</cell></row><row><cell>Filtering, term boosting</cell><cell>.1453</cell><cell>.1200</cell><cell>.0317</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,133.80,161.87,343.78,65.64"><head>Table 4 :</head><label>4</label><figDesc>Average DOCUMENT, ASPECT and PASSAGE2 for the EBI1Lucene and the different query expansions on average they were still worse than the baseline modified Lucene score. Figure</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,149.04,571.72,92.63,7.97"><p>http://www.highwire.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,149.04,581.20,90.83,7.97"><p>http://lucene.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,149.04,590.68,307.31,7.97"><p>http://lucene.apache.org/java/2 2 0/api/org/apache/lucene/search/Similarity.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,149.04,614.32,93.85,7.97"><p>http://monqjfa.berlios.de</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,149.04,594.52,96.47,7.97"><p>http://www.bootstrep.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,149.04,604.00,300.23,7.97"><p>ftp://ftp.ebi.ac.uk/pub/software/textmining/bootstrep/termrepository/20092007</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgements</head><p>This work was funded by the <rs type="funder">Network of Excellence</rs> "<rs type="projectName">Semantic Interoperability and Data Mining in Biomedicine" (NoE 507505</rs>) and by the <rs type="projectName">EC</rs> project <rs type="projectName">BOOTStrep</rs> <rs type="grantNumber">FP6-028099</rs> (www.bootstrep.org).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ADZteAx">
					<orgName type="project" subtype="full">Semantic Interoperability and Data Mining in Biomedicine&quot; (NoE 507505</orgName>
				</org>
				<org type="funded-project" xml:id="_3JxKDNe">
					<orgName type="project" subtype="full">EC</orgName>
				</org>
				<org type="funded-project" xml:id="_qnZSHba">
					<idno type="grant-number">FP6-028099</idno>
					<orgName type="project" subtype="full">BOOTStrep</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,139.80,120.50,22.21,8.97;7,194.16,120.50,17.82,8.97;7,258.47,120.50,29.84,8.97;7,326.15,120.50,48.97,8.97;7,411.35,120.50,46.87,8.97;7,490.90,120.50,55.97,8.97;7,144.00,133.82,13.73,8.97;7,174.00,133.82,380.33,8.97" xml:id="b0">
	<monogr>
		<idno>200 .449/.360/.292 .253/.097/.015 .1991/.1332/.0412 .2944/.1788/.0558 .3366/.1873/.0624</idno>
		<title level="m" coord="7,139.80,120.50,22.21,8.97;7,194.16,120.50,17.82,8.97;7,258.47,120.50,29.84,8.97;7,326.15,120.50,48.97,8.97;7,411.35,120.50,46.87,8.97;7,490.90,120.50,55.97,8.97">Topic Max Median EBI1Lucene EBI2Fusion EBI3Boosting</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.65,519.98,218.68,8.97;7,144.00,531.38,13.73,8.97;7,176.28,531.38,378.05,8.97" xml:id="b1">
	<monogr>
		<title/>
		<idno type="DOI">/.0048/.0003.0054/.0048/.0003.0054/.0048/.0003235.442/.364/.34.117/.064/.012.1422/.0764/.0405.0885/.0612/.0310.0063/.0079/.0021</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,133.80,557.27,343.70,9.96;7,133.80,569.15,129.98,9.96;10,133.80,222.30,75.35,12.93" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,133.80,557.27,343.70,9.96;7,133.80,569.15,129.98,9.96;10,133.80,222.30,75.35,12.93">Table 3: DOCUMENT, ASPECT and PASSAGE2 for the Maximum, Median and our official runs per topic References</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.28,246.71,328.30,9.96;10,149.28,258.71,328.19,9.96;10,149.28,270.59,328.27,9.96;10,149.28,282.59,328.29,9.96;10,149.28,294.47,48.61,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,429.26,246.71,48.33,9.96;10,149.28,258.71,328.19,9.96;10,149.28,270.59,328.27,9.96;10,149.28,282.59,251.98,9.96">Annotation and Disambiguation of Semantic Types in Biomedical Text: a Cascaded Approach to Named Entity Recognition. Workshop on Multi-Dimensional Markup in NLP</title>
		<author>
			<persName coords=""><forename type="first">Dietrich</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harald</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sylvain</forename><surname>Gaudan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,411.50,282.59,24.24,9.96">EACL</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Trente, Italy</pubPlace>
		</imprint>
	</monogr>
	<note>Miguel Arregui, and Goran Nenadic</note>
</biblStruct>

<biblStruct coords="10,149.28,314.39,328.24,9.96;10,149.28,326.39,328.33,9.96;10,149.28,338.39,200.41,9.96" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><forename type="middle">Jimeno</forename><surname>Yepes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frederic</forename><surname>Ehrler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Imad</forename><surname>Tbahriti</surname></persName>
		</author>
		<title level="m" coord="10,221.42,326.39,256.19,9.96;10,149.28,338.39,169.41,9.96">Report on the TREC 2006 Experiment: Genomics Track. the Fifteenth Text Retrieval Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.28,358.31,328.30,9.96;10,149.28,370.19,328.09,9.96;10,149.28,382.19,71.65,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,296.19,358.31,181.40,9.96;10,149.28,370.19,158.73,9.96">A simple algorithm for identifying abbreviation definitions in biomedical text</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,316.20,370.19,156.43,9.96">Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.28,402.11,328.22,9.96;10,149.28,414.11,328.11,9.96;10,149.28,425.99,328.17,9.96;10,149.28,437.99,267.26,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,367.86,402.11,109.64,9.96;10,149.28,414.11,58.30,9.96">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,229.92,414.11,247.47,9.96;10,149.28,425.99,328.17,9.96;10,149.28,437.99,26.26,9.96">SIGIR &apos;96: Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.28,457.91,328.22,9.96;10,149.28,469.91,328.16,9.96;10,149.28,481.79,328.30,9.96;10,149.28,493.79,125.66,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,241.81,457.91,214.99,9.96">Query expansion using lexical-semantic relations</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,149.28,469.91,328.16,9.96;10,149.28,481.79,221.30,9.96">Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 17th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>Springer-Verlag New York, Inc</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
