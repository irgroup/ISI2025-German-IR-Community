<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,113.48,163.15,366.36,18.08;1,221.97,185.07,149.37,18.08">York University at TREC 2007: Enterprise Document Search</title>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,310.99,222.65,64.04,9.41"><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
							<email>jhuang@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Inf ormation T echnology</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,113.48,163.15,366.36,18.08;1,221.97,185.07,149.37,18.08">York University at TREC 2007: Enterprise Document Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9E7708F4077C61230DC8B7520C0B6FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>York University evaluated a prepcessing approach for this year's enterprise document search task. With different parsing tools, we create two data sets. Based on each data set, we generate two official runs. Their results demonstrate that the removal of raw data in preprocessing stage has a negative impact on the retrieval performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year we use the Okapi system for our enterprise document search experiments. In contrary to last year's data post-processing approach, our focus in this year's enterprise track was on data preprocessing.</p><p>One of the main challenges in enterprise search is to deal with a large number of data type variation. Considering the enterprise search as a chain of functional components with data flow through, an obvious bottle neck of all-time is preprocessing. One of our major objectives is to develop a methodology to preprocess the data. This year, the enterprise track use a new data collection. The task is to find missing page or a set of pages contains keywords that can help to create an overview page about a given topic.</p><p>We assume that an overview page must be very "human-oriented" in comparison to machine generated pages. "Human-oriented" files intend to be "natural expression of opinons". For example, emails or lecture notes are much more human-oriented than a SQL report page or a database table file or dynamically generated Web forms. This assumption is not extremely logically sound. However, it does give us a start point to implement a preprocessing strategy First, we identify relevent files that are also human-oriented. After examining the data collection, we find that there are many documents with an empty body and a source path that links to an application file such as MS Word file, or a presentation slide, or a pdf file. They were crawled but not included in the data collection before we trace their location and download their contents. This reminds us the challenge of dealing with data type variation and the importance of pre-processing methodology. Also, we find there are a lot of documents that are database tables. Since we focus on finding human-oriented files, these files are in general not of interst to us. Therefore, these database tables can just be placed into our to-be removed list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our System and Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Okapi</head><p>We used Okapi BSS (Basic Search System) as our main search system. The weighting function used is BM25 <ref type="bibr" coords="2,206.41,285.84,9.96,10.46" target="#b1">[2]</ref>. For a given term t, a query q and a document d within a collection of documents, the weight w of d with respect to q and t is calculated by following formula: BM25 weighting scheme is the core of Okapi system. Relevance judgment of terms and documents are made based on calculated weights shown above.</p><formula xml:id="formula_0" coords="2,116.60,325.51,358.91,24.94">w = (k 1 + 1) × tf K + tf × log N -n + 0.5 n + 0.5 × (k 3 + 1) × qtf k 3 + qtf ⊕ k 2 × nq × (advl -dl) (advl + dl)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Preprocesing and Query Expansion</head><p>As discuss above, we examine a fraction of the data, for each identified data type, either re-collect the doc's body or mark the doc as to-be removed. We also investigate the effect of different parsers on the raw data. Finally, we generate two data set. One contains 370,715 documents. The other one contains 360,715 documents. These two data sets are used to create our four official runs.</p><p>Raw data are converted into its original form: one document per file. A well-written parser will generate an 'exch' file by a single run on the raw data. This is not true for the entperise track due to the fact that enterprise data type is never homogeneous. For query expansion, we add a narritive term list to query term list and use the average weight of query terms as a threshold. Query expansion, in gereral, does make a positive contribution to the retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results and Discussions</head><p>We used a java-based parser to process the raw data and create the first dataset. This parser removed all the XML tags and HTML tags. A text-base browser combined with perl script created the second dataset. Database files were removed from the second dataset. Then on each dataset, we generated two runs. One run was generated using query from the topic file. The other run was generated using queries expanded with narritive terms from topic files. We would like to investigate how the data post-processing (such as query expansion) is influenced by the data pre-processing.</p><p>The official runs were generated using Okapi 2.41 and the parameters for BM25 were set to 3, 0, 8 and 0.55 for k1, k2, k3 and b respectively. Table <ref type="table" coords="3,348.55,256.89,4.24,10.46" target="#tab_1">3</ref>.1 shows a comparison of parser during preprocessing. Table <ref type="table" coords="3,224.62,268.85,4.24,10.46" target="#tab_1">3</ref>.2 shows the effect of query expansion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>As the results show, more documents always give better performance although it seems to us that these removed documents have nothing to do with overview papers.</p><p>Also, recovering of those so-called human-oriented files did not give us obvious performance gain. Especially, when the number of recovered documents is not significant comparing to the size of the dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,141.89,367.56,309.53,136.16"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table coords="2,141.89,367.56,309.53,136.16"><row><cell></cell><cell>1 BM25 variables references</cell></row><row><cell>Variable</cell><cell>description</cell></row><row><cell>N</cell><cell>total number of indexed documents in the collection.</cell></row><row><cell>n</cell><cell>number of documents containing the term t. (n ≤ N )</cell></row><row><cell>tf</cell><cell>within document term frequency of t in d.</cell></row><row><cell>qtf</cell><cell>within query term frequency of t in q.</cell></row><row><cell>nq</cell><cell>number of query term (query length).</cell></row><row><cell>dl</cell><cell>length of document d.</cell></row><row><cell>avdl</cell><cell>average length of all indexed documents in the collection.</cell></row><row><cell cols="2">K K1,k2,k3,b constants, used to tune the system. k 1 × (1 -b + b × dl avdl )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,128.78,301.54,335.78,225.03"><head>Table 3 .</head><label>3</label><figDesc>1 Title only query, Port's stemming with gsl.lemurl</figDesc><table coords="3,128.78,321.17,335.78,205.40"><row><cell>Run</cell><cell>MAP</cell><cell>R-prec Description (Table 3.1)</cell></row><row><cell cols="3">york07ed1 0.4405 0.4484 a Java parser,blindly remove tags query only</cell></row><row><cell></cell><cell></cell><cell>370715 docs,keep 10000db files</cell></row><row><cell cols="3">york07ed2 0.4270 0.4480 lynx dumping tool, with perl script remove</cell></row><row><cell></cell><cell></cell><cell>page overhead,query only,360715 docs</cell></row><row><cell cols="3">Table 3.2 Query expanded with narrative, Port's stemming, gsl.lemurl</cell></row><row><cell>Run</cell><cell>MAP</cell><cell>R-prec Description (Table 3.2)</cell></row><row><cell cols="3">york07ed1 0.4405 0.4484 Query only, no expansion. 370,715 docs</cell></row><row><cell cols="3">york07ed4 0.4536 0.4553 Same as york07ed1, with narritive query</cell></row><row><cell></cell><cell></cell><cell>expansion</cell></row><row><cell cols="3">york07ed2 0.4270 0.4480 query only, 360,715 doc with db file re-</cell></row><row><cell></cell><cell></cell><cell>moved,no expansion</cell></row><row><cell cols="3">york07ed3 0.4237 0.4351 Same as york07ed2, with narritive expan-</cell></row><row><cell></cell><cell></cell><cell>sion</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This research is supported in part by the research grant from the <rs type="funder">Natural Sciences and Engineering Research Council (NSERC) of Canada</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,122.81,225.38,348.70,10.46;4,122.81,237.34,348.69,10.46;4,122.81,249.29,39.21,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,300.46,225.38,165.98,10.46">Relevance Weighting of Search Terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">K</forename><surname>Sparck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,122.81,237.34,254.99,10.46">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976-05">1976. May-June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,122.81,261.25,348.70,10.46;4,122.81,273.20,348.68,10.46;4,122.81,285.15,61.98,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,160.17,273.20,76.56,10.46">Okapi at TREC-5</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,249.33,273.20,199.36,10.46">Proceedings of 5th Text REtrieval Conference</title>
		<meeting>5th Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="page" from="143" to="166" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
