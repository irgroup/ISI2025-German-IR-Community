<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information at TREC</orgName>
								<orgName type="institution">University of Texas</orgName>
								<address>
									<addrLine>2007 Miles Efron, Don Turnbull</addrLine>
									<settlement>Carlos Ovalle</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Information</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University Station</orgName>
								<address>
									<postCode>D7000, 78712</postCode>
									<settlement>Austin</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">66DC8BBE5526AC14A65840DD0ABC6E9E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>This was the first year in which the University of Texas' School of Information (UT iSchool) participated in TREC. We limited our attention to a single task (feed distillation) within a single track (Blog). Our goal was to obtain high-precision results within a principled theoretical framework.</p><p>Our system used Apache's Lucene library <ref type="bibr" coords="1,294.76,291.36,14.08,10.63" target="#b0">[1]</ref> for its core indexing and retrieval functions. We also relied on language modeling extensions to Lucene provided by the Informatics Institute at the University of Amsterdam <ref type="bibr" coords="1,345.88,318.96,12.69,10.63" target="#b1">[2]</ref>. However, We altered these libraries to enable our IR approach. In particular, our results rely on a variant of the Kullback-Leibler (KL) divergence model <ref type="bibr" coords="1,291.40,346.56,13.08,10.63" target="#b2">[3,</ref><ref type="bibr" coords="1,307.48,346.56,8.56,10.63" target="#b3">4]</ref>. Given a query q we derive a score for each feed f in the corpus by the negative KL-divergence between the query language model and the language model for f. In the interest of maximizing precision at low numbers of documents retrieved, we limited our analysis to each feed's RSS posts, as opposed to its complete HTML representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sources of Evidence and Preprocessing</head><p>As first-year participants, our chief goal was to establish a baseline for our general IR approach. Within this goal, we thought it most realistic to concentrate on improving retrieval at high levels of precision.</p><p>In hopes that we could avoid introducing noisy data into our system, we indexed only text in the RSS feeds of each blog. Thus we ignored information that appeared only in blogs' HTML-coded content, which included posts, blog software formatting, blogrolls, pluginrelated content and other link text.</p><p>To improve retrieval at high precision, we did not use stemming of any kind. Nor did we employ any query expansion. Rather than cast our net widely by stemming or expanding, our attention was focused on finding a few high-quality results for each query.</p><p>Though the blog data set contains a good deal of spam and other putatively non-relevant material, we did not focus on spam detection or data cleaning. Our only effort to remove documents from consideration was a short, hand-crafted word blacklist. This list consisted mainly of obscene words and phrases; blogs with any of these words in their title element were not considered relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Model</head><p>The goal of the blog distillation task was to find RSS feeds that a reader interested in a particular topic would be likely to add to his or her RSS reader. Feeds were relevant if they evinced "a recurring, principle interest" in the particular topic. Thus the task required systems to generalize from specific blog posts to the feed that they appear in.</p><p>With this framework in mind, our approach relied on the notion of Kullback-Leibler divergence. Given a query q and a feed f we induced two language models over the words the indexing vocabulary. Based on these models, our retrieval function matched feeds to queries based on the negative KL divergence between their language models:</p><formula xml:id="formula_0" coords="2,174.98,236.69,213.10,100.06">! s(q, f ) = "D( ˆ # q || ˆ # f ) = " p(w | ˆ # q )log p(w | ˆ # f w $ )</formula><p>where the sum is taken over the w words in the indexing language. In all of our runs, language models were simple multinomials, fitted with Dirichlet smoothing, with a hyperparameter m=1000.</p><p>The appeal of the KL model for the topic distillation task lies in its flexibility when inducing the language model for a given feed. We experimented with two main approaches to defining the feed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feed-Level Models</head><p>The simplest language models we used were calculated by considering all text encountered in a feed as a large "bag of words." Thus for the ith feed, the maximum likelihood estimate for the probability of the jth word was simply the frequency of word j divided by the number of tokens in feed i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-Level Models</head><p>A more interesting approach to inducing each feed's language model lay in what we termed the 'post-level' approach. For these models, the probability of the jth word in the ith feed was estimated by the proportion of posts generated by feed i that contained word j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We submitted four runs to the blog distillation task, summarized in Table <ref type="table" coords="2,445.00,647.28,4.50,10.63" target="#tab_0">1</ref>. The ad hoc re-ranking algorithm applied in run UTBLRR increased the similarity of feeds based on the location of query terms within the text of a particular feed. i.e. Feeds with query terms near the beginning of their text (especially inside the title element) were given higher credence than feeds whose shared query terms appeared elsewhere in their text. This run was included primarily to see if adding several intuitive heuristics would improve our results over the more principled design of the other runs.  <ref type="figure" coords="3,124.60,452.64,6.00,10.63" target="#fig_0">1</ref> shows MAP for each of our submitted runs on each of the 50 topics the comprised the blog distillation task this year. The results of Table <ref type="table" coords="3,411.16,466.56,6.00,10.63" target="#tab_1">2</ref> are borne out in Figure <ref type="figure" coords="3,124.60,480.24,4.67,10.63" target="#fig_0">1</ref>; while MAP varied widely over the 50 topics, across our retrieval models, results were fairly static. Most importantly, this suggests that computing feed language models at the post-or feed-level did not bear heavily on the accuracy of the resulting retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Priority</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Because this is the first year of the blog distillation task, at the time of this writing we cannot judge the overall quality of our results. Finding MAP in the area of 22% seems low, and we hope to improve this number in subsequent years. However, we were happier with our observed precision at 10 documents retrieved (P10). While we do not know the distribution of P10 scores across participants this year, we were happy to find that we held the false positive rate to a fairly low number (P10~45%) at 10 documents retrieved. This was especially gratifying after our experience in the relevance assessment portion of the track. While judging document relevance, we were surprised by the quantity of spam and other junk posts in the data. We were thus pleased to hold the amount of unwanted information to a low level early in our rankings. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,90.04,480.96,393.47,10.63;4,90.04,113.40,431.52,364.56"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. MAP for each of 50 Topics on each of UT iSchool's submitted runs</figDesc><graphic coords="4,90.04,113.40,431.52,364.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.04,675.36,430.67,38.71"><head>Table 1 . UT iSchool runs submitted for the Blog Distillation Task</head><label>1</label><figDesc></figDesc><table coords="2,311.56,675.36,56.40,10.63"><row><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.04,256.56,428.62,164.95"><head>Table 2</head><label>2</label><figDesc>summarizes our results. Mean average precision for our baseline run (UTLC) was 0.212. Only one other run showed statistically significant difference in MAP; UTBLRR gave MAP 0.179. A paired t-test over 50 queries yielded p=0.004, suggesting that the ad hoc re-ranking approach actively degraded performance. However, this effect did not present itself with respect to precision at 10 documents returned. In this case, the p-value was 0.523.</figDesc><table coords="3,90.04,353.52,322.32,67.99"><row><cell></cell><cell>MAP</cell><cell>P10</cell></row><row><cell>UTLC</cell><cell>0.212</cell><cell>0.453</cell></row><row><cell>UTPLMU100</cell><cell>0.212</cell><cell>0.453</cell></row><row><cell>UTBLNRR</cell><cell>0.22</cell><cell>0.451</cell></row><row><cell>UTBLRR</cell><cell>0.178</cell><cell>0.44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,90.04,425.04,243.23,38.23"><head>Table 2 . Summary Results for UT iSchool runs Figure</head><label>2</label><figDesc></figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,94.54,539.76,4.50,10.63;4,126.04,539.76,168.12,10.63" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,196.84,539.76,92.07,10.63">Apache Foundation</title>
		<author>
			<persName coords=""><surname>Lucene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,94.54,553.44,4.50,10.63;4,126.04,553.44,343.32,10.63;4,126.04,567.36,188.04,10.63" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,126.04,553.44,204.21,10.63">Lucene Extensions for Language Modeling</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Amsterdam</publisher>
		</imprint>
		<respStmt>
			<orgName>Informatics Institute. University of Amsterdam</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="4,94.54,581.04,4.50,10.63;4,126.04,581.04,389.16,10.63;4,126.04,594.96,381.10,10.63;4,126.04,608.64,129.00,10.63" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,193.48,581.04,316.36,10.63">Language Model Information Retrieval with Document Expansion</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,138.52,594.96,368.62,10.63;4,126.04,608.64,36.57,10.63">Human Language Technology Conference of the North American Chapter of the ACL</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,94.54,622.56,4.50,10.63;4,126.04,622.56,372.83,10.63;4,126.04,636.24,375.96,10.63;4,126.04,650.16,115.32,10.63" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,244.36,622.56,254.51,10.63;4,126.04,636.24,155.27,10.63">A Study of Smoothing Methods for Language Models Applied to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,289.24,636.24,207.41,10.63">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
