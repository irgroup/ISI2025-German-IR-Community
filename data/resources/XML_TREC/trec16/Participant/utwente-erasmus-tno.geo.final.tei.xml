<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.51,148.91,367.96,15.12;1,266.86,170.83,69.28,15.12">Cross Language Information Retrieval for Biomedical Literature</title>
				<funder>
					<orgName type="full">Netherlands Genomics Initiative</orgName>
					<orgName type="abbreviated">NGI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,126.61,203.31,90.40,10.48;1,217.01,201.70,1.41,6.99"><forename type="first">Martijn</forename><surname>Schuemie</surname></persName>
							<email>m.schuemie@erasmusmc.nl</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Biosemantics Group</orgName>
								<orgName type="department" key="dep2">Medical Informatics Department</orgName>
								<orgName type="institution">ErasmusMC University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,138.50,217.26,66.62,10.48"><forename type="first">Erasmus</forename><surname>Mc</surname></persName>
						</author>
						<author>
							<persName coords="1,284.41,203.31,83.46,10.48;1,367.88,201.70,1.88,6.99"><forename type="first">Dolf</forename><surname>Trieschnigg</surname></persName>
							<email>trieschn@ewi.utwente.nl</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Human Media Interaction group</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,420.82,203.31,70.04,10.48;1,490.86,201.70,1.88,6.99"><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
							<email>kraaijw@acm.org</email>
							<affiliation key="aff3">
								<orgName type="institution">TNO Information and Communication Technology</orgName>
								<address>
									<settlement>Delft</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.51,148.91,367.96,15.12;1,266.86,170.83,69.28,15.12">Cross Language Information Retrieval for Biomedical Literature</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E6DEBE124066C60AEC8AC0487138FAFE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This workshop report discusses the collaborative work of UT, EMC and TNO on the TREC Genomics Track 2007. The biomedical information retrieval task is approached using cross language methods, in which biomedical concept detection is combined with effective IR based on unigram language models. Furthermore, a co-occurrence method is used to select and filter candidate answers. On its own, the cross lingual approach and the filtering do not strongly improve retrieval results. However, the combination of approaches does show a strong improvement over the monolingual baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC Genomics track focuses on literature disclosure in the genomics domain. This report discusses the collaborative work of the University of Twente, Erasmus Medical Center and TNO on the TREC Genomics Track 2007.</p><p>The 2007' task is to answer 36 biological information needs using a fixed collection of around 160.000 full-text articles from Highwire Press. The information needs require answers in the form of a particular entity type, ranging from "genes" to "signs or symptoms". The systems should return passages, short strings of text from the original documents, containing the answer.</p><p>During last year we achieved reasonable (document retrieval) results using unigram language models without using any additional knowledge from biological databases. In this year's approach we focus on:</p><p>• A cross language approach to improve query language model estimation. A concept-tagged corpus is used as a parallel corpus to create a statistical translation dictionary (translating concepts to tokens and vice versa). The dictionary is used to translate concepts detected in the topic description to a query language model.</p><p>• Using a co-occurrence based method to determine and filter candidate answers.</p><p>In the following section the approach will be discussed in more detail. After that, the runs and achieved results are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>Our approach consists of an offline and an online process.</p><p>The offline process, which is carried out beforehand, consists of the following steps:</p><p>• Creation of the ontologies for each of the entity types used in the topics;</p><p>• Biomedical concept recognition on the collection to create a concept-tagged collection;</p><p>• Using the concept-tagged collection to create a statistical translation dictionary (consisting of concept-word pairs and a probability);</p><p>• Creation of an index of the valid passages in the collection.</p><p>The offline process is discussed in section 3. The online process, the retrieval process which is carried out for each of the topics, consists of the following steps:</p><p>• Use the dictionary to create a query language model for the topic;</p><p>• Find the best matching spans;</p><p>• Extract candidate answer concepts based on co-occurrence and select spans containing candidate concepts.</p><p>The online process is discussed in section 4.</p><p>3 Offline process</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Collection preprocessing</head><p>The document collection preprocessing is similar to last year <ref type="bibr" coords="2,356.71,380.03,9.96,8.74" target="#b5">[6]</ref>. The HTML documents are split into sections with corresponding section titles, using several different templates to support the differences in document formatting. Texts within &lt;TABLE&gt;, &lt;A&gt; (hyperlink), and &lt;FONT&gt; tags are ignored, thus also ignoring figure captions. Sentences are split using a simple algorithm developed by our team, using an unsupervised sentence boundary detection approach (based on the work of A. Mikheev <ref type="bibr" coords="2,156.39,439.80,10.30,8.74" target="#b3">[4]</ref>). For each sentence the byte offsets of the first and the last character in that sentence are reported. Last year the sections materials &amp; methods, literature references and acknowledgements were removed. However, after observing that last year's ground truth data also contains relevant passages from these sections, we decided to include them for this year's participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ontology creation</head><p>To detect the concepts in the documents, we needed an ontology that contains one or more terms for each concept. For every category of concepts a specific source of information was used:</p><p>GENES and PROTEINS We made no distinction between genes and proteins. For five organisms (Homo sapiens, Mus musculus, Rattus Norvegicus, Drosophila melanogaster, and Caenorhabditis elegans) we extracted the gene and protein names from Swiss-Prott<ref type="foot" coords="2,488.60,589.49,3.97,6.12" target="#foot_0">1</ref> and Entrez-Gene<ref type="foot" coords="2,172.31,601.45,3.97,6.12" target="#foot_1">2</ref> . Entries with matching database identifiers were combined. Using data from HomoloGene<ref type="foot" coords="2,173.92,613.40,3.97,6.12" target="#foot_2">3</ref> , homologs in different species were also combined into a single concept.</p><p>MUTATIONS, CELLS, and NEOPLASMS For these categories, we used the appropriate subtrees from the MeSH (Medical Subject Headings<ref type="foot" coords="2,344.82,645.07,3.97,6.12" target="#foot_3">4</ref> ) thesaurus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRUGS, DISEASES and SIGNS AND SYMPTOMS</head><p>For these categories, we used the concepts belonging to the appropriate semantic types from the UMLS (Unified Medical Language System<ref type="foot" coords="2,191.20,688.69,3.97,6.12" target="#foot_4">5</ref> thesaurus.</p><p>TOXICITIES We manually created a thesaurus for this category, containing 17 different toxicities.</p><p>MOLECULAR FUNCTIONS For this category, we used the appropriate subtree from the Gene Ontology<ref type="foot" coords="3,180.29,152.92,3.97,6.12" target="#foot_5">6</ref> .</p><p>PATHWAYS We extracted pathway names from Medline using the following procedure: First, we selected a subset of documents using the query "gene OR protein", limited to publications in the last five years. We then extracted passages that matched the pattern "the &lt;x&gt; pathway", where &lt;x&gt; could be a maximum of four words. If &lt;x&gt; also occurred in the pattern "a &lt;x&gt; pathway" it was removed from the list, to correct for spurious matched such as "the unknown pathway" or "the complex pathway". We furthermore manually checked the remaining list of potential pathway names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STRAINS and ANTIBODIES</head><p>We were not able to construct thesauri for the categories STRAINS and ANTIBODIES.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Concept recognition</head><p>Concept recognition was performed using our Peregrine tool <ref type="bibr" coords="3,362.36,321.01,9.96,8.74" target="#b4">[5]</ref>, Both text and ontology terms were tokenized. A token was considered to be a consecutive string of letters and/or numbers, all other characters were discarded. Tokens in the text were matched to the tokens in the ontology terms to detect concepts in the text. For all concepts except genes or proteins, the tokens were reduced to their normalized form using the LVG normalizer <ref type="bibr" coords="3,353.61,368.83,10.52,8.74" target="#b2">[3]</ref> prior to matching. Because gene and protein names are often highly ambiguous, we used several simple rules to detect and possibly resolve ambiguous gene and protein names:</p><p>1. We first determined whether a term is ambiguous. A term is considered ambiguous if it refers to more than one gene in the dictionary, or when it is shorter than six characters and does not contain a number. A non-ambiguous term will automatically be assigned.</p><p>2. An ambiguous term will only be assigned if a synonym is found in the same document, or the term is the preferred name of the gene.</p><p>Because the simple disambiguation is rather strict, we also allowed ambiguous terms to be assigned if a keyword was found in the same document. A keyword is a word (i.e. a token) that occurs in any of the long-form names of the gene, and appears less than n times in the dictionary as a whole. We have achieved the best results with n = 1,000. For instance, in the term "Prostate Specific Antigen" the word "Prostate" appears less than 1,000 times in the dictionary. If the ambiguous synonym "PSA" is encountered in text, and the word "Prostate" is also encountered, the gene name is recognized.</p><p>Participation in the gene normalization task of the Biocreative 2 competition showed that this approach leads to a precision of 75% and a recall of 76% when linking human gene mentions in text to specific genes <ref type="bibr" coords="3,184.20,591.81,9.96,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Statistical translation dictionary</head><p>The tagged corpus is used as a parallel corpus to create a statistical translation dictionary. The dictionary consists of {conceptid, token, probability}-triples, indicating the probability that a particular token t denotes a particular biomedical concept c. The dictionary is created by tokenizing the concept-tagged collection and by counting the assignment of a token to a concept. Figure <ref type="figure" coords="3,508.02,673.37,4.98,8.74">1</ref> shows an example of tokenization and the assignment to concept ids.</p><p>The probability P dict (t|c) is estimated as follows:</p><formula xml:id="formula_0" coords="3,234.94,714.81,129.15,24.72">P dict (t|c) = f req(t, c) t f req(t , c)</formula><p>, where f req(t, c) is the number of times a token in the tagged corpus is assigned to the concept c. Figure <ref type="figure" coords="4,136.38,123.98,4.98,8.74" target="#fig_0">2</ref> shows a partial entry list for the concept "TNF kappa B".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original</head><p>Regulation by egr-  The dictionary can be used to determine the ambiguity and specificity of a token for a particular concept. How the dictionary is used is explained in section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Span indexing</head><p>The preprocessed text collection is split into valid spans, as defined by the task. The spans are treated as documents in a unigram index. For the tokenization we use the method evaluated by Trieschnigg et al <ref type="bibr" coords="4,164.38,523.02,9.96,8.74" target="#b6">[7]</ref>. This method showed to improve document mean average precision with 27% compared to a basic tokenizer on the 2006 topics.</p><p>The method works as follows:</p><p>• The input text is split on whitespace, the resulting strings are treated as a group:</p><p>-Extract tokens from the group consisting of either letters or digits.</p><p>-If more than one token was extracted from a group, add the concatenation of these tokens as an additional compound token.</p><p>• For each obtained token: skip if it appears on a stopword list, do Porter stemming if the token does not contain uppercase letters.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Online process</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Query language model estimation and span retrieval</head><p>For the retrieval process, we use the topic description in two "languages": Firstly, the original topic description in English. Secondly, the topic description in biomedical "concept language" as detected by the concept recognizer described in section 3.3. The topic description in "concept language" is translated to English using the statistical translation dictionary. A method similar to Xu <ref type="bibr" coords="5,118.51,406.01,10.52,8.74" target="#b7">[8]</ref> is used.</p><p>Our document retrieval is based on generative unigram language models. The language models of the indexed documents (in our case valid spans from complete articles) are compared to the language model of the query, and are ranked according to the likelihood of generating this query model. Both document and query model, P (t|D) and P (t|Q) respectively, assign a probability to the event of drawing a term t from it.</p><p>Our query model is a mixture of terms actually occurring in the original English query P (t|Q e ), and the terms which can be generated from a language model based on the conceptual representation of the query P (t|Q c ). The mixture query model looks as follows:</p><formula xml:id="formula_1" coords="5,211.12,519.94,301.88,9.65">P (t|Q) = αP (t|Q e ) + (1 -α)P (t|Q c ),<label>(1)</label></formula><p>where α is a mixture parameter, in our experiments fixed to 0.7 based on previous experimental results.</p><p>The English query model P (t|Q e ) is simply estimated based on maximum likelihood:</p><formula xml:id="formula_2" coords="5,245.50,579.25,267.50,14.38">P M L (t|Q e ) = tf (t,Qe) |Qe| ,<label>(2)</label></formula><p>where tf (t, Q) is the term frequency of the term t in the query Q and |Q| is the query length.</p><p>The conceptual query model P (t|Q c ) is based on which terms are used to denote biomedical concepts detected in the query:</p><formula xml:id="formula_3" coords="5,221.90,645.67,159.21,48.77">P (t|Q c ) = c∈Qc P (c, t|Q c ) = c∈Qc P (t|c, Q c )P (c|Q c )</formula><p>where c ∈ Q c are the concepts detected in the query and P (c, t|Q c ) is the probability that the term t is used to denote concept c in the query context. We simplify our model by dropping this dependence on the query context:</p><formula xml:id="formula_4" coords="5,221.80,745.64,149.43,11.14">P (t|Q c ) ≈ c∈Qc P (t|c)P (c|Q c ),</formula><p>where P (t|c) denotes the probability that a term t is used to represent concept c. We assume P (c|Q c ) is uniformly distributed and estimate P (t|c) using the dictionary:</p><formula xml:id="formula_5" coords="6,217.72,142.12,157.60,13.47">P M L (t|Q c ) = c∈Qc 1 |Qc| P dict (t|c).</formula><p>The retrieval status value (RSV), the function used to score a (span-)document D for a query Q, is defined as follows:</p><formula xml:id="formula_6" coords="6,200.16,206.16,221.89,26.80">RSV (Q, D) = t∈Q P (t|Q) log(1 + λP (t|D) (1 -λ)P (t|C)</formula><p>)</p><p>Where</p><formula xml:id="formula_7" coords="6,104.94,238.61,239.83,70.55">P M L (t|D) = tf (t, D) |D| P M L (t|C) = D∈C tf (t, D) D∈C |D| P (t|Q)</formula><p>is the probability of a term t to occur in the query language model. P (t|D) is the probability of a term being sampled from the document D, which is based on the maximum likelihood estimate. P (t|C) is the probability of a term being sampled from the background smoothing model C, which is based on maximum likelihood estimates on the collection. tf (t, D) is the term frequency of a term in a document, i.e. the number of occurrences of the term in the document. |D| denotes the document length, i.e. total number of tokens in the document. Finally, λ is the Jelinek-Mercer smoothing parameter which sets the relative influence of the background smoothing model. For more information see Hiemstra and Kraaij <ref type="bibr" coords="6,377.97,384.11,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="6,391.82,384.11,7.00,8.74" target="#b1">2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Candidate entity selection and filtering</head><p>After retrieving a list of relevant spans, a number of possible answers is extracted. This is simply done by filtering the concepts with the desired entity type from the best scoring spans. Initial experiments with this approach showed that naively using these entities as candidate answers resulted in too general answers. Therefore, we sort the answers by the log likelihood that an entity in our list of relevant spans was not the result of drawing it from a random span in the collection. Initially, we use the top 50 results from our retrieval run to find candidate answers. If no candidate answers are found in this set, the next 50 results are considered repeatedly until at least a single matching concept is found, however no more than a 1000 hits are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Runs and results</head><p>We submitted two automatic runs EMCUT1 and EMCUT2. Run EMCUT1 aimed at achieving a high aspect precision, by returning passages for different entities in a round-robin fashion. Run EMCUT2 simply returns the best scoring passages from each document, which do contain the requested entity type. The results from the offical runs are displayed in table <ref type="table" coords="6,385.34,604.05,3.87,8.74" target="#tab_4">2</ref>.</p><p>After the workshop we carried out a number of additional experiments. Figure <ref type="figure" coords="6,460.99,616.01,4.98,8.74" target="#fig_1">3</ref> shows the runs graphically, table <ref type="table" coords="6,188.91,627.96,4.98,8.74" target="#tab_3">1</ref> gives an overview of the results. The upper half of the table shows results in which we do not carry out candidate entity selection and filtering (named '-filter'). In the lower half of the table we do apply the approach described in section 4.2 (named '+filter'). As a baseline we use the untranslated query model based on maximum likelihood (named 'MLIR'), as described in eq. 2. The CLIR system used the proposed mixture model based on both maximum likelihood and concept-translation (eq. 1). The following subsections discuss the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Candidate selection and filtering</head><p>One would expect that candidate selection and filtering would improve precision at cost of recall: if we detected that the passage contains the requested entity type, it's more likely that it is relevant  to our query. However, if we miss a requested entity type during concept detection we might lose relevant answers as well. When we compare the upper half with the lower half of table 1, the precision based measures indeed confirm an increase in initial precision: precision at 5 and 10 retrieved relevant documents show a steady improvement over all runs. The average precision based measures show that especially the CLIR runs benefit from candidate selection and filtering. Also see the PR-curves for the baseline (figure <ref type="figure" coords="7,295.37,381.20,17.27,8.74" target="#fig_4">4(a)</ref>) and CLIR runs (fig. <ref type="figure" coords="7,410.02,381.20,16.61,8.74" target="#fig_4">4(b)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Concept cross translation</head><p>The numbers in table <ref type="table" coords="7,184.31,427.48,4.98,8.74" target="#tab_3">1</ref> show that the CLIR approach in general outperforms our baseline. Despite the reasonable average percentual increase, most of the differences are not significant. Figure <ref type="figure" coords="7,508.02,439.43,4.98,8.74" target="#fig_6">5</ref> shows the per topic difference in (document) average precision 7 . For 13 topics, no difference is witnessed because the concept recognizer did not detect any concepts, leading to no change in the query model. When no candidate selection takes place (fig. <ref type="figure" coords="7,388.81,475.30,16.24,8.74" target="#fig_6">5(a)</ref>), more than half of the affected topics is actually harmed by the cross language approach. On the other hand, a few topics (especially topics 209 and 229) benefit strongly from the CLIR approach.</p><p>The runs which do candidate selection (fig. <ref type="figure" coords="7,292.75,511.16,4.57,8.74" target="#fig_6">5</ref>(b) and 5(c)) seem to benefit more from the CLIR approach. Half of the topics shows an increase in average precision, the other half a decrease. However, the increases are much more substantial than the decreases, leading to a higher mean average precision.</p><p>We have compared the submitted runs (CLIR+filter) to its baseline (MLIR+filter) and investigated the differences for each topic. The runs using the concept language model often perform better because the only concept recognised in the query is the most important part of the query, and extra weight is given to this part. For instance, in topic 207, only the concept 'etidronate' is found, so the search is biased towards this concept, leading to better results. However, sometimes the concept found is not the most important part of the query. For instance, in topic 224 the concept 'lung cancer' is detected, but 'melanogenesis' is not, even though this is an essential part of the query. Consequently, the performance on this topic is drastically reduced by incorporating the concept language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This year we approached TREC Genomics using a cross language IR (CLIR) techniques. Moreover, we filtered the retrieved spans on the presence of the concept types requested by the query. 7 Thanks to Edgar Meij for the script to generate them.    On its own the CLIR approach gives varying results: some topics benefit from the reweighting of important query terms and the expansion with tokens related to the detected biomedical concepts. Other topics are actually harmed by the approach because the most important concepts were not detected. In many cases no concepts were detected because we limited our concept detection to concept types requested by the topics.</p><p>For the filtering we can say the same: on its own only the initial precision is improved by filtering on requested concept type.</p><p>Interestingly, the combination of CLIR and filtering does show a clear improvement over the baseline. Our hypothesis is that the filtering makes up for poor queries from the CLIR approach and benefits from improved CLIR queries.</p><p>Future work will be to further examine the cross language approach to biomedical IR. We expect better results when the initial concept recognition is more complete.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,130.21,416.41,342.57,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Dictionary entries for the concept "TNF kappa B" (partially shown)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,90.00,701.32,210.99,8.74"><head>Figure 3</head><label>3</label><figDesc>Figure 3 gives an overview of the online process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,213.05,310.87,176.89,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the online process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,90.00,277.64,423.00,8.74;7,90.00,289.60,36.56,8.74"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: PR-curves of systems with (aspect/precision run) and without candidate selection and filtering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,90.00,467.06,423.00,8.74;8,90.00,479.01,404.45,8.74"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Per topic difference in document average precision between CLIR and MLIR. Positive differences (CLIR &gt; MLIR) are shown above the x-axis. The labels show the topic numbers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,90.00,570.69,441.33,144.40"><head>Table 1 :</head><label>1</label><figDesc>Comparison of different retrieval systems. Between parentheses the change with the system's baseline (previous row); † and ‡ indicate a significant difference based on a Wilcoxon signed-rank test (p &lt; 0.05 and p &lt; 0.005 respectively.</figDesc><table coords="8,95.98,570.69,435.36,94.60"><row><cell cols="3">Without candidate entity selection (-filter)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Document measures</cell><cell cols="2">Passage MAP</cell><cell>Aspect</cell></row><row><cell></cell><cell></cell><cell>MAP</cell><cell>P@5</cell><cell>P@10</cell><cell>Pass.</cell><cell>Pass. 2</cell><cell>MAP</cell></row><row><cell>MLIR</cell><cell></cell><cell>0.210</cell><cell>0.394</cell><cell>0.358</cell><cell>0.045</cell><cell>0.046</cell><cell>0.121</cell></row><row><cell>CLIR</cell><cell></cell><cell>0.220 (4%)</cell><cell>0.389 (-1%)</cell><cell>0.375 (5%)</cell><cell>0.050 (11%)</cell><cell>0.053 (16% †)</cell><cell>0.113 (-7% ‡)</cell></row><row><cell cols="3">With candidate entity selection (+filter)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Document measures</cell><cell cols="2">Passage MAP</cell><cell>Aspect</cell></row><row><cell></cell><cell></cell><cell>MAP</cell><cell>P@5</cell><cell>P@10</cell><cell>Pass.</cell><cell>Pass. 2</cell><cell>MAP</cell></row><row><cell>MLIR (precision)</cell><cell></cell><cell>0.218</cell><cell>0.439</cell><cell>0.392</cell><cell>0.067</cell><cell>0.033</cell><cell>0.150</cell></row><row><cell>CLIR (precision)</cell><cell>EMCUT2</cell><cell>0.240 (10% †)</cell><cell>0.444 (1%)</cell><cell>0.425 (9%)</cell><cell>0.074 (10%)</cell><cell>0.038 (13%)</cell><cell>0.150 (-0%)</cell></row><row><cell>MLIR (aspect)</cell><cell></cell><cell>0.200</cell><cell>0.428</cell><cell>0.378</cell><cell>0.058</cell><cell>0.030</cell><cell>0.136</cell></row><row><cell>CLIR (aspect)</cell><cell>EMCUT1</cell><cell>0.234 (17%)</cell><cell>0.467 (9%)</cell><cell>0.419 (11%)</cell><cell>0.069 (18%)</cell><cell>0.037 (23%)</cell><cell>0.153 (13%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,165.54,780.88,271.93,8.74"><head>Table 2 :</head><label>2</label><figDesc>Performance scores for runs EMCUT1 and EMCUT2</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,709.56,88.92,6.64"><p>http://www.expasy.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,719.07,203.24,6.64"><p>http://www.ncbi.nlm.nih.gov/sites/entrez?db=gene</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,728.57,228.65,6.64"><p>http://www.ncbi.nlm.nih.gov/sites/entrez?db=homologene</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,105.24,738.07,203.24,6.64"><p>http://www.ncbi.nlm.nih.gov/sites/entrez?db=mesh</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,105.24,747.58,152.43,6.64"><p>http://www.nlm.nih.gov/research/umls</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="3,105.24,747.58,114.32,6.64"><p>http://www.geneontology.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgements</head><p>This work was part of the <rs type="institution">BioRange programme of the Netherlands Bioinformatics Centre (NBIC)</rs>, which is supported by a BSIK grant through the <rs type="funder">Netherlands Genomics Initiative (NGI)</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,104.71,362.21,408.28,7.86;10,104.71,373.17,408.29,7.86;10,104.71,384.13,408.29,7.86;10,104.71,395.09,33.28,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,258.21,362.21,236.97,7.86">Twenty-one at TREC-7: Ad hoc and cross language track</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,315.59,373.17,160.65,7.86">The Seventh Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="500" to="242" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
	<note>NIST</note>
</biblStruct>

<biblStruct coords="10,104.71,410.03,408.29,7.86;10,104.71,420.99,408.30,7.86;10,104.71,431.95,20.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,254.02,410.03,164.31,7.86">A language modeling approach for TREC</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,221.98,420.99,240.64,7.86">TREC: Experiment and Evaluation in Information Retrieval</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,104.71,446.89,408.29,7.86;10,104.71,457.85,408.29,7.86;10,104.71,468.81,45.56,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,289.33,446.89,223.68,7.86;10,104.71,457.85,51.89,7.86">Lexical methods for managing variation in biomedical terminologies</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,179.18,457.85,333.81,7.86;10,104.71,468.81,17.20,7.86">Proceedings of the 18th Annual Symposium on Computer Applications in Medical Care</title>
		<meeting>the 18th Annual Symposium on Computer Applications in Medical Care</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,104.71,483.76,361.32,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,175.89,483.76,121.36,7.86">Periods, capitalized words, etc</title>
		<author>
			<persName coords=""><forename type="first">Andrei</forename><surname>Mikheev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,304.92,483.76,71.81,7.86">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="289" to="318" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,104.71,498.70,408.29,7.86;10,104.71,509.66,298.23,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,265.70,498.70,247.30,7.86;10,104.71,509.66,25.45,7.86">Peregrine: Lightweight gene name normalization by dictionary lookup</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jelier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,150.01,509.66,165.57,7.86">Proceedings of the Biocreative 2 workshop</title>
		<meeting>the Biocreative 2 workshop<address><addrLine>Madrid</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-04">April 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,104.71,524.60,408.29,7.86;10,104.71,535.56,164.63,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,298.83,524.60,214.18,7.86;10,104.71,535.56,19.65,7.86">Concept based document retrieval for genomics literature</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,143.89,535.56,97.39,7.86">Proceedings of TREC 15</title>
		<meeting>TREC 15</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,104.71,550.51,408.29,7.86;10,104.71,561.46,408.29,7.86;10,104.71,572.42,408.29,7.86;10,104.71,583.38,102.46,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,318.48,550.51,194.52,7.86;10,104.71,561.46,90.33,7.86">The influence of basic tokenization on biomedical document retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M G</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,217.03,561.46,295.97,7.86;10,104.71,572.42,202.82,7.86">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="803" to="804" />
		</imprint>
	</monogr>
	<note>extended abstract</note>
</biblStruct>

<biblStruct coords="10,104.71,598.33,408.29,7.86;10,104.71,609.29,351.85,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,327.98,598.33,167.16,7.86">TREC 2001 cross-lingual retrieval at BBN</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,278.18,609.29,150.05,7.86">The Tenth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
