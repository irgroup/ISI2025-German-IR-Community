<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,85.34,75.37,441.20,12.64;1,229.85,91.47,152.43,12.64">WIDIT in TREC-2007 Blog Track: Combining Lexicon-based Methods to Detect Opinionated Blogs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,237.53,120.18,46.69,8.96"><forename type="first">Kiduk</forename><surname>Yang</surname></persName>
							<email>kiyang@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.59,120.18,32.23,8.96"><forename type="first">Ning</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,331.26,120.18,42.99,8.96"><forename type="first">Hui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,85.34,75.37,441.20,12.64;1,229.85,91.47,152.43,12.64">WIDIT in TREC-2007 Blog Track: Combining Lexicon-based Methods to Detect Opinionated Blogs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">042C85CDF081B3769DD2DF6E1F61058A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In TREC-2007, Indiana University"s WIDIT Lab<ref type="foot" coords="1,295.13,198.91,3.48,6.26" target="#foot_0">1</ref> participated in the Blog track"s opinion task and the polarity subtask. For the opinion task, whose goal is to "uncover the public sentiment towards a given entity/target", we focused on combining multiple sources of evidence to detect opinionated blog postings. Since detecting opinionated blogs on a given topic (i.e., entity/target) involves not only retrieving topically relevant blogs but also identifying those that contain opinions about the target, our approach to the opinion finding task consisted of first applying traditional IR methods to retrieve on-topic blogs and then boosting the ranks of opinionated blogs based on combined opinion scores generated by multiple opinion detection methods. The key idea underlying our opinion detection method is to rely on a variety of complementary evidences rather than trying to optimize a single approach. This fusion approach to opinionated blog detection is motivated by our past experience that suggested no single approach, whether lexicon-based or classifier-driven, is well-suited for the blog opinion retrieval task. To accomplish the polarity subtask, which requires classification of the retrieved blogs into positive or negative orientation, our opinion detection module was extended to generate polarity scores to be used for polarity determination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RESEARCH QUESTIONS</head><p>Having explored the topical search problem over the years <ref type="bibr" coords="1,331.54,396.91,58.01,9.94" target="#b7">(Yang, 2002;</ref><ref type="bibr" coords="1,392.25,396.91,77.18,9.94" target="#b10">Yang et. al, 2005)</ref>, we focused on the question of how to adapt a topical retrieval system for opinion finding task. The intuitive answer was to first apply IR methods to retrieve blogs about a target (i.e., on-topic retrieval), and then identify opinionated blogs by leveraging various evidences of opinion.</p><p>Therefore, our primary research question centers on the evidences of opinion, namely what they are and how they can be leveraged. To maximize the total coverage of opinion evidence, we considered the following three complementary sources of opinion evidence:</p><p> Opinion Lexicon: An obvious source of opinion evidence is the set of terms commonly used in expressing opinions (e.g., "Skype sucks", "Skype rocks", "Skype is cool").</p><p> Opinion Collocations: One of the contextual evidence of opinion comes from collocations used to mark adjacent statements as opinions (e.g., "I believe God exists", "God is dead to me").</p><p> Opinion Morphology: When expressing strong opinions or perspectives, people often use morphed word form for emphasis ("Skype is soooo buggy", "Skype is bugfested").</p><p>Because blogs are generated by content management software (i.e. blogware) that allows authors to create and update contents via a browser-based interface, they are laden with non-posting content for navigation, advertisement, and formatting display. Thus, our secondary research question concerns how such blogware-generated noise influences opinion detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">METHODOLOGY</head><p>WIDIT approach to blog opinion retrieval task consisted of three main steps: initial retrieval, on-topic retrieval optimization, and opinion identification. Initial retrieval was executed using the standard WIDIT retrieval method, on-topic retrieval optimization was done by a post-retrieval reranking approach that leveraged multiple topic-related factors, and opinion identification was accomplished by a fusion of five opinion modules that leveraged multiple sources of opinion evidence. To assess the effect of noise on retrieval performance, we explored various noise reduction methods with which to exclude non-English blogs and non-blog contents from the collection. The overview of WIDIT blog opinion retrieval system is shown in Figure <ref type="figure" coords="2,146.39,212.08,4.14,9.94" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Noise Reduction</head><p>To effectively eliminate the noise in blog data without inadvertently excluding valid content, we constructed Non-English Blog Identification (NBI) module that identifies non-English blogs for exclusion, and Blog Noise Elimination (BNE) module that excludes non-blog content portion of the blog. NBI leverages the characteristics of non-English (NE) blogs, which contain a large proportion of NE terms, and/or high frequency of NE stopwords. NBI heuristic, which scores documents based on NE content density and frequencies of stopwords (both English and non-English), was tuned by iteratively examining the NE blog clusters identified by the module to find false positives and adjusting the NE threshold until no false positives were found. BNE module, which uses markup tags to differentiate blog content (e.g., post, comments, etc.) from non-blog content (e.g., scripts, style texts, forms, sidebar, navigation, profile,</p><formula xml:id="formula_0" coords="3,117.63,356.76,286.06,43.97">  k k k ik ik k k ik f k f k q f avdl dl b b k f df df N d                    3 3 1 1 )) ( ) 1 (( 5 . 0 5 . 0 log</formula><p>advertisement, header, footer, etc.), was constructed by examining all unique markup tags in the blog collection to identify patterns to be captured by regular expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Initial Retrieval</head><p>The initial retrieval is executed by the WIDIT retrieval engine, which consists of document/query indexing and retrieval module. After removing markup tags and stopwords, WIDIT"s indexing modules applies a modified version of the simple plural remover (Frakes &amp; Baeza-Yates, 1992). <ref type="foot" coords="3,410.35,154.03,3.48,6.26" target="#foot_1">2</ref> The stopwords consisted of non-meaningful words such as words in a standard stopword list, non-alphabetical words, words consisting of more than 25 or less than 3 characters, and words that contain 3 or more repeated characters. Hyphenated words were split into parts before applying the stopword exclusion, and acronyms and abbreviations were kept as index terms <ref type="foot" coords="3,157.22,204.67,3.48,6.26" target="#foot_2">3</ref> .</p><p>In order to enable incremental indexing as well as to scale up to large collections, WIDIT indexes the document collection in fixed-size subcolllections, which are searched in parallel. The whole collection term statistics, derived after the creation of the subcollections, are used in subcollection retrievals so that subcollection retrieval results can simply be merged without any need for retrieval score normalizations.</p><p>Query indexing module includes query expansion submodules that identify nouns and noun phrases, expand acronyms and abbreviations, and extract non-relevant portion of topic descriptions with which to formulate various expanded versions of the query.</p><p>The retrieval module implements the probabilistic model using the Okapi BM25 formula. The simplified version of the Okapi BM25 relevance scoring formula <ref type="bibr" coords="3,365.95,320.83,128.02,9.94" target="#b4">(Robertson &amp; Walker, 1994)</ref> is used to implement the probabilistic model.</p><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">On-topic Retrieval Optimization</head><p>Optimizing the ranking of the initial retrieval results is important for two reasons. First, on-topic retrieval optimization is an effective strategy for incorporating topical clues not considered in initial retrieval <ref type="bibr" coords="3,509.98,440.61,30.23,9.94;3,72.02,453.33,25.15,9.94" target="#b7">(Yang, 2002;</ref><ref type="bibr" coords="3,101.05,453.33,114.97,9.94" target="#b8">Yang &amp; Albertson, 2004;</ref><ref type="bibr" coords="3,219.89,453.33,80.45,9.94" target="#b9">Yang et. al, 2007)</ref>. Second, our two-step strategy for targeted opinion detection consists of minimalistic initial retrieval that favors recall followed by post-retrieval reranking to boost precision.</p><p>Our on-topic retrieval optimization involves reranking of the initial retrieval results based on a set of topic-related reranking factors, where the reranking factors consist of topical clues not used in initial ranking of documents. The topic reranking factors used the study are: Exact Match, which is the frequency of exact query string occurrence in document, Proximity Match, which is the frequency of padded<ref type="foot" coords="3,508.90,526.92,3.48,6.26" target="#foot_3">4</ref> query string occurrence in document, Noun Phrase Match, which is the frequency of query noun phrases occurrence in document, and Non-Rel Match 5 , which is the frequency of non-relevant nouns and noun phrase occurrence in documents. All the reranking factors are normalized by document length. The on-topic reranking method consists of following three steps: 1) Compute topic reranking scores for top N results.</p><p>2) Partition the top N results into reranking groups based on the original ranking and a combination of the most influential reranking factors. The purpose of reranking groups is to prevent excessive influence of reranking by preserving the effect of key ranking factors.</p><p>3) Rerank the initial retrieval results within reranking groups by the combined reranking score.</p><p>The objective of reranking is to float low ranking relevant documents to the top ranks based on post-retrieval analysis of reranking factors. Although reranking does not retrieve any new relevant documents (i.e. no recall improvement), it can produce high precision improvement via post-retrieval compensation (e.g. phrase matching). The key questions for reranking are what reranking factors to consider and how to combine individual reranking factors to optimize the reranking effect. The selection of reranking factors depends largely on the initial retrieval method since reranking is designed to supplement the initial retrieval. The fusion of the reranking factors can be implemented by a weighted sum of reranking scores, where the weights represent the contributions of individual factors. The weighted sum method is discussed in more detail in the fusion section of the methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Opinion Detection</head><p>Determining whether a document contains an opinion is somewhat different from classifying a document as opinionated. The latter, which usually involves supervised machine learning, depends on the document"s overall characteristic (e.g., degree of subjectivity), whereas the former, which often entails the use of opinion lexicons, is based on the detection of opinion evidence. At the sentence or paragraph level, however, the distinction between the two becomes inconsequential since the overall characteristic is strongly influenced by the presence of opinion evidence.</p><p>For opinion mining, which involves opinion detection rather than opinion classification, opinion assessment methods are best applied at subdocument (e.g., sentence or paragraph) level. At subdocument level, the challenges of machine learning approach are compounded with two new problems: First, the training data with document-level labels is likely to produce a classifier not well suited for subdocument level classification. Second, the sparsity of features in short "documents" will diminish the classifier"s effectiveness.</p><p>Our opinion detection approach, which is entirely lexicon-based to avoid the pitfalls of the machine learning problems, relies on a set of opinion lexicons that leverage various evidences of opinion. The key idea underlying our method is to combine a set of complementary evidences rather than trying to optimize the utilization of a single source of evidence. We first construct opinion lexicons semi-automatically and used them in opinion scoring submodules to generate opinion scores of documents. The opinion scores are then combined to boost the ranks of opinionated blogs in a manner similar to the on-topic retrieval optimization.</p><p>Opinion scoring modules used in this study are High Frequency module, which identifies opinions based on the frequency of opinion terms (i.e., terms that occur frequently in opinionated blogs), Low Frequency module, which makes use of uncommon/rare terms (e.g., "sooo good") that express strong sentiments, IU module, which leverages n-grams with IU (I and you) anchor terms (e.g., I believe, You will love), Wilson's lexicon module, which uses a collection-independent opinion lexicon composed of a subset of Wilson"s subjectivity terms, and Opinion Acronym module, which utilizes a small set of opinion acronyms (e.g., imho). Each module computes two opinion scores for each lexicon used: a simple frequency-based score and a proximity score based on the frequency of lexicon terms that occur near the query string in a document. The generalized formula for opinion scoring can be described as</p><formula xml:id="formula_1" coords="4,145.74,618.75,228.29,38.78">) ( ) ( ) ( ) ( d len t s t f d opSC D L t     <label>(2)</label></formula><p>where L and D denote the term sets of a given lexicon and document d respectively, len(d) is the number of tokens in d, s(t) is the strength of term t as designated in the lexicon, and f(t) is the frequency function that returns either the frequency of t in d (simple score) or the frequency of t that co-occurs with the query string in d (proximity score). The proximity score, which is a strict measure that ensures the opinion found is on target, is liable to miss opinion expressions located outside the proximity window as well as those within the proximity of the target that is expressed differently from the query string. The simple score, therefore, can supplement the proximity score, especially when used in conjunction with the on-topic optimization.</p><p>For polarity detection, positive and negative polarity scores are computed for each score type (i.e. simple, proximity). The generalized formula for computing opinion polarity scores is shown below.</p><p>) (</p><formula xml:id="formula_2" coords="5,127.77,165.52,246.25,42.79">) ( ) ( ) ( d len t s t f d opSC D L t pol pol     (3)</formula><p>In equation 3, L pol describes the lexicon term subset whose polarity is pol (positive or negative). The default term polarity from the lexicon is reversed if the term appears near a valence shifter (e.g., not, never, no, without, hardly, barely, scarcely) in d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">High Frequency Module</head><p>The basic idea behind the High Frequency Module (HFM) is to identify opinions based on common opinion terms. Since common opinion terms, which are words often used to express opinions, will occur frequently in opinionated text and infrequently in non-opinionated text, we create the candidate HF lexicon by identifying high frequency terms from the positive blog training data (i.e. opinionated blogs) and excluding those that also have high frequency in the negative blog training data. The resulting term set is then manually reviewed to filter out spurious terms and to assign polarity and strength of opinion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Wilson's Lexicon Module</head><p>To supplement the HF lexicon, which is collection-dependent, we construct a set of opinion lexicons from Wilson"s subjectivity terms <ref type="bibr" coords="5,195.38,414.79,137.72,9.94" target="#b6">(Wilson, Pierce, &amp; Wiebe, 2003</ref>). Wilson's Lexicon Module (WLM) uses three collection-independent lexicons, which consists of strong and weak subjective terms extracted from Wilson"s subjectivity term list, and emphasis terms selected from Wilson"s intensifiers. Both strong and weak subjective lexicons inherit the polarity and strength from Wilson"s subjectivity terms, but the emphasis lexicon includes neither the strength nor polarity values since the strength and polarity of an emphasis term depend on the term it emphasizes (e.g., absolutely wonderful). In computing opinion scores (equation 2), emphasis terms are assigned the strength of 1, which is the minimum value for term strength. No polarity scores are generated with the emphasis lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.">Low Frequency Module</head><p>While HFM and WLM leverage the obvious source of opinion, namely the standard opinion lexicon used in expressing opinions (e.g., "Skype sucks", "Skype rocks", "Skype is cool"), Low Frequency Module (LFM) looks to the low frequency terms for opinion evidence. LFM is derived from the hypothesis that people become creative when expressing opinions and tend to use uncommon or rare term patterns <ref type="bibr" coords="5,480.43,584.01,59.69,9.94;5,72.02,596.76,23.80,9.94" target="#b5">(Wiebe et. al, 2004)</ref>. These creative expressions, or Opinion Morphology (OM) terms as we call it, may be intentionally misspelled words (e.g., luv, hizzarious), compounded words (e.g., metacool, crazygood), repeat-character words (e.g., sooo, fantaaastic, grrreat), or some combination of the three (e.g., metacoool, superrrrv). Since OM terms occur infrequently due to their creative and non-standard nature, we start the construction of the OM lexicon by identifying low frequency (e.g., df &lt; 100) terms in the blog collection. Words with three or more repeated characters in the low frequency term set are examined to detect OM patterns, which are encapsulated in a compilation of regular expressions. The regular expressions (OM regex) are refined iteratively by repeating the cycle described below:</p><p>1. Examine repeat-character patterns and compile regular expressions. 2. Apply regular expressions to the low frequency term set. 3. Modify regular expressions after comparing the result of step 2 with the repeat-character patterns in step 1. 4. Go to step 2.</p><p>To round out the OM regex, regular expressions that simulate misspellings by vowel substitutions (e.g., luv) as well as regular expressions for capturing compound morphing are constructed from HF and Wilson terms, applied to the LF term set, and refined iteratively in a manner similar to the repeat-character refinement steps describe above. LF terms not captured by OM regex but are nevertheless determined to be opinion terms form a basis for the OM lexicon. The final OM lexicon consists of the opinion terms flagged during the OM regex construction process as well as those identified during the final review of the LF term subset that excludes terms identified by the OM regex. The format of OM regex is consistent with other lexicons in that each entry is composed of a regular expression and associated polarity and strength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4.">IU Module</head><p>IU Module (IUM) is motivated by the observation that pronouns such as "I" and "you" appear very frequently in opinionated texts. IU collocations, which are n-grams with IU (I and you) anchor terms (e.g., I believe, you will love), mark adjacent statements as opinions (e.g., "I believe God exists", "God is dead to me"). In this regard, IU collocations provide yet another type of opinion evidence to complement the opinion lexicons of HFM/WLM and the opinion morphology of LFM.</p><p>For IU lexicon construction, we first extract n-grams that begin or end with IU anchors (e.g., I, you, we, my, your, our, me, etc.) from the positive blog training data and movie review data (obtained from http://www.cs.cornell.edu/people/pabo/movie-review-data/).</p><p>Since IU collocations are not collection-dependent, movie reviews provids additional data to broaden and strengthen the IU n-gram harvest. The extracted n-grams are then manually filtered to create the lexicon of IU collocations (e.g., "I believe", "my assessment", "good for you", etc.) with associated polarity and strength, after which the lexicon is expanded with additional IU collocations consisting of IU anchors and appropriate HF <ref type="bibr" coords="6,523.96,431.97,15.84,9.94;6,72.02,444.69,112.72,9.94">and Wilson terms (e.g., verbs)</ref>.</p><p>In order to accommodate the various forms of an IU collocation (e.g., I believe, I cannot but believe, I have always believed, etc.), IUM applies the IU lexicon in a slightly different manner than other modules. After preprocessing documents to compress certain prepositions, conjunctions, and articles (e.g., of, with, and, or, a, the, etc.), IU collocations in the lexicon are "padded" in such a way that document texts with up to two words in-between IU collocation words will be matched by IUM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.5.">Opinion Acronym Module</head><p>The Opinion Acronym lexicon used by Opinion Acronym Module (OAM) complements the IU lexicon with common IU collocation acronyms (e.g., imho). The OA lexicon consists of a manually filtered subset of netlingo"s chat acronyms and text message shorthand (http://www.netlingo.com/emailsh.cfm) in both acronym and expanded forms. Since opinion acronyms represent long phrases that serve as a clear indicator of opinion or sentiment, they are generally given higher opinion strength values than other lexicon entries. Like emphasis terms, no polarity is assigned to the OA lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Fusion</head><p>Topic reranking for on-topic retrieval optimization and opinion reranking for opinion detection generate multitudes of reranking scores that need to be combined. Two most common fusion methods are Similarity Merge <ref type="bibr" coords="6,103.46,685.56,90.30,9.94" target="#b1">(Fox &amp; Shaw, 1995)</ref> and Weighted Sum <ref type="bibr" coords="6,280.97,685.56,146.57,9.94" target="#b0">(Bartell, Cottrell, &amp; Belew, 1994)</ref>. Similarity Merge, based on the assumption that documents with higher overlap are more likely to be relevant, multiplies the sum of fusion component scores for a document by the number of fusion components that retrieved the document (i.e. overlap),. Instead of relying on overlap, the Weighted Sum method sums the fusion component scores weighted by their relative contributions, which is usually estimated from training data.</p><p>In our earlier investigations <ref type="bibr" coords="7,213.65,112.36,52.75,9.94" target="#b7">(Yang, 2002</ref><ref type="bibr" coords="7,274.01,112.36,23.70,9.94" target="#b8">(Yang, , 2004))</ref>, we found the normalized weighted sum formula to be most effective in combining fusion components that are dissimilar. The normalized weighted sum formula (equation 4) linearly combines the min-max normalized score of component i, (nSC i ) with fusion weight w i , to generate the fusion score. In the min-max normalization <ref type="bibr" coords="7,331.37,150.28,48.87,9.94" target="#b3">(Lee, 1997)</ref>, described in equation 5, S i (d) is the raw score of document d by component i, and min{S i } and max{S i } are the minimum and maximum scores by the component i.</p><formula xml:id="formula_3" coords="7,164.29,203.84,245.74,63.68">    k i i i d NS w d FS 1 )) ( ( ) ( (4) } min{ } max{ } min{ ) ( ) ( i i i i i S S S d S d NS    (5)</formula><p>In reranking, the original scores should be combined with fusion scores of reranking factors in a way that enables the documents with high reranking factors to float to the top without unduly influencing the existing document ranking. This reranking strategy can be expressed as</p><formula xml:id="formula_4" coords="7,110.34,336.23,299.68,31.16">      k i i i orig d NS w d NS d RS 1 )) ( ( * ) ( ) (  <label>(6)</label></formula><p>where NS orig (d) is the min-max normalized score of document d before reranking, and α and β are the weights that represent the estimated contributions of the original and combined reranking factor scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Dynamic Tuning</head><p>To optimize the reranking formulas, which involves determination of fusion weights (w i ) as well as original and reranking score weights (α and β), we implemented an interactive system tuning interface called Dynamic Tuning, which displays the effects of tuning parameter changes in real time to guide the human towards the system optimization state in a manner similar to bio-feedback. Dynamic Tuning, which is motivated by the idea of combining human intelligence, especially the pattern recognition ability, with the computational power of the machine, is implemented in a Web application that allows the human to examine not only the immediate effect of his/her system tuning but also the possible explanation of the tuning effect in the form of data patterns. By engaging in iterative dynamic tuning process that successively fine-tune the reranking parameters based on the cognitive analysis of immediate system feedback, system performance can be improved without resorting to an exhaustive evaluation of parameter combinations, which can not only be prohibitively resource intensive with numerous parameters but also fail to produce the optimal outcome due to its linear approach to factor combination.</p><p>Figure <ref type="figure" coords="7,121.80,591.96,5.52,9.94" target="#fig_1">2</ref> shows the dynamic tuning interface for optimizing the fusion formula that combines opinion reranking scores, and figure <ref type="figure" coords="7,204.87,604.56,5.52,9.94">3</ref> shows the dynamic tuning interface for optimizing the combination of polarity scores. In both interfaces, the effect of manual setting of the fusion formula weights are immediately displayed in terms of retrieval performance averaged over all topics as well as for the given topic. Individual reranking factor scores are also displayed for each document so that the human user may detect patterns that can be reflected in another cycle of tuning to beat the best performance (displayed in purple). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head><p>The effect of noise reduction is shown in Figure <ref type="figure" coords="8,293.60,689.28,4.14,9.94">4</ref>. Each bar in Figure <ref type="figure" coords="8,396.71,689.28,5.52,9.94">4</ref> represents the average gain in performance by noise reduction. In order to isolate the influence of noise reduction, we computed the performance differences of all system pairs whose only differences were noise reduction and averaged the results. The upward direction of the bars indicates the gain in performance by noise reduction, which is consistent across evaluation metrics as well as types of performance (i.e., topical, opinion, polarity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4. Noise Reduction Effect</head><p>As described in the methodology section, our approach to targeted opinion detection combined topic reranking to optimize the on-topic retrieval, opinion reranking to integrate opinion detection into on-topic retrieval, and fusion at various levels to affect the complementary combination of multiple methods as well as sources of evidence. Table <ref type="table" coords="9,218.16,308.47,5.52,9.94" target="#tab_0">1</ref> and<ref type="table" coords="9,248.86,308.47,5.52,9.94" target="#tab_1">2</ref> show the topic and opinion MAPs of the reranked results in comparison with the initial retrieval results (i.e. baseline). Topic MAP is the MAP computed using only the topical relevance (i.e., document is topically relevant), whereas opinion MAP is computed using the opinion relevance (i.e., document is topically relevant and opinionated).</p><p>Among the three main strategies, opinion reranking proved most useful (15% improvement in opinion MAP for short query, 11% improvement for long query over topic rerank results). Although topic reranking resulted in 16% improvement in topic MAP (short query) and 9% improvement (long query) over the initial retrieval results (Table <ref type="table" coords="9,177.52,396.91,3.96,9.94" target="#tab_0">1</ref>), it reduced the opinion MAP by 2.4% for short query and showed only 5.9% improvement for long query. In other words, topic reranking can hurt the opinion performance by over-boosting topically relevant documents to top ranks. , our The ability of opinion reranking method to compensate for the adverse effect of topic reranking is demonstrated in the short query column of Table <ref type="table" coords="9,388.04,625.08,4.14,9.94" target="#tab_1">2</ref>, where opinion reranking shows 15% improvement over topic reranking compared to 12% improvement over baseline. The fusion columns of the tables show only marginal improvements over the best non-fusion results (i.e., long query) except for the topic rerank row in Table <ref type="table" coords="9,200.62,663.00,4.14,9.94" target="#tab_1">2</ref>, which shows 7.3% improvement. This suggests the usefulness of fusion by illustrating its capacity to compensate for single method"s poor performance. Figure <ref type="figure" coords="9,122.06,688.32,4.14,9.94" target="#fig_2">5</ref>, which displays average performance improvements over baseline by topical (top chart) and opinion (bottom chart) relevance, shows the effect of topic reranking on the left side (r1-r0) and opinion reranking effect on the right side (r2-r0). The green bars (s0R1) indicate dynamic tuning results, while the red bars (s0R) represent results without dynamic tuning. The average performance improvement over baseline is computed by averaging the performance differences between all system pairs that are identical in all aspects except for the parameter in question (e.g., baseline vs. topic reranking with dynamic tuning). The fact that all the bars point upward shows that reranking is generally beneficial by all three measures (MAP, MRP, P@10). The markedly taller green bars on the right side suggests that dynamic tuning is quite effective in optimizing the opinion reranking formula. Opinion detection performances of TREC-2007 participants are shown in Figure <ref type="figure" coords="11,478.86,99.76,4.22,9.94" target="#fig_3">7</ref>. Each line, representing a TREC participant, starts on the left with the MAP of his/her baseline system and ends on the right with the MAP of the opinion detection system. The group of lines on the left shows participants whose opinion detection strategy had rather severely detrimental effects on performance, the middle lines show those with negligible opinion detection effects, and the lines on the right side show the ones with effective opinion detection methods. The fact that only one third of the TREC participants were able to devise effective opinion detection strategies reflects the difficulty associated with the targeted opinion detection task. Incidentally, the WIDIT performance line is the second from the top in the right side of Figure <ref type="figure" coords="11,516.70,188.32,4.14,9.94" target="#fig_3">7</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>Our experimental results showed the effectiveness of combining multiple complementary lexicon-based methods for opinion detection. The analysis of the results also revealed that Dynamic Tuning is a useful mechanism for fusion, and post-retrieval reranking is an effective way to integrate topical retrieval and opinion detection as well as to optimize the baseline result by considering factors not used in the initial retrieval stage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,160.82,551.85,290.24,9.94;2,77.25,222.29,458.95,326.85"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. WIDIT Blog Opinion Retrieval System Architecture</figDesc><graphic coords="2,77.25,222.29,458.95,326.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,149.78,326.47,312.63,9.94;8,73.50,72.00,468.25,251.75"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. WIDIT Dynamic Tuning Interface for Opinion Detection</figDesc><graphic coords="8,73.50,72.00,468.25,251.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,228.53,423.81,154.91,9.94;10,159.65,173.19,294.20,241.90"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Dynamic Tuning Effect</figDesc><graphic coords="10,159.65,173.19,294.20,241.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,171.14,406.87,269.93,9.94;11,154.50,224.94,304.05,179.20"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Opinion Detection Performances in TREC-2007</figDesc><graphic coords="11,154.50,224.94,304.05,179.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="9,73.50,115.95,467.20,127.40"><head></head><label></label><figDesc></figDesc><graphic coords="9,73.50,115.95,467.20,127.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,125.54,435.21,336.23,53.14"><head>Table 1 . Topic MAP</head><label>1</label><figDesc></figDesc><table coords="9,125.54,452.13,336.23,36.22"><row><cell></cell><cell>Short Query</cell><cell>Long Query</cell><cell>Fusion</cell></row><row><cell>Baseline</cell><cell>.3367</cell><cell>.3736</cell><cell>.3893 (+9.5%)</cell></row><row><cell>Topic Rerank</cell><cell>.3889 (+15.5%)</cell><cell>.4082 (+9.3%)</cell><cell>.4189 (+2.6%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,125.54,510.45,335.63,66.22"><head>Table 2 . Opinion MAP</head><label>2</label><figDesc></figDesc><table coords="9,125.54,527.37,335.63,49.30"><row><cell></cell><cell>Short Query</cell><cell>Long Query</cell><cell>Fusion</cell></row><row><cell>Baseline</cell><cell>.2640</cell><cell>.2817</cell><cell>.2900 (+2.9%)</cell></row><row><cell>Topic Rerank</cell><cell>.2579 (-2.4%)</cell><cell>.2983 (+5.9%)</cell><cell>.3305 (+7.3%)</cell></row><row><cell cols="2">Opinion Rerank .2959 (+14.7%)</cell><cell>.3303 (+10.7%)</cell><cell>.3343 (+1.2%)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,77.78,686.77,461.46,8.96;1,72.02,698.29,467.54,8.96;1,72.02,709.93,41.22,8.96"><p>Web Information Discovery Integrated Tool (WIDIT) Laboratory at the Indiana University School of Library and Information Science is a research lab that explores a fusion approach to information retrieval and knowledge discovery.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,77.78,682.57,439.31,7.24"><p>The simple plural remover was chosen to speed up indexing time and to minimize the overstemming effect of more aggressive stemmers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,76.58,692.16,369.39,7.24"><p>Acronym and abbreviation identification was based on simple pattern matching of punctuations and capitalizations.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,76.58,702.28,158.88,7.32;3,237.53,707.86,3.57,1.00;3,243.05,702.36,134.95,7.24"><p>"Padded" query string is a query string with up to k number of words in between query words.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,76.58,711.60,379.94,7.24"><p>Non-rel Match is used to suppress the document rankings, while other reranking factors are used to boost the rankings.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,72.02,556.29,467.85,9.94;11,90.02,568.89,438.77,9.94;11,90.02,581.61,43.17,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,313.24,556.29,226.64,9.94;11,90.02,568.89,32.83,9.94">Automatic combination of multiple ranked retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Bartell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,130.31,568.89,398.49,9.94;11,90.02,581.61,38.85,9.94">Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,72.02,598.20,465.25,9.94;11,90.02,610.92,142.83,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,225.23,598.20,147.05,9.94">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,382.25,598.20,155.02,9.94;11,90.02,610.92,95.53,9.94">Proceeding of the3rd Text Rerieval Conference (TREC-3)</title>
		<meeting>eeding of the3rd Text Rerieval Conference (TREC-3)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,72.02,627.60,451.56,9.94;11,90.02,640.20,161.94,9.94" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,295.98,627.60,223.09,9.94">Information retrieval: Data structures &amp; algorithms</title>
		<editor>Frakes, W. B., &amp; Baeza-Yates, R.</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,72.02,656.88,425.99,9.94;11,90.02,669.48,342.65,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,157.66,656.88,189.03,9.94">Analyses of multiple evidence combination</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,357.02,656.88,140.99,9.94;11,90.02,669.48,296.16,9.94">Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,74.42,420.92,9.94;12,90.02,87.04,435.31,9.94;12,90.02,99.76,213.87,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,245.02,74.42,247.92,9.94;12,90.02,87.04,136.28,9.94">Some simple approximations to the 2-Poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,233.00,87.04,292.33,9.94;12,90.02,99.76,167.41,9.94">Proceedings of the 17th ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17th ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,116.44,414.72,9.94;12,90.02,129.04,195.98,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,354.39,116.44,127.63,9.94">Learning subjective language</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,90.02,129.04,115.49,9.94">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="308" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,145.72,466.67,9.94;12,90.02,158.32,423.05,9.94;12,90.02,171.04,169.59,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,278.34,145.72,146.51,9.94">Identifying opinionated sentences</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,432.09,145.72,106.60,9.94;12,90.02,158.32,190.92,9.94">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics on Human Language Technology</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="33" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,187.60,468.14,9.94;12,90.02,200.32,218.79,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,148.42,187.60,279.03,9.94">Combining Text-and Link-based Retrieval Methods for Web IR</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,437.23,187.60,102.94,9.94;12,90.02,200.32,113.69,9.94">Proceedings of the 10th Text Rerieval Conference</title>
		<meeting>the 10th Text Rerieval Conference</meeting>
		<imprint>
			<date type="published" when="2001">2002. 2001</date>
			<biblScope unit="page" from="609" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,216.88,468.07,9.94;12,90.02,229.60,155.79,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,220.73,216.88,141.97,9.94">WIDIT in TREC2003 Web track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Albertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,371.61,216.88,168.49,9.94;12,90.02,229.60,108.26,9.94">Proceedings of the 12th Text Retrieval Conference (TREC2003)</title>
		<meeting>the 12th Text Retrieval Conference (TREC2003)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="328" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,246.28,465.76,9.94;12,90.02,258.91,156.77,9.94" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Valerio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m" coord="12,303.31,246.28,234.47,9.94;12,90.02,258.91,93.76,9.94">WIDIT in TREC 2006. Proceedings of the 15th Text Retrieval Conference</title>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2006">2007. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,72.02,275.59,467.24,9.94;12,90.02,288.19,423.65,9.94;12,90.02,300.91,60.33,9.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,442.70,275.59,96.57,9.94;12,90.02,288.19,190.51,9.94">WIDIT in TREC2004 Genomics, HARD, Robust, and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wead</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>La Rowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,290.20,288.19,223.47,9.94">Proceedings of the 13th Text Retrieval Conference</title>
		<meeting>the 13th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>TREC2004</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
