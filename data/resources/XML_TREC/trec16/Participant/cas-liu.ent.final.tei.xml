<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.90,58.00,376.06,16.65">Research on Enterprise Track of TREC 2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,125.40,103.10,68.36,11.10"><forename type="first">Huawei</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.37,103.10,70.90,11.10"><forename type="first">Guoyao</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.02,103.10,76.21,11.10"><forename type="first">Haiqiang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,369.97,103.10,39.16,11.10"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,417.31,103.10,69.30,11.10"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.90,58.00,376.06,16.65">Research on Enterprise Track of TREC 2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">736741E5003FB077FBEE7B73A1118D1E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We (ICT-CAS team) participated in the Enterprise Track of TREC 2007. This paper reports our experimental results on this track.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The goal of the Enterprise Track is to study the issues that arise when searching the documents of an enterprise (organization). It involves some new things, including new data and new tasks.</p><p>There are a variety of document types: web pages, news/email archives, document archives and many other document types. It is critical for enterprise track to utilize the particular characteristics of each document type appropriately.</p><p>Different from Enterprise Track 2005 and 2006, this year's enterprise track is explicitly divided into two tasks, document search task and expert search task. What's more, a new corpus is used instead of the W3C corpus adopted in the last two years' enterprise track. This new corpus is provided by CSIRO.</p><p>In last two year enterprise track, several models have been proposed to combat with expert search task. Among them, twostage language model <ref type="bibr" coords="1,141.27,419.60,10.51,8.10" target="#b1">[1]</ref> has been proved to be a successful model for expert search task. And many systems have been implemented with this model. This model consists of a document relevance model and a co-occurrence model. The document relevance model retrieves documents which are relevant to the query associated with expertise topic. Then, the co-occurrence model is used to find experts who are closely related to the expertise topic. Here, document is taken as a hidden variable, separating the query from the candidate experts. This year, our team's system adopts the framework of the twostage language model. Document search task and expert search task are addressed in this uniform framework. Firstly, documents are scored and ranked using BM25 retrieval model. Secondly, occurrence of each candidate expert is recognized and the score of each candidate expert is the aggregation of the score of all documents, which are relevant to the given query and contains more than one occurrence of this candidate expert.</p><p>The score for each document, produced by BM25 retrieval model, is used to rank the documents. And the ranked list of documents is submitted as the result of document search task. As for each topic, up to 1000 relevant documents are retrieved.</p><p>As to the expert search task, a ranked list of experts is submitted as the result for a given topic. Each list contains no more than 100 experts. The list is sorted according to the score of each expert. This report is organized as follows. Section 2 introduces the new things occurred in this year enterprise track. We discuss the query expansion and formulation in Section 3. Document search task are discussed in Section 4. Section 5 describes the expert search task. Section 6 concludes this report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">What's New in Enterprise Track 2007</head><p>Different from the last two year, there are two tasks in this year enterprise track. As stated in last section, document search task is explicitly divided from expert search task. Investigating whether the result of document search affects the result of expert search is an interesting problem. In addition, the topics are all from real users, including examples of "key pages" that should be retrieved. The judgments are also from real users.</p><p>As to expert search, no pre-defined list of candidate experts is provided. And for each topic, there are only a few experts (typically one or two).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Query Expansion and Formulation</head><p>A searcher's request on a topic is often complex and needs to be converted to queries for IR systems to process. For example, if topic is "sustainable agriculture", documents which are about "sustainable environment" are not so relevant. So, the query expansion and formulation is very important for IR systems.</p><p>A topic, provided by the organizer of enterprise track, consists of three fields, including title, narrative, key pages. The title field of a topic is typically used as the search query. However, by considering the narrative field, this query can often be expanded to form a number of more precise and informative queries leading to better search results. For an example, the title of the topic CE-001 is "Genetic Modification". If only the title field is used to form the query, the documents, which discuss biotechnology or GM and do not contain "genetic modification", are not retrieved. Examining the narrative field of this topic, we find that there are several other informative words or word pairs, including "gene technology", "biotechnology" and "GM".</p><p>The "key pages" field is for feedback runs and all our submitted runs are not feedback runs. So, we only use the title and narrative field of the topic to form the query.</p><p>The process of query expansion in our system is automatically completed. We simply delete all the stopwords in the narrative field and the remaining content are divided into several fragments. All this fragments are used to expand the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Document Search Task</head><p>For document search, systems will return ranked lists of documents from the CERC collection. Retrieved documents should tend to be authoritative pages such as project homepages and documents dedicated to the given topic, rather than pages that make passing mention of the topic.</p><p>The anchor texts on the hyperlink to a document are considered as the content of this document. In addition, the keywords in the meta field of a webpage (document) are also considered as the content of this document.</p><p>For our system, we adopt BM25 retrieval model, a well-known probabilistic model <ref type="bibr" coords="2,126.22,236.19,9.53,8.10" target="#b2">[3]</ref>.</p><p>Assume d is document belonging to the collection. We regard it as a vector</p><p>, where denotes the term frequency of </p><formula xml:id="formula_0" coords="2,69.49,306.25,224.64,15.01">d k d score ,<label>(1)</label></formula><p>where is the document frequency of term j df j , is the document length, is the average document length across the collection, and and are free parameters. The optimal values for and in CERC are respectively 1.5 and 0.3. Our team submits 4 runs for document search task. Table <ref type="table" coords="2,289.62,402.03,4.50,8.10" target="#tab_1">1</ref> describes the results of our four runs for document search task. We can see that the two runs based on BM25 retrieval model are better than the other two runs. The first and the second runs are based on BM25 retrieval model. The only difference is the query for each topic. The query for the first run are formed using only the title field of the topic, however, the query for the second run are based on both the title field and the narrative field of the topic.</p><p>In addition, we try to use PageRank <ref type="bibr" coords="2,191.81,643.35,10.51,8.10" target="#b3">[4]</ref> algorithm to re-rank the resulting ranked list of the second run. We choose the top 200 documents in the ranked list for each topic and construct directed graph, where the nodes are documents (web-pages) and the arcs are hyperlinks between them. We apply PageRank algorithm to the obtained graph with the parameter c=0.85. By re-ranking the top-200 documents, we obtain a new ranked list of documents for each topic. This is our third run for document search task.</p><p>The forth run are based on the second and the third runs. The score of the document in the forth run are based on the positions of this document in the second and third runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Expert Search Task 5.1 Expert Identity Recognition</head><p>In this year, there is not a list of candidate experts. We need find all the expert identities occurred in the document collection.</p><p>Email is regarded as the unique identity of an expert.</p><p>All the valid email addresses are in the format: firstname.lastname@csiro.au. However, several other email addresses should also be considered valid because of there are several sub-domains under the domain csiro.au, such as atnf.csiro.au, ento.csiro.au, cse.csiro.au and many other subdomains. If the username (the part before @ in the email address) of one email address is the same as that of another email address, these two email addresses are regarded being associated with the same person. For example, julie.carter@csiro.au, julie.carter@dwe.csiro.au and julie.carter@ento.csiro.au are associated with the same person. We try to find all the possible valid email addresses. We find all the occurrences of the symbol '@' and then judge whether this occurrence of symbol '@' is the component of an email address. By this method, we get lots of candidate email address, and then we filter the invalid email address. Finally, by incorporating the email addresses which have the same username, we get all the email addresses of candidate experts.</p><p>The real users in CSIRO provide total 152 email addresses as experts for all the 50 topics. Our expert identity recognition method recalls 129 of the 152 email addresses. The recall rate is about 85%.</p><p>After having got all the valid email addresses of candidate experts, we get the full name of candidate expert from her/his email addresses. For the example in last paragraph, the possible name for these email addresses is "Julie Carter". Other variety of expert names is also needed to be considered to improve the recall of the recognition. We use an automatic method to generate such variety of expert names. For the example used in this section, variety of names may include "J. Carter", "Ms. Carter", "Dr. Carter", "Prof. Carter", etc.</p><p>Up to now, we have got all the identifiers for each candidate experts, including email addresses, variety of expert names. We pre-process all the documents in the collection by replacing all the non-ASCII characters with spaces, removing HTML mark-up in web pages, replacing sequential spaces with a single space. Then we use the Aho-Corasick algorithm <ref type="bibr" coords="2,459.54,581.05,10.51,8.10" target="#b4">[5]</ref> to match these expert identifiers against the pre-processed documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Expert Search</head><p>For expert search, systems are required to return ranked lists of email addresses representing person. Our team submits 4 runs for expert search task. Table <ref type="table" coords="2,415.45,647.37,4.50,8.10" target="#tab_2">2</ref> shows the results for each run. The second run using two-stage language model is the best one. The forth run using the new method presented by us is in the second place.  As to the third run for expert search, we construct a profile for each candidate expert <ref type="bibr" coords="3,137.25,334.95,9.53,8.10" target="#b5">[6]</ref>. The profile of an expert is simply the concatenation of the documents in which this expert is mentioned. Then the rank of the expert is based on the score the corresponding profile. Given a query of a topic, the score of the profile are computed by BM25 retrieval model.</p><p>For the forth run, we try a new method. We construct a documentexpert graph from the mention relation between documents and experts. Given a query of a topic, we find all the relevant documents and construct a sub-graph from the complete document-expert graph. Then using HITS algorithm <ref type="bibr" coords="3,260.07,435.98,9.53,8.10" target="#b6">[7]</ref>, each document is assigned a hub-value and each expert is assigned a authority-value. Finally, a ranked list of experts is obtained according to the authority-value for each expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>This paper reports the experiments of our team on Enterprise Track 2007. We mainly design an expert search system based on the two-stage language model. The run based on two-stage language model is the best one in our four runs submitted. In addition, we try a new method based on HITS algorithm and the result is slightly worse than the run using two-stage language model. Most existing models focus on the relevance of expert given a topic. Only little attention is paid to the authority of the expert. Intuitively, the prior authority can be used to improve the effectiveness of existing models. Our team intends to explore how to obtain the knowledge of authority of expert as our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,54.00,277.23,11.03,8.10;2,136.08,261.99,3.06,8.26;2,123.00,261.99,2.30,8.26;2,111.06,261.99,2.30,8.26;2,100.13,261.99,3.06,8.26;2,107.94,266.88,2.68,4.82;2,131.04,266.88,3.27,4.82;2,126.42,261.99,4.59,8.26;2,103.44,261.99,4.59,8.26;2,85.62,261.99,4.59,8.26;2,113.64,260.93,9.18,11.92;2,93.18,259.03,5.03,11.24;2,178.56,267.07,1.46,4.73;2,172.38,262.23,4.50,8.10;2,71.58,277.23,222.53,8.10;2,54.01,290.26,196.39,8.10;2,244.80,320.41,4.47,8.05;2,242.58,320.41,2.24,8.05;2,238.14,320.41,4.47,8.05;2,252.72,306.25,4.47,8.05;2,250.50,306.25,2.24,8.05;2,246.06,306.25,4.47,8.05;2,196.79,313.21,11.43,8.05;2,174.29,324.78,2.98,8.05;2,139.38,324.78,2.98,8.05;2,122.82,324.78,4.47,8.05;2,117.72,324.78,5.96,8.05;2,157.43,306.25,2.98,8.05;2,153.71,306.25,4.47,8.05;2,135.83,306.25,2.98,8.05;2,97.25,313.21,2.98,8.05;2,88.61,313.21,2.98,8.05;2,114.42,329.56,2.61,4.70;2,142.80,311.01,2.61,4.70;2,231.48,317.53,4.90,10.95;2,239.34,303.37,4.90,10.95;2,219.60,303.37,4.90,10.95;2,179.05,321.90,4.90,10.95;2,144.13,321.90,4.90,10.95;2,128.35,321.90,4.90,10.95;2,147.85,303.37,4.90,10.95;2,102.49,310.33,4.90,10.95;2,226.92,325.18,1.45,4.70;2,234.84,311.02,1.45,4.70;2,191.88,329.56,1.45,4.70;2,166.62,311.02,1.45,4.70;2,218.46,320.41,6.96,8.05;2,226.32,306.25,6.96,8.05;2,210.96,306.25,5.97,8.05;2,185.94,324.78,4.47,8.05;2,157.56,331.74,15.41,8.05;2,161.70,319.20,6.96,8.05;2,150.73,324.78,4.47,8.05;2,134.77,324.78,4.47,8.05;2,110.65,324.78,3.97,8.05"><head></head><label></label><figDesc>term in d and V is the total number of terms in the vocabulary. The score of document d is computed by 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,102.36,227.22,9.48,16.30;3,115.08,237.08,3.69,6.34;3,156.78,229.64,4.86,10.86;3,94.98,229.64,4.86,10.86;3,118.74,238.74,3.74,4.66;3,112.20,238.74,2.59,4.66;3,254.34,232.50,4.44,7.99;3,246.96,232.50,3.94,7.99;3,212.04,232.50,31.55,7.99;3,163.80,232.50,47.83,7.99;3,146.95,232.50,4.44,7.99;3,124.20,232.50,19.23,7.99;3,85.39,232.50,3.94,7.99;3,62.83,232.50,19.23,7.99;3,259.87,232.50,2.96,7.99;3,250.87,232.50,2.22,7.99;3,243.85,232.50,2.96,7.99;3,152.47,232.50,2.96,7.99;3,143.71,232.50,2.96,7.99;3,89.46,232.50,2.96,7.99;3,82.33,232.50,2.96,7.99;3,143.28,269.31,4.50,8.10;3,54.00,286.71,240.03,8.10;3,54.00,297.27,240.16,8.10;3,54.00,307.83,192.78,8.10"><head>d</head><label></label><figDesc>The first and second run for expert search task are respectively based on the first and second run for document search task. The experts' score in these two runs are calculated by (2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,70.68,463.05,206.87,101.04"><head>Table 1 . Results of each run for document search task</head><label>1</label><figDesc></figDesc><table coords="2,72.18,482.37,203.63,81.72"><row><cell>Runs</cell><cell>MAP</cell><cell>MRR</cell><cell>Bpref</cell><cell>Recall@1000</cell></row><row><cell cols="4">DocRun01 0.3970 0.8384 0.3963</cell><cell>0.8580</cell></row><row><cell cols="4">DocRun02 0.4048 0.8158 0.4013</cell><cell>0.8322</cell></row><row><cell cols="4">DocRun03 0.1746 0.3493 0.2276</cell><cell>0.8322</cell></row><row><cell cols="4">DocRun04 0.3316 0.8014 0.3263</cell><cell>0.8322</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,54.00,56.43,240.14,220.98"><head>Table 2 . Results for each run for expert search task</head><label>2</label><figDesc></figDesc><table coords="3,54.00,75.75,240.14,201.66"><row><cell>Runs</cell><cell>MAP</cell><cell>MRR</cell><cell>Bpref</cell><cell>Recall@100</cell></row><row><cell cols="4">ExpertRun01 0.3066 0.4695 0.6784</cell><cell>0.6579</cell></row><row><cell cols="4">ExpertRun02 0.3689 0.5142 0.6851</cell><cell>0.6645</cell></row><row><cell cols="4">ExpertRun03 0.0146 0.0140 0.6844</cell><cell>0.6513</cell></row><row><cell cols="4">ExpertRun04 0.3433 0.5077 0.6884</cell><cell>0.6645</cell></row><row><cell cols="5">In the framework of two-stage language model, the score of</cell></row><row><cell cols="6">expert is based on the score of documents in which the expert is</cell></row><row><cell cols="6">mentioned. When we have obtained the score of all the documents</cell></row><row><cell cols="6">given a query of a topic, the score of expert e can be calculated by</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>,</cell><cell>(2)</cell></row><row><cell cols="6">where D is the set of documents in the collection CERC, and</cell></row><row><cell cols="6">NumberOfOccurrence(e, d) denotes how many times expert e is</cell></row><row><cell cols="2">mentioned in document .</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">ACKNOWLEDGMENTS</head><p>We thank to the member of social computing and P2P group in the <rs type="institution">Institute of Computing Technology, Chinese Academy of Sciences</rs>.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="3,322.38,238.58,92.18,10.80" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.88,252.63,198.17,8.10;3,335.88,263.19,194.18,8.10;3,335.88,273.75,43.33,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,463.30,252.63,70.75,8.10;3,335.88,263.19,146.68,8.10">Research on Expert Search at Enterprise Track of TREC2005</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,499.47,263.19,30.59,8.10;3,335.88,273.75,38.52,8.10">Proc. Of TREC</title>
		<meeting>Of TREC</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.88,305.07,200.16,8.10;3,335.88,315.63,192.36,8.10;3,335.88,326.19,206.62,8.10;3,335.88,336.74,54.31,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,485.25,305.07,50.79,8.10;3,335.88,315.63,139.18,8.10">Simple BM25 Extension to Multiple Weighted Fields</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,490.63,315.63,37.61,8.10;3,335.88,326.19,206.62,8.10;3,335.88,336.74,27.23,8.10">Thirteenth Conference on Information and Knowledge Management (CIKM)</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.88,352.35,216.03,8.10;3,335.88,362.91,211.28,8.10;3,335.88,373.47,73.78,8.10" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="3,499.02,352.35,52.89,8.10;3,335.88,362.91,139.98,8.10">The PageRank citation ranking: bring order to the web</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="3,335.88,389.07,218.37,8.10;3,335.88,399.63,219.32,8.10;3,335.88,410.19,70.18,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,448.18,389.07,106.08,8.10;3,335.88,399.63,94.63,8.10">Efficient string matching: An aid to bibliographic search</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Corasick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,436.41,399.63,107.49,8.10">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="333" to="340" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.88,425.79,221.00,8.10;3,335.88,436.35,201.46,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,520.58,425.79,36.30,8.10;3,335.88,436.35,106.97,8.10">THUIR at TREC 2005: Enterprise Track</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,458.83,436.35,55.92,8.10">Proc. Of TREC</title>
		<meeting>Of TREC</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.88,451.95,187.24,8.10;3,335.88,462.51,204.46,8.10;3,335.88,473.07,179.48,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,384.56,451.95,138.56,8.10;3,335.88,462.51,43.80,8.10">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,395.74,462.51,144.60,8.10;3,335.88,473.07,153.03,8.10">Proceedings of the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
