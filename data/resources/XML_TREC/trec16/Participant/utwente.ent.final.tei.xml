<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,66.76,72.36,476.21,16.84;1,56.71,92.29,496.31,16.84">University of Twente at the TREC 2007 Enterprise Track: Modeling relevance propagation for the expert search task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,173.32,138.01,84.79,11.06"><forename type="first">Pavel</forename><surname>Serdyukov</surname></persName>
							<email>serdyukovpv@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Database Group</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>PO Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.28,138.01,73.22,11.06"><forename type="first">Henning</forename><surname>Rode</surname></persName>
							<email>rodeh@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Database Group</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>PO Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,350.16,138.01,86.23,11.06"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
							<email>hiemstra@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Database Group</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>PO Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,66.76,72.36,476.21,16.84;1,56.71,92.29,496.31,16.84">University of Twente at the TREC 2007 Enterprise Track: Modeling relevance propagation for the expert search task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">11227C96A581AF7318F593D594BF9D07</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes several approaches which we used for the expert search task of the TREC 2007 Enterprise track. We studied several methods of relevance propagation from documents to related candidate experts. Instead of onestep propagation from documents to directly related candidates, used by many systems in the previous years, we do not limit the relevance flow and disseminate it further through mutual documents-candidates connections. We model relevance propagation using random walk principles, or in formal terms, discrete Markov processes. We experiment with infinite and finite number of propagation steps. We also demonstrate how additional information, namely hyperlinks among documents, organizational structure of the enterprise and relevance feedback may be utilized by the presented techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This is the third year of TREC 2007 Enterprise Track and the first year the University of Twente (Database group) participates in it. We submitted results only for the expert search task, the task of finding knowledgeable persons in the organization in response to the user query.</p><p>Most popular approaches to expert finding basically consist of two stages. They calculate some score, or the probability of a document to be relevant to the query, and then represent a candidate's expertise score as a sum of scores of related documents. For example, one of these methods, described in works by Balog et al. <ref type="bibr" coords="1,195.76,512.35,9.22,7.86" target="#b1">[1]</ref>, follows the language modeling principle of IR and considers the expertise level of the candidate expert e to be calculated as:</p><p>Expertise(e) = D∈R P (D|Q)P (e|D) <ref type="bibr" coords="1,281.13,560.05,11.78,7.86" target="#b1">(1)</ref> where if P (D) is distributed unform, then P (D|Q) ≈ P (Q|D), what is the probability of the document D to generate the query Q. This probability is the measure of document relevance according to LM-based IR. P (e|D) is the probability of association between the candidate and the document, what may depend on various factors: on the part of the document where a candidate mentioned, on our confidence that the mentioning of some person matches a specific candidate etc.</p><p>If we look at the Formula 1 we may notice that it mathematically describes a probabilistic process, in which a user selects a document among the ranked ones with some probability, reads the document, finds all candidate experts men-tioned in it and makes an inquiry to one of them with some probability. The selection of a document depends on its rank, or probabilistic score, and the following selection of a candidate depends on the level of its benefit/responsibility to the content of the document. We may look at this process as at one-step relevance probability propagation from documents to related candidate experts.</p><p>However, in reality its not likely that reading only one document and consulting only one person is enough to completely satisfy a personal information need in the enterprise. We may imagine that a user is willing to question several people and hence to find more contacts in the ranked documents by reading more of them. We may also find natural that a user goes over the ranked documents, not only coming back to them again and again, but following hyperlinks among documents. The discovery of new experts may be possible not through documents only, but also with the help of candidates the user is in contact with already: for example, they can send the user to their colleagues in the same department who expectedly possess similar expertise.</p><p>In our methods described in the next section we try to overcome the limitations of the one-step relevance propagation. We show how we model the process of collecting the expertise in the enterprise representing it as a multi-step or a non-stop process of consulting with both kinds of possible knowledge sources: documents and people. The rest of the paper contains our experimental results and the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELEVANCE PROPAGATION AS A RAN-DOM WALK</head><p>Our main goal in this work was to propagate the relevance coming from documents not only to immediate candidate neighbors, but further, through consequent connections in document-candidates graph, toward candidates and documents connected to starting nodes indirectly. We consider that the process of finding a relevant expert can not be modeled only as a one-step move from the ranked documents to the related persons, as described in Section 1. We present two kinds of random walk models: with finite and infinite number of steps. We consider that the probability of being in the specific candidate's state at the end of the walk reflects the personal expertise of this candidate. Obviously, if a candidate is very central (i.e. is mentioned in many documents, which are in turn contain references to many candidates and so on) then the probability to end up with her will be higher.</p><p>However, in both methods we assume that during the walk a user always has some strategy which allows him to find ex-perts relevant exactly to his query, but not just authoritative in the organization. This means that a user would always prefer not to move too far away from the ranked documents and/or to return to them regularly, taking a document from the ranked list again and starting a new walk. Now we describe our two random walk models implementing this strategy in two different ways.</p><p>There are some probabilities in formula 1 which we also use in our work. The probability of query to be generated by the document language model is calculated as:</p><formula xml:id="formula_0" coords="2,127.37,169.36,165.54,17.80">P (Q|D) = q∈Q P (q|D),<label>(2)</label></formula><formula xml:id="formula_1" coords="2,80.21,199.51,212.69,22.41">P (q|D) = (1 -λG) tf (q, D) |D| + λG D tf (q, D) D |D|<label>(3)</label></formula><p>where tf (q, D) is a term frequency of q in the document D, |D| is the document length and λG is a Jelinek-Mercer smoothing parameter -the probability of a term to be generated from the global language model. In all our experiments it is set to 0.5, what is standard in retrieval tasks.</p><p>In our work, we also exploit the probabilities of selection a document given a person and of selection a person given a document: </p><formula xml:id="formula_2" coords="2,81.43,313.05,66.78,13.67">P (D|e) = a(e,</formula><p>where a(e, D) is the non-normalized association score between the candidate e and the document D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">K-step random walk</head><p>In this approach, we imagine that a user after getting the list of ranked documents with the list of related candidates attached:</p><p>• selects one document with a probability proportional to its probability of relevance,</p><p>• makes K-steps of two kinds: if a user is in the document node, then one of related candidates is selected, or if a user is in the candidate node, then one of documents related to this candidate is selected.</p><p>If we consider this process as a walk over a bipartite graph with documents and candidates layers of nodes, than this becomes a process of moving to a node from an opposite layer at each step, starting from some node in a document layer.</p><p>We consider this walk as finite, so we believe in this case that at some point a user is tired or satisfied with some candidate and stops their search process. So, we iteratively calculate the probability that a random surfer will end up in a certain candidate starting the walk from the one of ranked documents, using the following formulas:</p><formula xml:id="formula_4" coords="2,100.74,611.78,192.16,21.91">P0(D) = P (Q|D) D∈R P (Q|D) , P0(e) = 0,<label>(5)</label></formula><formula xml:id="formula_5" coords="2,113.75,647.10,179.15,17.80">P k (D) = e→D P (D|e)P k-1 (e),<label>(6)</label></formula><formula xml:id="formula_6" coords="2,115.03,677.67,177.87,17.80">P k (e) = D→e P (e|D)P k-1 (D)<label>(7)</label></formula><p>The probability of starting this walk from a specific document is proportional to its probability to be relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Infinite random walk</head><p>In our second approach, we assume that the walk process has an infinite number of steps. Stationary probabilities of ending up in the candidate nodes are considered estimators of their expertise. However, the stationary distribution of a discrete Markov process which we use in our modeling does not depend on the initial distribution over states. In other words, the more steps the user does, the less important that the walk was started from certain document nodes and hence their relevance has much less influence on the selection of candidates. In the case of a non-stop walk along the paths with infinite number of nodes, the relevance appearing from ranked documents is propagated so often that it just gets spread equally over all nodes in the graph at some step in the future.</p><p>In order to retain the importance for a candidate to stay in proximity to relevant documents, we introduce the possibility to return regularly to the documents from any node of the graph and start the walk through mutual documentscandidates links again. We consider that the probability of jumping to the specific document equals its probability to be relevant, what makes candidates which are situated closer to them to be visited more often during a normal walk. The following formulas are used for iterations until convergence:</p><formula xml:id="formula_7" coords="2,322.05,324.88,233.87,32.90">P k (D) = λ P (Q|D) D∈R P (Q|D) + (1 -λ) e→D P (D|e)P k-1 (e),<label>(8)</label></formula><formula xml:id="formula_8" coords="2,378.05,368.55,177.87,17.80">P k (e) = D→e P (e|D)P k-1 (D)<label>(9)</label></formula><p>λ is the probability that at any step the user decides to make a jump and not to follow outgoing links anymore. The described Markov process is stochastic and irreducible (since each candidate and document is reachable due to introduced jumps to documents from any node) and hence has the stationary distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Adding organizational and document links</head><p>Our approaches are graph-based in nature. Usually, for this family of algorithms, the introduction of the new information into the analysis often comes to adding new discovered links among analyzed entities. This often helps to model their mutual relations and directions of influence better. The scenario of searching for expertise in the enterprise may include not only the moving from relevant documents to the candidates found in them, but also along documentdocument and candidate-candidate connections. In the case of the CSIRO collection, we can extract both of these types. Most CSIRO documents are made for web publication and hence often refer to each other. Candidates in turn often belong to the specific department in the CSIRO institute, whose name is usually the part of their email address. For example, the email address Alan.Smith@ento.csiro.au shows that Alan Smith works at the CSIRO Entomology research department. We inter-link all candidates in the same department and also take into account the hyperlinks among documents. After adding these new transitions to our documents-candidates graph, we have the following formulas for the Infinite Random Walk iterations: </p><formula xml:id="formula_9" coords="3,281.61,160.96,11.29,6.99">)<label>11</label></formula><p>where µD is the probability of following document-document connections being in the document node, µe is the probability of following candidate-candidate connections being in the candidate node. The new transition probabilities are calculated as:</p><formula xml:id="formula_10" coords="3,101.92,231.11,190.99,8.68">P (D|D ) = 1/N D , P (e|e ) = 1/N e ,<label>(12)</label></formula><p>where N D is the number of outgoing document links from the document D and N e is the number of outgoing candidate links from the candidate e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Adding relevance feedback</head><p>The useful feature of the relevance propagation approaches is that user feedback easily fits their framework. While in the absence of feedback information the relevance appears solely from the documents content, in the case of feedback it comes into the system also directly from user and shared among positively judged documents. Considering that, we utilized the list of relevant documents for a query provided by TREC in a simple way. We found the document among the ranked ones with the highest score and gave twice higher score to the feedback documents assuming that this relevance probability will be propagated to the adjacent candidates and further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELATED WORK</head><p>The presented belong to the family of documentcentric expert finding methods. They consider that the best estimator for the candidates expertise is the aggregated relevance of related documents <ref type="bibr" coords="3,163.93,491.51,9.73,7.86" target="#b1">[1,</ref><ref type="bibr" coords="3,176.22,491.51,7.17,7.86" target="#b9">9]</ref> or of surrounding text windows around candidate mentionings in these documents <ref type="bibr" coords="3,283.17,501.97,9.73,7.86" target="#b3">[3,</ref><ref type="bibr" coords="3,53.80,512.43,6.49,7.86" target="#b8">8]</ref>. Some document-centric methods already utilized the social network built using links among persons extracted from top documents. Campbell et al. <ref type="bibr" coords="3,196.89,533.35,9.73,7.86" target="#b2">[2]</ref> proposed the use of HITS algorithm <ref type="bibr" coords="3,120.97,543.81,9.73,7.86">[6]</ref> which performed better than just ranking by candidate's in-degree (related documents number). However, Chen et al. <ref type="bibr" coords="3,141.83,564.73,9.73,7.86" target="#b4">[4]</ref> found that a document-centric approach is still better than HITS based only ranking.</p><p>Markov chains are widely used in IR, mostly as variations of Google's Pagerank <ref type="bibr" coords="3,144.24,596.12,9.22,7.86" target="#b7">[7]</ref>. Some of them use strategies for the propagation of document relevance similar to ours. Jeh and Widom presented the Personalized Pagerank algorithm where random surfer jumped more likely to the documents which user initially preferred <ref type="bibr" coords="3,171.56,637.96,9.22,7.86" target="#b5">[5]</ref>. The approach by Richardson and Domingos makes a random, but "intelligent" surfer not only to follow hyperlinks, but also to move always in the direction of more relevant documents <ref type="bibr" coords="3,227.91,669.34,13.52,7.86" target="#b10">[10]</ref>. The propagation of item preference among similar users is modeled with discrete K-step Markov process for collaborative recommendation by Song et al. <ref type="bibr" coords="3,171.55,700.72,13.52,7.86" target="#b11">[11]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head><p>The CSIRO collection was indexed using Snowball stemmer at the text parsing stage. This year participants were not given a list of candidates, but just a structural template of their email addresses helping to recognize them in the documents. For the purpose of finding candidate experts, we extracted all emails from the collection with csiro.au domain and firstname.lastname-like first part. We also made an automatic match of emails with the same first part, but with different subdomains to one candidate identifier, found csiro.au email address without subdomains and the same firstname.lastname part. For example: Alan.Smith@cmis.csiro.au, Alan.Smith@ento.csiro.au → Alan.Smith@csiro.au. If the email address without subdomains did not exist in the collection for the specific person, it was made up. We also had a list of email addresses to be banned which were not personal, but organizational addresses (e.g. publishing.photos@csiro.au). Documents were retrieved using language model-based ranking function (see <ref type="bibr" coords="3,386.52,352.27,43.33,7.86">Formula 2)</ref>. For the analysis we took only top-K ranked documents.</p><p>In the experiments whose results we submitted to TREC, we retrieved 1500 documents since for the previous TREC testbeds, the number of retrieved documents necessary for the maximum performance varied from 1000 to 8000. We set the jumping probability λ to 0.01, µe and µD were both set to 0.1, the association scores a(e, D) used in formulas 4 were set to 1.0. The number of steps in K-Step Random Walk was 5. In total, we submitted 4 runs:</p><formula xml:id="formula_11" coords="3,330.14,466.89,196.88,7.89">• qorwkstep: K-Step Random Walk algorithm,</formula><p>• qorw: Infinite Random Walk algorithm,</p><p>• qorwnewlinks: Infinite Random Walk algorithm with inter-document and organizational links added (µe, µD &gt; 0),</p><p>• feedbackrun: Infinite Random Walk algorithm with the introduced feedback information.</p><p>Further we present the official results and the results of our successive experiments for the two main measures: the Mean Average Precision (MAP) and the Mean Reciprocal Rank (MRR).</p><p>We see in Table <ref type="table" coords="3,391.55,617.04,4.61,7.86" target="#tab_0">1</ref> that all algorithms used to produce the official runs showed similar performance, but the infinite random walk with and without additional links was slightly better. Adding new links did not improve MAP significantly, but MRR got more visible improvement.</p><p>However, after the submission and receiving results and relevance judgments from TREC, we continued our experiments. At first, we made an important observation: many candidates mentionings in the corpus are not accompanied with email addresses. If we take the firstname.lastname part of all extracted emails and additionally try to detect candidates in documents using these names (with a space instead of a dot in the middle), we find much more occurrences of the candidates in the collection. This improvement of candidates recognition tremendously influenced the overall performance (see Table <ref type="table" coords="4,150.41,109.94,3.58,7.86">2</ref>). We also discovered that the best number of documents retrieved is much smaller than that we used in our TREC submission and that was optimal for the previous collection. We demonstrate the performance of the baseline method described in Section 1 (which is also the K-Step random walk with 1 step) for the different numbers of retrieved documents in Figure <ref type="figure" coords="4,92.51,365.98,3.58,7.86" target="#fig_2">1</ref>. Besides the average increase of the performance due to using full names in candidates recognition, we also see that it is better to retrieve just 50 documents. Such a decrease in performance with retrieval of each next document can be explained by several reasons for the CSIRO collection. At first, this year there are only few experts per query and therefore they are probably so authoritative in the organization that all appear in the top most relevant documents. At second, since the list of candidates is not predefined, we get more and more candidates competing to be ranked higher while retrieving more documents. This means that it becomes much harder to distinguish among them, especially because the expertise of the ones found in many lower-ranked documents is apparently supported by just the amount and not by the quality of expertise evidence.</p><p>We repeated all experiments that we made for the TREC submission for all tested methods with 50 retrieved documents and with the additional candidates recognition using full names. We see in Table <ref type="table" coords="4,167.98,564.73,4.61,7.86">2</ref> that all methods appeared to be better than the baseline method, especially ones based on infinite random walk. We also see that the K-Step Random Walk only slightly outperforms the baseline method and adding new links also gives not so much improvement to the Infinite Random Walk method. However, these methods are dependent on more parameters and hence are more sensitive to their proper setup. So, we show further that with the tuned settings, these methods become much more powerful.</p><p>We continue by experimenting with different numbers of steps for K-step Random Walk. As we see in Figure <ref type="figure" coords="4,258.25,679.80,3.58,7.86" target="#fig_2">1</ref>, the K-Step Random Walk algorithm reaches its maximum performance (M AP = 0.382) after making 15 steps. Moreover, after making about 50 steps it starts to show a very stable be- In the follow-up experiments shown in Figure <ref type="figure" coords="4,518.14,337.92,4.61,7.86">2</ref> we test different values for µe and µD. We discover that adding links among documents does not influence the performance of the Infinite Random Walk positively. However, introducing links among candidates shows small, but noticeable improvement with a proper setup of µe. The ability to efficiently use the feedback information is very important for a modern IR system. We present a performance of all methods with the same parameter set which we used for TREC submission and with incorporated document relevance feedback in Table <ref type="table" coords="4,453.55,613.02,3.58,7.86" target="#tab_2">3</ref>.</p><p>We see that since the task became much easier with the presence of feedback, it is harder to distinguish between methods. However, all of them are slightly better than the baseline and especially the performance of the K-Step Random Walk algorithm and the Infinite Random Walk with additional links. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>We described a number of approaches for relevance propagation in the documents-candidates network for the expert search task. We used two kinds of discrete Markov processes (random walks) for the modeling. They both appeared to be better than a classic approach with one-step relevance propagation. We also showed how to utilize the additional information: hyperlinks among documents, organizational structure of the enterprise and the user feedback.</p><p>In the future, it would be interesting to continue managing relevance flow among documents and candidates. It is probably possible to obtain some candidates priors and hence let a user make random jumps not only to documents. Also, we may allow user not only to jump, but also to walk in the direction of more relevant documents or candidates with a higher prior.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,149.74,313.05,11.44,7.86;2,133.67,329.73,5.97,5.24;2,141.86,324.94,28.28,7.86;2,171.34,318.86,42.85,7.86;2,225.59,313.05,28.28,7.86;2,227.68,329.73,3.52,5.24;2,233.23,324.94,28.28,7.86;2,262.71,318.86,2.56,7.86"><head></head><label></label><figDesc>D) D a(e, D) , P (e|D) = a(e, D) e a(e, D) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,53.80,81.54,39.94,8.01;3,108.70,75.99,29.33,6.99;3,103.88,87.51,47.91,9.09;3,152.98,81.54,61.39,7.94;3,215.78,92.70,16.79,5.24;3,234.18,81.54,63.05,8.01;3,114.62,114.49,17.65,7.94;3,134.37,126.04,22.13,5.24;3,158.10,114.49,73.98,8.01;3,277.85,114.49,15.06,6.99;3,53.80,142.80,60.68,8.01;3,115.89,153.96,16.99,5.24;3,134.29,142.80,77.32,8.01;3,213.52,154.36,17.04,5.24;3,231.97,142.80,60.93,8.01;3,277.85,160.96,3.76,6.99"><head>P</head><label></label><figDesc>k (D) = λ P (Q|D) D∈R P (Q|D) +(1-λ)((1-µ D ) e→D P (D|e)P k-1 (e)+ +µ D D →D P (D|D )P k-1 (D )), (10) P k (e) = (1 -µe) D→e P (e|D)P k-1 (D) + µe e →e P (e|e )P k-1 (e ), (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,53.80,258.13,239.11,7.89;4,53.80,268.59,239.10,7.89;4,53.80,279.05,28.74,7.89"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Experiments with different numbers of retrieved documents and one-step relevance propagation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,323.02,549.73,226.00,7.89"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Experiments with values for µe and µD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,316.81,55.03,239.10,85.84"><head>Table 1 :</head><label>1</label><figDesc>TREC 2007 Expert search official results, candidates recognition with email-addresses only, 1500 documents retrieved</figDesc><table coords="3,377.12,55.03,118.49,44.45"><row><cell></cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>qorwkstep</cell><cell cols="2">0.1441 0.2250</cell></row><row><cell>qorw</cell><cell cols="2">0.1463 0.2378</cell></row><row><cell cols="3">qorwnewlinks 0.1481 0.2478</cell></row><row><cell>feedbackrun</cell><cell cols="2">0.2371 0.3517</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,53.80,55.03,239.10,87.63"><head>Table 3 :</head><label>3</label><figDesc>TREC 2007 Expert search unofficial results with candidates recognition by full names and 50 retrieved documents + using relevance feedback</figDesc><table coords="5,109.99,55.03,126.72,44.45"><row><cell></cell><cell>MAP</cell><cell>MRR</cell></row><row><cell cols="3">qorwkstep, k=1 0.4401 0.5720</cell></row><row><cell cols="3">qorwkstep, k=5 0.4528 0.5840</cell></row><row><cell>qorw</cell><cell cols="2">0.4409 0.5782</cell></row><row><cell>qorwnewlinks</cell><cell cols="2">0.4472 0.5838</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,58.28,344.59,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,359.01,198.17,7.86;5,72.62,369.47,202.22,7.86;5,72.62,379.93,171.49,7.86;5,72.62,390.39,220.22,7.86;5,72.62,400.85,203.74,7.86;5,72.62,411.31,20.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,242.48,359.01,28.30,7.86;5,72.62,369.47,186.56,7.86">Formal models for expert finding in enterprise corpora</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.62,379.93,171.49,7.86;5,72.62,390.39,220.22,7.86;5,72.62,400.85,146.38,7.86">SIGIR &apos;06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,422.77,214.77,7.86;5,72.62,433.23,212.78,7.86;5,72.62,443.69,216.35,7.86;5,72.62,454.15,167.27,7.86;5,72.62,464.61,205.77,7.86;5,72.62,475.07,72.69,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,72.62,433.23,208.29,7.86">Expertise identification using email communications</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">P</forename><surname>Maglio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cozzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,84.13,443.69,204.83,7.86;5,72.62,454.15,167.27,7.86;5,72.62,464.61,48.30,7.86">CIKM &apos;03: Proceedings of the twelfth international conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="528" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,486.53,217.30,7.86;5,72.62,496.99,215.57,7.86;5,72.62,507.45,220.28,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,212.63,486.53,77.28,7.86;5,72.62,496.99,150.90,7.86">Research on expert search at enterprise track of trec 2005</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,242.30,496.99,45.88,7.86;5,72.62,507.45,192.13,7.86">Proceedings of 14th Text Retrieval Conference (TREC 2005)</title>
		<meeting>14th Text Retrieval Conference (TREC 2005)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,518.91,181.37,7.86;5,72.62,529.37,191.81,7.86;5,72.62,539.83,187.75,7.86;5,72.62,550.29,192.00,7.86;5,72.62,560.75,171.57,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,116.39,529.37,148.03,7.86;5,72.62,539.83,187.75,7.86;5,72.62,550.29,55.31,7.86">Social Network Structure behind the Mailing Lists: ICT-IIIS at TREC 2006 Expert Finding Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">X S T</forename><surname>Haiqiang Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,146.74,550.29,117.88,7.86;5,72.62,560.75,143.31,7.86">Proceeddings of the 15th Text REtrieval Conference (TREC 2006)</title>
		<meeting>eeddings of the 15th Text REtrieval Conference (TREC 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,572.21,184.47,7.86;5,72.62,582.67,219.13,7.86;5,72.62,593.13,214.69,7.86;5,72.62,603.59,192.97,7.86;5,72.62,614.05,200.19,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,165.86,572.21,91.22,7.86;5,72.62,582.67,111.49,7.86">Simrank: a measure of structural-context similarity</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,202.31,582.67,89.43,7.86;5,72.62,593.13,214.69,7.86;5,72.62,603.59,163.50,7.86">KDD &apos;02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="538" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,625.51,173.86,7.86;5,72.62,635.97,201.90,7.86;5,72.62,646.43,20.99,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,141.63,625.51,104.85,7.86;5,72.62,635.97,98.07,7.86">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,178.14,635.97,28.95,7.86">J. ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.62,657.89,165.93,7.86;5,72.62,668.35,183.10,7.86;5,72.62,678.81,216.31,7.86;5,72.62,689.27,67.14,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,130.23,668.35,125.48,7.86;5,72.62,678.81,102.66,7.86">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sergey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="5,72.62,700.73,205.14,7.86;5,72.62,711.19,177.85,7.86;5,335.63,57.64,207.05,7.86;5,335.63,68.10,82.40,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,72.62,711.19,162.20,7.86">Window-based Enterprise Expert Search</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Macfarlane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,335.63,57.64,207.05,7.86;5,335.63,68.10,54.14,7.86">Proceeddings of the 15th Text REtrieval Conference (TREC 2006)</title>
		<meeting>eeddings of the 15th Text REtrieval Conference (TREC 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.63,79.55,204.65,7.86;5,335.63,90.02,211.93,7.86;5,335.63,100.48,199.08,7.86;5,335.63,110.94,179.15,7.86;5,335.63,121.40,205.03,7.86;5,335.63,131.86,116.71,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,451.39,79.55,88.90,7.86;5,335.63,90.02,211.93,7.86;5,335.63,100.48,15.40,7.86">Voting for candidates: adapting data fusion techniques for an expert search task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,369.47,100.48,165.24,7.86;5,335.63,110.94,179.15,7.86;5,335.63,121.40,91.59,7.86">CIKM &apos;06: Proceedings of the 15th ACM international conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.63,143.32,195.58,7.86;5,335.63,153.78,212.26,7.86;5,335.63,164.24,162.90,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,472.31,143.32,58.89,7.86;5,335.63,153.78,212.26,7.86;5,335.63,164.24,95.52,7.86">The intelligent surfer: Probabilistic combination of link and content information in pagerank</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,450.10,164.24,19.49,7.86">NIPS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.63,175.69,197.03,7.86;5,335.63,186.15,210.69,7.86;5,335.63,196.62,204.76,7.86;5,335.63,207.08,220.22,7.86;5,335.63,217.54,212.96,7.86;5,335.63,228.00,162.30,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,335.63,186.15,210.69,7.86;5,335.63,196.62,14.95,7.86">Personalized recommendation driven by information flow</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,368.91,196.62,171.49,7.86;5,335.63,207.08,220.22,7.86;5,335.63,217.54,146.38,7.86">SIGIR &apos;06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="509" to="516" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
