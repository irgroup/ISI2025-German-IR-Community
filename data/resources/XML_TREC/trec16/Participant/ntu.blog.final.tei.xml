<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,212.16,75.53,187.84,12.58">NTU at TREC 2007 Blog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,210.60,106.52,54.31,10.80"><forename type="first">Kevin</forename><surname>Hsin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University Taipei</orgName>
								<address>
									<postCode>106</postCode>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.41,106.52,36.15,10.80"><forename type="first">Yih</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University Taipei</orgName>
								<address>
									<postCode>106</postCode>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,329.88,106.52,71.67,10.80"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
							<email>hhchen@csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University Taipei</orgName>
								<address>
									<postCode>106</postCode>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,212.16,75.53,187.84,12.58">NTU at TREC 2007 Blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4688EB820B183EF10B742CF9DF2C43BB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participated in the Opinion Retrieval Task and the Polarity Subtask. An SVM classifier was used to determine the opinion polarities of documents. We found that the opinion mean average precisions for the runs using the SVM classifier is better than the opinion mean average precisions for the runs produced solely by the TFIDF retrieval model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The Blog track offers several tasks this year. We participated in the Opinion Retrieval Task and the Polarity Subtask. The Opinion Retrieval Task requires us to retrieve documents which are both relevant to a topic and contain opinions. The Polarity Subtask requires us to label the opinion polarities of documents. The possible polarities are negatively opinionated, positively opinionated and mixed polarity.</p><p>Our approach to solving these two problems is to use the TFIDF retrieval model to retrieve topic-relevant documents and then apply a support vector machine (SVM) classifier on these documents to identify their polarities. We used the data from TREC 2006 Blog Track's Opinion Retrieval Task as the training data. Our results show that the opinion mean average precisions (MAP) for runs not classified by the SVM classifier are slightly lower than the MAP for their corresponding runs classified by SVM classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>Our method for the Opinion Retrieval Task consists of two steps: retrieving topic-relevant documents and ranking the opinionated retrieved documents higher. We used the Lemur toolkit as the search engine for retrieving topic-relevant documents. <ref type="bibr" coords="1,432.42,661.03,3.99,7.18">1</ref> The information retrieval model was TFIDF. At most one thousand documents were retrieved for each topic.</p><p>After obtaining the topic-relevant documents, we classified them into four categories: no opinion, positively opinionated, negatively opinionated, and mixed polarity. Documents belonging to the latter three categories were relocated to the front of the document list.</p><p>The LibSVM toolkit was used as our SVM classifier.<ref type="foot" coords="2,385.80,164.35,3.99,7.18" target="#foot_1">2</ref> An annotated corpus was required to train the classifier, so we used the Blog06 collection combined with TREC 2006's Blog Track relevance judgment file as the training corpus. To construct the training corpus, we first retrieved the documents that have the opinion tags of 1, 2, 3 or 4.</p><p>Each of these documents is a training instance. Features were extracted from the documents' textual contents. We did not use entire documents. Instead, we used only certain sentences from the documents. For each document, we retained only the sentences that contain at least a word from their corresponding topic. The sentences immediately following these sentences were also kept. Features were extracted from this collection of sentences.</p><p>The features used were punctuations, words and emotion words. The emotion words are a set of words provided by the Internet General Inquirer's website. <ref type="bibr" coords="2,437.94,362.35,3.99,7.18">3</ref> We used binary feature weights. That is, if a feature appears in a training instance, then the feature has the weight of 1. The feature has weight 0 otherwise.</p><p>For the learning phase of the SVM classifier, we performed 5-fold cross-validation on the training corpus to estimate the best cost parameter for the linear kernel.</p><p>After the SVM classifier is generated, we apply it on 2007's topic-relevant documents retrieved by the Lemur toolkit. As with the training corpus, we did not extract features from all the contents of the topic-relevant documents. Only sentences containing words from their corresponding topics and the sentences immediately following the aforementioned sentences were retained for feature extraction. If the SVM classifier labels a topic-relevant document as having an opinion (i.e., negatively opinionated, positively opinionated, or mixed polarity), the document is moved to the front of the list.</p><p>Hence, the initial document list returned by Lemur was conceptually divided into two sub-lists: the list containing documents with opinions followed by the list containing documents without opinions. Within each list, the documents were ranked by their TFIDF relevance score. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID R-Accuracy</head><p>NTUManualOpP 0.1161 NTUAutoOpP 0.0967</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>Table <ref type="table" coords="3,122.27,334.10,6.00,10.80" target="#tab_0">1</ref> shows our results for the Opinion Retrieval Task. The Query Type column indicates whether queries were manually-generated or automatically-generated. We create manual queries by removing general words from the topics. For automatic queries, all the words in the topics are used. The Opinion-Finding column indicates whether document opinion classification was used. In other words, if this value is "no" for a run, then the run is generated solely by the TFIDF retrieval model.</p><p>In Table <ref type="table" coords="3,160.43,442.10,4.50,10.80" target="#tab_0">1</ref>, we see that manual queries have higher Topicrel MAPs and Opinion MAPs than automatic queries. When the Opinion-Finding function is turned on, Topicrel MAPs drop, but Opinion MAPs increase.</p><p>Table <ref type="table" coords="3,145.89,496.10,6.00,10.80">2</ref> shows our results for the Polarity Subtask. The NTUManualOpP run is generated by labeling the documents listed in NTUManualOp as negatively opinionated, positively opinionated, or mixed polarity. Similarly, the NTUAntoOpP run is generated by labeling the documents listed in NTUAutoOp with opinion categories. The results produced by using manual queries have better R-Accuracy than the automatic queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this study, we used the SVM classifier to determine the opinion polarities of documents. Only very simple textual features were used. It may be possible to improve the performance by using more complicated features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,95.28,77.12,414.32,139.80"><head>Table 1 :</head><label>1</label><figDesc>Opinion Retrieval Task Results</figDesc><table coords="3,95.28,95.72,414.32,121.20"><row><cell>Run ID</cell><cell cols="4">Query Type Opinion-Finding Topicrel MAP Opinion MAP</cell></row><row><cell>NTUManual</cell><cell>Manual</cell><cell>No</cell><cell>0.3051</cell><cell>0.2384</cell></row><row><cell cols="2">NTUManualOp Manual</cell><cell>Yes</cell><cell>0.2940</cell><cell>0.2393</cell></row><row><cell>NTUAuto</cell><cell>Automatic</cell><cell>No</cell><cell>0.2901</cell><cell>0.2254</cell></row><row><cell>NTUAutoOp</cell><cell>Automatic</cell><cell>Yes</cell><cell>0.2870</cell><cell>0.2282</cell></row><row><cell></cell><cell cols="3">Table 2: Polarity Subtask Results</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,95.64,710.94,116.88,9.02"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,95.64,699.42,166.44,9.02"><p>http://www.csie.ntu.edu.tw/~cjlin/libsvm/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,95.64,710.94,140.29,9.02"><p>http://www.webuse.umd.edu:9090/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
