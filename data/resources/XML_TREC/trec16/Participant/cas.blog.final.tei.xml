<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.42,102.09,254.48,16.20">NLPR in TREC 2007 Blog Track</title>
				<funder ref="#_97Pv3RM">
					<orgName type="full">National Sciences Foundation of China</orgName>
				</funder>
				<funder ref="#_Q6hPZRP">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_AjafRJ4">
					<orgName type="full">National Sciences Foundation of Beijing</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.10,147.37,40.46,9.50"><forename type="first">Liu</forename><surname>Kang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.01,147.37,49.31,9.50"><forename type="first">Gen</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.89,147.37,56.93,9.50"><forename type="first">Han</forename><surname>Xianpei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.96,147.37,46.30,9.50"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.42,102.09,254.48,16.20">NLPR in TREC 2007 Blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A7910CD8225F7482322516339B010C44</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the opinion retrieval system for TREC 2007 blog track. This paper focuses on two components of the system. One component is important content block detection component which is used to extract blog contents and get rid of noises in blog pages. Another component is opinion retrieval component which is used to give each sentence an opinion score and combine it with topic score based on SVR. The evaluation proves the validity of our algorithm in the task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Blog track had two tasks in the TREC 2007. We participate in the opinion retrieval task, which is the same as the task of TREC 2006. This task is to identify and rank opinionated blog posts for the given topic. There were 50 topics with Title, Description and Narrative terms.</p><p>Our system divides the opinion retrieval task into four main steps. The first step is important contents block detection, which is used to clean noises in blog pages. Our system segments pages into several blocks with different sizes based on layout. Then we extract some special features and use SVM classifier to detect important content from blog pages and discard unimportant block that was filled with noises. This step can remove noises and retain title, post and comments in blog pages. In the second step, we build index using Indri toolkits <ref type="bibr" coords="1,124.10,506.22,12.28,9.50">[2]</ref> and create query according to the "topic" fields provided by NIST. In the third step, we have two components, one is retrieval model including sentences retrieval model and document retrieval model. Using document retrieval, we can obtain topic relevant score for each document. Another component is opinion scoring model. In this component, we employ NB regression method to obtain opinion scores for each sentence output from the sentence retrieval model. In the last step, we treat the answer of TREC 2006 Blog track as training corpus and employ SVR to train a fusion model. By using this model, our system can integrate the topic relevant score and opinion score together. Finally, we re-sort the result of document retrieval. Top 1000 documents for each query are submitted.</p><p>Figure <ref type="figure" coords="1,138.25,646.62,5.28,9.50">1</ref> gives the frame of our system. We will introduce each step in detail in the following sections. Section 2 will introduce the important content block detection method and the query formulation process. In section 3, we will describe the retrieval module including document retrieval, sentence retrieval and fusion method between topic score and opinion score. Section 4 will analyze the results of the six submitted runs and give a conclusion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Preprocessing</head><p>Before indexing, we must preprocess the corpus. This step includes data cleaning, sentence splitting, transforming pages into regular TREC text format and query processing. In data cleaning step, we propose a novel denoising method named as important content block detection. It is based on page segmentation. In the following, we will dive a description to the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem of Blog Page Cleaning</head><p>Data cleaning is a very important preprocessing step because the corpus comes from online webpages with HLTM format, which contains many noises. These noises will reduce the quality of the retrieval result. However, blog pages are different to other pages (navigational pages, sell pages, etc) in aspect of page layout. When we need to find some opinion about an entity, we often focus on blog"s post, title, and its comments. Other parts in blog pages, such as links to previous posts, advertise, navigational links, some web special flags, can be treated as noise or unimportant contents. The presence of these parts may reduce retrieval quality. So our cleaning task is to extract important contents of blog pages and reduce pages noises.</p><p>However, the layout of blog pages is too simple compared to navigational pages and sell pages. Important contents in blog pages are centralized in isolated blocks. From Figure <ref type="figure" coords="2,430.37,653.61,3.96,9.50" target="#fig_0">2</ref>, we can see that the important content of a blog page, like title, post, comment, is set in the yellow region. Many links titled by "Previous Posts" are centralized in the right side of pages. So our method for extracting important contents in blog pages has two steps. In the first step, we segment one page into several visual isolated blocks. It made blog"s contents and noises to be integrated into isolated blocks respectively. In the second step, we use SVM classifier based on layout features and language features to identity important content blocks from the output of step one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Important Content Block Detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Blog Page Segmentation</head><p>The first step in important content block detection method is page segmentation. The segmentation method used in our system is based on VIPS [1] <ref type="bibr" coords="3,369.29,160.57,11.62,9.50" target="#b1">[3]</ref>. There are several methods which are based on DOM tree <ref type="bibr" coords="3,221.45,176.17,11.81,9.50" target="#b2">[4]</ref>[5] <ref type="bibr" coords="3,245.07,176.17,11.81,9.50" target="#b4">[6]</ref>. These methods use DOM tree parsed from HTML file to find important tags and use these important tags to segment pages. But pages have many visual structures, especially in blog pages, see Figure <ref type="figure" coords="3,295.05,207.37,3.96,9.50" target="#fig_0">2</ref>. DOM tree can reveal only tag structure rather than these visual layouts information. VIPS can make full use of the visual features of pages such as font, color and size. Figure <ref type="figure" coords="3,221.65,238.57,5.28,9.50" target="#fig_0">2</ref> gives a segmentation result for a blog page. We can see that the whole page is segmented into several individual blocks. In each block, content is almost unified. After segmentation, a block tree is built for each page. Each block except leaf node has a parent block node and several child block nodes. From each node in this block tree, we can extract some features including layout features and language features. By using SVM classifier and some heuristic rule, we can identify whether each node being content or noise. When we use VIPS method, we can set the value of segmentation level (pDoc). In our systems, we set this value was 8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Important Content Block Detection and the Experiments</head><p>This task is treated as a two-class classification problem. One class is important content blocks and the other is noise blocks. Noise blocks should be discarded and important content blocks should be retained. We extract some layout features for SVM classifier including spatial features, tag features, content features and so on. We also use language features based on unigram model. The important features are listed in Table <ref type="table" coords="3,319.84,728.49,3.96,9.50" target="#tab_1">1</ref>. To the block tree which is built after segmentation, we begin from leaf node to root, using SVM classifier and heuristic rule to decide whether each node is content or noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noises</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Important content blocks</head><p>We randomly extract 500 pages from blog corpus and labeled them manually. Then we get 1836 noise blocks and 3576 important content blocks. For testing the validation of our method, we select 70% labeled pages to train model and 30% for testing. Our aim is to get tradeoff results between precision and recall. We aim at getting better precision results on the condition of higher recall value of important content block. So the main contents of blogs will be retained for indexing. Important contents of blogs will not be lost after data cleaning. The experimental results are listed in Table <ref type="table" coords="4,126.51,169.93,3.96,9.50">2</ref>.</p><p>We also select 5 sites from testing data to test the robust of our method, because Blog pages in different site have the different layout. Table <ref type="table" coords="4,279.41,201.13,5.28,9.50" target="#tab_2">3</ref>  From Table <ref type="table" coords="4,160.45,641.22,3.97,9.50">2</ref>, we can see that our method based on combined features can extract important content block with high accuracy. The method combined with two kinds of features has higher precision than the method using only layout features. The results for different sites testified our method"s robustness. We have high recall of detecting important content block for different layout pages. That means that important contents are mainily retained after data cleaning. Because of the diversity of blog pages, the precision of some pages is not high like site "scotsman.com". But our first target is to ensure high recall of important content block class. So this case can be ignored and our method can get effective results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Format Transform</head><p>After data cleaning for blog page files, we need conduct sentence splitting and format transforming. We only retain texts in content blocks and removed images, tags, scripts and stylesheets from content blocks. Then we transform each blog pages into the following format. &lt;p&gt;means paragraph and &lt;s&gt; means sentences. &lt;title&gt; means the title of the blog. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;DOC&gt;</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Formulation</head><p>The TREC Blog track provided 50 topic including Title, Description and Narrative terms. We use Title, Title and Description to build queries respectively. The tagger in [8] is used to identify POS for each term. We only use all token in Title and nouns and adjectives in Description to create query. The word "opinion" in the Description terms is removed. We do not use any dictionary and corpus for query expansion. The reason is that our focus is mainly put on the data cleaning and fusion between topic score and opinion score. For retrieval component, because document retrieval and sentence retrieval are conducted respectively, our system need create two kinds of queries. Different queries will be created based on different formats. A sample of queries format is listed in the following. Because sentence retrieval is for searching topic relevant sentences, it would be processed in "&lt;s&gt;" field  #combine( lactose gas )  #combine(#combine(lactose gas) #combine(#2(lactose gas) symptoms remedies )  #combine[s] (#weight( 0.7 #2(lactose gas) 0.3#combine(lactose gas) )  #combine[s](#combine(lactose gas) #combine(#2(lactose gas) symptoms remedies ) 3 Index and Retrieval</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Retrieval and Sentence Retrieval</head><p>We use Indri toolkit to build two kinds of index. One index is built based on the output of important content block detecting. The file format is set be "trectext". Another index is built based on original blog corpus, file format is "trecweb". We do not use stemmer and stoplist when indexing.</p><p>After document retrieval, we can get a topic relevant score for each document. On the other side, we can obtain topic relevant sentences through sentence retrieval. We set the number of returned documents being 1000. The target of sentences retrieval is to get enough relevant sentences. So the number of returned sentences is set 10000. For the sentence retrieval component, we use two kinds of methods. One is based on passage retrieval in Indri. Each document texts are dynamically split into fixed length sentences (sentences length was set 100). Another method is based on sentence splitting toolkit. Each sentence length is not unified and sentence retrieval is processed on &lt;s&gt; domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Opinion Score</head><p>In the step, Our system could give each sentence returned by sentences retrieval a opinion score by using Naï ve Bayes regression method. We use resources clawed from web to train a NB regression model. Then we can obtain the opinion score for each relevant sentence by using it.</p><p>Training corpus was lacked because of the diversity of topical domain, though Pang [9] and Bing Liu [10] could provide limited subjective corpus respectively. The Corpus of Pang is movie reviews containing 5000 subjective and 5000 objective sentences. The corpus of Bing Liu is product reviews containing 4258 subjective sentences. We need more resources that cover more broad range of topic and can provide amount of subjective texts. [7] is a review site. Reviews can cover a lot of fields including restaurant, film, sport and other events. So we download reviews on this site <ref type="bibr" coords="6,127.82,372.76,12.28,9.50">[7]</ref> and treated all of them as subjective texts. We also use TREC-AP news corpus as objective texts. Altogether, we obtain 85,914 subjective sentences and 362,936 objective sentences. We use unigram as the feature types, and train Naï ve Bayes classifier to score each sentence.</p><p>When training, we use stemming tool and get opinion score of each word in training data. For each retrieval sentence, we use the following formula to obtain opinion score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( ) ( )</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Sentence</head><p>Score Sentence Score Word   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fusion</head><p>After document retrieval and sentence retrieval, our system obtains topic relevant score for each document and opinion score for each topic relevant sentences. The fusion component integrates two kinds of scores together. In last year, several groups employed many variations of the weighted sum formula. The weight of each part was set by experience or estimated by train data.</p><p>In our systems, we use SVR to integrate the topic relevant score and the opinion score.</p><p>The training corpus comes from TREC 2006 blog track answer. We extract some special features for SVR. The features are listed in the Table <ref type="table" coords="6,275.93,622.38,3.96,9.50">4</ref>. Because there are not one topic relevant sentence corresponding to a retrieval document, we employ average, sum, highest opinion score of sentences in retrieval document as feature for SVR.</p><p>In answer of TREC 2006 blog track, if one document is topic relevant but not expressing any opinion, it will obtain 1 point. If one document is topic relevant and expresses opinion on entity, this document will obtain 2 point, which means that this document contains subjective texts about denoted entity. The value of each document in answer text will be used for training. If the document output from the document retrieval process does not contain any sentence that was topic relevant for the query, the document will obtain  point. In our system,  equals 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The rank in the document retrieval result</head><p>The score in the document retrieval result Average opinion score of retrieval sentence in one retrieval document Sum opinion score of retrieval sentence in one retrieval document Highest opinion score of retrieval sentence in one retrieval document Table <ref type="table" coords="7,231.41,195.49,3.96,9.50">4</ref>. Feature List for Fusion Component</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submission and Results</head><p>TREC 2007 blog track contains 50 topics. For each submission, MAP, R-precision, bpref and P@10 were four main evaluation methods. We submit six automatic runs. In five runs, we use important content block detection component and one run not. We also employ different sentence split methods in six runs. In three runs, we use Title terms to build query. In other three runs, we use Title and Description terms to create query. Table <ref type="table" coords="7,324.53,328.00,5.28,9.50">5</ref>  From the experimental results shown in Table <ref type="table" coords="7,302.81,710.37,3.96,9.50" target="#tab_4">6</ref>, we can get the following conclusion.  Comparing the results of NLPRTD and NLPRPTD2, we can see that our data preprocessing component can get rid of noises effectively. After important content block detection, MAP value can be improved. We can also see that the MAP values of all runs with important content block detection are higher than those of the runs without that component. So it proves the validity of the "important content block" method.  Comparing the results of NLPRPTONLY and NLPRPST, we can see that all evaluation values Are improved slightly after opinion scoring and fusion. It means that our opinion score and fusion method is effective.  Comparing the results of NLPRPT and NLPRPST, we can see that performance with opinion score based on fixed length sentences is worse than that based on sentence splitting method. The performance of NLPRPT is even worse than NLPRPTONLY, i.e. the run without opinion component. But the result which we test in TREC 2006 block track was reverse.  Comparing the results of NLPRPTD1 and NLPRPTD2, we can see that performance with  =0.8 is better than  =1. That is in our expectation.</p><p> We also find that query built based on Title and Description can not performance much better than Title only. It is out of our expectation. In last year block track, the performance of the query based on Title, Description is much better than Title only. The reason may be that nouns and adjectives in Description term bring some noises into query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper describes our opinion retrieval system in detail for TREC 2007 blog track. Our system has two important components. The first important component is important content block detection. In this component, our system uses VIPS method to segment blog pages and used SVM classifier to extract important content in blog pages. Layout features and language features are employed. In the second important component, our system employs NB regression to obtain opinion score for each relevant sentence. And it uses SVR to integrate topic score and opinion score. Our six submitted runs performed not the best, but better than the median of all the submitted runs. The evaluation of our six runs shows the validity of two important components in our system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,195.26,597.24,204.78,9.21;3,178.70,365.30,237.95,221.50"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Segmentation of a sample blog page</figDesc><graphic coords="3,178.70,365.30,237.95,221.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,118.94,201.13,379.89,394.39"><head>Table 1 .</head><label>1</label><figDesc>also lists experiments results for each site. Some selected layout features</figDesc><table coords="4,118.94,232.81,379.89,362.71"><row><cell>Block Width/Page Width</cell><cell></cell><cell>Block Height/Page Height</cell></row><row><cell>Block Center Y/Page Height</cell><cell cols="2">Block Center X/Page Width</cell></row><row><cell>pDoc value in VIPS</cell><cell></cell><cell>Text number in one block</cell></row><row><cell>Link number in one block</cell><cell cols="2">Link Number/Token Number</cell></row><row><cell>Image number in one block</cell><cell></cell><cell>Number of Sub-block</cell></row><row><cell>Block depth in Block Tree</cell><cell></cell><cell>Block Tree Depth</cell></row><row><cell>&lt;FORM&gt; tag number in one block</cell><cell cols="2">&lt;P&gt; tag number in one block</cell></row><row><cell>Results</cell><cell cols="2">Only layout features Combined features</cell></row><row><cell>Precision</cell><cell>0.8031</cell><cell>0.85</cell></row><row><cell>Recall of Important Content Block</cell><cell>0.913</cell><cell>0.908</cell></row><row><cell cols="3">Table 2. Results of Important Content Block Detection</cell></row><row><cell>Site</cell><cell>Precision</cell><cell>Recall of Important Content Block</cell></row><row><cell>Northfield.org</cell><cell>0.9950</cell><cell>0.9890</cell></row><row><cell>mdcbowen.org</cell><cell>0.9490</cell><cell>0.9930</cell></row><row><cell>gutRumbles.com</cell><cell>0.9650</cell><cell>0.99</cell></row><row><cell>asktaxmoms.com</cell><cell>0.9280</cell><cell>0.8860</cell></row><row><cell>scotsman.com</cell><cell>0.7170</cell><cell>0.9950</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,145.46,610.14,304.42,9.50"><head>Table 3 .</head><label>3</label><figDesc>Results of Important Content Block Detection for Different Site</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,90.02,328.00,415.48,360.79"><head>Table 6 .</head><label>6</label><figDesc>is a description of the six runs in detail. The evaluation results of the six runs are given in Table6Result of Our Runs</figDesc><table coords="7,90.02,375.28,415.39,289.63"><row><cell>Run</cell><cell>Description</cell><cell></cell><cell></cell><cell></cell></row><row><cell>NLPRPST</cell><cell cols="4">Important Content Block Detection + Title + Sentence Splitting +  =0.8</cell></row><row><cell>NLPRPT</cell><cell cols="4">Important Content Block Detection + Title + Fixed Sentence Splitting +  =0.8</cell></row><row><cell cols="5">NLPRPTONLY Important Content Block Detection + Title + No Opinion Score Component</cell></row><row><cell>NLPRPTD1</cell><cell cols="4">Important Content Block Detection + Title_Description + Fixed Sentence</cell></row><row><cell></cell><cell>Splitting +  =1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>NLPRPTD2</cell><cell cols="4">Important Content Block Detection + Title_Description + Fixed Sentence</cell></row><row><cell></cell><cell>Splitting +  =0.8</cell><cell></cell><cell></cell><cell></cell></row><row><cell>NLPRTD</cell><cell cols="3">Title_Description + Fixed Sentence Splitting +  =0.8</cell><cell></cell></row><row><cell></cell><cell cols="2">Table 5. Description of Our Runs</cell><cell></cell><cell></cell></row><row><cell>Runs</cell><cell>MAP</cell><cell>R-precision</cell><cell>bpref</cell><cell>P@10</cell></row><row><cell>NLPRPST</cell><cell>0.2542</cell><cell>0.3168</cell><cell>0.2945</cell><cell>0.4620</cell></row><row><cell>NLPRPT</cell><cell>0.2476</cell><cell>0.2973</cell><cell>0.3018</cell><cell>0.4340</cell></row><row><cell>NLPRPTONLY</cell><cell>0.2506</cell><cell>0.3166</cell><cell>0.2917</cell><cell>0.4520</cell></row><row><cell>NLPRPTD1</cell><cell>0.2532</cell><cell>0.3036</cell><cell>0.2929</cell><cell>0.43</cell></row><row><cell>NLPRPTD2</cell><cell>0.2587</cell><cell>0.3088</cell><cell>0.2956</cell><cell>0.4560</cell></row><row><cell>NLPRTD</cell><cell>0.2462</cell><cell>0.2935</cell><cell>0.2723</cell><cell>0.472</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledge</head><p>This work is supported by the <rs type="funder">National Sciences Foundation of China</rs> under grant No. <rs type="grantNumber">60673042</rs> and <rs type="funder">National Sciences Foundation of Beijing</rs> under grant No. <rs type="grantNumber">4052027</rs>, <rs type="grantNumber">40734043</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_97Pv3RM">
					<idno type="grant-number">60673042</idno>
				</org>
				<org type="funding" xml:id="_AjafRJ4">
					<idno type="grant-number">4052027</idno>
				</org>
				<org type="funding" xml:id="_Q6hPZRP">
					<idno type="grant-number">40734043</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,111.02,637.98,394.38,9.50;8,111.02,653.61,215.31,9.50" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,376.34,637.98,129.06,9.50;8,111.02,653.61,101.44,9.50">VIPS: A Vision based Page Segmentation Algorithm</title>
		<author>
			<persName coords=""><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shipeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiying</forename><surname>Ma</surname></persName>
		</author>
		<idno>MSR-TR-2003-79. 2003</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.02,684.81,394.40,9.50;8,111.02,700.41,252.99,9.50" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Ruihua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
		<title level="m" coord="8,353.67,684.81,151.75,9.50;8,111.02,700.41,222.07,9.50">Learning Block Importance Models for Web Pages. 13th International WWW Conference</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.02,716.01,394.50,9.50;8,111.02,731.61,347.02,9.50" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,356.71,716.01,148.81,9.50;8,111.02,731.61,77.39,9.50">DOM-based Content Extraction of HTML Documents</title>
		<author>
			<persName coords=""><forename type="first">Suhit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gail</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Neistadt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Grimm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,195.84,731.61,231.30,9.50">The Twelfth International World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.02,747.20,394.23,9.50;9,111.02,76.31,394.31,9.50;9,111.02,91.93,59.88,9.50" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,236.09,747.20,264.36,9.50">Eliminating Noisy Information in Web Pages for Data Mining</title>
		<author>
			<persName coords=""><forename type="first">Lan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,111.02,76.31,394.31,9.50;9,111.02,91.93,28.80,9.50">The Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.02,107.53,394.39,9.50;9,111.02,123.13,375.30,9.50" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,201.71,107.53,284.49,9.50">Web page cleaning for web mining through feature weighting</title>
		<author>
			<persName coords=""><forename type="first">Lan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,111.02,123.13,345.03,9.50">proceedings of Eighteenth International Joint Conference on Artificial Intelligence</title>
		<meeting>Eighteenth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
