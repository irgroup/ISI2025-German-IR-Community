<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.37,104.32,332.46,15.12">TREC 2007 ciQA Task: University of Maryland</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,191.85,138.22,72.62,10.48"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
							<email>nmadnani@umiacs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland College Park</orgName>
								<address>
									<settlement>Maryland</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.44,138.22,53.77,10.48"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<email>jimmylin@umiacs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland College Park</orgName>
								<address>
									<settlement>Maryland</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.94,138.22,63.41,10.48"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
							<email>bonnie@umiacs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland College Park</orgName>
								<address>
									<settlement>Maryland</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.37,104.32,332.46,15.12">TREC 2007 ciQA Task: University of Maryland</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D323AAAA99046A7C3E4C23B5BF383C25</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Information needs are complex, evolving, and difficult to express or capture <ref type="bibr" coords="1,426.67,248.67,65.58,9.57" target="#b5">(Taylor, 1962)</ref>, a fact that is often overlooked by modern information retrieval systems. TREC, through the HARD track, has been attempting to introduce elements of interaction into large-scale evaluations in order to achieve high accuracy document retrieval <ref type="bibr" coords="1,230.83,289.32,62.07,9.57" target="#b0">(Allan, 2005)</ref>. Previous research has shown that well-constructed clarification questions can yield a better understanding of users' information needs and thereby improve retrieval performance <ref type="bibr" coords="1,169.87,316.42,78.94,9.57" target="#b3">(Lin et al., 2006)</ref>.</p><p>Interactive question answering has recently become a focus of research in the context of complex QA. The topics in the ciQA task are substantially different from factoid questions in that the information needs are complex, multi-faceted, and often not well defined or expressed. To investigate the role of interaction in complex QA, we experimented with two approaches. The first approach relied on Maximum Marginal Relevance (MMR) and is described in Section 2. The second approach employed the Multiple Alternative Sentence Compressions (MASC) framework (Zajic, 2007;<ref type="bibr" coords="1,474.53,397.71,76.07,9.57;1,64.60,411.26,24.24,9.57" target="#b4">Madnani et al., 2007)</ref>, described in Section 3. Section 4 presents official results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Initial Run</head><p>In one set of experiments, we adapted MMR to ciQA. First, we retrieved the top 100 documents from the corpus with Lucene using the topic template verbatim as the query. These documents were then broken into individual sentences, which served as the pool of candidates. The relevance component of each sentence is computed as the sum of the idf of matching terms from the topic template. For the redundancy component, we used cosine similarity between each candidate sentence and the current answer. To answer a complex question, the sentence selector iteratively selects the candidate with the highest score, recomputing the redundancy component at each step. The process ends when 25 sentences have been selected in this manner. We submitted these answers to NIST as run UMD07MMRa. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interaction Design</head><p>At each step in the MMR algorithm, the sentence selector recomputes the score of all candidate sentences. Although only the highest-scoring candidate is selected for inclusion in the final answer, a ranked list of all candidate sentences is implicitly generated in the process. The idea behind our ciQA interaction involved this decision point: what if we presented the ranked list of sentences to a human and asked the human to select the best sentence for inclusion in the answer? Our MMR-based interactive QA system was exactly designed this way (see Figure <ref type="figure" coords="2,370.55,482.17,4.24,9.57" target="#fig_0">1</ref>). At each iteration, the user is asked to select from a ranked list of candidate sentences. The selected sentence is added to the final answer, and a new ranked list of sentences is computed based on the standard MMR algorithm. We asked the user to iterate this process for the entire duration of the interaction session. If the final output was still less than 4000 characters, we continued iterating the MMR algorithm (selecting the highest-scoring candidate) until that quota was filled. We submitted this run to NIST as UMD07MMRb.</p><p>3 The MASC approach MASC (Multiple Alternative Sentence Compressions) is a framework originally developed for using sentence compression in query-focused automatic summarization of single and multiple documents. A MASC system uses a sentence compression module to generate multiple compressions of source sentences in combination with a candidate selector to construct a summary from the compressed candidates. The selector uses a combination of static and dynamic features to select candidates that maximize relevance while minimizing redundancy within the summary.</p><p>The MASC architecture consists of three stages: filtering, compression, and candidate selection. In the first stage (filtering), sentences of high relevance and centrality are selected for further processing downstream. In the second stage (sentence compression), multiple alternative compressed versions of the source sentences are generated, including a version with no compression, i.e., the original sentence. Our sentence compression module-Trimmer <ref type="bibr" coords="3,289.19,78.44,91.19,9.57" target="#b1">(Dorr et al., 2003;</ref><ref type="bibr" coords="3,386.42,78.44,88.55,9.57" target="#b6">Zajic et al., 2006;</ref><ref type="bibr" coords="3,481.02,78.44,63.41,9.57">Zajic, 2007)</ref>uses linguistically-motivated trimming rules to remove constituents from a parse tree. It associates compression-specific feature values, such as the number and parse tree depth of various rule applications, with the candidate compressions that can be used in candidate selection. These features are computed and stored in advance for each compressed candidate. In addition, we also compute four features based on the query (topic template), the candidate compression, and the topic cluster (top n documents retrieved from the corpus with Lucene using the template verbatim as the query):</p><p>1. Sentence Relevance. The relevance score of the sentence to the query.</p><p>2. Document Relevance. The relevance score of the document to the query.</p><p>3. Sentence Centrality. The centrality score of the sentence to the topic cluster.</p><p>4. Document Centrality. The centrality score of the document to the topic cluster.</p><p>The final stage in MASC is the selection of candidates from the pool created by filtering and compression. We use a weighted linear combination of static and dynamic candidate features to select the highest scoring candidate for inclusion in the summary. Static features are those discussed above. Dynamic features include redundancy with respect to the current summary state and the number of candidates already in the summary from a candidate's source document. The dynamic features are recomputed after every candidate selection.</p><p>When a candidate is selected, all other candidates derived from the same source sentence are removed from the candidate pool. The selector continues to pick candidates for inclusion in the summary until either the summary reaches the prescribed word limit or the pool is exhausted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Initial Run</head><p>This section describes our methodology for creating the initial run UMD07iMASCa for the ciQA task. Answers were generated by treating this task as a query-focused multi-document summarization task. First we retrieved the top 50 documents for each topic from the corpus with Lucene using the topic template verbatim as the query. Next, we tagged and parsed all documents and ran Trimmer to generate compressions for all sentences. We merged the question template and the narrative for each topic into a single query that was used to compute the relevance and centrality features for each compressed candidate. We then ran our MASC system to completion with a word limit of 250 words. The weights for the candidate features were optimized on a separate held-out development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interaction Design</head><p>This section describes the methodology used to create our final submission UMD07iMASCb based on the MASC approach. Since our original summarization system is completely automatic, we had to rearchitect it in order to incorporate the interaction with assessors. Processing up to the point prior to iterative selection of the answer candidates was the same as in the initial run.</p><p>Sentence Selection. We structured the system such that when first visiting the interaction URL, the assessors are presented with a list of the most relevant uncompressed sentences as determined by the Selector. After locating the most relevant sentence, the assessor is asked to click on the Show Compressions button next to the sentence. This redirects to another form that presents all compressions generated by Trimmer for that sentence (including the original sentence itself), sorted by length. See Figure <ref type="figure" coords="3,99.02,703.19,5.45,9.57" target="#fig_1">2</ref> for an example.   Candidate Selection. Each compression in the list is color coded-words that have been deleted from the original sentence to create this compression are shown in grey and the words actually present are shown in black. From this list, the assessor is asked to find the shortest compression that conveys all relevant information and add it to the response. See Figure <ref type="figure" coords="5,367.72,271.25,5.45,9.57" target="#fig_2">3</ref> for an example.</p><p>Once a compression has been added to the response, the assessor is presented with another list of sentences from the cluster. This list may have some of the same sentences seen earlier except for any that have already been included in the response. The process is repeated for as long as the assessor deems necessary (until the allotted interaction time runs out).</p><p>Automatic augmentation. Before submitting the final run, any answers created by assessors that are less than 250 words are further augmented with candidate selections made by our automatic summarization system until that word limit is reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The pyramid F-scores of our submitted ciQA runs are shown in Table <ref type="table" coords="5,404.55,438.37,4.24,9.57" target="#tab_0">1</ref>. It does not appear that our interactions were effective-the MMR interaction basically left the F-score unchanged, and the MASC interaction actually decreased the F-score.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,64.60,349.40,486.00,9.57;2,64.60,362.95,265.57,9.57;2,64.60,62.38,504.01,270.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Interface for candidate sentence selection in the MMR approach. At each iteration, the user is asked to select a sentence for inclusion in the answer.</figDesc><graphic coords="2,64.60,62.38,504.01,270.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,64.60,430.26,486.00,9.57;4,64.60,443.81,486.00,9.57;4,64.60,457.36,115.37,9.57;4,64.60,109.10,504.00,305.10"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Interface for candidate sentence selection in the MASC approach. The user is first asked to select the most relevant sentence, and is then redirected to the interface shown in Figure 3 for selection of the best compression.</figDesc><graphic coords="4,64.60,109.10,504.00,305.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,64.72,671.09,485.75,9.57;4,64.60,569.34,503.99,85.69"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Interface for selecting the best compression of a candidate sentence in the MASC approach.</figDesc><graphic coords="4,64.60,569.34,503.99,85.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,149.08,63.78,317.03,143.38"><head>Table 1 :</head><label>1</label><figDesc>Pyramid F-score of our submitted runs to the ciQA task.</figDesc><table coords="5,203.61,63.78,207.97,108.43"><row><cell></cell><cell>MMR</cell><cell></cell></row><row><cell>type</cell><cell>runtag</cell><cell>pyramid F-score</cell></row><row><cell cols="2">initial UMD07MMRa</cell><cell>0.333</cell></row><row><cell>final</cell><cell>UMD07MMRb</cell><cell>0.334</cell></row><row><cell></cell><cell>MASC</cell><cell></cell></row><row><cell>type</cell><cell>runtag</cell><cell>pyramid F-score</cell></row><row><cell cols="3">initial UMD07iMASCa 0.182</cell></row><row><cell>final</cell><cell cols="2">UMD07iMASCb 0.156</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="1,88.81,443.24,149.29,12.62;1,64.60,469.99,486.00,9.57;1,64.60,483.54,486.01,9.57;1,64.60,497.09,486.00,9.57;1,64.60,510.63,486.00,9.57;1,64.60,524.18,486.01,9.57;1,64.60,537.73,486.00,9.57;1,64.60,551.28,308.55,9.57"><p>The MMR ApproachMaximum Marginal Relevance (MMR) is an extractive technique for document summarization<ref type="bibr" coords="1,519.61,469.99,30.99,9.57;1,64.60,483.54,83.87,9.57" target="#b2">(Goldstein et al., 2000)</ref>. The basic idea is to iteratively select from a candidate pool of sentences until a desired length has been achieved. The score of a candidate sentence is computed from a weighted sum of two components: the relevance component and the redundancy component. At each step, the MMR algorithm selects the candidate with the highest score for inclusion in the final summary. Typically, the relevance component of a candidate sentence remains static, whereas the redundancy component is recomputed at each iteration as the summary grows in length.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,64.60,537.74,486.00,9.57;5,81.53,551.29,356.90,9.57" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,164.41,537.74,380.78,9.57">HARD track overview in TREC 2005: High accuracy retrieval from documents</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,95.17,551.29,270.23,9.57">Proceedings of the Fourteenth Text REtrieval Conference</title>
		<meeting>the Fourteenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005. TREC 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,64.60,573.81,486.00,9.57;5,81.53,587.35,469.07,9.57;5,81.53,600.90,468.12,9.57" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,381.25,573.81,169.34,9.57;5,81.53,587.35,154.68,9.57">Hedge Trimmer: A parse-and-trim approach to headline generation</title>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">M</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,263.93,587.35,286.67,9.57;5,81.53,600.90,311.10,9.57">Proceedings of the HLT-NAACL 2003 Text Summarization Workshop and Document Understanding Conference (DUC 2003)</title>
		<meeting>the HLT-NAACL 2003 Text Summarization Workshop and Document Understanding Conference (DUC 2003)<address><addrLine>Edmonton, Alberta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,64.60,623.42,486.00,9.57;5,81.53,636.97,469.06,9.57;5,81.53,650.52,285.45,9.57" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,433.59,623.42,117.01,9.57;5,81.53,636.97,207.46,9.57">Creating and evaluating multi-document sentence extract summaries</title>
		<author>
			<persName coords=""><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vibhu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,312.61,636.97,237.99,9.57;5,81.53,650.52,213.20,9.57">Proceedings of the Ninth International Conference on Information and Knowledge Management</title>
		<meeting>the Ninth International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>CIKM</publisher>
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,64.60,673.03,486.00,9.57;5,81.53,686.58,469.06,9.57;5,81.53,700.13,467.86,9.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,437.70,673.03,112.89,9.57;5,81.53,686.58,165.81,9.57">Exploring the limits of single-iteration clarification dialogs</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eileen</forename><surname>Abels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,271.10,686.58,279.50,9.57;5,81.53,700.13,388.28,9.57">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2006)</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="469" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,64.60,64.89,486.00,9.57;6,81.53,78.44,469.06,9.57;6,81.53,91.99,355.34,9.57" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,456.85,64.89,93.75,9.57;6,81.53,78.44,273.68,9.57">Multiple alternative sentence compressions for automatic text summarization</title>
		<author>
			<persName coords=""><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Necip</forename><surname>Fazil Ayan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,383.30,78.44,167.30,9.57;6,81.53,91.99,296.31,9.57">Proceedings of the 2007 Document Understanding Conference (DUC-2007) at NLT/NAACL 2007</title>
		<meeting>the 2007 Document Understanding Conference (DUC-2007) at NLT/NAACL 2007<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,64.60,114.51,473.89,9.57" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,182.36,114.51,148.96,9.57">The process of asking questions</title>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">S</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<publisher>American Documentation</publisher>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="391" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,64.60,137.02,486.00,9.57;6,81.53,150.57,469.07,9.57;6,81.53,164.12,409.32,9.57" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,419.96,137.02,130.64,9.57;6,81.53,150.57,269.33,9.57">Sentence compression as a component of a multi-document summarization system</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,381.13,150.57,169.47,9.57;6,81.53,164.12,125.76,9.57;6,287.48,164.12,90.36,9.57">Proceedings of the 2006 Document Understanding Conference</title>
		<meeting>the 2006 Document Understanding Conference<address><addrLine>New York, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
	<note>NLT/NAACL 2006</note>
</biblStruct>

<biblStruct coords="6,64.60,186.64,486.00,9.57;6,81.53,200.18,356.81,9.57" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,176.14,186.64,374.47,9.57;6,81.53,200.18,100.57,9.57">Multiple Alternative Sentence Compressions (MASC) as a Tool for Automatic Summarization Tasks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zajic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
