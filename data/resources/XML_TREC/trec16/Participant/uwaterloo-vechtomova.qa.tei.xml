<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.00,154.89,467.25,15.12">Complex Interactive Question Answering Enhanced with Wikipedia</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,166.56,187.37,79.97,10.48"><forename type="first">Ian</forename><surname>Mackinnon</surname></persName>
							<email>imackinn@cs.uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>ON</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Olga Vechtomova</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>ON</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.00,154.89,467.25,15.12">Complex Interactive Question Answering Enhanced with Wikipedia</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F6C311FD735B97B8F15FF06B10D60819</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In ciQA, templates are used with several bracketed items we call "facets" which are the basis of information being sought. This information is returned in the form of nuggets. Due to the concepts being sought having multiple terms to describe them, it becomes difficult to determine which sentences in the AQUAINT-2 news articles contain the query terms being sought, as they may be represented in the parent document by a variety of different phrases still making reference to the query term. For example, if the term "John McCain" were being sought, it might appear in an article, however, the sentence which is the vital nugget may simply contain "Senator Mc-Cain"; an imperfect match.</p><p>Traditional query expansion <ref type="bibr" coords="1,202.34,461.70,13.37,8.74" target="#b4">[5]</ref> of facets would introduce new terms which are related but do not necessarily mean the same as the original facet. This does not always help the problem of query terms appearing in relevant documents but not relevant sentences within documents, it only introduces related terms which cannot be considered synonymous with the facet being retrieved. In this year's TREC, we hope to overcome some of this problem by looking for synonyms for facets using Wikipedia.</p><p>Many of the ciQA facets are proper nouns and most thesauri, such as WordNet, do not contain entries for these. Thus, a new manner of finding synonyms must be found. In recent years, several new approaches have been proposed to use Wikipedia as a source of lexical information <ref type="bibr" coords="1,162.87,642.03,13.11,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,179.67,642.03,7.01,8.74" target="#b6">7]</ref>, as it can be downloaded in its entirety, and contains relatively high quality articles <ref type="bibr" coords="1,101.57,665.94,11.09,8.74" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Wikipedia</head><p>Every article in Wikipedia represents a concept, and all links from other articles must have an anchor text over the link. We also know that there are Wikipedia guidelines for what the anchor text should be for a link, and that we can assume that, provided editors are following the rules, the anchor text of the link will be of high quality. As we can see from this excerpt from the Wikipedia manual of style<ref type="foot" coords="1,465.66,374.35,3.97,6.12" target="#foot_0">1</ref> : "It is possible to link words that are not exactly the same as the linked article title, for example, [[English language-English]]. However, make sure that it is still clear what the link refers to without having to follow the link." -Wikipedia Manual of Style</p><p>The anchor texts which point to the article will contain other terms for the same concept, which are necessary to get a better understanding of what concepts are represented in the text.</p><p>In order to make use of this information, we built a parser to extract every link in the Wikipedia collection; some <ref type="bibr" coords="1,360.29,555.05,9.96,8.74">45</ref>  by doing a reverse lookup on our listing, as we can see in Table <ref type="table" coords="2,129.15,415.31,3.87,8.74" target="#tab_0">2</ref>. It is using this information that we can effectively find synonyms for the concept of "Radio Waves". We are also given a type of confidence measure for those synonyms in the form of the linking frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Wikipedia Article Selection for Facets</head><p>We have devised a method of using the anchor text within Wikipedia links in order to resolve a small set of concepts which are represented in a candidate sentence.</p><p>We define the algorithm to turn a facet into a list of concepts as follows:</p><p>1. Set window length to n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">For each possible position of window, check all</head><p>anchor text in Wikipedia to see if the phrase or term is recognized. If it is, record the matching string and drop the words covered in the window from future consideration. See Fig 1.</p><p>3. Decrease the length of the window by one (n = n -1). If the window length is 1, do not look up stopwords in term dictionary, simply ignore. Go to step 2 if window length is greater than 0.</p><p>4. For terms extracted from the query, look at the frequency of that term when linking to different articles. If an article has a majority of the links with that term as anchor text pointing to it, resolve that article to be the most relevant article for that multi-word unit. If no article has more than half the links with that anchor text pointing to it, drop the multi-word unit from consideration, as the term is ambiguous. However, if the frequency of anchor text linking to that article is less than 2, it is ignored.  In our experiments, we initially set n = 5.</p><p>4 Submitted Runs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">UWinitBASE</head><p>The UWinitBASE run is based on the ciQA run UWATCIQA1 from 2006 <ref type="bibr" coords="3,177.88,184.22,12.45,8.74" target="#b7">[8]</ref>. Only minor tuning parameter changes were made. This base system selects sentences for a given query as follows:</p><p>1. Parse out the initial topic to get the 2 or 3 facets from the test topic.</p><p>2. Split apart each of facets into single terms, join all the terms together into one list, and perform a BM25[6] retrieval<ref type="foot" coords="3,167.62,301.30,3.97,6.12" target="#foot_1">2</ref> . The top 50 documents from the AQUAINT newswire corpus are returned by the system and kept in order according to their BM25 scores.</p><p>3. Since we are interested in nuggets which contain information about the relationship between all of the facets, we need to ensure that all of the concepts noted in the test topic are represented in the document somewhere. For each of the returned documents, we wish to determine the validity of the document by ensuring at least one non-stopword from each of the facets exists in the document. Invalid documents are moved to the end of the list of 50 documents, effectively giving us an ordered list of valid documents sorted by BM25 followed by invalid documents sorted by BM25.</p><p>4. At this point we have a rather nice list of documents which likely contain information about the test topic, however, our goal is not to retrieve a list of relevant documents like many other TREC tasks, but rather to return a list of nuggets. To do this we break up the documents from the top 50 into their constituent sentences. In order to preserve the rankings provided to us by BM25, we keep the sentences in order in which their parent document occurred in the top 50 ranking.</p><p>5. We next require a method of ranking sentences for return. To do this, we will apply a score of 0,1,2, or 3 to a sentence depending on the number of facets which are represented in a candidate sentence. Each topic will have 2 or 3 facets containing a number of terms within them. For each facet, let us consider Γ = γ 1 ...γ n to be the set of non-stopword terms for a facet in a ciQA topic.</p><p>A score is assigned to a candidate sentence S, by iterating through all the γ i in Γ, and determining if any of the non-stopword stems of the terms exist in the sentence. If at least one exists, a nugget is said to be represented in the facet. More formally:</p><formula xml:id="formula_0" coords="3,336.45,316.64,202.80,32.75">score(S, Γ) = 1 if a γ i ∈ Γ exists in S 0 otherwise<label>(1)</label></formula><p>We get the total score for S by taking the sum of the score(S, Γ) for each facet in the topic.</p><p>A sort is then performed on the list of sentences, but it is of great importance that the sort preserve the original ordering of the sentences with the same score. This allows for sentences which come from a document with a higher BM25 score to be ranked higher, given that they are likely more relevant to the test topic. In the likely event of ties, given that there are potentially hundreds of candidate sentences and only 3 possible scores in the highest case, ties are broken by applying a Brill tagger <ref type="bibr" coords="3,444.18,502.33,12.55,8.74" target="#b0">[1]</ref> to the text of the facets, and re-sorting the sentences based on the number of proper nouns from the facet which the sentence contains. The motivation of this being that proper nouns would be included in sentences that are more likely to be relevant, rather than just segue sentences in a news article.</p><p>6. The top n ranked sentences for each topic are output by the system. n = 30 seems to be a standard number of nuggets to return so as not to be too verbose but to allow for enough sentences to be returned that most of the vital nuggets would be accounted for in the sentences returned by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">UWinitWIKI</head><p>This run utilizes the Wikipedia article parsing algorithm described earlier. Our intent is to incorporate the information from a facet's set of anchor text, A, in addition to the set of terms in the facet, Γ. A higher score is given to a candidate sentence, S, if it contains an anchor text term from A in it as opposed to simply a term from the facet. More formally:</p><formula xml:id="formula_1" coords="4,78.20,247.05,222.45,46.67">score(S, γ i ) =    1.2 if an α i ∈ A exists in S 1 if a γ i ∈ Γ exists in S 0 otherwise (2)</formula><p>The score of 1.2 is rather arbitrary. It just needed to be higher than 1, but low enough such that 2 matches from A would not be ranked higher than 3 from Γ.</p><p>From here, sentences are sorted according to score as before. The only difference from the baseline system is the integration of the A terms from the anchor text. The remaining issue is what method is used to select the articles from Wikipedia for the given facet, for which UWinitWIKI uses the automatic method described earlier. In the case where no article is available, the original metod from UWinitBASE is used, and the facets are broken up into their constituent terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">UWfinalWIKI</head><p>This run was similar to UWbaseWIKI in that anchor text selected from Wikipedia articles chosen for each facet. However, articles were used not from the parsing algorithm but rather articles selected by NIST assessors. The form given to the NIST assessors can be seen in Fig 3 . NIST assessors were given a "short list" of articles related to the facet, and were asked to select the minimum set which best described the facet.</p><p>The short list was given in order to make the job of the assessor easier to perform and not requiring an open ended search of the entire Wikipedia collection for relevant articles. The short lists consisted of up to 10 candidate articles obtained by taking articles from a Yahoo! search for the facet text restricted Unfortunately, on the final day of the interaction phase, when only a small number of topics had been assessed, network access to the .uwaterloo.ca domain was cutoff due to an external outage and no further topics could be interactive with by the NIST assessors, meaning most of the nuggets returned for topics in this run are identical to UWinitBASE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">UWfinalMAN</head><p>In light of this network error, a manual run was submitted using articles selected by the author using the same selection interface. No other manual interaction was performed. It was necessary to give some kind of indication about the impact of humans picking the articles used for anchor text expansion rather than the automatic algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The results for the submitted runs can be found in Table <ref type="table" coords="4,337.50,642.03,3.87,8.74" target="#tab_1">3</ref>. Using the Nuggeteer <ref type="bibr" coords="4,434.58,642.03,13.64,8.74" target="#b3">[4]</ref> system on ciQA2006 data, a 10% performance increase was found using the systems from UWinitBASE and UWinitWIKI, Looking at individual topic performance we see that contrasting UWinitBASE to UWinitWIKI, 11 topics were improved, 8 unchanged and 12 were worse off. Comparing UWiniWIKI to UWfinalMAN, 8 topics were improved, 14 unchanged, and 10 worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>While the scores from all the runs were higher than the medians and generally performed very well, we were disappointed that there was no net benefit to using the synonyms derived from the Wikipedia link structure. Similar tests using the 2006 data showed a modest increase in F-scores. However, different nuggets were returned by the two systems mean that it could be possible to identify trends in topics that performed poorly using the Wikipedia systems, and account for them. It may also be necessary to assign a weight to the anchor texts based on their frequencies as links. This would allow us to grade the synonym and incorporate it into the score more accurately.</p><p>Interestingly, human interaction yielded little benefit to this. It is likely that the human-selected articles which differed from the automatically selected ones were on topics which were not affected by the synonyms derived from the Wikipedia articles.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,310.61,430.74,228.64,8.74;2,310.61,442.70,228.65,8.74;2,310.61,454.65,113.60,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: When a window recognizes a multi-word unit from the nugget, it saves it and drops the text from future consideration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,310.61,617.50,228.64,8.74;2,310.61,629.46,210.27,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Multi-Word Units are resolved to whichever article has the most links with that anchor text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,310.61,303.35,228.64,8.74;4,310.61,315.30,107.90,8.74;4,311.54,124.80,226.77,163.43"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Screenshot of the user interaction to pick a articles from a short list.</figDesc><graphic coords="4,311.54,124.80,226.77,163.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,310.61,555.05,228.65,92.85"><head>Table 2 :</head><label>2</label><figDesc>Frequency of Anchor Text for "Radio</figDesc><table coords="1,310.61,555.05,228.65,92.85"><row><cell>million links. Using this information,</cell></row><row><cell>we can see what article links to which, but more im-</cell></row><row><cell>portantly, what text is used to link to an article, and</cell></row><row><cell>with what frequency. As we can see in Table 1, there</cell></row><row><cell>are several different articles with 'radio waves' as an-</cell></row><row><cell>chor text on links to it.</cell></row><row><cell>Similarly, once we have an article, we can examine</cell></row><row><cell>what anchor text is used to label links to that article</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,72.00,134.88,228.64,158.88"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table coords="5,72.00,134.88,228.64,158.88"><row><cell cols="2">Nugget Pyramid Scores along with Median</cell></row><row><cell>for Runs</cell><cell></cell></row><row><cell>Run</cell><cell>F-Score</cell></row><row><cell>UWbaseINIT</cell><cell>0.388</cell></row><row><cell>UWbaseWIKI</cell><cell>0.388</cell></row><row><cell cols="2">Baseline Median 0.359</cell></row><row><cell>UWfinalWIKI</cell><cell>0.380</cell></row><row><cell>UWfinalMAN</cell><cell>0.386</cell></row><row><cell>Final Median</cell><cell>0.361</cell></row><row><cell cols="2">respectively. Compared to the results from this year,</cell></row><row><cell cols="2">which are unchanged between the two baseline runs.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,325.85,658.41,207.47,6.64;1,310.61,667.88,80.45,6.64"><p>http://en.wikipedia.org/wiki/Wikipedia:Manual_of_ Style_\%28links\%29</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,87.24,667.30,149.48,6.99"><p>Using default parameters k=1.2, b=0.75</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,326.10,149.78,213.14,8.74;5,326.10,161.74,213.14,8.74;5,326.10,173.69,213.14,8.74;5,326.10,185.65,127.28,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,363.06,149.78,176.18,8.74;5,326.10,161.74,213.14,8.74;5,326.10,173.69,110.68,8.74">Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,451.48,173.69,87.76,8.74;5,326.10,185.65,30.97,8.74">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="543" to="565" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,205.57,213.15,8.74;5,326.10,217.53,213.15,8.74;5,326.10,229.48,213.14,8.74;5,326.10,241.44,213.15,8.74;5,326.10,253.39,160.42,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,476.21,205.57,63.04,8.74;5,326.10,217.53,213.15,8.74;5,326.10,229.48,74.79,8.74">Computing semantic relatedness using wikipedia-based explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,424.57,229.48,114.67,8.74;5,326.10,241.44,213.15,8.74;5,326.10,253.39,48.17,8.74">Proceedings of The Twentieth International Joint Conference for Artificial Intelligence</title>
		<meeting>The Twentieth International Joint Conference for Artificial Intelligence<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,273.32,213.14,8.74;5,326.10,285.27,190.93,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,364.48,273.32,170.11,8.74">Internet encyclopaedias go head to head</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,326.10,285.27,27.60,8.74">Nature</title>
		<imprint>
			<biblScope unit="volume">438</biblScope>
			<biblScope unit="issue">7070</biblScope>
			<biblScope unit="page" from="900" to="901" />
			<date type="published" when="2005-12">December 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,305.20,213.14,8.74;5,326.10,317.15,213.14,8.74;5,326.10,329.11,213.14,8.74;5,326.10,341.06,22.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,458.20,305.20,81.05,8.74;5,326.10,317.15,213.14,8.74;5,326.10,329.11,66.11,8.74">Nuggeteer: Automatic nugget-based evaluation using descriptions and judgements</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,412.22,329.11,120.71,8.74">Proceedings of NAACL/HLT</title>
		<meeting>NAACL/HLT</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,360.99,213.15,8.74;5,326.10,372.94,213.14,8.74;5,326.10,384.90,43.72,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,402.49,360.99,136.76,8.74;5,326.10,372.94,31.53,8.74">On term selection for query expansion</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,369.99,372.94,114.20,8.74">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="364" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,404.82,213.14,8.74;5,326.10,416.78,213.14,8.74;5,326.10,428.74,213.14,8.74;5,326.10,440.69,213.15,8.74;5,326.10,452.65,213.15,8.74;5,326.10,464.60,213.15,8.74;5,326.10,476.56,189.13,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,470.14,404.82,69.11,8.74;5,326.10,416.78,213.14,8.74;5,326.10,428.74,132.47,8.74">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,478.25,428.74,61.00,8.74;5,326.10,440.69,213.15,8.74;5,326.10,452.65,213.15,8.74;5,326.10,464.60,68.76,8.74">Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 17th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA; New York, Inc</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,496.48,213.14,8.74;5,326.10,508.44,213.15,8.74;5,326.10,520.39,213.15,8.74;5,326.10,532.35,213.14,8.74;5,326.10,544.30,111.97,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,464.77,496.48,74.47,8.74;5,326.10,508.44,192.88,8.74">Wikirelate! computing semantic relatedness using wikipedia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,326.10,520.39,213.15,8.74;5,326.10,532.35,129.22,8.74">Proceedings of the Twenty-First National Conference on Artificial Intelligence</title>
		<meeting>the Twenty-First National Conference on Artificial Intelligence<address><addrLine>Boston, Mass</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07">July 2006</date>
			<biblScope unit="page" from="1419" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,326.10,564.23,213.15,8.74;5,326.10,576.18,213.14,8.74;5,326.10,588.14,213.14,8.74;5,326.10,600.09,22.69,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,476.67,564.23,62.58,8.74;5,326.10,576.18,213.14,8.74;5,326.10,588.14,155.66,8.74">Identifying relationships between entities in text for complex interactive question answering task</title>
		<author>
			<persName coords=""><forename type="first">Karamuftuoglu</forename><surname>Vechtomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,508.20,588.14,24.84,8.74">TREC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
