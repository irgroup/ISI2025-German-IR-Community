<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.83,169.73,358.66,15.11">FDU at TREC 2007: opinion retrieval of Blog Track</title>
				<funder ref="#_6hh3b2h">
					<orgName type="full">NSF of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.89,203.64,45.52,10.48"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,214.17,203.64,75.59,10.48"><forename type="first">Bingqing</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName coords="1,300.17,203.64,40.04,10.48"><forename type="first">Lide</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName coords="1,351.05,203.64,84.21,10.48"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
						</author>
						<title level="a" type="main" coord="1,117.83,169.73,358.66,15.11">FDU at TREC 2007: opinion retrieval of Blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">883CFC03D06C7EA88510E0F9ABD3D82A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the opinion retrieval task at Blog Track 07. The system consisted of the preprocess part, the topic retrieval part and sentiment analysis part. In the topic retrieval part, we adopted pseudo-relevance feedback and a novel approach to form a modified query. In the sentiment analysis part, each blog post was given an opinion score based on the sentences contained in this post. The subjectivity of each sentence was predicted by a CME classifier. Then the blog posts were reranked based on the similarity given by the topic retrieval and the opinion score given by the sentiment analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The opinion retrieval task <ref type="bibr" coords="1,240.66,425.24,13.40,9.57" target="#b0">[1]</ref> was aimed to explore the information seeking behaviour in the blogosphere. The large scale test collection, the TREC Blog06 collection <ref type="bibr" coords="1,196.46,452.33,12.73,9.57" target="#b1">[2]</ref>, was used again in Blog Track 07.</p><p>Our approach to this task was a three-step process. A preprocess was first conducted to extract the content from the permalink HTML pages. Lucene<ref type="foot" coords="1,151.31,491.03,4.23,6.99" target="#foot_0">1</ref> was used to build the index on the preprocessed corpora. Then in the topic retrieval part, we retrieved the top 2000 blog posts for each topic. The expansion terms for a query were extracted by pseudo-relevance feedback. A machine learning approach was developed to select the expansion terms aiming at raising the MAP. In the sentiment analysis part, a CME classifier was trained to predict the subjectivity of each sentence in a blog post. Then a SVM classifier gave an opinion score for this blog post based on the sentence-analysis. Finally, all the blog posts were reranked based on the similarity given by the topic retrieval and the opinion score given by the sentiment analysis. The top 1000 blog posts were submitted.</p><p>The remainder of this paper is structured as follows. Section 2 provides an overview of the system. Section 3 describes the topic retrieval part. Section 4 describes the sentiment analysis part. Section 5 introduces the submitted runs and the evaluation result. Conclusions are made in section 6. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>The system was composed by the preprocess part, the topic retrieval part and the sentiment analysis part. The system architecture is shown in Figure <ref type="figure" coords="2,117.83,419.07,4.24,9.57" target="#fig_0">1</ref>.</p><p>The preprocess part was designed to extract the content of the permalink HTML pages, which would be discussed in section 2.1.</p><p>The topic retrieval part retrieved 2000 blog posts for each of the 50 topics. Pseudo-relevance feedback extracted expansion query terms from the initial retrieval result. The top t expansion terms together with the weight were generated from the top k returned documents. A SVM was trained to rerank these expansion terms.</p><p>The sentiment analysis gave each blog post an OpScore(opinion score). A CME classifier was trained to predict the subjectivity for each sentence in a blog post. This CME classifier was trained on the movie review data. Based on the sentence-level prediction, the OpScore for this blog post was predicted by a SVM classifier.</p><p>Combining the OpScore with the similarity by the topic-retrieval part, the 2000 blog posts were reranked and the top 1000 were selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpus and Preprocess</head><p>The TREC Blog06 collection contains the permalinks HTML pages, the feed file and the blog homepage. We only use the permalink HTML pages for the opinion retrieval task. These permalinks HTML pages were in different style and some of them were poorly structured, filled with noisy information.</p><p>For each blog post, we discarded the hyper-links, the script and the style information in the web page and filter all the html tags. Some html pages were damaged and we only filtered the html tags and hyper-links in those damaged-structure html pages.</p><p>Before the preprocess, the permalink HTML pages amounted to about 80G, after the preprocess the cleaned permalink HTML pages amounted to about 18G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Topic Retrieval</head><p>Based on the preprocessed corpora, index was build using Lucene. Pseudorelevance feedback modified the original query by adding expansion terms from the initial retrieval. Expansion terms were further selected using machine learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pseudo-Relevance feedback</head><p>For the vector space model, query expansion approach had been discussed to reformulate the query so that it could be closer to the term-weight vector space of relevant documents. The standard Rochio formulation <ref type="bibr" coords="3,413.00,400.59,14.29,9.57" target="#b3">[4]</ref> generated a modified query -→ q m as follows</p><formula xml:id="formula_0" coords="3,193.64,432.94,207.04,33.77">-→ q m = α -→ q + β |D r | ∀ -→ d j ∈Dr -→ d j - γ |D n | ∀ -→ d j ∈Dn -→ d j</formula><p>D r : set of relevant documents among the retrieved documents. D n : set of non-relevant documents among the retrieved documents. α, β, γ are constants.</p><p>For the pseudo-relevance feedback in our case, it was assumed that the top k documents from the initial retrieval made up of the relevant document set D r , the non-relevant document set D n was hard to define and omitted here. Then the query was reformed as follows</p><formula xml:id="formula_1" coords="3,117.83,573.94,358.65,114.30">-→ q m = -→ q + α ∀ -→ d j ∈Dr -→ d j = -→ q + α -→ d -→ q was the original query, -→ d j represented the term weight vector of doc- ument j, -→ d j = (w 1,j , w 2,j , • • • , w n,j ). And -→ d = ∀ -→ d j ∈Dr -→ d j = ∀ -→ d j ∈Dr (w 1,j , w 2,j , • • • , w n,j ) = (w 1 , w 2 , • • • , w n )</formula><p>w i,j was the term weight of word i in document j, and w i = w i,j was the term weight of word i in the local collection D r . We used a heauristic modified w i,j = tf i,j * idf i /sidf i , where sidf i was the idf value of word i in the local collection D r , while the idf i was the idf value of word i in the global collection. This formulation decreased the weight of those terms, which had similar distribution in the local document set D r and the global collection.</p><p>The vector -→ d contained the term weight of all the words. α = 0.5 max(w i )</p><p>was a factor, which normalized every term weight in -→ d and made any term weight lower than 0.5. We assumed that the weight of any expanded term should be less than the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Expanded Terms Reranked by SVM</head><p>We needed the top t terms together with the weight to form a modified query. This could be done by ranking all the term weight in -→ d to find the top t terms. However, we hoped to find out a machine learning approach for the expansion term selection. These two approaches were both tried in our submitted runs.</p><p>A SVM was trained to predict on the expanded terms. The advantage using a machine learning approach was that the expanded term selection could be conducted more reliable compared with ranking the terms by empirical expression. Our approach provided a method to generate the training data set, to tell whether one expanded term was more related to the topic than another expanded term.</p><p>The training set of instance-label pairs (x i , y i ) were generated from Blog Track 06. x i ∈ R n representing the feature vector of the expanded term i and y i is a label indicating the closeness of this term with the topic. SV M light was used to train a RBF regression module. The training data was generated as follows.</p><p>1. original query q was retrieved and evaluated by trec eval, the MAP referred as BaseM AP 2. expanded terms of this query were extracted. (t 1 , t 2 , • • • )</p><p>3. for the expanded term t i , build the feature vector x i 4. q and t i form a new query q i , which was retrieved and evaluated by trec eval, the MAP referred as T ermM AP i 5. y i = T ermM AP i BaseM AP , the pair (x i , y i ) was an instance of the training data</p><p>The feature vector of the expanded term t i , x i ∈ R n was defined as</p><formula xml:id="formula_2" coords="4,117.83,682.80,389.53,24.43">x i = (sumtf, avgT f, maxT f, idf, sdf, sidf, (idf -sidf ), sumtf idf, sumtf idf sidf )</formula><p>where for expanded term t i , sumtf was the sum of term frequency of every document in D r , avgT f was the average term frequency in D r , maxT f was the maximum term frequency in D r , idf was the idf in the global collection, sdf was the document frequency in D r , sidf was the idf in D r .</p><p>The label y i = T ermM AP i BaseM AP indicated the relationship of expanded term t i with the topic. The closeness of the expanded term was calculated by how much this term could help to raise the MAP when adding it to the original query. y i &gt; 1 meant this term was useful in raising the performance, while y i &lt; 1 meant this term was less related.</p><p>SV M Light was used to do the RBF regression. Blog Track 06 provided two kinds of assessment on the run, the opinion retrieval results and the topic-relevance results. Correspondingly, two kinds of regression module were trained on these two assessments. The module trained on the topicrelevance results was aimed to raise the topic-relevance MAP with no sentiment analysis feature. The module trained on the opinion retrieval results was aimed to raise the opinion retrieval MAP, which had sentiment analysis feature to some extense.</p><p>For a topic, empirically, the top 120 documents composed of the D r , the top 400 expanded terms were predicted and reranked. The top 200 expanded terms were finally added to the original query to form a new one. The top 2000 blog posts were returnedby retrieving this new modified query. Each blog post was assigned a similarity score Sim representing the relevance of this post with the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Sentiment Analysis</head><p>Sentiment Analysis in opinion retrieval task focused on the classification between the opinion blog post and non-opinion blog post. First, each sentence of a blog post was given a sentence score indicating the subjectivity of this sentence. Then, based on all the sentences in this blog post, an OpScore(opinion score) was given to indicate the subjectivity of this blog post by SVM. Finally, the OpScore given by the sentiment analysis and Sim(similarity) given by the topic retrieval was combined to form a final score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sentence Evaluation and Blog post Evaluation</head><p>For the sentence evaluation, each sentence was predicted by a CME classifier. The training data for the CME classifier was from the movie review data 2 . The subjectivity data set v1.0 of movie-review data contains 5000 subjective and 5000 objective processed sentences. The features for the CME classifier were unigram, bigram, whether this sentence contains words in opinion. The opinion word was detected by General Inquirer Lexicon<ref type="foot" coords="6,382.78,141.90,4.23,6.99" target="#foot_2">3</ref> .</p><p>For the blog post evaluation, a SVM classifier was trained to predict the OpScore(opinion score) for a blog post based on all the sentences in this blog post. The training data (x i , y i ) were generated from the Blog Track 06. The training data was opinioned relevant documents(labeled as y i = +1) and non-opinioned but relevant documents(labeled as y i = -1).</p><p>The feature x i was generated from all the sentences in the i -th blog post. A blog post was transformed into a vector. Each element in the vector corresponded to a sentence. Suppose there were l sentences in a blog post, each sentence got a sentence score describing the subjectivity or objectivity. The blog post could be represented as follows,</p><formula xml:id="formula_3" coords="6,159.24,302.12,269.65,24.97">-→ d O = (s 1 , s 2 , • • • , s l ), s i &gt; 0 sentence i is subjective s i &lt; 0 sentence i is objective</formula><p>Then, another two vector describing the subjectivity and the objectivity could be derived from</p><formula xml:id="formula_4" coords="6,155.49,347.17,277.16,93.94">-→ d O . --→ d Sub = (s 1 , s 2 , • • • , s l ), s i &gt; 0 sentence i is subjective s i = 0 sentence i is objective --→ d Obj = (s 1 , s 2 , • • • , s l ), s i = 0 sentence i is subjective s i &lt; 0 sentence i is objective</formula><p>A sentence was taken as relevant sentence if this sentence contained the term in the original query. The document was presented as follows</p><formula xml:id="formula_5" coords="6,144.23,485.92,299.67,23.90">-→ d T = (t 1 , t 2 , • • • , t l ), t i = 1 if sentence contain query term 0 otherwise</formula><p>Then, a fuzzy relevant sentence vector could be derived from -→ d T . If the previous two sentences contained the query term, this sentence could also be labeled as relevant sentence. </p><formula xml:id="formula_6" coords="6,120.61,575.60,195.22,18.35">-→ d F = (t 1 , t 2 , • • • , t l ), t i = 1 previous</formula><formula xml:id="formula_7" coords="7,123.81,284.26,255.31,54.97">|)(1 + |d T |) sim subscore relwin d T Sub • d F /(1 + |d Sub |)(1 + |d F |) sim objscore relbase d T Obj • d T /(1 + |d Obj |)(1 + |d T |) sim objscore relwin d T Obj • d F /(1 + |d Obj |)(1 + |d F |)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Similarity and Opinion Score</head><p>The opinion score(OpScore ∈ (-1, 1)) given by the SVM classifier was integrated with the similarity(Sim ∈ (0, 1)) given by the topic retrieval.</p><p>The opinion score was normalized to (0, 1) by a logistic function, the logistic opinion score(LogOpScore) was defined as</p><formula xml:id="formula_8" coords="7,204.55,447.21,179.03,24.43">y = 1 1 + e -λx , λ = 5 if x &lt; 0 λ = 3 if x &gt; 0</formula><p>The final score for a blog post was Score = LogOpScore * Sim, all the blog posts were reranked by the final score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Submission and Evaluation Results</head><p>We submitted 6 automatic runs, as follows:</p><p>• FDUNoOpTisd: A baseline run only using the pseudo-relevance feedback without SVM regression module</p><p>• FDUNOpRSVMT: the FDUNoOpTisd with SVM regression module trained on topic-relevance results</p><p>• FDUTisdOpSVM: the FDUNoOpTisd with SVM regression module trained on opinion retrieval results, this module has some feature of sentiment analysis</p><p>• FDUNoOpTSem: the FDUNoOpTisd run with sentiment analysis</p><p>• FDUTNRSVMSem: the FDUNOpRSVMT run with sentiment analysis</p><p>• FDUTOSVMSem: the FDUTisdOpSVM run with sentiment analysis The evaluation results of the 6 submitted runs are listed in the table 1 and table 2. All these submitted results were using query expansion techniques, so we added a "baseline" result for comparison. This "baseline" run didn't use any query expansion or sentiment analysis module. Our best run "FDUTisdOpSVM" is emphasized in the table.</p><p>From the table above, we can find that the query expansion approach using SVM to rank the expanded terms could get better performance than using the empirical expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We described our system in this paper. The opinion retrieval task required the combination of information retrieval techniques and the sentiment analysis approaches.</p><p>We developed a pseudo-relevance feedback approach by empirical query reformulation. A novel approach was developed to rerank the expanded terms by machine learning method. The sentiment analysis was based on sentence-level analysis. In future work, we intend to make a further exploration on the expansion approach using machine learning method and the sentiment classification of a blog post.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,224.58,334.61,145.14,9.57;2,118.40,126.79,357.51,191.76"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Architecture</figDesc><graphic coords="2,118.40,126.79,357.51,191.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,117.83,576.38,358.65,60.26"><head></head><label></label><figDesc>2 sentences contain query term 0 otherwise Features x i were generated from the vector d Sub , d Obj and d T , d F . The features we used are described as follows.</figDesc><table coords="7,123.81,129.19,329.05,167.39"><row><cell>Feature</cell><cell>Description</cell></row><row><cell>subscore relbase subscore relwin objscore relbase</cell><cell>d T Sub • d T d T Sub • d F d T Obj • d T</cell></row><row><cell>objscore relwin</cell><cell>d T Obj • d F</cell></row><row><cell>rel base cnt</cell><cell># relevant sentences</cell></row><row><cell>rel base cnt</cell><cell># fuzzy relevant sentences</cell></row><row><cell>relbase sub cnt</cell><cell># sentences both relevant and subjective</cell></row><row><cell>relbase obj cnt</cell><cell># sentences both fuzzy relevant and objective</cell></row><row><cell>relwin sub cnt</cell><cell># sentences both relevant and objective</cell></row><row><cell>relwin obj cnt</cell><cell># sentences both fuzzy relevant and objective</cell></row><row><cell cols="2">sim subscore relbase d T Sub • d</cell></row></table><note coords="7,266.86,284.26,57.92,10.77"><p>T /(1 + |d Sub</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,155.75,202.89,279.18,132.16"><head>Table 1 :</head><label>1</label><figDesc>Opinion Finding Result</figDesc><table coords="8,155.75,227.85,279.18,107.20"><row><cell>Run</cell><cell>MAP</cell><cell cols="2">R-prec b-Pref</cell><cell>P@10</cell></row><row><cell>baseline</cell><cell>0.2388</cell><cell>0.3011</cell><cell>0.3083</cell><cell>0.3680</cell></row><row><cell>FDUNoOpTisd</cell><cell>0.2992</cell><cell>0.3351</cell><cell>0.3357</cell><cell>0.4340</cell></row><row><cell>FDUNOpRSVMT</cell><cell>0.3178</cell><cell>0.3447</cell><cell>0.3498</cell><cell>0.4520</cell></row><row><cell>FDUTisdOpSVM</cell><cell cols="4">0.3179 0.3467 0.3501 0.4540</cell></row><row><cell>FDUNoOpTSem</cell><cell>0.3019</cell><cell>0.3382</cell><cell>0.3381</cell><cell>0.4460</cell></row><row><cell cols="2">FDUTNRSVMSem 0.3141</cell><cell>0.3475</cell><cell>0.3496</cell><cell>0.4620</cell></row><row><cell>FDUTOSVMSem</cell><cell>0.3143</cell><cell>0.3465</cell><cell>0.3499</cell><cell>0.4600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,155.75,369.59,279.18,132.16"><head>Table 2 :</head><label>2</label><figDesc>Topic Relevance Result</figDesc><table coords="8,155.75,394.55,279.18,107.20"><row><cell>Run</cell><cell>MAP</cell><cell cols="2">R-prec b-Pref</cell><cell>P@10</cell></row><row><cell>baseline</cell><cell>0.3927</cell><cell>0.4520</cell><cell>0.5222</cell><cell>0.6340</cell></row><row><cell>FDUNoOpTisd</cell><cell>0.4506</cell><cell>0.4744</cell><cell>0.5272</cell><cell>0.6320</cell></row><row><cell>FDUNOpRSVMT</cell><cell>0.4709</cell><cell>0.4888</cell><cell>0.5428</cell><cell>0.6520</cell></row><row><cell>FDUTisdOpSVM</cell><cell cols="4">0.4714 0.4889 0.5432 0.6540</cell></row><row><cell>FDUNoOpTSem</cell><cell>0.4355</cell><cell>0.4626</cell><cell>0.5113</cell><cell>0.6500</cell></row><row><cell cols="2">FDUTNRSVMSem 0.4484</cell><cell>0.4765</cell><cell>0.5228</cell><cell>0.6620</cell></row><row><cell>FDUTOSVMSem</cell><cell>0.4488</cell><cell>0.4768</cell><cell>0.5232</cell><cell>0.6620</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,134.42,714.25,103.96,7.86"><p>http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,134.42,707.04,243.43,7.86"><p>http://www.cs.cornell.edu/People/pabo/movie-review-data/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,134.42,659.59,160.34,7.86"><p>http://www.wjh.harvard.edu/ inquirer/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was partially supported by <rs type="funder">NSF of China</rs> under the grant of <rs type="grantNumber">60673038</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_6hh3b2h">
					<idno type="grant-number">60673038</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,140.26,310.97,336.23,9.57;9,140.25,324.52,336.23,9.57;9,140.25,338.07,21.82,9.57" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,189.87,324.52,195.29,9.57">Overview of the TREC-2006 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,415.35,324.52,56.06,9.57">TREC 2006</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,140.26,360.58,336.23,9.57;9,140.25,374.13,336.23,9.57;9,140.25,387.68,336.23,9.57;9,140.25,401.23,50.01,9.57" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<idno>TR-2006-224</idno>
		<title level="m" coord="9,321.95,360.58,154.53,9.57;9,140.25,374.13,222.76,9.57">The TREC Blog06 Collection : Creating and Analysing a Blog Test Collection</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">DCS Technical Report</note>
</biblStruct>

<biblStruct coords="9,140.26,423.75,336.23,9.57;9,140.25,437.30,94.28,9.57" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,359.89,423.75,116.60,9.57;9,140.25,437.30,31.05,9.57">Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="117" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,140.26,459.81,336.23,9.57;9,140.25,473.36,336.23,9.57;9,140.25,486.91,313.07,9.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,203.43,459.81,203.91,9.57">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rochio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,175.11,473.36,301.37,9.57;9,140.25,486.91,81.37,9.57">The SMART Retrieval System-Experiments in Automatic Document Processing</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</editor>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Pretince Hall Inc</publisher>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
