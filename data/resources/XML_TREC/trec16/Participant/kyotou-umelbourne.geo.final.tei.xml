<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,94.40,115.29,423.14,15.13;1,280.18,137.21,51.65,15.13">Passage Retrieval with Vector Space and Query-Level Aspect Models</title>
				<funder>
					<orgName type="full">Japan Society for the Promotion of Science</orgName>
					<orgName type="abbreviated">JSPS</orgName>
				</funder>
				<funder>
					<orgName type="full">Australian Research Council&apos;s Center for Perceptive and Intelligent Machines in Complex Environments</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,168.53,171.01,71.11,10.51"><forename type="first">Raymond</forename><surname>Wan</surname></persName>
							<email>rwan@kuicr.kyoto-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Bioinformatics Center</orgName>
								<orgName type="department" key="dep2">Institute for Chemical Research</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<postCode>611-0011</postCode>
									<settlement>Gokasho, Uji</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.09,171.01,41.96,10.51"><forename type="first">Vo</forename><surname>Ngoc</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.33,171.01,92.64,10.51"><forename type="first">Hiroshi</forename><surname>Mamitsuka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Bioinformatics Center</orgName>
								<orgName type="department" key="dep2">Institute for Chemical Research</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<postCode>611-0011</postCode>
									<settlement>Gokasho, Uji</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,94.40,115.29,423.14,15.13;1,280.18,137.21,51.65,15.13">Passage Retrieval with Vector Space and Query-Level Aspect Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EC2D446AA967815D58AFAD4953BAB950</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report describes the joint work by Kyoto University and the University of Melbourne for the TREC Genomics Track in 2007. As with 2006, the task for this year was the retrieval of passages from a biomedical document collection. The overall framework of our system from 2006 remains unchanged and is comprised of two parts: a paragraph-level retrieval system and a passage extraction system. These two systems are based on the vector space model and a probabilistic word-based aspect model, respectively. This year, we have adopted numerous changes to our 2007 system which we believe corrected some problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Kyoto University and the University of Melbourne participated together for the TREC Genomics Track in 2007. As with last year's task, this year's aim was to retrieve passages from a full-text HTML collection of biomedical journals (see <ref type="bibr" coords="1,195.50,468.35,83.53,9.59" target="#b4">Hersh et al. [2006]</ref> for further details). While the collection this year remains unchanged, new queries were employed as well as modifications to the scoring scheme for passages.</p><p>Last year, we introduced our system for passage retrieval made of a paragraph-level retrieval system and a passage extraction system <ref type="bibr" coords="1,219.06,508.99,79.31,9.59" target="#b11">[Wan et al., 2006]</ref>. Since our performance last year was unsatisfactory, we re-designed parts of the system using what we learned from 2006. In Section 2, we begin with a brief description of our method. Section 3 describes our 2007 system by comparing against our 2006 system. Section 4 covers our three officially submitted runs and an additional set of runs that was performed after our results were released. Finally, we summarize this report in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>The main task is to select passages from a collection of biomedical articles which are relevant to a query. Both the 2006 and 2007 tracks used the same collection of full papers from HighWire Press. Each article is in HTML and segmented into paragraphs (as indicated by the HTML &lt;p&gt; tags). Passages are sections of contiguous characters that do not include any of these paragraph boundaries. Performance is measured in terms of aspect, document, and passage retrieval.</p><p>Our method consists of two parts working together: a paragraph-level retrieval system and a passage extraction system. Based on the vector space model (VSM), the paragraph-level retrieval system constructs an index off-line. When given a query, a ranked list of relevant paragraphs are identified and passed to the passage extraction system. By using scores obtained from a probabilistic word-based aspect model derived from word-pair co-occurrences, the contiguous sequence of words (a passage) from each paragraph that is most relevant to the query is returned. The paragraph score and the passage score are aggregated for passage re-ranking as the final step.</p><p>In the remainder of this section, we describe the two parts of this method in general terms. Implementation details are deferred to the section after.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>We begin by defining some notation. The requirements of the Genomics Track makes it necessary to view the document collection as having a hierarchical structure. The document collection D is composed of a set of documents d, which are each made up of paragraphs r ∈ R. We assume that within a paragraph r, there is at most one relevant passage p. The set of words in D is W and the set of words that form a query q is Q. All words in the query are assumed to also be in the collection (i.e., Q ∈ W ).</p><p>A word is represented as i for a query and j for a paragraph, such that q = {i} and r = {j}. The paragraph frequency or the number of paragraphs that contain j is f j . The within paragraph frequency of word j in paragraph r is f r,j . Note that our terminology differs slightly from the information retrieval field since we are operating primarily at the paragraph-level. That is, even though the collection is based on articles, we view it as a collection of paragraphs.</p><p>The word-based aspect model makes use of the co-occurrence of two words. We make a distinction between the co-occurrence n(i, j) and the co-occurrence scores c(i, j). The co-occurrence n(i, j) is the observed frequency of appearances of both i and j in the same paragraph throughout D. These values are used as input into our aspect model. The co-occurrence scores are the outputs from this process. In both matrices, n(i, j) and c(i, j) are undefined when i = j. The maximum co-occurrence score is denoted c max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Vector Space Model</head><p>The paragraph-level retrieval engine employed as the first component of our system has two functions: a) to generate the primary statistics needed for calculating the co-occurrence scores between pairs of terms, and b) to produce the first-round result list to each query, which will be further refined by the aspect model. The major function is the second one, where each original query is processed as a ranked query using the impact-based ranking approach.</p><p>The impact-based ranking approach is essentially a variation of the vector space model, where each distinct term of the collection is represented as a dimension in the n-dimension vector space (where n is the number of distinct terms in the collection). In this space, each document or query is represented by a vector, whose coordinates in a dimension is interpreted as the "importance" of the corresponding term in the document (or query). Traditionally, the coordinates are computed in a quantitative way and are floatingpoint values, and the level of similarity between a document and a query is defined as the cosine of the angle between the two respective vectors. In the impact-based approach, however, the coordinates (called impacts) are produced in a qualitative manner, and are integers values between 0 and (in this case) 8. Moreover, the level of similarity is now defined as the scalar product of the document and the query vector. <ref type="bibr" coords="2,470.93,624.49,69.00,9.59;2,72.00,638.04,29.08,9.59" target="#b0">Anh and Moffat [2005]</ref> describes the motivations and the details behind impact-based ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Aspect Model</head><p>The aspect model (also, latent semantic analysis) has been proposed by others to associate words to documents <ref type="bibr" coords="2,101.45,702.41,104.32,9.59" target="#b2">[Deerwester et al., 1990</ref><ref type="bibr" coords="2,205.78,702.41,99.68,9.59" target="#b6">, Hofmann et al., 1998</ref>]. As summarized by <ref type="bibr" coords="2,406.78,702.41,105.59,9.59" target="#b2">Deerwester et al. [1990]</ref>, one-mode factor analysis consists of a matrix of associations between all pairs of a single type of object. Deerwester et al. applies two-mode factor analysis where a matrix of two different types of objects is constructed.</p><p>In their case, it is a term by document matrix which indicates the number of times term i occurs in document j. Using singular value decomposition, they reduce this matrix into k-dimensional space, and in doing so, show how latent semantic analysis (LSA) can be useful for document retrieval. Probabilistic latent semantic analysis (PLSA) <ref type="bibr" coords="3,146.65,143.48,75.80,9.59" target="#b5">[Hofmann, 2001]</ref> adds a probabilistic model to this earlier work by employing an iterative approach using the Expectation-Maximization (EM) algorithm <ref type="bibr" coords="3,348.26,157.03,98.88,9.59" target="#b3">[Dempster et al., 1977]</ref>.</p><p>For our method, we return to one-mode factor analysis and combine this with PLSA. Instead of constructing a matrix of documents against documents, we build a matrix of words against words. We reduce this matrix to k clusters or latent states, where k is much less than the number of unique words in the collection (i.e., k |W |). The co-occurrence score c(i, j) for the word pair (i, j) is obtained by summing across all of the latent states Z, which is of size</p><formula xml:id="formula_0" coords="3,183.55,238.10,356.45,55.23">|Z| = k: c(i, j) = ∑ z∈Z p(i|z)p(j|z)p(z),<label>(1)</label></formula><p>The parameters of this aspect model can be estimated using the EM algorithm by iterating between the following E-step and M-step:</p><formula xml:id="formula_1" coords="3,88.94,340.96,451.06,44.73">E-step: p(z|i, j) = p(i|z)p(j|z)p(z) ∑ z ∈Z p(i|z )p(j|z )p(z )<label>(2)</label></formula><p>M-step:</p><formula xml:id="formula_2" coords="3,237.86,400.39,302.14,96.05">p(i|z) = ∑ j∈W n(i, j)p(z|i, j) (3) p(j|z) = ∑ i∈Q n(i, j)p(z|i, j) (4) p(z) = ∑ i∈Q ∑ j∈W n(i, j)p(z|i, j). (<label>5</label></formula><formula xml:id="formula_3" coords="3,535.76,474.41,4.24,9.59">)</formula><p>Initial values are generated at random using a uniform distribution. The output from the word-based aspect model (AM) is a set of scores c(i, j) such that c(i, j) = c(j, i), where i = j. Instead of assigning a score to c(i, j) when i = j, we consider variations on the maximum co-occurrence score c max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TREC 2007 System Description</head><p>The organization of our system this year is shown in Figure <ref type="figure" coords="3,339.24,590.84,4.09,9.59" target="#fig_0">1</ref>. The inputs to the system are the document collection D and a query q. The output is a ranked list of passages. In the figure, "indexing" and "querying" refer to the paragraph-level retrieval system, while "passage extraction" and "score derivation" are parts of the passage extraction system. Re-ranking of passages by aggregating their paragraph and passage scores is performed as the final step, "score merging".</p><p>The parts of the paragraph-level retrieval system are self-explanatory. Score derivation refers to the use of the aspect model to assign scores to pairs of words. Passage extraction uses these scores to identify the words in the paragraph that are most relevant to the query. After the passages are extracted, as a requirement of the Genomics Track, their character positions in their respective documents are calculated using the Smith-Waterman sequence alignment algorithm <ref type="bibr" coords="3,283.18,712.78,124.39,9.59" target="#b10">[Smith and Waterman, 1981]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Differences</head><p>The main differences between our two systems are shown in Table <ref type="table" coords="4,363.00,406.47,5.45,9.59" target="#tab_0">1</ref> (see <ref type="bibr" coords="4,391.16,406.47,75.02,9.59" target="#b11">Wan et al. [2006]</ref> for a description of our last year's system.). After reporting our 2006 results, there were bugs in our system that were found and corrected for our 2007 system. We believe these problems affected the reliability of the co-occurrence scores produced by the aspect model. The most significant difference this year is how the aspect model is used. Previously, the scores c(i, j) were obtained off-line. Using last year's stemming rules, there were 1,299,308 unique words. At this size, the corresponding matrix and associated data structures for the aspect model would require significant amounts of memory. We address this issue by selecting a co-occurrence matrix of size n by n, where n |W |. Last year, we chose all words that appeared in at least 1% of the collection of 162,259 articles (n = 13,895).</p><p>While last year's method has the advantage of employing the aspect model off-line, it was found that much of the co-occurrence matrix was unused. Since the purpose of the matrix is to score a paragraph against a query in order to trim it to a more concise passage, applying this step on-line would be more sensible. Thus, the dimensions of the matrix chosen this year was m by n, where m = |Q|. Moreover, if one of the dimensions of the matrix is reduced, then the other dimension can be increased to |W |. This idea forms the basis of our implementation this year. The co-occurrence matrix is calculated on-line on a perquery basis instead of a per-collection basis. Unfortunately, this approach would make real-time querying infeasible.</p><p>Last year, we investigated both paragraph and document-level indexing in the retrieval system. Our results showed that document-level yielded poor effectiveness results. Because of this, we focused exclusively on paragraph-level retrieval.</p><p>We made extensive use of external databases in 2006 to expand the query through the addition of synonyms. We used the Biomedical abbreviation server, Entrez Gene, and Medical Subject Headings to expand query terms for both querying and passage extraction (see <ref type="bibr" coords="5,325.27,75.74,81.76,9.59" target="#b1">Chang et al. [2002]</ref>, <ref type="bibr" coords="5,414.08,75.74,87.82,9.59" target="#b8">Maglott et al. [2005]</ref>, <ref type="bibr" coords="5,508.96,75.74,30.91,9.59;5,72.00,89.29,54.28,9.59" target="#b9">Nelson et al. [2004]</ref> for details about these sources of biological synonyms). While we no longer use these ideas this year, they remain possible options for our system in the future.</p><p>However, words are parsed in the same way as last year. A word is a contiguous sequence of alphabetic or numeric characters, but not a mix of both. So, "CD44" and "CD-44" are both divided into the two words "CD" and "44". Case-folding is also employed, as well as a stop-word list of 471 words. Instead of using the Lovins stemming algorithm <ref type="bibr" coords="5,197.09,157.03,63.16,9.59" target="#b7">[Lovins, 1968]</ref>, we chose a simplified algorithm which considers only regular endings such as -s, -es, -ed, -ly, and -ing.</p><p>In addition to these differences, the formula used for scoring passages was completely changed, as we describe next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scoring Passages</head><p>We re-designed the scoring mechanism so that it more closely resembles work by others in information retrieval (see <ref type="bibr" coords="5,132.59,262.05,87.66,9.59" target="#b12">Witten et al. [1999]</ref> for details). The basic idea remains the same. Instead of calculating a single value (such as the cosine similarity) between the paragraph and the query, our aim is to assign a score to each paragraph word relative to the query words. If the two words match exactly, then some constant score is added to the paragraph. Otherwise, a smaller score is added for a mismatch. A passage is obtained from the paragraph by isolating the highest scoring section.</p><p>Last year's method for paragraph scoring involved breaking the paragraph into sections, where each section begins or ends with punctuation marks such as full stops and semi-colons. Then, every possible contiguous group of one or more sections is tested against the query. At the TREC 2006 conference, it was noticed that most groups extracted only one passage per paragraph. As our approach yielded little benefit and was too time consuming, we restrict each paragraph to produce only one passage this year. Punctuation marks are still used, but their use is deferred until later when character positions are calculated.</p><p>The score for a word j in paragraph r against the query q is defined as:</p><formula xml:id="formula_4" coords="5,209.36,429.64,326.40,33.18">s(q, r, j) = |R| f j × (1 + log f r,j ) ∑ i∈q c(i, j). (<label>6</label></formula><formula xml:id="formula_5" coords="5,535.76,440.97,4.24,9.59">)</formula><p>where |R| is the number of paragraphs in the collection and c(i, j) is the score between two words i and j. We investigated two methods for calculating this score: Methods 1 and 2. Each method consists of two cases based on whether or not i = j.</p><formula xml:id="formula_6" coords="5,158.29,519.47,295.42,86.64">Method 1 c(i, j) = { c max if i = j c(i, j) otherwise (7) Method 2 c(i, j) = { ln(1 + |R| f i ) × c max if i = j ln(1 + |R| f i ) × c(i, j) otherwise (8)</formula><p>The requirement of both methods is to keep the values between the two cases relatively close. If the constant score for a match is much larger than a mismatch, then the usefulness of the co-occurrence scores is minimized and the scoring scheme resembles a simple count of terms that appear in both the paragraph and the query. Because of this, we keep the match score to be the maximum value in the entire co-occurrence table (c max ). Method 1 is our baseline where c max and c(i, j) are used without modification as the match and mismatch scores, respectively. Method 2 applies a scaling factor based on the inverse document frequency (IDF) of the query term f i .</p><p>If each paragraph word's score was used immediately for isolating a passage, then each passage would be the longest contiguous sequence of words whose endpoints are words also found in the query (since they would have the highest scores). To rectify this, we update the score of each word j using its neighboring scores. We simply added half the score of each word's two immediate neighboring words and one quarter of the score of the two words which are two words away j, as depicted by Equation ( <ref type="formula" coords="6,429.33,129.94,3.86,9.59">9</ref>). In the future, we hope to investigate scoring mechanisms which employ a multiplication factor which decreases with increasing distance from j. s (q, r, j) = s(q, r, j) + 1 2 (s(q, r, j -1) + s(q, r, j + 1)) + 1 4 (s(q, r, j -2) + s(q, r, j + 2)) ( <ref type="formula" coords="6,531.52,196.95,4.24,9.59">9</ref>)</p><p>With these updated scores, we obtain a passage by locating the two highest scoring words in the paragraph to act as endpoints of the passage. Note that "highest scoring words" can be any word and not necessarily words that are also query terms. The score of this passage p against the query q is divided by its length in words, according to Equation (10):</p><formula xml:id="formula_7" coords="6,243.17,282.11,292.29,33.18">s(q, p) = 1 |p| × ∑ j∈p s (q, j) . (<label>10</label></formula><formula xml:id="formula_8" coords="6,535.46,293.43,4.54,9.59">)</formula><p>Since punctuation marks are more natural boundaries for English texts, the final passage returned extends both endpoints to the nearest punctuation mark. However, the score of the passage excludes these extra characters. The last step is to map each passage to character positions using the Smith-Waterman algorithm. <ref type="bibr" coords="6,101.53,411.12,54.52,9.59">et al. [2006]</ref> reports that the collection consists of 12,641,127 legal spans (sequences of characters which did not contain any HTML paragraph tags). However, when indexed by our paragraph-level retrieval system using the case folding, stop-word list, and stemming rules described above, the number of paragraphs was |R| = 10,234,783. Thus, many documents were "empty" according to our system and were excluded. The number of unique words was W = 1,480,399. Both of these values are larger than last year due in part to our simplified stemming algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hersh</head><p>For all of the experiments described in this section, the parameters for the aspect model remained unchanged. The number of clusters was k = 100 clusters. The stopping condition of the EM algorithm was either a maximum number of iterations of 50 or when the difference in maximum likelihood between two consecutive iterations differed less than 0.0001. The Smith-Waterman algorithm was used using 1, -1, and 0 for the scores for a match, mismatch, and a gap, respectively.</p><p>Three submissions were evaluated as part of our participation in the Genomics Track. Also, we performed an additional set of runs which examined the effect from several variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Submitted Runs</head><p>The parameters for our official runs are shown in Table <ref type="table" coords="6,314.34,624.53,4.09,9.59" target="#tab_1">2</ref>. We assign a name to each run in the first column. While the Genomics Track requires 1,000 results per query, our paragraph retrieval system can pass more than 1,000 paragraphs to the passage extraction system. The number of results provided is shown in the second column. Two scoring mechanisms were described in the previous section, and both were applied, as shown in the third column.</p><p>Both parts of our system assign a unique score. The paragraph-level retrieval system assigns a score to the entire paragraph. The passage retrieval system, though, assigns a score to the returned passage. These  <ref type="table" coords="7,98.74,294.82,4.24,9.59">3</ref>: The results for our three official runs and additional statistics from all 66 official runs submitted to the TREC Genomics track for evaluation.</p><p>two scores are normalized and weighted such that the total weight is always 100%. A run with a weight of 100% is using only one of the systems to rank the final results.</p><p>Table <ref type="table" coords="7,115.74,366.51,5.45,9.59">3</ref> shows the results from our official runs as well as some statistics covering all 66 runs that were submitted for pooled evaluation. Retrieval effectiveness was measured in terms of document, aspect, and passage retrieval mean average precision (MAP) across all 36 queries using at most 1000 passages per query. Two methods of calculating passage retrieval were used. "Passage" is identical to last year's scheme, while "Passage2" is the official passage retrieval measure for this year.</p><p>Out of our three runs, kyoto1 performed the best, but only average compared with runs by other groups. Our document retrieval performance was close to the median, while our other three scores were well below. The performance of the other two runs were significantly worse. From these results, we hypothesized that the cause of the problem with these two runs were the number of results from VSM, the scoring method, or the weight for score merging. We examined these three parameters with an additional set of runs which we call Varied-Method-2.</p><p>Also, after the submission of our official runs, we realized that there were problems in our implementation of the passage extraction system. There were errors in the scoring mechanism used by the passage extraction system and the alignment of passages to character positions using the Smith-Waterman algorithm. These problems were fixed and the changes are reflected in Varied-Method-2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Additional Runs</head><p>A additional set of runs called Varied-Method-2 varied three different parameters. The results for the four measures are shown in Figure <ref type="figure" coords="7,229.30,620.56,5.45,9.59" target="#fig_1">2</ref> with MAP plotted against the VSM percentage (0% means that AM is used exclusively to rank passages). Each of the three lines in each graph indicate the number of results supplied by the paragraph-level retrieval system. The horizontal gray line indicates the median MAP as reported in Table <ref type="table" coords="7,148.96,661.21,4.09,9.59">3</ref>.</p><p>Our results for our official runs are also plotted on the graphs even though they are obtained from a system that had errors in it and thus, may not be comparable. Unfortunately, it would appear that fixing the problems actually degraded our system's performance. The only noticeable improvement was our Passage2 results. Combining the results of Table <ref type="table" coords="8,248.93,518.92,5.45,9.59">3</ref> and the trend of all of the lines, kyoto3 should perform better than kyoto2. Since it does not, it implies that Method 1 performs worse and using the inverse document frequency seems required.</p><p>Excluding the Passage measure, all of our measures approach or slightly pass the median. The results show that an increase in the VSM percentage yields improved MAP in all cases. The optimal percentage appears to be around 95% or 100%. That is, the scores from the aspect model adversely affect the final ranking and are worse than the scores provided by the impact-based vector space model. Also, having less results from the VSM is better since the dotted line always performs the best in all four graphs. When more results are available to the passage extraction system, its scoring scheme moves irrelevant paragraphs into the top 1,000 passages for scoring, reducing our effectiveness.</p><p>In this report, we have described our work for the TREC 2007 Genomics Track. The two most notable changes to our system compared to last year was a shift to a query-based, on-line aspect model and a change in the passage scoring mechanism. Overall, our performance is average compared to other participants with MAP scores close to the median. An additional set of runs with a corrected system show that, unfortunately, our effectiveness has worsened slightly.</p><p>It would appear that the weight attributed to the VSM or the AM is one of the most significant factors affecting our method. The ranking provided by the VSM seems more useful, indicating that more work is required on the scoring regime used by the AM.</p><p>In the future we wish to examine both parts of the system more closely. So far, we have not investigated the effect from varying the parameters of the paragraph-level retrieval system. Variations, such as stemming rules, could have a noticeable effect on passage retrieval effectiveness. As for the aspect model, we have not properly evaluated varying values for the many parameters, such as the the number of latent states. Other future considerations include reducing the running time and the use of external biological databases to improve effectiveness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,72.00,210.01,467.94,9.59;4,72.00,223.55,468.02,9.59;4,72.00,237.10,48.16,9.59"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our system includes a vector space model and an aspect model which include four components: indexing, querying, passage extraction, and score derivation. A final score merging steps performs passage re-ranking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,100.39,485.67,411.11,9.59"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Mean average precision versus VSM percentage for the three sets of additional runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,126.49,261.30,359.03,100.60"><head>Table 1 :</head><label>1</label><figDesc>Differences between our 2006 and 2007 systems.</figDesc><table coords="4,126.49,261.30,359.03,77.74"><row><cell>Feature</cell><cell>2006 System</cell><cell>2007 System</cell></row><row><cell>Aspect model</cell><cell cols="2">collection-level (off-line) query-level (on-line)</cell></row><row><cell>Indexing level</cell><cell>article/paragraph</cell><cell>paragraph only</cell></row><row><cell>Look-up to external databases</cell><cell>yes</cell><cell>no</cell></row><row><cell>Stemming algorithm</cell><cell>Lovins</cell><cell>simplified stemming</cell></row><row><cell>Number of passages/paragraph</cell><cell>&gt; 1</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,72.00,74.66,355.61,229.75"><head>Table 2 :</head><label>2</label><figDesc>The three official runs submitted by our group.</figDesc><table coords="7,72.00,74.66,355.61,229.75"><row><cell>ID</cell><cell cols="3">Number of results Scoring VSM:AM from VSM method</cell></row><row><cell>kyoto1</cell><cell>1000</cell><cell>2</cell><cell>100 0</cell></row><row><cell>kyoto2</cell><cell>5000</cell><cell>2</cell><cell>0 100</cell></row><row><cell>kyoto3</cell><cell>5000</cell><cell>1</cell><cell>50 50</cell></row><row><cell>ID</cell><cell cols="3">Document Aspect Passage Passage2</cell></row><row><cell>kyoto1</cell><cell>0.1892</cell><cell>0.1208 0.0474</cell><cell>0.0209</cell></row><row><cell>kyoto2</cell><cell>0.1191</cell><cell>0.0302 0.0235</cell><cell>0.0054</cell></row><row><cell>kyoto3</cell><cell>0.1022</cell><cell>0.0312 0.0204</cell><cell>0.0065</cell></row><row><cell>Minimum</cell><cell>0.0329</cell><cell>0.0197 0.0029</cell><cell>0.0008</cell></row><row><cell>Median</cell><cell>0.1897</cell><cell>0.1311 0.0565</cell><cell>0.0377</cell></row><row><cell>Mean</cell><cell>0.1862</cell><cell>0.1326 0.0560</cell><cell>0.0398</cell></row><row><cell>Maximum</cell><cell>0.3286</cell><cell>0.2631 0.0976</cell><cell>0.1148</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements: We thank <rs type="person">Ichigaku Takigawa</rs> (<rs type="affiliation">Kyoto University</rs>) for helpful discussions about the aspect model. RW was supported by a postdoctoral fellowship from the <rs type="funder">Japan Society for the Promotion of Science (JSPS)</rs>. VNA was supported by the <rs type="funder">Australian Research Council's Center for Perceptive and Intelligent Machines in Complex Environments</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,72.00,400.62,468.00,8.76;9,82.91,412.58,346.99,8.76" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,175.31,400.62,180.12,8.76">Simplified similarity scoring using term ranks</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Anh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,373.06,400.71,166.94,8.55;9,82.91,412.67,252.80,8.55">Proc. 28th ACM International Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>28th ACM International Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="226" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,432.72,468.01,8.76;9,82.91,444.67,371.13,8.76" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,249.00,432.72,250.15,8.76">Creating an online dictionary of abbreviations from MEDLINE</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,509.26,432.81,30.75,8.55;9,82.91,444.76,194.60,8.55">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="612" to="620" />
			<date type="published" when="2002-12">November-December 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,464.82,467.94,8.76;9,82.91,476.77,312.97,8.76" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,391.59,464.82,144.51,8.76">Indexing by latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,82.91,476.86,219.76,8.55">Journal of the American Society of Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,496.91,468.01,8.76;9,82.91,508.87,188.15,8.76" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,228.90,496.91,261.03,8.76">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,498.69,497.00,41.32,8.55;9,82.91,508.96,110.10,8.55">Journal of the Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,529.01,468.01,8.76;9,82.91,540.96,211.98,8.76" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,307.46,529.01,151.32,8.76">TREC 2006 Genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">K</forename><surname>Rekapalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,479.08,529.10,60.93,8.55;9,82.91,541.05,138.52,8.55">Proc. 15th Text Retrieval Conference (TREC 2006)</title>
		<meeting>15th Text Retrieval Conference (TREC 2006)</meeting>
		<imprint>
			<date type="published" when="2006-11">November 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,561.10,467.99,8.76;9,82.91,573.06,96.83,8.76" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,127.55,561.10,252.61,8.76">Unsupervised learning by probabilistic latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,388.80,561.19,72.24,8.55">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="177" to="196" />
			<date type="published" when="2001-02">January-February 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,593.20,467.98,8.76;9,82.91,605.16,250.39,8.76" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,245.30,593.20,105.57,8.76">Learning from dyadic data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,370.43,593.29,169.55,8.55;9,82.91,605.25,156.20,8.55">Proc. 11th Conference on the Advances in Neural Information Processing Systems</title>
		<meeting>11th Conference on the Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="466" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,625.30,468.00,8.76;9,82.91,637.25,76.64,8.76" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,131.32,625.30,156.42,8.76">Development of a stemming algorithm</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B</forename><surname>Lovins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,298.65,625.39,223.79,8.55">Mechanical Translation and Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="22" to="31" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,657.39,467.99,8.76;9,82.91,669.35,154.43,8.76" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,279.23,657.39,196.56,8.76">Entrez Gene: Gene-centered information at NCBI</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Maglott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ostell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">D</forename><surname>Pruitt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tatusova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,484.87,657.48,55.12,8.55;9,82.91,669.44,34.70,8.55">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2005-01">January 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,689.49,467.94,8.76;9,82.91,701.44,457.09,8.76;9,82.91,713.40,52.30,8.76" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,364.37,689.49,175.57,8.76;9,82.91,701.44,192.80,8.76">The MeSH translation maintenance system: Structure, interface design, and implementation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schopen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-L</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Arluk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,299.59,701.53,209.66,8.55">Proc. 11th World Congress on Medical Informatics</title>
		<meeting>11th World Congress on Medical Informatics</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="67" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,76.36,468.00,8.76;10,82.91,88.31,79.97,8.76" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,209.35,76.36,199.74,8.76">Identification of common molecular subsequences</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Waterman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,418.16,76.45,117.66,8.55">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="195" to="197" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,109.24,467.99,8.76;10,82.91,121.19,457.09,8.76;10,82.91,133.15,212.80,8.76" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,297.54,109.24,242.45,8.76;10,82.91,121.19,66.20,8.76">Combining vector-space and word-based aspect models for passage retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Anh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Takigawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mamitsuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,357.45,121.28,182.55,8.55;10,82.91,133.24,21.44,8.55">Proc. 15th Text Retrieval Conference (TREC 2006)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>15th Text Retrieval Conference (TREC 2006)</meeting>
		<imprint>
			<date type="published" when="2006-11">November 2006</date>
			<biblScope unit="page" from="500" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,154.07,414.08,8.76" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="10,230.17,154.16,81.94,8.55">Managing Gigabytes</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
