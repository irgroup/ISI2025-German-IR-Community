<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,146.92,101.71,318.16,16.17">MultiText Legal Experiments at TREC 2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,101.75,137.85,78.99,6.50"><forename type="first">Stefan</forename><surname>BÃ¼ttcher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,190.00,137.85,103.93,6.50"><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.03,137.85,100.94,6.50"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,413.96,137.85,96.29,6.50"><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.23,151.80,94.92,6.50"><forename type="first">David</forename><forename type="middle">R</forename><surname>Cheriton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,146.92,101.71,318.16,16.17">MultiText Legal Experiments at TREC 2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3FA3FF71EB8E30823F0658C256002C24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For the legal track we used the Wumpus search engine and investigated several methods that have proven successful in other domains, including cover density ranking and Okapi BM25 ranking. In addition to the traditional bag-of-words model we used boolean terms and character 4-grams. Pseudo-relevance feedback was eected using logistic regression on character 4-grams. Some runs specically excluded documents returned by the boolean query so as to increase the number of such documents in the pool. While our runs were all marked as manual, this was only because the process was not fully automated and several tuning parameters were set after we viewed the data; no data-specic tuning was performed in conguring the system for our runs. Our best performing runs used a combination of all of the above-mentioned techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction 2 Legal Track</head><p>For the legal track, we investigated several primitive approaches that have worked well in other domains, and combinations of approaches (combination itself being an approach that has worked well elsewhere <ref type="bibr" coords="1,116.57,563.23,39.62,6.64" target="#b4">[LBCC04,</ref><ref type="bibr" coords="1,159.51,563.23,23.42,6.64" target="#b5">LC06]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Legal Retrieval Methods</head><p>The following is a brief description and rationale for each run. wat2nobool</p><p>One of the goals of the legal track is to compare boolean vs non-boolean information retrieval. To better understand this dierence the wat1fusion run excludes all documents matched by the boolean query run. This is done separately for each query due to the possibility of a document being returned for more than one query. The intent of this approach was to explicitly give high rank to relevant documents that</p><p>were not identied at all by the boolean query.</p><p>wat3desc </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Requested</head><p>Text Field wat3desc "Zmem" , "memb" , "embe" , "mber" , "bers" , "ersh" , "rshi" , "ship" , "hipZ" , "ipZa" , "pZan" , "Zand" , "ando" , "ndor" , "dorZ" , "orZp" , "rZpa" , "Zpar" , "part" , "arti" , "rtic" , "tici" , "icip" ,....,"estZ" Final Query Field wat9boolgram "tradeZorganiz" , "Ztra" , "trad" , "rade" , "adeZ" , "deZo" , "eZor" , "Zorg" , "orga" , "rgan" , "gani" , "aniz" , "nizZ" , "tradeZassoc" , "Ztra" , "trad" , "rade" , "adeZ" , "deZa" , "eZas" , "Zass" ,..., "nceZ" Feedback Method wat4feed "dxxe" ,"xckk" ,"irzp" ,"ticu" ,"ztel" ,"geme" ,"oves" ,"sxuu" ,"alty" ,"asua" ,"szys" ,"pzzn" ,"zxkd" ,"tzyf" ,"zo" ,"mzco" ,"elxw" ,"lxwh" ,"ppar" ,"oned" ,"appa" ,"ot" ,"xuzc" ,"gnsz" ,"szyf" ,"paym" ,"yxxu",...,"szsa wat4feed</p><p>We implemented a new pseudo feedback method for the legal track. For feedback, we took the top-scoring 20 documents from each run and assumed them to be relevant. We took the lowest-scoring 20 documents (at the depth returned by the boolean query: the value of the FinalB eld) and assumed them to be non-relevant. The documents were parsed into overlapping character 4-grams and logistic regression was used to determine the 4-grams most associated with relevant documents. These 4-grams were used as the query in a BM25 run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>wat5nofeed</head><p>A fusion of runs wat2nobool, wat3desc, wat6qap, wat7bool, wat8gram. The fusion of runs was done using the CombMNZ combination method. This run is almost the same as the wat1fusion but wat4feed</p><p>was not included for combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>wat6qap</head><p>A relaxed version of the boolean run. This run was ranked using cover density ranking. The approach that MutliText has used with success over the years for IR and QA[CCKL00, CCL01] that searches for short intervals of text containing important terms from the query. We the run relaxed because the highest-level disjuncts (or conjuncts) from the boolean queries are removed. For example, the query ("smoke" or "cigarette") and ("girl" or "boy") was considered to have two terms:</p><p>("smoke" or "cigarette") ("girl" or "boy") wat7bool This is our boolean run. The run is ranked with by proximity-ranked <ref type="bibr" coords="2,403.51,297.08,28.54,6.64" target="#b1">[CC96]</ref> boolean queries. The queries were recast in GCL, the MultiText query language, and ranked in inverse proportion to the length of interval of text satisfying the query. This approach should give roughly the same documents as supplied, but ranked so as to improve early relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>wat8gram</head><p>A fusion of runs wat3desc, wat4feed, wat9boolgram</p><p>The fusion of runs was done using the CombMNZ combination method.</p><p>wat9boolgram</p><p>This run was not submitted but was one the of runs combined to create wat8gram. Each boolean query was converted to a bag of words. The bag of words were then converted to 4-grams. The 4-gram bag of word queries are issued against the corpus using the okapi BM25 document ranking. This run is very similar to wat3desc which uses 4-grams from the Re-questedText eld where this runs user 4-grams from the FinalQuery eld.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N-Gram Query Examples</head><p>Table <ref type="table" coords="2,338.30,619.53,4.98,6.64" target="#tab_1">1</ref> shows the 4 grams produced by the dierent runs for query 93. The FinalQuery eld for topic 93 is:</p><p>("trade organiz!" OR "trade assoc!") AND (member! OR participat!) AND (property</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OR casualty) AND insurance</head><p>The RequestText eld is: The Z in the query denes white space. The Feedback query terms are very interesting as only the most important part of the word is used for feedback. This might appear more true then it really is because the 4-gram are rank by importance and therefore the full word might appear but not be in order. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Legal Track Results</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,72.00,647.87,43.33,7.64;1,72.00,667.20,229.01,6.64;1,72.00,679.15,229.02,6.64;1,72.00,691.11,229.02,6.64;1,72.00,703.06,229.02,6.64;1,72.00,715.02,229.01,6.64;1,310.98,218.64,229.02,6.64;1,310.98,230.59,229.02,6.64;1,310.98,242.55,229.01,6.64;1,310.98,254.50,229.02,6.64;1,310.98,266.46,88.28,6.64"><head>wat1fuseA</head><label></label><figDesc>fusion of runs wat2nobool, wat3desc, wat4feed, wat6qap, wat7bool, wat8gram. The fusion of runs was done using the CombMNZ[SF94, BKFS95] combination method. CombMNZ is a common method of combining multiple retrieval schemes. It combines and re-scores all documents for each query from a set of retrieval schemes. The fused document score is the sum of the scores for the given document of the schemes multiply by the number of schemes the document appeared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,218.28,370.20,172.12,6.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Legal Runs -Precision Recall</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,72.00,205.59,285.80,62.38"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="2,285.47,205.59,72.33,6.64"><row><cell>: 4-gram queries</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,72.00,400.43,441.32,321.23"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="3,72.00,400.43,441.32,321.23"><row><cell></cell><cell>run</cell><cell>map</cell><cell>bpref</cell><cell># relevant</cell></row><row><cell></cell><cell>wat1fuse</cell><cell>0.1415</cell><cell>0.3834</cell><cell>3666</cell></row><row><cell></cell><cell>wat2nobool</cell><cell>0.0383</cell><cell>0.1696</cell><cell>1635</cell></row><row><cell></cell><cell>wat3desc</cell><cell>0.1079</cell><cell>0.3273</cell><cell>3365</cell></row><row><cell></cell><cell>wat4feed</cell><cell>0.0364</cell><cell>0.2145</cell><cell>1542</cell></row><row><cell></cell><cell>wat5nofeed</cell><cell>0.1478</cell><cell>0.3866</cell><cell>3648</cell></row><row><cell></cell><cell>wat6qap</cell><cell>0.0692</cell><cell>0.2720</cell><cell>2041</cell></row><row><cell></cell><cell>wat7bool</cell><cell>0.0912</cell><cell>0.3046</cell><cell>2133</cell></row><row><cell></cell><cell>wat8gram</cell><cell>0.0878</cell><cell>0.3242</cell><cell>3382</cell></row><row><cell cols="2">shows our mean average precision(map),</cell><cell></cell><cell></cell></row><row><cell cols="2">bpref scores and the number of relevant documents</cell><cell></cell><cell></cell></row><row><cell cols="2">returned for our legal track runs. The fusion runs</cell><cell></cell><cell></cell></row><row><cell cols="2">wat1fuse, wat1nofeed outperforms the other runs.</cell><cell></cell><cell></cell></row><row><cell cols="2">Not including the feedback in the fusion has very</cell><cell></cell><cell></cell></row><row><cell>little aect.</cell><cell>Using the RequestText eld as the</cell><cell></cell><cell></cell></row><row><cell cols="2">query, wat3desc outperforms the boolean approach</cell><cell></cell><cell></cell></row><row><cell cols="2">wat7bool with respect to map and bpref. It is sur-</cell><cell></cell><cell></cell></row><row><cell cols="2">prising that using the RequestText retrieves over 50%</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,310.98,529.83,229.02,191.83"><head>Table 2 :</head><label>2</label><figDesc>Legal Track Run Resultsmore relevant documents than the boolean . It is also unexpected that the boolean retrieval retrieves only 2133 of the 4344 relevant documents. This show that methods other than boolean need to be used to achieve full recal. Excluding the documents returned by the boolean run from the fusion does poorly as one might expect but it does nd 1635 relevant doc-</figDesc><table /><note coords="3,310.98,667.20,229.02,6.64;3,310.98,679.15,229.02,6.64;3,310.98,691.11,229.02,6.64;3,310.98,703.06,229.01,6.64;3,310.98,715.02,134.96,6.64"><p><p><p>uments. The Feedback wat4feed and relaxed boolean wat6qap don't seem to work as well as the other methods but they make an important contribution to the fusion run. Figure</p>1</p>shows the precision recall graphs for the legal track runs.</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,120.67,98.80,180.35,6.64;4,120.67,110.76,180.34,6.64;4,120.67,122.71,180.35,6.64;4,120.67,134.67,180.35,6.64;4,120.67,146.62,89.09,6.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,181.52,110.76,119.50,6.64;4,120.67,122.71,180.35,6.64;4,120.67,134.67,69.52,6.64">Combining the evidence of multiple query representations for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,201.74,135.07,94.32,6.11">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">431448</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,120.67,166.55,180.34,6.64;4,120.67,178.50,180.35,6.64;4,120.67,190.46,180.35,6.64;4,120.67,202.41,180.34,6.64;4,120.67,214.37,22.69,6.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,288.56,166.55,12.45,6.64;4,120.67,178.50,180.35,6.64;4,120.67,190.46,114.44,6.64">Interactive substring retrieval (MultiText Experiments for TREC-5)</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,263.65,190.86,37.37,6.11;4,120.67,202.81,90.56,6.11">th Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,120.83,234.29,180.19,6.64;4,120.67,246.25,180.35,6.64;4,120.67,258.20,180.35,6.64;4,120.67,270.16,180.34,6.64;4,120.67,282.11,22.69,6.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,244.89,246.25,56.13,6.64;4,120.67,258.20,122.34,6.64">Question answering by passage selection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I E</forename><surname>Kisman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,264.86,258.60,36.16,6.11;4,120.67,270.56,90.56,6.11">th Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,120.67,302.04,180.35,6.64;4,120.67,313.99,180.35,6.64;4,120.67,325.95,180.35,6.64;4,120.67,337.90,180.35,6.64;4,120.67,349.86,70.47,6.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,265.74,313.99,35.28,6.64;4,120.67,325.95,175.78,6.64">Exploiting redundancy in question answering</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,133.59,338.30,80.23,6.11">SIGIR Conference</title>
		<meeting><address><addrLine>Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,120.67,369.78,180.35,6.64;4,120.67,381.74,180.35,6.64;4,120.67,393.69,180.35,6.64;4,120.67,405.65,180.34,6.64;4,120.67,417.61,180.35,6.64;4,120.67,429.96,180.35,6.11;4,120.67,441.52,151.61,6.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,153.74,393.69,147.28,6.64;4,120.67,405.65,180.34,6.64;4,120.67,417.61,18.15,6.64">A multi-system analysis of document and term selection for blind feedback</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,168.85,418.00,132.17,6.11;4,120.67,429.96,180.35,6.11;4,120.67,441.91,52.26,6.11">CIKM &apos;04: Thirteenth ACM conference on Information and knowledge management</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">261269</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,120.67,461.44,180.35,6.64;4,120.67,473.40,180.35,6.64;4,120.67,485.75,180.35,6.11;4,120.67,497.71,180.35,6.11;4,120.67,509.26,58.65,6.64;4,72.00,525.79,229.02,10.04;4,120.67,541.14,180.35,6.64;4,120.67,553.10,180.35,6.64;4,120.67,565.05,162.84,6.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,150.89,473.40,110.13,6.64">On-line spam lter fusion</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,282.44,473.80,18.58,6.11;4,120.67,485.75,180.35,6.11;4,120.67,497.71,176.20,6.11;4,208.84,553.50,92.17,6.11;4,120.67,565.45,46.13,6.11">29th ACM SIGIR Conference on Research and Development on Information Retrieval</title>
		<meeting><address><addrLine>Seattle; Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">2006. 1995</date>
		</imprint>
	</monogr>
	<note>Third Text REtrieval Conference</note>
</biblStruct>

<biblStruct coords="4,120.67,584.98,180.35,6.64;4,120.67,596.93,180.35,6.64;4,120.67,608.89,164.92,6.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,120.67,596.93,141.91,6.64">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,282.14,597.33,18.87,6.11;4,120.67,609.29,91.08,6.11">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page">0</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
