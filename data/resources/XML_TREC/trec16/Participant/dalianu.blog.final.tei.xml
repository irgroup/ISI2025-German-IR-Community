<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,198.66,116.71,197.94,12.24">DUTIR at TREC 2007 Blog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,179.52,140.52,34.77,8.77"><forename type="first">Song</forename><surname>Rui</surname></persName>
						</author>
						<author>
							<persName coords="1,220.70,140.52,34.52,8.77"><forename type="first">Tang</forename><surname>Qin</surname></persName>
						</author>
						<author>
							<persName coords="1,261.92,140.52,45.36,8.77"><forename type="first">Daming</forename><surname>Shi</surname></persName>
							<email>damingshi@gmail.com</email>
						</author>
						<author>
							<persName coords="1,313.58,140.52,46.25,8.77"><forename type="first">Hongfei</forename><surname>Lin</surname></persName>
							<email>hflin@dlut.edu.cn</email>
						</author>
						<author>
							<persName coords="1,366.22,140.52,49.71,8.77"><forename type="first">Zhihao</forename><surname>Yang</surname></persName>
							<email>yangzh@dlut.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">LingGong Road Shahekou District</orgName>
								<address>
									<postCode>116023</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,198.66,116.71,197.94,12.24">DUTIR at TREC 2007 Blog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E343610D3D863C4AFF878CA65B73B535</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes DUTIR at TREC 2007 Blog Track. In data preprocessing, a non English language list created from the corpus was used to remove the non English blogs, blog templates were also used to extract the post and comment; in Opinion Retrieval task, information in the meta tags were also indexed; in the polarity subtask, a method based on SVM was used and the Information Gain attribute selecting method was used to assist SVM; in Feed Distillation task, three type of feeds were analyzed according to their tag structure, information extracted from particular tags of the feeds were finally indexed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>DUTIR (Information Retrieval Laboratory of Dalian University of Technology) participated in all of the tasks of the TREC 2007 Blog Track, including Opinion Retrieval Task, Polarity Subtask and Feed Distillation Task. Modules designed for different tasks are described separately below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Opinion retrieval task</head><p>In Opinion Retrieval Task, the main retrieval unit is permalink. The processing was divided into three steps: Data Preprocessing, Indexing, and Query Construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Preprocessing</head><p>In this step, non English Blogs were removed, useless tags such as Script and Style were also removed, and some blog templates which have a relatively large proportion in corpus were made use of to extract the desired content accurately.</p><p>A non English list which contains about 120 non English languages was created from the corpus. Feeds and its permalinks that belong to these non English languages were removed. Table .1 shows the non English feeds extracted by the non English list. The Non English feed number is 37625 accounting for 4.99% of the total feed number (753,681).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Total Feed Number 753,681</head><p>Non English Feed Number 37625</p><p>Non English Feed Proportion 4.99ï¼…</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table.1 Non English Feeds Proportion</head><p>Tags such as Script, Style and so on are useless and contribute to a large proportion of the corpus. Some simple pattern matching techniques were used in order to remove these tags.</p><p>Blogs generated by programs follow well defined markup rules allowing the post's content to be identified <ref type="bibr" coords="1,127.51,682.98,10.38,8.77" target="#b0">[1]</ref>. So some blog templates which contribute to relatively a larger proportion of the corpus such as Blogger, WordPress and so on were manually read and summarized into particular templates. However, because of the large corpus, we were unable to construct all of the templates, only blogs with top proportions were extracted into some templates, the remains were parsed off all of the html tags with toolkit htmlparser <ref type="bibr" coords="2,131.47,121.86,10.33,8.77" target="#b1">[2]</ref>. Table .2 below show the other results of the Data Preprocessing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Indexing</head><p>The preprocessed permalinks were later indexed with Indri Search Engine <ref type="bibr" coords="2,383.44,363.42,10.38,8.77">[3]</ref>. Besides the desired content between the tags, keywords and description parts of the Meta tags were also indexed as another two fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query construction</head><p>In this step, two tasks were focused on: constructing a sentimental lexicon and extending the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Construction of sentimental lexicon</head><p>Although there were already some sentimental lexicons that have been constructed, such as Welsh to English Lexicon [4], General Inquiry [5] and SentiWordNet [6] and so on, most of the words in the lexicons don't emerge frequently in corpus because of the casual language style of blogs. So instead of using one of the lexicons, we choose to build our own lexicon which contains about 2000 sentimental words that emerge frequently in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Query expansion</head><p>When the queries were being constructed, exact or partially exact match of words in the title parts were consider first and this will contribute to the topic relevance of the results. However, not all of the topics could get enough results with the exact or partially exact match, in this case, query extension including adding some key words in description and narrative fields to the query or making use of some knowledge found in knowledge base on Internet, such as Wikipedia were used. For example, there is a topic about a band and we need to find all of the blogs that expressed some opinions about this band or its members. Necessary information such as the names of the members needs to be found on Internet due to the inexistence of this information in description and narrative fields. Query feedback was also tried; however, results were disappointing. A simple method was used to find the blogs expressing opinions about a topic, which is judging by the emergence of sentimental words around topic words <ref type="bibr" coords="2,387.15,632.95,10.29,8.77" target="#b2">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Results</head><p>Table .3 shows the six Runs submitted in Opinion Retrieval Task. From Table .3, the runs with opinion words added to assist in finding opinions behaved better than those without. Moreover, more retrieval fields will not bring better results, DUTRun4, DUTRun5 and DUTRun6 relatively behaved worse than DUTRun1, DUTRun2 and DUTRun3. More fields mean more noise. However, moderately using the restriction in other fields will improve the results.  .4, the opinion finding method in this paper seems to be helpful, improving our performance on the task by 10.38%, despite our good performing baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Polarity subtask</head><p>In this task, a method based on Information Gain (IG) and Supporting Vector Machine (SVM) was finally used to judge the polarity of blogs. With the 2006's 50 queries and their associated relevance judgments, there was no need to find training set. One of the original experiments which were later proved to be ineffective was to train each document with the whole content. Often there were more than one topic in a document; to train the whole document seems to be confused. So sentences with topic words and their pronouns were extracted as the final training set. During the accomplishment of this task, several tests were tried including method based on sentimental lexicon, method based on machine learning and the combination of the two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Method based on sentimental lexicon</head><p>This method is mainly judging the polarity by the distribute density of sentimental words. However, some documents which were labeled as negative contained many positive words. This made the method only based on the distribute density of sentimental words seem not much too accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Method based on machine learning</head><p>A method based on SVM was used to train the corpus. Feature selection is necessary before training. Since this is a sentimental classification problem, sentimental words in the lexicon were considered as feature words first. However, the classification accuracy was not very satisfying. Feature words selected by Information Gain were later used as features to train the corpus. Moreover, combination of the two was also tried. The whole classification was divided into two steps: First, classify the training set into opinionated ones and non ones; second, classify the opinionated ones into positive, negative and the combination of the two  .6, systems which are more successful at retrieving opinionated documents ahead of relevant ones, they will then have more documents for which they can make a correct classification. The five groups in this table also performed well in the opinion retrieval task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Feed distillation task</head><p>In this task, feed files were preferred as retrieval units due to the need to submit feedno. Like the opinion retrieval task, processing was divided into three steps: Data Preprocessing, Indexing, and Query Construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data preprocessing</head><p>Some manual work such as analyzing the possible formats of the feed files and recording the possible tags that contain desired information according different formats are necessary. Finally three types of feed formats were found according their different displaying styles: RSS, RDF, and ATOM. Moreover, some types of feed could be divided into smaller units such as Item or Entry. Whether for the whole feed or the smaller units in it, desired contents in them are often in the fixed tags such as &lt;description&gt;, &lt;content&gt;, &lt;summary&gt; and so on. So feed files with non English ones removed were later parsed according these tags with htmlparser iteratively. When using htmlparser, these tags need to be defined and registered in order to identify these tags and extract contents among them. The size of original feed is 38.8GB and the size of feed after non English ones and undesired contents are removed becomes 17.5GB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Indexing</head><p>Preprocessed data were later indexed with Indri Search Engine <ref type="bibr" coords="5,343.90,257.82,10.38,8.77">[3]</ref>. Feeds are different from permalinks, there are often redundant feeds among different files and the contents of them are varying or not. So when run query on the index, it needs to remove the redundant feeds and make a little adjustment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Expanding the queries</head><p>In this step, some key words in description and narrative fields were utilized to expand the queries, knowledge found in some knowledge base were also utilized. Since this task is different from opinion retrieval task which needs to find all of the opinionated blogs about a particular topic, moreover, content of each topic that belongs to this task is quite wide, news also meet requirement, so not each query was constructed with sentimental words added.  .7, the method in this paper to find feeds was not satisfying. During the manually labeling phase, this fact was already found. A lot of feeds that contently relate to particular topic are in fact do not have enough even no correspond permalinks, while our method only focused on the content of feeds, so the final result was consequently not satisfying. We are confirmed that the addition of the consideration of permalinks to the method that used in this task will perform better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>After analyzing and comparing the results, some conclusions can be drawn. When finding opinions, a sentimental lexicon which contains opinion words frequently emerged in blog corpus is necessary. Title field is the basic field, other fields are not as important as title field and should be used with caution in case of bring noise. It seems that simply considering feed as retrieval unit do not perform well in Feed Distillation task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,228.48,318.85,155.32,8.77"><head>Table . 2</head><label>.</label><figDesc>Permalink Preprocessing Result</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,136.50,154.92,322.27,158.65"><head>Table . 3</head><label>.</label><figDesc>Opinion runs submitted Table.4 shows the top 5 improvements of the best submitted compulsory automatic title-only runs over the baselines.</figDesc><table coords="2,136.50,154.92,322.27,158.65"><row><cell>RunID</cell><cell cols="2">Description</cell><cell></cell><cell cols="3">MAP R-Precision P@10</cell></row><row><cell>DUTRun1</cell><cell cols="3">Automatic and title-only</cell><cell>0.2890</cell><cell cols="2">0.3368</cell><cell>0.502</cell></row><row><cell>DUTRun2</cell><cell cols="3">Total Permalink Number Title +Opinion Words</cell><cell>0.3190</cell><cell cols="2">3,215,171 0.3671</cell><cell>0.6</cell></row><row><cell>DUTRun3</cell><cell cols="3">Non English Permalink Number Title +Description+ Opinion Words</cell><cell>0.3094</cell><cell cols="2">173026 0.3527</cell><cell>0.6060</cell></row><row><cell>DUTRun4</cell><cell cols="3">Non English Permalink Proportion Title +Description</cell><cell>0.2843</cell><cell cols="2">5.38ï¼… 0.3360</cell><cell>0.4820</cell></row><row><cell>DUTRun5</cell><cell cols="3">Size of total permalinks Title+ Description +Narrative</cell><cell>0.2279</cell><cell cols="2">88.7GB 0.3029</cell><cell>0.5060</cell></row><row><cell cols="5">Size of total permalinks with Non English Permalinks and &lt;DOCHDR&gt; tags removed DUTRun6 Title +Description +Narrative + Opinion Words 0.2959</cell><cell cols="2">81GB 0.3401</cell><cell>0.6080</cell></row><row><cell cols="6">Size of total permalinks with Script and Style tags removed moreover.</cell><cell>66GB</cell></row><row><cell cols="5">Size of total permalinks with whole or parts of tags removed according to some blog templates</cell><cell cols="2">16.7GB</cell></row><row><cell>Group</cell><cell cols="2">Best Baseline Baseline</cell><cell cols="2">Best Non-baseline</cell><cell>Non</cell><cell>%Increase</cell></row><row><cell></cell><cell></cell><cell>Map</cell><cell></cell><cell></cell><cell>Baseline</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MAP</cell></row><row><cell cols="2">UGlasgow(Ounis) uogBOPFProx</cell><cell>0.2817</cell><cell cols="2">uogBOPFProxW</cell><cell>0.3264</cell><cell>15.87%</cell></row><row><cell>IndianaU (Yang)</cell><cell>Oqsnr1Base</cell><cell>0.2537</cell><cell>oqsnr2opt</cell><cell></cell><cell>0.2894</cell><cell>14.07%</cell></row><row><cell>UArkansas</cell><cell>UALR07Base</cell><cell>0.2554</cell><cell cols="2">UALR07BlogIU</cell><cell>0.2911</cell><cell>13.98%</cell></row><row><cell>Littlerock</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(Bayrak)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DalianU (Yang)</cell><cell>DUTRun1</cell><cell>0.289</cell><cell>DUTRun2</cell><cell></cell><cell>0.319</cell><cell>10.38%</cell></row><row><cell cols="3">UWaterloo (Olga) UWbasePhrase 0.2486</cell><cell cols="2">UWopinion3</cell><cell>0.2631</cell><cell>5.83%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,97.14,482.52,355.76,23.05"><head>Table . 4</head><label>.</label><figDesc>The top 5 improvements over the baselines for automatic title-only runs According to Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,87.42,228.06,420.62,344.89"><head>Table . 5</head><label>.</label><figDesc>Table.5 shows the six polarity runs submitted. Because of the correspondence between polarity runs and opinion runs, it seems that the runs behave better in opinion retrieval task also behave better in polarity task. Polarity runs submitted Table6shows the top 5 best-scoring title-only polarity detection run for each group in terms of R-accuracy, regardless of the topic length, and sorted in decreasing order of R-accuracy.</figDesc><table coords="4,124.44,267.42,335.29,305.53"><row><cell>Run</cell><cell>R-Acc</cell><cell>A@10</cell><cell></cell><cell>A@1000</cell></row><row><cell>DUTRun1P</cell><cell>0.1603</cell><cell>0.2708</cell><cell></cell><cell>0.0412</cell></row><row><cell>DUTRun2P</cell><cell>0.1721</cell><cell>0.3080</cell><cell></cell><cell>0.0406</cell></row><row><cell>DUTRun3P</cell><cell>0.1624</cell><cell>0.3040</cell><cell></cell><cell>0.0400</cell></row><row><cell>DUTRun4P</cell><cell>0.1608</cell><cell>0.2620</cell><cell></cell><cell>0.0406</cell></row><row><cell>DUTRun5P</cell><cell>0.1356</cell><cell>0.2520</cell><cell></cell><cell>0.0255</cell></row><row><cell>DUTRun6P</cell><cell>0.1591</cell><cell>0.3020</cell><cell></cell><cell>0.0380</cell></row><row><cell>Group</cell><cell>Run</cell><cell>R-Acc</cell><cell>A@10</cell><cell>A@1000</cell></row><row><cell>UIUC (Zhang)</cell><cell>uic75cpnm</cell><cell>0.2295</cell><cell>0.3700</cell><cell>0.0493</cell></row><row><cell>UAmsterdam</cell><cell>uams07ipolt</cell><cell>0.1827</cell><cell>0.2640</cell><cell>0.0418</cell></row><row><cell>(de Rijke)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>IndianaU</cell><cell>oqsnr2optP</cell><cell>0.1799</cell><cell>0.2800</cell><cell>0.0401</cell></row><row><cell>(Yang)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DalianU</cell><cell>DUTRun2P</cell><cell>0.1721</cell><cell>0.3080</cell><cell>0.0406</cell></row><row><cell>(Yang)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Zhejiangu</cell><cell>EAGLE2P</cell><cell>0.1510</cell><cell>0.2380</cell><cell>0.0427</cell></row><row><cell>(Qiu)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,97.14,584.34,344.86,27.55"><head>Table . 6</head><label>.</label><figDesc>The top 5 best polarity runs for each group in terms of R-accuracy According to Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,87.42,419.70,399.17,189.91"><head>Table . 7</head><label>.</label><figDesc>shows the top 5 best-scoring automatic title-only run from each participating group in terms of MAP, and sorted in decreasing order.</figDesc><table coords="5,118.44,469.14,353.07,140.47"><row><cell>Group</cell><cell>Run</cell><cell>MAP</cell><cell>R-prec</cell><cell>b-Bref</cell><cell>P@10</cell><cell>MRR</cell></row><row><cell>CMU</cell><cell>CMUfeedW</cell><cell>0.3695</cell><cell>0.4245</cell><cell>0.3861</cell><cell>0.5356</cell><cell>0.7537</cell></row><row><cell>(Callan)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>UGlasgow</cell><cell>uogBDFeMNZP</cell><cell>0.2923</cell><cell>0.3654</cell><cell>0.3210</cell><cell>0.5311</cell><cell>0.7834</cell></row><row><cell>(Ounis)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>UMass</cell><cell>UMaTiPCSwGR</cell><cell>0.2529</cell><cell>0.3334</cell><cell>0.2902</cell><cell>0.5111</cell><cell>0.8093</cell></row><row><cell>(Allen)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>KobeU</cell><cell>Kudsn</cell><cell>0.2420</cell><cell>0.3148</cell><cell>0.2714</cell><cell>0.4622</cell><cell>0.7605</cell></row><row><cell>(Seki)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DalianU</cell><cell>DUTDRun1</cell><cell>0.2285</cell><cell>0.3105</cell><cell>0.2768</cell><cell>0.3711</cell><cell>0.5813</cell></row><row><cell>(Yang)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,87.42,614.64,408.11,22.99"><head>Table . 7</head><label>.</label><figDesc>Blog distillation results: the top 5 automatic title-only run with the best MAP, sorted by MAP As shown in Table</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,99.10,223.70,283.37,7.88" xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Attardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,99.10,223.70,141.08,7.88">Blog Mining through Opinionated Words</title>
		<imprint/>
		<respStmt>
			<orgName>UniversitÃ  di Pisa</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,102.44,238.82,297.19,7.88" xml:id="b1">
	<monogr>
		<ptr target="http://sourceforge.net/project/showfiles.php?group_id=24399" />
		<title level="m" coord="6,102.44,238.82,74.08,7.88">HTML Parser Tool Kit</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,101.13,314.72,406.83,7.88;6,87.42,329.90,216.63,7.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,261.51,314.72,246.45,7.88;6,87.42,329.90,18.48,7.88">Knowledge Transfer and Opinion Detection in the TREC2006 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,124.97,329.90,174.74,7.88">Proceedings of Text Retrieval Conference (TREC)</title>
		<meeting>Text Retrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
