<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,73.18,83.76,463.35,15.48">Language Modeling Approaches to Blog Post and Feed Finding</title>
				<funder ref="#_j3Rh2aT">
					<orgName type="full">NWO</orgName>
				</funder>
				<funder ref="#_XqFUf8W #_mQFU6KK #_NDh8dfU #_PzHzygJ #_WVNVUSr #_brWWztM #_kKNqenx #_AZbtDGk #_7VRdenK #_xe6YZT9">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_4CDrgTn">
					<orgName type="full">E.U. IST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,141.75,116.28,87.61,10.75"><forename type="first">Ernsting</forename><surname>Breyten</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
								<address>
									<addrLine>Kruislaan 403</addrLine>
									<postCode>1098 SJ</postCode>
									<settlement>Amsterdam</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.26,116.28,97.60,10.75"><forename type="first">Weerkamp</forename><surname>Wouter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
								<address>
									<addrLine>Kruislaan 403</addrLine>
									<postCode>1098 SJ</postCode>
									<settlement>Amsterdam</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,380.76,116.28,90.19,10.75"><surname>Maarten De Rijke</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
								<address>
									<addrLine>Kruislaan 403</addrLine>
									<postCode>1098 SJ</postCode>
									<settlement>Amsterdam</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,73.18,83.76,463.35,15.48">Language Modeling Approaches to Blog Post and Feed Finding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4A79555F1AD155B6B6393BB0C5BDAEB1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our participation in the TREC 2007 Blog track. In the opinion task we looked at the differences in performance between Indri and our mixture model, the influence of external expansion and document priors to improve opinion finding; results show that an out-of-the-box Indri implementation outperforms our mixture model, and that external expansion on a news corpus is very benificial. Opinion finding can be improved using either lexicons or the number of comments as document priors.</p><p>Our approach to the feed distillation task is based on aggregating post-level scores to obtain a feed-level ranking. We integrated time-based and persistence aspects into the retrieval model. After correcting bugs in our post-score aggregation module we found that time-based retrieval improves results only marginally, while persistence-based ranking results in substantial improvements under the right circumstances.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We describe our experiments for this year's edition of the Blog track. Our main aims were <ref type="bibr" coords="1,184.91,463.25,11.62,8.64" target="#b0">(1)</ref> to compare our inhouse mixture model against an Indri-based baseline for topical blog post retrieval, and (2) for the distillation task to examine the influence of time and frequency of posting about a given topic on retrieval effectiveness. In two largely independent sections we first discuss our work on the opinion finding task (Section 2) and then our work on the feed distillation task (Section 3). We conclude in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Opinion Finding</head><p>The opinion finding task aims at returning blog posts that contain an opinion regarding a certain topic <ref type="bibr" coords="1,231.03,615.18,10.58,8.64" target="#b6">[7]</ref>. The results of last year's opinion finding task indicate that a strong topical retrieval system is the single most important part of opinion finding. In Section 2.1 we present the models we use for topical retrieval and the usage of external expansion to improve topical blog post retrieval is discussed in Section 2.2. Section 2.3 shows the implementation of opinion finding indicators. Finally we present run details (Section 2.5) and results (Section 2.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Topic Retrieval</head><p>Our baseline approach to the topical blog post retrieval task uses language models. The models we use in this track are similar to the models we use in the TREC Enterprise track and are described more fully in <ref type="bibr" coords="1,443.53,262.16,10.58,8.64" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Indri</head><p>For comparison we use an out-of-the-box implementation of Indri 2.4<ref type="foot" coords="1,350.88,329.34,3.49,6.05" target="#foot_0">1</ref> to process the 2007 topics. As preprocessing steps we strip all HTML tags and remove stopwords; we do not apply stemming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">External Expansion</head><p>Our baseline query model p(t|q) is simply estimated using p(t|q) = n(t, q) • |q| -1 , with n(t, q) being the number of occurrences of term t in query q, and |q| the query length.</p><p>To improve topical retrieval performance we use relevance models <ref type="bibr" coords="1,347.73,463.21,10.79,8.64" target="#b1">[2]</ref>; the relevance models are constructed using feedback documents and return feedback terms with an associated weight. Instead of constructing the relevance models based on the top K documents of the blog collection we use insights from <ref type="bibr" coords="1,374.36,511.04,11.62,8.64" target="#b5">[6]</ref> stating that many queries issued on blog search engines are in fact news related. We use the (contemporaneous) AQUAINT-2 news corpus to construct relevance models; from the top 40 document, we select the top 10 terms. We normalize their weights so that they sum to 1. The weighted query is issued against the blog collection to retrieve the final set of blog posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Query Rewriting</head><p>For expansion on the Indri run, we also apply the query rewriting strategies proposed in <ref type="bibr" coords="1,453.84,651.62,10.79,8.64" target="#b4">[5]</ref>: individual terms of multiple-term queries are combined into phrases using the Indri query language. A query like "sci fi channel" is rewritten to combinations of sci fi, fi channel, sci fi channel, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Priors</head><p>On top of our topical retrieval method, we implement opinion finding methods using query independent document priors (p(d)). We believe blog posts have a degree of opinionatedness regardless of the topic; besides, this approach does not have a negative impact on the speed of the retrieval system.</p><p>The main issue, then, is how to estimate the document priors. We compare two document priors for opinionatedness:</p><p>(1) a lexical approach and (2) a comment-based approach. The lexical approach uses a list of opinionated words from the OpinionFinder system. <ref type="foot" coords="2,161.62,193.84,3.49,6.05" target="#foot_1">2</ref> From this list we extract only the strong positive and strong negative words. The document prior is then estimated as given in Eq. 1:</p><formula xml:id="formula_0" coords="2,53.80,237.94,178.88,14.11">p(d) = w i=1 c(w i , d) • |d| -1 , (<label>1</label></formula><formula xml:id="formula_1" coords="2,61.54,241.22,3.87,8.64">)</formula><p>where w is the list of opinionated words and c(w i , d) is the count of opinion word i in document d and |d| is the document length in words.</p><p>Our second, comment-based approach is based on the intuition that opinionated blog posts are more likely to attract discussion. When a post contains an explicit point of view on a topic, readers are more likely to comment (either by agreeing or by expressing their own opinion on the topic). Using this idea, we estimate document priors as follows:</p><formula xml:id="formula_2" coords="2,53.80,380.16,172.09,9.65">p(d) = log(N comments,d ),<label>(2)</label></formula><p>where N comments,d is the number of comments in document d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Polarity</head><p>New in this year's opinion task is the polarity subtask: given an opinionated post we need to identify whether it is either negative, positive or neutral. To address this task we experiment with two approaches. The first approach continues on the opinionated words list of the previous section. We use the two opinionated lists separately (positive and negative words) and use Eq. 3 to estimate the polarity of each post:</p><formula xml:id="formula_3" coords="2,53.80,553.23,198.58,34.83">pol(d) =    positive if r(d) &gt; 0.01 negative if r(d) &lt; -0.01 neutral otherwise,<label>(3)</label></formula><p>where r(d) is defined as</p><formula xml:id="formula_4" coords="2,53.80,620.84,215.94,14.11">r(d) = ( n i=1 c(n i , d) - p i=1 c(p i , d)) • |d| -1 , (4)</formula><p>in which n is the list of negative words, p the list of positive words, c(n i , d) the number of times word n i occurs in document d and |d| the document length in words.</p><p>For our second approach we look at expressions of opinion other than words. The idea is that posts containing more expressive language tend to be more negative about the topic discussed in that post. To estimate this negativity, we use the following indicators: exclamation marks, question marks, ellipsis (...), and all caps strings of more than 3 characters. The ratio of these indicators is calculated for each blog post using Eq. 5, where c(i, d) is the total number of occurrences of the above indicators in document d and |d| is the document length in words. Polarity is estimated according Eq. 6:</p><formula xml:id="formula_5" coords="2,316.81,160.99,199.55,38.82">r(d) = c(i, d) • |d| -1 (5) pol(d) = positive if r(d) &lt; 0.1 negative if r(d) ≥ 0.1 (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Runs</head><p>For the runs using the mixture model we use the 2006 topics and assessments to estimate the best mixture weights. Results show that only the title component has a positive influence on retrieval performance and the best mixture is estimated to be 0.15 title, 0.60 body text and 0.25 background. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Results</head><p>We look at the performance of our runs on topical retrieval, opinion retrieval and polarity identification. Table <ref type="table" coords="2,523.13,649.86,4.98,8.64" target="#tab_0">1</ref> shows the MAP and p@10 scores for all runs on the retrieval tasks and the R-accuracy<ref type="foot" coords="2,393.56,672.10,3.49,6.05" target="#foot_2">3</ref> on the polarity identification <ref type="bibr" coords="2,515.71,673.77,10.58,8.64" target="#b3">[4]</ref>. Surprisingly, the mixture model runs with external expansion perform significantly worse than the baseline run, even though we see an improvement of external expansion on the Indri runs; it appears that the external expansion is not performed correctly, leading to expanded queries that miss original query terms. Topic 902 (lactose gas) provides an example: the expanded query contains the terms gas, contamination, water, underground, solution, tce, eaten, whey, study, atoms, but the original query term lactose is missing. The performance decreases dramatically from 0.4127 in the baseline run to 0.003 in the expanded runs. This error occurs in about half of the topics, making the final run scores (both on MAP and precision) much lower. An example of a topic that is expanded correctly, is topic 947 (sasha cohen).</p><p>It achieves an AP score of 0.2897 in the baseline run, which increases to 0.6371 in the expanded runs. Similar effects are noticeable in other correctly expanded queries.</p><p>Both the lexicon and comment-based approach have a positive influence on opinion retrieval, with the lexicon approach outperforming the comment-based approach. Finally, polarity detection based on the difference between positive word ratio and negative word ratio performs only slightly better than the punctuation approach, even though the latter distinguishes only positive and negative posts and ignores neutral posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feed distillation</head><p>The feed distillation task is a new task and it aims at finding feeds that are devoted to a given topic. The general idea is that a user can be presented with a suggested list of feeds that are worth reading, given the topic. Although the task is new, it resembles the Expert Search task in the Enterprise track, and the Topic Distillation task in the Web track.</p><p>Below, we present the models we used for topic distillation, and for incorporating aspects of time and persistence in the retrieval model, to improve the accuracy of our feed distillation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Topic retrieval</head><p>The method we use to address topic retrieval for the feed distillation task is based on ranking individual posts contained in the feed; it is akin to the method in Section 2.1 (Eq. 1-5). However, p(t|θ d ) is estimated simply as follows: p(t|θ d ) = p(t|d), <ref type="bibr" coords="3,316.81,134.10,11.62,8.64" target="#b6">(7)</ref> where p(t) is the maximum likelihood-estimate of the term t in the document collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Time-based Reweighing</head><p>To improve the accuracy of our topical retrieval system, we incorporate query independent document priors which are based on the creation date of the documents. More recent documents are assumed to better reflect the current interests of a feed (blogger), and that these should therefore rank higher. We model this intuition using a time-based language model <ref type="bibr" coords="3,344.21,287.77,10.79,8.64" target="#b2">[3]</ref>:</p><formula xml:id="formula_6" coords="3,316.81,299.69,167.86,9.65">p(d|q) ∝ p(q|d)p(d|T d ),<label>(8)</label></formula><p>where p(d|T d ) is a time-based prior in the model. Since we are interest in recency and not a specific event, we use an exponential distribution to calculate the priors. This distribution is defined as follows:</p><formula xml:id="formula_7" coords="3,316.81,373.79,187.80,11.72">p(d|T d ) = P (T d ) = λe -λ(T C -T d ) (9)</formula><p>The optimal value of the parameter λ is determined in training experiments. T C and T d are measured in days; T C signifies the most recent date of the documents in the collection, and T d refers to the document being considered.</p><p>Using time-based document priors only works when using blog posts as the unit of retrieval. In order to derive a ranked list of feeds (as required) from a ranked list of blog posts, we take the score of the highest ranked n blog posts of a feed as follows:</p><formula xml:id="formula_8" coords="3,316.81,512.02,208.98,30.55">score(bl|q) = r=n r=1 d R(r, d) • p(d|q) • n -1 ,<label>(10)</label></formula><p>where bl is a feed, and d ranges over blog posts in bl. R(r, d) is equal to 1 if the rank of document d is equal to r, 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Persistence-based Reweighing</head><p>Another way to improve the accuracy of our retrieval system is to consider the frequency of on-topic blog posts for feeds. We assume that the number of matching blog posts is proportional to the interest of a blogger in the topic. Consequently, we can derive a ranking of feeds according to the frequency of blog posts matching the topic in question. However, this ignores the fact that some feeds may contain a disproportionate number of blog posts, in comparison to other feeds. We therefore consider the number of on-topic blog posts in the feed versus the number of blog posts, either matching the topic or not, to score the feeds.</p><p>We incorporate this "persistence score" in our retrieval model using a linear combination of both the topic-based score and the persistence score. The topic-based score per blog post is calculated as detailed in Section 3.1 and the score per feed is calculated similar to Eq. 10 (i.e., we take the highest scoring blog post per feed). This leads to:</p><formula xml:id="formula_9" coords="4,53.80,260.79,204.57,9.65">p(bl|q) = λ • p c (bl|q) + (1 -λ) • p f (bl|q),<label>(11)</label></formula><p>where p c (bl|q) denotes the topic-based score for the feed given the topic, and p f (bl|q) denotes the persistence score for the feed given the topic; note that p c (bl|q) is the same as in Eq. 10, while p f (bl|q) is defined as follows:</p><formula xml:id="formula_10" coords="4,53.80,339.28,185.80,12.72">p f (bl|q) = d∈bl R(d|q) • |bl| -1 (12)</formula><p>Here, R(d|q) = 1 if p(d|q) &gt; 0, and R(d|q) = 0 otherwise; |bl| denotes the number of blog posts in the blog bl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Runs</head><p>The following runs were submitted: uams07bdtop uses the topical blog post retrieval model as described in Section 3.1 and aggregates blog posts to a feed according to Eq. 10.</p><p>uams07tblm uses the time-based retrieval model as described in Section 3.2. Training experiments showed the λ = 0.04 was the optimal setting for the exponential function.</p><p>uams07bdfreq uses the persistence retrieval model as described in Section 3.3. λ = 0.5 was the setting used in this run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results</head><p>We now consider the performance of our runs for the feed distillation task. The results are displayed in Table <ref type="table" coords="4,258.41,615.09,3.74,8.64" target="#tab_1">2</ref>, which shows, for each run, the MAP scores, as well as the p@10 and p@30 scores. Unfortunately, well after the submission, it emerged that there was a bug in the aggregation module that implements Eq. 10; essentially, it equated the score of a feed with that of its single best scoring post (instead of aggregating the score from the top n posts). In Table <ref type="table" coords="4,183.58,698.87,4.98,8.64" target="#tab_2">3</ref> we report on results with the corrected aggregation module. We find that taking an ag-n MAP p@10 p@30 gregate of the top 8 posts to compute the score of the feed tends to yield the best performance, for all measures considered. A topic-level analysis revealed that 8 is optimal, not just on average, but for nearly all individual topics.</p><p>The time-based prior improved only slightly over the best performing relevance-only baseline (based on aggregating n = 8 posts). When we further integrate the output of the (corrected) aggregation module with persistence-based scoring, i.e., recreating the run labeled uams07bdfreq, but now based on the corrected aggregation module, the best scores we are able to achieve are 0.3629 (MAP; +8.2% over the best scoring relevance-only baseline in Table <ref type="table" coords="4,514.87,410.00,3.60,8.64" target="#tab_2">3</ref>), 0.5289 (p@10; +1.3%), and 0.4022 (p@30; +7.7%); the improvements in MAP and p@30 are significant.</p><p>In sum, then, after implementing our bug fixes we found that feeds can be ranked effectively by considering a small set of posts only, that the time-based prior leads to minor improvements, but that the persistence-based score leads to substantial gains in effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper we described our participation in the TREC 2007 Blog track. Our aim for the opinion finding task was to experiment with Indri and a mixture model. Result show that Indri significantly outperforms the mixture model. External expansion using a news corpus leads to improvement over the Indri baseline run, although bugs in the implementation caused decreased performance in the mixture model. Opinion finding by means of document priors shows beneficial, especially in case of lexicons. Overall we can conclude that opinion finding is highly dependent on topical retrieval and that focus still should be on this aspect: opinion detection can be done using lexicons, but non-lexical features also show promising results.</p><p>As to the feed distillation task, our (corrected) results</p><p>show that using time-based document priors improved slightly over the baseline run. Incorporating a persistence score based on the relative frequency with which a blogger posts about a given topic, led to further significant improvements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,316.81,310.47,239.10,9.03;2,336.74,322.81,104.33,8.64;2,316.81,336.87,239.10,9.03;2,336.74,349.22,219.18,8.64;2,336.74,361.17,193.80,8.64;2,316.81,375.23,239.10,9.03;2,336.74,387.58,219.18,8.64;2,336.74,399.53,34.02,8.64;2,316.81,413.60,239.10,9.03;2,336.74,425.94,219.18,8.64;2,336.74,437.89,147.21,8.64;2,316.81,451.96,239.10,9.03;2,336.74,464.30,219.18,8.64;2,336.74,476.26,219.18,8.64;2,336.74,488.21,30.45,8.64;2,316.81,502.27,239.10,9.03;2,336.74,514.62,219.18,8.64;2,336.74,526.57,201.99,8.64;2,316.81,540.64,239.10,9.03;2,336.74,552.98,219.18,8.64;2,336.74,564.94,219.18,8.64;2,336.74,576.89,219.18,8.64;2,336.74,588.85,107.64,8.64"><head></head><label></label><figDesc>(A) uams07indbl the baseline run uses an out-of-thebox Indri implementation. (B) uams07topic the topic run also uses Indri out-of-thebox; queries are first rewritten and then expanded using the external corpus (as described in Section 2.2). (C) uams07mmbl the baseline mixture model run: the best mixture as tested on the 2006 data without additional features. (D) uams07mmq identical to the previous run; instead of the baseline query model relevance models are used based on feedback on a news corpus. (E) uams07mmqcom identical to the previous run; to identify opinionated posts document priors based on the number of comments are included as discussed in Section 2.3 (F) uams07mmqop identical to run uams07mmq; document priors based on the ratio of opinionated words (Section 2.3) are used to estimate opinionatedness. (G) polarity runs uams07topic, uams07mmbl and uams07mmqop use the opinionated words ratio as polarity indicator. Runs uams07mmq and uams07mmqcom use the punctuation-based polarity identifier (see Section 2.4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.80,64.07,239.10,157.17"><head>Table 1 :</head><label>1</label><figDesc>Blog post retrieval results</figDesc><table coords="3,53.80,76.60,239.10,144.64"><row><cell></cell><cell>topic</cell><cell>opinion</cell><cell>polarity</cell></row><row><cell>run id</cell><cell>MAP p@10</cell><cell>MAP p@10</cell><cell>R-acc.</cell></row><row><cell>A</cell><cell cols="2">0.4342 0.6800 0.3281 0.4920</cell><cell>-</cell></row><row><cell>C</cell><cell cols="2">0.3105 0.6060 0.2123 0.3840</cell><cell>0.1284</cell></row><row><cell>B</cell><cell cols="2">0.4741 0.7620 0.3453 0.5620</cell><cell>0.1827</cell></row><row><cell>D</cell><cell cols="2">0.1898 0.4500 0.1273 0.2520</cell><cell>0.0711</cell></row><row><cell>F</cell><cell cols="2">0.1865 0.4720 0.1459 0.3200</cell><cell>0.0840</cell></row><row><cell>E</cell><cell cols="2">0.1834 0.4620 0.1302 0.2900</cell><cell>0.0677</cell></row><row><cell cols="4">From Table 1 it is clear that run B (uams07topic, Indri with</cell></row><row><cell cols="3">external expansion) performs best on all tasks.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,83.46,64.07,177.29,55.78"><head>Table 2 :</head><label>2</label><figDesc>Feed distillation results</figDesc><table coords="4,83.46,74.55,177.29,45.29"><row><cell>run id</cell><cell>MAP p@10 p@30</cell></row><row><cell>uams07bdtop</cell><cell>0.1589 0.3111 0.2141</cell></row><row><cell cols="2">uams07bdtblm 0.1605 0.3067 0.2156</cell></row><row><cell cols="2">uams07bdfreq 0.1248 0.2467 0.2170</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,316.81,68.43,239.11,186.79"><head>Table 3 :</head><label>3</label><figDesc>Evaluation results obtained by ranking feeds based only on aggregating different numbers of posts; n is the number of posts considered. Based on a corrected implementation of Eq. 10.</figDesc><table coords="4,372.35,68.43,128.02,128.19"><row><cell>1 0.1849 0.3267 0.2274</cell></row><row><cell>2 0.2740 0.4467 0.3037</cell></row><row><cell>3 0.3061 0.4844 0.3363</cell></row><row><cell>4 0.3198 0.4978 0.3459</cell></row><row><cell>5 0.3289 0.5133 0.3578</cell></row><row><cell>6 0.3328 0.5156 0.3615</cell></row><row><cell>7 0.3345 0.5178 0.3689</cell></row><row><cell>8 0.3354 0.5222 0.3733</cell></row><row><cell>9 0.3344 0.5089 0.3711</cell></row><row><cell>10 0.3329 0.4978 0.3681</cell></row><row><cell>15 0.3259 0.5000 0.3719</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,331.16,712.12,110.47,6.91"><p>http://www.lemurproject.org/indri/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,68.14,712.12,154.05,6.91"><p>URL: http://www.cs.pitt.edu/mpqa/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,331.16,692.94,224.71,7.17;2,316.81,702.40,239.11,7.17;2,316.81,712.12,79.69,6.91"><p>The R-accuracy is the fraction of retrieved documents above rank R that are classified correctly, where R is the number of opinion-containing documents for that topic.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments <rs type="person">Maarten de Rijke</rs> was supported by <rs type="funder">NWO</rs> under project numbers <rs type="grantNumber">017.001.190</rs>, <rs type="grantNumber">220-80-001</rs>, <rs type="grantNumber">264-70-050</rs>, <rs type="grantNumber">354-20-005</rs>, <rs type="grantNumber">600.065.120</rs>, <rs type="grantNumber">612-13-001</rs>, <rs type="grantNumber">612.000.106</rs>, <rs type="grantNumber">612.066.302</rs>, <rs type="grantNumber">612.069.006</rs>, <rs type="grantNumber">640.001.501</rs>, <rs type="grantNumber">640.002.501</rs>, and by the <rs type="funder">E.U. IST</rs> programme of the 6th <rs type="programName">FP for RTD</rs> under project Mul-tiMATCH contract <rs type="grantNumber">IST-033104</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_j3Rh2aT">
					<idno type="grant-number">017.001.190</idno>
				</org>
				<org type="funding" xml:id="_XqFUf8W">
					<idno type="grant-number">220-80-001</idno>
				</org>
				<org type="funding" xml:id="_mQFU6KK">
					<idno type="grant-number">264-70-050</idno>
				</org>
				<org type="funding" xml:id="_NDh8dfU">
					<idno type="grant-number">354-20-005</idno>
				</org>
				<org type="funding" xml:id="_PzHzygJ">
					<idno type="grant-number">600.065.120</idno>
				</org>
				<org type="funding" xml:id="_WVNVUSr">
					<idno type="grant-number">612-13-001</idno>
				</org>
				<org type="funding" xml:id="_brWWztM">
					<idno type="grant-number">612.000.106</idno>
				</org>
				<org type="funding" xml:id="_kKNqenx">
					<idno type="grant-number">612.066.302</idno>
				</org>
				<org type="funding" xml:id="_AZbtDGk">
					<idno type="grant-number">612.069.006</idno>
				</org>
				<org type="funding" xml:id="_7VRdenK">
					<idno type="grant-number">640.001.501</idno>
				</org>
				<org type="funding" xml:id="_4CDrgTn">
					<idno type="grant-number">640.002.501</idno>
					<orgName type="program" subtype="full">FP for RTD</orgName>
				</org>
				<org type="funding" xml:id="_xe6YZT9">
					<idno type="grant-number">IST-033104</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,70.40,267.96,222.50,8.64;5,70.40,279.92,222.50,8.64;5,70.40,291.69,137.99,8.82" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,70.40,279.92,222.50,8.64;5,70.40,291.87,43.00,8.64">The University of Amsterdam at the TREC 2007 Enterprise Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,311.80,222.50,8.64;5,70.40,323.57,222.51,8.82;5,70.40,335.53,222.50,8.59;5,70.40,347.48,222.51,8.82;5,70.40,359.62,73.21,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,187.85,311.80,105.05,8.64;5,70.40,323.75,26.81,8.64">Relevance-based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,114.72,323.57,178.18,8.59;5,70.40,335.53,222.50,8.59;5,70.40,347.48,150.41,8.59">Proceedings of the 24th Annual international ACM SIGIR Conference on Research and Development in information Retrieval (SIGIR &apos;01)</title>
		<meeting>the 24th Annual international ACM SIGIR Conference on Research and Development in information Retrieval (SIGIR &apos;01)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,379.36,222.51,8.82;5,70.40,391.32,222.50,8.59;5,70.40,403.27,222.51,8.82;5,70.40,415.41,62.27,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,152.09,379.54,114.63,8.64">Time-based language models</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,275.09,379.36,17.81,8.59;5,70.40,391.32,222.50,8.59;5,70.40,403.27,191.09,8.59">Proceedings of the 12th International Conference on Information and Knowledge Managment (CIKM)</title>
		<meeting>the 12th International Conference on Information and Knowledge Managment (CIKM)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="469" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,435.33,222.50,8.64;5,70.40,447.11,187.87,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,242.49,435.33,50.41,8.64;5,70.40,447.29,93.38,8.64">Overview of the trec 2007 blog track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,181.89,447.11,46.93,8.59">This Volume</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,467.21,222.50,8.64;5,70.40,478.99,222.50,8.82;5,70.40,490.94,222.50,8.59;5,70.40,502.90,222.50,8.59;5,70.40,514.85,222.50,8.82;5,70.40,526.99,48.31,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,197.57,467.21,95.33,8.64;5,70.40,479.17,116.03,8.64">A markov random feld model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,207.83,478.99,85.07,8.59;5,70.40,490.94,222.50,8.59;5,70.40,502.90,222.50,8.59;5,70.40,514.85,24.81,8.59">SIGIR &apos;05: Proceedings of the 28th annual international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.40,546.74,222.51,8.82;5,70.40,558.87,128.83,8.64" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,116.88,546.74,124.52,8.59">Applied Text Analytics for Blogs</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>University of Amsterdam</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="5,70.40,578.79,222.50,8.64;5,70.40,590.75,222.50,8.64;5,70.40,602.53,222.50,8.59;5,70.40,614.48,103.13,8.82" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,118.65,590.75,159.01,8.64">Overview of the TREC-2006 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,70.40,602.53,164.42,8.59">The Fifteenth Text REtrieval Conference</title>
		<title level="s" coord="5,243.94,602.53,48.96,8.59;5,70.40,614.48,73.45,8.82">TREC 2006) Proceedings. NIST</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
