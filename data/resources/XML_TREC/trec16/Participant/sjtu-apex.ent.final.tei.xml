<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">307D404E6A52A85044C9866A2B17AD0E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p> Position Weighting. Same query appearances in different positions of pages actually weigh differently. The probability of a page to be a key page in which the query appears in the beginning of its content is much higher than that of the page in which the query appears in the end. Illuminated by this, we use the position of query appearance in documents to boost their scores.  Query Combination. In our system, each query is transformed into several forms: Phrase Query, Proximity Query, Ordinary Query, Expanded Query and Reshuffled Phrase Query. Each query weighs differently and may be applied to different fields of documents. Scores are finally merged together linearly. Query Expansion will be introduced in Section 3.4 of Expert Search Task.</p><p>For Expert Search Task, we adhere to the system we built last year <ref type="bibr" coords="2,425.79,283.43,11.80,9.05" target="#b2">[2]</ref>, which focuses on Expert Annotation, query formation, two-stage similarity model development and enabling them in a statistical framework. This year we complement our system mainly in several aspects, among which, static ranking for expert candidates deserves underlining. Besides, data preprocessing as well as query expansion will also be introduced.</p><p>1. ExpertRank and Topic Sensitive ExpertRank. Compared to last year, the expert list is parsed from the corpus and thus may involve large noises. Hence we resort to static ranking method to handle this. The idea is to let experts vote for each other. A co-appearance can be viewed as a vote, similar to links in PageRank. In the light of this we proposed and experimented on ExpertRank and Topic Sensitive ExpertRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data preprocessing.</head><p> Parsing Corpus for Expert Name List. To get a list of experts, we parse email appearances in the corpus. Comprehensive situations like anti-spam and alias are handled. Names containing single word or host names are filtered.  VisualPageRank and Expert Homepage Detection. Different HTML structures contribute differently in establishing evidences. We propose a DOM-Tree based VisualPageRank method to distinguish valuable and valueless HTML pages. Besides, we view name appearances in HTML Title as homepage signals, and boost the score of these pages as evidences to support an expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Query Expansion.</head><p>We use narrative field of queries for query expansion. Features used to select words are: Query Similarity and Inverse Document Frequency.</p><p>The rest of the report is organized as follows. Section 2 and 3 records the technique highlights of Document Search and Expert Search tasks separately. Section 4 shows the preliminary experimental results of the submitted runs of both the two tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Document Search</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Static Ranking Approaches</head><p>For this part, firstly, we tried PageRank algorithm to compute the importance of each web page. However, the web graph is not complete in our corpus due to the sparseness of data. Thus PageRank does not perform well here. Similarly, Topic-Sensitive PageRank is not a good choice for this task, either. Then we tried HostRank to calculate web page importance.</p><p>HostRank algorithm starts from computing the importance of a host. And the hierarchy structure of the host is then used to distribute the host's importance to web pages within the host.</p><p>The HostRank algorithm consists of 2 steps:</p><p> Calculate the Host's importance Similar to PageRank algorithm, HostRank algorithm treats each host as a page in PageRank algorithm. Here we define hosts as the sub-layers of sub-portals like "http://www.csiro.au/science" , "https://www.bioinformatics.csiro.au/GeneRave". This is because they are the highest level of URL whose importance should be distinguished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Propagation of the host's importance</head><p>After obtaining the importance of hosts, we can propagate the importance along the hierarchy of these hosts. Some factors should be taken into account when processing a page: depth of URL (indicating the inside linking structure); whether the page is an index page or a content page; links pointing to the page from outside hosts.</p><p>More specifically, if page 𝑃 𝑖 is pointed to by its ancestor page 𝑃 𝑗 in a hierarchy of a host, we have 𝑃 𝑖 's importance 𝐻𝑜𝑠𝑡𝑅𝑎𝑛𝑘(𝑃 𝑖 ) calculated by Equation <ref type="bibr" coords="3,442.01,497.89,10.66,9.05" target="#b1">(1)</ref>.</p><formula xml:id="formula_0" coords="3,205.73,515.41,265.09,11.69">𝐻𝑜𝑠𝑡𝑅𝑎𝑛𝑘 𝑃 𝑖 = 𝜔 𝑖 • 𝐻𝑜𝑠𝑡𝑅𝑎𝑛𝑘 𝑃 𝑗<label>(1)</label></formula><p>Where the weight 𝜔 𝑖 is defined as:</p><formula xml:id="formula_1" coords="3,202.97,558.36,267.85,11.33">𝜔 𝑖 = 𝜃 • 𝐿𝑖𝑛𝑘 𝑃 𝑖 + 1 -𝜃 𝐼𝑛𝑑𝑒𝑥(𝑃 𝑖 )<label>(2)</label></formula><p>𝐼𝑛𝑑𝑒𝑥(𝑃 𝑖 ) is a Boolean value denoting whether the page is an index page. We use rules to discriminate index pages. If the URL of a page contains "index" or "default", or end up with "/", it is viewed as an index page.</p><p>𝐿𝑖𝑛𝑘(𝑃 𝑖 ) is defined as the percentage of the inlinks of page 𝑃 𝑖 , which is calculated in equation <ref type="bibr" coords="3,183.34,635.08,10.66,9.05" target="#b3">(3)</ref>.</p><formula xml:id="formula_2" coords="3,141.74,651.03,329.08,27.20">𝐿𝑖𝑛𝑘 𝑃 𝑖 = 𝛽 • 𝑂𝐼𝐿(𝑃 𝑖 ) 𝑂𝐼𝐿(𝑃 𝑘 ) 𝑃 𝑘 ∈𝐻𝑜𝑠𝑡 (𝑃 𝑖 ) + (1 -𝛽) • 𝐼𝐼𝐿(𝑃 𝑖 ) 𝐼𝐼𝐿(𝑃 𝑘 ) 𝑃 𝑘 ∈𝐻𝑜𝑠𝑡 (𝑃 𝑖 )<label>(3)</label></formula><p>Here 𝑂𝐼𝐿(𝑃 𝑖 ) is the number of hyperlinks from pages outside the host to page 𝑃 𝑖 , and 𝐼𝐼𝐿(𝑃 𝑖 ) is the number of hyperlinks from inside the host to the page 𝑃 𝑖 . 𝐻𝑜𝑠𝑡 𝑃 𝑖 is the host containing page 𝑃 𝑖 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Preprocessing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Title Extraction</head><p>Title field of web documents has been proved to be a high-quality information source in web search Tracks at TREC. From observation, half of the documents in our corpus lacks the title field or leave the field as "untitled". Therefore, we extract not only the &lt;TITLE&gt; tag of html pages but also the titles from the body content by exploring &lt;H1&gt;, &lt;H2&gt; tags. Then a Multi-Level Title field is obtained.</p><p>From the preliminary results of our evaluation over test query, using the VSM model to perform search on title field can improve the performance dramatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Body Detection</head><p>Here Bodies of documents are defined as the main content of a document, which is the most important information source of a page. Through our observation, body fields usually contain head tags like &lt;H1&gt;, &lt;H2&gt;…&lt;H6&gt;, while non-body fields like navigator or templates usually have a higher percentage of links. Thus we develop our 2-step algorithm as follows.</p><p> Dividing the page based on DOM tree structure. By this method, many navigators and useless templates have been removed, while most of the useful information has been kept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Similarity Matching</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Position Weighting</head><p>Sometimes a page contains certain relevant information about a topic, but it is not a key page to the topic (e.g. News Summaries). The position of query terms' appearances in a page is a good feature to judge whether this is key page or not. Thus we exploit Position Weighting for queries and documents.</p><p>For query Q and document D, the Position Weight can be calculated as:</p><formula xml:id="formula_3" coords="5,216.53,153.91,254.29,31.28">𝑃𝑊 𝑄, 𝐷 = 1 𝑄 𝐿𝑒𝑛(𝐷) 𝑃𝑜𝑠(𝑞 𝑖 , 𝐷) 𝑞 𝑖 ∈𝑄 (4)</formula><p>Here 𝑄 is the number of different query terms in 𝑄, 𝑃𝑜𝑠(𝑞 𝑖 , 𝐷) is the first appearing position of query term 𝑞 𝑖 in 𝐷 and 𝐿𝑒𝑛 𝐷 is the length of 𝐷. This score is finally combined to the Similarity Score after scaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Query Combination.</head><p>Query preprocessing is adopted in our system. Each query is transformed into several forms: Phrase Query, Proximity Query, Ordinary Query, Expanded Query and Reshuffled Phrase Query. Each query form weighs differently and may be applied to different fields of documents. Query Expansion technique will be introduced in Section 3.4; Reshuffled Phrase Query denotes the Phrase Query formed by reshuffling the query terms; others are similar to <ref type="bibr" coords="5,274.36,324.11,10.66,9.05" target="#b2">[2]</ref>.</p><p>Our system uses the OKAPI BM25 <ref type="bibr" coords="5,285.22,341.51,11.90,9.05" target="#b3">[3]</ref> model to compute the Similarity Score between queries and documents' title, keywords, anchor text, H1, H2 and extracted body field respectively. Each field is calculated under five kinds of query formats mentioned above. The scores are combined linearly after normalization.</p><p>In order to achieve a combinable Similarity Score for different queries and document fields, we normalize each score into a value between [0, 1]. All the BM25 scores are obtained by using a form of standard BM25 formula with parameters k1 set to 1.2 and k2 to 20. We use the normalization introduced by <ref type="bibr" coords="5,287.36,493.33,10.75,9.05" target="#b4">[4]</ref>.</p><p>After obtaining the combined score, we use HostRank score to re-rank the documents. The re-ranking formula is:</p><formula xml:id="formula_4" coords="5,125.90,539.28,344.92,12.80">𝑆 𝑟𝑒𝑟𝑎𝑛𝑘 𝑄, 𝐷 = 𝑆 𝑏𝑚 25 𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑 𝑄, 𝐷 • 𝑃𝑊(𝑄, 𝐷) • (1 + 𝛼 • 𝐻𝑜𝑠𝑡𝑅𝑎𝑛𝑘 𝐷 )<label>(6)</label></formula><p>Where 𝑆 𝑏𝑚 25 𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑 𝑄, 𝐷 is the combined BM25 score and 𝐻𝑜𝑠𝑡𝑅𝑎𝑛𝑘 𝐷 is the HostRank score computed within the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Expert Search</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ExpertRank and Topic Sensitive ExpertRank</head><p>Compared to last year, the expert list is parsed from the corpus and thus may involve large noises. Hence we resort to static ranking method to handle this.</p><p>The idea of ExpertRank is to let experts vote for each other. A co-occurrence of two experts would contribute two directed links between them, one pointing from the first expert to the second and the other from the second back to the first. After this a directed graph is constructed, of which each vertex represents an expert candidate and each edge indicates a certain propagation of importance from the source to the target node. Then we can apply the ExpertRank algorithm to the expert graph. The algorithm is basically the same with PageRank algorithm, but different in the sense that here edges from one expert candidate to another are weighted. This is because two experts co-occurring regularly are meant to share much more importance with each other than with others. Below we describe the algorithm in detail. Some of the concepts and formulas are derived from <ref type="bibr" coords="6,286.15,264.59,10.66,9.05" target="#b1">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Expert Rank</head><p>Consider expert candidate c and c' pointing to c, P(c) represents the set of all possible c'. Let W(c',c) be the weight of the edge from c' to c, and W(c') be the sum of weights of outgoing edges of c'. Also the rank value of candidate c is regarded as Rank(c). For the initialization, Rank(c) for every candidate is set to 1/N, where N is the total number of expert candidates. Then the iteration of propagation is started until convergence. In each iteration i, the rank of each candidate c is re-computed as equation ( <ref type="formula" coords="6,165.27,368.51,3.64,9.05" target="#formula_5">7</ref>):</p><formula xml:id="formula_5" coords="6,182.30,386.03,288.52,26.57">𝑅𝑎𝑛𝑘 𝑖 𝑐 = 𝑅𝑎𝑛𝑘 𝑖-1 𝑐 ′ • 𝑊(𝑐 ′ , 𝑐)/𝑊(𝑐 ′ ) 𝑐 ′ ∈𝑃(𝑐)<label>(7)</label></formula><p>The computation can also be explained as eigenvector calculation as expressed by <ref type="bibr" coords="6,455.35,426.97,10.87,9.05" target="#b1">[1]</ref>:</p><formula xml:id="formula_6" coords="6,242.45,444.49,228.37,11.51">𝑅𝑎𝑛𝑘 = 𝑀 × 𝑅𝑎𝑛𝑘<label>(8)</label></formula><p>From this point of view, we did not really do the iteration in practice. Since the expert graph we built is symmetrical, it is easy to solve equation (8). The solution is:</p><formula xml:id="formula_7" coords="6,212.45,499.21,258.37,26.09">𝑅𝑎𝑛𝑘 𝑐 = 𝑐𝑜𝑜𝑐𝑐𝑢𝑟(𝑐, 𝑐 ′ ) 𝑑∈𝐷 𝑐′≠𝑐 (9)</formula><p>Here 𝐷 is the entire document collection. 𝑐𝑜𝑜𝑐𝑐𝑢𝑟(𝑐, 𝑐 ′ ) is 1 if 𝑐 and 𝑐 ′ co-occur in document 𝑑. After normalizing 𝑅𝑎𝑛𝑘 1 to 1, it yields the final ExpertRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>𝑅𝑎𝑛𝑘 𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑 𝑐 = 𝑅𝑎𝑛𝑘(𝑐)</head><p>𝑅𝑎𝑛𝑘 1</p><p>(10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Topic Sensitive ExpertRank</head><p>The intention of Topic Sensitive ExpertRank is that, the distributions of expert importance over different topics are not similar, and it's unreasonable to compare the importance of experts in different fields. Thus the rank value calculated by the global propagation is very rough. To perform more accurate statistic ranking and better approximate the importance of the expertise of experts, we clustered the entire corpus into 70 topic related categories by URL analysis. The clustering method is to first build a suffix tree of all URL hosts (together 100 in all) in the CSIRO corpus, and cut the tree at level 3. Besides, the term vector of each category is calculated and indexed. The real time computation of an expert candidate's final rank value involves the conditional probability 𝑃(𝑇 𝑘 |𝑞) , where q is the given query. 𝑃(𝑇 𝑘 |𝑞) is calculated using equation (12).</p><formula xml:id="formula_8" coords="7,178.34,476.52,292.48,29.81">𝑃 𝑇 𝑘 𝑞 = 𝑃(𝑇 𝑘 ) ⋅ 𝑃(𝑞|𝑇 𝑘 ) 𝑃(𝑞) ∝ 𝑃(𝑇 𝑘 ) ⋅ 𝑃(𝑞 𝑖 |𝑇 𝑘 ) 𝑖<label>(12)</label></formula><p>Here q i is the ith term of query q. In practices we use Query Expansion to better approximate the distribution of queries over the vocabulary.</p><p>The final rank value of candidate c, Rank(c), is computed by equation (13).</p><formula xml:id="formula_9" coords="7,209.33,565.57,261.49,26.09">𝑅𝑎𝑛𝑘 𝑐 = 𝑃 𝑇 𝑘 𝑞 • 𝑅𝑎𝑛𝑘 𝑘 (𝑐) 𝑘<label>(13)</label></formula><p>The Topic Sensitive ExpertRank is later multiplied to the similarity ranking value to yield the score of expert candidates. In the submitted runs we use Topic Sensitive ExpertRank instead ExpertRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Preprocessing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Parsing Corpus for Expert Name List</head><p>Using the full name as email address is recommended in many enterprises for easily management. Benefited from this, we match emails to expert names by extracting them directly from the email address. Two problems calls for attention in the process of parsing email appearance. The first is how to handle anti-spam formats while the second is how to recognize the emails that are not dedicated for a single person. Our method firstly replaces all the tokens such as "dot", "at" and "atmark" by the corresponding symbols. Then we use an enhanced regular expression to detect all the emails from context. We also extract emails containing "first" as a substring, such as firstname.lastname and firstname.surname. Named Entity Recognization Tool is used to extract all the names in the context of these emails to complete the candidate list.</p><p>To handle the problem of non-personal emails and build a clean expert name list, we construct several filtering rules:</p><p> Filter out emails that do not end with the host name of the organization.  Filter out emails containing numbers.  Filter out emails with host names appearing in the person name part. Host names are extracted from the URL hosts. (e.g. If URL http://www.bio.csiro.au/* exists in the corpus, the email xxx.bio@csiro.au should be filtered.)  Filter out emails with single letter in its person name part.</p><p>After this a list of expert candidates (both names and their corresponding emails) is obtained, and we are able to perform the expert identification algorithm <ref type="bibr" coords="8,440.66,552.97,12.70,9.05" target="#b2">[2]</ref> we proposed last year to index all the appearances of expert candidates in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">VisualPageRank and Expert Homepage Detection</head><p>The intention of VisualPageRank is to recognize and degrade pages that are unhelpful or too noisy to establish a good evidence for expert search, while Expert Homepage Detection contributes in the opposite way by detecting and upgrading highly possible expert homepages to support the correspondent experts.</p><p>Through observation we find that unhelpful or noisy pages come from either too simple or too complicated pages. So we explore into the HTML structure of web pages. A Vision based content tree is built by separating texts using a group of tags.</p><p>Thresholds are set to the number of blocks and total depth of the tree. By degrading the score of pages that are below the lower threshold or above the upper threshold, we are able to reduce their influences to the task.</p><p>For Expert Homepage Detection, since we only want to utilize the highly possible expert homepages, we simply run the expert name identification algorithm <ref type="bibr" coords="9,426.19,201.56,12.60,9.05" target="#b2">[2]</ref> on title field of pages, and filter out pages that contain only low confidence name masks <ref type="bibr" coords="9,445.66,212.96,13.70,9.05" target="#b2">[2]</ref> or multiple expert candidates. The left pages are viewed as the homepage to the corresponding expert in its title, and their support to the homepage owner are boosted.</p><p>Note that the score of a page here denotes to Q d in <ref type="bibr" coords="9,328.00,253.55,10.66,9.05" target="#b2">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Query Expension</head><p>As mentioned above, to better approximate the distribution of queries over term vocabulary, we adopt Query Expansion in our system. Query Expansion is used in two ways in the system, the first is to serve as one additional query format for the computation of Q q in [2], the other is for calculating 𝑃 𝑇 𝑘 𝑞 in equation (8).</p><p>The candidate terms of Query Expansion comes from the narrative fields of given topics. There are two approaches for selecting terms. The first is quite straight forward, by calculating the inverse document frequency of each word. Three terms with the highest score are added into the original query term bag. The second approach we try is to extract a window based context vector in the corpus for each candidate term, and calculate the cosine similarity between the context vector and the query vector. Also three words with the highest score are then selected. The idea of this approach is to keep the topic of the query focused during the expansion. Finally the first is adopted among the final runs, since the window size for context extraction is very hard to determine lacking training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment Result</head><p>Here we list the evaluation results of the 4 Document Search runs and 4 Expert Search runs we submitted from TREC committee. Table <ref type="table" coords="9,330.74,526.09,4.98,9.05" target="#tab_2">2</ref> and Table <ref type="table" coords="9,383.59,526.09,4.98,9.05" target="#tab_3">3</ref> show the results of Document Search and Expert Search respectively. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,230.09,316.49,135.05,8.18;7,124.82,339.10,326.30,9.87;7,208.49,360.46,23.23,9.96;7,231.65,364.84,3.84,6.96;7,240.65,360.46,19.32,9.96;7,297.53,360.46,52.60,9.96;7,350.59,359.66,1.52,6.33;7,352.51,360.46,4.13,9.96;7,278.33,375.64,16.75,8.31;7,262.73,375.64,13.40,6.96"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A Sample of URL Suffix TreeFor each category (topic) T k , we bias the ExpertRank vectors using equation (11).𝑅𝑎𝑛𝑘 𝑘 𝑐 = 𝑐𝑜𝑜𝑐𝑐𝑢𝑟(𝑐, 𝑐 ′ ) 𝑑∈𝑇 𝑘 𝑐′≠𝑐</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,124.82,264.41,345.80,97.67"><head>Table 1 .</head><label>1</label><figDesc>Example of anti-spam formats</figDesc><table coords="8,124.82,287.51,345.80,74.57"><row><cell>Email</cell><cell>Anti-Spam Format</cell></row><row><cell>Tom.McGinness@csiro.au</cell><cell>Tom . McGinness @ csiro . au</cell></row><row><cell></cell><cell>Tom DOT McGinness AT csiro DOT au</cell></row><row><cell></cell><cell>firstname.lastname@csiro.au (Tom McGinness shows</cell></row><row><cell></cell><cell>in the same page.)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,124.82,555.43,345.80,133.70"><head>Table 2 .</head><label>2</label><figDesc>Evaluation of Document Search Runs BASE includes all the techniques we mentioned in Section 2 except Reshuffled Phrase Query (denoted here as RS-PQ). STEM stands for stemming of words before indexing. Run SJTUEntDS04 is different from SJTUEntDS01 since it's a feedback run which uses given key pages to perform further Query Expansion.</figDesc><table coords="9,124.82,578.53,336.44,99.08"><row><cell>Run ID</cell><cell cols="2">DS-BASE RS-PQ</cell><cell>STEM</cell><cell>MAP</cell><cell>R-PREC</cell></row><row><cell cols="2">SJTUEntDS01 Y</cell><cell>N</cell><cell>N</cell><cell>0.3130</cell><cell>0.3365</cell></row><row><cell cols="2">SJTUEntDS02 Y</cell><cell>Y</cell><cell>N</cell><cell>0.3793</cell><cell>0.3934</cell></row><row><cell cols="2">SJTUEntDS03 Y</cell><cell>N</cell><cell>Y</cell><cell>0.3222</cell><cell>0.3395</cell></row><row><cell cols="2">SJTUEntDS04 Y</cell><cell>N</cell><cell>N</cell><cell>0.3295</cell><cell>0.3454</cell></row><row><cell>Here DS-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,124.82,178.94,345.76,168.14"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of Expert Search Runs BASE includes the Email Parsing, VisualPageRank, Query Expansion and the system last year<ref type="bibr" coords="10,203.44,303.59,12.31,9.05" target="#b2">[2]</ref> excluding Cluster Based Re-ranking. The exclusion is because the clustering of automatically parsed expert list is very inaccurate compared to the predefined list last year. TS-ER stands for Topic Sensitive ExpertRank while HP-DT refers to Homepage Detection.</figDesc><table coords="10,124.82,202.04,328.75,99.08"><row><cell>Run ID</cell><cell cols="2">ES-BASE TS-ER</cell><cell>HP-DT</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell cols="2">SJTUEntES01 Y</cell><cell>N</cell><cell>N</cell><cell>0.4395</cell><cell>0.6140</cell></row><row><cell cols="2">SJTUEntES02 Y</cell><cell>Y</cell><cell>N</cell><cell>0.4343</cell><cell>0.6039</cell></row><row><cell cols="2">SJTUEntES03 Y</cell><cell>N</cell><cell>Y</cell><cell>0.4427</cell><cell>0.6131</cell></row><row><cell cols="2">SJTUEntES04 Y</cell><cell>Y</cell><cell>Y</cell><cell>0.4410</cell><cell>0.6146</cell></row><row><cell>Here ES-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,129.32,376.41,64.64,10.72" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Reference</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.94,403.30,322.33,9.06" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,200.81,403.31,104.14,9.05">Topic-Sensitive PageRank</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,325.85,403.30,104.44,9.06">Proceedings of WWW2002</title>
		<meeting>WWW2002</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,140.50,420.83,329.83,9.05;10,124.82,432.36,345.88,9.06;10,124.82,443.88,129.72,9.06" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,389.15,420.83,81.18,9.05;10,124.82,432.37,176.26,9.05">Research on Expert Search at Enterprise Track of TREC 2006</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,325.49,432.36,145.21,9.06;10,124.82,443.88,100.31,9.06">proceedings of 15th Text Retrieval Conference (TREC 2006)</title>
		<meeting>15th Text Retrieval Conference (TREC 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,139.10,461.41,318.34,9.05;10,124.82,472.80,120.24,9.06" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,356.47,461.41,95.36,9.05">Gatford: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,136.90,472.80,103.73,9.06">Text REtrieval Conference</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,139.10,490.33,331.19,9.05;10,124.82,501.85,338.06,9.05;10,124.82,513.36,337.61,9.06;10,124.82,524.89,22.65,9.05" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="10,170.90,501.85,272.75,9.05">Microsoft Research Asia at Web Track and Terabyte Track of TREC</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>In: proceedings of the Thirteenth Text Retrieval Conference Proceedings (TREC-2004</note>
</biblStruct>

<biblStruct coords="10,139.10,542.29,325.08,9.05;10,124.82,553.80,224.59,9.06" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,316.37,542.29,147.81,9.05;10,124.82,553.81,68.77,9.05">Exploiting the Hierarchical Structure for Link Analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,213.89,553.80,105.73,9.06">Proceedings of SIGIR2005</title>
		<meeting>SIGIR2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,139.10,571.33,304.13,9.05;10,124.82,582.85,332.30,9.05;10,124.82,594.37,270.66,9.05" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,316.49,571.33,126.74,9.05;10,124.82,582.85,100.83,9.05">The PageRank citation ranking: Bringing order to the web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<idno>SIDL-WP-1999-0120</idno>
		<imprint>
			<date type="published" when="1998">1998. 1999</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Digital Library Technologies Project</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
