<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,85.26,87.44,441.49,14.82">Topic Categorization for Relevancy and Opinion Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,167.22,120.40,78.83,10.16"><forename type="first">Guangxu</forename><surname>Zhou</surname></persName>
							<email>gxzhou@ualr.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Arkansas at Little Rock Little Rock</orgName>
								<address>
									<postCode>72204</postCode>
									<region>AR</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.09,120.40,72.09,10.16"><forename type="first">Hemant</forename><surname>Joshi</surname></persName>
							<email>hemant.joshi@acxiom.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Acxiom Research</orgName>
								<orgName type="institution">Acxiom Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.78,120.40,80.01,10.16"><forename type="first">Coskun</forename><surname>Bayrak</surname></persName>
							<email>cxbayrak@ualr.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Arkansas at Little Rock Little Rock</orgName>
								<address>
									<postCode>72204</postCode>
									<region>AR</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,85.26,87.44,441.49,14.82">Topic Categorization for Relevancy and Opinion Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AEA2B69DA2DAAA2884CEC27656C488B6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>University of Arkansas at Little Rock's Blog Track team participated in only the core task of the blog track this year. The data acquired was identical to that of previous year except some new .retrieval tasks were introduced. The core task was to identify blogs that are opinionated about a certain subject. Fifty new topics were provided by National Institute of Standards and Technology (NIST) this year. Apart from the core task, two subtasks were also introduced. Polarity subtask was to detect polarity of the opinionated blog about a given topic. Feed distillation subtask was based on finding feeds rather than individual permalinks. Last year, we participated in the core task <ref type="bibr" coords="1,218.29,364.00,12.23,10.16">[1]</ref> and this year we planned to continue on our previous work. Although an attempt was made last year to use Active Learning with Support Vector Machine (SVM) to detect opinionated blog, identifying the opinion expressed about a given topic was unsuccessful. The difference this time around is in the use of search engines to conduct the topic search, categorizations of queries for further training, and a Natural Language based "onepass-processing" approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>Total of 6 runs were allowed for each participating team this year. The blog data provided [2] [3] consists of approximately 3.2 million permalinks from 100,649 feeds. The data consists of spam blogs as well as non-English language blogs. Also the opinions expressed may be in colloquial form or in abbreviations commonly used as chat lingo over the internet. Once opinion is detected, we need to find out if the opinion expressed is about a particular topic. Using paragraphs or passages as the context of opinion detection has shown to produce good results <ref type="bibr" coords="1,72.00,543.45,11.48,10.16">[4]</ref>. We intended to limit our focus not through windowing techniques but through combination of Natural Language Processing (NLP) and Machine Learning techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Categorization</head><p>Apart from blog data, we also analyzed the 50 topics provided this year and divided them into 6 categories namely thing, company, food, event, location and person. Figure <ref type="figure" coords="1,474.74,609.04,6.09,10.16" target="#fig_0">1</ref> shows the distribution of 2007 blog track topics. Categorization of topics helped us get a general idea about the topics. We were able to come up with generic patterns to detect an opinion for each category. Category identification was useful in Categorized Machine Learning approach that we will discuss later in this paper. Majority of the queries were in person, company, thing and event categories. We submitted total of 6 runs: 2 baseline and 4 other runs each using a different approach. The baseline run, UALR07BlogBase, was obtained with Indri search engine, part of Lemur language Modeling toolkit [5] with pseudo document feedback. Topics given were simply mapped to Indri syntax. We did not use query expansion for the base run. We used title field only for the UALR07BlogBase run. For the second base run, UALR07TDN we used Title and description as well as narrative fields. Below we describe the other 4 runs submitted, each with a different approach.</p><p>1. UALR07BlogIU: IU run was our significant contribution this year to blog track. This run is based on assumption that presence of subjectivity indicators near topic or query words is good indicator of the content opinionated about a given topic. We chose words like "I", "you", "we", "me" as well as words such as "like", "feel", "think" etc. and mapped the distance of these words to the topic given a window size of 10 or 20 words. We believe that the presence of subjectivity indicator words near the topic under investigation provides a clue for selecting these blogs with a preference.</p><p>Run UALR07BlogIU was a run using modified indri queries. We used unordered window size of 20 words (#uw20 in indri query syntax). Only title field from the given topics was considered for this run. We looked for words such as {me, we, I, they, you, he, she} and also words such as {like, love, hate, suck, nice, good, bad, awesome, awful, never, think and, feel} within unordered window of 20 words to topics such as Mozart. This allowed for weighting those queries that consist of word Mozart along with opinion indicators higher than blogs that only contain word Mozart or generic opinion words. Our initial experiments showed an improvement by using relaxed window size of 20 instead of 10.</p><p>The unordered window was preferred because we were not certain about the order in which a topic and opinion about that topic will be expressed.</p><p>2. UALR07BlogIU2: IU2 run was designed to be an improvement over IU run discussed above. Instead of title only, we used narrative and description fields for the given topic and expanded the query to contain those extra words near the opinion indicator words.</p><p>The opinion indicator words were the same as those used in UALR07BlogIU run. So UALR07BlogIU run is title only run whereas UALR07BlogIU2 is Title-Description and Narrative based run (TDN). The reason for using TDN fields was to increase recall levels, especially in the lower ranks for each topic results. Again the queries were modified to be compatible with Indri format and unordered window of 20 words was used.</p><p>3. UALR07BlogCML: Categorized Machine Learning (CML) run was designed to take advantage of the 6 general categories of topics. In the previous year we trained SVM on all topics and used active learning approach to judge the most difficult blogs to make a prediction. This approach, although promising, seems to focus on only certain topics rather than all 50 of them. We need to be able to generalize queries and train SVMs to detect opinions in each of those categories. So we trained SVM with linear kernel and C-SVM on each of the 6 categories mentioned earlier. Using active learning we further trained SVM to predict opinionated blogs in that category. Next based on each query we predicted opinionated blogs from the top 1500 results obtained for each query using Indri. We re-ranked these 1500 results giving more importance to opinionated blogs. This approach addresses issues with topic relevance as well as uses machine learning techniques to build category specific models for prediction of opinionated blogs. The other significant difference from that of the last year was limiting the scope of prediction not to all the given categories but only to top 1500 results obtained for each query in that category. This eliminates noise or spam blogs and thus should produce better accuracy than the one reported in the previous year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">UALR07Text:</head><p>We used a new natural language based "one-pass-processing<ref type="foot" coords="3,532.50,375.78,3.90,6.49" target="#foot_0">1</ref> " approach for this run. We did not rely on Indri's language model to generate results of the run. Instead we used complete Natural Language Processing approach and regular expressions for retrieval. We parsed permalink documents to extract text from only English blogs. Blogs in languages other than English were ignored. We then segmented each text permalink into passages and used sum of passages matching hand crafted regular expressions of topic to generate final score of each document. Finally, we ranked all documents in descending order of scores. Using passage for establishing a context is a promising idea since it will eliminate possibilities of blogs referring to the words in the topic but not expressing opinion about the topic. Passages are of flexible length and usually referred to &lt;p&gt; and &lt;/p&gt; tags in HTML documents. We also wanted to compare performance of NLP approach with that of language modeling where we determine probabilistic values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head><p>We compare results from all 6 runs. Table <ref type="table" coords="4,103.42,335.74,6.09,10.16" target="#tab_2">2</ref> shows the opinion results comparison of the 6 runs submitted. The highest values are shown in bold numbers for each row. Also for Mean Average Precision comparison, results of UALR07BlogIU run reported best values. From tables 1 and 2, it can be concluded that presence of opinion words near a topic is a good approach to identify blogs that are opinionated about a particular topic.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We experimented with 3 different approaches and evaluated their performances in detecting blogs that are opinionated about a given topic. UALR07Text run performs as good as indri baseline run and in fact has even better results for certain topics. We intend to refine our technique and make some improvements over the results of UALR07Text run. CML and IU runs also provided new intuitive way of looking at opinion detection problem. Both performed satisfactorily over the baseline.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,124.68,310.30,362.51,10.16"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Categorization of 2007 blog track topics into 6 generic categories</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,72.00,636.58,467.96,10.16;4,72.00,649.18,467.96,10.16;4,72.00,661.84,467.93,10.16;4,72.00,674.50,379.03,10.16"><head>Figure 2 ,Figure 2 :Figure 3 :</head><label>223</label><figDesc>Figure2, shows the interpolated precision-recall response comparison between the 6 runs submitted for topic relevance. Similarly, Figure3shows the interpolated precision recall response comparison for opinion detection. All 4 runs, UALR07BlogIU, UALR07BlogCML, UALR07BlogIU2, and UALR07Text performed better than the 2 baseline runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,72.00,582.64,468.03,35.42"><head>Table 1 :</head><label>1</label><figDesc>Table 1 shows the topic relevance results comparison over 50 queries for all runs submitted. The numbers in bold are the highest values for the judging criteria. Mean Average Precision (MAP) values are shown with gray background. Topic Relevance Results comparison of 6 runs submitted</figDesc><table coords="4,72.00,100.42,444.57,207.50"><row><cell></cell><cell>UALR07</cell><cell>UALR07BlogI</cell><cell>UALR07</cell><cell>UALR07</cell><cell>UALR07Blo</cell><cell>UALR07</cell></row><row><cell></cell><cell>Base</cell><cell>U</cell><cell>CML</cell><cell>BlogIU2</cell><cell>gTDN</cell><cell>Text</cell></row><row><cell>num_rel</cell><cell>12187</cell><cell>12187</cell><cell>12187</cell><cell>12187</cell><cell>12187</cell><cell>12187</cell></row><row><cell>num_rel_ret</cell><cell>7846</cell><cell>7881</cell><cell>7846</cell><cell>7256</cell><cell>6817</cell><cell>7612</cell></row><row><cell>map</cell><cell>0.3401</cell><cell>0.3612</cell><cell>0.3316</cell><cell>0.3292</cell><cell>0.2931</cell><cell>0.3081</cell></row><row><cell>P5</cell><cell>0.624</cell><cell>0.796</cell><cell>0.58</cell><cell>0.784</cell><cell>0.664</cell><cell>0.556</cell></row><row><cell>P10</cell><cell>0.628</cell><cell>0.734</cell><cell>0.59</cell><cell>0.74</cell><cell>0.652</cell><cell>0.534</cell></row><row><cell>P15</cell><cell>0.6147</cell><cell>0.708</cell><cell>0.6027</cell><cell>0.6973</cell><cell>0.6187</cell><cell>0.5253</cell></row><row><cell>P20</cell><cell>0.6</cell><cell>0.675</cell><cell>0.584</cell><cell>0.67</cell><cell>0.589</cell><cell>0.51</cell></row><row><cell>P30</cell><cell>0.578</cell><cell>0.6353</cell><cell>0.564</cell><cell>0.6133</cell><cell>0.5533</cell><cell>0.4967</cell></row><row><cell>P100</cell><cell>0.471</cell><cell>0.4864</cell><cell>0.4714</cell><cell>0.4604</cell><cell>0.419</cell><cell>0.4304</cell></row><row><cell>P200</cell><cell>0.3801</cell><cell>0.3886</cell><cell>0.3814</cell><cell>0.3628</cell><cell>0.3296</cell><cell>0.3499</cell></row><row><cell>P500</cell><cell>0.2468</cell><cell>0.2534</cell><cell>0.2496</cell><cell>0.2263</cell><cell>0.2149</cell><cell>0.2248</cell></row><row><cell>P1000</cell><cell>0.1569</cell><cell>0.1576</cell><cell>0.1569</cell><cell>0.1451</cell><cell>0.1363</cell><cell>0.1522</cell></row><row><cell>From</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.00,297.76,467.95,22.82"><head>Table 1 ,</head><label>1</label><figDesc>UALR07BlogIU run reported highest MAP and precision_at_N values. We also notice that MAP is less for UALR07BlogTDN run compared to UALR07BlogBase run.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,76.68,411.58,451.71,209.42"><head>Table 2 :</head><label>2</label><figDesc>Opinion Results comparison for 6 runs submitted</figDesc><table coords="4,76.68,439.18,451.71,181.82"><row><cell></cell><cell>UALR07</cell><cell>UALR07BlogI</cell><cell>UALR07</cell><cell>UALR07</cell><cell>UALR07Blo</cell><cell>UALR07</cell></row><row><cell></cell><cell>Base</cell><cell>U</cell><cell>CML</cell><cell>BlogIU2</cell><cell>g TDN</cell><cell>Text</cell></row><row><cell>num_rel</cell><cell>7000</cell><cell>7000</cell><cell>7000</cell><cell>7000</cell><cell>7000</cell><cell>7000</cell></row><row><cell>num_rel_ret</cell><cell>4717</cell><cell>4736</cell><cell>4717</cell><cell>4313</cell><cell>3976</cell><cell>4545</cell></row><row><cell>map</cell><cell>0.2554</cell><cell>0.2911</cell><cell>0.2521</cell><cell>0.265</cell><cell>0.2102</cell><cell>0.2183</cell></row><row><cell>P5</cell><cell>0.452</cell><cell>0.632</cell><cell>0.432</cell><cell>0.636</cell><cell>0.428</cell><cell>0.456</cell></row><row><cell>P10</cell><cell>0.44</cell><cell>0.58</cell><cell>0.42</cell><cell>0.558</cell><cell>0.406</cell><cell>0.408</cell></row><row><cell>P15</cell><cell>0.4187</cell><cell>0.5427</cell><cell>0.4227</cell><cell>0.524</cell><cell>0.3773</cell><cell>0.3787</cell></row><row><cell>P20</cell><cell>0.402</cell><cell>0.51</cell><cell>0.407</cell><cell>0.492</cell><cell>0.36</cell><cell>0.37</cell></row><row><cell>P30</cell><cell>0.374</cell><cell>0.4647</cell><cell>0.3753</cell><cell>0.446</cell><cell>0.3333</cell><cell>0.3493</cell></row><row><cell>P100</cell><cell>0.283</cell><cell>0.3274</cell><cell>0.2872</cell><cell>0.3092</cell><cell>0.2414</cell><cell>0.2716</cell></row><row><cell>P200</cell><cell>0.2275</cell><cell>0.2443</cell><cell>0.231</cell><cell>0.2261</cell><cell>0.1875</cell><cell>0.2179</cell></row><row><cell>P500</cell><cell>0.1484</cell><cell>0.1544</cell><cell>0.1506</cell><cell>0.1344</cell><cell>0.1228</cell><cell>0.1361</cell></row><row><cell>P1000</cell><cell>0.0943</cell><cell>0.0947</cell><cell>0.0943</cell><cell>0.0863</cell><cell>0.0795</cell><cell>0.0909</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,83.10,675.55,456.75,9.27;3,72.00,687.55,467.97,9.27;3,72.00,699.07,162.94,9.27"><p>A new dictionary based paragraph scoring method, which is designed to handle the ranking of topic relevance and opinion detection at the same time, since the topic-relevance and opinion-finding have similar effect on scoring and ranking.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="institution">NIST</rs> for taking the lead to organize the TREC conference and the people who made it a pleasant experience by participating in it. We also would like to thank <rs type="person">Dr. Nasrolah Samadi</rs>'s constructive comments in revising this manuscript.</p></div>
			</div>			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
