<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,190.08,87.16,249.54,15.84">Document Structure with IRTools</title>
				<funder ref="#_EdREmDz">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,267.36,108.12,91.70,12.00"><forename type="first">Gregory</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Arctic Region Supercomputing Center</orgName>
								<orgName type="institution">University of Alaska Fairbanks</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,190.08,87.16,249.54,15.84">Document Structure with IRTools</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F6846C06069EFFEFA959E16641C9BC90</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The IRTools software toolkit was modified for 2003 to utilize a MySQL database for the inverted index. Indexing was for each occurrence of each term in the collection, with HTML structure, location offset, paragraph, and subdocument weight considered. This structure enables some more sophisticated queries than a "bag of words" approach. Post hoc results from the TREC 2002 Named Page Web task are presented, in which a staged fall through approach to topic processing yielded good results, with exact precision of 0.49. The paper also provides an overview of IRTools and its interactive interface, as well as an invitation for IR researchers to get involved with the GridIR standards formation process.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>This year, the IRTools software toolkit was not quite ready in time for the TREC 2003 Web submission. Instead, this paper describes a set of runs on the 2002 Named Page Web track completed in October and November 2003. The paper should be interesting to TREC participants because it describes a rather different, and considerably more flexible, approach to information retrieval (IR) than described in the author's prior TREC entries <ref type="bibr" coords="1,468.13,379.56,41.69,12.00;1,90.00,393.24,25.84,12.00">(Newby, 2002)</ref>.</p><p>IRTools is a software toolkit intended for IR research. Development was partially funded by the NSF, and the software is freely downloadable at http://sourceforge.net/projects/irtools. The goal of IRTools, scheduled for official release in 2004, is to operate as a programmer's toolkit for IR experimentation. It encompasses several major IR models (the vector space model or VSM, Boolean retrieval, and variations on latent semantic indexing or LSI). It enables both interactive use via a Web-based front end, and batch-oriented retrieval for TREC-like experiments.</p><p>IRTools is one of several systems being adopted as a reference system for Grid Information Retrieval (GIR, see http://www.gridir.org), a working group under the Global Grid Forum (http://www.gridforum.org), which the author co-chairs. GIR-WG has presented requirements and architecture documents <ref type="bibr" coords="1,290.69,573.48,96.01,12.00" target="#b1">(Gamiel et al. 2003;</ref><ref type="bibr" coords="1,389.70,573.48,87.87,12.00" target="#b4">Nassar et al. 2003)</ref>, and members of the working group are developing reference implementation systems as both proof-of-concept and early models for operational systems. GridIR is similar to WAIS <ref type="bibr" coords="1,90.00,615.00,90.84,12.00" target="#b2">(Kahle et al., 1992)</ref>, in that multiple retrieval collections are federated in ad hoc ways to provide merged results. GridIR operates in standards-based environment such as Web services (http://www.w3c.org/2002/ws) and the Open Grid Services Architecture and other Grid standards <ref type="bibr" coords="2,163.38,73.80,65.88,12.00" target="#b0">(Foster, 2003)</ref>. These standards offer infrastructure for end-to-end security, event notification, and other capabilities.</p><p>In this paper, some of the back-end of IRTools is described. Post hoc results from the 2002 Named Page Web track results are presented. Future research is described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Structure and Back End</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Similarly to most long-time TREC participants, the author has gone through many different variations in the code base for IRTools and predecessor systems. Fundamentally, though, these IR systems have several main components and purposes in common:</p><p>1. Document metadata, in which documents are assigned document ID numbers (docids). How many terms per document? What TREC document number (docnum), URL or other label is associated with a document? 2. Term metadata, in which terms are assigned term ID numbers (termids). How frequently does the term occur in a collection? 3. Inverted index, in which lists of docids for each termid are stored for quick lookup.</p><p>How frequently does term i occur in document j, and at what locations in the document? 4. Sequential index, in which representations of documents are stored for relevance feedback, query expansion, context extracts, etc. What terms occur near term i in document j?</p><p>One of the largest fundamental technical challenges for nearly all IR systems is to quickly determine a set of candidate docids, given a list of termids as query. Set building occurs when the individual lists of docids from inverted index entries are merged (or sorted and merged). Once the sets are built, ranking of results can occur. This general approach is taken regardless of whether a Boolean AND or a Boolean OR is used, as well as for relevance feedback or other forms of query expansion.</p><p>We can consider the problem of information retrieval in terms of matrices of term-document relations. Table <ref type="table" coords="2,170.68,535.08,6.00,12.00" target="#tab_0">1</ref> shows a small set of documents and their term frequencies:  The advantage of the method shown in Table <ref type="table" coords="3,310.00,185.40,6.00,12.00" target="#tab_1">2</ref> over Table <ref type="table" coords="3,373.66,185.40,6.00,12.00" target="#tab_0">1</ref> is that significant space savings results by not storing the zero cells (well over 99% of cells in large IR test collections). Furthermore, multi-way sort and merge algorithms (see <ref type="bibr" coords="3,359.45,213.00,64.02,12.00" target="#b3">Knuth, 1998)</ref> enable stepping through the list of postings for each query term without requiring that the entire inverted index, or even a complete row of postings, be in main memory.</p><p>The benefit of the inverted index is not without a price, however: in Table <ref type="table" coords="3,448.37,268.44,4.50,12.00" target="#tab_0">1</ref>, it is a simple matter to see what terms occur in a particular document by reading down the columns, and document statistics such as average term frequency are easily computed on the fly. With an inverted index, the other structures mentioned earlier (or something similar) are required for computing term and document weights and for query expansion.</p><p>In practice, of course, there is considerable variety in exactly what is needed by a particular IR system for effective ranking. By post-processing the inverted index, for example, it might be possible to rank entries by document weight, such that early entries are more likely to be associated with highly ranked documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Postings in IRTools</head><p>In past years, IRTools and earlier systems have used a variety of file structures to store the inverted index and other data about an IR test collection. The primary desire left unfulfilled by these file structures is to consider document qualities beyond the "bag of words" level. The bag of words, which is one of the fundamental (often implicit) approaches used in IR literature, looks at term occurrences in documents but not at where those terms occur. Furthermore, the bag of words model does not take document structure into account -for example, HTML documents have title tags, meta tags, paragraph tags, and so forth which might be important for computing the weight of a term in a document. Moreover, term position within documents is the fundamental element for phrase matching, or adjacency/nearness measures. Alternate structures, such as PAT arrays <ref type="bibr" coords="3,435.79,562.44,97.52,12.00" target="#b1">(Gonnet et al., 1992)</ref>, may be employed for this, but for current purposes we would like to see whether the inverted index might be modified to add these capabilities.</p><p>By taking document structure and term position into account, new types of queries are enabled. "Term 1, near term 2, both in a TITLE tag." "Term 1 and Term 2 in the same paragraph tag will be weighted twice as much as when they are not in the same paragraph." "Term 1 and Term 2 in the same document, but without Term 3 as a table heading."</p><p>Two challenges were encountered in implementing this level of analysis. First, the model needed to change from a bag of words, in which a posting in the inverted index is made for each term in each document, to a model where information needs to be stored for each occurrence of a term in each document. Secondly, in addition to fast search methods at the term level (i.e., the rows in  The size and range of unsigned integers (uints) is 4 bytes, from 0 to 4GB, unsigned smalls (usmall) is 2 bytes (0 to 64K), and tiny integers (utiny) from 0 to 255. This nets 17 bytes per posting -that is, per term occurrence in a document, plus overhead and indexing. As shown in Table <ref type="table" coords="4,132.66,405.96,4.50,12.00" target="#tab_4">4</ref>, an index was built on each of these database columns as well as combinations of columns, which more than doubled both insertion time and the database size on disk, but allowed many queries to run without requiring linear searches through the postings.</p><p>In the postings, Offset is simply the word number in the document, with any term offset over 64K being skipped. WhichPara is simply the paragraph number (with some simple rules for "what is a paragraph" in HTML, implemented in the LibWWW parser), with any paragraphs over 255 being mapped to 255. WeightInSubdoc is simply a traditional document weight that is incremented for additional occurrences. The ability to uniquely weigh a term occurrence within a document is powerful, but further research is needed to determine what sort of weighting scores to implement.</p><p>TagListID is the most interesting column. In the collection, a list of all HTML tag sequences was kept. For example, well-formed HTML should start (after a DOCTYPE) with an HTML tag, a HEAD tag, and perhaps a TITLE or META tag. So, the first title term might occur in a tag sequence such as: HTML, HEAD, TITLE. In the inverted index, a unique TagListID was assigned to each tag sequence. By normalizing the HTML data and forcing them to be indexed as well formed, this enables searches for terms in title tags, as well as much more specific searches (e.g., terms in italics, in table columns, in table rows, in the body section of an HTML document). In practice, it was found that just under 64K unique TagListIDs were needed for the Web02 collection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Indexing the Web02 Collection</head><p>IRTools was used to index the TREC Web02 test collection of 1.2M HTML documents (about 20GB). Other than the MySQL database described above, the main innovation this year was to add a complete HTML parser. LibWWW from the World Wide Web consortium was chosen. LibWWW has proven to be fast and reasonably efficient, but poorly documented and rife with memory leaks that occur in ongoing use (such as the multi-day indexing process of Web02). Term and document information was stored in Berkeley DB files, as in prior years, and the sequential index was dropped, because it can be efficiently generated by selecting all postings for a DocID from the MySQL database.</p><p>Statistics for the Web02 collection are presented in Table <ref type="table" coords="5,368.38,568.68,4.50,12.00" target="#tab_5">5</ref>. Terms with more than 20 occurrences in a document were arbitrarily capped at 20 (although term counts continued to accrue, data concerning the 21 st term occurrence and beyond were omitted). All terms were considered, without use of a stoplist, truncation or stemming. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Flexibility</head><p>With the use of the MySQL database and indices on all columns, IRTools is suitable for both batch-oriented TREC topics, as well as a variety of on-demand queries. Context-sensitive document extracts are simply a matter of retrieving a range of database rows for a particular DocID. So is a title for display.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks and Outcomes</head><p>The revisions to IRTools discussed here were not quite ready in time for the TREC 2003 Web track deadline (results from running TREC 2003 tasks on last year's system were submitted instead). Here, we present results using relevance judgments (qrels) from the TREC 2002 Named Page finding task of the Web track. In that task, the goal was to identify particular pages or Web sites based on a description of their name. By its nature, this is a task that desires relatively small response sets for high precision. Only a few relevant pages were identified for most topics. Four runs, plus a combined run, were evaluated in two different scenarios.</p><p>• Run 1 searched only the HTML title tag for query terms. Weighting for this and all other runs favored the exact query phrase, but was otherwise Lnu.Ltc using the VSM. • Run 2 looked for the exact query phrase within the same paragraph (where paragraph is defined as any block-level set of text, including tags such as p, table, and ul). • Run 3 ranked documents containing all query terms with offsets plus or minus 10 from one another. (The actual implementation was that each query term had to be within 10 terms from the first query term.) • Run 4 was a "bag of words" approach, in which any document with all query terms was considered for ranking. • The fifth set was the combination of all prior sets. These results are summarized in Tables <ref type="table" coords="8,161.00,224.27,6.00,13.28" target="#tab_6">6</ref> and<ref type="table" coords="8,190.33,224.27,4.50,13.28" target="#tab_7">7</ref>.</p><p>It was speculated that the four runs could operate in a "fall through" manner: if run 1 yielded no results for a particular topic, run 2 would ensue. Similarly, run 3 would only occur for a topic if run 2 yielded no results. The bag of words approach in run 4 was, essentially, a move of desperation. Thus, the "Combined" column of Table <ref type="table" coords="8,361.02,293.15,6.00,13.28" target="#tab_6">6</ref> is the result of all 150 topics in which one or more of the runs were completed, only the last of which produced results. This is the fall through scenario.</p><p>The other scenario is to simply use each method alone on all 150 topics. At the outset, we presumed that Run 1 would provide the highest precision, while Run 4 would find additional relevant documents but at the expense of far lower recall.  <ref type="table" coords="9,120.32,72.35,6.00,13.28" target="#tab_6">6</ref> shows that relatively high precision was achieved in Run 1 (title only), but at the expense of many queries for which no results were submitted. 34 topics resulted in 142 documents identified as potentially relevant, 20 of which actually were. Most topics only produced a few documents, with only 64 ("work/life center map"), 88 ("export import bank") and 137 ("endangered species picture book") in the double digits with 31, 31, and 14 documents each, but none was relevant. Those topics are in contrast to topics that hit exactly, with one to three documents found, all of which were relevant.</p><p>Of the 116 (150 -34) topics submitted to Run 2 (exact phrase), only 13 resulted in documents being presented, and with lower scores overall than Run 1. As would be expected, exact phrase is not necessarily indicative of a named page -and in this case, the named pages with exact phrase were more likely to be title pages.</p><p>Another 77 of the remaining 103 topics resulted in "hits" for Run 3, the adjacency search. Numerically, this was the richest set, with 22 new relevant documents found out of 82 possible for those topics. But the 519 non-relevant documents resulted in low overall scores, and a very low exact precision. The low variety in precision scores across all runs are because most topics had very small response sets, due to the specificity of the IRTools query.</p><p>Only 26 topics remained for Run 4, and 21 of these resulted in some documents being found.</p><p>Failure to produce any hits on the other 5 is mostly attributable to parsing issues (i.e., "ecoli" versus "ecoli", and the infamous "u.s." versus "us" versus "u.s"). The bottom line here is that a fall through approach seems reasonable: start with more specific topics, and then try less specific queries before giving up. Adjusting the adjacency search to a smaller window, or requiring term ordering as in the topic, could help.</p><p>For comparison, runs of all 150 topics were made with each of Run 1 through Run 4. Results for Run 1, of course, matched those for the fall through method. For Runs 2, 3, and 4, results dropped off rapidly due to increasing numbers of non-relevant documents being added to the response set. Table <ref type="table" coords="9,187.69,472.43,6.00,13.28" target="#tab_7">7</ref> summarizes these results. We see in Table <ref type="table" coords="9,170.65,640.43,6.00,13.28" target="#tab_7">7</ref> that the high specificity of Run 2, with an exact phrase search, did not fare much worse than in the fall through case, where Run 2 only occurred if Run 1 failed. But for Runs 3 and 4, a disproportionately large number of candidates were submitted for a relatively small number of relevant documents. These boosted the Relevant Retrieved scores, but were not especially successful methods otherwise.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,249.08,413.64,279.42,12.00;6,90.00,427.56,328.42,12.00"><head></head><label></label><figDesc>Figures 1 and 2 illustrate some of the query flexibility and output options provided by IRTools through a Web-based front-end.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,90.00,461.16,213.12,12.00;6,90.48,479.76,431.04,220.32"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Advanced IRTools Query Form</figDesc><graphic coords="6,90.48,479.76,431.04,220.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,90.00,169.08,223.52,12.00;7,90.48,187.68,431.04,452.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Basic IRTools Query with Output</figDesc><graphic coords="7,90.48,187.68,431.04,452.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.00,568.68,442.16,145.92"><head>Table 1 : Term by Document Matrix</head><label>1</label><figDesc></figDesc><table coords="2,90.00,589.08,442.16,125.52"><row><cell></cell><cell>Doc 1</cell><cell>Doc 2</cell><cell>Doc 3</cell><cell>Doc 4</cell><cell>Doc 5</cell></row><row><cell>Term 1</cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>1</cell></row><row><cell>Term 2</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>2</cell></row><row><cell>Term 3</cell><cell>0</cell><cell>3</cell><cell>1</cell><cell>0</cell><cell>2</cell></row><row><cell>Term 4</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>3</cell><cell>0</cell></row><row><cell cols="6">In Table 1, most terms do not occur in most documents, and most documents do not have</cell></row><row><cell cols="6">most terms. This results in many cells with zero entries. Such a sparse matrix may be more</cell></row><row><cell cols="6">efficiently represented as a list of postings in an inverted file, as shown in Table 2.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,93.72,263.29,75.36"><head>Table 2 : Postings in an Inverted Index</head><label>2</label><figDesc></figDesc><table coords="3,90.00,113.88,263.29,55.20"><row><cell>Term 1</cell><cell>Doc 1=2</cell><cell>Doc3=1</cell><cell>Doc 5=1</cell></row><row><cell>Term 2</cell><cell>Doc 2=1</cell><cell>Doc 5=2</cell><cell></cell></row><row><cell>Term 3</cell><cell>Doc 2=3</cell><cell>Doc 5=20</cell><cell></cell></row><row><cell>Term 4</cell><cell>Doc 2=3</cell><cell>Doc 3=1</cell><cell>Doc 5=2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,90.00,101.40,447.65,178.32"><head></head><label></label><figDesc>Table2above), fast search on other qualities are also required, such as on the paragraph, subdocument, and offset location in a document. These goals seemed to fit well with what database management systems are good for, so MySQL was chosen for the TREC 2003 implementation of the inverted index.MySQL, like PostgreSQL, is free and open source, and therefore suitable for use with IRTools. Both have similar capabilities and characteristics, but the availability of a C++ API for MySQL was a deciding factor for its choice. MySQL's MyISAM or INNODB table styles utilize either the Berkeley DB or similar approaches to storage on disk, in B-trees and related file structures. (We note here that IRTools has utilized Berkeley DB tables directly through their C++ API for several years.) Table3shows the table structure for the inverted index. The term and document data remained in Berkeley DB tables managed by IRTools directly, and will not be further elaborated on here.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,90.00,301.56,431.99,46.56"><head>Table 3 : Inverted Index Table Structure in MySQL</head><label>3</label><figDesc></figDesc><table coords="4,90.00,321.96,431.99,26.16"><row><cell>Name</cell><cell>DocID</cell><cell>Offset</cell><cell>TermID</cell><cell cols="3">TagListID WhichPara WeightInSubdoc</cell></row><row><cell>Type</cell><cell>uint</cell><cell>usmall</cell><cell>uint</cell><cell>usmall</cell><cell>utiny</cell><cell>ufloat</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,90.00,73.80,419.22,323.28"><head>Table 4 : Inverted Index Table Creation</head><label>4</label><figDesc></figDesc><table coords="5,90.00,94.20,419.22,261.36"><row><cell>CREATE TABLE `inv0web02` (</cell></row><row><cell>`docid` int(10) unsigned NOT NULL default '0',</cell></row><row><cell>`offset` smallint(5) unsigned NOT NULL default '0',</cell></row><row><cell>`termid` int(10) unsigned NOT NULL default '0',</cell></row><row><cell>`taglistid` smallint(5) unsigned NOT NULL default '0',</cell></row><row><cell>`whichpara` tinyint(3) unsigned NOT NULL default '0',</cell></row><row><cell>`weight_in_subdoc` float unsigned NOT NULL default '0',</cell></row><row><cell>PRIMARY KEY (`docid`,`offset`),</cell></row><row><cell>KEY `termid_index` (`termid`),</cell></row><row><cell>KEY `whichpara_index` (`whichpara`),</cell></row><row><cell>KEY `taglistid_index` (`taglistid`),</cell></row><row><cell>KEY `weight_index` (`weight_in_subdoc`),</cell></row><row><cell>KEY `docid_index` (`docid`),</cell></row><row><cell>KEY `offset_index` (`offset`),</cell></row><row><cell>KEY `termid_docid_whichpara_offset` (`termid`,`docid`,`whichpara`,`offset`),</cell></row><row><cell>KEY `termid_docid_whichpara_offset_weight(</cell></row><row><cell>`termid`,`docid`,`whichpara`,`offset`,`weight_in_subdoc`),</cell></row><row><cell>KEY `termid_docid_taglist_weight` (`termid`,`docid`,`taglistid`,`weight_in_subdoc`),</cell></row><row><cell>KEY `termid_docid_taglistid_offset_weight(</cell></row></table><note coords="5,94.01,357.48,270.95,12.00;5,96.00,371.40,187.76,12.00;5,90.00,385.08,90.53,12.00"><p>`termid`,`docid`,`taglistid`,`offset`,`weight_in_subdoc`), KEY `termid_docid` (`termid`,`docid`) ) TYPE=MyISAM</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,90.00,79.80,448.82,258.48"><head>Table 5 : Web02 Build Statistics</head><label>5</label><figDesc>468 million rows is, indeed, a large database table. At a ratio of 4:1, the size of the database compared to input data is not nearly as favorable as for other IR systems. Furthermore, the random access nature of inserts (combined with numerous indexes) resulted in insertions which were very much disk bound. While indexing, CPU utilization was often below 10%, while awaiting disk I/O. Generally this behavior is consistent with other indexes for IR, and no slower than the Berkeley DB or other B-tree disk methods. The difference was that keeping track of virtually every term occurrence resulted in a far larger database.</figDesc><table coords="6,90.00,100.20,360.90,155.04"><row><cell>System</cell><cell>Dell 4600</cell></row><row><cell></cell><cell>Dual Xeon processor 2.8Ghz</cell></row><row><cell></cell><cell>16GB RAM</cell></row><row><cell></cell><cell>960GB RAID-5 disk</cell></row><row><cell>Processing time</cell><cell>5 days</cell></row><row><cell>MySQL database size (inverted index)</cell><cell>About 80GB</cell></row><row><cell>Number of inverted rows (postings)</cell><cell>About 468,000,000</cell></row><row><cell>Size of other file structures</cell><cell>About 500MB</cell></row><row><cell>Total index size</cell><cell>About 81GB</cell></row><row><cell>We note that</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,90.00,397.32,449.52,303.91"><head>Table 6 : Web02 Named Page Task Results Summary for Fall Through Queries</head><label>6</label><figDesc></figDesc><table coords="8,90.00,416.27,449.52,284.96"><row><cell>Recall</cell><cell>Precision</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Run 1</cell><cell>Run 2</cell><cell>Run 3</cell><cell>Run 4</cell><cell>Combined</cell></row><row><cell></cell><cell></cell><cell cols="4">(If Run 1 fails)(If Run 2 fails)(If Run 3 fails)(Complete set)</cell></row><row><cell>0</cell><cell>0.5392</cell><cell>0.2461</cell><cell>0.1447</cell><cell>0.4048</cell><cell>0.2839</cell></row><row><cell>0.1</cell><cell>0.5392</cell><cell>0.2461</cell><cell>0.1447</cell><cell>0.4048</cell><cell>0.2839</cell></row><row><cell>0.2</cell><cell>0.5392</cell><cell>0.2461</cell><cell>0.1447</cell><cell>0.4048</cell><cell>0.2839</cell></row><row><cell>0.3</cell><cell>0.5392</cell><cell>0.2461</cell><cell>0.1447</cell><cell>0.4048</cell><cell>0.2839</cell></row><row><cell>0.4</cell><cell>0.5392</cell><cell>0.2461</cell><cell>0.1447</cell><cell>0.4048</cell><cell>0.2839</cell></row><row><cell>0.5</cell><cell>0.5392</cell><cell>0.2461</cell><cell>0.1447</cell><cell>0.4048</cell><cell>0.2839</cell></row><row><cell>0.6</cell><cell>0.451</cell><cell>0.2333</cell><cell>0.1447</cell><cell>0.3095</cell><cell>0.2483</cell></row><row><cell>0.7</cell><cell>0.451</cell><cell>0.2333</cell><cell>0.1447</cell><cell>0.3095</cell><cell>0.2483</cell></row><row><cell>0.8</cell><cell>0.451</cell><cell>0.2333</cell><cell>0.1447</cell><cell>0.3095</cell><cell>0.2483</cell></row><row><cell>0.9</cell><cell>0.451</cell><cell>0.2333</cell><cell>0.1447</cell><cell>0.3095</cell><cell>0.2483</cell></row><row><cell>1</cell><cell>0.451</cell><cell>0.2333</cell><cell>0.1447</cell><cell>0.3095</cell><cell>0.2483</cell></row><row><cell># of Queries</cell><cell>34</cell><cell>13</cell><cell>77</cell><cell>21</cell><cell>145</cell></row><row><cell>Retrieved</cell><cell>142</cell><cell>104</cell><cell>541</cell><cell>75</cell><cell>862</cell></row><row><cell>Relevant</cell><cell>39</cell><cell>17</cell><cell>82</cell><cell>27</cell><cell>165</cell></row><row><cell>Relevant retrieved</cell><cell>20</cell><cell>6</cell><cell>22</cell><cell>11</cell><cell>59</cell></row><row><cell>Exact precision</cell><cell>0.49</cell><cell>0.23</cell><cell>0.1</cell><cell>0.33</cell><cell>0.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,90.00,507.48,387.04,118.15"><head>Table 7 : Web02 Named Page Task Results Summary for Independent Runs</head><label>7</label><figDesc></figDesc><table coords="9,90.00,526.43,294.72,99.20"><row><cell></cell><cell>Run 2</cell><cell>Run 3</cell><cell>Run 4</cell></row><row><cell># of Queries</cell><cell>150</cell><cell>150</cell><cell>150</cell></row><row><cell>Queries with results</cell><cell>33</cell><cell>123</cell><cell>145</cell></row><row><cell>Retrieved</cell><cell>403</cell><cell>1548</cell><cell>1593</cell></row><row><cell>Relevant</cell><cell>38</cell><cell>137</cell><cell>165</cell></row><row><cell>Relevant retrieved</cell><cell>17</cell><cell>50</cell><cell>47</cell></row><row><cell>Exact precision</cell><cell>0.21</cell><cell>0.1</cell><cell>0.1</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Future Directions</head><p>IRTools has many facets. It is hoped that other information scientists will consider utilizing parts of it for their own research, perhaps even contributing new components. For the immediate future, the main research topic of interest is how to allocate term weights in subdocuments. Must these be computed after the initial indexing, when term characteristics for the whole collection are known? What about incorporating collection-level statistics such as page rank? What adjustments to traditional tf, idf and pivot scores are needed? From a development perspective, the biggest effort will go to a reference implementation for GridIR. TREC participants are urged to get involved with GridIR. Apart from being of inherent interest to many of us, GridIR is a ripe platform for experimentation on query results merging, information filtering, and different document types. More information, including standards documents, is online at www.gridir.org.</p></div>
			</div>
			<div type="funding">
<div><p>The research described here was partially funded by <rs type="funder">National Science Foundation</rs> grant #<rs type="grantNumber">0352029</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EdREmDz">
					<idno type="grant-number">0352029</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,90.00,290.27,422.14,13.28;10,90.00,303.95,119.71,13.28" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,189.37,290.27,178.30,13.28">The Grid: Computing without bounds</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,384.42,290.27,127.72,13.28;10,90.00,303.95,119.71,13.28">Scientific American April. Online: www.sciam.com</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,90.00,331.55,445.54,13.28;10,90.00,345.47,304.79,13.28;10,90.00,373.07,438.80,13.28;10,90.00,386.75,433.85,13.28;10,90.00,400.67,197.42,13.28" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,453.97,331.55,81.57,13.28;10,90.00,345.47,103.88,13.28;10,210.02,345.47,157.77,13.28;10,403.75,373.07,125.06,13.28;10,90.00,386.75,99.96,13.28">New indices for text: PAT trees and PAT arrays</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><forename type="middle">;</forename><surname>Gamiel</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Sousan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><forename type="middle">;</forename><surname>Newby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nassib</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaston</forename><forename type="middle">H</forename><surname>Gonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ricardo</forename><forename type="middle">;</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Snider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,221.72,386.75,260.87,13.28">Information Retrieval: Data Structures and Algorithms</title>
		<imprint>
			<date type="published" when="1992">2003. 1992</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Upper Saddle River, New Jersey</pubPlace>
		</imprint>
	</monogr>
	<note>Grid information retrieval requirements</note>
</biblStruct>

<biblStruct coords="10,90.00,428.27,402.48,13.28;10,90.00,441.95,429.83,13.28;10,90.00,455.87,289.43,13.28" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,441.08,428.27,51.40,13.28;10,90.00,441.95,366.21,13.28">Wide Area Information Servers: An executive information system for unstructured files</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kahle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tiene</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,470.50,441.95,49.33,13.28;10,90.00,455.87,229.07,13.28">Electronic Networking: Research, Applications and Policy</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="68" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,90.00,484.92,433.14,12.00;10,90.00,498.84,140.40,12.00" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,413.44,484.92,104.60,12.00">Sorting and Searching</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Knuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,203.35,484.92,170.74,12.00">The Art of Computer Programming</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="1998">1998</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,90.00,524.99,446.87,13.28;10,90.00,538.91,388.80,13.28;10,90.00,567.96,442.54,12.00;10,90.00,581.88,313.13,12.00" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,95.47,538.91,183.28,13.28;10,294.04,538.91,184.76,13.28;10,90.00,567.96,122.30,12.00;10,228.89,567.96,196.94,12.00">Online: www.gridir.org/wg_docs.html Newby, Gregory B. 2002</title>
		<author>
			<persName coords=""><forename type="first">Nassib</forename><forename type="middle">;</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><forename type="middle">;</forename><surname>Newby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><forename type="middle">;</forename><surname>Gamiel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><forename type="middle">;</forename><surname>Dovey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeremiah</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,123.35,581.88,117.22,12.00">TREC 2002 Proceedings</title>
		<editor>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Progress in General-Purpose IR Software</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
