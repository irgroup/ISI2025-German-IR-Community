<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.18,83.96,356.88,14.88;1,474.00,80.42,4.08,9.75">THUIR at TREC 2003: Novelty, Robust and Web *</title>
				<funder ref="#_AukPUR7">
					<orgName type="full">Chinese National Key Foundation Research &amp; Development Plan</orgName>
				</funder>
				<funder ref="#_jwzXaqd">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_4wexS69">
					<orgName type="full">Natural Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,173.58,109.87,44.84,9.16"><forename type="first">Min</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.01,109.87,43.12,9.16"><forename type="first">Chuan</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.12,109.87,41.31,9.16"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.41,109.87,33.19,9.16"><forename type="first">Le</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.12,109.87,56.50,9.16"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.18,83.96,356.88,14.88;1,474.00,80.42,4.08,9.75">THUIR at TREC 2003: Novelty, Robust and Web *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CD20E22C902A768B3872625D4358666E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is the second time that Tsinghua University Information Retrieval Group (THUIR) participates in TREC. In this year, we took part in four tracks: novelty, robust, web and HARD, describing in following sections, respectively. A new IR system named TMiner has been built on which all experiments have been performed. In the system, Primary Feature Model (PFM) <ref type="bibr" coords="1,462.72,216.38,8.22,6.12" target="#b0">[1]</ref> has been proposed and combined with BM2500 term weighting <ref type="bibr" coords="1,314.28,231.98,8.16,6.12" target="#b1">[2]</ref> , which led to encouraging results. Word-pair searching has also been performed and improves system precision. Both approaches are described in robust experiments (section 2), and they were also used in web track experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Novelty track</head><p>Our research on this year's novelty track mainly focused on four aspects: (1) unsupervised relevance judgment; (2) efficient sentence redundancy computing; (3) supervised sentence classification; (4) supervised redundancy threshold learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Unsupervised relevance judgment</head><p>The work of finding relevant information is useful for task1 and task3. Since words mismatch problem is dominant in sentence comparison, three kinds of approaches have been carried out in unsupervised relevance judgment to solve the problem as following.</p><p>(1) Query Expansion (QE) using WordNet synonymy and hyponomy, and Dr Lin Dekang's dictionary of term dependency <ref type="bibr" coords="1,210.90,462.38,8.22,6.12">[3]</ref> ;</p><p>(2) QE with query terms' local co-occurrence words in a window of W according to supposed relevant document set (without initial search, named LCE in our previous study <ref type="bibr" coords="1,439.98,493.58,8.22,6.12" target="#b2">[4]</ref> ). In task3, the co-occurrence information was got in given relevant sentences in top five documents;</p><p>(3) Pseudo relevance feedback. After initial retrieval, top M terms in top ranked N 1 sentences and not in last N 2 sentences were added to the query. In task3, the top documents were defined as given relevant sentences.</p><p>Approach (1) and (2) had been already described in our last year's novelty track report <ref type="bibr" coords="1,485.94,571.58,8.16,6.12" target="#b2">[4]</ref> , and were to make further observation in this year's tasks. Therefore we only give some more information about approach (3) as follows.</p><p>Local feedback strategies are based on expanding the query with terms correlated to known query terms. Generally, the expanding n terms are extracted from the top m document (In our novelty track experiments, each sentence is taken as an individual document, m=2) after initial search. The n terms are chosen based on the similarity sim(q, k v ) of them <ref type="bibr" coords="1,300.36,665.18,8.22,6.12" target="#b3">[5]</ref> . The value of sim(q, k v ) is calculated as:</p><p>Where w u,q is indexed query weight. c u,v is calculated as follows in our experiments: ′ are frequencies that term s u and s v occurred within the distance of W words to the observing query term, respectively. In our experiments, the window W is set to 3.</p><formula xml:id="formula_0" coords="1,198.24,683.98,140.31,27.11">∑ ∈ × = ⋅ = Q k v u q u v v u c w k q k q sim , ,<label>) , ( i.</label></formula><p>iii.</p><formula xml:id="formula_1" coords="2,107.22,199.53,114.94,28.33">∑ ∑ ∈ ∈ = ) ( ) ( , )</formula><p>, (</p><formula xml:id="formula_2" coords="2,97.74,199.43,118.53,29.71">1 u i v j s V k s V k j i v u k k r c</formula><p>Where r(k i , k j ) is the distance between terms k i and k j in the same sentence. If k i and k j are in different documents, r(k i , k j ) = .</p><p>There are quite a few terms that occur in a great deal of sentences frequently. They may be in both relevant and irrelevant sentences. We assume that the last k sentences in the initial retrieval are not relevant (k=25 in all experiments), therefore terms in these sentences are useless and should not be expanded.</p><p>Table <ref type="table" coords="2,128.34,335.46,5.25,9.16">1</ref> shows experimental results with above approaches. All QE were performed on short queries. It is shown that all QE approaches improve the system performance. The more terms expanded, the better results were got. Among all QE approaches we observed, local co-occurrence within 10 words' window with Mutual Information weighting performs best, which made 14.5% improvement. And QE with Dr Lin Dekang's proximity and dependency dictionary are also greatly helpful. Unfortunately, our official run THUIRnv0312 used the one with almost the least improvement. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Efficient sentence redundancy computing</head><p>On sentence redundancy elimination, rather than general similarity computing, we used unsymmetrical sentence overlap. That is the same as last year. Our experimental results show it makes trivial improvement comparing to the symmetrical measure of similarity. Besides, the subtopic-based redundancy elimination has been proposed. Generally in a topic, several key-points are concerned, while only one point can be described in each result sentence. Therefore, a natural idea is to divide the topic into subtopics, and then inter-topic documents, inborn, take novel information. Therefore only documents in the same subtopic (cluster) should be used to calculate redundancy. Considering that clusters will help prevent the elimination of inter-cluster documents, if clusters are neatly defined, a better recall will be assured.</p><p>Three subtopic clustering approaches have been proposed: one is topic-oriented, and another two are document-oriented.</p><p>For topic-oriented clustering approach, &lt;title&gt;, &lt;description&gt;, and each sentence in "narrative" were taken as subtopic individually. Documents were clustered to subtopics according to their distance to each subtopic description. (Shown as subtopic I in following)</p><p>For document-oriented clustering, subtopic clusters are built by two ways:</p><p>(1) Clustering with syntax analysis: To "event" type topic, take date (year and month) as the feature; to "opinion" type topic, the opinion holder is taken as the feature. Both features were extracted using rules automatically. (Shown as subtopic II in following)</p><p>(2) Automatic results clustering by sentence vector distance using KNN-like approach. The sentences vectors are extremely sparse so that only a small number of clusters were formed. Therefore, the method hardly improves (though not deteriorating) the results. (Shown as subtopic III in following)</p><p>Table <ref type="table" coords="3,123.62,384.67,5.25,9.16" target="#tab_1">2</ref> shows the effects of different subtopic-based redundancy elimination approaches. All official runs we submitted in task1 were using overlap-based redundancy computing, and the elimination thresholds were all set to 0.55 in task1.</p><p>In task2, mistakes has been made during upload the official runs results because of the coming of submit time deadline. Then all official runs are all wrong in task2, which we can not resume and the THUIRnv0221 and THUIRnv0222 are the same ones. The correct ones we tend to submit are also listed in Table2 (un-official runs). Besides above approaches, redundancy computing based on triple overlap has been proposed and studied. Firstly, extract syntax triples of each relevant sentence. Secondly, only those triples of V or N are kept for further computation. Thirdly, compute overlap of each sentence pair by triples' overlap. At last, give a threshold and eliminate sentences with high overlap score. Following table3 shows the effects of the approach. The approach was used in task4, and the threshold for official runs is learnt by the given five documents. Following Table3 shows the effects of the approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Supervised sentence classification</head><p>In task3, we taken the problem of finding relevant information as finding a suitable binary sentence classification using provided relevant sentences in top five documents. A SVM classifier has been used. Features were extracted according to key words in training sentences (sentences given in first five documents). The basic assumption is that the features of relevant sentences are different from that of irrelevant sentences. In terms of positive examples and negative examples, SVM finds a hyper-plane in the feature space, which is chosen to maximize the margin of the training positive and negative points <ref type="bibr" coords="4,145.50,415.10,8.20,6.12" target="#b4">[6]</ref> . In the given first 5 documents of each topic, relevant sentences are used as positive examples, and the remaining ones are negative examples. Proportion of positive and negative examples has been balanced in our approach by giving a weighting of 150:1. A linear SVM has been trained. We used a SVM package (version 2.4, by Chih-Wei Hsu, etc. <ref type="bibr" coords="4,323.94,461.90,8.22,6.12">[7]</ref> ) to create the classifier.</p><p>It shows that this supervised sentence classification does helpful on finding relevance, which can be seen in the following Table <ref type="table" coords="4,209.30,495.79,3.95,9.16" target="#tab_4">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Supervised redundancy threshold learning</head><p>As we known, redundancy threshold setting is one of the important issues in finding new information. For unsupervised task (task1 and task2), according to the high similarity between documents and topics, a fixed threshold has been set. While For task3 and task4, supervised learning has been performed. We trained the threshold by two ways: one is to tune a fixed threshold to all topics by the given known documents, and another one is to tune a different parameter for each topic. It seems that the elimination threshold trained by top five documents, which was set to fixed 0.8 in task4, works well to the remaining ones.documents. Further analysis and observation need to be done. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5.">Submitted official runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Robust track</head><p>In this year's robust track, our basic idea is: "bad" topics are not topics that only seldom documents can be returned after retrieval, but the ones that return too many irrelevant documents. Therefore the key point of our work is to improve the system precision to these topics, namely, to perform a cagey and strict judgment of relevance.</p><p>We implemented two novel approaches in our TMiner system, namely Primary Feature Model and Word Pair Search, aiming to enhance system performance in terms of precision. They are used in both robust and web tracks.</p><p>Besides, query quality is also an important factor to system performance. We eliminate the negative description of the topic in &lt;narr&gt; field automatically, hence a long query without negative information was generated. Effect of using other fields of topics was also observed, shown in Figure1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Primary Feature Model</head><p>As we known, terms appear in the title, heading or other emphasized fields in the document are more generally important to the reader than the other body text. They represented the notion of the authors on the main content of the document. We take these special fields as Primary Feature Fields (PFF). Terms in the primary feature fields in the entire collection construct a Primary Feature Space (PFS). This space is not of uniform distribution. Therefore, terms with higher density in the space should be more significant as features. Generally, the density of the feature dimension can be represented by the term frequency in the primary feature space:</p><formula xml:id="formula_3" coords="6,264.96,396.88,41.50,23.92">∑ = = N k ik i tf D 1</formula><p>Where tf ik is occurrence frequency of term i in PFF of document k, and N is the total number of documents in the collection.</p><p>Since documents are built by different authors with different backgrounds and writing habits, the description of the field may not be canonical. To reduce the influence of the information leak caused by different author, it's better to limit the same terms from one page contributing to the feature density only once. i.e.</p><formula xml:id="formula_4" coords="6,172.68,525.97,229.06,29.74">   = otherwise k doc of field primary the in occurs i term if tf ik , 0 , 1</formula><p>Therefore the density of the feature dimension is be simplified to:</p><formula xml:id="formula_5" coords="6,257.88,584.18,57.96,23.68">i N k ik i n tf D = = ∑ =1</formula><p>Where n i is the number of documents which contains term i in its primary feature space in the collection. Then the term weight in the primary feature space can be represented by:</p><formula xml:id="formula_6" coords="6,255.06,651.31,62.74,11.82">) 1 log( ) 2 ( + = n w</formula><p>Where tf i and n i are simplified as tf and n respectively. By doing so, in a documents collection, the weight of a term in the query is composed of the weights in PFS and in body text. Therefore the new similarity scoring function can be presented as:</p><formula xml:id="formula_7" coords="6,166.44,729.13,216.78,26.30">) )( ( ) 1 ( ) 1 ( ] ) 1 ( [ 3 3 1 ) 2 ( ) 1 ( qtf k tf K qtf k tf k w w Q T PF BT + + + + - + ∑ ∈ λ λ</formula><p>where ) 1 ( BT w is the Robertson/Sparck Jones weight for a term according to body text, ) 2 ( PF w is the weight in terms of primary feature field, λ is the impact factor of the body text. When λ =1, the scoring function is same as traditional Robertson/Sparck Jones probabilistic model.</p><p>In this year's robust task, the &lt;headline&gt; of the documents were used as Primary Feature Field.</p><p>The effects are shown in Table <ref type="table" coords="7,220.66,151.03,5.25,9.16" target="#tab_7">5</ref> (λ=0.1). Trivial improvement is got on the performance of worst topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Word Pair Search</head><p>The basic idea of word pair is that if adjacent words in the query are also adjacent in the document, then the document would be more likely to be relevant. In our word pair implementation, word pairs in a query are treated as additional terms for the query; and DF, TF information are calculated and added to the original query term weights by a weighted summation.  </p><formula xml:id="formula_8" coords="7,165.00,289.57,254.36,56.03">) ( ) ( ) 1 ( ) 1 ( ) 1 ( 2 3 3 1 ) 1 (<label>2</label></formula><formula xml:id="formula_9" coords="7,90.06,289.57,363.58,54.41">N W qtf k tf K qtf k tf k W W df df N W where W qtf k tf K qtf k tf k W W λ</formula><p>Note: a weight λ is multiplied to the word pair part of the total weights to constrain the impact of the word pair weight on the final document results.</p><p>DF of word pair (e.g. word pair AB) can be estimated in different ways: a.</p><p>DF is specified by a constant the user provides. This estimation method is called wp 1 in our experiments. b.</p><p>DF of AB can be estimated with the number of documents that contain both the two terms: A and B. We call it wp 2 method. c.</p><p>DF of AB can be the exact document frequency of the pair AB. The wp 3 . Effects of Word Pair Search are shown in Table <ref type="table" coords="7,299.01,480.67,3.95,9.16">6</ref>. It is encouraging that although Word Pair Search makes much improvement in terms of average system performance, but it enhances the average performances of "bad" topics obviously. (In the table 6, λ of title and description query were set to 0.2 and 0.3 respectively). 1: long query retrieval, using BM2500+PFS weighting 2: long query without negative information, using BM2500+PFS weighting 3: long query baseline retrieval 4: combine short query retrieval and retrieval on description field 5: retrieval on description field with Word Pair Search and BM2500 + PFS weighting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Web track</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Introduction</head><p>In this year's TREC Web Track research, we participated in both Known-Item Search and Topic Distillation Tasks.</p><p>In Topic Distillation task, only entry pages of key sites should be returned as results. Therefore, two kinds of approaches have been studied: "Top-to-Bottom" retrieval, and "Bottom-to-Top" one. The key point in both approaches is: how to give a clear and precise definition of entry pages and use it to get an entry page list. According to our definition, we developed an entry page locating algorithm concerning the following characteristics of pages: URL information, document length, in-site out-link rate and in-link number. With the algorithm, four entry page lists have been built according to different threshold (strict or relaxed metric) and number of entry pages returned from one site.</p><p>On term weighting, a Primary Feature Space (PFS) model has been proposed. In PFS model, as has been described in section 2, a DF-related weighting is performed on words in Primary Feature Field (PFF), which makes improvement compared with traditional IDF-related weighting. In-link anchor text, title and keywords of in-site-out-link pages, and bold text are proved to be good PFF in our experiments.</p><p>Besides, searching with word pair has been added to scoring, which improves the accuracy of result ranking, as has been described in section 2.</p><p>A novel site uniting method is also proposed to confirm that any key resource we found is not part of a larger site also principally devoted to the topic.</p><p>In Page Finding task, other than in-link anchor text used in TD task, the out-link anchor text are used to decide the webpage candidate set. Then rank the candidates according to the term weighting on full text and return top results. It shows that the out-link anchor text is much more effective than the full text of the page. And it is different to the general idea that the out-link anchor text describes the page the link point to more than the page itself.</p><p>Abbreviations were extracted from the corpus automatically, and were expanded in topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Definition and locating algorithm of entry pages</head><p>In this year's topic distillation task, we are concentrating solely on websites (represented by their entry pages) as key resources. Before retrieval, it is necessary for us to find out what an entry page is and how to find it. In our dictionary, an entry page is the main entry point of a web site and a bridge between pages inside and outside the web site; it should have the following characteristics:</p><p>(a) An entry page can connect (directly or indirectly) to all pages in the web site it belongs to. (b) When pages outside the web site want to visit pages inside the site, they mainly visit the entry page at first. According to the definition, we may see that entry pages should have some special features in their URLs, link structures, etc. In our research, we divide entry pages into two types: topic-related and non-topic-related. For topic-related entry pages, their URLs always contain one or more query words. For example, "www.drugabuse.gov/DrugPages/Marijuana.html" is an entry page of its sub-site for the topic "Where can I locate information on the pros and cons of legalizing marijuana". For non-topic-related entry pages, they always have the following features:</p><p>(1) url: root, subroot, named as "index.htm" etc, or named as the topic words of the sub-site;</p><p>(2) length: an entry page is usually not too long;</p><p>(3) in-site-out-link: an entry page should have enough in-site-out-link; (4) in-link: an entry page should have enough in-link (especially links from pages in different site/server).</p><p>In this way, about 15% pages have been selected to form the key entry pages collection, which cover about 68% useful key resources for 50 testing queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Topic distillation with entry page lists</head><p>With the entry page locating algorithm, four entry page lists have been built according to different threshold (strict or relaxed metric) and number of entry pages returned from one site. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>List</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Top-down topic distillation</head><p>In the top-down algorithm, we restrict our data set on selected entry pages. With an ideal entry page locating algorithm, entry page retrieval is obviously a clever choice for topic distillation task, because it discard pages that are not possibly key resources. But in practical world, any locating algorithm brings in noises and may discard some entry pages which will perhaps be key site representatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Bottom-up topic distillation</head><p>In the bottom-up algorithm, we try to locate key sites instead of key pages. Entry page of one site is returned as result. We first retrieve on full text, and then use the following algorithm to re-rank the results:  <ref type="figure" coords="10,284.53,244.27,3.95,9.16" target="#fig_4">2</ref>, both bottom-up and top-down perform much better than full-text retrieval. It shows the entry page locating algorithm is conceive and reliable. And the top-down method is perhaps more useful for this kind of topic distillation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Using document structures</head><p>The effect of using HTML document structure is studied in our experiments. It is found that in-link anchor information is useful for known-item search. We also tested several new parts of HTML document in topic distillation experiments. They are: in-site out-link anchors, in-site out-link page titles and in-site out-link page keywords.</p><p>For a certain page A, in-site out-link anchors are anchors describing links from A to other pages in the site where A is. So the anchors are located on A; that is quite different from frequently-used in-link anchors which are on pages linking to A. However, in-site out-link title / keyword are on pages A points to, although in the entry page finding process, we can consider them as descriptions of A.</p><p>Using of in-site out-link is particularly useful for topic distillation task, shown in Figure <ref type="figure" coords="10,491.34,459.07,3.94,9.16">3</ref>, the experiment is on the entry page data set. Full text retrieval experiment is shown in Figure <ref type="figure" coords="10,458.33,474.67,3.95,9.16">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Then we can conclude that:</head><p>To the whole collection, in-link anchor performs better. To the entry pages text set: 1) in-link anchor no longer works; 2) full text is reliable; 3) in-site out-link anchor leads to astonishing results; 4) in-site title / keywords may be too short to improve retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Topic distillation with different weighting schemes</head><p>We experimented with the following weighting schemes in the topic distillation task: Primary feature space model and BM2500 model. In the chart below, category axis represents the rate BM2500/PFS. It shows that with a broad parameter scale, we get improvement using PFS weighting scheme combined with BM2500 weighting. We compared the two weighting schemes in the following charts. The first experiment is performed on full text data set; while the second is on the entry page set. It shows that PFS method only performs poor, but it can stably improve performance if we combines it with the BM2500 weighting scheme. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,122.82,66.33,12.82,22.03;2,126.60,86.07,5.00,8.59;2,158.28,69.60,6.58,14.69;2,110.52,69.60,6.58,14.69;2,136.14,91.59,1.38,4.34;2,124.74,91.59,1.38,4.34;2,175.92,83.13,2.21,4.34;2,146.28,83.13,2.49,4.34;2,131.40,88.52,5.07,6.12;2,119.94,88.52,3.51,6.12;2,182.52,80.06,1.95,6.12;2,173.16,80.06,2.73,6.12;2,153.30,80.06,1.95,6.12;2,143.58,80.06,2.73,6.12;2,103.20,80.06,3.12,6.12;2,97.26,80.06,3.51,6.12;2,168.78,73.79,3.34,10.46;2,139.26,73.79,3.34,10.46;2,91.86,73.79,5.33,10.46;2,179.28,80.05,1.76,6.12;2,150.06,80.05,1.76,6.12;2,101.34,80.05,1.76,6.12;2,188.22,74.76,2.63,9.16;2,79.38,108.36,25.65,9.16;2,123.30,113.66,1.95,6.12;2,113.28,113.66,5.31,7.42;2,109.14,107.39,3.34,10.46;2,119.94,113.66,1.76,6.12;2,128.04,108.36,15.22,9.16;2,166.26,113.66,1.95,6.12;2,156.96,113.66,4.91,7.42;2,152.64,107.39,3.34,10.46;2,163.02,113.66,1.76,6.12;2,170.58,108.36,338.81,9.91;2,79.38,125.94,8.50,9.16;2,126.48,117.51,12.82,22.03;2,130.26,137.25,5.00,8.59;2,179.82,120.06,2.96,14.69;2,162.72,120.78,6.58,14.69;2,149.52,120.06,2.96,14.69;2,113.82,120.78,6.58,14.69;2,139.74,142.77,1.38,4.34;2,128.46,142.77,1.38,4.34;2,180.72,134.31,2.21,4.34;2,150.36,134.31,2.49,4.34;2,135.00,139.69,5.07,6.12;2,123.66,139.69,3.51,6.12;2,187.32,131.24,1.95,6.12;2,178.02,131.24,2.73,6.12;2,157.32,131.24,1.95,6.12;2,147.72,131.24,2.73,6.12;2,106.08,131.24,3.12,6.12;2,100.14,131.24,3.51,6.12;2,173.70,124.97,3.34,10.46;2,143.40,124.97,3.34,10.46;2,94.80,124.97,5.33,10.46;2,184.08,131.24,1.76,6.12;2,154.08,131.24,1.76,6.12;2,104.22,131.24,1.76,6.12;2,79.38,159.54,25.65,9.16;2,123.00,164.84,1.95,6.12;2,113.40,164.84,5.13,7.42;2,109.08,158.57,3.34,10.46;2,119.82,164.84,1.76,6.12;2,115.20,153.66,2.96,14.69;2,127.02,159.54,15.22,9.16;2,165.18,164.84,1.95,6.12;2,155.88,164.84,4.91,7.42;2,151.56,158.57,3.34,10.46;2,161.94,164.84,1.76,6.12"><head></head><label></label><figDesc>frequencies that term s u and s v occurred in the whole document, respectively.ii.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,172.50,228.67,271.23,9.16"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Effects of using different topic field to generate queries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,145.07,418.15,24.96,9.16;9,203.18,418.15,49.12,9.16;9,126.06,434.53,36.00,9.16;9,203.18,434.53,64.70,9.16;9,126.06,450.85,38.91,9.16;9,203.15,450.85,208.00,9.16;9,126.06,467.23,38.34,9.16;9,203.24,467.23,206.82,9.16;9,126.06,483.55,36.02,9.16;9,203.14,483.55,203.81,9.16"><head></head><label></label><figDesc>threshold, but only one Entry Page per site Parse list Strict threshold, and only one Entry Page per site Root list Non-file pages only, and one Entry Page per site</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="10,200.40,228.67,194.44,9.16;10,100.38,244.27,415.70,9.16;10,79.38,259.87,436.66,9.16;10,79.38,275.47,311.87,9.16"><head>ForFigure 2</head><label>2</label><figDesc>Figure 2 bottom-up and top-down comparisonAccording to experiment results in Figure2, both bottom-up and top-down perform much better than full-text retrieval. It shows the entry page locating algorithm is conceive and reliable. And the top-down method is perhaps more useful for this kind of topic distillation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,174.00,606.96,181.42,8.53"><head>Figure 3 Figure 4</head><label>34</label><figDesc>Figure 3 Fields retrieval on entry page text set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="11,226.62,365.47,141.97,9.16"><head>Figure 5</head><label>5</label><figDesc>Figure 5 PFS + BM2500 retrieval</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,89.52,501.67,410.65,41.62"><head>Table 2 Results of subtopic-based redundancy elimination (task2)</head><label>2</label><figDesc></figDesc><table coords="3,89.52,517.75,20.41,9.16"><row><cell>Task</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,97.08,550.63,408.44,139.84"><head>Subtopic I, threshold = 0.55 0.46 0.74 0.505 THUIRnv0315</head><label></label><figDesc></figDesc><table coords="3,97.08,566.83,408.44,123.64"><row><cell></cell><cell>Short query, Subtopic II, threshold = 0.8</cell><cell>0.47</cell><cell>0.62 0.457</cell><cell>un-official run</cell></row><row><cell></cell><cell>Short query, Subtopic III, threshold = 0.8</cell><cell>0.48</cell><cell>0.62 0.458</cell><cell>un-official run</cell></row><row><cell>2</cell><cell>Subtopic II, threshold = 0.8</cell><cell cols="2">0.708 0.983 0.812</cell><cell>un-official run</cell></row><row><cell></cell><cell>Subtopic III, 4 clusters, threshold = 0.8</cell><cell cols="3">0.713 0.982 0.815 un-official run</cell></row><row><cell></cell><cell>Baseline, tuned threshold = 0.8</cell><cell cols="3">0.714 0.980 0.815 un-official run</cell></row><row><cell></cell><cell>Unknown wrong submission</cell><cell>0.68</cell><cell>0.72 0.687</cell><cell>THUIRnv0323</cell></row><row><cell></cell><cell>Unknown wrong submission</cell><cell>0.69</cell><cell>0.69 0.679</cell><cell>THUIRnv0321 &amp; THUIRnv0322</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,97.08,119.47,400.41,139.00"><head>Table 3</head><label>3</label><figDesc>Results of triple-overlap-based elimination</figDesc><table coords="4,97.08,135.55,400.41,122.92"><row><cell>Elimination threshold</cell><cell>P</cell><cell>R</cell><cell>P*R</cell><cell>F</cell><cell></cell></row><row><cell>0.8</cell><cell>0.716</cell><cell>0.789</cell><cell>0.563</cell><cell>0.734</cell><cell>un-official run</cell></row><row><cell>0.85</cell><cell>0.70</cell><cell>0.88</cell><cell>0.614</cell><cell>0.765</cell><cell>THUIRnv0342</cell></row><row><cell>0.9</cell><cell cols="2">0.684 0.939</cell><cell>0.641</cell><cell>0.777</cell><cell>un-official run</cell></row><row><cell>0.95</cell><cell cols="2">0.652 0.982</cell><cell>0.641</cell><cell>0.771</cell><cell>un-official run</cell></row><row><cell>Different threshold for Each topic</cell><cell cols="2">0.720 0.780</cell><cell>-</cell><cell>0.728</cell><cell>THUIRnv0341</cell></row><row><cell>Different threshold for Each topic (tuned parameters)</cell><cell>0.728</cell><cell>0.954</cell><cell>0.697</cell><cell>0.819</cell><cell>un-official run</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,131.28,519.19,331.41,57.52"><head>Table 4</head><label>4</label><figDesc>Effects of supervised sentence classification using SVM</figDesc><table coords="4,131.28,535.27,331.41,41.44"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell></cell></row><row><cell>Baseline (using long query)</cell><cell>0.43</cell><cell>0.73</cell><cell>0.479</cell><cell>THUIRnv0334</cell></row><row><cell>Linear SVM</cell><cell>0.42</cell><cell>0.82</cell><cell>0.493</cell><cell>THUIRnv0331</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,79.38,558.67,420.72,177.49"><head>Table 5</head><label>5</label><figDesc></figDesc><table coords="7,79.38,558.67,420.72,177.49"><row><cell cols="4">Effects on using Primary Feature Model</cell><cell cols="4">Table 6 Effects of Word Pair Search</cell></row><row><cell></cell><cell>MAP</cell><cell>p(10)</cell><cell>worst 25 topics</cell><cell></cell><cell>MAP</cell><cell>p(10)</cell><cell>worst 25 topics</cell></row><row><cell>long</cell><cell cols="2">0.2571 0.444</cell><cell>0.0282</cell><cell>Title</cell><cell>0.199</cell><cell>0.351</cell><cell>0.0142</cell></row><row><cell>long.pfs</cell><cell cols="2">0.2597 0.446</cell><cell>0.0289</cell><cell>Title.wp 3</cell><cell>0.205</cell><cell>0.356</cell><cell>0.0153</cell></row><row><cell>long.non-neg</cell><cell cols="2">0.2667 0.452</cell><cell>0.0235</cell><cell></cell><cell cols="2">+3.1% +1.4%</cell><cell>+7.8%</cell></row><row><cell cols="3">long.no-neg.pfs 0.2676 0.453</cell><cell>0.0252</cell><cell>Desc</cell><cell>0.231</cell><cell>0.392</cell><cell>0.0114</cell></row><row><cell>description</cell><cell cols="2">0.2307 0.392</cell><cell>0.0114</cell><cell>Desc.wp 3</cell><cell>0.240</cell><cell>0.406</cell><cell>0.0132</cell></row><row><cell>description.pfs</cell><cell cols="2">0.2339 0.394</cell><cell>0.0118</cell><cell></cell><cell cols="3">+3.8% +3.6% +15.8%</cell></row><row><cell cols="3">2.3. Submitted Official Runs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="11,79.38,459.84,421.95,304.24"><head>Runs submitted and Evaluation Results Topic distillation runs description:</head><label></label><figDesc></figDesc><table coords="11,79.38,459.84,421.95,304.24"><row><cell>THUIRtd0304</cell><cell></cell><cell>Root list</cell><cell>PFS only</cell><cell cols="3">Entry Page in-site out-link anchor</cell><cell>0.0692</cell></row><row><cell>THUIRtd0305</cell><cell></cell><cell>Full text</cell><cell>BM2500+ PFS</cell><cell>Full text all fields</cell><cell></cell><cell>0.1262</cell></row><row><cell>Unofficial run1</cell><cell></cell><cell>Base list</cell><cell>BM2500 only</cell><cell cols="2">Entry page all fields</cell><cell>0.1293</cell></row><row><cell>Unofficial run2</cell><cell></cell><cell>Base list</cell><cell>BM2500+ PFS</cell><cell cols="3">Entry Page in-site out-link anchor</cell><cell>0.1629</cell></row><row><cell cols="4">Known item search runs description and results:</cell><cell></cell><cell></cell></row><row><cell>Runs</cell><cell></cell><cell>Description</cell><cell></cell><cell></cell><cell></cell><cell>MRR</cell></row><row><cell cols="6">THUIRpf0301 Full text retrieval +NPrank+ THUIRtd0305 (BM2500)</cell><cell>0.561</cell></row><row><cell cols="5">THUIRpf0302 Full Text retrieval + THUIRtd0305 (BM2500)</cell><cell></cell><cell>0.45</cell></row><row><cell cols="4">THUIRpf0303 THUIRpf0304 + NPrank</cell><cell></cell><cell></cell><cell>0.496</cell></row><row><cell cols="5">THUIRpf0304 Retrieve on anchor text, using abbr., BM2500</cell><cell></cell><cell>0.463</cell></row><row><cell cols="5">THUIRpf0305 Retrieve on anchor text, not using abbr., BM2500</cell><cell></cell><cell>0.466</cell></row><row><cell>0.088</cell><cell></cell><cell></cell><cell></cell><cell>0.17</cell><cell></cell></row><row><cell>0.084 0.086</cell><cell cols="2">R-Precision</cell><cell></cell><cell>0.15 0.16</cell><cell>R-Precision</cell></row><row><cell>0.082</cell><cell></cell><cell></cell><cell></cell><cell>0.13 0.14</cell><cell></cell></row><row><cell>0.08</cell><cell></cell><cell></cell><cell></cell><cell>0.12</cell><cell></cell></row><row><cell>0.078</cell><cell></cell><cell></cell><cell></cell><cell>0.11</cell><cell></cell></row><row><cell>0.076</cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell><cell></cell></row><row><cell cols="2">BM2500</cell><cell>PFS only</cell><cell>BM2500 +</cell><cell>BM2500</cell><cell>PFS only</cell><cell>BM2500 +</cell></row><row><cell>only</cell><cell></cell><cell></cell><cell>PFS best</cell><cell>only</cell><cell></cell><cell>PFS best</cell></row><row><cell cols="4">Figure 6 weight schmes on full text set</cell><cell cols="3">Figure 7 weight schmes on entry page set</cell></row><row><cell>3.6. Runs</cell><cell></cell><cell>Data Set</cell><cell>Weighting</cell><cell>Field Selection</cell><cell></cell><cell>R-pre</cell></row><row><cell>THUIRtd0301</cell><cell></cell><cell cols="2">Parse list BM2500 only</cell><cell>Full text bold</cell><cell></cell><cell>0.1036</cell></row><row><cell>THUIRtd0302</cell><cell></cell><cell cols="2">Unite list BM2500 only</cell><cell>Full text bold</cell><cell></cell><cell>0.0994</cell></row><row><cell>THUIRtd0303</cell><cell></cell><cell>Base list</cell><cell>PFS only</cell><cell cols="3">Entry Page in-site out-link title / keyword</cell><cell>0.0786</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* Supported by the <rs type="funder">Chinese National Key Foundation Research &amp; Development Plan</rs> (Grant <rs type="grantNumber">G1998030509</rs>), <rs type="funder">Natural Science Foundation</rs> No.<rs type="grantNumber">60223004</rs>, and National 863 High Technology Project No. <rs type="grantNumber">2001AA114082</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AukPUR7">
					<idno type="grant-number">G1998030509</idno>
				</org>
				<org type="funding" xml:id="_4wexS69">
					<idno type="grant-number">60223004</idno>
				</org>
				<org type="funding" xml:id="_jwzXaqd">
					<idno type="grant-number">2001AA114082</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,95.27,335.47,420.61,9.16;12,79.38,351.07,428.55,9.16" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruihua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
		<title level="m" coord="12,293.54,335.47,222.34,9.16;12,79.38,351.07,237.51,9.16">DF or IDF? On the Use of HTML Primary Feature Fields for Web IR, the 12th World Wide Web conference</title>
		<imprint>
			<date type="published" when="2003-05">2003. May, Hungarian, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,94.31,366.67,313.15,9.16" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="12,234.97,366.67,114.64,9.16">Okapi/Keenbow at TREC-8</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<idno>TREC-8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,95.10,397.87,420.83,9.16;12,97.32,413.47,237.35,9.16" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,171.13,397.87,344.80,9.16;12,97.32,413.47,165.07,9.16">Expansion-Based Technologies in Finding Relevant and New Information: THU TREC2002 Novelty Track Experiments</title>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<idno>TREC-2002</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,94.34,429.07,424.70,9.16;12,97.32,444.67,61.54,9.16" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,212.41,429.07,183.79,9.16">Local feedback in full-text retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Attar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Fraenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,403.45,429.07,80.55,9.16">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="397" to="417" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,96.32,460.27,419.66,9.16;12,97.32,475.87,82.01,9.16" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,174.08,460.27,219.42,9.16">Trends and controversies: Support vector machine</title>
		<author>
			<persName coords=""><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,403.01,460.27,108.27,9.16">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
