<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,126.24,83.77,359.50,21.60;1,159.36,111.37,293.30,21.60">A Language Modeling Approach to Passage Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,157.44,141.88,54.00,10.80"><forename type="first">Dell</forename><surname>Zhang</surname></persName>
							<email>dell.z@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<address>
									<postCode>S15-05-24</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">National University</orgName>
								<address>
									<postCode>117543</postCode>
									<country>Singapore Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Singapore-MIT Alliance</orgName>
								<address>
									<addrLine>4 Engineering Drive</addrLine>
									<postCode>E4-04-10</postCode>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<address>
									<postCode>S15-05-24</postCode>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="institution">National University</orgName>
								<address>
									<postCode>117543</postCode>
									<country>Singapore Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Singapore-MIT Alliance</orgName>
								<address>
									<addrLine>4 Engineering Drive</addrLine>
									<postCode>E4-04-10</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,386.16,141.88,64.37,10.80"><forename type="first">Wee</forename><forename type="middle">Sun</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<address>
									<postCode>S15-05-24</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">National University</orgName>
								<address>
									<postCode>117543</postCode>
									<country>Singapore Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Singapore-MIT Alliance</orgName>
								<address>
									<addrLine>4 Engineering Drive</addrLine>
									<postCode>E4-04-10</postCode>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<address>
									<postCode>S15-05-24</postCode>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="institution">National University</orgName>
								<address>
									<postCode>117543</postCode>
									<country>Singapore Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Singapore-MIT Alliance</orgName>
								<address>
									<addrLine>4 Engineering Drive</addrLine>
									<postCode>E4-04-10</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Science Drive</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<postCode>117576</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Science Drive</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<address>
									<postCode>117576</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,126.24,83.77,359.50,21.60;1,159.36,111.37,293.30,21.60">A Language Modeling Approach to Passage Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">33D4C84C98A26E003655AD0434E885B2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports our efforts on developing a language modeling approach to passage question answering. In particular, we address the following two problems: (i) generalized language modeling for question classification; (ii) constrained language modeling for passage retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Text Retrieval Conference (TREC) has a Question Answering (QA) track to support large-scale evaluation for open-domain QA systems <ref type="bibr" coords="1,255.36,367.60,7.48,9.07" target="#b0">[1]</ref><ref type="bibr" coords="1,262.84,367.60,3.74,9.07" target="#b1">[2]</ref><ref type="bibr" coords="1,262.84,367.60,3.74,9.07" target="#b2">[3]</ref><ref type="bibr" coords="1,266.58,367.60,7.48,9.07" target="#b3">[4]</ref>. The TREC2003 QA track consists of two separate tasks, the main task and the passage task. We only participated in the passage task.</p><p>The passage task of a QA system is to find a small chunk of text that contains the exact-phrase answer of a given question from a large document collection. Lin et al. <ref type="bibr" coords="1,329.75,408.16,11.52,9.07" target="#b4">[5]</ref> have showed that users prefer passages over exact-phrase answers in a real-world setting because paragraph-sized chunks provide context. Furthermore, exact-phrase answers are too short to make good training data for future research, making passages a better resource.</p><p>This paper reports our efforts on developing a language modeling approach to passage question answering. In particular, we address the following two problems: (i) generalized language modeling for question classification; (ii) constrained language modeling for passage retrieval.</p><p>The rest of this paper is organized as follows. In §2, we give a brief review of the language modeling technique. In §3, we describe the architecture of our TREC2003 QA system. In §4, we describe the question classification module. In §5, we describe the passage retrieval module. In §6, we present the evaluation results. In §7, we make concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Language Modeling</head><p>The language modeling technique is originally motivated by speech recognition, and it has become widely used in many other application areas such as document classification and information retrieval. This section gives a brief review of the language modeling technique. Please be referred to <ref type="bibr" coords="1,423.13,595.35,10.92,9.07" target="#b5">[6,</ref><ref type="bibr" coords="1,438.00,595.35,8.40,9.07" target="#b6">7]</ref> for more detailed explanation.</p><p>The goal of language modeling, in general, is to build a language model L M that captures the statistical regularities of natural language L . Given a word string 1 2 ... l S w w w</p><formula xml:id="formula_0" coords="1,91.92,637.18,428.16,28.97">= , L M attempts to predict Pr[ | ] L S M Pr [ ] L S =</formula><p>, the occurring probability of S in L .</p><p>The most common language model is the n-gram model. Despite of its simplicity, the n-gram model works quite well in practice. Applying the chain rule of probability, we get</p><formula xml:id="formula_1" coords="2,127.92,74.85,192.60,25.57">Pr [ ] L S 1 2 Pr [ ... ] L l w w w = 1 1 1 Pr [ | ... ] l L i i i w w w - = = ∏ .</formula><p>The n-gram model approximates this probability by assuming that the occurrence of i w only depends on its preceding 1 nwords, i.e., <ref type="bibr" coords="2,164.88,137.01,2.89,5.21" target="#b0">1</ref> 1</p><p>Pr [ | ... ]</p><formula xml:id="formula_2" coords="2,136.32,128.14,154.68,14.53">L i i w w w - 1 1 Pr [ | ... ] L i i n i w w w -+ - = .</formula><p>A straightforward way to estimate λ ≤ ≤ is a weighting parameter. More powerful smoothing methods include additive smoothing (e.g. Laplace smoothing), Jelinek-Mercer smoothing, Katz smoothing, Witten-Bell smoothing, Kneser-Ney smoothing, and so on <ref type="bibr" coords="2,178.32,308.80,10.53,9.07" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Overview</head><p>The architecture of our TREC2003 QA system is shown in Figure <ref type="figure" coords="2,370.80,345.99,3.66,9.07" target="#fig_0">1</ref>. It consists of two major modules: question classification and passage retrieval. The question classification module identifies each question's preferred answer type using question-class language models, which are learned from thousands of labeled training examples. The language modeling based classification algorithm has many advantages over the popular Naive Bayes algorithm. To tackle the scarcity of training data, we build question-topic language models on generalized question structures but not specific word sequences. The generalized question structures are derived from the original questions through various lexical, syntactic and semantic generalization rules.</p><p>The passage retrieval module identifies each question's expected answer context using question-topic language models, which are learned from Web search results. Given a question, we first get a set of relevant passages from the local document collection. Then we search the Web, build a question-topic language model and augment it with a set of probabilistic constraints. Next we rank the retrieved passages using the question-topic language model. Finally, we return the highest ranked passage whose score is above a threshold as the answer. The language modeling based retrieval algorithm implicitly has the power of massive query expansion, which is helpful to overcome the lexical chasm between questions and answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Question Classification</head><p>The task of question classification could be automatically accomplished using machine learning methods <ref type="bibr" coords="3,90.00,134.32,7.92,9.07" target="#b8">[9]</ref><ref type="bibr" coords="3,97.92,134.32,3.96,9.07" target="#b9">[10]</ref><ref type="bibr" coords="3,101.88,134.32,11.88,9.07" target="#b10">[11]</ref>. Here we attempt to apply language modeling to question classification. Given a question 1 2 ... k Q q q q = , it is natural to assign it to the question class which has highest posterior probability, i.e., * arg max Pr</p><formula xml:id="formula_3" coords="3,127.44,176.14,101.16,14.35">[ | ] C C C Q = .</formula><p>The posterior probability Pr[ | ] C Q can be computed via Bayes's rule:</p><formula xml:id="formula_4" coords="3,127.92,210.21,189.72,23.40">Pr[ | ] C Q Pr[ | ]Pr[ ] Pr[ ] Q C C Q = Pr[ | ]Pr[ ] Q C C ∝ .</formula><p>The prior probability </p><formula xml:id="formula_5" coords="3,136.08,265.42,197.28,14.35">[ | ] Q C Pr[ | ] C Q M = Pr [ ] C Q = 1 2 Pr [ ... ]</formula><p>C k q q q = . In our QA system, smoothed bigram models (see §2) are used to implement question-class language models.</p><p>The language modeling based classification (LMC) algorithm is very similar to the popular Naïve Bayes (NB) algorithm <ref type="bibr" coords="3,155.28,323.20,15.26,9.07" target="#b11">[12]</ref>. In fact, the LMC algorithm is a straightforward generalization of the NB algorithm: a uniram classifier with Laplace smoothing corresponds exactly to the traditional NB classifier. However, the LMC algorithm possesses many advantages over the NB algorithm, including modeling longer context with larger n and applying superior smoothing techniques in the presence of sparse data <ref type="bibr" coords="3,427.22,357.99,15.26,9.07" target="#b12">[13]</ref>.</p><p>Note that the power of language modeling is often hurt by the scarcity of training data. Applying language modeling to question classification is no exception. To overcome this obstacle, we build question-topic language models on generalized question structures but not specific word sequences. For instance, a question in the form "When was sb. born?" always asks for a date no matter who "sb." is, so if we have a DATE-class language model that can accurately predict the probability of the generalized question structure "When was &lt;PERSON&gt; born?", we are able to ensure correct classification of the question "When was Albert Einstein born?" even though "Albert Einstein" has never occurred in the training data.</p><p>The generalized question structures are derived from the original questions through various generalization rules, which may include: • lexical generalization, e.g., replacing every acronym with &lt;ACRONYM&gt;, replacing every number with &lt;NUMBER&gt;; • syntactical generalization, e.g., replacing every quoted-string with &lt;QUOTED&gt;, replacing every clause with &lt;CLAUSE&gt;; • semantic generalization, e.g., replacing every string that is a named entity (like organization) with a tag representing its type (like &lt;ORGANIZATION&gt;), replacing every word that belongs to a specific semantic category (like animal) with a tag representing its hypernym (like &lt;ANIMAL&gt;). The named entity recognizer is modified from a component of GATE <ref type="bibr" coords="3,376.81,580.00,16.56,9.07" target="#b13">[14]</ref> (available at http://gate.ac.uk/), and the semantic categories are defined taking advantage of WordNet (available at http://www.cogsci.princeton.edu/~wn/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Passage Retrieval</head><p>Recently the language modeling technique has been introduced to information retrieval area and shown considerable success in many applications <ref type="bibr" coords="3,262.07,651.76,12.19,9.07" target="#b14">[15]</ref><ref type="bibr" coords="3,274.26,651.76,4.06,9.07" target="#b15">[16]</ref><ref type="bibr" coords="3,274.26,651.76,4.06,9.07" target="#b16">[17]</ref><ref type="bibr" coords="3,274.26,651.76,4.06,9.07" target="#b17">[18]</ref><ref type="bibr" coords="3,278.33,651.76,12.19,9.07" target="#b18">[19]</ref>. Here we attempt to apply language modeling to passage retrieval in QA scenario.</p><p>Given a question 1 2 ... k Q q q q = , we first get a set of relevant passages from the local document collection, using the MG software <ref type="bibr" coords="3,188.40,695.68,16.55,9.07" target="#b19">[20]</ref> (available at http://www.cs.mu.oz.au/mg/). The passages are defined as halfoverlapped text windows each consisting of a fixed number (30 in our case) of words. Every passage is restricted not to cross paragraph boundary. Please be referred to <ref type="bibr" coords="4,349.44,74.07,16.80,9.07" target="#b20">[21]</ref> for a recent survey of various kinds of passages.</p><p>These passages need to be ranked according to their possibilities of containing the right answer. From the language modeling standpoint, effective ranking of passages could be achieved by constructing a questiontopic language model, which represents our expectations about the answer context. The primary difficulty here is the lack of training data.</p><p>Lavrenko and Croft <ref type="bibr" coords="4,174.24,154.96,16.79,9.07" target="#b14">[15]</ref> have proposed a wise method called "relevance-based language modeling", that can build a unigram model R M describing a topic in absence of training data. Their method is to approximate Pr <ref type="bibr" coords="4,152.64,182.55,14.74,9.07;4,185.04,182.55,3.36,9.07">[ | ]</ref> R w M by the formula:</p><formula xml:id="formula_6" coords="4,127.92,201.34,151.34,22.02">Pr[ | ] R w M Pr[ | ] w Q ≈ 1 2 1 2</formula><p>Pr[ , , ,..., ] Pr[ , ,..., ] k k w q q q q q q = 1 2</p><formula xml:id="formula_7" coords="4,371.04,218.25,16.23,6.31">1 2</formula><p>Pr[ , , ,..., ] Pr[ , , ,..., ] k k w w q q q w q q q = ∑ .</p><p>To estimate the joint probability</p><formula xml:id="formula_8" coords="4,254.88,236.46,16.49,6.35">1 2</formula><p>Pr[ , , ,..., ] k w q q q , we assume that there exists a set M of underlying source distributions from which w and 1 2 , ,..., k q q q could have been sampled independently, then we get</p><formula xml:id="formula_9" coords="4,154.80,277.26,16.49,6.35">1 2</formula><p>Pr[ , , ,..., ]</p><formula xml:id="formula_10" coords="4,140.64,262.90,253.32,33.36">k w q q q 1 Pr[ ] Pr[ | ] Pr[ | ] D k D D i D M i M w M q M ∈ =   =       ∑ ∏ M .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thus the probability Pr[ | ]</head><p>R w M can be computed as</p><formula xml:id="formula_11" coords="4,90.00,306.63,255.00,45.83">Pr[ | ] R w M 1 2 Pr[ | ]Pr[ | , ,..., ] D D D k M w M M q q q ∈ = ∑ M . Now it becomes obvious that R</formula><p>M is a linear mixture of distributions from M, where each distribution D M is "weighted" by its posterior probability of generating the question,</p><formula xml:id="formula_12" coords="4,388.56,356.55,87.72,11.06">1 2 Pr[ | , ,..., ] D k M q q q .</formula><p>Since previous research work has revealed immense benefits of exploiting the Web data for QA <ref type="bibr" coords="4,487.24,376.47,15.72,9.07" target="#b21">[22,</ref><ref type="bibr" coords="4,506.20,376.47,11.97,9.07" target="#b22">23]</ref>,</p><p>we decide to construct M from the question's relevant Web search results. As in [23], we formulate several queries by rewriting the question Q , and submit these queries to a search engine like Google k M q q q should have near-zero values for all but the top-N search results. In practice, the strict probabilistic interpretation of M q q q could be relaxed and substituted by any heuristic estimate, as long as it is non-negative and sums to 1 <ref type="bibr" coords="4,454.56,486.88,15.26,9.07" target="#b15">[16]</ref>. In our QA system,</p><formula xml:id="formula_13" coords="4,126.00,499.59,83.76,11.06">1 2 Pr[ | , ,..., ] D k</formula><p>M q q q is substituted by a weight of D M whose value is set according to the precision of its corresponding query <ref type="bibr" coords="4,245.05,513.76,15.46,9.07" target="#b22">[23]</ref>. For example, the search results returned by the query "+the Louvre Museum +is located" would be weighted higher than those returned by the query "Louvre". Furthermore, we augment the question-topic language model R M with a set of constraints which are expressed as probabilities of various events. The constraints used in our QA system include:</p><p>• answer-type constraints, e.g., <ref type="figure" coords="4,224.64,571.14,23.85,9.04">Pr[A |</ref> ] 0 R M = that means R M should give zero probability to passages containing no named entity of the desired answer type A ;</p><p>• answer-context constraints, e.g., for a question in the form "How did sb. die?", we could force </p><formula xml:id="formula_14" coords="4,102.72,606.46,367.56,14.08">Pr[survive | ] 0.0 R M = , Pr[wreck | ] 0.1 R M = , Pr[kill | ] 0.2 R M = , Pr[suicide | ] 0.2 R M = ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∑</head><p>. In this way, we are able to incorporate some prior knowledge into the question-topic language model. What remains is to use the constructed question-topic language model R M to rank relevant passages. For each passage P , we build a smoothed unigram model (see §2) P M . As suggested in <ref type="bibr" coords="4,453.60,701.67,15.26,9.07" target="#b15">[16]</ref>, we use the Kullback-Leibler (KL) divergence between passage language model P M and question-topic language model R M to rank passages. The KL divergence (also known as relative entropy) between P M and R M is defined as:</p><formula xml:id="formula_15" coords="5,127.92,114.70,229.80,27.78">( || ) P R divergence M M Pr[ | ] Pr[ | ]log Pr[ | ] P P w R w M w M w M = ∑ .</formula><p>Passages whose language models have a smaller divergence with the question-topic language model are considered more relevant to the question's topic. The KL divergence yields a reasonable ranking metric, but has problems when straightforwardly used in QA scenario. Consider a passage P which is very vague (looks too much like general English), it is unlikely to contain the right answer even if ( || )</p><p>P R divergence M M is small, because it does not describe a specific topic. To avoid such trivial passages, we leverage a notion of language model clarity <ref type="bibr" coords="5,289.20,207.75,15.45,9.07" target="#b16">[17]</ref>. Given a passage language model P M , its clarity is defined as ( )</p><formula xml:id="formula_16" coords="5,140.40,219.34,153.60,14.34">P clarity M ( || ) P G divergence M M =</formula><p>, where G M is the language model of general English estimated from a very large corpus. Consequently we rank the relevant passages according to the following score function:</p><p>( ) score P ( || ) ( )</p><formula xml:id="formula_17" coords="5,127.92,257.26,270.69,89.22">P R P divergence M M clarity M = - + ( || ) ( || ) P R P G divergence M M divergence M M = - + Pr[ | ] Pr[ | ] Pr[ | ]log Pr[ | ]log Pr[ | ] Pr[ | ] P P P P w w R G w M w M w M w M w M w M = - + ∑ ∑ Pr[ | ] Pr[ | ]log Pr[ | ] R P w G w M w M w M = ∑ .</formula><p>That is, the degree to which P M is similar to R M , increased to the extent that P M is a clear (focused) model that differs from general English. Note that adding clarity has resulted in the denominator that plays a role similar to IDF in standard information retrieval <ref type="bibr" coords="5,316.12,375.99,15.26,9.07" target="#b23">[24]</ref>. Finally, we return the highest ranked passage whose score is above a threshold as the answer. If no such answer could be found, we return 'NIL'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Massive query expansion is an integral part of the language modeling based retrieval algorithm, because we compute the probability Pr[ | ]</head><p>R w M for every word in the language. This helps our QA system to overcome the lexical chasm between questions and answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>The document set for evaluation is the AQUAINT collection that consists of 1,033,461 documents taken from the New York Times, the Associated Press, and the Xinhua News Agency newswires. The question set for evaluation contains 413 factoid questions that seek short, fact-based answers.</p><p>A submission for the passage task must contain exactly one answer for each factoid question. An answer is either "NIL" or an extracted passage from a document. A passage should be no longer than 250 bytes, and judged either incorrect (does not contain a correct answer), unsupported (contains a correct answer, but the document doesn't say so), or correct. Unresponsive passages (a passage that refers to an imitation or copy; a passage that contains multiple instances of the correct semantic category of the answer without actually specifying which is the answer; passages that omit necessary units; etc.) are incorrect. For a question with no correct answer in the document collection, only "NIL" answer is correct. The final score for a passage task submission is its accuracy (the fraction of answers judged correct).</p><p>The official evaluation result of our TREC2003 QA system is shown in Table <ref type="table" coords="5,403.68,607.36,3.66,9.07" target="#tab_3">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper reports our efforts on developing a language modeling approach to passage question answering. We want to demonstrate and advocate that language modeling may provide a uniform framework in which QA systems can integrate evidences from multiple knowledge sources to find the right answer.</p><p>Possible future work include: extending this language modeling approach to handle definition questions and list questions; integrating textual patterns <ref type="bibr" coords="6,285.60,273.28,16.80,9.07" target="#b21">[22]</ref> into language models; building language models to exploit structured and semi-structured data, particularly HTML/XML data on the Web.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,190.56,541.59,230.78,9.07;2,175.44,373.04,261.12,160.56"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The architecture of our TREC 2003 QA system.</figDesc><graphic coords="2,175.44,373.04,261.12,160.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,90.00,415.35,431.92,9.07;4,90.00,428.07,242.17,9.07;4,346.32,433.62,4.21,5.24;4,336.72,424.78,23.75,13.13;4,361.68,414.12,18.60,27.78;4,384.70,428.07,55.31,9.07;4,457.44,428.07,3.36,9.07;4,451.92,433.62,4.21,5.24;4,429.60,428.07,21.12,9.07;4,474.96,428.07,27.36,9.07;4,483.60,433.62,4.21,5.24;4,492.24,428.07,6.72,9.07;4,467.04,424.78,5.53,13.13;4,504.48,428.07,18.00,9.07;4,90.00,442.95,128.25,9.07;4,235.92,442.95,3.36,9.07;4,230.16,447.66,4.31,6.35;4,207.84,442.95,314.50,9.07;4,90.00,458.07,140.64,9.07;4,267.60,462.78,16.25,6.35;4,234.96,458.07,77.76,9.07"><head>2</head><label>2</label><figDesc>(http://www.google.com) to get search results. For each search result D , we build a smoothed unigram model (see §2) that is to be used as a source distribution D M ∈ M, so that Pr[ | ] tractable, we only use the top-N search results. This simplification is reasonable because the probability 1 Pr[ | , ,..., ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,238.71,432.15,39.07"><head></head><label></label><figDesc>Pr[ ] C can be estimated by the fraction of training questions labeled C . To estimate the probability Pr[ | ] Q C , we build a question-class language model C M for C and then get Pr</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,407.34,607.36,3.66,9.07"><head>Table 1 .</head><label>1</label><figDesc>. The evaluation result of our TREC2003 QA system.</figDesc><table coords="6,203.52,93.04,232.08,81.07"><row><cell>#(test questions)</cell><cell>413</cell></row><row><cell>#(correct answers)</cell><cell>173</cell></row><row><cell>#(unsupported answers)</cell><cell>9</cell></row><row><cell>#(incorrect answers)</cell><cell>231</cell></row><row><cell>accuracy</cell><cell>173 / 413 = 0.419</cell></row><row><cell>precision of recognizing no answer</cell><cell>10 / 64 = 0.156</cell></row><row><cell>recall of recognizing no answer</cell><cell>10 / 30 = 0.333</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,126.00,322.23,394.24,9.07;6,126.00,333.76,295.57,9.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,199.53,322.23,189.77,9.07">The TREC-8 Question Answering Track Report</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,410.40,322.23,109.84,9.07;6,126.00,333.76,116.57,9.07">Proceedings of the 8th Text Retrieval Conference (TREC)</title>
		<meeting>the 8th Text Retrieval Conference (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="77" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.98,345.28,394.34,9.07;6,126.00,356.56,315.24,9.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,199.44,345.28,209.37,9.07">Overview of the TREC-9 Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,430.08,345.28,90.24,9.07;6,126.00,356.56,136.26,9.07">Proceedings of the 9th Text Retrieval Conference (TREC)</title>
		<meeting>the 9th Text Retrieval Conference (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.98,368.08,393.05,9.07;6,126.00,379.60,345.48,9.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,199.44,368.08,223.53,9.07">Overview of the TREC 2001 Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,444.24,368.08,74.80,9.07;6,126.00,379.60,156.62,9.07">Proceedings of the 10th Text Retrieval Conference (TREC)</title>
		<meeting>the 10th Text Retrieval Conference (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="157" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.99,391.12,393.05,9.07;6,126.00,402.64,335.64,9.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,199.44,391.12,223.53,9.07">Overview of the TREC 2002 Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,444.24,391.12,74.80,9.07;6,126.00,402.64,156.62,9.07">Proceedings of the 11th Text Retrieval Conference (TREC)</title>
		<meeting>the 11th Text Retrieval Conference (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="57" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,126.00,414.16,391.14,9.07;6,126.00,425.68,375.13,9.07;6,126.00,437.20,190.44,9.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,436.23,414.16,80.92,9.07;6,126.00,425.68,126.36,9.07">The Role of Context in Question Answering Systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bakshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,314.41,425.68,186.72,9.07;6,126.00,437.20,57.66,9.07">Conference on Human Factors and Computing Systems (CHI)</title>
		<meeting><address><addrLine>Fort Lauderdale, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.99,448.72,387.98,9.07;6,126.00,460.24,173.15,9.07" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,185.20,448.72,236.85,9.07">A Bit of Progress in Language Modeling, Extended Version</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<idno>MSR-TR-2001-72</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,125.98,471.76,389.30,9.07;6,126.00,483.04,222.84,9.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,188.92,471.76,317.71,9.07">Two Decades Of Statistical Language Modeling: Where Do We Go From Here?</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,126.00,483.04,96.87,9.07">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1270" to="1278" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.99,494.56,350.55,9.07;6,126.00,506.08,375.69,9.07" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,236.00,494.56,240.54,9.07;6,126.00,506.08,36.50,9.07">An Empirical Study of Smoothing Techniques for Language Modeling</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<idno>TR-10-98</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Group, Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,126.00,517.60,393.84,9.07;6,126.00,529.12,135.72,9.07" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,158.99,517.60,200.42,9.07">Question Classification Using Language Modeling</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note>in CIIR Technical Report</note>
</biblStruct>

<biblStruct coords="6,126.00,540.64,370.72,9.07;6,126.00,552.16,359.64,9.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,207.98,540.64,118.12,9.07">Learning Question Classifiers</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,346.32,540.64,150.40,9.07;6,126.00,552.16,210.59,9.07">Proceedings of the 19th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 19th International Conference on Computational Linguistics (COLING)<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="556" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.99,563.68,346.33,9.07;6,126.00,575.20,351.62,9.07;6,126.00,586.72,332.04,9.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,232.68,563.68,220.47,9.07">Question Classification using Support Vector Machines</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,126.00,575.20,351.62,9.07;6,126.00,586.72,185.00,9.07">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,126.00,598.24,323.68,9.07" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<title level="m" coord="6,176.16,598.24,72.32,9.07">Machine Learning</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw Hill</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>international ed</note>
</biblStruct>

<biblStruct coords="6,126.00,609.52,379.13,9.07;6,126.00,621.04,362.08,9.07;6,126.00,632.56,194.52,9.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,247.80,609.52,257.32,9.07;6,126.00,621.04,54.21,9.07">Combining Naive Bayes and n-Gram Language Models for Text Classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,200.64,621.04,287.44,9.07;6,126.00,632.56,66.69,9.07">Proceedings of the 25th European Conference on Information Retrieval Research (ECIR)</title>
		<meeting>the 25th European Conference on Information Retrieval Research (ECIR)<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="335" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.99,644.08,367.38,9.07;6,126.00,655.60,159.72,9.07" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,200.62,644.08,205.81,9.07">GATE, a General Architecture for Text Engineering</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,417.36,644.08,76.01,9.07;6,126.00,655.60,44.40,9.07">Computers and the Humanities</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="223" to="254" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.99,667.12,370.09,9.07;6,126.00,678.65,369.60,9.07;6,126.00,690.17,227.64,9.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,252.94,667.12,140.44,9.07">Relevance-Based Language Models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,415.68,667.12,80.40,9.07;6,126.00,678.65,369.60,9.07;6,126.00,690.17,69.08,9.07">Proceedings of 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,125.99,74.07,392.25,9.07;7,126.00,85.60,364.56,9.07;7,126.00,97.12,278.04,9.07" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,315.14,74.07,130.80,9.07">Cross-Lingual Relevance Models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Choquette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,468.24,74.07,50.00,9.07;7,126.00,85.60,364.56,9.07;7,126.00,97.12,119.48,9.07">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,126.00,108.64,370.52,9.07;7,126.00,120.16,384.88,9.07;7,126.00,131.68,220.44,9.07" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,455.54,108.64,40.98,9.07;7,126.00,120.16,165.19,9.07">Relevance Models for Topic Detection and Tracking</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Deguzman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Laflamme</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,312.48,120.16,198.40,9.07;7,126.00,131.68,71.42,9.07">Proceedings of the Human Language Technology Conference (HLT)</title>
		<meeting>the Human Language Technology Conference (HLT)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,125.99,142.96,379.37,9.07;7,126.00,154.48,391.80,9.07;7,126.00,166.00,133.80,9.07" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,228.39,142.96,179.87,9.07">Passage Retrieval based on Language Models</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,430.32,142.96,75.04,9.07;7,126.00,154.48,386.95,9.07">Proceedings of the 11th ACM CIKM International Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the 11th ACM CIKM International Conference on Information and Knowledge Management (CIKM)<address><addrLine>McLean, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,126.00,177.52,394.33,9.07;7,126.00,189.04,354.65,9.07;7,126.00,200.56,379.56,9.07;7,126.00,212.08,75.96,9.07" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="7,295.03,177.52,225.30,9.07;7,126.00,189.04,99.63,9.07">Automatic Image Annotation and Retrieval using Cross-Media Relevance Models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,247.68,189.04,232.97,9.07;7,126.00,200.56,303.08,9.07">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,126.00,223.60,357.12,9.07;7,126.00,235.12,315.25,9.07" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<title level="m" coord="7,285.36,223.60,197.76,9.07;7,126.00,235.12,91.92,9.07">Managing Gigabytes: Compressing and Indexing Documents and Images</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,125.97,246.64,387.39,9.07;7,126.00,258.16,306.84,9.07" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="7,235.60,246.64,169.23,9.07">Effective Ranking with Arbitrary Passages</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kaszkiel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,415.68,246.64,97.68,9.07;7,126.00,258.16,191.04,9.07">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="344" to="364" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,126.00,269.68,361.70,9.07;7,126.00,280.96,380.56,9.07;7,126.00,292.48,103.08,9.07" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="7,233.94,269.68,253.76,9.07;7,126.00,280.96,41.46,9.07">Web based Pattern Mining and Matching Approach to Question Answering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,189.36,280.96,233.90,9.07">Proceedings of the 11th Text Retrieval Conference (TREC)</title>
		<meeting>the 11th Text Retrieval Conference (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,125.99,304.00,377.86,9.07;7,126.00,315.52,382.08,9.07;7,126.00,327.04,361.08,9.07" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="7,332.10,304.00,171.76,9.07;7,126.00,315.52,27.67,9.07">Web Question Answering: Is More Always Better?</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,174.48,315.52,333.60,9.07;7,126.00,327.04,202.28,9.07">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="291" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,126.00,338.56,381.36,9.07;7,126.00,350.08,57.48,9.07" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m" coord="7,277.20,338.56,119.80,9.07">Modern Information Retrieval</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
