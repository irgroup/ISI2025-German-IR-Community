<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.72,109.17,356.55,18.08;1,112.38,131.09,234.96,18.08;1,347.35,129.32,22.11,12.55;1,376.41,131.09,123.20,18.08">Robust, Web and Genomic Retrieval with Hummingbird SearchServer TM at TREC 2003</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-02-04">February 4, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,264.32,166.15,83.36,10.46"><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
							<email>stephen.tomlinson@hummingbird.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hummingbird Ottawa</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.72,109.17,356.55,18.08;1,112.38,131.09,234.96,18.08;1,347.35,129.32,22.11,12.55;1,376.41,131.09,123.20,18.08">Robust, Web and Genomic Retrieval with Hummingbird SearchServer TM at TREC 2003</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-02-04">February 4, 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">C581A14BA6E1314B9DF552B5059C093E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hummingbird participated in 4 tasks of TREC 2003: the ad hoc task of the Robust Retrieval Track (find at least one relevant document in the first 10 rows from 1.9GB of news and government data), the navigational task of the Web Track (find the home or named page in 1.2 million pages (18GB) from the .GOV domain), the topic distillation task of the Web Track (find key resources for topics in the first 10 rows from home pages of .GOV), and the primary task of the Genomics Track (find all records focusing on the named gene in 1.1GB of MEDLINE data). In the ad hoc task, SearchServer found a relevant document in the first 10 rows for 48 of the 50 new short (Title-only) topics. In the navigational task, SearchServer returned the home or named page in the first 10 rows for more than 75% of the 300 queries. In the distillation task, a SearchServer run found the most key resources in the first 10 rows of the submitted runs from 23 groups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Hummingbird SearchServer<ref type="foot" coords="1,192.99,443.21,3.97,7.32" target="#foot_0">1</ref> is an indexing, search and retrieval engine for embedding in Windows and UNIX information applications. SearchServer, originally a product of Fulcrum Technologies, was acquired by Hummingbird in 1999. Founded in 1983 in Ottawa, Canada, Fulcrum produced the first commercial application program interface (API) for writing information retrieval applications, Fulcrum r Ful/Text TM . The SearchServer kernel is embedded in many Hummingbird products, including SearchServer, an application toolkit used for knowledge-intensive applications that require fast access to unstructured information.</p><p>SearchServer supports a variation of the Structured Query Language (SQL), SearchSQL TM , which has extensions for text retrieval. SearchServer conforms to subsets of the Open Database Connectivity (ODBC) interface for C programming language applications and the Java Database Connectivity (JDBC) interface for Java applications. Almost 200 document formats are supported, such as Word, WordPerfect, Excel, PowerPoint, PDF and HTML.</p><p>SearchServer works in Unicode internally <ref type="bibr" coords="1,269.94,575.80,10.52,10.46" target="#b4">[5]</ref> and supports most of the world's major character sets and languages. The major conferences in text retrieval evaluation (TREC <ref type="bibr" coords="1,383.65,587.75,9.96,10.46" target="#b8">[9]</ref>, CLEF <ref type="bibr" coords="1,431.38,587.75,10.52,10.46" target="#b0">[1]</ref> and NTCIR <ref type="bibr" coords="1,502.16,587.75,10.79,10.46" target="#b6">[7]</ref>) have provided opportunities to objectively evaluate SearchServer's support for more than a dozen languages.</p><p>This paper looks at experimental work with SearchServer for robust retrieval (robustness of ad hoc search across topics), web navigation (find the one page the user wanted, i.e. a known-item search task), web distillation (find key resource pages for broad topics), and genomic retrieval (a domain-specific task). For the submitted runs in August 2003, an experimental post-5.x development build of SearchServer was used.</p><p>The document set of the TREC 2003 Robust Retrieval Track was a subset of the news and government data of TREC Disks 4 and 5. It consisted of 528,155 documents totaling 1,997,002,586 bytes (1.9 GB). The average document size was 3781 bytes. For more information, see the track overview paper.</p><p>For this ad hoc task, participants were asked to focus not just on mean average precision but on at least one other measure indicative of "robustness" across results, such as the number of topics for which at least one relevant was retrieved in the first 10 rows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The custom text reader called cTREC, described in our first TREC paper <ref type="bibr" coords="2,401.45,203.88,14.61,10.46" target="#b9">[10]</ref>, already supported detailed handling of the TREC Disk collections. For example, it allowed indexing of text following particular tags (such as &lt;HEADLINE&gt; and &lt;TEXT&gt;) and disabled indexing for text surrounded by other tags (such as &lt;PAGE&gt;...&lt;/PAGE&gt;) and for the tags themselves. As this year's guidelines did not restrict the fields allowed for indexing, we used the /k option of cTREC to allow indexing of text tagged as keywords (in particular, text tagged by &lt;IN&gt; or &lt;SUBJECT&gt; in the case of the disks used this year). Past experiments suggest that this detailed handling does not affect the results much.</p><p>We used the mygov.stp stopword list (99 English stopwords) first used for a web task last year <ref type="bibr" coords="2,500.22,287.56,14.61,10.46" target="#b11">[12]</ref>. The option to support inflections from lexical English stemming was enabled. We also experimented with an option to construct term vectors for result list clustering for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Searching</head><p>The submitted humR03d run was a "plain" SearchServer run on the Description field of each topic. It used SearchServer's Intuitive Searching (i.e. the IS ABOUT predicate of SearchSQL). Here is an example SearchSQL query for topic 314:</p><p>SELECT RELEVANCE('V2:3') AS REL, DOCNO FROM ROBUST03 WHERE FT_TEXT IS_ABOUT 'Commercial harvesting of marine vegetation such as algae, seaweed and kelp for food and drug purposes.' ORDER BY REL DESC;</p><p>SearchServer's relevance value calculation is the same as described last year <ref type="bibr" coords="2,425.51,475.84,14.61,10.46" target="#b11">[12]</ref>. Briefly, SearchServer dampens the term frequency and adjusts for document length in a manner similar to Okapi <ref type="bibr" coords="2,469.07,487.79,10.52,10.46" target="#b7">[8]</ref> and dampens the inverse document frequency using an approximation of the logarithm. SearchServer's relevance values are always an integer in the range 0 to 1000.</p><p>Before the queries were run, various SET statements were issued. "SET MAX SEARCH ROWS 1000" ensured the resulting working table would contain at most 1000 rows. Inflections from English stemming were enabled by "SET VECTOR GENERATOR 'word!ftelp/lang=english/base/noalt | * | word!ftelp/lang=english/inflect' " (for more details on stemming for several European languages, see our CLEF paper <ref type="bibr" coords="2,129.05,571.47,14.76,10.46" target="#b13">[14]</ref>). The importance of document length to the relevance value calculation was set with "SET RELEVANCE DLEN IMP 750" (scale of 0 to 1000).</p><p>We automatically removed "query stop words" such as "find", "relevant" and "document" from the topics before presenting them to SearchServer, i.e. words which are not stop words in general but were commonly used in previous years' TREC and CLEF topics as general instructions (this year's topics were not reviewed). An evaluation in last year's CLEF paper <ref type="bibr" coords="2,250.22,631.25,15.50,10.46" target="#b10">[11]</ref> found this step to be of only minor impact in several European languages including English.</p><p>The submitted humR03t run was the same as humR03d except that the Title field of the topic was used instead of the Description. For example, for topic 314, the Where clause was just "WHERE FT TEXT IS ABOUT 'Marine Vegetation' ". This run represented a "plain" SearchServer run for Title queries.</p><p>The submitted humR03de run used query expansion from blind feedback. The first two rows of the humR03d run were used to find additional query terms. Only terms appearing in at most 5% of the documents (based on the most common inflection of the term) were included. Mathematically, the approach is similar to Rocchio feedback with weights of one-half for the original query and one-quarter for each of the 2 expansion rows. This was the same blind feedback approach as used for Arabic experiments at TREC last year <ref type="bibr" coords="3,524.50,97.40,15.50,10.46" target="#b11">[12]</ref> except that we just used 2 rows for expansion this time instead of 5 (diagnostics on past CLEF and TREC ad hoc tasks suggested fewer rows may be more effective, perhaps because most tasks have fewer relevant documents to feed back in per topic than the Arabic task did). Blind feedback from the top retrieved documents is often effective at increasing recall later in the result list without sacrificing early precision, important components of the average precision measure. However, the large number of additional query terms negatively impacts performance. In practice, users could manually add terms to the query rather than work blindly. For this run, the measure in mind was average precision.</p><p>The submitted humR03dc run re-ordered the top 100 rows of humR03d so that the first 10 rows were from different clusters to see if that increased the chance of a relevant document in the top 10 rows. The steps were as follows:</p><p>First, the parameter settings were the same as for humR03d except that "SET MAX SEARCH ROWS 100" was used instead of 1000. Hence a relevant document had to appear in the top 100 for re-ordering to have a chance of moving it into the top 10.</p><p>Next, a result list clustering query was run on the 100 row working table, producing a set of up to 10 clusters. Each of the 100 rows appeared in exactly one cluster; the number of rows in each cluster could differ. Within each cluster, the rows were ordered by the original relevance value. The clusters themselves were ordered by the average relevance value of the rows of the cluster. The clustering was based on the term vectors of the documents built at index-time. Other than its impact on which 100 documents were clustered, the query had no impact on the clustering.</p><p>Finally, a round-robin of the clusters was followed, with the row of highest remaining relevance score of each cluster placed into the final result. (In the submitted file, the first 3 digits after the decimal point are the relevance value of the document, and the 4th digit is the cluster number from 0-9.)</p><p>The top 100 rows of humR03d and humR03dc should be the same except for the order. The first row for a topic in humR03d would appear somewhere in the top 10 for the topic in humR03dc. The other rows in the top 10 might differ.</p><p>The final result of humR03dc had at most 100 rows per topic. We did not bother to pad to 1000 rows. Hence for this run there was a bias against measures which consider documents retrieved past 100 rows, such as recall and average precision. For this run, the measure in mind was the 'relevant in the top 10 rows' measure.</p><p>The submitted humR03tc run was the same as humR03dc except that it was based on humR03t instead of humR03d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results</head><p>For this task, there were 50 "old" topics and 50 "new" topics.</p><p>The 50 old topics were selected (by the task organizers) from past years' ad hoc TREC topics 301-450 to produce a set of "tough" topics, i.e. topics on which few systems produced a high precision score when they were originally used (though there may have been a bias against topics on which all systems produced a low score; the track overview paper may elaborate more). As they were already in the public domain, the guidelines allowed groups to continue to study these topics for this year's submissions, which might also help lead to techniques for improving results on tough topics. One must be cautious however at reading too much into results on these topics (even "statistically significant" results) because of the possibility that the techniques are tuned to this data.</p><p>For the 50 new topics, (automatic) systems were not allowed to be altered based on examination of the topics, so in that sense the results may be more meaningful. But there was no reason to expect these topics to be as "tough" as the specially-selected older set (it is very hard to predict which topics will be tough in advance) so for the purpose of this track (robustness across topics) there may not be enough challenging topics to distinguish the techniques.</p><p>We separately list the results for each of these sets of topics (we do not bother to look at the combined scores). Also, for the 50 new topics, the relevance assessors distinguished "highly relevant" documents from just "relevant" documents. 43 of the 50 topics had at least one "highly relevant" document. We list the scores averaged over those 43 topics when just considering highly relevants as relevant (tagged with "newH"). Table <ref type="table" coords="4,115.47,524.04,4.98,10.46" target="#tab_0">1</ref> gives an overview of several precision scores for each submitted run (also, in brackets, is an unsubmitted run (because of the 5-run submission limit) produced at the same time, humR03te, an analog of humR03de for Titles). Listed for each run are its mean average precision (AvgP), the mean precision after  5, 10 and 20 documents retrieved (P@5, P@10 and P@20 respectively), the mean interpolated precision at 0% and 30% recall (Rec0 and Rec30 respectively), the mean precision after R documents retrieved (P@R) where R is the number of relevant documents for the topic, and the ratio of the number of topics with at least one relevant retrieved in the top 10 vs. the total number of topics (%Rel10). (Definitions of the measures are in last year's paper <ref type="bibr" coords="5,159.41,264.87,14.61,10.46" target="#b11">[12]</ref>, and they likely are also in an appendix of the conference proceedings.) It appears that for every measure listed, the score on the "new" topics is higher than the corresponding score for the "old" topics, i.e. as expected, the "old" topics were more challenging (on average). For tables focusing on the impact of one particular difference in approach, the columns are as follows:</p><p>• "Experiment" indicates whether the Title or Description topics were used ("T" or "D" respectively) and whether the score is based on the old topics ("old"), the new topics when treating all relevants the same ("new"), or the new topics just counting highly relevants as relevant ("newH").</p><p>• "AvgDiff" is the average (mean) difference in the score.</p><p>• "95% Confidence" is an approximate 95% confidence interval for the average difference calculated using Efron's bootstrap percentile method<ref type="foot" coords="5,255.89,395.30,3.97,7.32" target="#foot_1">2</ref> [3] (using 100,000 iterations). If zero is not in the interval, the result is "statistically significant" (at the 5% level), i.e. the feature is unlikely to be of neutral impact, though if the average difference is small (e.g. &lt;0.020) it may still be too minor to be considered "significant" in the magnitude sense.</p><p>• "vs." is the number of topics on which the score was higher, lower and tied (respectively) with the feature enabled. These numbers should always add to the number of topics (50 or 43).</p><p>• "2 Largest Diffs (Topic)" lists the two largest differences in the score (based on the absolute value) with each followed by the corresponding topic number in brackets (the old topic numbers range from 301 to 450 and the new topic numbers from 601 to 650).</p><p>Table <ref type="table" coords="5,114.68,527.88,4.98,10.46" target="#tab_1">2</ref> shows the impact of the clustering-based technique on the percentage of topics with a relevant in the first 10 rows. For Description queries, this is based on subtracting the scores of humR03d from humR03dc, and for the Title queries, subtracting the scores of humR03t from humR03tc. As you can see, there was a net gain of 2 topics with a relevant in the top 10 on the old Description queries (7 gained but 5 lost), though this was not statistically significant, and the loss of 4 on the old Title queries was statistically significant. On the new queries, the finding was similar; the differences were not significant on the Description queries but were on the Title queries, both when counting all relevants or just highly relevants.</p><p>Table <ref type="table" coords="5,115.81,611.57,4.98,10.46" target="#tab_2">3</ref> shows the impact of the blind feedback technique on the average precision score (based on subtracting humR03d from humR03de, and humR03t from (unsubmitted run) humR03te). The increase was statistically significant for 5 of the 6 cases, the exception being for highly relevants on the new Description topics.</p><p>Table <ref type="table" coords="5,113.89,659.39,4.98,10.46" target="#tab_3">4</ref> shows the impact of the same blind feedback technique on the perentage of topics with a relevant in the first 10 rows (based on the same runs as Table <ref type="table" coords="5,307.09,671.34,3.87,10.46" target="#tab_2">3</ref>). None of the impacts were statistically significant. For the plain SearchServer runs, more topics found a relevant in the first 10 rows using the Titles than the Descriptions (42 to 39 for the old topics, 48 to 46 for the new topics (though tied at 31 when restricting to highly relevants) as per Table <ref type="table" coords="6,221.81,394.46,3.87,10.46" target="#tab_0">1</ref>). These results might suggest that shorter queries are more "robust" (perhaps extra details throw off a system more often than missing details, even though the longer queries score higher on the other listed measures which reward recall more). However, these changes in the number of topics with a relevant in the first 10 rows did not pass a significance test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Web Retrieval</head><p>Both tasks of the TREC 2003 Web Track used the same .GOV collection as last year. It consists of pages downloaded from the .gov domain of the World Wide Web in early 2002. Uncompressed, it is 19,455,030,550 bytes (18.1 GB) and a total of 1,247,753 documents. The average document size is 15,592 bytes. For more information on the .GOV collection, see <ref type="bibr" coords="6,351.08,514.99,9.96,10.46" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing</head><p>The indexing approach was the same as described in last year's paper <ref type="bibr" coords="6,383.80,563.78,15.50,10.46" target="#b11">[12]</ref> (except that a newer version of the software was used which may have contained an updated English lexicon for stemming).</p><p>Briefly: in addition to full-text indexing, the custom text reader cTREC populated particular columns such as TITLE (if any), URL, URL TYPE and URL DEPTH. The URL TYPE was set to ROOT, SUB-ROOT, PATH or FILE, based on the convention which worked well in TREC 2001 for the Twente/TNO group <ref type="bibr" coords="6,100.68,623.56,15.50,10.46" target="#b14">[15]</ref> on the entry page finding task (also known as the home page finding task). The URL DEPTH was set to a term indicating the depth of the page in the site. Table <ref type="table" coords="6,377.04,635.51,4.98,10.46" target="#tab_4">5</ref> contains URL types and depths for example URLs, and Table <ref type="table" coords="6,187.60,647.47,4.98,10.46" target="#tab_5">6</ref> shows the number of .GOV pages of each URL type and depth. The exact rules we used are given in last year's paper <ref type="bibr" coords="6,238.85,659.42,14.61,10.46" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Searching</head><p>Even though the 2 web tasks are potentially quite different (the navigational task is a known-item task (one right answer), while the topic distillation task is focused on distilling broad topics to key resource pages), we used the same techniques for both tasks for each of the 5 submitted runs (and most of the techniques used were the same as last year). This allows us to compare the impact of the techniques on different tasks.</p><p>The submitted humNP03l and humTD03l runs used the same approach as the diagnostic base run described in last year's paper <ref type="bibr" coords="7,210.42,155.09,15.50,10.46" target="#b11">[12]</ref> which was just to search the content (FT TEXT column) using the IS ABOUT predicate (i.e. the same approach as used for the "plain" runs of the Robust task).</p><p>The submitted humNP03pl and humTD03pl runs used the same approach as last year's hum02pd run. Below is an example SearchSQL query. The queries differed from humNP03l and humTD03l in that that properties and phrases in properties were given a little extra weight. (The ALL PROPS column contained the title, URL, first heading and some meta tags, but not most of the document content; see last year's paper for the details.) Note that the FT TEXT column also indexed all of the properties except for the URL. The CONTAINS predicate does phrase searching, so the listed terms would have to occur adjacently in the specified order (except stop words). "SET PHRASE DISTANCE 4" was previously specified so that there could be up to 4 characters between adjacent terms (plus additional whitespace). By default, the CONTAINS predicate does exact searching (i.e. no inflections from stemming), though some Unicodebased normalizations (e.g. decompositions and conversion to upper-case) are still done. The motivation for including the query as a phrase was that it seemed the query might often be in the title or other property information of the document (e.g. a query in mind was "Washington State Legislature" (which was not one of the 150 official queries last year)). The phrase searching was just given one-tenth the weight of content searching for relevance ranking purposes. Experiments on the TREC 2001 entry page finding task suggested a small weight was helpful (on average) but a strong weight had a negative impact.</p><p>The IS ABOUT predicate uses SearchServer's Intuitive Searching. It by default matches inflections froms English stemming and just requires one of the terms to have a match. It was used with WEIGHT 1 on the ALL PROPS column to increase the ranking of documents with query terms in the title or other property information. It was used with WEIGHT 10 on the FT TEXT column (which represents the external document). Again, these weights were chosen based on what worked well on the TREC 2001 entry page finding task.</p><p>The submitted humNP03upl and humTD03upl runs used the same approach as last year's hum02upd run. The 'u' indicates a higher weight was given to URLs of particular type and depth. See last year's paper for an example of the SearchSQL syntax <ref type="bibr" coords="7,251.85,557.58,14.61,10.46" target="#b11">[12]</ref>.</p><p>The submitted humNP03uhpl and humTDuhpl runs used the same approach as last year's hum02uhp run except for using a document length importance of 500 instead of 250 (500 was used for all submitted web runs this year). The 'h' indicates an even higher weight was given to URL TYPE (the 3 terms of WEIGHT 10 were given WEIGHT 25). On the TREC 2001 entry page finding task, the stronger URL TYPE weights gave similar MRR scores to the lower ones.</p><p>The submitted humNP03up and humTD03up runs were the same as humNP03upl and humTD03upl (respectively) except that linguistic expansion from English stemming was disabled (i.e. matching of inflections was disabled) by "SET VECTOR GENERATOR '' ".</p><p>For the navigational (humNP03*) runs, the statement "SET MAX SEARCH ROWS 50" was previously executed so that the working table would contain at most 50 rows, whereas for the topic distillation (humTD03*) runs, the statement "SET MAX SEARCH ROWS 1000" was previously executed. For the web queries, no query terms were discarded (e.g. there was no expectation that discarding the words "find", "relevant" and "document" would be beneficial, unlike for the Robust task). Of course, the index omitted a few stop words (e.g. "the", "by") as previously mentioned.</p><p>SearchServer's relevance value calculation is the same as described for the Robust task. Additionally, when multiple predicates are combined, as was done for some of the web approaches, SearchServer currently does not normalize by query length. For example, the URL TYPE clauses would have a lot less relative impact if the topic query contained 5 words instead of 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>The evaluation measures are likely explained in an appendix of this volume. Briefly, for the navigational task, "Reciprocal Rank" for a topic is one divided by the rank in which the home or named page was found (using the smallest rank if there were duplicates of the page), or zero if the page was not found. "Mean Reciprocal Rank" (MRR) is the average of the reciprocal ranks over all the topics. "%Top10" is the percentage of topics for which the home or named page was found in the first 10 rows. "%Fail" is the percentage of topics for which the home or named page was not found in the first 50 rows. The topic distillation measures are the same as described previously in the Robust section.</p><p>Table <ref type="table" coords="8,113.99,582.17,4.98,10.46" target="#tab_7">7</ref> shows the scores of the submitted navigational runs in descending order by mean reciprocal rank over all 300 queries. The HP columns show the scores just for the 150 home page queries. The NP columns show the scores just for the 150 named page queries. (The topics did not state whether they were of HP or NP type; that information was provided by the organizers after the submission date for use in analysis.)</p><p>Table <ref type="table" coords="8,114.26,629.99,4.98,10.46">8</ref> shows the impact when isolating each technique distinguishing the submitted navigational runs:</p><p>• The 'u' factor (extra weight for URL type and depth) increased MRR dramatically on the home pages (23 points) but (like last year) was detrimental on the named pages (9 points). More diagnostics are below.</p><p>• The 'p' factor (extra weight for HTML properties and phrases in properties) increased MRR 14 points on both home and named pages. More diagnostics are below. • The 'l' factor (linguistic expansion (inflections) from lexical English stemming) made little difference (on average).</p><p>• The 'h' factor (even more extra weight for URL type) was detrimental even on the home page queries, even though it had a neutral impact on the TREC 2001 entry page task.</p><p>Table <ref type="table" coords="9,114.56,591.95,4.98,10.46" target="#tab_8">9</ref> isolates the components of the 'p' factor. 'v' denotes that the run included TITLE IS ABOUT (i.e. vector) matching with weight 1, and 'q' denotes that the run included TITLE CONTAINS (i.e. phrase) matching with weight 1. Adding the 'v' factor (to a full content search with weight 10) increased MRR significantly for both home pages and named pages (8 and 12 points respectively as per the "v (vl-l)" rows). The 'q' factor had significant, though smaller, increases (6 and 5 points respectively as per the "q (ql-l)" rows). If one of these was already done, adding the other still led to a significant increase except in the case of adding phrase matching to a vector match for named pages (as per the "NP q (vql-vl)" row). Using the ALL PROPS column instead of the TITLE column did not lead to a further significant increase as per "other (pl-vql)" rows. So for the 'p' factor, like last year, most of the benefit appears to have come from the TITLE weighting, but unlike last year, both vector and phrase matching helped significantly, not just vector -0.026 (-0.049,-0.003) 5-13-32 -0.300 <ref type="bibr" coords="10,422.89,272.80,11.62,10.46" target="#b6">(7)</ref>, -0.200 <ref type="bibr" coords="10,475.47,272.80,12.73,10.46" target="#b8">(9)</ref> matching (perhaps the topics this year happened to be part of the title of the desired page more often than last year). Table <ref type="table" coords="10,114.95,340.29,9.96,10.46" target="#tab_9">10</ref> isolates the components of the 'u' factor. 'r' denotes the weight assigned to the URL TYPE values (ROOT, SUBROOT, PATH) and 'd' denotes the weight assigned to the URL DEPTH values ('u' was 'r10d5' and is in Table <ref type="table" coords="10,176.46,364.21,3.87,10.46">8</ref>). A small weight on either the url depth or type increased the home page score substantially without a significant drop in the named page score (as per the 'd5' and 'r5' rows). So it may be reasonable to include a small weight on url structure in a general web page search system, regardless of the expected frequency ratio of home page and named page queries. Higher weights may be reasonable if home page queries are expected to be a lot more common.</p><p>Table <ref type="table" coords="10,114.54,423.98,9.96,10.46" target="#tab_10">11</ref> shows the scores of the submitted topic distillation runs in descending order by Precision@10. The humTD03upl run had the highest Precision@10 score of any submitted run from the 23 groups, even though its score means it found on average just more than 1 key resource page in the first 10 rows (the judgements contained 8 key resource pages per topic on average). The topics were broad (e.g. "science" was an example in the task guidelines) and the top retrieved rows may have been filled with many more pages that were "relevant" to the topic even though they were not judged "key resources" by the assessors.</p><p>Tables 12, 13 and 14 show the impact of the submitted topic distillation techniques on Precision@10, average precision and Precision@R respectively:</p><p>• The 'u' factor (extra weight for URL type and depth) increased Precision@10 by 7 points and produced a statistically significant increase for all 3 examined measures. This is not surprising because the key resources were required to be home pages this year.</p><p>• The 'p' factor (extra weight for HTML properties and phrases in properties) did not have a significant impact on Precision@10, but Tables <ref type="table" coords="10,262.87,583.01,9.96,10.46" target="#tab_12">13</ref> and<ref type="table" coords="10,297.81,583.01,9.96,10.46" target="#tab_13">14</ref> show it led to a significant increase in the average precision and Precision@R measures.</p><p>• The 'l' factor (linguistic expansion (inflections) from lexical English stemming) made little difference for most topics except for some measures for topic 17 ("Polygraphs").</p><p>• The 'h' factor (even more extra weight for URL type) had a significant negative impact on the examined measures.</p><p>Overall, the impacts on the distillation scores were much more like the impacts on the home page finding scores than the named page finding scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Genomic Retrieval</head><p>For the primary task of the Genomics Track (find all records focusing on the named gene), the MEDLINE data consisted of 525,938 documents (records), all in one file ("trec-medline") of 1,158,771,473 bytes (1.1 GB) uncompressed. The average record length was 2203 bytes. More information should be in the track overview paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Indexing</head><p>The cTREC text reader (described in the Robust section) was enhanced to include a /M option for identifying the MEDLINE records (documents) during table expansion from the "trec-medline" file. For the individual records, the /p option of cTREC was used, i.e. we just passed through all of the text for indexing, including identifiers such as "UI", "PMID", "MH" etc. (Maybe next year we will enhance the text reader to populate columns from particular fields, such as the Title, allowing experiments with the record structure like we did for the web data.)</p><p>A different stopfile, mynum.stp, was used for this task. It contained just one instruction, AL = "0-9", which means to treat the digits 0 to 9 as alphabet characters. For example, this would cause the symbol "CDKN1A" to be indexed as 1 term instead of 3. Experiments on the training queries found the scores were a little higher with this indexing change. The mynum.stp stopfile did not contain any stop words as the training queries did not seem to use much natural language.</p><p>Punctuation characters, including hyphens and parentheses, were still treated as term separators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Searching</head><p>The submitted runs used IS ABOUT queries based on combining just 5 of the 8 query fields: the 2 name fields (OFFICIAL GENE NAME, PREFERRED GENE NAME) and the 3 symbol fields (OFFICIAL SYMBOL, ALIAS SYMBOL, PREFERRED SYMBOL). The other 3 fields were omitted (PREFERRED PRODUCT, ALIAS PROT, PRODUCT) because they were found to be harmful on the training topics. Also, the species information was ignored for the submitted runs.</p><p>The submitted humG03ns run gave equal weight to the five fields. An example SearchSQL query is below (from run humG03ns test topic 1). The parentheses between query fields were just added for readability and did not affect the IS ABOUT search: The submitted humG03ns5 run gave 5 times the weight to the three symbol fields (by repeating them 5 times in the query, rather than using the WEIGHT clause), which was modestly helpful on the training topics (though not significantly so).</p><p>Inflections from stemming were disabled for both runs. The document length importance was set to 0 for both runs. More details of the relevance ranking are in the Robust and Web sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Table <ref type="table" coords="12,99.47,355.13,9.96,10.46" target="#tab_14">15</ref> shows various scores of the submitted runs, humG03ns and humG03ns5 (the column headings are explained in the Robust section).</p><p>At the conference, some groups found that filtering by species (organism) was helpful, presumably because of the artificial way the relevance assessments were created for this first Genomics task. The NLM paper <ref type="bibr" coords="12,529.48,391.00,10.52,10.46" target="#b5">[6]</ref> described how to convert the species name in the topic statement to the MH field in the MEDLINE records (map 'Homo sapiens' to 'Human', map 'Mus musculus' to 'Mice', map 'Rattus norvegicus' to 'Rats', map 'Drosophila melanogaster' to 'Drosophila'). The NRC reported that just 10 of the official right answers were discarded if restricting to fields of the same organism <ref type="bibr" coords="12,307.07,438.83,9.96,10.46" target="#b1">[2]</ref>.</p><p>The diagnostic "base run" is the same as humG03ns except that it adds a phrase-match restriction to just include documents of the specified species, e.g. "AND (FT TEXT CONTAINS 'MH -Human' WEIGHT 0)" was added to the query if the species was 'Homo sapiens'. It was assigned "WEIGHT 0" so that it would not affect the relevance calculation. Table <ref type="table" coords="12,255.79,486.64,9.96,10.46" target="#tab_14">15</ref> shows that the base run scored a 0.312 mean average precision, an increase of more than 13 points over humG03ns.</p><p>The "+5x phrases" diagnostic run of Table <ref type="table" coords="12,275.58,510.56,9.96,10.46" target="#tab_14">15</ref> additionally boosted the scores of records which contained any of the query fields as complete phrases, by use of the CONTAINS predicate. In the CONTAINS predicate, hyphenated terms match not just terms separated with different punctuation or white space, but also concatenations of the terms (e.g. a CONTAINS search for 'CRE-BP1' would additionally match not just 'CRE(BP1)', 'CRE BP1', etc., but also 'CREBP1'). The WHERE clause for topic 1 was WHERE ( FT_TEXT IS_ABOUT 'activating transcription factor 2 () ATF2 () HB16 () CREB2 () TREB7 () CRE-BP1' OR (FT_TEXT CONTAINS 'activating transcription factor 2' WEIGHT 5) OR (FT_TEXT CONTAINS 'ATF2' WEIGHT 5) OR (FT_TEXT CONTAINS 'HB16' WEIGHT 5) OR (FT_TEXT CONTAINS 'CREB2' WEIGHT 5) OR (FT_TEXT CONTAINS 'TREB7' WEIGHT 5) OR (FT_TEXT CONTAINS 'CRE-BP1' WEIGHT 5) ) AND (FT_TEXT CONTAINS 'MH -Human' WEIGHT 0) Table <ref type="table" coords="12,114.05,692.38,9.96,10.46" target="#tab_15">16</ref> compares a number of diagnostic runs to the base run (always subtracting the base run's scores in average precision from the listed run). For example, the first row shows that the "+5x phrases" run scored on average 4 points higher than the base run (0.356 minus 0.312 is 0.044), and this difference was statisticially significant (see the Robust section for a detailed explanation of the column headings of Table <ref type="table" coords="13,72.00,378.44,8.30,10.46" target="#tab_15">16</ref>). Phrasing: The "+2x phrases" and "+1x phrases" runs used 'WEIGHT 2' and 'WEIGHT 1' for the phrases instead of 'WEIGHT 5', and they also produced significant 4 point gains. The "phrases only" run just used the phrases (dropping the IS ABOUT predicate) and scored about the same as the base run on average, though with a lot of variance. The "number parsing" run used a table with the default parsing of alphanumerics (e.g. "CDKN1A" would be treated as 3 terms (CDKN, 1, A) instead of 1), in a sense removing the natural phrasing of symbols, and the 4 point drop in score passed the significance test. (Note that if the symbols matched as phrases when names did not, the effect would be the same as just increasing the symbol weight (described below), which may be why topic 24 shows a similar increase in Table <ref type="table" coords="13,455.70,474.09,9.96,10.46" target="#tab_15">16</ref> for both phrases and symbol weighting.) There is probably room for improvement in this term matching area (e.g. a search for 'CDKN1A' will not match 'CDKN 1A' with the parsing rules used for this task).</p><p>Query fields: The "2x sym" and "5x sym" runs were the same as the diagnostic base run except that the symbols were each listed twice and five times (respectively) to boost their impact on the score. Table <ref type="table" coords="13,72.00,533.85,9.96,10.46" target="#tab_15">16</ref> shows the 3 point gain of "2x sym" was statistically significant, while the 2 point gain of "5x sym" was not. Just using the symbols (omitting the name fields) scored 3 points lower on average (as per the "omit names" run), but with a lot of variance. Just using the names and not the symbols scored a significant 11 points lower (as per the "omit symbols" run). Adding in the 3 other fields (preferred product, product, alias prot) scored a significant 5 points lower (as per the "all fields" run). Overall, it appears the symbols are the most useful of the query fields for this task, though perhaps we're not making as effective use of the names as we could (as the phrase experiments suggested).</p><p>Relevance ranking: Squaring the importance of inverse document frequency to the relevance calculation (by using SearchServer relevance method 'V2:4' instead of 'V2:3') scored 2 points higher, but did not quite pass the significance test, as per the listed "idf squared (V2:4)" run. Enabling document length normalization or matching of inflections from English stemming made little difference for this task as per the listed "DLEN 500" and "stemming on" runs. Simpler ranking techniques, such as just counting the number of query terms matched (relevance method '2:2') or simply counting all the matches in a record (relevance method '2:1') scored dramatically lower (14 and 20 points respectively, as per the listed "terms count (2:2)" and "hits count (2:1)" runs) indicating that a combination of term frequency dampening and inverse document frequency is still valuable for this task (though we have not separated the impact of these techniques).</p><p>As previously mentioned, not restricting to the species given in the topic scored more than 13 points lower as per the listed "omit species" run (the difference of the humG03ns run and the base run). Adding the species to the IS ABOUT vector instead of using a strict CONTAINS match scored 7 points lower (as per the listed "vector species" run). At the conference it was stated that in a real task it can be useful to find the gene in different species, so these species results apparently are examples of misleading conclusions from the artificial nature of the judgements used this year.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,90.62,80.42,430.78,250.76"><head>Table 1 :</head><label>1</label><figDesc>Precision of Submitted Runs</figDesc><table coords="4,90.62,93.17,430.78,238.00"><row><cell>Run</cell><cell>AvgP</cell><cell>P@5</cell><cell>P@10</cell><cell>P@20</cell><cell>Rec0</cell><cell>Rec30</cell><cell>P@R</cell><cell>%Rel10</cell></row><row><cell>(humR03te-old)</cell><cell>0.131</cell><cell>34.4%</cell><cell>33.0%</cell><cell>27.7%</cell><cell>0.564</cell><cell>0.189</cell><cell>19.4%</cell><cell>40/50</cell></row><row><cell>humR03t-old</cell><cell>0.109</cell><cell>30.4%</cell><cell>28.8%</cell><cell>23.9%</cell><cell>0.555</cell><cell>0.151</cell><cell>17.1%</cell><cell>42/50</cell></row><row><cell>humR03tc-old</cell><cell>0.057</cell><cell>20.8%</cell><cell>17.8%</cell><cell>18.1%</cell><cell>0.476</cell><cell>0.070</cell><cell>12.6%</cell><cell>38/50</cell></row><row><cell>humR03de-old</cell><cell>0.148</cell><cell>38.8%</cell><cell>35.2%</cell><cell>28.1%</cell><cell>0.656</cell><cell>0.187</cell><cell>19.6%</cell><cell>38/50</cell></row><row><cell>humR03d-old</cell><cell>0.127</cell><cell>37.2%</cell><cell>29.6%</cell><cell>24.7%</cell><cell>0.635</cell><cell>0.167</cell><cell>17.4%</cell><cell>39/50</cell></row><row><cell>humR03dc-old</cell><cell>0.071</cell><cell>26.0%</cell><cell>20.6%</cell><cell>17.3%</cell><cell>0.582</cell><cell>0.072</cell><cell>13.4%</cell><cell>41/50</cell></row><row><cell>(humR03te-new)</cell><cell>0.332</cell><cell>51.2%</cell><cell>44.8%</cell><cell>35.8%</cell><cell>0.684</cell><cell>0.482</cell><cell>33.6%</cell><cell>46/50</cell></row><row><cell>humR03t-new</cell><cell>0.280</cell><cell>46.8%</cell><cell>41.0%</cell><cell>32.2%</cell><cell>0.672</cell><cell>0.401</cell><cell>30.6%</cell><cell>48/50</cell></row><row><cell>humR03tc-new</cell><cell>0.147</cell><cell>28.4%</cell><cell>20.4%</cell><cell>19.7%</cell><cell>0.630</cell><cell>0.194</cell><cell>18.9%</cell><cell>42/50</cell></row><row><cell>humR03de-new</cell><cell>0.377</cell><cell>57.2%</cell><cell>48.4%</cell><cell>39.9%</cell><cell>0.767</cell><cell>0.543</cell><cell>37.7%</cell><cell>43/50</cell></row><row><cell>humR03d-new</cell><cell>0.346</cell><cell>57.6%</cell><cell>47.6%</cell><cell>38.6%</cell><cell>0.779</cell><cell>0.500</cell><cell>34.5%</cell><cell>46/50</cell></row><row><cell>humR03dc-new</cell><cell>0.178</cell><cell>33.6%</cell><cell>23.4%</cell><cell>21.1%</cell><cell>0.687</cell><cell>0.227</cell><cell>20.8%</cell><cell>44/50</cell></row><row><cell>(humR03te-newH)</cell><cell>0.253</cell><cell>28.8%</cell><cell>21.2%</cell><cell>16.2%</cell><cell>0.430</cell><cell>0.342</cell><cell>25.4%</cell><cell>31/43</cell></row><row><cell>humR03t-newH</cell><cell>0.225</cell><cell>24.6%</cell><cell>19.8%</cell><cell>15.1%</cell><cell>0.402</cell><cell>0.307</cell><cell>24.1%</cell><cell>31/43</cell></row><row><cell>humR03tc-newH</cell><cell>0.117</cell><cell>9.8%</cell><cell>8.1%</cell><cell>8.0%</cell><cell>0.333</cell><cell>0.140</cell><cell>10.0%</cell><cell>22/43</cell></row><row><cell>humR03de-newH</cell><cell>0.309</cell><cell>30.2%</cell><cell>24.2%</cell><cell>17.8%</cell><cell>0.551</cell><cell>0.424</cell><cell>28.2%</cell><cell>32/43</cell></row><row><cell>humR03d-newH</cell><cell>0.305</cell><cell>32.6%</cell><cell>23.5%</cell><cell>17.2%</cell><cell>0.579</cell><cell>0.413</cell><cell>29.8%</cell><cell>31/43</cell></row><row><cell>humR03dc-newH</cell><cell>0.176</cell><cell>18.6%</cell><cell>11.6%</cell><cell>10.2%</cell><cell>0.491</cell><cell>0.225</cell><cell>17.4%</cell><cell>27/43</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,112.03,363.50,387.93,103.26"><head>Table 2 :</head><label>2</label><figDesc>Impact of Clustering on Percentage of Topics With a Relevant in Top 10</figDesc><table coords="4,112.03,378.19,387.93,88.56"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>D-old-Rel10</cell><cell>0.040</cell><cell>(-0.101, 0.181)</cell><cell>7-5-38</cell><cell>1.000 (330), 1.000 (401)</cell></row><row><cell>D-new-Rel10</cell><cell>-0.040</cell><cell>(-0.121, 0.041)</cell><cell>1-3-46</cell><cell>1.000 (605), -1.000 (608)</cell></row><row><cell>T-old-Rel10</cell><cell>-0.080</cell><cell>(-0.161,-0.019)</cell><cell>0-4-46</cell><cell>-1.000 (394), -1.000 (336)</cell></row><row><cell>D-newH-Rel10</cell><cell>-0.093</cell><cell>(-0.210, 0.001)</cell><cell>1-5-37</cell><cell>1.000 (643), -1.000 (616)</cell></row><row><cell>T-new-Rel10</cell><cell>-0.120</cell><cell>(-0.221,-0.039)</cell><cell>0-6-44</cell><cell>-1.000 (612), -1.000 (642)</cell></row><row><cell>T-newH-Rel10</cell><cell>-0.209</cell><cell>(-0.373,-0.069)</cell><cell>2-11-30</cell><cell>1.000 (631), 1.000 (620)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,109.96,587.25,392.08,103.26"><head>Table 3 :</head><label>3</label><figDesc>Impact of Blind Feedback on Average Precision</figDesc><table coords="4,109.96,601.93,388.21,88.57"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>(T-new-AvgP)</cell><cell>0.052</cell><cell>( 0.031, 0.075)</cell><cell>40-10-0</cell><cell>0.345 (614), 0.188 (607)</cell></row><row><cell>D-new-AvgP</cell><cell>0.031</cell><cell>( 0.004, 0.057)</cell><cell>34-16-0</cell><cell>-0.221 (616), 0.205 (633)</cell></row><row><cell>(T-newH-AvgP)</cell><cell>0.027</cell><cell>( 0.012, 0.043)</cell><cell>30-10-3</cell><cell>0.180 (648), 0.147 (626)</cell></row><row><cell>(T-old-AvgP)</cell><cell>0.022</cell><cell>( 0.010, 0.035)</cell><cell>32-18-0</cell><cell>0.181 (350), 0.174 (372)</cell></row><row><cell>D-old-AvgP</cell><cell>0.021</cell><cell>( 0.008, 0.035)</cell><cell>32-17-1</cell><cell>0.167 (350), 0.146 (320)</cell></row><row><cell>D-newH-AvgP</cell><cell>0.004</cell><cell>(-0.016, 0.022)</cell><cell>25-17-1</cell><cell></cell></row></table><note coords="4,383.05,680.04,119.00,10.46"><p><p>-0.213 (644), -0.128</p>(614)    </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,110.86,80.42,390.28,103.26"><head>Table 4 :</head><label>4</label><figDesc>Impact of Blind Feedback on Percentage of Topics With a Relevant in Top 10</figDesc><table coords="5,110.86,95.10,390.28,88.57"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>D-newH-Rel10</cell><cell>0.023</cell><cell>(-0.070, 0.117)</cell><cell>3-2-38</cell><cell>1.000 (601), 1.000 (633)</cell></row><row><cell>(T-newH-Rel10)</cell><cell>0.000</cell><cell>(-0.094, 0.094)</cell><cell>2-2-39</cell><cell>1.000 (636), 1.000 (628)</cell></row><row><cell>D-old-Rel10</cell><cell>-0.020</cell><cell>(-0.081, 0.041)</cell><cell>1-2-47</cell><cell>1.000 (356), -1.000 (426)</cell></row><row><cell>(T-old-Rel10)</cell><cell>-0.040</cell><cell>(-0.141, 0.061)</cell><cell>2-4-44</cell><cell>1.000 (356), 1.000 (439)</cell></row><row><cell>(T-new-Rel10)</cell><cell>-0.040</cell><cell>(-0.121, 0.041)</cell><cell>1-3-46</cell><cell>1.000 (627), -1.000 (632)</cell></row><row><cell>D-new-Rel10</cell><cell>-0.060</cell><cell>(-0.141, 0.001)</cell><cell>0-3-47</cell><cell>-1.000 (632), -1.000 (610)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,145.45,80.42,317.79,127.16"><head>Table 5 :</head><label>5</label><figDesc>Examples of URL type and depth values</figDesc><table coords="6,145.45,95.10,317.79,112.48"><row><cell>URL</cell><cell>Type</cell><cell cols="2">Depth Depth Term</cell></row><row><cell>http://nasa.gov/</cell><cell>ROOT</cell><cell>1</cell><cell>URLDEPTHA</cell></row><row><cell>http://www.nasa.gov/</cell><cell>ROOT</cell><cell>1</cell><cell>URLDEPTHA</cell></row><row><cell>http://jpl.nasa.gov/</cell><cell>ROOT</cell><cell>2</cell><cell>URLDEPTHAB</cell></row><row><cell>http://fred.jpl.nasa.gov/</cell><cell>ROOT</cell><cell>3</cell><cell>URLDEPTHABC</cell></row><row><cell>http://nasa.gov/jpl/</cell><cell>SUBROOT</cell><cell>2</cell><cell>URLDEPTHAB</cell></row><row><cell>http://nasa.gov/jpl/fred/</cell><cell>PATH</cell><cell>3</cell><cell>URLDEPTHABC</cell></row><row><cell>http://nasa.gov/index.html</cell><cell>ROOT</cell><cell>1</cell><cell>URLDEPTHA</cell></row><row><cell>http://nasa.gov/fred.html</cell><cell>FILE</cell><cell>2</cell><cell>URLDEPTHAB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,164.26,242.89,283.50,91.30"><head>Table 6 :</head><label>6</label><figDesc>Number of Pages of each URL Type and Depth</figDesc><table coords="6,164.26,257.59,283.50,76.61"><row><cell>Type</cell><cell>#Pages</cell><cell>Depth</cell><cell>#Pages</cell><cell>Depth</cell><cell>#Pages</cell></row><row><cell>ROOT</cell><cell>6,906</cell><cell>1</cell><cell>635</cell><cell>6</cell><cell>269,949</cell></row><row><cell>SUBROOT</cell><cell>18,179</cell><cell>2</cell><cell>16,792</cell><cell>7</cell><cell>136,513</cell></row><row><cell>PATH</cell><cell>55,332</cell><cell>3</cell><cell>128,898</cell><cell>8</cell><cell>44,960</cell></row><row><cell>FILE</cell><cell>1,167,336</cell><cell>4</cell><cell>282,086</cell><cell>9</cell><cell>15,289</cell></row><row><cell></cell><cell></cell><cell>5</cell><cell>344,694</cell><cell>10+</cell><cell>7,937</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,93.43,80.42,425.15,265.28"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table coords="8,93.43,80.42,425.15,265.28"><row><cell></cell><cell></cell><cell></cell><cell cols="4">Scores of Submitted Navigational Runs</cell><cell></cell></row><row><cell></cell><cell></cell><cell>300</cell><cell>HP</cell><cell>150</cell><cell></cell><cell>NP</cell><cell>150</cell></row><row><cell>Run</cell><cell cols="8">MRR %Top10 %Fail MRR %Top10 %Fail MRR %Top10 %Fail</cell></row><row><cell>humNP03up</cell><cell>0.545</cell><cell>77.3%</cell><cell>12.3% 0.584</cell><cell>82.0%</cell><cell></cell><cell>8.7% 0.506</cell><cell>72.7%</cell><cell>16.0%</cell></row><row><cell>humNP03upl</cell><cell>0.535</cell><cell>77.7%</cell><cell>11.7% 0.591</cell><cell>82.7%</cell><cell></cell><cell>8.0% 0.480</cell><cell>72.7%</cell><cell>15.3%</cell></row><row><cell>humNP03pl</cell><cell>0.465</cell><cell>68.3%</cell><cell>17.3% 0.361</cell><cell>56.7%</cell><cell cols="2">27.3% 0.568</cell><cell>80.0%</cell><cell>7.3%</cell></row><row><cell cols="2">humNP03uhpl 0.386</cell><cell>56.7%</cell><cell>26.0% 0.500</cell><cell>70.7%</cell><cell cols="2">16.7% 0.271</cell><cell>42.7%</cell><cell>35.3%</cell></row><row><cell>humNP03l</cell><cell>0.321</cell><cell>54.3%</cell><cell>25.7% 0.223</cell><cell>41.3%</cell><cell cols="2">40.7% 0.420</cell><cell>67.3%</cell><cell>10.7%</cell></row><row><cell cols="8">Table 8: Impact of Submitted Navigational Techniques on Reciprocal Rank</cell></row><row><cell>Experiment</cell><cell></cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell></cell><cell cols="3">2 Largest Diffs (Topic)</cell></row><row><cell>HP u (upl -pl)</cell><cell></cell><cell>0.229</cell><cell>( 0.168, 0.291)</cell><cell cols="2">87-17-46</cell><cell cols="3">1.000 (321), 1.000 (395)</cell></row><row><cell>HP p (pl -l)</cell><cell></cell><cell>0.139</cell><cell>( 0.093, 0.187)</cell><cell cols="2">72-14-64</cell><cell cols="3">1.000 (422), 1.000 (200)</cell></row><row><cell>HP l (upl -up)</cell><cell></cell><cell>0.007</cell><cell>(-0.011, 0.026)</cell><cell cols="2">14-13-123</cell><cell cols="3">0.667 (271), 0.500 (349)</cell></row><row><cell cols="2">HP h (uhpl -upl)</cell><cell>-0.091</cell><cell>(-0.134,-0.050)</cell><cell cols="2">14-57-79</cell><cell cols="3">-1.000 (355), -0.977 (300)</cell></row><row><cell>NP u (upl -pl)</cell><cell></cell><cell>-0.088</cell><cell>(-0.134,-0.042)</cell><cell cols="2">13-66-71</cell><cell cols="3">-1.000 (359), 0.950 (154)</cell></row><row><cell>NP p (pl -l)</cell><cell></cell><cell>0.147</cell><cell>( 0.092, 0.204)</cell><cell cols="2">74-17-59</cell><cell cols="3">-1.000 (416), 0.975 (151)</cell></row><row><cell>NP l (upl -up)</cell><cell></cell><cell>-0.026</cell><cell>(-0.055, 0.002)</cell><cell cols="2">14-32-104</cell><cell cols="3">0.889 (215), -0.875 (306)</cell></row><row><cell cols="2">NP h (uhpl -upl)</cell><cell>-0.209</cell><cell>(-0.257,-0.162)</cell><cell>1-92-57</cell><cell></cell><cell cols="3">-1.000 (249), -1.000 (154)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,87.30,80.97,437.40,178.53"><head>Table 9 :</head><label>9</label><figDesc>Diagnostics of Extra Weight on Document Structure (Navigational Task, Reciprocal Rank)</figDesc><table coords="9,102.20,96.21,407.61,163.28"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>HP v (vl-l)</cell><cell>0.079</cell><cell>( 0.045, 0.115)</cell><cell>60-19-71</cell><cell>0.933 (425), 0.917 (333)</cell></row><row><cell>HP q (ql-l)</cell><cell>0.056</cell><cell>( 0.027, 0.088)</cell><cell>44-15-91</cell><cell>0.976 (385), 0.909 (307)</cell></row><row><cell>HP qv (vql-l)</cell><cell>0.115</cell><cell>( 0.073, 0.159)</cell><cell>62-19-69</cell><cell>1.000 (334), 1.000 (389)</cell></row><row><cell>HP v (vql-ql)</cell><cell>0.058</cell><cell>( 0.025, 0.095)</cell><cell>44-27-79</cell><cell>0.978 (389), 0.917 (425)</cell></row><row><cell>HP q (vql-vl)</cell><cell>0.036</cell><cell>( 0.009, 0.066)</cell><cell>27-18-105</cell><cell>1.000 (389), 0.800 (322)</cell></row><row><cell>HP other (pl-vql)</cell><cell>0.024</cell><cell>(-0.015, 0.064)</cell><cell>37-29-84</cell><cell>1.000 (266), -0.857 (334)</cell></row><row><cell>NP v (vl-l)</cell><cell>0.120</cell><cell>( 0.073, 0.169)</cell><cell>74-16-60</cell><cell>0.975 (151), 0.969 (286)</cell></row><row><cell>NP q (ql-l)</cell><cell>0.050</cell><cell>( 0.014, 0.089)</cell><cell>41-20-89</cell><cell>-1.000 (416), 0.975 (151)</cell></row><row><cell>NP qv (vql-l)</cell><cell>0.128</cell><cell>( 0.078, 0.180)</cell><cell>71-18-61</cell><cell>-1.000 (416), 0.975 (151)</cell></row><row><cell>NP v (vql-ql)</cell><cell>0.078</cell><cell>( 0.041, 0.117)</cell><cell>55-17-78</cell><cell>0.963 (178), -0.909 (304)</cell></row><row><cell>NP q (vql-vl)</cell><cell>0.008</cell><cell>(-0.017, 0.032)</cell><cell>21-18-111</cell><cell>-0.857 (248), -0.750 (259)</cell></row><row><cell>NP other (pl-vql)</cell><cell>0.019</cell><cell>(-0.013, 0.051)</cell><cell>30-27-93</cell><cell>-0.938 (196), -0.800 (449)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="9,95.06,292.38,421.88,202.44"><head>Table 10 :</head><label>10</label><figDesc>Diagnostics of Extra Weight on URL Structure (Navigational Task, Reciprocal Rank)</figDesc><table coords="9,95.06,307.62,421.88,187.20"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>HP d5 (d5pl-pl)</cell><cell>0.158</cell><cell>( 0.110, 0.207)</cell><cell>73-7-70</cell><cell>1.000 (384), 1.000 (395)</cell></row><row><cell>HP d10 (d10pl-pl)</cell><cell>0.205</cell><cell>( 0.151, 0.261)</cell><cell>85-10-55</cell><cell>1.000 (244), 1.000 (384)</cell></row><row><cell>HP d15 (d15pl-pl)</cell><cell>0.213</cell><cell>( 0.152, 0.275)</cell><cell>84-16-50</cell><cell>1.000 (184), 1.000 (244)</cell></row><row><cell>HP d20 (d20pl-pl)</cell><cell>0.173</cell><cell>( 0.109, 0.238)</cell><cell>79-22-49</cell><cell>1.000 (392), 1.000 (395)</cell></row><row><cell>HP r5 (r5pl-pl)</cell><cell>0.168</cell><cell>( 0.121, 0.217)</cell><cell>76-8-66</cell><cell>0.941 (201), 0.941 (328)</cell></row><row><cell>HP r10 (r10pl-pl)</cell><cell>0.213</cell><cell>( 0.157, 0.269)</cell><cell>81-13-56</cell><cell>1.000 (395), 1.000 (321)</cell></row><row><cell>HP r5d5 (r5d5pl-pl)</cell><cell>0.231</cell><cell>( 0.176, 0.288)</cell><cell>87-11-52</cell><cell>1.000 (184), 1.000 (321)</cell></row><row><cell>NP d5 (d5pl-pl)</cell><cell>-0.001</cell><cell>(-0.024, 0.024)</cell><cell>23-29-98</cell><cell>0.950 (154), 0.750 (264)</cell></row><row><cell>NP d10 (d10pl-pl)</cell><cell>-0.027</cell><cell>(-0.062, 0.008)</cell><cell>20-45-85</cell><cell>-0.952 (359), 0.950 (154)</cell></row><row><cell>NP d15 (d15pl-pl)</cell><cell>-0.084</cell><cell>(-0.127,-0.043)</cell><cell>16-61-73</cell><cell>-1.000 (359), -0.875 (189)</cell></row><row><cell>NP d20 (d20pl-pl)</cell><cell>-0.166</cell><cell>(-0.215,-0.119)</cell><cell>10-79-61</cell><cell>-1.000 (359), -1.000 (249)</cell></row><row><cell>NP r5 (r5pl-pl)</cell><cell>-0.013</cell><cell>(-0.039, 0.013)</cell><cell>11-34-105</cell><cell>0.833 (383), 0.750 (264)</cell></row><row><cell>NP r10 (r10pl-pl)</cell><cell>-0.069</cell><cell>(-0.109,-0.030)</cell><cell>10-61-79</cell><cell>-0.941 (359), -0.900 (216)</cell></row><row><cell>NP r5d5 (r5d5pl-pl)</cell><cell>-0.040</cell><cell>(-0.075,-0.005)</cell><cell>19-48-83</cell><cell>0.950 (154), -0.929 (359)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="10,104.08,80.42,403.86,91.30"><head>Table 11 :</head><label>11</label><figDesc>Scores of Submitted Topic Distillation Runs</figDesc><table coords="10,104.08,95.10,403.86,76.62"><row><cell>Run</cell><cell>AvgP</cell><cell>P@5</cell><cell>P@10</cell><cell>P@20</cell><cell>Rec0</cell><cell>Rec30</cell><cell>P@R</cell><cell>Topics</cell></row><row><cell>humTD03upl</cell><cell>0.139</cell><cell>14.4%</cell><cell>12.8%</cell><cell>9.2%</cell><cell>0.382</cell><cell>0.166</cell><cell>14.9%</cell><cell>50</cell></row><row><cell>humTD03up</cell><cell>0.120</cell><cell>14.8%</cell><cell>12.4%</cell><cell>8.9%</cell><cell>0.362</cell><cell>0.147</cell><cell>13.3%</cell><cell>50</cell></row><row><cell>humTD03uhpl</cell><cell>0.098</cell><cell>13.2%</cell><cell>10.2%</cell><cell>6.9%</cell><cell>0.357</cell><cell>0.105</cell><cell>10.7%</cell><cell>50</cell></row><row><cell>humTD03pl</cell><cell>0.100</cell><cell>6.8%</cell><cell>5.6%</cell><cell>5.2%</cell><cell>0.247</cell><cell>0.118</cell><cell>9.0%</cell><cell>50</cell></row><row><cell>humTD03l</cell><cell>0.051</cell><cell>4.8%</cell><cell>4.4%</cell><cell>3.1%</cell><cell>0.152</cell><cell>0.077</cell><cell>3.6%</cell><cell>50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="10,122.68,203.91,366.63,79.35"><head>Table 12 :</head><label>12</label><figDesc>Impact of Topic Distillation Techniques on Precision@10</figDesc><table coords="10,122.68,218.61,366.63,64.66"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>u (upl -pl)</cell><cell>0.072</cell><cell>( 0.035, 0.113)</cell><cell>25-5-20</cell><cell>0.600 (7), 0.400 (32)</cell></row><row><cell>p (pl -l)</cell><cell>0.012</cell><cell>(-0.009, 0.035)</cell><cell>8-6-36</cell><cell>0.300 (48), 0.200 (15)</cell></row><row><cell>l (upl -up)</cell><cell>0.004</cell><cell>(-0.019, 0.027)</cell><cell>7-4-39</cell><cell>0.300 (43), -0.300 (31)</cell></row><row><cell>h (uhpl -upl)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="10,118.81,621.50,374.37,79.35"><head>Table 13 :</head><label>13</label><figDesc>Impact of Topic Distillation Techniques on Average Precision</figDesc><table coords="10,118.81,636.19,374.37,64.66"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>p (pl -l)</cell><cell>0.049</cell><cell>( 0.002, 0.111)</cell><cell>39-9-2</cell><cell>0.956 (24), 0.944 (17)</cell></row><row><cell>u (upl -pl)</cell><cell>0.038</cell><cell>( 0.009, 0.069)</cell><cell>35-12-3</cell><cell>0.343 (49), 0.337 (18)</cell></row><row><cell>l (upl -up)</cell><cell>0.019</cell><cell>(-0.011, 0.066)</cell><cell>16-22-12</cell><cell>1.000 (17), -0.152 (15)</cell></row><row><cell>h (uhpl -upl)</cell><cell>-0.041</cell><cell>(-0.079,-0.012)</cell><cell>13-35-2</cell><cell>-0.750 (17), -0.187 (7)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="11,118.81,80.42,374.37,79.34"><head>Table 14 :</head><label>14</label><figDesc>Impact of Topic Distillation Techniques on R-Precision</figDesc><table coords="11,118.81,95.10,374.37,64.66"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>u (upl -pl)</cell><cell>0.059</cell><cell>( 0.021, 0.100)</cell><cell>20-3-27</cell><cell>0.667 (49), 0.462 (7)</cell></row><row><cell>p (pl -l)</cell><cell>0.054</cell><cell>( 0.004, 0.119)</cell><cell>11-3-36</cell><cell>1.000 (24), 1.000 (17)</cell></row><row><cell>l (upl -up)</cell><cell>0.016</cell><cell>(-0.018, 0.065)</cell><cell>6-3-41</cell><cell>1.000 (17), -0.250 (15)</cell></row><row><cell>h (uhpl -upl)</cell><cell>-0.042</cell><cell>(-0.095,-0.001)</cell><cell>7-15-28</cell><cell>-1.000 (17), -0.333 (49)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="12,82.46,80.42,423.12,169.87"><head>Table 15 :</head><label>15</label><figDesc>Precision of Genomics Runs</figDesc><table coords="12,82.46,93.17,423.12,157.11"><row><cell>Run</cell><cell>AvgP</cell><cell>P@5</cell><cell>P@10</cell><cell>P@20</cell><cell>Rec0</cell><cell>Rec30</cell><cell>P@R</cell><cell>Topics</cell></row><row><cell>humG03ns</cell><cell>0.175</cell><cell>16.4%</cell><cell>14.8%</cell><cell>11.7%</cell><cell>0.394</cell><cell>0.239</cell><cell>15.3%</cell><cell>50</cell></row><row><cell>humG03ns5</cell><cell>0.185</cell><cell>18.0%</cell><cell>15.8%</cell><cell>12.3%</cell><cell>0.399</cell><cell>0.257</cell><cell>16.7%</cell><cell>50</cell></row><row><cell>base (diag.)</cell><cell>0.312</cell><cell>27.2%</cell><cell>23.6%</cell><cell>18.0%</cell><cell>0.599</cell><cell>0.420</cell><cell>28.9%</cell><cell>50</cell></row><row><cell>+5x phrases</cell><cell>0.356</cell><cell>33.2%</cell><cell>24.8%</cell><cell>20.0%</cell><cell>0.613</cell><cell>0.463</cell><cell>31.6%</cell><cell>50</cell></row><row><cell cols="4">SELECT RELEVANCE('V2:3') AS REL, DOCNO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>FROM med03n</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">WHERE FT_TEXT IS_ABOUT 'activating transcription factor 2 ()</cell><cell></cell><cell></cell></row><row><cell cols="5">ATF2 () HB16 () CREB2 () TREB7 () CRE-BP1'</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ORDER BY REL DESC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="13,106.46,80.42,399.09,240.73"><head>Table 16 :</head><label>16</label><figDesc>Impact of Genomics Techniques on Average Precision</figDesc><table coords="13,106.46,95.10,399.09,226.05"><row><cell>Experiment</cell><cell>AvgDiff</cell><cell>95% Confidence</cell><cell>vs.</cell><cell>2 Largest Diffs (Topic)</cell></row><row><cell>+5x phrases</cell><cell>0.044</cell><cell>( 0.015, 0.076)</cell><cell>28-18-4</cell><cell>0.441 (24), 0.266 (23)</cell></row><row><cell>+2x phrases</cell><cell>0.043</cell><cell>( 0.016, 0.073)</cell><cell>29-17-4</cell><cell>0.441 (24), 0.316 (23)</cell></row><row><cell>+1x phrases</cell><cell>0.037</cell><cell>( 0.011, 0.066)</cell><cell>32-14-4</cell><cell>0.441 (24), 0.314 (23)</cell></row><row><cell>2x sym</cell><cell>0.027</cell><cell>( 0.007, 0.052)</cell><cell>28-19-3</cell><cell>0.441 (24), 0.205 (4)</cell></row><row><cell>idf squared (V2:4)</cell><cell>0.020</cell><cell>(-0.006, 0.048)</cell><cell>24-23-3</cell><cell>0.441 (24), -0.231 (18)</cell></row><row><cell>5x sym</cell><cell>0.019</cell><cell>(-0.010, 0.051)</cell><cell>22-23-5</cell><cell>0.441 (24), 0.280 (15)</cell></row><row><cell>phrases only</cell><cell>0.002</cell><cell>(-0.058, 0.058)</cell><cell>28-19-3</cell><cell>-0.733 (7), -0.631 (20)</cell></row><row><cell>DLEN 500</cell><cell>-0.006</cell><cell>(-0.014, 0.001)</cell><cell>17-29-4</cell><cell>-0.119 (16), -0.074 (18)</cell></row><row><cell>stemming on</cell><cell>-0.012</cell><cell>(-0.036, 0.005)</cell><cell>11-27-12</cell><cell>-0.463 (27), -0.167 (16)</cell></row><row><cell>omit names</cell><cell>-0.030</cell><cell>(-0.079, 0.016)</cell><cell>16-32-2</cell><cell>-0.733 (7), 0.441 (24)</cell></row><row><cell>number parsing</cell><cell>-0.038</cell><cell>(-0.071,-0.004)</cell><cell>16-30-4</cell><cell>0.334 (11), -0.331 (9)</cell></row><row><cell>all fields</cell><cell>-0.055</cell><cell>(-0.083,-0.031)</cell><cell>9-35-6</cell><cell>-0.382 (31), -0.312 (36)</cell></row><row><cell>vector species</cell><cell>-0.069</cell><cell>(-0.102,-0.034)</cell><cell>7-41-2</cell><cell>-0.333 (27), -0.329 (28)</cell></row><row><cell>omit symbols</cell><cell>-0.113</cell><cell>(-0.152,-0.075)</cell><cell>8-40-2</cell><cell>-0.489 (31), -0.429 (19)</cell></row><row><cell>terms count (2:2)</cell><cell>-0.136</cell><cell>(-0.182,-0.094)</cell><cell>5-44-1</cell><cell>-0.717 (27), -0.507 (29)</cell></row><row><cell>omit species</cell><cell>-0.137</cell><cell>(-0.177,-0.099)</cell><cell>2-46-2</cell><cell>-0.489 (20), -0.489 (27)</cell></row><row><cell>hits count (2:1)</cell><cell>-0.199</cell><cell>(-0.246,-0.154)</cell><cell>3-47-0</cell><cell>-0.619 (27), -0.543 (47)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.24,665.89,452.76,9.49;1,72.00,676.48,468.13,8.37"><p>Fulcrum r is a registered trademark, and SearchServer TM , SearchSQL TM , Intuitive Searching TM and Ful/Text TM are trademarks of Hummingbird Ltd. All other copyrights, trademarks and tradenames are the property of their respective owners.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,87.24,691.16,452.87,8.37;5,72.00,700.62,221.01,8.37"><p>See<ref type="bibr" coords="5,102.85,691.16,13.18,8.37" target="#b10">[11]</ref> for some comparisons of confidence intervals from the bootstrap percentile, Wilcoxon signed rank and standard error methods for both average precision and Precision@10.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="14,87.50,193.20,332.21,10.46" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><surname>Cross-Language</surname></persName>
		</author>
		<ptr target="http://www.clef-campaign.org/" />
		<title level="m" coord="14,159.72,193.20,116.36,10.46">Evaluation Forum web site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,87.50,211.22,452.52,10.46;14,82.51,223.18,457.49,10.46;14,82.51,235.13,38.80,10.46" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="14,246.16,211.22,173.55,10.46">Finding Gene Function using LitMiner</title>
		<author>
			<persName coords=""><forename type="first">Berry</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruijn</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joel</forename><surname>Martin</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>Institute for Information Technology, National Research Council of Canada</orgName>
		</respStmt>
	</monogr>
	<note>Notebook paper in draft TREC 2003 Conference Proceedings</note>
</biblStruct>

<biblStruct coords="14,87.50,253.16,452.52,10.46" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="14,263.17,253.16,142.17,10.46">An Introduction to the Bootstrap</title>
		<author>
			<persName coords=""><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,87.50,271.19,360.87,10.46" xml:id="b3">
	<monogr>
		<ptr target="http://www.ted.cmis.csiro.au/TRECWeb/govinfo.html" />
		<title level="m" coord="14,87.50,271.19,113.50,10.46">The .GOV Test Collection</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,87.50,289.21,452.51,10.46;14,82.51,301.17,243.48,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,167.44,289.21,214.97,10.46">Converting the Fulcrum Search Engine to Unicode</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Hodgson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,401.72,289.21,138.29,10.46;14,82.51,301.17,46.07,10.46">Sixteenth International Unicode Conference</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-03">March 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,87.50,319.19,452.51,10.46;14,82.51,331.15,403.72,10.46" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="14,195.45,319.19,344.56,10.46;14,82.51,331.15,125.07,10.46">Methods for accurate retieval of MEDLINE citations in functional genomics. National Library of Medicine</title>
		<author>
			<persName coords=""><forename type="first">Mehmet</forename><surname>Kayaalp</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Notebook paper in draft TREC 2003 Conference Proceedings</note>
</biblStruct>

<biblStruct coords="14,87.50,349.18,32.79,10.46;14,143.76,349.18,58.68,10.46;14,225.91,349.18,18.60,10.46;14,267.99,349.18,43.73,10.46;14,335.22,349.18,11.93,10.46;14,370.64,349.18,10.93,10.46;14,405.04,349.18,39.13,10.46;14,467.66,349.18,25.18,10.46;14,516.34,349.18,23.67,10.46;14,82.51,361.13,213.77,10.46" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="14,149.10,349.18,53.35,10.46;14,225.91,349.18,18.60,10.46;14,267.99,349.18,43.73,10.46;14,335.22,349.18,11.93,10.46;14,370.64,349.18,10.93,10.46;14,405.04,349.18,39.13,10.46;14,467.66,349.18,25.18,10.46;14,516.34,349.18,18.94,10.46">NII-NACSIS Test Collection for IR Systems) Home Page</title>
		<author>
			<persName coords=""><surname>Ntcir</surname></persName>
		</author>
		<ptr target="http://research.nii.ac.jp/∼ntcadm/index-en.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,87.50,379.16,452.51,10.46;14,82.51,391.11,457.49,10.46;14,82.51,403.07,354.34,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,501.88,379.16,38.13,10.46;14,82.51,391.11,33.92,10.46">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec3/t3proceedings.html" />
	</analytic>
	<monogr>
		<title level="m" coord="14,240.18,391.11,266.79,10.46">Overview of the Third Text REtrieval Conference (TREC-3)</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="500" to="226" />
		</imprint>
		<respStmt>
			<orgName>City University.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,87.50,421.09,303.87,10.46" xml:id="b8">
	<monogr>
		<ptr target="http://trec.nist.gov/" />
		<title level="m" coord="14,87.50,421.09,206.35,10.46">Text REtrieval Conference (TREC) Home Page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.47,439.12,447.53,10.46;14,82.51,451.08,457.49,10.46;14,82.51,463.03,381.46,10.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,273.93,439.12,219.44,10.46">Hummingbird&apos;s Fulcrum SearchServer at TREC-9</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Blackwell</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec9/t9proceedings.html" />
	</analytic>
	<monogr>
		<title level="m" coord="14,253.28,451.08,281.47,10.46">Proceedings of the Ninth Text REtrieval Conference (TREC-9)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Ninth Text REtrieval Conference (TREC-9)</meeting>
		<imprint>
			<biblScope unit="page" from="500" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.47,481.06,434.20,10.46;14,526.65,479.99,12.85,7.32;14,82.51,493.01,457.50,10.46;14,82.51,504.97,239.22,10.46" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,188.64,481.06,338.03,10.46;14,526.65,479.99,12.85,7.32;14,82.51,493.01,72.91,10.46">Experiments in 8 European Languages with Hummingbird SearchServer TM at CLEF 2002</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<ptr target="http://clef.iei.pi.cnr.it:2002/workshop2002/WN/26.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="14,302.17,493.01,232.70,10.46">Working Notes for the CLEF 2002 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.47,523.00,447.54,10.46;14,82.51,534.95,79.71,10.46;14,162.22,533.87,12.85,7.32;14,181.83,534.95,358.17,10.46;14,82.51,546.91,457.50,10.46;14,82.51,558.86,237.69,10.46" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,187.37,523.00,352.64,10.46;14,82.51,534.95,79.71,10.46;14,162.22,533.87,12.85,7.32;14,181.83,534.95,68.02,10.46">Experiments in Named Page Finding and Arabic Retrieval with Hummingbird SearchServer TM at TREC 2002</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec11/t11proceedings.html" />
	</analytic>
	<monogr>
		<title level="m" coord="14,501.92,534.95,38.08,10.46;14,82.51,546.91,222.30,10.46">Proceedings of the Eleventh Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lori</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>the Eleventh Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page">251</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.47,576.89,205.93,10.46;14,298.39,575.82,12.85,7.32;14,314.01,576.89,225.99,10.46;14,82.51,588.84,457.49,10.46;14,82.51,600.80,258.72,10.46" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,179.79,576.89,118.61,10.46;14,298.39,575.82,12.85,7.32;14,314.01,576.89,39.61,10.46">Hummingbird SearchServer TM at TREC</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec10/t10proceedings.html" />
	</analytic>
	<monogr>
		<title level="m" coord="14,117.51,588.84,224.74,10.46;14,409.23,588.84,130.77,10.46;14,82.51,600.80,13.28,10.46">Proceedings of the Tenth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Tenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication 500-250</note>
</biblStruct>

<biblStruct coords="14,92.47,618.83,447.54,10.46;14,82.51,630.78,119.53,10.46;14,202.04,629.70,12.85,7.32;14,218.57,630.78,321.43,10.46;14,82.51,642.73,245.57,10.46" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,185.03,618.83,354.98,10.46;14,82.51,630.78,119.53,10.46;14,202.04,629.70,12.85,7.32;14,218.57,630.78,60.07,10.46">Lexical and Algorithmic Stemming Compared for 9 European Languages with Hummingbird SearchServer TM at CLEF 2003</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<ptr target="http://clef.iei.pi.cnr.it/2003/WNweb/19.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="14,390.19,630.78,149.81,10.46;14,82.51,642.73,41.16,10.46">Working Notes for the CLEF 2003 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.47,660.76,447.53,10.46;14,82.51,672.71,457.49,10.46;14,82.51,684.68,457.49,10.46;14,82.51,696.63,237.69,10.46" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,372.05,660.76,167.95,10.46;14,82.51,672.71,159.93,10.46">Retrieving Web Pages using Content, Links, URLs and Anchors</title>
		<author>
			<persName coords=""><forename type="first">Thijs</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec10/t10proceedings.html" />
	</analytic>
	<monogr>
		<title level="m" coord="14,501.92,672.71,38.08,10.46;14,82.51,684.68,216.00,10.46;14,378.51,684.68,157.00,10.46">Proceedings of the Tenth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Tenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication 500-250</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
