<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.64,107.37,288.53,15.54">TREC12 Web and Interactive Tracks at CSIRO</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.60,141.25,56.66,11.03"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
							<email>nick.craswell@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.49,141.25,63.10,11.03"><forename type="first">David</forename><surname>Hawking</surname></persName>
							<email>david.hawking@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.93,141.25,60.22,11.03"><forename type="first">Trystan</forename><surname>Upstill</surname></persName>
							<email>trystan.upstill@cs.anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">CSIT Building</orgName>
								<orgName type="institution" key="instit2">ANU Canberra</orgName>
								<address>
									<postCode>ACT 0200</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,198.00,183.97,65.13,11.03"><forename type="first">Alistair</forename><surname>Mclean</surname></persName>
							<email>alistair.mclean@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.41,183.97,61.19,11.03"><forename type="first">Ross</forename><surname>Wilkinson</surname></persName>
							<email>ross.wilkinson@csiro.au</email>
							<affiliation key="aff0">
								<orgName type="department">CSIRO ICT Centre</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.03,183.97,54.65,11.03"><forename type="first">Mingfang</forename><surname>Wu</surname></persName>
							<email>mingfang.wu@csiro.au</email>
						</author>
						<title level="a" type="main" coord="1,161.64,107.37,288.53,15.54">TREC12 Web and Interactive Tracks at CSIRO</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D321D53CB0F8B0FD82296FA211F7FED8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This year, CSIRO teams participated in all three tasks of the web track; these being: the automatic topic distillation task, the home/named page finding task and the interactive topic distillation task. This paper describes our approaches, experiments and results. The following section describes our experiments in the two automatic tasks, and Section 3 describes our experiment in the interactive task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The web track</head><p>CSIRO submitted a total of 10 runs to the non-interactive portion of the 2003 Web Track -5 runs for home/named page finding and 5 runs for Topic Distillation. The runs are labeled csiro03 <ref type="bibr" coords="1,454.09,411.37,29.18,11.03">[TYPE]</ref>[RUNID], where TYPE is ``ki'' for known item runs and ``td'' for topic distillation runs. This year we focused on tuning Okapi BM25 and Web evidence parameters. Our home/named page finding submissions use tunings computed for both home and named page finding, and evaluate two run combination methods. Our topic distillation submissions are tuned for home page finding only and test whether the Web evidence evaluated is useful, and whether the use of stemming improves performance.</p><p>We did not incorporate PageRank or simple indegree this year because of previously observed poor performance for named page finding and homepage finding. Instead our query-independent Web evidence included URL length and two important sub-types of indegree (off-site and on-site).</p><p>Throughout our experiments we tuned Okapi BM25 (through the k 1 and b parameters), anchor-text weighting and other query independent Web evidence. The parameters were tuned using a hill climbing algorithm, with complete exploration of 2 parameters at a time, on a grid computer consisting of cluster of 20 dual processor Intel Xeon machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Home/named page finding</head><p>We submitted runs based on three tunings (for a home page task, a named page task and both at the same time), and evaluated two combination methods. We trained using last year's .GOV named page finding query/result set, and using a home page finding training set derived from a first .GOV resource listing.</p><p>We submitted runs tuned for both home page and named page finding at the same time (csiro03ki01), tuned for named page finding only (csiro03ki02) and tuned for home page finding only (csiro03ki03). We also submitted two combinations of these runs. The first was an interleaved run (csiro03ki04 --interleaving csiro03ki02 and csiro03ki03), and the second a run that summed scores achieved in both rankings (csiro03ki05). A summary of our home/named page finding submissions, and their retrieval effectiveness is presented in Table <ref type="table" coords="1,166.44,714.24,3.75,11.03" target="#tab_0">1</ref>. Our results show that tuning specifically for the home page finding task significantly harmed our named page retrieval effectiveness (csiro03ki02 vs. csiro03ki03). Our highest ARR was achieved using the NPonly tuning, whilst the best S@10 used interleaved lists from HP and NP tunings. The results report that an overemphasis on home page finding evidence can hinder named page searches.</p><p>The run with the highest S@10 (csiro03ki04) interleaved the csiro03ki02 and csiro03ki03 runs (i.e. top HP, top NP, second HP, second NP etc.). To improve early precision, if we encountered a keyword that strongly indicated a named page query<ref type="foot" coords="2,211.80,387.47,3.24,7.17" target="#foot_0">1</ref> was occurring we led with the top NP, rather then the top HP result. From further post-hoc evaluations (see csiro03kins) we determined that leading with NP rather than HP would have further improved precision (achieving an ARR improvement of 0.717). In summary, interleaving HP then NP without query classification achieves an ARR of 0.646. Interleaving HP then NP with swapping if query appears to be a named page query achieves an ARR of 0.667. Finally, interleaving NP then HP without query classification achieves 0.717.</p><p>We could not find a single tuning that is equally useful for each type of query. This raises interesting query classification, or further combination of evidence questions. A superior classifier may well have taken into account other evidence, such as query length, while a better combination may have taken into account the strength of the home page evidence (and only led with a homepage result if it was sufficiently strong).</p><p>There are some limitations inherent in the training sets we used for tuning. The set of home pages was taken from a .GOV portal, which may inadvertently have favored prestigious, or larger and more popular home pages. Further, last year some of the named pages were in fact home pages, whereas this year there was a distinction made between named pages and home pages. Our named page tuning was therefore based on a mixed query set with a smaller ratio of home pages. This may have slightly biased our training towards home page queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Topic Distillation</head><p>Our Topic Distillation runs were based on the home page tunings built for the home/named page task. The run results are presented in Table <ref type="table" coords="2,225.38,633.85,3.75,11.03" target="#tab_1">2</ref>. Our best run (csiro03td03) used the home page tuning and incorporated stemming. When removing hyperlink evidence (i.e. csiro03td02 and csiro03td04) we observed a decrease in retrieval performance. Likewise, we observed a 2% decrease in performance when using standard tunings for Okapi BM25 (csiro03td01 vs. csiro03td05). Post-hoc we computed a new run based on the named page finding tunings used in our home/named page finding submission (csiro03tdns), this tuning reduced the Avg R-Prec to 0.1166.</p><p>The results from the topic distillation task appear to support the notion that our home page training set favored prominent resources (an advantage for Topic Distillation). Further, our results illustrate the usefulness of web evidence, and stemming, when addressing Topic Distillation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Interactive Sub-track</head><p>In this year's interactive sub-track, searchers were asked to construct a resource list that covers all major aspects of a broad topic through interaction with an information access system. Similar to that in automatic topic distillation task [1], a key resource page is defined as a main page of a website which is:</p><p>1. principally devoted to the topic, 2. providing credible information on the topic, and 3. not part of a larger site also devoted to the same topic.</p><p>Take the topic "adoption procedures" and the website &lt;http://www.courtinfo.ca.gov/&gt; as an example, the main page that meets the above requirements is &lt;http://www.courtinfo.ca.gov/shelfhelp/family/adlption/&gt;, all the pages referring to this page or referred to by this page would fail one of the above conditions.</p><p>To assess whether a web page is a key resource page, a searcher needs to make the following judgments about the page:</p><p>1) Is it relevant?</p><p>2) Does it have the right scope? (Is it too broad or too narrow compared with that of other relevant pages from the same site?)</p><p>In the interactive track, searchers were also asked to make one more judgment:</p><p>3) Does it cover a different aspect from the previous saved web pages?</p><p>The traditional ranked list provides users with a set of entry points to their corresponding websites, then users have to browse each website to decide whether the entry point is the main page, or if not, whether there is a page within the site could be the main page. The above three tasks (especially the task 2 and 3) are not explicitly supported by this kind of delivery interface.</p><p>We aimed to investigate the effectiveness of a task tailored delivery method to assist searchers in making the above three judgment tasks. Our hypothesis was that searchers would have a better performance on the assigned tasks by using the interface designed to support the above judgment tasks than a generic interface (such as a ranked list).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Delivery interfaces</head><p>The Panoptic topic distillation engine was used as the back-end search engine for both interfaces. To concentrate on the comparison of the two delivery interfaces, we decided to fix the query for all topics and for all searchers, i.e. searchers were restricted to explore the same set of retrieved documents. The queries were optimized to return shallow pages from a web site and to make sure the precision at top ten returned documents was acceptable.</p><p>The baseline interface (referred to as TDLinear for Topic Distillation with Linear interface), was the delivery interface from the Panoptic topic distillation engine. As shown in Figure <ref type="figure" coords="4,421.17,232.20,3.76,11.03">1</ref>, this interface provided searchers with a ranked list of top 100 potential relevant key resource pages in five consecutive pages, with each page showing the titles and summaries of 20 documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 . The delivery interface for the ranked list</head><p>To validate our hypothesis, we designed the experimental interface (referred to as TDHierarchic for Topic Distillation with Hierarchical delivery interface) that explicitly supports searchers' assessment tasks. The experimental interface consists of two parts: the site summary and the sitemap.</p><p>1. The site summary (Figure <ref type="figure" coords="5,207.83,72.13,3.71,11.03" target="#fig_0">2</ref>): The top 100 retrieved pages (from Panoptic topic distillation engine) were firstly grouped according to their corresponding departments (organizational structure), and then further sub-divided into their secondary business units (websites). Each of the websites was summarized and represented by using the titles of the top three most relevant pages. The summary not only described the content of the site, but also provided three candidate entry points to the site. We decided not to show the summary of a document directly for two reasons: the summary of the document may not be suitable for the topic distillation task and showing the summary of a document would make the interface cluttered. Instead, we placed a "Summary" icon next to each title. If a searcher wanted to read the summary of a document, he/she could hover the mouse over the "Summary" icon, a pop-up window would appear next to the icon to show the summary. The content of this summary is the same as that for the same document in TDLinear interface.</p><p>We expected that the grouping mechanism in this interface would help searchers select a relevant website and a web page from the website as a starting point to browse from, and also support searchers with the third judgment task -the websites of different departments (or different sectors of the same department) would provide different perspectives on the searched topic.</p><p>2. The sitemap (Figure <ref type="figure" coords="5,190.17,256.44,3.71,11.03">3</ref>): After a searcher entered a web site, a hierarchical sitemap was provided to support the second judgment. The same query was used to retrieve the top 100 documents from just that site. The sitemap provided an outline view of the distribution of these retrieved pages according to the directory structure of the website. By using this sitemap, the searcher would be able to see the distribution of retrieved pages above or under the current directory, and to have an overview of the location of current page in the whole site. Therefore, our hypothesis could be rephrased more specifically as that a searcher may perform the topic distillation task better with TDHierarchic interface than with TDLinear interface. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Experimental procedure</head><p>We adopted the same experimental design as used by all participating groups in the interactive track. In this experimental design, subjects searching four topics on each interface, the sequence of interface and topics varied among subjects. A complete design requires a group of 16 subjects.</p><p>During the experiment, all subjects were asked to follow the following procedure:</p><p>• Subjects filled in the pre-search questionnaire about their demographic information and their search experience.</p><p>• We explained the search task to the subjects and gave subjects an example as recommended by the track guidelines.</p><p>• After acknowledged their understanding of the search task, subjects were then presented with the two experimental interfaces, and were free to ask any question.</p><p>• Subjects were randomly given a search number. The sequence of each topic and its associated interface for each search number was pre-programmed according to the experimental design. Subjects had 15 minutes for each topic, and were prompted to move to the next topic when their times run out. .</p><p>• Prior to each interface, subjects had a chance of hands-on practice with an example topic. This helps them to get familiar with the interface.</p><p>• Prior to the search of each topic, subjects were required to fill in a pre-search questionnaire about their familiarity with the topic. After the search of the topic, subjects were also required to fill in a postsearch questionnaire about their experience of that particular search topic.</p><p>• Subjects filled in a post-system questionnaire after each interface (with four search topics).</p><p>• Subjects filled in an exit questionnaire at the end of the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Subjects</head><p>Sixteen students were recruited from local universities. They are all from computer science background. Among them, one is a PhD student; four of them are undergraduate students; and the rest eleven are all Master students. They have an average age of 23.8. On average, they have 4.4 years of online searching experience, they regarded themselves as experienced searcher (Mean=5.44, Std=0.73); fifteen of them search the web daily. Comparatively, they have more experience with web search engines (Mean=6.19, Std=0.66) than the web site directory (Mean=5.56, Std=1.71).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4.">Measurements</head><p>The saved lists from each search session (per topic, per interface) were gathered and sent to NIST for assessment. The assessment was based on four criteria: relevance, depth, coverage, and repetition. The assessors were asked to answer each of the following questions/statements on a five-point Likert scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance:</head><p>The page is relevant for the topic. From the questions, we can see that the relevance and the depth judgment are document based, while the coverage and repetition are list based.</p><p>Transaction logging, questionnaire, and screen recording are the main methods used to collect data. During each search session, every significant event -such as reading a document and saving the URL -was automatically captured. Questionnaires common to all participating groups in the interactive track were adapted to our testing hypothesis. Screen recording was used to capture the search process for further detailed analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Performance with two interfaces</head><p>Tables 3 to 6 show each objective measure over all search sessions for each interface, averaged over topics and subjects. Overall, there is no significant difference between two interfaces (TDLinear vs TDHierarchic) by any measure, although there are topic variations.</p><p>As we discussed earlier, one motivation for this year's interactive track was to compare the results from the interactive topic distillation with that from automatic topic distillation. Thus, for each topic, we take a list of top N documents generated by Panoptic topic distillation engine, where N is the number nearest to the average size of all saved lists for that topic. For each of these lists, we can measure its relevance and depth, given that assessors had provided with corresponding assessments for each document. In the rare occasions when one of the top N documents was not picked up by any searcher as relevant, we would then assign it to the "highly irrelevant" category. For the lists automatically generated by Panoptic, their relevance and depth are shown in Tables <ref type="table" coords="7,204.36,598.68,4.98,11.03" target="#tab_2">3</ref> and<ref type="table" coords="7,231.71,598.68,4.98,11.03" target="#tab_3">4</ref> denoted as TDAuto (for Topic Distillation from Automatic system).</p><p>From Table <ref type="table" coords="7,144.00,610.08,4.98,11.03" target="#tab_2">3</ref> and Table <ref type="table" coords="7,200.70,610.08,3.75,11.03" target="#tab_3">4</ref>, we can find that, in six out of eight topics, the lists saved by searchers (TDLinear) are more relevant and closer to the right level than the lists from the automatic approach (TDAuto). Overall, these differences are significant (p &lt; 0.0003<ref type="foot" coords="7,357.84,631.67,3.24,7.17" target="#foot_1">2</ref> and p &lt; 0.0001 for the relevance and depth respectively). The difference between TDHiearchic and TDAuto is not found significant in terms of relevance, but significant (p &lt; 0.005) in terms of depth.</p><p>In the automatic topic distillation track, systems are judged according to the number of good answers they found in the top ten results. Here the "good" answers are those of high relevance and right depth. To compare the interactive system with the automatic tool using an equivalent measure, we also use the relevance and depth as the indicator of a "good" answer: if the relevance score of a saved page is 1 or 2, and the depth score of the page is between 2 and 4 inclusively, we would assume the page is a good answer. By applying this rule, the Tables <ref type="table" coords="8,233.37,129.60,4.98,11.03" target="#tab_2">3</ref> and<ref type="table" coords="8,261.38,129.60,4.98,11.03" target="#tab_3">4</ref> can be converted into the Table <ref type="table" coords="8,409.68,129.60,4.98,11.03" target="#tab_6">7</ref> <ref type="foot" coords="8,414.72,128.15,3.24,7.17" target="#foot_2">3</ref> . The difference between TDAuto and TDLinear is significant at 0.02 (paired t-test). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,223.56,688.81,164.90,11.03;5,125.88,375.72,360.12,304.56"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2 . The site summary interface</figDesc><graphic coords="5,125.88,375.72,360.12,304.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,126.00,206.64,382.05,11.03;7,126.00,224.16,334.00,11.03;7,126.00,241.68,311.93,11.03;7,126.00,259.20,335.66,11.03;7,126.00,276.60,382.05,11.03;7,126.00,294.12,344.95,11.03;7,126.00,311.64,266.45,11.03"><head>1=</head><label></label><figDesc>Agree strongly, 2 = Agree slightly, 3 = Neutral, 4 = Disagree slightly, 5 = Disagree strongly Depth: Is the page too broad, too narrow or at the right level of detail for the topic? 1 = Too broad, 2 = Bit broad, 3 = Right level, 4 = Bit narrow, 5 = Too narrow Coverage: The set of saved entry points covers all the different aspects of the topic. 1 = Agree strongly, 2 = Agree slightly, 3 = Neutral, 4 = Disagree slightly, 5 = Disagree strongly Repetition: How much repetition/overlap is there within the set of saved entry points? 1 = None, 2 = Minimal, 3 = Some, 4 = A lot of, 5 = Way too much</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="4,117.00,296.88,369.00,341.16"><head></head><label></label><figDesc></figDesc><graphic coords="4,117.00,296.88,369.00,341.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,132.72,71.88,346.56,261.36"><head></head><label></label><figDesc></figDesc><graphic coords="6,132.72,71.88,346.56,261.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.00,89.88,431.95,199.55"><head>Table 1 : Home/named page submissions summary. To aid our understanding of retrieval performance we computed ARR for home pages only ``ARR (HP)'' and named pages only ``ARR (NP).'' We also computed a further run post-hoc (csiro03kins)</head><label>1</label><figDesc></figDesc><table coords="2,95.40,130.80,418.77,158.63"><row><cell>Run</cell><cell>Description</cell><cell>ARR</cell><cell>S@10 (%)</cell><cell>ARR (HP)</cell><cell>ARR (NP)</cell></row><row><cell>csiro03ki01</cell><cell>Tuned for HP and NP</cell><cell>0.692</cell><cell>83.7</cell><cell>0.815</cell><cell>0.569</cell></row><row><cell>csiro03ki02</cell><cell>Tuned for HP</cell><cell>0.603</cell><cell>77.7</cell><cell>0.774</cell><cell>0.432</cell></row><row><cell>csiro03ki03</cell><cell>Tuned for NP</cell><cell>0.702</cell><cell>84</cell><cell>0.755</cell><cell>0.649</cell></row><row><cell>csiro03ki04</cell><cell>HP and NP tunings</cell><cell>0.667</cell><cell>86.3</cell><cell>0.801</cell><cell>0.532</cell></row><row><cell></cell><cell>interleaved (HP then NP)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>w/q.class</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>csiro03ki05</cell><cell>HP and NP tunings</cell><cell>0.699</cell><cell>81</cell><cell>0.812</cell><cell>0.586</cell></row><row><cell></cell><cell>combined</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>csiro03kins</cell><cell>HP and NP tunings</cell><cell>0.717</cell><cell>87</cell><cell>0.781</cell><cell>0.651</cell></row><row><cell></cell><cell>interleaved (NP then HP)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,72.13,432.01,142.43"><head>Table 2 : Topic distillation submissions summary. Post-hoc we computed a run based using the name page tunings (csiro03tdns)</head><label>2</label><figDesc></figDesc><table coords="3,111.12,101.77,385.63,112.79"><row><cell>Run</cell><cell>Description</cell><cell>Average R-Prec</cell></row><row><cell>csiro03td01</cell><cell>Tuned for HP</cell><cell>0.1438</cell></row><row><cell>csiro03td02</cell><cell>Tuned for HP without query-ind. hyperlink evidence</cell><cell>0.1162</cell></row><row><cell>csiro03td03</cell><cell>Tuned for HP with stemming</cell><cell>0.1636</cell></row><row><cell>csiro03td04</cell><cell>Tuned for HP without anchor evidence</cell><cell>0.0988</cell></row><row><cell>csiro03td05</cell><cell>Tuned for HP with "normal" bm25 tuning (k 1 =2, b=0.75)</cell><cell>0.1217</cell></row><row><cell>csiro03tdns</cell><cell>Tuned for NP</cell><cell>0.1166</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,114.00,158.53,383.42,83.27"><head>Table 3 :</head><label>3</label><figDesc>Relevance of the saved/retrieved documents (The closer a score is to 1, the better)</figDesc><table coords="8,114.00,176.77,383.42,65.03"><row><cell></cell><cell>T1</cell><cell>T2</cell><cell>T3</cell><cell>T4</cell><cell>T5</cell><cell>T6</cell><cell>T7</cell><cell>T8</cell><cell>Mean</cell></row><row><cell>TDAuto</cell><cell>3.17</cell><cell>1.14</cell><cell>2.50</cell><cell>2.86</cell><cell>1.67</cell><cell>2.75</cell><cell>3.43</cell><cell>2.83</cell><cell>2.54</cell></row><row><cell>TDLinear</cell><cell>2.81</cell><cell>1.37</cell><cell>2.7</cell><cell>2.41</cell><cell>1.13</cell><cell>2.38</cell><cell>2.43</cell><cell>2.49</cell><cell>2.22</cell></row><row><cell cols="2">TDHierarchic 3.56</cell><cell>1.85</cell><cell>2.52</cell><cell>2.74</cell><cell>1.22</cell><cell>2.96</cell><cell>2.81</cell><cell>2.03</cell><cell>2.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,114.00,266.05,383.66,83.15"><head>Table 4 :</head><label>4</label><figDesc>Depth of the saved/retrieved documents (The closer a score is to 3, the better)</figDesc><table coords="8,114.00,284.17,383.66,65.03"><row><cell></cell><cell>T1</cell><cell>T2</cell><cell>T3</cell><cell>T4</cell><cell>T5</cell><cell>T6</cell><cell>T7</cell><cell>T8</cell><cell>Mean</cell></row><row><cell>TDAuto</cell><cell>4.00</cell><cell>3.71</cell><cell>2.50</cell><cell>4.14</cell><cell>3.33</cell><cell>3.13</cell><cell>4.14</cell><cell>3.67</cell><cell>3.58</cell></row><row><cell>TDLinear</cell><cell>3.77</cell><cell>3.19</cell><cell>2.26</cell><cell>3.83</cell><cell>2.99</cell><cell>3.40</cell><cell>3.62</cell><cell>3.46</cell><cell>3.32</cell></row><row><cell cols="2">TDHierarchic 4.30</cell><cell>2.88</cell><cell>2.47</cell><cell>3.83</cell><cell>2.87</cell><cell>3.37</cell><cell>3.71</cell><cell>3.01</cell><cell>3.31</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,111.12,373.45,389.18,65.15"><head>Table 5 :</head><label>5</label><figDesc>Coverage of the saved list (The closer a score is to 1, the better)</figDesc><table coords="8,111.12,391.69,389.18,46.91"><row><cell></cell><cell>T1</cell><cell>T2</cell><cell>T3</cell><cell>T4</cell><cell>T5</cell><cell>T6</cell><cell>T7</cell><cell>T8</cell><cell>Mean</cell></row><row><cell>TDLinear</cell><cell>1.63</cell><cell>2.13</cell><cell>3.25</cell><cell>4.5</cell><cell>1.25</cell><cell>1.25</cell><cell>1.00</cell><cell>4.88</cell><cell>2.48</cell></row><row><cell cols="2">TDHierarchic 2.38</cell><cell>2.63</cell><cell>2.50</cell><cell>4.63</cell><cell>2.25</cell><cell>1.25</cell><cell>1.00</cell><cell>3.63</cell><cell>2.53</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,113.76,462.85,383.90,65.27"><head>Table 6 : Repetition of the saved list</head><label>6</label><figDesc>(The closer a score is to 1, the better)</figDesc><table coords="8,113.76,481.09,383.90,47.03"><row><cell></cell><cell>T1</cell><cell>T2</cell><cell>T3</cell><cell>T4</cell><cell>T5</cell><cell>T6</cell><cell>T7</cell><cell>T8</cell><cell>Mean</cell></row><row><cell>TDLinear</cell><cell>2.57</cell><cell>2.25</cell><cell>1.75</cell><cell>2.38</cell><cell>1.50</cell><cell>3.0</cell><cell>3.0</cell><cell>2.63</cell><cell>2.38</cell></row><row><cell>TDHiearchic</cell><cell>2.50</cell><cell>1.63</cell><cell>2.13</cell><cell>3.38</cell><cell>2.00</cell><cell>3.25</cell><cell>3.25</cell><cell>1.25</cell><cell>2.42</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,114.00,552.61,383.42,82.91"><head>Table 7 : Precision of the saved/retrieved list</head><label>7</label><figDesc></figDesc><table coords="8,114.00,570.49,383.42,65.03"><row><cell></cell><cell>T1</cell><cell>T2</cell><cell>T3</cell><cell>T4</cell><cell>T5</cell><cell>T6</cell><cell>T7</cell><cell>T8</cell><cell>Mean</cell></row><row><cell>TDAuto</cell><cell>0.33</cell><cell>1.00</cell><cell>0.67</cell><cell>0.29</cell><cell>0.83</cell><cell>0.50</cell><cell>0.43</cell><cell>0.50</cell><cell>0.57</cell></row><row><cell>TDLinear</cell><cell>0.48</cell><cell>0.88</cell><cell>0.53</cell><cell>0.52</cell><cell>0.97</cell><cell>0.62</cell><cell>0.54</cell><cell>0.48</cell><cell>0.63</cell></row><row><cell cols="2">TDHierarchic 0.18</cell><cell>0.78</cell><cell>0.61</cell><cell>0.48</cell><cell>0.95</cell><cell>0.51</cell><cell>0.49</cell><cell>0.60</cell><cell>0.58</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,97.32,698.29,424.73,11.03;2,90.00,709.81,32.03,11.03"><p>Query terms were selected from last years query set and included terms such as ``"page", "form" and "2000"''</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="7,95.76,709.81,237.83,11.03"><p>All significant tests in the interactive part used paired t-test.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="8,97.20,686.89,424.83,11.03;8,90.00,698.29,432.06,11.03;8,90.00,709.81,126.36,11.03"><p>Compared to the automatic topic distillation task our assessment is fairly lenient and the queries have been manually adjusted to the task. Although the absolute values of the precision are high, it is the relative differences that are noteworthy.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Searcher effort</head><p>The numbers of unique documents (after removing duplicated occurrences and un-accessible pages) read and saved are shown in Table <ref type="table" coords="9,217.89,102.25,3.75,11.03">8</ref>. The second row shows that subjects read significantly more documents from TDLinear interface (Mean=24.17) than that from TDHierarchic interface (Mean=17.73) ( p &lt; 0.0002). However, the third row did not show much difference in the number of saved documents from each interface. To understand how and where subjects put their effort, we had a closer look on how subjects divided their effort on each interface.</p><p>The TDLinear interface has two parts: the window for the ranked list (TDLinear-R) and the window to show the content of a selected document (TDLinear-C). The TDHierarchic interface has three parts: the window for the grouped ranked list (TDHierarchic-R), the frame for the tree structure of a selected web site (TDHierarchic-T), and the frame to show the content of a selected document (TDHierarchic-C).</p><p>There is not much difference between TDLinear-C and TDHierarchic-C, except their window sizes. The difference is that TDHiearchic has an extra interface panel (TDHierarchic-T), and TDHierarchic-R is probably more complex than TDLinear-R.</p><p>Table <ref type="table" coords="9,115.81,382.56,4.98,11.03">9</ref> shows the division of effort from the first four searchers. By examining the recorded screen actions from the these four searchers, we observed that these searchers spent an average 36% of their total search time and on average opened 15 (unique) documents to read from TDLinear-R. While in TDHierarchic-G window, searchers spent similar amount of time (37% of their total search time), but opened only 9.3 (unique) documents. We observed that searchers picked up documents to open sequentially and spent less time to read document summaries in TDLinear-R, while they spent more time to read document summaries (by hovering the mouse over the "Summary" icon) and even read summaries from a few documents before they opened a document in TDHierarchic-G.</p><p>While these four searchers spent on average 64% of their total search time and opened 7.9 documents to read from TDLinear-C, they divided their effort in two frames in TDHierarchic. These four searchers spent on average 19% of their search time on TDHierarchic-T, 44% on TDHierarchic-C, but opened a similar number of (unique) documents. This implies that the searchers used the tree structure more often to help them to browse the selected web site. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Subjective measures</head><p>After each topic, subjects were required to fill in a post-search questionnaire about their experience of the search topic and their sense of the task completeness. All questions are on 7-point Likert scale with 1=strongly disagree, 4=neutral, and 7=strongly agree. Table <ref type="table" coords="10,341.08,113.77,10.02,11.03">10</ref> shows that subjects gave higher score to TDHierarchic interface on all seven questions. Q2: The pages I just saved focuses on the topic well. Q3: The pages I just saved are the main pages of their corresponding websites. Q4: The pages I just saved together provide a good coverage of the topic. Q5: The pages I just saved will be helpful for the targeted audiences. Q6: I have enough time to do an effective search. Q7: I believe that I have succeeded in my performance of the task.</p><p>After each system, subjects were asked to fill in a post-system questionnaire to get their opinion on the usability of each system. Table <ref type="table" coords="10,216.96,312.60,10.02,11.03">11</ref> shows the average score for each interface for seven questions. There are significant difference between two interfaces for question 3 and question 4, that is: searchers strongly agreed that the organization of the search results of TDHierarichic interface was clearer and more useful for them to select an entry point to start with. Q1: It was easy to learn to use this system. Q2: It was easy to use this system. Q3: The organization of the search results is clear to me. Q4: the organization of the search results is useful for me to select an entry point to search. Q5: The summary of each search results helped me to decide the relevance of that website. Q6: The summary of each search result is useful for me to select an entry point to search. Q7: The web structure of my selected entry point is useful for me to judge whether the entry point is the main page.</p><p>Table <ref type="table" coords="10,115.44,534.48,9.98,11.03">12</ref> shows searchers' answer to the three questions in the exit search questionnaire. Overall, most of the searchers perceived that TDHierarchic interface is easier to use and supporting their task better, and they liked TDHierarchic interface the best overall. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Discussion</head><p>In this experiment, we found that our searchers preferred the experimental interface (TDHierarchic) and perceived that they fulfilled their task better by using the experimental interface than the ranked list interface (TDLinear). However, we didn't find any significant difference between the two interfaces on searchers' performance in terms of relevance, depth, coverage and repetition.</p><p>One of our hypotheses was that we could increase performance by encouraging searchers to compare items rather than make individual judgments. This was implemented on the site summary interface. By further examining searchers' behavior, we found that the interface for grouping documents into sites changed search behavior: searchers spent time selecting amongst the results from a specific site by looking at and comparing the summaries. Searchers selected fewer pages to examine and the overall results were similar to the ranked list interface indicating that users had compared and made good selection decisions. Also in the post-system questionnaire, searchers stated strongly that the grouping interface was useful for them to select an entry point to search. However, confounded by many other factors, it is not clear whether this behavior would be beneficial to the overall task.</p><p>Comparing the results from our interactive system with that of the corresponding automatic system, we found a significant improvement in terms of relevance, depth and precision. That indicates that engagement of a searcher's effort has a positive effect on the system performance, and that there is room for improvement for systems to reduce searcher effort.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,94.50,317.39,65.21,13.28" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
