<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.56,73.25,351.55,15.54;1,237.00,90.65,121.45,15.54">Approach of Information Retrieval with Reference Corpus to Novelty Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.08,129.93,63.22,11.03"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
							<email>mftsai@nlg.csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.80,129.93,65.70,11.03"><forename type="first">Ming-Hung</forename><surname>Hsu</surname></persName>
							<email>mhhsu@nlg.csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.00,129.93,59.70,11.03"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
							<email>hh_chen@csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.56,73.25,351.55,15.54;1,237.00,90.65,121.45,15.54">Approach of Information Retrieval with Reference Corpus to Novelty Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">379012D85ECCFC3DDADE1D94B0D15262</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to the results of TREC 2002, we realized the major challenge issue of recognizing relevant sentences is a lack of information used in similarity computation among sentences. In TREC 2003, NTU attempts to find relevant and novel information based on variants of employing information retrieval (IR) system. We call this methodology IR with reference corpus, which can also be considered an information expansion of sentences. A sentence is considered as a query of a reference corpus, and similarity between sentences is measured in terms of the weighting vectors of document lists ranked by IR systems. Basically, we looked for relevant sentences by comparing their results on a certain information retrieval system. Two sentences are regarded as similar if they are related to the similar document lists returned by IR system. In novelty parts, similar analysis is used to compare each relevant sentence with all those that preceded it to find out novelty. An effectively dynamic threshold setting which is based on what percentage of relevant sentences is within a relevant document is presented. In this paper, we paid attention to three points: first, how to use the results of IR system to compare the similarity between sentences; second, how to filter out the redundant sentences; third, how to determine appropriate relevance and novelty threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Procedure</head><p>The flow of IR with reference corpus is illustrated in Figure <ref type="figure" coords="1,347.04,434.37,3.76,11.03">1</ref>, which contains an IR system and a reference corpus inside. To begin with, each sentence from the known relevant documents is treated as a query to a certain IR system that retrieves documents from the reference corpus. Then, a sentence can be transformed into a vector that uses each unique document retrieved by the IR system as one dimension and set the relevant weight assigned by the IR system as the weight of each dimension. An IR system, for instance, may retrieve top m documents from the reference corpus for a query. Therefore, a sentence can be regarded as a vector of m dimensions of weights assigned by the IR system. Finally, similarity metric is applied to measure the similarity between vectors, and the threshold is also applied to the following operations, retrieval or filter. Below we discuss this approach in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">IR System and Reference Corpus</head><p>In the experiments, the document sets used in TREC-6 text collection <ref type="bibr" coords="1,380.88,583.89,124.64,11.03" target="#b8">(Voorhees and Harman, 1997)</ref> were considered as a reference corpus. It consists of 556,077 documents. Okapi IR system <ref type="bibr" coords="1,89.88,606.81,168.92,11.03" target="#b6">(Robertson, Walker and Beaulieu, 1998</ref>) is adopted to experiment this approach. In the initial experiments, Okapi was in the option of bm25, and had average precision 0.2181 on TREC-6 text collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Flow of IR with Reference Corpus Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Similarity Computation</head><p>The cosine similarity computation is considered in our task. The metric is shown as follows.</p><p>, , 1 cos( , )</p><formula xml:id="formula_0" coords="2,245.64,326.60,257.97,31.37">|| || || || l i k j k k i j i j v v s s s s = × = (1)</formula><p>where si is represented as a sentence-vector <ref type="bibr" coords="2,280.92,366.40,65.51,11.08">(vi,1, vi,2, …, vi,l)</ref>, l denotes the number of documents retrieved from the reference corpus by IR system; and sj is another sentence-vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Threshold Setting</head><p>We consider what percentage of sentences is relevant within a document. In <ref type="bibr" coords="2,412.08,423.88,93.37,11.08;2,89.88,435.45,10.30,11.03">TREC 2002, Larkey et al.</ref> showed that about 5% of the sentences contained relevant materials for average topic. We also discovered the percentage of relevant sentences gets less when total number of given sentences is more. Therefore, we used logarithmic regression as follows to simulate the relationship between total number of the given sentences and percentage of the relevant sentences.</p><p>A dynamic threshold setting model is proposed as follows. Assume normal distribution with mean µ and standard deviation / is adopted to specify the similarity distribution of the given sentences with a topic. We compute the cosine of a topic vector T and a given sentence vector Si (1 i m), where m denotes total number of the given sentences. The percentage n denotes that top n percentages of the given sentences will be reported. Similarity thresholds (THrelevance) are determined by these percentages.</p><p>1 cos( , )</p><formula xml:id="formula_1" coords="2,224.28,553.77,279.09,161.27">m i i T S m µ = = (2) 2 1 (cos( , ) ) m i i T S m µ = = (3) relevance TH = +z µ (4) 2 / 2 1 ( ) 1 2 z y z e d y n = = (5)</formula><p>We first compute the percentage n, and then derive z by Formula (5). Finally, TH relevance is computed by Formula (4). Therefore, the relevance threshold is determined by the total number of given sentences.</p><p>In the novelty part, a threshold of novelty decision, TH novelty , determines the degree of redundancy. If the similarity score of two sentences is larger than THnovelty, then one of them has to be filtered out depending to their temporal order. In this way, the redundant sentences are filtered out and only the novel sentences are kept. The remaining sentences are the result of the novelty detector. Two algorithms are proposed as follows. Assume there are r relevant sentences, s 1 , s 2 , …, s r for topic t.</p><p>(1) Static threshold approach Let T be a set containing novel sentences found up to know. Initially, T={s1}. For each relevant sentence si (2 i r), if there exists a sentence in T whose similarity with si is larger than a predefined threshold, then si is not a novel sentence and is removed; otherwise, si is kept in T.</p><p>(2) Dynamic threshold approach Assume s 1 is a novel sentence. Compute the similarities between s 1 and s i (2 i r).</p><p>Determine the novelty threshold, TH novelty , in the same way as TH relevance . Filter out the top n% of sentences with the higher similarities with s 1. Let R be the remaining sentences. If the number of sentences in R is less than 30 1 , then regard these sentences as novel sentences and stop. Otherwise, select the first sentence in R, regard it as a novel sentence and repeat the same filtering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Finding Relevant Sentences</head><p>This part is to give the set of 25 relevant documents for each topic and to identify all relevant sentences. We first treated each given sentence as a query to IR system, and then get a vector of document weight assigned by IR system. Next, we applied the cosine function to measure similarity between sentences. In the part of threshold setting, we used the statistics of TREC 2002 novelty track to simulate the relation of total number of given sentences and percentage of relevant sentences. Formula 6 and Figure <ref type="figure" coords="3,183.72,388.89,4.98,11.03" target="#fig_0">2</ref> show the trend. Because some topics may get less percentage, we apply a parameter to multiply the percentage calculated by Formula ( <ref type="formula" coords="3,335.83,400.41,3.91,11.03">6</ref>) to retrieve more sentences. Take Ln-4 for example. That means that it multiplies 4 to the calculated percentage. Figure <ref type="figure" coords="3,130.68,632.93,5.00,11.07" target="#fig_1">3</ref> shows the experimental results of relevance detection. These results are totally different to those of last year, because the number of qrels of relevance information is dramatically more than that of last year. Last year, the percentage of relevant sentences within the whole given sentences was about 5%, but this year some topics even has about 50 percent of relevant sentences. Therefore, our average recall gets lower since our relevance threshold is too high. That demonstrates the issue of identifying an appropriate threshold in the novelty detection is very important. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Finding Novel Sentences</head><p>This part is to identify sentences that include new information among the relevant sentences. In other words, this part will filter out the redundant sentences. The key issue of finding novel sentences is how to differentiate the meaning of sentences accurately. We extend the idea, i.e., employing IR with reference corpus approach to expand a sentence, to find novel sentences. We experiment two novelty threshold setting algorithms, i.e., static and dynamic settings. In order to test this model, we use the perfect relevance results to experiment. And the number of consulted documents retrieved by IR system is set to 300.</p><p>Figure <ref type="figure" coords="4,131.16,379.65,4.98,11.03">4</ref> demonstrates the results of finding novelty with static threshold setting. When novelty threshold is 1, it does not filter out any sentences. The performance gets better as the novelty threshold is higher. Figure <ref type="figure" coords="4,210.24,402.69,4.98,11.03" target="#fig_2">5</ref> shows the results of finding novelty with dynamic threshold setting. The result reveals that the more percentage filtered, the worse the performance is. From these results, the performance will be better if we filter out fewer sentences. Therefore, we set the novelty threshold higher in the submitted runs to achieve better performance. Table <ref type="table" coords="5,116.04,120.33,4.98,11.03" target="#tab_0">1</ref> and 2 show the runs we submitted in task 1 and 3 of novelty detection, where the number of consulted documents is set to 300 , the dynamic relevance threshold uses Ln-1, and NTU11, NTU12, NTU13 and NTU14 uses topic description and narrative. In the novelty part of task 1, all runs use the static threshold setting where NTU11, NTU13 and NTU15 are set to 0.8; NTU12 and NTU14 are set to 0.9. In the task3, we use Ln-2, and Ln-3 functions to retrieve more relevant sentences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task2 &amp; Task4</head><p>Tables <ref type="table" coords="5,119.88,441.69,4.98,11.03" target="#tab_2">3</ref> and<ref type="table" coords="5,145.92,441.69,4.98,11.03" target="#tab_3">4</ref> show the results of task 2 and 4 of novelty track. We use two novelty algorithms to find novelty sentences. In task 2, NTU21, NTU22 and NTU23 use static threshold; NTU24 and NTU25 use globe threshold setting. In task 4, NTU41, NTU42 and NTU43 also use static threshold; NTU44 and NTU45 use dynamic threshold. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,213.00,610.54,169.14,9.96"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An illustration of Logarithmic Trend</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,197.28,254.26,200.70,9.96"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Experimental Results of Relevance Detection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,147.72,584.86,299.82,9.96"><head>Figure 5 .</head><label>5</label><figDesc>Figure 4. Experimental Results of Novelty Detection with Static Threshold Setting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,187.68,190.54,224.78,99.57"><head>Table 1 .</head><label>1</label><figDesc>Task 1 Submitted Results</figDesc><table coords="5,187.68,208.41,224.78,81.71"><row><cell></cell><cell>Relevant Detection</cell><cell>Novelty Detection</cell></row><row><cell></cell><cell cols="2">Avg P Avg R Avg F Avg P Avg R Avg F</cell></row><row><cell>NTU11</cell><cell cols="2">0.59 0.16 0.225 0.43 0.15 0.197</cell></row><row><cell>NTU12</cell><cell cols="2">0.59 0.16 0.225 0.43 0.15 0.200</cell></row><row><cell>NTU13</cell><cell cols="2">0.58 0.16 0.223 0.43 0.15 0.195</cell></row><row><cell>NTU14</cell><cell cols="2">0.58 0.16 0.223 0.42 0.15 0.197</cell></row><row><cell>NTU15</cell><cell cols="2">0.57 0.14 0.209 0.42 0.14 0.180</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,187.68,304.78,224.78,100.41"><head>Table 2 .</head><label>2</label><figDesc>Task 3 Submitted Results</figDesc><table coords="5,187.68,322.65,224.78,82.55"><row><cell></cell><cell>Relevant Detection</cell><cell>Novelty Detection</cell></row><row><cell></cell><cell cols="2">Avg P Avg R Avg F Avg P Avg R Avg F</cell></row><row><cell>NTU31</cell><cell cols="2">0.56 0.20 0.266 0.39 0.19 0.217</cell></row><row><cell>NTU32</cell><cell cols="2">0.57 0.25 0.301 0.39 0.23 0.241</cell></row><row><cell>NTU33</cell><cell cols="2">0.58 0.22 0.287 0.40 0.21 0.236</cell></row><row><cell>NTU34</cell><cell cols="2">0.58 0.27 0.330 0.40 0.26 0.270</cell></row><row><cell>NTU35</cell><cell cols="2">0.57 0.22 0.287 0.39 0.21 0.240</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,233.28,500.26,133.94,106.77"><head>Table 3 .</head><label>3</label><figDesc>Task 2 Submitted Results</figDesc><table coords="5,233.28,518.73,133.94,88.31"><row><cell></cell><cell>Novelty Detection</cell></row><row><cell></cell><cell>Avg P Avg R Avg F</cell></row><row><cell>NTU21</cell><cell>0.71 0.98 0.812</cell></row><row><cell>NTU22</cell><cell>0.70 0.99 0.811</cell></row><row><cell>NTU23</cell><cell>0.70 0.99 0.812</cell></row><row><cell>NTU24</cell><cell>0.74 0.42 0.495</cell></row><row><cell>NTU25</cell><cell>0.74 0.42 0.501</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,232.32,622.30,135.74,103.65"><head>Table 4 .</head><label>4</label><figDesc>Task 4 Submitted Results</figDesc><table coords="5,232.32,640.29,135.74,85.67"><row><cell></cell><cell cols="2">Novelty Detection</cell></row><row><cell></cell><cell cols="2">Avg P Avg R Avg F</cell></row><row><cell>NTU41</cell><cell>0.67</cell><cell>0.98 0.785</cell></row><row><cell>NTU42</cell><cell>0.67</cell><cell>0.99 0.784</cell></row><row><cell>NTU43</cell><cell>0.67</cell><cell>0.99 0.784</cell></row><row><cell>NTU44</cell><cell>0.68</cell><cell>0.46 0.507</cell></row><row><cell>NTU45</cell><cell>0.68</cell><cell>0.47 0.509</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,89.88,99.94,415.59,9.96;6,101.28,110.26,404.25,9.96;6,101.28,120.58,239.10,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,225.00,99.94,196.60,9.96">Retrieval and Novelty Detection at the Sentence Level</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bolivar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,438.00,99.94,67.47,9.96;6,101.28,110.26,400.74,9.96">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003-08-01">July 28-August 01, 2003. 2003</date>
			<biblScope unit="page" from="314" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,89.88,130.90,415.65,9.96;6,101.28,141.34,53.40,9.96" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,245.04,130.90,256.70,9.96">Topic Detection and Tracking: Event-Based Information Organization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonnell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yamron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,89.88,151.66,415.54,9.96;6,101.28,161.98,404.28,9.96;6,101.28,172.30,56.34,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,199.08,151.66,170.37,9.96">An NLP &amp; IR Approach to Topic Detection</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">W</forename><surname>Ku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,389.16,151.66,116.26,9.96;6,101.28,161.98,141.74,9.96">Topic Detection and Tracking: Event-Based Information Organization</title>
		<editor>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaime</forename><surname>Carbonnell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Yamron</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="243" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,89.88,182.74,415.72,9.96;6,101.28,193.06,356.52,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,324.12,182.74,181.48,9.96;6,101.28,193.06,60.22,9.96">A Summarization System for Chinese News from Multiple Sources</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-C</forename><surname>Wung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,167.64,193.06,259.52,9.96">In Journal of American Society for Information Science and Technology</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,89.88,203.38,415.62,9.96;6,101.28,213.70,79.62,9.96;6,180.84,212.41,4.80,6.64;6,188.28,213.70,300.54,9.96;6,488.76,212.41,4.80,6.64;6,493.44,213.70,7.50,9.96;6,500.88,212.41,4.80,6.64;6,101.28,224.14,90.59,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,240.12,203.38,250.68,9.96">Identification of Relevant Novel Sentences Using Reference Corpus</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,101.28,213.70,79.62,9.96;6,180.84,212.41,4.80,6.64;6,188.28,213.70,170.34,9.96">Proceedings of the 26 th European Conference on Information Retrieval</title>
		<meeting>the 26 th European Conference on Information Retrieval</meeting>
		<imprint>
			<publisher>ECIR</publisher>
			<date type="published" when="2004-04-07">5 th -7 th April 2004. 2004</date>
		</imprint>
		<respStmt>
			<orgName>University of Sunderland, U.K.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,89.88,234.46,415.42,9.96;6,101.28,244.78,404.28,9.96;6,101.28,255.10,24.12,9.96;6,89.88,265.54,415.50,9.96;6,101.28,275.86,404.25,9.96;6,101.28,286.18,137.52,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,142.68,234.46,169.87,9.96;6,165.96,265.54,218.03,9.96">UMass at TREC2002: Cross Language and Novelty Tracks</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Larkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,334.20,234.46,171.10,9.96;6,101.28,244.78,189.02,9.96;6,401.64,265.54,103.74,9.96;6,101.28,275.86,98.96,9.96">Proceedings of the Eleventh Text REtrieval Conference. NIST Special Publication: SP 500-251</title>
		<meeting>the Eleventh Text REtrieval Conference. NIST Special Publication: SP 500-251<address><addrLine>Gaithersburg, Maryland; Gaithersburg; Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2002-11-19">November 19-22, 2002. 2002. November 19-22, 2002. 2002</date>
			<biblScope unit="volume">500</biblScope>
		</imprint>
	</monogr>
	<note>TREC</note>
</biblStruct>

<biblStruct coords="6,89.88,296.50,415.62,9.96;6,101.28,306.94,404.38,9.96;6,101.28,317.26,285.81,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,278.88,296.50,226.62,9.96;6,101.28,306.94,37.27,9.96">Okapi at TREC-7: Automatic ad hoc, Filtering, VLC and Interactive</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,154.56,306.94,197.60,9.96;6,410.64,306.94,95.02,9.96;6,101.28,317.26,40.58,9.96">Proceedings of the Seventh Text REtrieval Conference</title>
		<meeting>the Seventh Text REtrieval Conference<address><addrLine>Gaithersburg; Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-11">November 9-11. 1998</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="253" to="264" />
		</imprint>
	</monogr>
	<note>NIST Special Publication: SP 500-242</note>
</biblStruct>

<biblStruct coords="6,89.88,327.58,415.72,9.96;6,101.28,337.90,404.25,9.96;6,101.28,348.22,176.99,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,196.92,327.58,222.80,9.96">Some Similarity Computation Methods in Novelty Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,437.04,327.58,68.56,9.96;6,101.28,337.90,136.75,9.96;6,300.72,337.90,147.02,9.96">Proceedings of the Eleventh Text REtrieval Conference</title>
		<meeting>the Eleventh Text REtrieval Conference<address><addrLine>Gaithersburg; Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2002">November 19-22, 2002. 2002</date>
		</imprint>
	</monogr>
	<note>NIST Special Publication: SP 500-251</note>
</biblStruct>

<biblStruct coords="6,89.88,358.66,415.66,9.96;6,101.28,368.98,273.36,9.96" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Harman</surname></persName>
		</author>
		<title level="m" coord="6,241.32,358.66,264.22,9.96;6,101.28,368.98,86.30,9.96">Proceedings of the Sixth Text Retrieval Conference. NIST Special Publication: SP 500-240</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename></persName>
		</editor>
		<meeting>the Sixth Text Retrieval Conference. NIST Special Publication: SP 500-240<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">November 19-21, (1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,89.88,379.30,415.54,9.96;6,101.28,389.62,404.28,9.96;6,101.28,400.06,24.12,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,154.20,379.30,176.04,9.96">THU at TREC2002: Novelty, Web and Filtering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,346.44,379.30,158.98,9.96;6,101.28,389.62,189.02,9.96">Proceedings of the Eleventh Text REtrieval Conference, NIST Special Publication: SP 500-251</title>
		<meeting>the Eleventh Text REtrieval Conference, NIST Special Publication: SP 500-251<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">November 19-22, 2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
