<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.54,132.06,315.30,18.82">From TREC to DUC to TREC Again</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-02-03">February 3, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,105.12,171.41,100.37,14.36;1,205.58,169.49,1.66,9.96"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
							<email>conroy@super.org</email>
							<affiliation key="aff0">
								<orgName type="department">IDA/Center for Computing Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.43,171.41,117.32,14.36;1,359.87,169.49,2.21,9.96"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Dunlavy</surname></persName>
							<email>ddunlavy@cs.umd.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.71,171.41,114.80,14.36;1,511.62,169.49,2.21,9.96"><forename type="first">Dianne</forename><forename type="middle">P</forename><surname>O'leary</surname></persName>
							<email>oleary@cs.umd.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.54,132.06,315.30,18.82">From TREC to DUC to TREC Again</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-02-03">February 3, 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">D02D7BB7B2858D7D340EA13652CCFBAD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Document Understanding Conference (DUC) uses TREC data as a test bed for algorithms for single and multiple document summarization. For the 2003 DUC task of choosing relevant and novel sentences, we tested a system based on a Hidden Markov Model (HMM). In this work, we use variations of this system on the tasks of the TREC Novelty Track for finding relevant and new sentences.</p><p>Our complete information retrieval system couples a query handler, a document clusterer, and a summary generator with a convenient user interface. For the TREC tasks, we use only the summarization part of the system, based on an HMM, to find relevant sentences in a document and we use linear algebra techniques to determine the new sentences among these.</p><p>For the tasks in the 2003 TREC Novelty Track we used a simple preprocessing of the data which consisted of term tokenization and SGML DTD processing. Details of each of these methods are presented in Section 2.</p><p>The algorithms for choosing relevant sentences were tuned versions of those presented by members of our group in the past DUC evaluations (see <ref type="bibr" coords="1,304.70,487.80,12.33,11.97" target="#b4">[5,</ref><ref type="bibr" coords="1,321.56,487.80,9.09,11.97" target="#b7">8,</ref><ref type="bibr" coords="1,335.19,487.80,14.94,11.97" target="#b14">15]</ref> for more details). The enhancements to the previous system are detailed in Section 3.</p><p>Several methods were explored to find a subset of the relevant sentences that had good coverage but low redundancy. In our multi-document summarization system, we used the QR algorithm on term-sentence matrices. For this work, we explored the use of the singular value decomposition as well as two variants of the QR algorithm. These methods are defined in Section 4. The evaluation of these methods is discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preprocessing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tokenization</head><p>The tokenization was quite simple. First the text was converted to lower case. All contiguous strings of characters taken from the set {a,b,...,z} were terms except for those matched on a short list of stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Parsing Files using DTDs</head><p>Using the SGML document type definition (DTD) for a document allowed us to determine the set of all possible SGML tags that exist in documents of that type. Using these tag sets, we distinguished which sentences 1) were candidates for relevant sentences, 2) were not candidates for relevant sentences but which contained key terms or phrases that would aid in identifying relevant sentences, and 3) contained no useful information for the task of extracting relevant sentences. We created a new attribute, stype, for the SGML tag denoting a sentence boundary, &lt;s&gt;, in order to denote each of these three types of sentences. The possible values for this new attribute are 1, 0, and -1, respectively. Table <ref type="table" coords="2,207.81,319.74,5.85,11.97" target="#tab_0">1</ref> presents the values of stype used for sentences embedded into the SGML tags encountered in the several types of documents used in the evaluation.</p><p>Choosing to embed information into the document itself instead of creating a processing module in our algorithm allowed us flexibility in using the information throughout the various stages of our system. Furthermore, it will allow us to expand the types of sentence classification without changing the code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Finding Relevant Sentences</head><p>An HMM, in contrast to a naive Bayesian approach ( <ref type="bibr" coords="2,357.29,460.07,12.07,11.97" target="#b0">[1]</ref>, <ref type="bibr" coords="2,379.19,460.07,17.31,11.97" target="#b11">[12]</ref>), has fewer assumptions of independence. In particular, it does not assume that the probability that sentence i is relevant is independent of whether sentence i -1 is relevant. In the HMM developed for this evaluation, we used a joint distribution for the features set which varied based upon the position in the document.</p><p>All of the features used by the HMM were based upon the terms (as defined in Section 2.1) found in a sentence. The features for the HMM were as follows:</p><p>• number of signature terms, n sig , in a sentence-value is o 1 (i) = log(n sig + 1).</p><p>• number of subject tokens, n subj , in a sentence-value is o 2 (i) = log(n subj + 1).</p><p>• position of the sentence in the document-built into the state-structure of the HMM.</p><p>The signature terms are the terms that are more likely to occur in the document (or document set) than in the corpus at large. To identify these terms, we used the log-likelihood statistic suggested by Dunning <ref type="bibr" coords="2,121.69,664.10,12.33,11.97" target="#b8">[9]</ref> and used first in summarization by Lin and Hovy <ref type="bibr" coords="2,390.94,664.10,17.14,11.97" target="#b12">[13]</ref>. The statistic is equivalent to a mutual information statistic and is based on a 2-by-2 contingency table of counts for each term.</p><p>The subject terms are a special subset of the signature terms. These are the signature terms that occur in sentences with stype = 0, for example, headline and subject heading sentences. The features were normalized component-wise to have mean zero and variance one. In addition, the features for sentences with stype 0 and -1 were coerced to be -1, which forced these sentences to have an extremely low probability of being selected as relevant sentences.</p><p>An HMM handles the positional dependence, dependence of features, and Markovity. (For more details about HMMs, see <ref type="bibr" coords="3,189.93,480.89,12.33,11.97" target="#b1">[2]</ref> and <ref type="bibr" coords="3,229.00,480.89,17.31,11.97" target="#b13">[14]</ref>.) The model we proposed has 2s + 1 states, with s relevance states and s + 1 non-relevance states. A picture of the Markov chain is given in Figure <ref type="figure" coords="3,520.96,495.33,4.54,11.97" target="#fig_0">1</ref>. Note that we allowed hesitation only in non-relevance states and skipping of states only from relevance states. This chain was designed to model the extraction of up to s -1 lead relevant sentences and an arbitrary number of supporting relevant sentences. Using training data, we obtained a maximum-likelihood estimate for each transition probability and this formed an estimate, M , for the transition matrix for our Markov chain, where element (i, j) of M is the estimated probability of transitioning from state i to state j.</p><p>Associated with each state i is an output function, b i (O) = P r(O|state i), where O is an observed vector of features. We made the simplifying assumption that the features were multivariate normal. The output function for each state was estimated by using the training data to compute the maximum-likelihood estimate of its mean and covariance matrix. We estimated 2s + 1 means, but assumed that all of the output functions shared a common covariance matrix.</p><p>Training for the HMM was straightforward given marked data. Since the states of the HMM were known in the training data, creating the model simply amounted to computing the maximum likelihood statistics given the counts. In particular, the training data helped determine the number of states for the HMM. The upshot was that a state space consisting of thirteen states (six relevance states and seven non-relevance states) was optimal given TREC 2002 data. (For Tasks <ref type="figure" coords="4,355.35,303.59,5.85,11.97">3</ref> and<ref type="figure" coords="4,389.55,303.59,4.54,11.97">4</ref>, when some of the TREC 2003 data is allowed for training, the optimal number of states was three-one relevance state and two non-relevance states.)</p><p>With this model we computed γ j (i), the probability that sentence j corresponded to state i. We computed the probability that a sentence was a relevant sentence by summing γ j (i) over all even values of i, values corresponding to relevance states. This posterior probability, which we define as g j , was used to select the most likely relevant sentences. We refer the reader to <ref type="bibr" coords="4,467.65,390.26,12.33,11.97" target="#b3">[4]</ref> for details.</p><p>This posterior probability was used to select which sentences were likely to be relevant. The selection algorithm attempted to choose the number of sentences so that the expected F 1 score was maximized. The approximate F 1 score was computed based on the expected precision, E(P ), and expected recall, E(R), as follows:</p><formula xml:id="formula_0" coords="4,260.33,461.00,98.71,28.26">F 1 = 2E(P )E(R) E(P ) + E(R)</formula><p>where</p><formula xml:id="formula_1" coords="4,269.25,505.80,80.43,28.30">E(P ) = t S g t |S|</formula><p>where |S| is the cardinality of the set S of sentences selected, and</p><formula xml:id="formula_2" coords="4,266.71,565.74,87.20,30.43">E(R) = t S g t t g t .</formula><p>The set S was chosen by selectively choosing the sentences in decreasing order of their probability of being a relevant sentence. The score F 1 was then computed and the set S increased as long as F 1 increased. Another feature that was considered previously (during the DUC evaluation) for our system was based on the query terms derived from the topic descriptions. We attempted to use this information in two ways. The first was to simply add an additional feature to the HMM. This approach actually decreased the precision of the system. The second method we considered used the derived query terms in conjunction with an information retrieval (IR) system to rank each document. The hope was to use a combination of these IR scores and the HMM sentence scores to generate the relevant sentences. Unfortunately, the IR scores did not correlate strongly with the likelihood that a document's sentence would be chosen as relevant. We hypothesize that since the document collection only contains documents relevant to the query, the topic description terms do not add any additional information. Clearly, more analysis is required to determine why the topic descriptions did not help in the generation of relevant sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Finding New Sentences</head><p>To choose a subset of the candidate relevant sentences to produce new sentences we experimented with three algorithms: a QR decomposition, a pivoted QR decomposition, and the singular value decomposition (SVD). These methods all work on the term-sentence matrix, A, where A ij is 1 if term i occurs in relevant sentence j. Before applying the sentence selection algorithms, the columns of A were normalized; the Euclidean length of a column was set equal to the probability that the corresponding sentence was indeed relevant. For Tasks 2 and 4 these probabilities were 1 since the relevant sentences were given, while for Task 3, the probability was equal to the score produced by the HMM for that sentence, g j .</p><p>The SVD was used as an optional preprocessing to the matrix A before applying the QR or pivoted QR. The SVD is a matrix factorization method that returns the best low rank approximation for a matrix. The idea of using such preprocessing was borrowed from information retrieval, where the SVD is the basis for Latent Semantic Indexing (LSI) <ref type="bibr" coords="5,338.50,385.67,11.68,11.97" target="#b5">[6]</ref>. LSI has been shown to be quite useful in uncovering latent relationships between columns of term-document matrices, thus allowing for more conceptual rather than exact term matching for query-based document retrieval (see <ref type="bibr" coords="5,528.42,414.56,12.33,11.97" target="#b2">[3,</ref><ref type="bibr" coords="5,545.00,414.56,8.44,11.97" target="#b6">7]</ref>). The goal was to use the SVD to help uncover latent redundancy amongst the relevant sentences. Given A ∈ R m×n , let k = min(m, n). Then the SVD of A <ref type="bibr" coords="5,372.37,443.45,18.18,11.97" target="#b9">[10]</ref> is defined by orthogonal vectors u i of length m, and orthogonal vectors v i of length n, i = 1, . . . , k, and nonnegative numbers</p><formula xml:id="formula_3" coords="5,58.32,472.34,291.89,50.80">σ 1 ≥ σ 2 ≥ ... ≥ σk ≥ 0, such that A = k i=1 σ i u i v T i .</formula><p>As described in <ref type="bibr" coords="5,153.02,528.80,17.14,11.97" target="#b10">[11]</ref>, the rank-k matrix (k ≤ k) that gives the optimal approximation to a given matrix A (as measured in the 2-norm or Frobenius norm) is</p><formula xml:id="formula_4" coords="5,263.46,563.86,96.79,36.02">ÃSV D = k i=1 σ i u i v T i .</formula><p>The rank k was determined empirically for this application and corresponds to a preassigned small error.</p><p>A QR decomposition, with or without pivoting, can be applied either to the weighted termsentence matrix A w = A or the lower rank approximation of A w = ÃSV D . The QR decomposition was used to determine whether a sentence should be considered new or redundant. In the QR factorization a sentence was considered redundant if the vector corresponding to it was of small weight, say less than τ, a predefined threshold. Specifically, we developed the following algorithms for selecting new, or novel, sentences. Algorithm 4.1 (Thresholded QR Decomposition) Suppose A w has m rows and n columns: i.e., the document has m unique terms and n sentences. The following iteration constructs a matrix Q with columns q i , a matrix R with nonzero elements r ji , and an ordering for the columns in an array Index.</p><p>For i = 1, 2, . . . , min(m, n),</p><p>Among the remaining columns of A w , choose the first column with 2-norm greater than τ . Denote this column by a , where is its index in the original matrix.</p><p>Set Index i = .</p><p>Set q i = a / a .</p><p>Update the remaining columns of A w to make them orthogonal to the chosen column: for each unchosen column a j , set r ji = a T j q i and set a j = a j -r ji q i . The set of "new" sentences of size k contains sentences Index 1 , . . . , Index k .</p><p>The standard implementation of the pivoted QR decomposition is a "Gram-Schmidt" process and was used to select new sentences as follows.</p><p>Algorithm 4.2 (Pivoted QR Decomposition) Suppose A w has m rows and n columns: i.e., the document has m unique terms and n sentences. The following iteration constructs a matrix Q with columns q i , a matrix R with nonzero elements r ji , and an ordering for the columns in an array Index.</p><p>For i = 1, 2, . . . , min(m, n),</p><p>Among the remaining columns of A w , choose the column with maximal norm. Denote this column by a , where is its index in the original matrix.</p><p>Set Index i = .</p><p>Set q i = a / a .</p><p>Update the other columns of A w to make them orthogonal to the chosen column: for each unchosen column a j , set r ji = a T j q i and set a j = a j -r ji q i . The set of "new" sentences of size k contains sentences Index 1 , . . . , Index k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>For Task 1 the HMM used for TREC was trained using the marked relevant and new sentences in the Novelty data from TREC 2002. Specifically, for Task 1 three models were built. The first focused on only the novel sentences. To strengthen the model further a subset of the novel sentences were chosen by hand for 24 of the document sets. This process removed many sentences that did not convey relevant information when taken out of their original context. These data were then used to build an HMM to score the sentences and determine which features should be included. This was the model that our group used in DUC 2003 and in the entries labeled ccsummeoqr and ccsummeosvd for Task 1.</p><p>A second model used the subset of the data from the LA Times articles only. It was hoped that this subset was more representative of the TREC 2003 data than the complete collection from TREC 2002. One entry for Task 1 used this model and was labeled ccsumlaqr.</p><p>The third model was based on all of the relevant sentences from TREC 2002. For Task 1 the given relevant sentences were used to build the HMM and the entries were labeled ccsumrelqr and ccsumrelsvd.</p><p>Note that for Task 1 the suffixes "svd" and "qr" denote the results using a truncated SVD followed by a pivoted QR and those using just a pivoted QR, respectively.</p><p>All three models for extracting relevant sentences performed comparably and unfortunately, generated fewer sentences than the human judges did in 2003, since they were predicting relevant sentences based upon the smaller number of sentences selected by the judges in 2002.</p><p>For the task of selecting the new sentences given a list of putative relevant sentences and only TREC 2002 data, it appears that the preprocessing by using a truncated SVD was not worthwhile. The two SVD methods gave median F 1 scores below those given by the pivoted QR method. The results of extracting relevant and new sentences for Task 1 are presented in Tables <ref type="table" coords="7,518.92,291.63,5.85,11.97" target="#tab_1">2</ref> and<ref type="table" coords="7,552.81,291.63,4.54,11.97" target="#tab_2">3</ref>, respectively. In Task 2 we were given the relevant sentences and had to determine the new sentences. We submitted 4 approaches: an SVD followed by a pivoted QR (ccsum2svdpqr ), an SVD followed by a thresholded QR (ccsumt2svdqr ), a pivoted QR (ccsumt2pqr ), and a thresholded QR (ccsumt2qr ). The thresholded QR was added for this task, since all the relevant sentences were known and a thresholded QR was thought to more closely simulate how a human would perform the task by scanning the sentences in order and deleting those that were redundant. All of these methods performed comparably and tended to give relatively high recall (see Table <ref type="table" coords="8,447.17,147.17,4.54,11.97" target="#tab_3">4</ref>). It is interesting to note that the pivoted QR appears to have a considerably higher median rank for F 1 relative to the peer systems, despite its median precision, recall and F 1 being comparable with the other 3 entries. Overall, our system performed comparably with the best systems, which also generated F 1 scores around 0.80.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Median Precision Median Recall</head><p>In Tasks 3 and 4 we were given the relevant and new sentences for the first 5 documents of each of the document sets. We realized after submitting our results that we should not have included any sentences from these first 5 documents, even if they were correct, since the scoring script was keying on only documents from the last 20 in each document set. As a result of our submission error our precision numbers were penalized. Therefore, for Tasks 3 and 4, we present here tables giving the corrected results (Tables <ref type="table" coords="8,240.66,291.63,5.85,11.97" target="#tab_5">6</ref> and<ref type="table" coords="8,272.48,291.63,5.19,11.97" target="#tab_7">8</ref>) as well as the results of those submitted (Tables <ref type="table" coords="8,533.62,291.63,5.85,11.97" target="#tab_4">5</ref> and<ref type="table" coords="8,58.32,306.08,4.54,11.97" target="#tab_6">7</ref>). The former are a true reflection of the performance of our submitted methods, while the latter is a "monument" reminding us to read submission rules carefully!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Median Precision Median Recall Median F For Task 3 we were given the relevant and new sentences for the first 5 documents of each document set. We built a single HMM based on these relevant sentences for our methods using a pivoted QR (ccsum3pqr ), a thresholded QR (ccsum3qr ), and an SVD followed by a pivoted QR (ccsum3svdpqr ). Consequently, the precision, recall, and rank for our three entries were the same (see Table <ref type="table" coords="8,115.50,606.31,4.54,11.97" target="#tab_5">6</ref>). Our method for estimating the length based upon expected F1 score appeared to want to "go long,... very long," thus, giving a median recall of 93. In contrast, the models used in Task 1 generated too few sentences. Still the overall F 1 score was 66 (for the corrected submissions), which was comparable to the best scoring systems as given in the overview of the results of the Novelty Track evaluation (see Figure <ref type="figure" coords="8,250.53,664.10,5.85,11.97">8</ref> in <ref type="bibr" coords="8,273.92,664.10,17.31,11.97" target="#b15">[16]</ref>).</p><p>For the second part of Task 3, selecting the new sentences based on the predicted relevant sentences, the method of pivoted QR nudged out the thresholded QR and the SVD followed by a pivoted QR (see Table <ref type="table" coords="8,186.88,707.43,4.54,11.97" target="#tab_7">8</ref>). For Task 4 we were given all relevant sentences and the new sentences from the first 5 documents in each set. Here, we attempted to optimize the thresholds for both the truncated SVD and the pivoted QR based on the given new sentences. In Table <ref type="table" coords="9,345.61,308.39,4.54,11.97" target="#tab_8">9</ref>, ccsum4spq001 refers to the entry with a threshold set to 0.001 while ccsumt4sqr01 refers the the entry using a threshold of 0.01. The smaller threshold resulted in fewer new sentences, although it did not increase the median precision and did reduce the recall, which resulted in a lower F 1 score. Of the group of entries, the pivoted QR did the best. Its shining virtue was that it did not miss a single new sentence; however it did generate nearly twice the number that the judges did. Also, the precision of these methods is generally lower than in Task 2, which indicates that the tuning of the model based on the new sentences from the first 5 documents did not help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Median Precision Median Recall</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Median Precision Median Recall Median F </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,105.49,227.84,409.36,11.97"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Markov Chain to Extract 2 Lead Sentences and Supporting Sentences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,58.32,87.95,503.59,312.92"><head>Table 1 :</head><label>1</label><figDesc>Mapping SGML tags to stype values. All tags not shown but allowed by each DTD are assigned stype = -1.</figDesc><table coords="3,133.97,87.95,352.55,261.53"><row><cell>File</cell><cell>DTD</cell><cell>Filename</cell><cell>SGML Tag</cell><cell>stype</cell></row><row><cell cols="2">APW* ACQUAINT</cell><cell cols="2">acquaint.dtd &lt;TEXT&gt;</cell><cell>1</cell></row><row><cell>NYT*</cell><cell></cell><cell></cell><cell>&lt;HEADLINE&gt;</cell><cell>0</cell></row><row><cell>XIE*</cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell cols="2">FBIS* FBIS</cell><cell>fbis.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;TI&gt;</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;H1&gt;, . . . , &lt;H8&gt;</cell><cell>0</cell></row><row><cell>FR*</cell><cell cols="2">Federal Register fr.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;SUMMARY&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;SUPPLEM&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;FOOTNOTE&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;DOCTITLE&gt;</cell><cell>0</cell></row><row><cell>FT*</cell><cell cols="2">Financial Times ft.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;HEADLINE&gt;</cell><cell>0</cell></row><row><cell>LA*</cell><cell>LA Times</cell><cell>latimes.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;HEADLINE&gt;</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;SUBJECT&gt;</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;GRAPHIC&gt;</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,100.09,329.39,420.10,213.57"><head>Table 2 :</head><label>2</label><figDesc>Performance of CCSUM on Task 1: Relevant Sentences; 55 Total Entries</figDesc><table coords="7,376.59,329.39,133.45,12.75"><row><cell>Median F 1 Median Rank</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,107.96,553.53,403.38,103.95"><head>Table 3 :</head><label>3</label><figDesc>Performance of CCSUM on Task 1: New Sentences; 55 Total Entries</figDesc><table coords="7,107.96,587.34,403.38,70.14"><row><cell>Run</cell><cell cols="4">Median Precision Median Recall Median F 1 Median Rank</cell></row><row><cell>ccsum2svdpqr</cell><cell>70</cell><cell>90</cell><cell>78</cell><cell>19</cell></row><row><cell>ccsumt2svdqr</cell><cell>69</cell><cell>92</cell><cell>80</cell><cell>15</cell></row><row><cell>ccsumt2pqr</cell><cell>70</cell><cell>95</cell><cell>80</cell><cell>9</cell></row><row><cell>ccsumt2qr</cell><cell>69</cell><cell>92</cell><cell>80</cell><cell>15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,109.12,668.06,398.17,11.97"><head>Table 4 :</head><label>4</label><figDesc>Performance of CCSUM on Task 2: New Sentences; 45 Total Entries</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,102.69,347.19,414.90,162.48"><head>Table 5 :</head><label>5</label><figDesc>Performance of CCSUM on Task 3:Relevant Sentences; 38 Total Entries</figDesc><table coords="8,427.27,347.19,84.07,12.75"><row><cell>1 Median Rank</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,75.70,520.25,468.83,11.97"><head>Table 6 :</head><label>6</label><figDesc>Corrected Performance of CCSUM on Task 3:Relevant Sentences; 38 Total Entries</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,107.96,87.95,403.38,146.77"><head>Table 7 :</head><label>7</label><figDesc>Median F 1 Median Rank Performance of CCSUM on Task 3:New Sentences; 38 Total Entries</figDesc><table coords="9,107.96,102.79,403.38,131.93"><row><cell>ccsum3pqr</cell><cell>26</cell><cell>91</cell><cell>41</cell><cell>21</cell></row><row><cell>ccsum3qr</cell><cell>25</cell><cell>94</cell><cell>38</cell><cell>24</cell></row><row><cell>ccsum3svdpqr</cell><cell>26</cell><cell>89</cell><cell>41</cell><cell>22</cell></row><row><cell>Run</cell><cell cols="4">Median Precision Median Recall Median F 1 Median Rank</cell></row><row><cell>ccsum3pqr</cell><cell>33</cell><cell>91</cell><cell>48</cell><cell>11</cell></row><row><cell>ccsum3qr</cell><cell>30</cell><cell>94</cell><cell>44</cell><cell>15</cell></row><row><cell>ccsum3svdpqr</cell><cell>32</cell><cell>89</cell><cell>47</cell><cell>12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,86.68,245.29,446.89,11.97"><head>Table 8 :</head><label>8</label><figDesc>Corrected Performance of CCSUM on Task 3:New Sentences; 38 Total Entries</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,86.68,436.30,446.89,107.13"><head>Table 9 :</head><label>9</label><figDesc>Corrected Performance of CCSUM on Task 4:New Sentences; 41 Total Entries</figDesc><table coords="9,427.44,436.30,84.07,12.75"><row><cell>1 Median Rank</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,82.36,613.66,479.52,11.97;9,82.39,628.11,479.50,11.97;9,82.39,642.55,205.55,11.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,383.16,613.66,178.72,11.97;9,82.39,628.11,91.99,11.97">A Scalable Summarization System Using Robust NLP</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Aone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gorlinsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,205.76,628.11,356.13,11.97;9,82.39,642.55,100.98,11.97">Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on Intelligent Scalable Text Summarization</title>
		<meeting>the ACL&apos;97/EACL&apos;97 Workshop on Intelligent Scalable Text Summarization</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,82.36,666.96,479.52,11.97;9,82.39,681.41,479.46,11.97;9,82.39,695.85,51.31,11.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,333.40,666.96,228.48,11.97;9,82.39,681.41,328.63,11.97">A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Petrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Soules</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,428.19,681.41,86.54,11.97">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="164" to="171" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,89.39,479.49,11.97;10,82.39,103.83,287.11,11.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,368.72,89.39,193.13,11.97;10,82.39,103.83,108.58,11.97">Using Linear Algebra for Intelligent Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>O'brien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,201.08,103.83,54.84,11.97">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="573" to="595" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,128.00,479.53,11.97;10,82.39,142.45,479.45,11.97;10,82.39,156.89,66.25,11.97" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,228.82,128.00,333.07,11.97;10,82.39,142.45,113.12,11.97">Text Summarization via Hidden Markov Models and Pivoted QR Matrix Decomposition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-03">March, 2001</date>
			<pubPlace>College Park, Maryland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="10,82.36,181.06,479.47,11.97;10,82.39,195.50,438.55,11.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,378.38,181.06,183.45,11.97;10,82.39,195.50,205.96,11.97">Using HMM and Logistic Regression to Generate Extract Summaries for DUC</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,322.27,195.50,163.04,11.97">DUC 01 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,219.67,479.53,11.97;10,82.39,234.11,479.54,11.97;10,82.39,248.56,104.58,11.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,82.39,234.11,188.83,11.97">Indexing by Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,279.73,234.11,277.08,11.97">Journal of the American Society of Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,272.72,479.52,11.97;10,82.39,287.17,356.63,11.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,169.36,272.72,330.48,11.97">Improving the Retrieval of Information from External Sources</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,516.49,272.72,45.39,11.97;10,82.39,287.17,242.30,11.97">Behavior Research Methods, Instruments, and Computers</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="229" to="326" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,311.34,479.48,11.97;10,82.39,325.79,479.53,11.97;10,82.39,340.23,198.67,11.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,144.05,325.79,386.85,11.97">Performance of a Three-Stage System for Multi-Document Summarization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dunlavy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Van Halteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,82.39,340.23,163.04,11.97">DUC 03 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,364.40,479.49,11.97;10,82.39,378.84,140.19,11.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,158.19,364.40,311.20,11.97">Accurate Methods for Statistics of Surprise and Coincidence</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,486.92,364.40,74.93,11.97;10,82.39,378.84,53.49,11.97">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,403.01,479.56,11.97;10,82.39,417.45,440.34,11.97" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,305.14,403.01,245.43,11.97">Rank Degeneracy and Least Squares Problems</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Klema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Stewart</surname></persName>
		</author>
		<idno>No. TR-456</idno>
		<imprint>
			<date type="published" when="1976">1976</date>
			<pubPlace>College Park, Maryland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="10,82.36,441.62,479.53,11.97;10,82.39,456.06,174.08,11.97" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,238.56,441.62,108.61,11.97">Matrix Computations</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">V</forename><surname>Loan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>The Johns Hopkins University Press</publisher>
			<pubPlace>Baltimore, MD</pubPlace>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct coords="10,82.36,480.23,479.54,11.97;10,82.39,494.68,479.51,11.97;10,82.39,509.13,147.46,11.97" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,281.93,480.23,177.50,11.97">A Trainable Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kupiec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,490.20,480.23,71.70,11.97;10,82.39,494.68,479.51,11.97;10,82.39,509.13,43.78,11.97">Proceedings of the 18th Annual International SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 18th Annual International SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,533.29,479.47,11.97;10,82.39,547.74,124.48,11.97;10,206.97,546.76,7.93,7.24;10,220.18,547.74,341.83,11.97;10,82.39,562.18,62.40,11.97" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,191.93,533.29,358.37,11.97">The Automatic Acquisition of Topic Signatures for Text Summarization</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,97.64,547.74,109.23,11.97;10,206.97,546.76,7.93,7.24;10,220.18,547.74,341.83,11.97;10,82.39,562.18,26.56,11.97">Proceedings of the 18 th International Conference on Computational Liguistics (COLLING 2000)</title>
		<meeting>the 18 th International Conference on Computational Liguistics (COLLING 2000)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,586.35,479.54,11.97;10,82.39,600.79,158.23,11.97" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,155.11,586.35,331.29,11.97">A Tutorial on Hidden Markov Models and Selected Applications</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,503.64,586.35,58.26,11.97;10,82.39,600.79,58.36,11.97">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="257" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,624.96,479.42,11.97;10,82.39,639.40,479.55,11.97;10,82.39,653.85,358.85,11.97" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,88.17,639.40,473.77,11.97;10,82.39,653.85,128.83,11.97">Understanding Machine Performance in the Context of Human Performance for Multidocument Summarization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,242.57,653.85,163.04,11.97">DUC 02 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,82.36,678.02,479.51,11.97;10,82.39,692.47,311.83,11.97" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,224.93,678.02,216.92,11.97">Overview of the TREC 2003 Novelty Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,471.32,678.02,90.54,11.97;10,82.39,692.47,250.30,11.97">Proceedings of the Twelfth Text REtrieval Conference (TREC 2003)</title>
		<meeting>the Twelfth Text REtrieval Conference (TREC 2003)</meeting>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
