<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,82.68,31.14,446.16,12.91;1,279.48,45.66,53.11,12.91">Passage Scoring for Question answering via Bayesian inference on lexical relations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.04,59.65,79.21,10.76"><forename type="first">Deepa</forename><surname>Paranjpe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engg</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.91,59.65,114.64,10.76"><forename type="first">Ganesh</forename><surname>Ramakrishnan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engg</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,363.64,59.65,99.05,10.76"><forename type="first">Sumana</forename><surname>Srinivasan</surname></persName>
							<email>sumana@it.iitb.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engg</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,82.68,31.14,446.16,12.91;1,279.48,45.66,53.11,12.91">Passage Scoring for Question answering via Bayesian inference on lexical relations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">10AA3B2FFAF8821F57DF598B1517E189</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many researchers have used lexical networks and ontologies to mitigate synonymy and polysemy problems in Question Answering (QA), systems coupled with taggers, query classifiers, and answer extractors in complex and ad-hoc ways. We seek to make QA systems reproducible with shared and modest human effort, carefully separating knowledge from algorithms. To this end, we propose an aesthetically "clean" Bayesian inference scheme for exploiting lexical relations for passage-scoring for QA . The factors which contribute to the efficacy of Bayesian Inferencing on lexical relations are soft word sense disambiguation, parameter smoothing which ameliorates the data sparsity problem and estimation of joint probability over words which overcomes the deficiency of naive-bayes-like approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes an approach to probabilistic inference using lexical relations, such as expressed by a WordNet, an ontology, or a combination, with applications to passage-scoring for open-domain question answering (QA).</p><p>The use of lexical resources in Information Retrieval (IR) is not new; for almost a decade, the IR community has considered the use of natural language processing techniques <ref type="bibr" coords="1,217.25,479.41,80.84,9.82;1,72.00,491.77,25.15,9.82" target="#b9">(Lewis and Jones, 1996)</ref> to circumvent synonymy, polysemy, and other barriers to purely string-matching search engines. In particular, a number of researchers have attempted to use the English WordNet to "bridge the gap" between query and response. Interestingly, the results have mostly been inconclusive or negative <ref type="bibr" coords="1,274.17,553.45,20.05,9.82;1,72.00,565.69,57.84,9.82">(Fellbaum, 1998a)</ref>. A number of explanations have been offered for this lack of success, some of which are ¢ presence of unnecessary links and absence of necessary links in the WordNet <ref type="bibr" coords="1,251.00,614.77,47.29,9.82;1,93.84,627.13,28.53,9.82">(Fellbaum, 1998b)</ref>, ¢ hurdle of Word Sense Disambiguation (WSD) <ref type="bibr" coords="1,93.84,662.65,79.51,9.82" target="#b12">(Sanderson, 1994)</ref> ¢ ad-hocness in the distance and scoring functions <ref type="bibr" coords="1,358.87,136.57,74.38,9.82" target="#b0">(Abe et al., 1996)</ref>.</p><p>2 Proposed approach 2.1 An inferencing approach to QA Given a question and a passage that contains the answer, how do we correlate the two ? Take for example, the following question What type of animal is Winnie the Pooh? and the answer passage is A Canadian town that claims to be the birthplace of Winnie the Pooh wants to erect a giant statue of the famous bear; but Walt Disney Studios will not permit it.</p><p>It is clear that there is a linkage between the question word animal and the answer word bear. That the word bear occurred in the answer, in the context of Winnie, means that there was a hidden "cause" for the occurrence of bear, and that was the concept of £ animal¤ .</p><p>In general, there could be multiple words in the question and answer that are connected by many hidden causes. The causes themselves may have hidden causes associated with them. These causal relationships are represented in ontologies and Word-Nets. The familiar English WordNet, in particular, encodes relations between words and concepts. For instance WordNet gives the hypernymy relation between the concepts £ animal¤ and £ bear¤ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">WordNet</head><p>WordNet <ref type="bibr" coords="1,355.60,527.05,75.62,9.82">(Fellbaum, 1998b</ref>) is an online lexical reference system in which English nouns, verbs, adjectives and adverbs are organized into synonym sets or synsets, each representing one underlying lexical concept. Noun synsets are related to each other through hypernymy (generalization), hyponymy (specialization), holonymy (whole of) and meronymy (part of) relations. Of these, (hypernymy, hyponymy) and (meronymy,holonymy) are complementary pairs.</p><p>The verb and adjective synsets are very sparsely connected with each other. No relation is available between noun and verb synsets. However, 4500 adjective synsets are related to noun synsets with pertainyms (pertaining to) and attra (attributed with) relations.</p><p>For example, the synset £ dog, domestic dog, canis familiaris¤ has a hyponymy link to £ corgi, welshcorgi¤ and meronymy link to £ flag¤ ("a conspicuously marked or shaped tail"). While the hyponymy link helps us answer the question (TREC#371) "A corgi is a kind of what?", the meronymy connection here is perhaps more confusing than useful: this sense of flag is rare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Inferencing on lexical relations</head><p>It is surprisingly difficult to make the simple idea of bridging passage to query through lexical networks perform well in practice. Continuing the example of Winnie the bear (section 2.1), the English WordNet has five synsets on the path from bear to animal: £ carnivore...¤ , £ placental mammal...¤ , £ mammal...¤ , £ vertebrate..¤ , £ chordate...¤ . Some of these intervening synsets would be extremely unlikely to be associated with a corpus that is not about zoology; a common person would more naturally think of a bear as a kind of animal, skipping through the intervening nodes.</p><p>It is, however, dangerous to design an algorithm which is generally eager to skip across links in a lexical network. E.g., few QA applications are expected to need an expansion of "bottle" beyond "vessel" and "container" to "instrumentality" and beyond. Another example would be the shallow verb hierarchy in the English WordNet, with completely dissimilar verbs within very few links of each other. There is also the problem of missing links.</p><p>Another important issue is which 'hidden causes' (synsets) should be inferred to have caused words in the text. This is a classical problem called word sense disambiguation (WSD). For instance, the word dog belongs to 6 noun synsets in Word-Net. Which of the ¡ synsets should be treated as the 'hidden cause' that generated the word dog in the passage could be inferred from the fact that collie is related to dog only through one of the latter's senses -it's sense as £ dog, domestic dog, Canis familiaris¤ . But this problem of finding the 'appropriate' hidden causes, in general, in non-trivial. Given that state-ofthe-art WSD systems perform not better than 74% <ref type="bibr" coords="2,72.00,625.69,81.66,9.82" target="#b12">(Sanderson, 1994)</ref>  <ref type="bibr" coords="2,158.23,625.69,49.94,9.82" target="#b9">(Lewis and</ref><ref type="bibr" coords="2,212.73,625.69,81.49,9.82;2,72.00,638.05,59.19,9.82">Jones, 1996) (Fellbaum, 1998b)</ref>, in this paper, we use a probabilistic approach to WSD -called 'soft WSD' (Pushpak, ) ; hidden nodes are considered to have probabilisti-cally 'caused' words in the question and answer or in other words, causes are probabilistically 'switched on'.</p><p>Clearly, any scoring algorithm that seeks to utilize WordNet link information must also discriminate between them based (at least) on usage statistics of the connected synsets. Also required is an estimate of the likelihood of instantiating a synset into a token because it was "activated" by a closely related synset. We find a Bayesian belief network (BBN) a natural structure to encode such combined knowledge from WordNet and corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Bayesian Belief Network</head><p>A Bayesian Network <ref type="bibr" coords="2,406.51,205.21,84.07,9.82" target="#b6">(Heckerman, 1995)</ref> for a set of random variables ¢ ¤£ £ ¥¢ §¦ ¥©¢ ©¢ ¤ consists of a directed acyclic graph (DAG) that encodes a set of conditional independence assertions about variables in ¢ and a set of local probability distributions associated with each variable. Let "! denote the set of immediate parents of ¢ #! in the DAG, and $ % ! a specific instantiation of these random variables.</p><p>The BBN encodes the joint distribution</p><formula xml:id="formula_0" coords="2,313.50,295.05,226.35,82.30">&amp; (' ) 10 ¦ ¥¨0 2¨0 43 as &amp; (' 5) 10 ¦ ¥¨0 5 2¨0 43 6£ 7 ! 98 @¦ &amp; (' ) 10 ! BA $ % ! 3 (1)</formula><p>Each node in the DAG encodes &amp; (' 5) 10 ! ©A $ % ! 3 as a "conditional probability table" (CPT).</p><p>The idea of constructing BBN from WordNet has been proposed by <ref type="bibr" coords="2,393.81,426.37,69.71,9.82" target="#b14">(Rebecca, 1998)</ref>. But that idea is centered around doing hard-sense disambiguationto find the 'correct' sense each word in the text.</p><p>In this paper, we particularly explore the idea of doing soft sense disambiguation i.e. synsets are probabilistically considered to be causes of their constituent words. Moreover, WSD is not an end in itself. The goal is to connect the words within question and answer passage and also across the question and answer passage. WSD is only a by-product.</p><p>Our goal is to build a QA system which implements a clear division of labor between the knowledge base and the scoring algorithm, codifies the knowledge base in a uniform manner, and thereby enables a generic algorithm and a shared, extensible knowledge base. Based on the discussion above, our knowledge representation must be probabilistic, and our system must combine and be robust to multiple, noisy sources of information from query and answer terms.</p><p>Moreover, we would like to be able to learn important properties of our knowledge base from continual training of our system with corpus samples as well as samples of successful and unsuccessful (question, answer) pairs. In essence, we would like to automate as far as possible, the customization of lexical networks to QA tasks. Given the English WordNet, it should be possible to reconstruct our algorithm completely from this paper.</p><p>Toward these ends, we describe how to induce a Bayesian Belief Network (BBN) from a lexical network of relations. Specifically, we propose a semi-supervised learning mechanism which simultaneously trains the BBN and associates text tokens ,which are words, to synsets in the WordNet in a probabilistic manner ("soft WSD"). Finally, we use the trained BBN to score passages in response to a question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Building a BBN from WordNet</head><p>Our model of the BBN is that each synset from WordNet is a boolean event associated with a question, a passage, or both. Textual tokens are also events. Each event is a node in the BBN. Events can cause other events to happen in a probabilistic manner, which is encoded in CPTs. The specific form of CPT we use is the well-known noisy-OR of Pearl <ref type="bibr" coords="3,72.00,364.21,54.73,9.82" target="#b10">(Pearl, 1988)</ref>.</p><p>We introduce a node in the BBN for each noun, verb, and adjective synset in WordNet. We also introduce a node for each (non-stop-word) token in the corpus and all questions. Hyponymy, meronymy, and attribute links are introduced from WordNet. Sense links are used to attach tokens to potentially matching synsets. E.g., the string "flag" may be attached to synset nodes £ sag, droop, swag, flag¤ and £ a conspicuously marked or shaped tail¤ . (The purpose of probabilistic disambiguation is to estimate the probability that the string "flag" was caused by each connected synset node.)</p><p>This process creates a hierarchy in which the parent-child relationship is defined by the semantic relations in WordNet. is a parent of ¡ iff is the hypernym or holonym or attribute-of or is a synset containing the word ¡ . The process by which the Bayesian Network is built from the WordNet hypergraph of synsets and and from the mapping between words and synsets is depicted in figure <ref type="figure" coords="3,243.01,612.49,4.07,9.82" target="#fig_0">1</ref>. We define going-up the hierarchy as the traversal from child to parent.</p><p>Ideally, we should update the entire BBN and its CPTs while scanning over the training corpus. In practice, BBN training and inference are CPU-and memory-intensive processes.</p><p>We compromise by first attaching the token nodes to their synsets and then walking up the WordNet hierarchy up to a maximum height decided purely by CPU and memory limitations. We believe that the probabilistic influence from distant nodes is too feeble and unreliable to warrant modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our QA system</head><p>The overall question answering system that we propose is depicted in figure <ref type="figure" coords="3,424.81,368.41,4.07,9.82" target="#fig_1">2</ref>. The question triggers the TFIDF retrieval module to pick up 50 most relevant documents. These documents are subjected to a sliding window to produce ¢ passages of length £ each. The Bayesian belief network described in section 2.5 ranks these passages. The first ranked passage is supposed to contain the answer. The belief network parameters are the CPTs, which are initialized as noisy-or CPTs. The Bayesian belief network is trained offline using the Expectation Maximization algorithm <ref type="bibr" coords="3,491.26,650.29,48.01,9.82;3,313.20,662.65,25.15,9.82" target="#b15">(Dempster, 1977)</ref> on windows sliding over the whole corpus.</p><p>1: while CPTs do not converge do 2: for each window of words in the text do 3:</p><p>Clamp the word nodes in the Bayesian Network to a state of 'present' 4:</p><p>for each node in Bayesian network do 5:</p><p>find its joint probabilities with all configurations of its parent nodes (E Step) 6: end for 7: end for 8: Update the conditional probability tables for all random variables (M Step) 9: end while Figure <ref type="figure" coords="4,114.58,138.26,3.48,8.07">3</ref>: Training the Bayesian Network for a corpus</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training the belief network</head><p>The figure <ref type="figure" coords="4,120.03,189.25,5.39,9.82">3</ref> describes the algorithm for training the BBN obtained from the WordNet. We initialize the CPTs as noisy-or. The instances we use for training are windows of length ¡ each from the corpus. Since the corpus is normally not tagged with WordNet senses, all variables, other than the words observed in the window (i.e. the synset nodes in the BBN) are hidden or unobserved. Hence we use the Expectation Maximization algorithm <ref type="bibr" coords="4,250.06,287.89,48.01,9.82;4,72.00,300.25,25.15,9.82" target="#b15">(Dempster, 1977)</ref> for parameter learning. For each instance, we find the expected values of the hidden variables, given the present state of each of the observed variables. These expected values are used after each pass through the corpus to update the CPT for each node. The iterations through the corpus are done till the sum of the squares of Kullback-Liebler divergences between CPTs in successive iterations do not differ more than a threshold, or in other words, till the convergence criterion is met. Figure <ref type="figure" coords="4,272.09,411.25,5.39,9.82">3</ref> outlines the algorithm for training the Bayesian Network over a corpus. We basically customize the Bayesian Network CPTs to a particular corpus by learning the local CPTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ranking answer passages</head><p>Given a question, we rank the passages with the joint probability of the question words, given the candidate answer. Every question or answer can be looked upon as an event in which the its word nodes are switched to the state 'present'. Therefore, if ¢ ¦ £¢ ¢ are passages and ¤ is the ques- tion, the answer is that passage ¢ "! which maximizes ¥ #) ¤ A ¢ ! 3 over all passages ¢ ! deemed as candidate an- swers. &amp; (' ) ¤ A ¢ ! 3 is the joint probability of the words of ¤ , each being in state 'present' in the Bayesian network, given that all the word nodes for ¢ ! are clamped to the state 'present' in the belief network. Figure <ref type="figure" coords="4,108.65,650.29,5.39,9.82" target="#fig_2">4</ref> outlines the actual passage ranking algorithm.</p><p>1: Load the Bayesian Network parameters 2: for each question q do 3: for each candidate passage p do 4: clamp the variables (nodes) corresponding to the passage words in network to a state of 'present' 5:</p><p>Find the joint probability of all question words being in state 'present' i.e., ¦ ¨ § © 6: end for 7: end for 8: Report the passages in decreasing order of ¦ § © &amp; (' ) ¢ ! BA ¤ 3 , therefore, may not help in bridging the re- lation between answer words. (b) The passage will be penalized if contains many words which are not present in the question and are also not closely related to the question words through the WordNet. This could happen despite the fact that the passage contains a few words which are all present in the question and/or are semantically closely related to the question, in addtion to containing the answer to the question. Also, (c) if passages ¢ ! 's are of varying lengths, &amp; (' 2) ¤ A ¢ ! 3 's are brought to the same scale-that of question words which are fixed across passages/snippets, whereas, &amp; (' 2) ¢ "! BA ¤ 3 can be affected and penalized by long snippets.</p><p>In fact, our apprehensions about using &amp; ' ) ¢ "! A ¤ 3 will be justified in the experimental section -the QA performace obtained using &amp; (' ) ¢ "! A ¤ 3 is drasti- cally poorer -in fact it is worse than the baseline QA algorithm.</p><p>Dealing with non-WordNet words: Suppose, there is a word in the question which is not there in the WordNet. Like the answer passages, we could have ignored such words. But, the question may be seeking an answer to precisely such a word. Also, the number of words being very small in the question, no word in the question should be ignored. We deal with this situation in the following way. We call a word, a connecting word if it the key word that links the passage to the question. Note that for WordNet words, the connecting nodes were Word-Net concepts. In the case of non-WordNet words, we don't have any hidden, connecting nodes. So we consider the words themselves to be possible connections. Let ! #" $ %$ '&amp; (! 0) 1 be a random variable which takes the state 'present' if is a connecting word between the question and the answer. It's state is 'absent' if it is not a connecting word. Let 2¤ , 3¢ be random variables that are 'present' if occurs in the question or answer respectively, else they are 'absent'.</p><p>By Bayes rule, we get the following probability that the word occurs in the question, given that it occurs in the answer (1=Present, 0=absent).</p><formula xml:id="formula_1" coords="5,73.70,74.50,217.80,113.05">¦ ¨ § © ¡ ' £¢ ¤ ¥¢ ¤ §¦ ¦ ¨ § © ¡ ' ¨¢ ¤ © © ¢ ¤ "! ¦ ¨ § © ¡ #¢ ¤ © $ % &amp;© ' ¢ ¤ ! ¦ § © ¡© © ( )¢ ¤ 10 ¦ ¨ § © ¡ ' ¨¢ 32 © © ¢ 32 0 "! ¦ ¨ § © ¡ #¢ 32 © $ % &amp;© ' ¢ 32 # ! ¦ § © ¡© $ % © ( )¢ )2 #</formula><p>where</p><formula xml:id="formula_2" coords="5,72.00,193.35,226.80,56.60">¥ 54 ) ! #" $ %$ '&amp; ! 0) £ 6 3 , ¥ 74 ) 2¤ £ 6 A ! #" $ %$ '&amp; ! 0) 1 £ 86 3 , ¥ 74 ) 3¢ £ 96 A ! #" $ %$ '&amp; ! 0) £ 96 3 , and ¥ 74 ) ! #" $ %$ '&amp; ! 0) 1</formula><p>£ @6 3 and their complements are estimated from question answer pairs. Moreover, the occurrence of non WordNet words is assumed to be independent of each other and also of the occurrence of WordNet words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Use of Regular Expressions for passage Filtering</head><p>A study of the available question-answer pairs from the earlier TREC releases, helped us to identify patterns for filtering passages corresponding to every question type. The question type is identified for a group of question cue phrases. For every group, a regular expression is identified. A question cue phrase can belong to more than one group of cue phrases.</p><p>For example, the group of cue phrases that belong to the class of DURATION such as how long how often, how short, how frequently, how far how fast, how swift, how old and how new make it manditory for the answer to contain regular expressions such as A CB 5D FE (G . The regular expressions that were used were quite involved. A balance between general versus specific regular expression needs to be achieved since very general regular expressions do not serve any purpose in the answer phrase filtering while very specific regular expressions give a very low recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">BBN simplification</head><p>Following are some of our observations regarding the approach of Bayesian Inferencing for identifying the answer passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Observation on variety of dependency arcs in BBN</head><p>In the preliminary experiments with Bayesian Inferencing, we initialized all CPTs as noisyH or.</p><p>NoisyH or CPTs make sense for nodes which could be caused exclusively by one of the parents i.e.</p><p>when the occurrence of one parent event precludes the occurrence of other parent events. This is true for word nodes, whose parents are factually its different senses and occurrence of one sense of a word, precludes occurrence of its other senses. But this is not true for nodes that are synsets H the parents of such nodes are compositional in nature H the child is simultaneously the hyponym of some of its parents and the meronym of its other parents. Hence, we need to revamp our approach of using a noisyH or model for the entire network, from the leaf nodes corresponding to the words upto the root nodes. We propose to initialize the words nodes with noisyH or CPTs and synset nodes with noisyH and CPTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Observation on senses of a word</head><p>Our observation is that word senses as given by WordNet, or for that matter word senses given by any lexicon, are not completely orthogonal or unrelated. In fact, to different extents, word senses overlap and form softH clusters. We feel that any algorithm that attempts to exploit relations between word senses must explicitly take care of this fact. In doing bayesian inferencing with the whole network, we tried to capture this phenomenon implicitly through the idea of soft sense disambiguation. But this was at the cost of computationally and memory intensive algorithms. We are working in the direction of simplifying the network beforeH hand. We present some observations and a simple algorithm in pursuit of the goal.</p><p>The observation is that wordH senses with similar ancestral lineage have more overlap in their meanings than those with completely distinct ancestral lineages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and future work</head><p>We have described a passage-scoring algorithm for QA via Bayesian inference on lexical relations. By separating the inference algorithm from the design of the knowledge base, we made our system extensible and trainable from a corpus.</p><p>Our work hinges upon the existence of lexical relations in the WordNet. We would like to point out here that no special efforts were made in the construction of the Bayesian Network from WordNet nor did we attempt to fill in the desirable 'missing links' between words or synsets in WordNet or remove spurious links in WordNet. Thus, we are able to find probabilities based on semantic relations to the extent given by links in WordNet and we are able to uncorrelated words from each other to the extent they are disconnected in WordNet. To some extent, we attempt to learn the Bayesian Network parameters and this does result in improvement in Question Answering performance. But it will be interesting to see if training the network with bigger corpora improves the performance further. Another experiment that remains to be tried is training the Bayesian Network with samples of successful and unsuccessful (question, answer) pairs.</p><p>One thing to note is that if all the question words are contained in the passage, the passage will get a high rank because it will induce a joint probability score of 6 on the question. This can happen even if the answer is not contained in the passage.</p><p>Another limitation is the computational and memory cost. On an average it took 0.03 seconds for Bayesian inferencing on a passage. The memory requirement goes upto 30MB. One future work will comprise of reducing the online memory and computational requirements by simplifying the network structure and/or making certain computations offline.</p><p>We would also like to find better initial values to speed up learning and avoid local optima. We would like to re-introduce the notion of lexical proximity into our inference process, so as to further improve the accuracy of WSD. We also wish to explore how continual feedback and retraining of the BBN can improve the accuracy of our system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,313.20,167.18,226.67,8.07;3,313.20,176.30,25.43,8.07"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Building a BBN from WordNet and associated text tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,364.80,511.94,120.76,8.07"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall QA system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,329.52,122.18,193.92,8.07;4,324.12,154.33,109.22,9.82;4,438.10,132.25,38.91,29.40;4,454.00,156.55,5.10,7.00;4,460.10,139.75,5.10,29.40;4,461.50,156.55,5.10,7.00;4,461.50,139.75,16.60,29.40;4,479.52,154.33,18.92,9.82;4,502.90,132.25,26.32,29.40;4,518.00,156.55,5.00,7.00;4,524.20,139.75,9.40,29.40;4,530.80,156.55,5.00,7.00;4,536.30,139.75,5.00,29.40;4,313.20,166.69,226.25,9.82"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Ranking answer passages for given question The reason for choosing &amp; (' 2)¤ A ¢ "! 3 over &amp; ' ) ¢ ! A ¤ 3is that (a) ¤ typically contains very few words.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,72.00,521.78,226.53,8.07;6,82.92,531.74,215.63,8.07;6,82.92,541.70,172.46,8.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,201.76,521.78,96.77,8.07;6,82.92,531.74,114.48,8.07">Learning word association norms using tree cut pair models</title>
		<author>
			<persName coords=""><forename type="first">Naoki</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,214.24,531.74,84.31,8.07;6,82.92,541.70,168.57,8.07">Proceedings of the 13th International Conference on Machine Learning</title>
		<meeting>the 13th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,562.58,226.55,8.07;6,82.92,572.54,215.71,8.07;6,82.92,582.50,210.82,8.07" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,148.17,562.58,150.39,8.07;6,82.92,572.54,55.36,8.07">Implementation of the smart information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<idno>TR85- 686</idno>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,72.00,603.26,226.65,8.07;6,82.92,613.22,215.77,8.07;6,82.92,623.18,215.77,8.07;6,82.92,633.14,215.74,8.07;6,82.92,643.10,129.76,8.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,111.47,613.22,167.37,8.07">Exploiting redundancy in question answering</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,82.92,623.18,215.77,8.07;6,82.92,633.14,215.74,8.07;6,82.92,643.10,22.35,8.07">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="358" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,663.98,226.54,8.07;6,324.12,26.90,215.49,8.07;6,324.12,36.86,119.92,8.07" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,144.81,663.98,153.74,8.07;6,324.12,26.90,152.30,8.07">WordNet: An Electronic Lexical Database, chapter Using WordNet for Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>The MIT Press</publisher>
			<biblScope unit="page" from="285" to="303" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,55.82,226.78,8.07;6,324.12,65.78,95.81,8.07" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,423.19,55.82,116.80,8.07;6,324.12,65.78,32.41,8.07">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,84.74,226.64,8.07;6,324.12,94.70,215.72,8.07;6,324.12,104.66,215.65,8.07;6,324.12,114.62,215.86,8.07;6,324.12,124.58,152.88,8.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,448.73,104.66,91.04,8.07;6,324.12,114.62,88.28,8.07">Falcon: Boosting knowledge for answer engines</title>
		<author>
			<persName coords=""><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Vasile Rus</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Morarescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,433.36,114.62,106.62,8.07;6,324.12,124.58,107.43,8.07">Proceedings of the ninth text retrieval conference (TREC-9)</title>
		<meeting>the ninth text retrieval conference (TREC-9)</meeting>
		<imprint>
			<date type="published" when="2000-11">2000. November</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,143.54,226.53,8.07;6,324.12,153.50,191.02,8.07" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,416.45,143.54,123.28,8.07;6,324.12,153.50,32.83,8.07">A Tutorial on Learning Bayesian Networks</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
		<idno>MSR-TR-95-06</idno>
		<imprint>
			<date type="published" when="1995-03">1995. March</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,313.20,172.34,226.55,8.07;6,324.12,182.30,215.62,8.07;6,324.12,192.26,215.64,8.07;6,324.12,202.34,104.58,8.07" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,388.64,172.34,151.11,8.07;6,324.12,182.30,106.48,8.07">From sentence processing to information access on the world wide web</title>
		<author>
			<persName coords=""><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,439.12,182.30,100.62,8.07;6,324.12,192.26,190.46,8.07">AAAI Spring Symposium on Natural Language Processing for the World Wide Web</title>
		<meeting><address><addrLine>Stanford CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,221.18,226.55,8.07;6,324.12,231.14,215.75,8.07;6,324.12,241.10,215.63,8.07;6,324.12,251.06,33.35,8.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,324.12,231.14,140.32,8.07">Scaling question answering to the web</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Cody</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,485.31,231.14,54.57,8.07;6,324.12,241.10,188.33,8.07">Proceedings of the Tenth International World Wide Web Conference</title>
		<meeting>the Tenth International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="150" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,270.02,226.64,8.07;6,324.12,279.98,215.61,8.07;6,324.12,289.94,96.30,8.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,496.08,270.02,43.76,8.07;6,324.12,279.98,148.52,8.07">Natural language processing for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,479.17,279.98,60.57,8.07;6,324.12,289.94,38.17,8.07">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="101" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,308.90,226.67,8.07;6,324.12,318.86,215.75,8.07;6,324.12,328.82,41.49,8.07" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="6,370.53,308.90,169.34,8.07;6,324.12,318.86,116.36,8.07">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan Kaufmann Publishers, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,347.78,226.66,8.07;6,324.12,357.74,215.74,8.07;6,324.12,367.70,215.64,8.07;6,324.12,377.66,98.33,8.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,429.54,347.78,110.33,8.07;6,324.12,357.74,47.75,8.07">A maximum entropy part-ofspeech tagger</title>
		<author>
			<persName coords=""><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,390.31,357.74,149.55,8.07;6,324.12,367.70,147.09,8.07">Proceedings of the Empirical Methods in Natural Language Processing Conference</title>
		<meeting>the Empirical Methods in Natural Language Processing Conference</meeting>
		<imprint>
			<date type="published" when="1996-05-17">1996. May 17-18, 1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,396.50,226.68,8.07;6,324.12,406.46,215.85,8.07;6,324.12,416.42,215.74,8.07;6,324.12,426.50,171.97,8.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,409.27,396.50,130.61,8.07;6,324.12,406.46,66.26,8.07">Word sense disambiguation and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,407.46,406.46,132.51,8.07;6,324.12,416.42,215.74,8.07;6,324.12,426.50,76.61,8.07">Proceedings of SIGIR-94, 17th ACM International Conference on Research and Development in Information Retrieval</title>
		<meeting>SIGIR-94, 17th ACM International Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, IE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,445.34,226.52,8.07;6,324.12,455.30,126.26,8.07" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Vorhees</surname></persName>
		</author>
		<title level="m" coord="6,391.75,445.34,147.97,8.07;6,324.12,455.30,122.90,8.07">Overview of TREC-9 question answering track. Text REtreival Conference 9</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,474.26,226.63,8.07;6,324.12,484.22,215.61,8.07;6,324.12,494.18,215.75,8.07;6,324.12,504.14,215.63,8.07;6,324.12,514.10,164.08,8.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,521.96,474.26,17.87,8.07;6,324.12,484.22,215.61,8.07;6,324.12,494.18,196.91,8.07">Constructing Bayesian networks from WordNet for word sense disambiguation: representation and processing issues</title>
		<author>
			<persName coords=""><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O'</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rebecca</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,324.12,504.14,215.63,8.07;6,324.12,514.10,160.25,8.07">Proc. COLING-ACL &apos;98 Workshop on the Usage of Word-Net in Natural Language Processing Systems</title>
		<meeting>COLING-ACL &apos;98 Workshop on the Usage of Word-Net in Natural Language essing Systems</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,533.06,226.55,8.07;6,324.12,543.02,215.74,8.07;6,324.12,552.98,215.28,8.07" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="6,502.57,533.06,37.18,8.07;6,324.12,543.02,200.99,8.07">Maximum Likelihood from Incomplete Data via The EM Algorithm</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,324.12,552.98,124.94,8.07">Journal of Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,571.94,226.65,8.07;6,324.12,581.90,215.75,8.07;6,324.12,590.95,208.48,9.40;6,535.60,582.85,4.70,9.40;6,324.12,601.82,215.65,8.07;6,324.12,611.78,107.80,8.07" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,524.14,571.94,15.71,8.07;6,324.12,581.90,215.75,8.07;6,324.12,591.86,70.44,8.07">Text Representation with WordNet Synsets: A Soft Sense Disambiguation Approach</title>
		<author>
			<persName coords=""><forename type="first">Ganesh</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,405.43,590.95,127.17,9.40;6,535.60,582.85,4.70,9.40;6,324.12,601.82,215.65,8.07;6,324.12,611.78,42.95,8.07">To appear in Proceedings of the ¢¡ £ International Conference on Natural Language in Information Systems</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
