<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,153.68,154.89,303.88,15.49">Approaches to Robust and Web Retrieval</title>
				<funder ref="#_qH2kh8S #_vcFtVDQ #_qBt2JNQ #_HwwqdFb #_5RRypF7 #_dF2ZXGc">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_GUmgT9c #_r2BgDeJ #_RrtrJUJ #_xsXKcNN #_VB5Ng4w">
					<orgName type="full">NWO</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,113.75,187.37,63.92,10.76"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,189.63,187.37,74.71,10.76;1,264.34,185.07,1.49,7.86"><forename type="first">Christof</forename><surname>Monz</surname></persName>
							<email>christof@umiacs.umd.edu</email>
						</author>
						<author>
							<persName coords="1,276.29,187.37,90.19,10.76"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
						</author>
						<author>
							<persName coords="1,378.44,187.37,119.06,10.76"><forename type="first">Börkur</forename><surname>Sigurbjörnsson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Language &amp; Inference Technology Group</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute for Advanced Computer Studies</orgName>
								<orgName type="institution">Uni-versity of Maryland</orgName>
								<address>
									<addrLine>3161 A.V. Williams Building</addrLine>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,153.68,154.89,303.88,15.49">Approaches to Robust and Web Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">91F65243AF7D623812508638C9419DDB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our participation in the TREC 2003 Robust and Web tracks. For the Robust track, we experimented with the impact of stemming and feedback on the worst scoring topics. Our main finding is the effectiveness of stemming on poorly performing topics, which sheds new light on the role of morphological normalization in information retrieval. For both the home/named page finding and topic distillation tasks of the Web track, we experimented with different document representations and retrieval models. Our main finding is effectiveness of the anchor text index for both tasks, suggesting that compact document representations are a fruitful strategy for scaling-up retrieval systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year, our aim for the Web track was to experiment with different document representations and retrieval models for the home/named page finding and topic distillation tasks. The Robust track was new in 2003; our aim here was to investigate the impact of blind feedback and stemming on poorly performing topics.</p><p>For both tracks, our experiments exploited the homegrown FlexIR document retrieval system <ref type="bibr" coords="1,240.84,591.83,10.57,8.97" target="#b8">[9]</ref>. The main goal underlying FlexIR's design is to facilitate flexible experimentation with a wide variety of retrieval components and techniques. FlexIR is implemented in Perl, and supports many types of pre-processing, scoring, indexing, and term-weighting methods.</p><p>The rest of this paper is organized as follows. In two (largely self-contained) sections we describe our work for the Robust and Web tracks. Finally, we summarize our findings in a concluding section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Robust Track</head><p>After describing the experimental setup for this track, we discuss our runs investigating the impact of blind feedback and stemming on the poorly performing topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Description</head><p>All Robust track runs use the FlexIR information retrieval system. We employ a number of techniques: Tokenization We remove punctuation marks, apply casefolding, and map marked characters into the unmarked tokens. We either index the words themselves, or the stems of the words. We use the Snowball stemming algorithm <ref type="bibr" coords="1,457.26,538.42,15.27,8.97" target="#b13">[13]</ref>. Snowball is a small string processing language designed for creating stemming algorithms for use in information retrieval</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval model</head><p>We use a multinominal language model with Jelinek-Mercer smoothing <ref type="bibr" coords="1,462.07,602.18,10.58,8.97" target="#b3">[4]</ref>. For all robust track runs, we use a uniform query term importance weight of 0.15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Blind feedback</head><p>Term weights are recomputed by using the standard Rocchio method <ref type="bibr" coords="1,454.76,653.99,15.27,8.97" target="#b11">[12]</ref>, where we consider the top 10 documents to be relevant and doc-uments ranked 501-1000 to be non-relevant. We allow at most 20 terms to be added to the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runs</head><p>We conduct two sets of experiments using (1) only the description field of the topics (D-topics), or (2) both the title and description fields (TD-topics). Using the resulting queries, we constructed the following four runs:</p><p>Words Language model run on a word-based index. This runs serves as the baseline for our stemming and feedback experiments.</p><p>Words+feedback Language model run on a word-based index, using Rocchio blind feedback.</p><p>Stems Language model run on the Snowball stemmed index.</p><p>Stems+feedback Language model run on the Snowball stemmed index, using Rocchio blind feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" coords="2,98.56,416.28,4.98,8.97" target="#tab_0">1</ref> gives the results of the runs over all 100 robust topics (best scores in boldface). The second column shows the mean average precision, the third the precision at 10 documents, the fourth the percentage of topics with no relevant document in the top 10; the fifth shows the area underneath the MAP(X) versus X curve for the worst 25 topics. The results of blind feedback are mixed at best. On the one hand feedback helps the overall score for the runs using TD-topics, with a best precision at 10 and a best score for mean average precision. On the other hand feedback hurts the performance on the worst scoring topics. For the runs using D-topics, feedback deteriorates scoring on all measures.</p><p>We can regard the T-field of the topics as a "gold standard" experiment on query expansion. If we compare the score of runs using TD-topics with the scores of runs using D-topics, we see an improvement on all measures and runs. In particular the improvement on the weak-scoring topic measures is substantial.</p><p>The results for Snowball stemming are positive overall. Stemming helps both the overall performance, with a best score for precision at 10, as well as the performance of the worst scoring topics, with a best score for the percentage of topics with a top 10 relevant document. For runs using D-topics, stemming gives the best score for all measures. The use of both stemming and feedback gives the best score for the area under the MAP(X) curve for the runs using TD-topics, but does not promote performance on the other measures.</p><p>We also break down the score over the 50 old topics (in Table <ref type="table" coords="2,335.77,359.09,4.15,8.97" target="#tab_1">2</ref>) and the 50 new topics (in Table <ref type="table" coords="2,479.95,359.09,3.60,8.97" target="#tab_2">3</ref>). Note that the area underneath MAP(X) versus X curve (in the last column) is now calculated for the worst 12 topics. For both the old and new topics, the effectiveness of feedback and stemming is comparable to the effectiveness on all topics. There is, however, a striking difference in the performance between the two types of topics: the new topics give a much higher mean average precision score. This is an obvious consequence of the way the old topics were selected for inclusion in this year's Robust track. As a result, the worst topic measures are dominated by the old topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Web Track</head><p>After describing our experimental setup for this track, we discuss our runs for the home/named page finding task (known-item search), followed by the runs for the topic distillation task (key resource search).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Description</head><p>All Web track runs use the FlexIR information retrieval system. We employ a number of techniques:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document representation</head><p>We create indexes for (1) the full documents, ( <ref type="formula" coords="3,161.98,379.02,3.87,8.97">2</ref>) the text in the title tags, (3) the anchor texts pointing toward the document. For the anchor texts index, we unfold relative links and normalize URLs, and do not index repeated occurrences of the same anchor text <ref type="bibr" coords="3,187.23,426.84,15.27,8.97" target="#b9">[10]</ref>.</p><p>Tokenization We remove HTML-tags, punctuation marks, apply case-folding, and map marked characters into the unmarked tokens. We either index the free-text without further processing, or use the Snowball stemming algorithm <ref type="bibr" coords="3,214.83,490.60,15.27,8.97" target="#b13">[13]</ref>.</p><p>Retrieval model We use three retrieval models. First, a statistical language model <ref type="bibr" coords="3,199.72,518.50,11.62,8.97" target="#b3">[4]</ref> with a uniform query term importance weight of either 0.35 or 0.70. Second, the Okapi weighting scheme <ref type="bibr" coords="3,233.73,542.41,16.60,8.97" target="#b10">[11]</ref> with tuning parameters k = 1.5 and b = 0.8. Third, the Lnu.ltc weighting scheme <ref type="bibr" coords="3,168.92,566.32,11.62,8.97" target="#b0">[1]</ref> with slope at 0.1 or 0.2; the pivot was set to the average number of unique words per document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combination</head><p>We use the standard combination methods such as CombSUM and CombMAX <ref type="bibr" coords="3,237.30,618.12,10.58,8.97" target="#b2">[3]</ref>, or weighted fusion <ref type="bibr" coords="3,120.05,630.08,15.27,8.97" target="#b14">[14]</ref>. We combine either full length runs, or limit the combination to the top n results. Unless indicated otherwise, we normalize the scores before combining them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minimal span weighting</head><p>We calculate a minimally matching span for each document. Intuitively, a minimal matching span is the smallest text excerpt from a document that contains all terms which occur in the query and the document. Minimal span weighting depends on three factors (for details, see <ref type="bibr" coords="3,493.66,187.74,10.79,8.97" target="#b1">[2,</ref><ref type="bibr" coords="3,506.94,187.74,7.47,8.97" target="#b4">5,</ref><ref type="bibr" coords="3,516.90,187.74,7.05,8.97" target="#b7">8]</ref>).</p><p>1. document similarity: The document similarity is computed for the whole document, i.e., positional information is not taken into account.</p><p>Similarity scores are normalized with respect to the maximal similarity score for a query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">span size ratio:</head><p>The span size ratio is the number of unique matching terms in the span over the total number of tokens in the span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">matching term ratio:</head><p>The matching term ratio is the number of unique matching terms over the number of unique terms in the query, after stop word removal.</p><p>In two separate sections, we will now address our runs and results for the home/named page finding task, and the topic distillation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Home/Named Page Finding Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runs</head><p>We submitted the following five official runs for the home/named page finding task: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UAmsT03WnOWS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results of the official runs for the home/named page finding task are shown in Table <ref type="table" coords="4,207.11,161.43,4.98,8.97" target="#tab_3">4</ref> (best scores in boldface). The second column gives the mean reciprocal rank, the third the number and percentage of topics with a relevant document in the top 10, the fourth the number and percentage of topics for which no relevant document is found (in the top 50). The language model run combining the non-stemmed documents, titles, and anchors scores best with an average reciprocal rank of 0.5185. The Lnu.ltc weighted combination of the three stemmed indexes scores second best. Table <ref type="table" coords="4,106.97,366.37,4.98,8.97" target="#tab_4">5</ref> shows the mean average precision of the base runs used in combinations for our official runs. All Lnu.ltc runs use a slope of 0.2, and all language model runs use a uniform term weight of 0.70. Here, we retrieve up to 1,000 documents per topic, leading to slightly higher MRRs than the official runs using a maximum of 50 documents. We see an interesting difference between the three retrieval models: where the Lnu.ltc and Okapi models score best on the full document representation, the language model runs on the anchor text index score more than 20% better than the runs on the full document index.</p><p>In fact, our best score on a single index is on the language model run on the non-stemmed anchor text index. There is no clear benefit of the use of a stemming algorithm on the mean reciprocal ranks: stemming improves the score for four out of the nine comparative runs.</p><p>There is another interesting difference between the retrieval models, which has to do with combination. The combination of Okapi runs on the document stems and words, UAmsT03WnOWS, does not improve over document stems run. The combination of the three stemmed Lnu.ltc runs, run UAmsT03WnLn3, does improve 34.8% over the best scoring stemmed runs. The combination of the three non-stemmed language model runs, UAmsT03WnLM3, improves 16.9% over the best scoring base runs. Finally, the run using the matching-span weighting uses a Lnu.ltc full document base run with a different slope of 0.1 scoring a MRR of 0.2742. The resulting run, UAmsT03WnMSW, improves no less than 48.5% over the underlying base run. We also break down the score over the 150 home page topics (in Table <ref type="table" coords="4,375.23,367.26,4.14,8.97" target="#tab_5">6</ref>) and the 150 named page topics (in Table <ref type="table" coords="4,326.50,379.22,3.60,8.97" target="#tab_6">7</ref>). Here we see a much better performance on the named page topics. This is perhaps unexpected because named page finding is conceived to be a more difficult task than home page finding. The simple explanation is that we decided not to apply special home page finding strategies. Although techniques like slash-counts or URL priors are effective for home page finding <ref type="bibr" coords="4,481.65,534.83,10.58,8.97" target="#b6">[7]</ref>, they seem to hurt the named page topics considerably. Even without a particular home page bias, home pages can be retrieved with reasonable effectiveness, as is witnessed by our results for the home page topics in Table <ref type="table" coords="4,466.97,582.66,3.74,8.97" target="#tab_5">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Topic Distillation Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runs</head><p>We submitted the following five official runs for the topic distillation task:</p><p>UAmsT03WtOk3 Weighted fusion of Okapi runs on the three stemmed indexes: 0.7 full documents, 0.2 titles; and 0.1 anchor texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UAmsT03WtLM3</head><p>Weighted fusion of language model runs on the three stemmed indexes: 0.7 full documents (λ = 0.35), 0.2 titles (λ = 0.7), and 0.1 anchor texts (λ = 0.7). We combine the probabilities without normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UAmsT03WtOkI</head><p>Weighted fusion of 0.9 Okapi run on the stemmed full document index with 0.1 of a link topology measure. We applied the realized indegree on the top 10 documents <ref type="bibr" coords="5,197.22,267.44,15.27,8.97" target="#b9">[10]</ref>. This is a variant of HITS <ref type="bibr" coords="5,117.40,279.39,11.61,8.97" target="#b5">[6]</ref> where we consider the fraction of inlinks that is in the local set-roughly a tf•idf measure for link topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UAmsT03WtLMI</head><p>Weighted fusion of 0.9 language model run (λ = 0.35) on the stemmed full document index with 0.1 of the realized indegree of the top 10 documents.</p><p>UAmsT03WtOkC Weighted fusion of 0.8 Okapi run on the stemmed full document index with 0.2 of a URLbased reranking. The reranking was done by clustering the found pages by their base URLs, and to only return the page with the lowest slash-count per cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results of the official runs for the topic distillation task are shown in Table <ref type="table" coords="5,170.99,498.37,4.98,8.97" target="#tab_7">8</ref> (best scores in boldface). The second column shows the mean average precision, the third to fifth columns show the precision at 10, 20, and 30 documents, respectively. The best score is obtained by UAmsT03WtOk3, the fusion of Okapi runs on the three stemmed indexes. The second best score is obtained by UAmsT03WtOkC, a URL-based clustering of the Okapi full documents run. Before discussing the results of our ex-periments, we first evaluate the results of the runs used to create our official runs. Table <ref type="table" coords="5,344.93,152.37,4.98,8.97" target="#tab_8">9</ref> shows the results of the base runs used in combination for our official runs. All these runs use the Snow- ball stemming algorithm <ref type="bibr" coords="5,414.06,271.12,15.27,8.97" target="#b13">[13]</ref>. We see a remarkable divergence between the scoring for Okapi and the language model. The Okapi model performs comparable on all the three indexes, documents, titles, and anchors. The language model performs poorly on the document and title indexes, but excels for the anchor text index. The combination of the three Okapi runs, UAmsT03WtOk3, improves significantly over the best underlying run (MAP +38.4%, Precision at 10 +25.6%). The combination of language model runs, UAmsT03WtLM3, uses far from optimal relative weights and, as a result, does not improve over the anchor text run. The runs using the hyperlink graph topology do not result in significant improvement. The Okapi run UAmsT03WtOkI slightly improves its precision at 10 over the document run; whereas the language model run UAmsT03WtLMI slightly decreases its precision at 10 over the document run. Finally, the Okapi run clustering per base URL, UAmsT03WtOkC, does improve over the Okapi document run (MAP +25.1%, Precision at 10 +16.2%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper we have described our participation in the TREC 2003 Robust and Web tracks.</p><p>For the Robust track, we experimented with the impact of stemming and feedback on the worst scoring topics. Our results suggest that blind feedback can help overall performance but does not increase the effectiveness on the lowest scoring topics. Our results also suggest that applying a stemming algorithm does benefit both the overall performance, as well as the performance of the worst scoring topics. This result sheds some new light on the role of morphological normalization in information retrieval.</p><p>For the Web track, we saw very similar results for both the home/named page finding task and the topic distillation task. Using the hyperlinks in the collection for creating an anchor text index turns out to be very effective. Also, the use of HTML-structure in the documents to elicit their titles turns out to be effective. Combining these alternative document representations with a standard document index led to our best scores for both tasks.</p><p>A further general observation is the effectiveness of compact document representations, such as indexing only document titles, or only anchor texts pointing toward documents. These compact document representations result in performance that meets or exceeds the performance of a massive full document text index. This result suggests that it is feasible to create effective retrieval indexes for even larger web collections, provided that the appropriate document representation is chosen.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,387.32,506.43,151.92,8.97;3,330.53,518.38,194.95,8.97;3,310.61,534.32,228.64,8.97;3,330.53,546.28,131.45,8.97;3,310.61,562.22,228.64,8.97;3,330.53,574.17,208.71,8.97;3,330.53,586.13,156.47,8.97;3,310.61,602.07,228.64,8.97;3,330.53,614.02,208.72,8.97;3,330.53,625.98,186.36,8.97;3,310.61,641.92,228.64,8.97;3,330.53,653.87,208.71,8.97;3,330.53,665.83,51.88,8.97"><head></head><label></label><figDesc>CombSUM of top 1000 of Okapi on word-based and stemmed full document indexes. UAmsT03WnLM Language model run (λ = 0.70) on word-based full document index. UAmsT03WnLn3 CombMAX on the top 25 of Lnu.ltc runs (slope = 0.2) on the three stemmed indexes: full documents, titles, and anchor texts. UAmsT03WnLM3 Weighted fusion of language model runs (λ = 0.70) on the three word-based indexes: 0.7 full documents, 0.2 titles, and 0.1 anchor texts. UAmsT03WnMSW Minimal span weighting based on the Lnu.ltc run (slope = 0.1) on the stemmed full document index.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,78.38,443.46,215.89,107.57"><head>Table 1 :</head><label>1</label><figDesc>Results for the Robust track (D top and TD bottom).</figDesc><table coords="2,78.38,454.49,215.89,96.54"><row><cell>Run identifier</cell><cell cols="2">MAP Prec.10 NoTop10 MAP(X)</cell></row><row><cell>Words</cell><cell>0.2065 0.3530</cell><cell>15.0% 0.0076</cell></row><row><cell cols="2">Words+feedback 0.1970 0.3420</cell><cell>17.0% 0.0059</cell></row><row><cell>Stems</cell><cell>0.2319 0.3960</cell><cell>14.0% 0.0126</cell></row><row><cell cols="2">Stems+feedback 0.2068 0.3570</cell><cell>16.0% 0.0098</cell></row><row><cell>Words</cell><cell>0.2324 0.4050</cell><cell>9.0% 0.0216</cell></row><row><cell cols="2">Words+feedback 0.2452 0.4110</cell><cell>13.0% 0.0210</cell></row><row><cell>Stems</cell><cell>0.2450 0.4150</cell><cell>6.0% 0.0256</cell></row><row><cell cols="2">Stems+feedback 0.2373 0.4040</cell><cell>14.0% 0.0273</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,316.98,374.31,215.89,107.57"><head>Table 2 :</head><label>2</label><figDesc>Results for the old topics (D top and TD bottom).</figDesc><table coords="2,316.98,385.34,215.89,96.54"><row><cell>Run identifier</cell><cell cols="2">MAP Prec.10 NoTop10 MAP(X)</cell></row><row><cell>Words</cell><cell>0.1066 0.2640</cell><cell>14.0% 0.0064</cell></row><row><cell cols="2">Words+feedback 0.0969 0.2460</cell><cell>20.0% 0.0039</cell></row><row><cell>Stems</cell><cell>0.1164 0.3020</cell><cell>18.0% 0.0108</cell></row><row><cell cols="2">Stems+feedback 0.1065 0.2640</cell><cell>18.0% 0.0085</cell></row><row><cell>Words</cell><cell>0.1349 0.3180</cell><cell>12.0% 0.0142</cell></row><row><cell cols="2">Words+feedback 0.1377 0.3200</cell><cell>16.0% 0.0143</cell></row><row><cell>Stems</cell><cell>0.1327 0.3300</cell><cell>6.0% 0.0185</cell></row><row><cell cols="2">Stems+feedback 0.1361 0.3300</cell><cell>16.0% 0.0204</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="2,316.98,491.87,215.89,107.57"><head>Table 3 :</head><label>3</label><figDesc>Results for the new topics (D top and TD bottom).</figDesc><table coords="2,316.98,502.90,215.89,96.54"><row><cell>Run identifier</cell><cell cols="2">MAP Prec.10 NoTop10 MAP(X)</cell></row><row><cell>Words</cell><cell>0.3064 0.4420</cell><cell>16.0% 0.0142</cell></row><row><cell cols="2">Words+feedback 0.2971 0.4380</cell><cell>14.0% 0.0105</cell></row><row><cell>Stems</cell><cell>0.3475 0.4900</cell><cell>10.0% 0.0294</cell></row><row><cell cols="2">Stems+feedback 0.3071 0.4500</cell><cell>14.0% 0.0216</cell></row><row><cell>Words</cell><cell>0.3300 0.4920</cell><cell>6.0% 0.0433</cell></row><row><cell cols="2">Words+feedback 0.3528 0.5020</cell><cell>10.0% 0.0368</cell></row><row><cell>Stems</cell><cell>0.3572 0.5000</cell><cell>6.0% 0.0551</cell></row><row><cell cols="2">Stems+feedback 0.3386 0.4780</cell><cell>12.0% 0.0478</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,78.38,188.61,215.89,73.89"><head>Table 4 :</head><label>4</label><figDesc>Results for home/named page finding.</figDesc><table coords="4,78.38,199.24,215.89,63.26"><row><cell>Run identifier</cell><cell>MRR</cell><cell>Top 10</cell><cell>not found</cell></row><row><cell>UAmsT03WnOWS</cell><cell cols="3">0.3833 178 (59.3%) 70 (23.3%)</cell></row><row><cell>UAmsT03WnLM</cell><cell cols="3">0.3592 170 (56.7%) 81 (27.0%)</cell></row><row><cell>UAmsT03WnLn3</cell><cell cols="3">0.4982 218 (72.7%) 38 (12.7%)</cell></row><row><cell>UAmsT03WnLM3</cell><cell cols="3">0.5185 214 (71.3%) 46 (15.3%)</cell></row><row><cell>UAmsT03WnMSW</cell><cell cols="3">0.4073 189 (63.0%) 64 (21.3%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,78.38,391.50,215.89,84.85"><head>Table 5 :</head><label>5</label><figDesc>MRR for home/named page finding base runs.</figDesc><table coords="4,78.38,402.13,215.89,74.22"><row><cell cols="2">Index type</cell><cell cols="2">Lnu.ltc Okapi</cell><cell>LM</cell></row><row><cell cols="2">Documents Words</cell><cell>0.3750</cell><cell cols="2">0.3795 0.3604</cell></row><row><cell></cell><cell>Stems</cell><cell>0.3697</cell><cell cols="2">0.3833 0.3616</cell></row><row><cell>Titles</cell><cell>Words</cell><cell>0.2339</cell><cell cols="2">0.3421 0.3536</cell></row><row><cell></cell><cell>Stems</cell><cell>0.3655</cell><cell cols="2">0.3334 0.3487</cell></row><row><cell>Anchors</cell><cell>Words</cell><cell>0.3068</cell><cell cols="2">0.3593 0.4436</cell></row><row><cell></cell><cell>Stems</cell><cell>0.2934</cell><cell cols="2">0.3379 0.4278</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,316.98,274.69,215.89,73.89"><head>Table 6 :</head><label>6</label><figDesc>Results for home page topics.</figDesc><table coords="4,316.98,285.32,215.89,63.26"><row><cell>Run identifier</cell><cell>MRR</cell><cell>Top 10</cell><cell>not found</cell></row><row><cell>UAmsT03WnOWS</cell><cell>0.2567</cell><cell cols="2">67 (44.7%) 55 (36.7%)</cell></row><row><cell>UAmsT03WnLM</cell><cell>0.2462</cell><cell cols="2">64 (42.7%) 60 (40.0%)</cell></row><row><cell>UAmsT03WnLn3</cell><cell>0.4105</cell><cell cols="2">97 (64.7%) 26 (17.3%)</cell></row><row><cell>UAmsT03WnLM3</cell><cell cols="3">0.4402 101 (67.3%) 33 (22.0%)</cell></row><row><cell>UAmsT03WnMSW</cell><cell>0.2708</cell><cell cols="2">73 (48.7%) 53 (35.3%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="4,316.98,394.44,215.89,73.89"><head>Table 7 :</head><label>7</label><figDesc>Results for named page topics.</figDesc><table coords="4,316.98,405.07,215.89,63.26"><row><cell>Run identifier</cell><cell>MRR</cell><cell>Top 10</cell><cell>not found</cell></row><row><cell>UAmsT03WnOWS</cell><cell cols="3">0.5098 111 (74.0%) 15 (10.0%)</cell></row><row><cell>UAmsT03WnLM</cell><cell cols="3">0.4721 106 (70.7%) 21 (14.0%)</cell></row><row><cell>UAmsT03WnLn3</cell><cell cols="3">0.5859 121 (80.7%) 12 (8.0%)</cell></row><row><cell>UAmsT03WnLM3</cell><cell cols="3">0.5969 113 (75.3%) 13 (8.7%)</cell></row><row><cell>UAmsT03WnMSW</cell><cell cols="3">0.5438 116 (77.3%) 11 (7.3%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="5,78.38,513.20,215.89,73.89"><head>Table 8 :</head><label>8</label><figDesc>Results for topic distillation.</figDesc><table coords="5,78.38,523.83,215.89,63.26"><row><cell>Run identifier</cell><cell>MAP</cell><cell>Prec. at 10, 20, 30</cell></row><row><cell>UAmsT03WtOk3</cell><cell cols="2">0.1344 0.0980 0.0810 0.0787</cell></row><row><cell>UAmsT03WtLM3</cell><cell cols="2">0.1019 0.0840 0.0630 0.0533</cell></row><row><cell>UAmsT03WtOkI</cell><cell cols="2">0.0862 0.0760 0.0660 0.0567</cell></row><row><cell>UAmsT03WtLMI</cell><cell cols="2">0.0412 0.0280 0.0260 0.0267</cell></row><row><cell>UAmsT03WtOkC</cell><cell cols="2">0.1127 0.0860 0.0650 0.0540</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="5,316.98,177.53,215.89,84.85"><head>Table 9 :</head><label>9</label><figDesc>Results for topic distillation stemmed base runs.</figDesc><table coords="5,316.98,188.16,215.89,74.22"><row><cell>Run type</cell><cell>MAP</cell><cell>Prec. at 10, 20, 30</cell></row><row><cell>Doc. Okapi</cell><cell cols="2">0.0901 0.0740 0.0580 0.0527</cell></row><row><cell>Title Okapi</cell><cell cols="2">0.0870 0.0780 0.0590 0.0453</cell></row><row><cell>Anchor Okapi</cell><cell cols="2">0.0971 0.0780 0.0560 0.0493</cell></row><row><cell>Doc. LM (0.35)</cell><cell cols="2">0.0386 0.0300 0.0320 0.0293</cell></row><row><cell>Title LM (0.70)</cell><cell cols="2">0.0434 0.0480 0.0360 0.0293</cell></row><row><cell>Anchor LM (0.70)</cell><cell cols="2">0.1068 0.0860 0.0560 0.0473</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments Jaap Kamps was supported by <rs type="funder">NWO</rs> under project numbers <rs type="grantNumber">400-20-036</rs> and <rs type="grantNumber">612.066.302</rs>. <rs type="person">Christof Monz</rs> was supported by <rs type="funder">NWO</rs> under project numbers <rs type="grantNumber">612-13-001</rs> and <rs type="grantNumber">220-80-001</rs>. <rs type="person">Maarten de Rijke</rs> was supported by <rs type="funder">NWO</rs> under project numbers <rs type="grantNumber">612-13-001</rs>, <rs type="grantNumber">365-20-005</rs>, <rs type="grantNumber">612.069.006</rs>, <rs type="grantNumber">612.000.106</rs>, <rs type="grantNumber">220-80-001</rs>, <rs type="grantNumber">612.000.207</rs>, and <rs type="grantNumber">612.066.302</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GUmgT9c">
					<idno type="grant-number">400-20-036</idno>
				</org>
				<org type="funding" xml:id="_r2BgDeJ">
					<idno type="grant-number">612.066.302</idno>
				</org>
				<org type="funding" xml:id="_qH2kh8S">
					<idno type="grant-number">612-13-001</idno>
				</org>
				<org type="funding" xml:id="_RrtrJUJ">
					<idno type="grant-number">220-80-001</idno>
				</org>
				<org type="funding" xml:id="_xsXKcNN">
					<idno type="grant-number">612-13-001</idno>
				</org>
				<org type="funding" xml:id="_VB5Ng4w">
					<idno type="grant-number">365-20-005</idno>
				</org>
				<org type="funding" xml:id="_vcFtVDQ">
					<idno type="grant-number">612.069.006</idno>
				</org>
				<org type="funding" xml:id="_qBt2JNQ">
					<idno type="grant-number">612.000.106</idno>
				</org>
				<org type="funding" xml:id="_HwwqdFb">
					<idno type="grant-number">220-80-001</idno>
				</org>
				<org type="funding" xml:id="_5RRypF7">
					<idno type="grant-number">612.000.207</idno>
				</org>
				<org type="funding" xml:id="_dF2ZXGc">
					<idno type="grant-number">612.066.302</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,91.92,475.54,208.72,8.07;6,91.92,486.50,208.72,8.07;6,91.92,497.46,208.72,8.07;6,91.92,508.42,208.72,8.07;6,91.92,519.38,148.44,8.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,237.44,475.54,63.20,8.07;6,91.92,486.50,121.65,8.07">New retrieval approaches using SMART: TREC 4</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,91.92,497.46,179.85,8.07">The Fourth Text REtrieval Conference (TREC-4)</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="500" to="236" />
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,91.92,531.93,208.72,8.07;6,91.92,542.89,208.72,8.07;6,91.92,553.85,208.73,8.07;6,91.92,564.81,208.72,8.07;6,91.92,575.76,208.72,8.07;6,91.92,586.72,179.08,8.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,236.83,531.93,63.81,8.07;6,91.92,542.89,101.09,8.07">Exploiting redundancy in question answering</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,230.42,553.85,70.22,8.07;6,91.92,564.81,208.72,8.07;6,91.92,575.76,181.37,8.07">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kraft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Harper</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</editor>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="358" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,91.92,599.28,208.72,8.07;6,91.92,610.24,208.72,8.07;6,91.92,621.19,208.72,8.07;6,91.92,632.15,208.72,8.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,166.12,599.28,120.05,8.07">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,161.93,610.24,138.71,8.07;6,91.92,621.19,33.43,8.07">The Second Text REtrieval Conference (TREC-2)</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="500" to="215" />
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,91.92,644.71,208.72,8.07;6,91.92,655.66,208.72,8.07;6,91.92,666.62,146.39,8.07" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,140.82,644.71,159.83,8.07;6,91.92,655.66,22.33,8.07">Using Language Models for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Center for Telematics and Information Technology, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="6,330.52,128.64,208.72,8.07;6,330.52,139.60,208.72,8.07;6,330.52,150.56,208.72,8.07;6,330.52,161.52,208.72,8.07;6,330.52,172.48,131.77,8.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,431.10,139.60,108.15,8.07;6,330.52,150.56,152.66,8.07">The University of Amsterdam at the TREC 2003 question answering track</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schlobach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Tsur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,497.83,150.56,41.41,8.07;6,330.52,161.52,93.25,8.07">The Twelfth Text REtrieval Conference</title>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2003">2003. 2004</date>
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,185.03,208.72,8.07;6,330.52,195.99,193.40,8.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,393.36,185.03,145.89,8.07;6,330.52,195.99,43.27,8.07">Authoritative structures in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,380.96,195.99,68.00,8.07">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,208.54,208.72,8.07;6,330.52,219.50,208.72,8.07;6,330.52,230.46,208.72,8.07;6,330.52,241.42,208.72,8.07;6,330.52,252.38,208.72,8.07;6,330.52,263.34,208.72,8.07;6,330.52,274.29,97.49,8.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,508.47,208.54,30.77,8.07;6,330.52,219.50,191.05,8.07">The importance of prior probabilities for entry page search</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,393.67,241.42,145.57,8.07;6,330.52,252.38,208.72,8.07;6,330.52,263.34,107.31,8.07">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Myaeng</surname></persName>
		</editor>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,286.85,208.72,8.07;6,330.52,297.81,208.72,8.07;6,330.52,308.77,49.55,8.07" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,368.74,286.85,170.51,8.07;6,330.52,297.81,133.22,8.07">From Document Retrieval to Question Answering. ILLC dissertation series 2003-04</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Amsterdam</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,321.32,208.72,8.07;6,330.52,332.28,208.72,8.07;6,330.52,343.24,208.72,8.07;6,330.52,354.20,208.72,8.07;6,330.52,365.15,208.72,8.07;6,330.52,376.11,208.72,8.07;6,330.52,387.07,55.18,8.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,433.79,321.32,105.45,8.07;6,330.52,332.28,208.72,8.07;6,330.52,343.24,56.48,8.07">Shallow morphological analysis in monolingual information retrieval for Dutch, German and Italian</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,415.31,354.20,123.94,8.07;6,330.52,365.15,102.40,8.07">Evaluation of Cross-Language Information Retrieval Systems</title>
		<title level="s" coord="6,341.83,376.11,131.60,8.07">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001. 2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="262" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,399.62,208.72,8.07;6,330.52,410.58,208.72,8.07;6,330.52,421.54,208.72,8.07;6,330.52,432.50,208.73,8.07;6,330.52,443.46,208.72,8.07;6,330.52,454.42,20.17,8.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,474.53,399.62,64.72,8.07;6,330.52,410.58,77.09,8.07">The University of Amsterdam at TREC</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,397.60,421.54,141.65,8.07;6,330.52,432.50,46.63,8.07">The Eleventh Text REtrieval Conference (TREC 2002)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2002">2002. 2003</date>
			<biblScope unit="page" from="500" to="251" />
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,466.97,208.72,8.07;6,330.52,477.93,208.72,8.07;6,330.52,488.89,151.99,8.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,490.44,466.97,48.80,8.07;6,330.52,477.93,136.10,8.07">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,477.36,477.93,61.88,8.07;6,330.52,488.89,82.29,8.07">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,501.44,208.72,8.07;6,330.52,512.40,208.72,8.07;6,330.52,523.36,208.72,8.07;6,330.52,534.32,208.72,8.07;6,330.52,545.28,15.69,8.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,382.19,501.44,153.89,8.07">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,403.60,512.40,135.65,8.07;6,330.52,523.36,153.91,8.07">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</editor>
		<imprint>
			<publisher>Prentice-Hall Series in Automatic Computation</publisher>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,348.46,545.28,152.13,8.07" xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Prentice-Hall</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<pubPlace>Englewood Cliffs NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,557.83,208.72,8.07;6,330.52,568.79,203.49,8.07" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="6,369.45,557.83,169.80,8.07;6,330.52,568.79,21.61,8.07">Stemming algorithms for use in information retrieval</title>
		<author>
			<persName coords=""><surname>Snowball</surname></persName>
		</author>
		<ptr target="http://www.snowball.tartarus.org/" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.52,581.34,208.72,8.07;6,330.52,592.30,208.72,8.07;6,330.52,603.26,208.72,8.07;6,330.52,614.22,208.72,8.07;6,330.52,625.18,208.72,8.07;6,330.52,636.14,208.72,8.07;6,330.52,647.10,58.86,8.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,441.63,581.34,97.61,8.07;6,330.52,592.30,115.48,8.07">Predicting the performance of linearly combined IR systems</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,351.93,614.22,187.32,8.07;6,330.52,625.18,208.72,8.07;6,330.52,636.14,59.13,8.07">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Moffat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Wilkinson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</editor>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="190" to="196" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
