<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.40,122.40,325.12,15.49;1,146.04,142.08,319.98,15.49">Relevance Propagation for Topic Distillation UIUC TREC-2003 Web Track Experiments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.40,173.15,75.61,10.76"><forename type="first">Azadeh</forename><surname>Shakery</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.04,173.15,85.34,10.76"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.40,122.40,325.12,15.49;1,146.04,142.08,319.98,15.49">Relevance Propagation for Topic Distillation UIUC TREC-2003 Web Track Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FF98C609EAEF90C4D4048701C33172F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report our experiments on the Web Track TREC-2003. We submitted five runs for the topic distillation task. Our goal was to evaluate the standard language modeling algorithms for topic distillation, as well as to explore the impact of combining link and content information.</p><p>We proposed a new general relevance propagation model for combining link and content information, and explored a number of specific methods derived from the model. The experiment results show that combining link and content information generally performs better than using only content information, though the amount of improvement is sensitive to the document collection and tuning of parameters.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We participated in the topic distillation task of TREC-2003 Web Track with two goals:</p><p>1. Evaluating our basic language modeling algorithms for topic distillation.</p><p>2. Exploring how to effectively combine the link information with the content information.</p><p>The reports about this task from TREC-2002 seem to indicate that a standard content-based retrieval algorithm, such as Okapi, performs very well for topic distillation. So we decided to test how a basic language modeling approach would perform. Specifically, we used the standard query likelihood method with Dirichlet prior smoothing <ref type="bibr" coords="1,72.00,613.48,11.63,8.97" target="#b7">[8]</ref> as well as the two-stage language modeling algorithm, which is supposed to tune the parameters automatically according to the query <ref type="bibr" coords="1,163.68,634.96,10.69,8.97" target="#b8">[9]</ref>.</p><p>Intuitively, the link information may provide some clues as to whether a page is a key resource or not. It is thus interesting to explore how we may combine the link information with the content information to improve the accuracy in finding key resources. We propose a new general relevance propagation model for combining link information with the content information. The relevance propagation model naturally captures the intuition that a web page's value depends on the page's content value (self relevance) as well as the values of all the pages that are linked to this page (through either inlinks or outlinks). It allows every page to propagate its self relevance value to the neighboring pages through links to generate a "hyperrelevance" value for each page.</p><p>We consider several interesting special cases of this general relevance propagation model, and derive several specific methods for combining link information with content information. We use the query likelihood method with Dirichlet prior smoothing as well as the two-stage smoothing for computing the self relevance value of a page (solely based on the content). We then apply these different propagation methods to propagate every page's self relevance value along links to obtain a hyperrelevance value for each page. The hyper-relevance values are used to produce the final ranking for selecting key resources.</p><p>The experiment results show that combining link and content information generally performs better than using only content information, though the amount of improvement is sensitive to the document collection and tuning of parameters.</p><p>The rest of this paper is organized as follows. In Section 2, we briefly describe the language modeling algorithms that we experimented with. In Section 3, we present the general Relevance Propagation Model and three specific propagation methods. In Section 4, we briefly discuss how to implement the general relevance propagation model. In Section 5, we analyze the results of our experiments on TREC-2002 and TREC-2003 data. Finally, in Section 6, we give the conclusions and future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Language Modeling Algorithms</head><p>Our basic content-based retrieval algorithm is the Kullback-Leibler (KL) divergence between the query language model and the document language model <ref type="bibr" coords="1,514.18,656.68,10.78,8.97" target="#b0">[1,</ref><ref type="bibr" coords="1,528.91,656.68,7.27,8.97" target="#b6">7]</ref>. This method is a generalization of the query likelihood retrieval method proposed in <ref type="bibr" coords="1,422.02,678.28,11.75,8.97" target="#b4">[5]</ref> and can support feedback more naturally than the query likelihood method. In this retrieval method, in order to compute a score for a document w.r.t. a query, we first compute a query language model and a document language model, and then compute the KL-divergence of these two models. The main issue in computing the document language model is smoothing, and we explore two smoothing methods -Dirichlet prior and two-stage smoothing. We also explore two different ways of computing a query language model, one using the query text alone and one using both the query text and some pseudo feedback documents. The details of these methods can be found in <ref type="bibr" coords="2,172.31,172.96,15.33,8.97" target="#b9">[10]</ref>.</p><p>From these different combinations, we decide to use the following approaches as our baseline "content only" runs:</p><p>1. Dirichlet Prior Smoothing, no feedback: This is the simplest language modeling approach.</p><p>2. Two-stage smoothing, mixture model feedback: This is a relatively sophisticated language modeling approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relevance Propagation Model</head><p>The results of TREC-2002 Web Track did not seem to favor approaches combining link and content information.</p><p>The best official results were from Tsinghua university <ref type="bibr" coords="2,72.00,353.92,15.53,8.97" target="#b10">[11]</ref>; they explored the use of out-degree, as well as anchor text to find key resources. What they found was that anchor-text was useful, but out-degree was not. The second and third best results on TREC-2002 Web Track were from City University <ref type="bibr" coords="2,162.39,397.00,11.63,8.97" target="#b1">[2]</ref> and Chinese-Academy <ref type="bibr" coords="2,274.10,397.00,11.63,8.97" target="#b5">[6]</ref> respectively. None of these groups used the link information in finding the key resources. However, intuitively, the content similarity of a page to a query, on its own, may not be sufficient for selecting a key resource, and the link information can be useful in finding key resources. A good resource is a page whose content is related to the query topic, and which has links to and/or from other related resources. So two factors are important in selecting good resources: the content of the page and the relevance of the pages which have links to/from the page.</p><p>Motivated by these observations, we propose a new general relevance propagation model for combining link and content information. Specifically, We define the "hyper-relevance" score of each page as a function of three variables, the content similarity of the page to the query ("self relevance"), a weighted sum of the hyperrelevance scores of the pages that point to the page, and a weighted sum of the hyper-relevance scores of the pages that are pointed to by the page. Formally, the relevance propagation model can be written as :</p><formula xml:id="formula_0" coords="2,75.96,636.48,221.15,19.51">h(p) = f (S(p), p i →p h(pi)wI (pi, p), p→p j h(pj)wO(p, pj))</formula><p>where h(p) is the hyper-relevance score of page p, S(p) is the content similarity between the page p and the query (i.e., "self relevance"), and w I and w O are weighting functions for in-link and out-link pages, respectively.</p><p>In principle, the choice of function f could be arbitrary. An interesting choice is a linear combination of the vari-ables shown below:</p><formula xml:id="formula_1" coords="2,339.48,116.37,172.07,69.36">h(p) = αS(p) + β pi→p h(p i )w I (p i , p) + γ p→pj h(p j )w O (p, p j )) α + β + γ = 1</formula><p>The hyper-relevance scores can be computed iteratively until they converge to a limit, which is the final score of the page for ranking; more detail is presented in Section 4.</p><p>We now consider three special cases of this general relevance propagation model. Each special case corresponds to some reasonable user behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Weighted In-Link</head><p>This model of user behavior is quite similar to the model of PageRank <ref type="bibr" coords="2,365.34,301.36,10.60,8.97" target="#b3">[4]</ref>, except that it is not query-independent. The random surfer is given a start page at random. He keeps traversing links until he gets bored and starts from another random page. The probability that the random surfer visits a page is its hyper-relevance score. This model has some characteristics which distinguish it from PageRank. First, it works on a subset of pages which are in the working set, rather than working on the whole set of data. (The details of constructing the working set is given in section 4.2) One of the properties of pages in the working set is that their content similarity to the query is above a threshold, so they can not be completely unrelated to the query. Second, the probability that the random surfer traverses an edge is proportional to the similarity of the target page and the query. That is, it is more probable that the user traverses and edge which leads to a more similar page, than jumping to a less similar page. Besides, when the random surfer gets bored, it jumps to new pages based on their similarity to the query. This behavior can be formally modeled as follows. In each iteration, the new score of each page is computed as:</p><formula xml:id="formula_2" coords="2,330.72,538.17,189.58,48.00">h(p) = αS(p) + (1 -α) pi→p h(p i )w(p i → p) w(p i → p) ∝ S(p)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Weighted Out-Link</head><p>In this model, we assume that given a page to a user, he reads the content of the page with probability α and he traverses the outgoing edges with probability (1 -α). We also assume that it is more likely that the user traverses an edge that leads to a page whose content-similarity is higher.</p><p>Formally, we compute the hyper-relevance of each page iteratively using:</p><formula xml:id="formula_3" coords="2,329.52,711.21,191.88,20.29">h(p) = αS(p) + (1 -α) p→pj h(p j )w(p → p j ) w(p → p j ) ∝ S(p j )</formula><p>In each iteration, the hyper-relevance of each page is computed as a combination of its self-relevance and the hyperrelevance of the pages that it points to. The pages that are linked from a page do not have the same impact on its weight. Pages whose contents are more similar to the query are assumed to have more impact on the score of the page than those which are less similar. This effect is indicated in w(p → p j ). The hyper-relevance scores of pages are computed iteratively until they converge to a value, which are used to rank the pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Uniform Out-Link</head><p>In this special case, we assume that at each page, the user reads the content of the page, and with probability (1 -α) he reads all the pages that are linked from the page. So the score of each page will be equal to a combination of its self relevance and the scores of all its linked pages.</p><p>Formally the hyper-relevance of each page is computed iteratively. In each iteration, the hyper-relevance of each page is:</p><formula xml:id="formula_4" coords="3,116.16,347.61,140.64,20.29">h(p) = S(p) + (1 -α) p→pj h(p j )</formula><p>4 Implementation Issues</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preprocessing</head><p>We indexed all the web pages before dealing with queries. We used the Lemur toolkit for document indexing <ref type="bibr" coords="3,270.00,439.72,10.60,8.97" target="#b2">[3]</ref>. For document tokenization, we used the Fox stopword list and Porter stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constructing the Working Set</head><p>We do not run our experiments on the whole set of data. Instead, for each query, we first construct a working set of pages and then find the top ranked pages among the pages of this subset.</p><p>To construct the working set, we first find the top 100000 pages which have the highest content similarity to the query from the whole collection of pages. We assume that the pages that are not among these pages can not be key resources for the given query. From these 100000 pages, a small number (about 200) of the most similar pages are selected to be the core set of pages. We then expand the core set to the working set by adding the pages that are among the 100000 pages and which point to the pages in the core set or are pointed to by the pages in the core set. We then run our experiments on these working sets. Note that each working set is specific to a query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Computing the Hyper-relevance Values</head><p>In order to be able to compute the scores efficiently, we should come up with a way to find the hyper-relevance scores easily and in a feasible amount of time. In our implementation, we use matrix multiplication iteratively to compute the scores. We can use existing matrix multiplication methods to speed up the computation process.</p><p>Suppose that query Q and parameters are given. Our goal is to compute the limit hyper-relevance scores. To this end, we construct a square matrix U n×n where n is the number of pages in the working set.</p><p>To construct the matrix, we first set all the entries to zero (u ij = 0, 1 ≤ i, j ≤ n). We then add the influence of out-links: for each 1 ≤ i, j ≤ n, we add β × w(p i → p j ) to the entry u ij . Then we add the influence of in-links by adding γ × w(p i → p j ) to the entries u ji . The only thing that remains is to add the effect of self content similarity. To add this effect, we add α × S(p i ) to all the entries u ij , 1 ≤ j ≤ n.</p><p>We then construct a vector H n of hyper-relevance scores. At the beginning, we set all the entries in H to be 1</p><p>n . The vector H should maintain the property that the sum of all the entries equal to one in every step.</p><p>In each step, we multiply U by H and we normalize the H vector. Each entry h i in H corresponds to the hyperrelevance value of page p i . It is easy to show that after multiplication, the hyper-relevance values are updated according to the general relevance propagation model.</p><p>If we do the multiplication and normalization iteratively, the hyper-relevance scores will converge to a limit, which is the final score we use for sorting results. The results of our algorithms on TREC-2002 data were quite promising. We explored the three presented methods, as well as a couple of other ways of propagating the relevance scores, and all the methods outperformed the baseline content-only language modeling method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Preliminary Experiments</head><p>Table <ref type="table" coords="3,345.57,644.80,4.19,8.97" target="#tab_1">5</ref>.1 summarizes our experiments on TREC-2002 data. Figure <ref type="figure" coords="3,364.62,655.60,5.03,8.97" target="#fig_0">1</ref> shows the results of our algorithms compared to the baseline method.</p><p>As can be seen from the chart, all the methods have improvements over baseline.</p><p>Uniform out-link always perform better than baseline, while Weighted out-link has improvements for α &gt; 0.2 and Weighted in-link has improvements for α &gt; 0.7.   <ref type="figure" coords="4,87.58,559.60,5.03,8.97" target="#fig_2">2</ref> shows the results of our algorithms on TREC-2003 data. We see that for a majority settings of the parameter, the weighted out-link approach actually improves the performance clearly, but the α value that we obtained by training on the 2002 data corresponds to a bad setting for TREC-2003. When we optimize the parameter α on the TREC 2003 test set, both the weighted in-link and weighted out-link methods outperform the baseline.</p><p>As can be seen from the chart, the baseline method did not give good results on this year's data and although the proposed algorithms improved the ranking a bit, the overall precision was not good.</p><p>Comparing our two baseline runs (i.e., "2s Base"and "Dir Base"), we see that the two-stage smoothing coupled with mixture model for feedback performs significantly better than the the Dirichlet prior smoothing, confirming  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Discussion</head><p>We tried to find the reason for our poor results for this year's task. One difference between TREC-2002 data and TREC-2003 data is the number of relevant documents for each query. The average number of relevant documents per query is 31.48 for TREC-2002, while it is only 10.32 for TREC-2003 data. To find out whether this is a reason for our poor performance. We do experiments on two subsets of queries: a selected subset of queries from TREC-2002 whose average number of relevant documents is smaller than the average over all the queries and a selected subset of queries from TREC-2003 whose average number of relevant documents is larger than the average over all queries.</p><p>Our subset of queries from TREC-2002 data contains 25 queries with 10.48 relevant documents on average. The subset of queries from TREC-2003 data contains 20 queries with 19 relevant documents on average.</p><p>We tried our algorithms on these two subsets of queries. Figure <ref type="figure" coords="4,339.09,575.44,5.03,8.97">3</ref> and Figure <ref type="figure" coords="4,390.75,575.44,5.03,8.97">4</ref> show the results for the TREC-2002 subset and TREC-2003 subset, respectively.</p><p>As can be seen from Figure <ref type="figure" coords="4,437.51,598.96,3.77,8.97">3</ref>, the performance is not as good as the performance we obtained using the whole set of queries, but is not as poor as the results we obtained for TREC-2003 either.</p><p>On the other hand, Figure <ref type="figure" coords="4,437.15,643.96,5.03,8.97">4</ref> shows that the performance is better than the performance we obtained using the whole set of queries, but is not as good as the TREC-2002 results.</p><p>What we can conclude is that small number of relevant documents per query can be a factor in our poor performance in TREC-2003, but there should be other reasons as well, that we are trying to find out. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Directions</head><p>We explored two language modeling approaches for the topic distillation task: (1) basic query likelihood method with Dirichlet prior smoothing, and (2) two-stage smoothing with mixture model feedback. The results show that the the two-stage smoothing with feedback significantly outperforms the query likelihood method, confirming the effectiveness of two-stage smoothing <ref type="bibr" coords="5,251.30,579.40,11.63,8.97" target="#b8">[9]</ref> and mixture model feedback method <ref type="bibr" coords="5,188.01,590.20,11.75,8.97" target="#b6">[7]</ref> We also proposed a new general relevance propagation model for combining link and content information, and explored a number of specific methods derived from the model. The experiment results show that combining link and content information generally performs better than using only content information, though the amount of improvement is sensitive to the document collection and tuning of parameters.</p><p>For the future work, we plan to do more experiments to find out what factors affect the performance of our algorithms. We will also explore how to tune the parameters for obtaining the optimal results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,99.24,256.60,174.41,8.97"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Experiments on TREC-2002 Data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,338.16,271.72,174.53,8.97"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Experiments on TREC-2003 Data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,72.00,256.60,228.83,8.97"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Experiments on the Subset of TREC-2002 Data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,331.92,480.28,187.17,85.65"><head>Table 1 :</head><label>1</label><figDesc>Experiments on TREC-2002 Data</figDesc><table coords="3,331.92,480.28,187.17,64.62"><row><cell>Links P@10 Content In Out 0.255 √ 0.267 √ √ Dir + W. OUT 0.265 Run Dir. Base Dir + W. IN √ √ Dir + U. OUT 0.265 √ √</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.00,306.64,229.08,261.93"><head>Table 5 .</head><label>5</label><figDesc>2 summarizes our experiments on TREC-2003 data. The second column in the table is precision at 10 for the submitted runs, while the third column shows precision at 10 when the parameters are tuned to get the optimal results.</figDesc><table coords="4,72.00,370.84,229.08,197.73"><row><cell>Run Dir. Base Dir+W. In Dir+W. Out Dir+U. Out 2s Base 2s+W. In 2s+W. Out 2s+U. Out</cell><cell>P@10 α = 0.8 α = 0.1 0.054  *  0.054 0.058  *  0.066 0.054  *  0.072 0.054  *  0.054 0.064  *  0.064 0.066 0.078 0.062 0.082 0.062 0.062</cell><cell>Links Cont. In Out √ √ √ √ √ √ √ √ √ √ √ √ √ √</cell></row><row><cell cols="3">Table 2: Experiments on TREC-2003 Data</cell></row><row><cell cols="2">*  : Submitted Runs</cell><cell></cell></row><row><cell cols="3">Unlike our results on TREC-2002 data, our experi-</cell></row><row><cell cols="3">ments on TREC-2003 data were not that promising. Fig-</cell></row><row><cell>ure</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,332.51,118.72,207.33,8.97;5,332.52,129.40,207.58,8.97;5,332.52,140.20,207.45,8.97;5,332.52,151.00,62.78,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,426.83,118.72,113.00,8.97;5,332.52,129.40,207.58,8.97;5,332.52,140.20,31.82,8.97">Document language models, query models, and risk minimization for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,380.94,140.20,84.57,8.97">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001-09">2001. Sept 2001</date>
			<biblScope unit="page" from="111" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.51,169.72,207.48,8.97;5,332.52,180.52,84.61,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,399.39,169.72,71.23,8.97">Pliers at trec 2002</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Macfarlane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,490.50,169.72,49.49,8.97;5,332.52,180.52,55.17,8.97">Proceedings of TREC 2002</title>
		<meeting>TREC 2002</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.51,199.24,207.38,8.97;5,332.52,209.92,207.36,8.97;5,332.52,220.72,56.55,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,446.75,199.24,93.13,8.97;5,332.52,209.92,50.24,8.97">Experiments using the lemur toolkit</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,398.92,209.92,140.95,8.97;5,332.52,220.72,27.57,8.97">Proceedings of the 2001 TREC conference</title>
		<meeting>the 2001 TREC conference</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.51,239.44,207.60,8.97;5,332.52,250.24,207.24,8.97;5,332.52,260.92,207.49,8.97;5,332.52,271.72,111.21,8.97" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,332.52,250.24,207.24,8.97;5,332.52,260.92,29.21,8.97">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Digital Library Technologies Project</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="5,332.51,290.44,207.35,8.97;5,332.52,301.24,207.24,8.97;5,332.52,311.92,155.31,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,437.98,290.44,101.87,8.97;5,332.52,301.24,124.35,8.97">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,479.11,301.24,60.64,8.97;5,332.52,311.92,60.87,8.97">Proceedings of the ACM SIGIR</title>
		<meeting>the ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.51,330.64,207.32,8.97;5,332.52,341.44,207.23,8.97;5,332.52,352.24,207.27,8.97;5,332.52,362.92,47.55,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,443.50,341.44,96.25,8.97;5,332.52,352.24,100.55,8.97">Trec 11 experiments at cas-ict: Filtering and web</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,452.99,352.24,86.79,8.97;5,332.52,362.92,18.11,8.97">Proceedings of TREC 2002</title>
		<meeting>TREC 2002</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.51,381.76,207.23,8.97;5,332.52,392.44,207.37,8.97;5,332.52,403.24,207.33,8.97;5,332.52,414.04,200.72,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,436.79,381.76,102.95,8.97;5,332.52,392.44,137.44,8.97">Model-based feedback in the KL-divergence retrieval model</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,492.18,392.44,47.71,8.97;5,332.52,403.24,207.33,8.97;5,332.52,414.04,106.66,8.97">Tenth International Conference on Information and Knowledge Management (CIKM 2001)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.50,432.76,207.35,8.97;5,332.52,443.44,207.58,8.97;5,332.52,454.24,207.34,8.97;5,332.52,465.04,82.67,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,427.79,432.76,112.06,8.97;5,332.52,443.44,207.58,8.97;5,332.52,454.24,50.04,8.97">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,401.32,454.24,85.65,8.97">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001-09">2001. Sept 2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.51,483.76,207.47,8.97;5,332.52,494.44,207.37,8.97;5,332.52,505.24,141.98,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,434.87,483.76,105.11,8.97;5,332.52,494.44,111.30,8.97">Two-stage language models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,464.62,494.44,75.27,8.97;5,332.52,505.24,14.22,8.97">Proceedings of SI-GIR</title>
		<meeting>SI-GIR</meeting>
		<imprint>
			<date type="published" when="2002-08">2002. Aug 2002</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.50,523.96,207.69,8.97;5,332.52,534.76,207.58,8.97;5,332.52,545.44,207.22,8.97;5,332.52,556.24,74.42,8.97" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,497.88,523.96,42.30,8.97;5,332.52,534.76,207.58,8.97;5,332.52,545.44,134.98,8.97">Improving the robustness of language models: Uiuc trec-2003 robust and genomics experiments</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,490.24,545.44,49.50,8.97;5,332.52,556.24,44.98,8.97">Notebook of TREC 2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.50,574.96,207.22,8.97;5,332.52,585.76,207.35,8.97;5,332.52,596.56,192.47,8.97" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,420.01,585.76,119.86,8.97;5,332.52,596.56,37.75,8.97">Thu trec 2002: Web track experiments</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,388.61,596.56,106.94,8.97">Proceedings of TREC 2002</title>
		<meeting>TREC 2002</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
