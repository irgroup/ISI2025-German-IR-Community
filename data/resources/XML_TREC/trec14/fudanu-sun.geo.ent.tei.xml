<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,233.82,75.94,139.07,14.42;1,372.96,72.21,5.25,9.45">WIM at TREC 2005 *</title>
				<funder>
					<orgName type="full">National Natural Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,127.80,111.12,39.49,9.02"><forename type="first">Junyu</forename><surname>Niu</surname></persName>
						</author>
						<author>
							<persName coords="1,174.17,111.12,29.92,9.02"><forename type="first">Lin</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName coords="1,211.08,111.12,42.63,9.02"><forename type="first">Luqun</forename><surname>Lou</surname></persName>
						</author>
						<author>
							<persName coords="1,260.87,111.12,41.80,9.02"><forename type="first">Fang</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName coords="1,310.00,111.12,35.93,9.02"><forename type="first">Chen</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName coords="1,352.49,111.12,58.15,9.02"><forename type="first">Haiqing</forename><surname>Zheng</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,417.80,111.12,66.39,9.02"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<email>xjhuang@fudan.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science &amp; Engineering Department</orgName>
								<orgName type="laboratory">Lab of Web Information Mining</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">{jyniu,sunl</orgName>
								<address>
									<postCode>032021211, 032021202, 042021182, 042021175</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,233.82,75.94,139.07,14.42;1,372.96,72.21,5.25,9.45">WIM at TREC 2005 *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DD1EA081318656BF20261B10FEE3C280</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information retrieval</term>
					<term>text categorization</term>
					<term>domain-specific terms extraction</term>
					<term>ontology</term>
					<term>SVM</term>
					<term>probabilistic model</term>
					<term>entity recognition</term>
					<term>Rocchio</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the three TREC tasks we participated in this year, which are, Genomics track's categorization task and ad hoc task, and Enterprise track's known item search task. For the categorization task, we adopt a domain-specific terms extraction method and an ontology-based method for feature selection. A SVM classifier and a Rocchio based two staged classifier were also used in this experiment. For the ad-hoc task, we used BM25 algorithm, probabilistic model and query expansion. For the Enterprise track, language model was adopted, and entity recognition was also implemented in our experiment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>WIM participated in Genomics track and Enterprise track in TREC 2005. This year's Genomics track consists of two tasks, one is called ad-hoc retrieval task, the other is called categorization task. In the ad hoc task of Genomics track, we mainly concern on: <ref type="bibr" coords="1,213.13,490.63,11.68,9.02" target="#b0">(1)</ref> the efficiency of language model; (2) query expansion (3) the weight of query terms. In this year's Enterprise Track, we attended Known Item Search task. This paper is organized as follows. First, we give a detailed description of our experiment on categorization task. We present the main architecture of our system and discuss every step independently and carefully. Then we discuss our work on ad hoc task. Finally, we describe our system for enterprise track of this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Categorization task of Genomics Track</head><p>The categorization task is similar to last year's triage task <ref type="bibr" coords="1,133.90,674.58,11.70,9.02" target="#b0">[1]</ref> in the purpose of classifying the The data set of this task is collected from three magazines in the biochemistry field which contains 11880 documents. And those articles are in SGML format. The task is to find out the articles to be sent to the curators for manual operation. Those articles are regarded as the "positive" samples, while the others are treated as the "negative" samples. And the official measurement for this categorization task is the utility score which just like last year.</p><p>We have submitted twelve runs of this task which will be discussed carefully later, and got highest scores of E and G subtasks on the feature generated by the feature selection method based on domain-specific term extraction using corpus comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System description</head><p>As figure <ref type="figure" coords="1,357.76,536.57,5.01,9.02" target="#fig_0">1</ref> shows, the system contains three main parts:</p><p>cleaning, feature selection, and classification.</p><p>In the cleaning part, a SGML parser was developed to transform the corpus files into pure text format files. The document's body text, keywords, and glossary were extracted. We experimented using different parts of the document for feature selection and classifying. Terms were separated by the punctuation and blank characters, the hyphen characters and the full stop characters between figures or characters were ignored too. Porter stemmer and different stopword lists were implemented.</p><p>In the feature selection part, two feature selection methods were implemented, one of which focused on domain-specific term extraction using corpus comparison, the other focused on word-meaning and the usage of domain-specific ontology.</p><p>In the classification part, two-stage classification strategy was used. Classifiers such as SVM Light <ref type="bibr" coords="2,281.40,154.86,10.52,9.02" target="#b2">[3]</ref>, NN, KNN, and Rocchio were implemented on different features to find out the best combination of classifier and feature. To extract domain-specific terms without these limits, we assume that the distribution of terms following the domain-specific terms varies in different domain corpus, and the larger variation indicates the larger speciality of the domain-specific terms.</p><p>Based on this assumption, we selected the GOV corpus as the general domain corpus, for each term, we compared the distribution of terms following it then the speciality score is computed out, terms with top speciality were selected as domain-specific terms. Finally, documents were represented by these domain-specific terms and terms around them.</p><p>Our experiment has shown good results. And the performance is acceptable. The genomics domain-specific terms in genomics corpus can be computed out in some minutes.</p><p>The architecture of this method is shown in the following figure <ref type="figure" coords="2,384.46,223.80,3.76,9.02" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Corpus selection</head><p>To select a corpus for comparing, there are two basic requirements in corpus selection: (1) the selected corpus should be in general domain, contains wide range topics; (2) the selected corpus should contain similar number of terms as the genomics corpus.</p><p>However, it's hard to follow the second requirement strictly. We selected a subset of the GOV corpus with similar size instead of similar number of terms as the genomics corpus, which can meet the second requirement approximately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Bi-gram phrase analysis and computing the speciality scores using corpus comparison</head><p>Bi-gram phrase is defined as two terms without any terms or punctuation between them.</p><p>In order to compute the speciality scores of each term, the same terms were assigned a unique ID in two corpuses. Then, the following statistics were counted:</p><p>(1) tf i A : frequency of term i in Genomics Corpus. (2) tf i B : frequency of term i in GOV Corpus. (3) pf ij A : frequency of bi-gram phrase begin with term i and end with term j in Genomics Corpus. (4) pf ij B : frequency of bi-gram phrase begin with term i and end with term j in GOV Corpus.</p><p>(5) fn i : the number of different terms following term i in bi-gram phrases in both Corpuses.</p><p>The speciality scores of terms are calculated by the following formula: According to this formula, terms with fn i =0 are ignored, terms with S i B =0 and S i A ≠0 are assigned -1 to indicate maximum value. Terms with higher speciality score are selected as genomics domain-specific terms.</p><formula xml:id="formula_0" coords="3,141.41,305.05,101.04,81.31">∑ = - = i fn j i B i A ij A i fn tf pf S 1 2 ) 1 ( ∑ = - = i fn j i A i B ij B i fn tf pf S</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Feature selection with domain-specific terms</head><p>The selected genomics domain-specific terms and 2 or 4 terms before or following them are selected to represent the document. In order to see how well this method works, we simply use single terms as features. We compared the raw term frequency and log term frequency as the feature value, and found out that log term frequency worked much better than the raw term frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ontology-guided Feature Selection</head><p>For large corpus multi-class classification, it is a challenge to select a certain amount of informative features to represent the documents. High dimension of features will distinctly reduce the performance of classifiers. General text categorization methods, which treat document as "bag of words" and compare the term-goodness by statistic information rather than semantic information, lead to poor understanding of documents. Furthermore, recognizing the entities is a key problem for biomedical text categorization. The meanings of the entities and the inherent hierarchical structure of the nomenclature are not appropriately treated in those approaches. Our research shows that feature selection employing a domain-specific ontology has a promising effect in solving these problems.  The paragraphs in the body text and captions of the figures in biomedical essays are regarded as informative. Therefore words from these parts were selected. Keyword and glossary are special parts, while both of them are helpful to define the key concepts discussed in the document. Hence keywords and glossaries were selected as features too. For dimension reduction, we abandoned the frequently used methods, such as document frequency, chi-square and information gain, which all define a threshold to select an acceptable number of features for classifiers. An ontology-guided approach was adopted instead. We made advantage of the medical ontology MESH_Tree and manmade rules concluded from the cheatsheet to reduce the influence of synonyms and hyponyms. Synonymous terms were removed and entities were changed to a more general form according to MESH_Tree. After the two steps, each feature was given a weight related to its distribution in the corpus. The weight of term i in document k was computed by a formula slightly different from the original entropy formula.</p><formula xml:id="formula_1" coords="4,90.00,270.47,205.63,65.72">1 1 log( 1.0) * (1 [ log( )]) log N ij ij ik ik j i i i i f f a f n n N df df = = + + ∑ 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Classifiers</head><p>Classifiers we used include the SVM Light  For the second stage classifier in the year's categorization track, we used a traditional Rocchio algorithm. The Rocchio algorithm was used a lot in the relevance feedback in information retrieval area <ref type="bibr" coords="4,111.11,696.97,10.63,9.02" target="#b3">[4]</ref>. This algorithm first formed a center of each class, and then computed the similarity between all the samples in the test set and that center vector. Then we did classification according to the similarity value. We will describe the Rocchio classifier implemented in our experiment in the following part.</p><p>After the feature selection step a sample in the corpus was represented by a vector such as ( , ,..., , )</p><formula xml:id="formula_2" coords="4,318.84,163.92,203.18,16.68">i i m m F t w t w = &lt; &gt; &lt; &gt; , in which</formula><p>stands for the term of indexed files, and is the corresponding weight to the term . Then we form an initial profile for these training samples. So the center of each class is as follows:</p><formula xml:id="formula_3" coords="4,318.06,186.11,189.37,71.54">i t i w i t 1 2</formula><p>( , , , )</p><formula xml:id="formula_4" coords="4,318.06,240.96,117.93,18.06">i i i i m Center w w w = L</formula><p>, where the weight of the feature term is ) , ( At last, a threshold for each class was defined, and those documents with similarity value bigger than the threshold was classified as the positive ones, while those with smaller similarity values were be treated as the negative ones.</p><p>And we also do some slightly change to the equation we mentioned before, which means that we did not use all the negative samples. We notice that those documents which are more similar to the positive samples have stronger effect to the classification results. So, we formed a new set called Nearly Positive Set, presented as . In our experiment we treated the articles which i npos derived from the filtering step which applied those decision rules we described as our first stage classifier. So we get the new equation to form the center of each class as follows:</p><formula xml:id="formula_5" coords="5,125.88,127.12,135.52,29.92">l i l i ij il il d pos d npos w w α β ∈ ∈ = - ∑ ∑ w .</formula><p>Table <ref type="table" coords="5,115.79,172.62,5.01,9.02">2</ref> shows the final utility of our experiment, which shows that about 3% increment on normalized utility when we use the near positive samples.</p><p>Here we want to point out that in our categorization task, the negative samples are really important. We have done some experiments which showed that if we just ignore the negative samples, the performance will be really bad when compared to the runs which when using the negative samples which are in the near positive set. From table 2 we will see that the normalized utility of the latter method improves nearly about 15%.</p><p>Table <ref type="table" coords="5,114.89,508.74,3.91,9.02">2</ref>: The utility score of each class for different classifiers (these data derived from thresholds which adjusted from those used for official runs)</p><p>In this year's track, we have combined the two feature selection methods with different classifiers, such as Neural Network, k-nearest neighbor, SVM Light , Rocchio and so on, from which we found that when combined with the domain-specific term extraction the SVM Light classifier produced the best results. The parameters for this classifier we adopted were just the same as Fujita <ref type="bibr" coords="5,115.82,646.75,10.62,9.02" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Results</head><p>We submitted 3 series of runs for each subtask, totally 12 official runs. Details are listed in the following table <ref type="table" coords="5,380.04,74.34,3.77,9.02" target="#tab_1">3</ref>. "Window" is defined as the selected domain-specific terms together with terms around them.</p><p>"Window Size" is defined as the number of terms before or following the selected domain-specific term.</p><p>Table <ref type="table" coords="6,116.70,223.80,5.01,9.02" target="#tab_2">4</ref> gives a glance of our best results among all official results of this year's categorization task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Conclusions and future work of Categorization Task</head><p>The results of our official runs have shown that the methods mentioned above worked well.</p><p>For the domain-specific terms extraction method, the results have shown that the assumption is reasonable, the extracted terms can represent the domain-specific documents very well, and are fitter for the Embryologic Gene Expression class among the four classes.</p><p>The ontology-guided feature selection method also has positive affect. It has reduced the dimension and improved the system performance successfully.</p><p>And in our experiment we found that some classification methods are really sensitive to the feature which selected from the initial corpus and the dimension of the feature space. After compared a lot classifiers, such as SVM, Neural Network and so on, we found that the performance of the Rocchio classifier seems really stable.</p><p>We believe that the combination of these two feature selection methods will generate better features and lead to better results. This is what we plan to do in the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Ad Hoc retrieval task of Genomics Track</head><p>This year we also attended genomics ad hoc, of which the queries changed bit, making it much closer to normal requirement than before.</p><p>The ad hoc retrieval task was designed to simulate the subject topic retrieval against a ten year subset (4,591,008 records) of the MEDLINE bibliographic database as 2004. This year, there were fifty official (and other samples) search topics derived from interviews on real biology researchers, taking the form of QA (question &amp;&amp; answer) rather than phrases.</p><p>Relevance assessments were carried out by using the conventional pooling method, and all the pooled documents were divided into three genres: definitely relevant (DR), possibly relevant (PR) or not relevant (NR) against the information needs. Documents in the first two genres were considered relevant in official evaluations.</p><p>Participants were required to submit two sets of top 1000 relevance ranked lists of documents retrieved by either automatically or manually constructed queries from given search topics. There were no specific restrictions concerning using data resources, and we only chose some dictionaries as our main resources.</p><p>This year we mainly concerned on the difference between BM25 algorithm <ref type="bibr" coords="6,439.86,442.32,11.74,9.02" target="#b5">[6]</ref> and the KLdivergence algorithm <ref type="bibr" coords="6,406.07,453.78,11.68,9.02" target="#b6">[7]</ref> and give each dictionary a distinct weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Description</head><p>We mainly used two sets of systems, okapi and probabilistic language model, which were quite popular in the past few years.</p><p>We extracted TI, MH,AD and AB from the Corpus, weighing respectively 1.0, 0.5, 0.5 and 1.0, and remarkably influencing the final result according to results of the previous years.</p><p>In the course, we also utilized the porter stemming and removed the stop words, and found that stemming could improve the MAP. Furthermore, we also applied the blind feedback technology for Okapi <ref type="bibr" coords="6,413.40,672.84,11.70,9.02" target="#b7">[8]</ref> BM25 algorithm and KL-divergence for Language models. This year, two values of the parameters in our system --k1and b of our system were respectively 0.1 and 0.8.</p><p>Uses of probabilistic language model in information retrieval intended to adopt a theoretically motivated retrieval model. Ponte and Croft first applied a document unigram model to compute the probability of the given query generated from a document <ref type="bibr" coords="7,202.17,270.43,10.60,9.02" target="#b8">[9]</ref>. Furthermore, the probabilistic language model was also used by the FUJITA who achieved the best MAP score.</p><p>This year, the three parameters of out system---the value of feedback coefficient, the number of terms feedback and the value of documents feedback were respectively 0.1, 10 and 100</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Expansion</head><p>For each search topic, we held it was better for us to look up the categories of the terms if a question contained more than two genomics terms. If these terms belonged to one category, the weight should be added. For example, for two query terms in the human category, the weight of them should receive a bonus of 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bonus</head><p>Others 0.0 Mouse 0.2 Human 0.5 Table <ref type="table" coords="7,130.90,548.88,3.91,9.02">5</ref>: Term Category and relevant bonus We also weighed the dictionaries. Every dictionary should have a distinctive weight. Thesaurus looked up in one dictionary should bring the dictionary's weight, so even a query term that was extended, should have some different weight of thesauruses. But the result wasn't satisfying, probably due to the problems in the programming or the wrong method. This needs our efforts to improve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>We submitted 50 search topics results, all of which got judged except the topic 135. Through this experiment, we conclude that the performance of KL-divergence is a bit better than that of BM25 algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Conclusions and future work of Ad hoc task</head><p>For the ad hoc retrieval task, we submitted one run using BM25 algorithm and another run using KL-divergence with Dirichlet smoothing. It seems that the run using KL-divergence with Dirichlet smoothing is better than the one using BM25 algorithm.</p><p>In future, we will continue the research on the query expanding methods and how to give a reasonable weight. Furthermore, we may improve the smoothing method used in the KL-divergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Enterprise Track</head><p>This year is the first year of this track. And there are few mature methods or model. We mainly focus on Known Item Search subtask of the email search. The scenario of this subtask is that the user is trying to find an important email that they know exists.</p><p>Among the 25 questions for training, we found there are 4 questions contained people names while 3 questions contained time information. For these 7 (28%) special questions, we tried to do entity recognition, which seems also effective for the test questions from our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments</head><p>Figure <ref type="figure" coords="7,346.91,564.71,5.01,9.02" target="#fig_6">5</ref> shows our system architecture. And the retrieval model is a unigram language-modeling algorithm based on Kullback-Leibler divergence <ref type="bibr" coords="7,316.62,599.22,15.34,9.02" target="#b9">[10]</ref>.</p><p>We recognize people's name and time based on a set of rules. Both of the two kinds of information are looked as phrases. It means, when we do retrieval for these phrases, the nearer the words in phrase appear, the higher the score of the mail is.</p><p>We found that there are many questions related to people's name and time ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results &amp; discussions</head><p>The Average reciprocal rank of our submitted run is: 0.533. The figure 5 below is the ranking distributing figure of our system. 39% questions gain rank1. Number of topics for which target page found in top 10: 98 (78.4%)</p><p>The data related questions gain 40% better, and people's name contained questions gain 12.3% effects. So, people's name and time recognition can improve retrieval results.</p><p>However, we could not do well for some questions. 6 questions are like QA question. For example, KI64: Why doesn't Amaya have a hand-shaped cursor? And the average RR of 67 submitted runs for the 6 questions are 0.059, 0.091, 0.125, 0.333, 0.5, and 1. So, normal method could not do well for this kind of questions. I think, in future we can make improves using two measures below:</p><p>A. More semantic understanding is needed.</p><p>Try to use some common methods in QA B. The relation between original message and the reply messages. Basically, there are two kinds of results people trying to get from the known-item search: one kind is announcements, which is always locate in the original message; the other kind is the answer of some questions, which always locate in the reply messages. For the second kind, the reply messages need more attention.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,213.24,126.36,9.02;2,90.00,223.02,205.50,171.78"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System architecture</figDesc><graphic coords="2,90.00,223.02,205.50,171.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,316.62,247.74,205.32,9.02;2,316.62,259.20,153.15,9.02;2,316.62,269.04,205.68,236.88"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of feature selection based on domain-specific terms extraction</figDesc><graphic coords="2,316.62,269.04,205.68,236.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,175.38,379.14,3.49,6.32;3,239.10,362.22,3.49,6.32;3,234.54,364.20,3.98,10.83;3,222.96,356.64,5.98,10.83;3,180.97,364.20,3.98,10.83;3,215.52,420.93,4.54,6.50;3,214.02,429.87,2.06,6.50;3,215.88,402.93,4.54,6.50;3,214.02,411.81,2.06,6.50;3,189.60,419.91,2.06,6.50;3,207.30,423.19,6.37,11.16;3,207.30,405.13,6.37,11.16;3,162.48,413.23,27.62,11.16;3,196.14,408.77,6.98,15.66;3,90.00,451.59,23.46,9.47;3,113.46,451.32,114.11,9.02;3,90.00,463.11,6.78,9.47;3,96.78,460.93,3.96,5.65;3,100.74,462.84,11.82,9.74;3,112.56,460.93,3.96,5.65;3,116.52,462.84,85.05,9.02;3,90.00,474.36,172.86,9.02"><head></head><label></label><figDesc>i : speciality score of term i.S iA , S i B : temporary variables Other symbols have been illustrated above.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="3,316.62,292.80,205.39,9.02;3,316.62,304.32,98.02,9.02;3,316.62,349.50,216.84,272.28"><head>Figure 3</head><label>3</label><figDesc>Figure 3 describe the architecture of this ontology guided feature selection.</figDesc><graphic coords="3,316.62,349.50,216.84,272.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="3,316.62,328.20,217.05,9.02;3,316.62,339.72,69.73,9.02"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Architecture of the ontology guided feature selection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="4,400.62,269.40,3.89,5.98;4,397.20,263.06,3.30,10.34;4,392.04,312.33,1.41,4.43;4,409.14,312.33,1.41,4.43;4,449.16,312.33,1.41,4.43;4,466.02,312.33,1.41,4.43;4,362.52,300.87,3.93,6.11;4,420.66,300.87,3.93,6.11;4,477.61,300.87,3.87,6.11;4,388.44,309.21,20.90,6.11;4,445.56,309.21,20.36,6.11;4,355.26,294.39,8.08,10.57;4,413.46,294.39,8.08,10.57;4,379.14,289.47,7.63,15.67;4,437.03,289.47,6.64,15.67;4,394.14,306.76,4.99,8.57;4,451.25,306.76,4.99,8.57;4,370.74,290.16,6.64,14.83;4,428.21,290.16,6.64,14.83;4,470.34,294.39,8.08,10.57;4,393.54,286.84,12.94,22.24;4,450.54,286.84,12.94,22.24;4,316.62,335.16,36.27,9.02;4,377.58,340.57,1.93,6.05;4,361.14,334.13,160.89,10.46;4,316.62,353.15,120.99,9.02;4,476.70,353.15,45.29,9.02;4,316.62,369.90,173.84,9.02;4,464.46,358.57,1.93,6.05;4,446.88,352.13,17.28,10.46;4,496.32,363.61,7.75,15.92;4,507.42,369.90,2.51,9.02;4,511.98,364.28,6.46,15.25;4,316.62,384.05,205.42,9.02;4,316.62,395.58,205.42,9.02;4,316.62,407.10,188.82,9.02;4,316.62,418.56,205.48,9.02;4,316.62,430.08,205.37,9.02;4,316.62,441.60,172.45,9.02;4,472.62,501.70,12.76,21.94;4,434.81,501.70,12.76,21.94;4,443.52,466.49,12.76,21.94;4,477.12,521.35,3.82,8.53;4,439.32,521.35,3.82,8.53;4,448.02,486.13,3.82,8.53;4,416.04,486.11,6.55,14.63;4,476.52,500.21,5.03,6.08;4,474.36,523.79,1.94,6.08;4,495.06,515.33,3.88,6.08;4,438.72,500.21,5.03,6.08;4,436.62,523.79,1.94,6.08;4,457.26,515.33,3.88,6.08;4,447.42,464.99,5.03,6.08;4,445.26,488.57,1.94,6.08;4,479.34,480.17,3.88,6.08;4,465.96,480.17,3.88,6.08;4,405.06,496.49,1.94,6.08;4,365.16,496.49,1.94,6.08;4,487.26,509.06,7.97,10.42;4,449.46,509.06,7.97,10.42;4,471.48,473.90,7.97,10.42;4,458.16,473.90,7.97,10.42;4,373.20,490.27,32.53,10.42;4,358.26,490.27,5.98,10.42;4,335.76,490.27,17.93,10.42;4,480.54,523.60,3.49,6.27;4,495.96,506.80,3.49,6.27;4,442.80,523.60,3.49,6.27;4,458.16,506.80,3.49,6.27;4,451.44,488.38,3.49,6.27"><head></head><label></label><figDesc>set of positive training samples for class i , and means the negative training samples for the class i. i neg α , β are real numbers, which indicate the importance of positive and negative portion of the training samples when forming the center of each class.When the center for each class was formed, we can compute the similarity between the documents to be classified and each class's center vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,316.62,167.22,160.88,9.02"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Question distributing figure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,89.99,350.04,205.48,286.94"><head>Table 1 :</head><label>1</label><figDesc>The number of the test files before and after filtering</figDesc><table coords="4,90.00,569.04,197.30,32.72"><row><cell>Corpus Size Before Filtering</cell><cell>After Filtering</cell></row><row><cell>6043</cell><cell>2494</cell></row></table><note coords="4,261.24,350.04,34.15,9.02;4,90.00,361.56,205.37,9.02;4,90.00,373.08,78.86,9.02;4,168.78,370.99,14.04,5.83;4,185.76,373.08,109.66,9.02;4,89.99,384.54,205.48,9.02;4,89.99,396.06,205.39,9.02;4,89.99,407.59,143.66,9.02;4,90.00,430.56,205.35,9.02;4,90.00,442.08,205.38,9.02;4,90.00,453.54,205.34,9.02;4,90.00,465.06,205.30,9.02;4,90.00,476.53,205.45,9.02;4,90.00,488.05,205.38,9.02;4,90.00,499.57,205.33,9.02;4,90.00,511.04,205.40,9.02;4,90.00,522.56,205.39,9.02;4,90.00,534.08,205.43,9.02;4,90.00,545.55,180.78,9.02"><p><p>, Neural Network, KNN, and Rocchio. Our experiments show that the SVM Light classifier is suitable for the feature generated by the domain-specific term extraction method, while the Rocchio classifier is suitable for ontology based method.</p>After having researched the corpus carefully we realized that the four classes of this year's Genomics track's categorization task have there specialty. Taking the T(tumor) class for example, there are some specialties from the aspect of word-building. Some words always indicate that those articles having strong relationship with the class T. While some others indicate that this article must have no or less relationship with that class. All the documents in the corpus are filtered by those rules. After that, we got a small corpus.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,90.00,98.94,432.10,616.94"><head>Table 3 :</head><label>3</label><figDesc>The results of official runs.</figDesc><table coords="5,316.62,361.92,205.48,353.96"><row><cell>MarsI: we select the best runs for each subtask in</cell></row><row><cell>our experiments, their classifier are all SVM Light ,</cell></row><row><cell>the features are all generated by the feature</cell></row><row><cell>selection method based on domain-specific term</cell></row><row><cell>extraction using corpus comparison.</cell></row><row><cell>A. window size is 4, top 2000 specified</cell></row><row><cell>domain-specific terms, except terms</cell></row><row><cell>with the speciality score of -1.</cell></row><row><cell>E. window size is 2, top 500 specified</cell></row><row><cell>domain-specific terms, except terms</cell></row><row><cell>with the speciality score of -1.</cell></row><row><cell>G. window size is 4, top 2000 specified</cell></row><row><cell>domain-specific terms, except terms</cell></row><row><cell>with the speciality score of -1.</cell></row><row><cell>T. window size is 0, top 25000 specified</cell></row><row><cell>domain-specific terms, including terms</cell></row><row><cell>with the speciality score of -1, about</cell></row><row><cell>5000 terms with lowest otherness score</cell></row><row><cell>added to the stopword list.</cell></row><row><cell>MarsII: features are generated by the feature</cell></row><row><cell>selection method based on domain-specific term</cell></row><row><cell>extraction using corpus comparison. We fix the</cell></row><row><cell>number of domain-specified terms as 500, except</cell></row><row><cell>terms with the speciality score of -1, and the size</cell></row><row><cell>of window as 2, use SVM Light classifier, to see how</cell></row><row><cell>it works for different subtask. This series of runs</cell></row><row><cell>comes out the highest mean normal utility score of</cell></row><row><cell>our three series of runs.</cell></row><row><cell>MarsIII: we employed a domain-specific ontology</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,160.20,332.28,64.97,9.02"><head>Table 4 :</head><label>4</label><figDesc>Results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,379.80,127.74,79.02,9.02"><head>Table 6 :</head><label>6</label><figDesc>the Results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,315.00,91.73,222.95,619.94"><head>table 7</head><label>7</label><figDesc></figDesc><table coords="7,454.62,702.66,67.38,9.02"><row><cell>). There are 16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,116.28,442.44,157.84,20.54"><head>Table 7 :</head><label>7</label><figDesc>number of questions contained time/people name.</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* Supported by the <rs type="funder">National Natural Science Foundation</rs> of</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,337.62,468.84,184.29,9.02;8,337.62,480.30,184.44,9.02;8,337.62,491.82,110.27,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,423.71,468.84,98.20,9.02;8,337.62,480.30,62.29,9.02">TREC 2004 Genomics Track Overview</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,407.01,480.30,115.05,9.02;8,337.62,491.82,83.37,9.02">Proceedings of the 13th Text Retrieval Conference</title>
		<meeting>the 13th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,337.62,514.80,184.38,9.02;8,337.62,526.32,184.40,9.02;8,337.62,537.84,184.42,9.02;8,337.62,549.30,75.39,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,431.35,514.80,90.65,9.02;8,337.62,526.32,144.86,9.02">Machine Learning in Automated Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,499.26,526.32,22.76,9.02;8,337.62,537.84,124.10,9.02">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Volume: 34 Mar</note>
</biblStruct>

<biblStruct coords="8,337.62,572.34,184.43,9.02;8,337.62,583.80,184.49,9.02;8,337.62,595.32,184.24,9.02;8,337.62,606.84,184.38,9.02;8,337.62,618.31,66.95,9.02" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,403.08,572.34,118.96,9.02;8,337.62,583.80,184.49,9.02;8,337.62,595.32,163.08,9.02">Advances in Kernel Methods -Support Vector Learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<editor>B. Scholkopf and C. Burges and A. Smola</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT-Press</publisher>
		</imprint>
	</monogr>
	<note>Making Large-Scale SVM Learning Practical</note>
</biblStruct>

<biblStruct coords="8,337.62,641.27,184.35,9.02;8,337.62,652.80,38.35,9.02;8,392.52,652.80,11.70,9.02;8,420.71,652.80,47.78,9.02;8,485.08,652.80,36.96,9.02;8,337.62,664.32,184.35,9.02;8,337.62,675.78,184.24,9.02;8,337.62,687.31,184.33,9.02;8,337.62,698.83,33.33,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,422.87,641.27,99.10,9.02;8,337.62,652.80,38.35,9.02;8,392.52,652.80,11.70,9.02;8,420.71,652.80,47.78,9.02;8,485.08,652.80,33.26,9.02">Incremental Relevance Feedback for Information Filtering</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,337.62,664.32,184.35,9.02;8,337.62,675.78,184.24,9.02;8,337.62,687.31,148.38,9.02">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Zurich</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="270" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.00,74.34,184.44,9.02;9,111.00,85.86,184.27,9.02;9,111.00,97.32,184.31,9.02;9,111.00,108.85,165.25,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,180.15,74.34,115.29,9.02;9,111.00,85.86,184.27,9.02;9,111.00,97.32,116.76,9.02">Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis</title>
		<author>
			<persName coords=""><forename type="first">Fujita</forename><surname>Sumio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,234.83,97.32,60.48,9.02;9,111.00,108.85,138.35,9.02">Proceedings of the 13th Text Retrieval Conference</title>
		<meeting>the 13th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.00,131.82,184.36,9.02;9,111.00,143.34,184.36,9.02;9,111.00,154.86,184.43,9.02;9,111.00,166.32,12.26,9.02;9,154.56,166.32,22.25,9.02;9,208.16,166.32,17.66,9.02;9,257.06,166.32,38.34,9.02;9,111.00,177.85,89.15,9.02;9,221.99,177.85,22.26,9.02;9,265.96,177.85,29.42,9.02;9,111.00,189.37,184.28,9.02;9,111.00,200.83,35.91,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,138.23,154.86,72.26,9.02">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,233.46,154.86,61.97,9.02;9,111.00,166.32,12.26,9.02;9,154.56,166.32,22.25,9.02;9,208.16,166.32,17.66,9.02;9,257.06,166.32,38.34,9.02;9,111.00,177.85,84.46,9.02">Proceedings of the Third Text REtrieval Conference(TREC-3)</title>
		<meeting>the Third Text REtrieval Conference(TREC-3)<address><addrLine>Washington D.C</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.00,223.80,184.34,9.02;9,111.00,235.32,184.31,9.02;9,111.00,246.84,184.39,9.02;9,111.00,258.30,184.35,9.02;9,111.00,269.83,184.43,9.02;9,111.00,281.35,184.44,9.02;9,111.00,292.81,35.91,9.02" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,248.69,223.80,46.65,9.02;9,111.00,235.32,184.31,9.02;9,111.00,246.84,167.22,9.02">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,111.00,258.30,184.35,9.02;9,111.00,269.83,184.43,9.02;9,111.00,281.35,90.33,9.02">Proceedings of the 2001 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 2001 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.00,315.84,184.35,9.02;9,111.00,327.30,184.46,9.02;9,111.00,338.82,184.30,9.02;9,111.00,350.34,184.36,9.02;9,111.00,361.81,184.39,9.02;9,111.00,373.33,184.42,9.02;9,111.00,384.85,101.96,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,272.66,315.84,22.69,9.02;9,111.00,327.30,184.46,9.02;9,111.00,338.82,184.30,9.02;9,111.00,350.34,35.24,9.02">Some Simple Effective Approximations to the 2-Poisson Model for Probabilistic Weighted Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,166.68,350.34,128.68,9.02;9,111.00,361.81,184.39,9.02;9,111.00,373.33,180.51,9.02">Proceedings of the 1994 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1994 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.00,407.81,184.45,9.02;9,111.00,419.34,184.30,9.02;9,111.00,430.80,184.30,9.02;9,111.00,442.32,184.43,9.02;9,111.00,453.79,184.31,9.02;9,111.00,465.31,37.59,9.02" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,249.03,407.81,46.41,9.02;9,111.00,419.34,180.73,9.02">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,125.64,430.80,169.66,9.02;9,111.00,442.32,184.43,9.02;9,111.00,453.79,86.93,9.02">Proceedings of the 1998 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1998 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,111.00,488.27,184.42,9.02;9,111.00,499.80,183.36,9.02" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,245.03,488.27,50.39,9.02;9,111.00,499.80,77.21,9.02">Elements of Information Theory</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
