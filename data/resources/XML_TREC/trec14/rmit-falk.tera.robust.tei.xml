<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,96.48,117.90,418.70,23.74">RMIT University at TREC 2005: Terabyte and Robust Track</title>
				<funder ref="#_uPmt223">
					<orgName type="full">RMIT University</orgName>
				</funder>
				<funder>
					<orgName type="full">Australian Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.00,152.59,76.47,16.49"><forename type="first">Yaniv</forename><surname>Bernstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>GPO Box 2476V</addrLine>
									<postCode>3001</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.35,152.59,78.63,16.49"><forename type="first">Bodo</forename><surname>Billerbeck</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>GPO Box 2476V</addrLine>
									<postCode>3001</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.98,152.59,66.77,16.49"><forename type="first">Steven</forename><surname>Garcia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>GPO Box 2476V</addrLine>
									<postCode>3001</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,193.68,166.51,75.28,16.49"><forename type="first">Nicholas</forename><surname>Lester</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>GPO Box 2476V</addrLine>
									<postCode>3001</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.96,166.51,60.42,16.49"><forename type="first">Falk</forename><surname>Scholer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>GPO Box 2476V</addrLine>
									<postCode>3001</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.38,166.51,58.85,16.49"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<addrLine>GPO Box 2476V</addrLine>
									<postCode>3001</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.76,222.55,78.41,16.49"><forename type="first">William</forename><surname>Webber</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,96.48,117.90,418.70,23.74">RMIT University at TREC 2005: Terabyte and Robust Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DB5A7B9E33B1C38FD76DA6D5C41E958F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We used zettair for all experiments outlined in this paper. Zettair is a publicly available retrieval engine developed by the Search Engine Group at RMIT University. It is available under a BSD license from http://www.seg.rmit.edu.au/zettair and was described in more detail in our submission to TREC last year (Billerbeck et al., 2004).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Terabyte Track</head><p>We participated in all three tasks: adhoc, efficiency and named page finding. The description of the runs and the results are given in the following for each of the three tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>RMIT University participated in the terabyte and robust tracks in TREC 2005.</p><p>The terabyte track consists of the three tasks: adhoc retrieval, efficient retrieval, and named page finding. For the adhoc retrieval task we used a language modelling approach based on query likelihood, as well as a new technique aimed at reducing the amount of memory used for ranking documents. For the efficiency task, we submitted results from both a single-machine system and one that was distrubuted among a number of machines, with promising results. The named page task was organised by RMIT University and as a result we repeated last year's experiments, slightly modified, with this year's data.</p><p>The robust track has two subtasks: adhoc retrieval, and query difficulty prediction. For adhoc retrieval, we employed a standard local analysis query expansion method, sourcing expansion terms for different runs from the collection supplied, from a side corpus, or a combination of both. In one run, we also tested removing duplicate documents from the list of results; in order to predict topic difficulty, we evaluated different document priors of the documents in the result set, in the hope of supplying a more robust set of answers at the cost of returning a potentially smaller number of relevant documents. The second task was to predict query difficulty. To this end, we compared the order of the documents in the result sets to the ordering as determined by document priors. A high similarity in orderings indicated that the query was poor. Two different priors were used. The first was based on document access counts, where each document is given a score that is derived from how likely it is to be ranked by a randomly generated query. The second was directly related to the document size.</p><p>In this paper we outline our approaches and experiments in both tracks, and discuss our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Adhoc Task</head><p>Unlike last year, where we used Okapi BM25, both adhoc runs we submitted this year are based on language modelling, using a query likelihood approach with Dirichlet smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dirichlet-smoothed Language Modelling</head><p>The query likelihood can be formulated as follows:</p><formula xml:id="formula_0" coords="2,257.28,183.33,97.29,20.34">P (q|d) = tâˆˆq P (t|d)</formula><p>where q is the user query, while document d is one of N documents in the collection, f t of which contain term t. The Dirichlet-smoothed term probability <ref type="bibr" coords="2,285.38,220.42,96.94,13.74" target="#b25">(Zhai and Lafferty, 2004</ref>) is:</p><formula xml:id="formula_1" coords="2,221.88,241.41,166.20,23.52">P (t|d) = |d| Âµ + |d| Ã— f t,d |d| + Âµ Âµ + |d| Ã— f t N</formula><p>where |d| is the length of document d, f t,d is the number of occurrences of term t in document d, and Âµ is a smoothing parameter. Through a series of rank-equivalent transformations, the query likelihood can be efficiently computed by: log P (q|d)</p><formula xml:id="formula_2" coords="2,234.60,314.49,181.06,27.55">rank = |q| Ã— log Î» d + tâˆˆqâˆ©d log N Ã— f t,d Âµ Ã— f t + 1</formula><p>where Î» d = Âµ/ (Âµ + |d|). We trained Âµ on last year's terabyte topics, and set Âµ to a value of 1,500. No stopping was used for this task and -due to an oversight -neither was stemming. Using this approach to the query likelihood model we obtained the run ZETDIRHOC. This run was used as a baseline to compare against the following run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effective Accumulator Limiting</head><p>For the ZETDIRA run made use of a new accumulator scheme, which limits accumulators for greater memory efficiency during query evaluation. This scheme is employed for query evaluation using document-ordered inverted lists processed in a termwise fashion. It keeps accumulators in a linked list for ease of insertion and removal. Unlike previous schemes <ref type="bibr" coords="2,127.75,475.90,102.21,13.74" target="#b14">(Moffat and Zobel, 1996)</ref>, once an accumulator is added for a particular document, it can be removed, depending on a partial similarity threshold that is varied in order to control the number of accumulators used to evaluate the query. For each term, the floating point partial similarity threshold corresponds to an f d,t occurrence threshold, which postings potentially creating new accumulators must exceed before being inserted into the accumulator list. However, existing accumulators are removed if they fall below the partial similarity threshold as they are examined. The partial similarity threshold is set to the minimum partial similarity value while there is no possibility of the accumulator limit being exceeded. Once a sufficiently frequent term is processed that limiting must be employed, an initial partial similarity threshold is estimated from the first few postings. This threshold is re-evaluated periodically, with the period between re-evaluations doubling each time. A simple statistical estimate of the number of expected accumulators at the end of the term is made during each re-evaluation. If this estimate is within a tolerance factor of the accumulator limit, no changes are made to the thresholds. Otherwise, the f d,t threshold is adjusted up or down by a step, with the partial similarity threshold adjusted correspondingly. The step quantity is initially set to half of the f d,t threshold, and halves after each re-evaluation. See <ref type="bibr" coords="2,386.86,631.30,95.18,13.74">Lester et al. (to appear)</ref> for a full description of this method.</p><p>For the ZETDIRA run, we used the new scheme with a limit of 100,000 accumulators, which is 0.4% of the collection size. We employed the same accumulator scheme for the baseline run, but since we used a large accumulator size -240,000 accumulators for 24,000,000 documents, which has been shown to have virtually no impact on retrieval performance <ref type="bibr" coords="2,270.51,691.06,102.11,13.74" target="#b14">(Moffat and Zobel, 1996)</ref> -we effectively did not make use of the accumulator limiting scheme for the baseline.  <ref type="bibr" coords="3,90.72,169.36,26.21,8.97">(bpref)</ref>, and precision at the number of relevant documents for each query (R-P).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Results for the adhoc runs are shown in Table <ref type="table" coords="3,285.15,205.90,3.77,13.74">1</ref>. Our results are reasonably close to the median results obtained over all submitted runs. As expected, the average effectiveness results of our adaptive pruning scheme are effectively the same as the baseline scheme. Note that this scheme has only a negligible effect on evaluation time, but it has a far lower memory consumption (see <ref type="bibr" coords="3,348.89,241.78,92.78,13.74">Lester et al. (to appear)</ref> for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Efficiency Task</head><p>We submitted two runs for the efficiency task. The first one is zettair as described in Section 3.1, using a query likelihood approach with Dirichlet smoothing, but here we used stemming (which was not used for the effectiveness task). There were also other minor differences, as explained below. For the second run, we used a modified system in order to evaluate queries in a distributed manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monolithic</head><p>We made the following modifications to the search engine that was used for the baseline adhoc run. We used a stoplist of 477 terms to stop queries. However, the index was not stopped. Furthermore, in order to decrease the size of the index and speed up query evaluation (since less data has to be processed), we did not store word offsets in the index.</p><p>The machine we used for this experiment was a Intel Pentium IV 2.8 GHz with 2 GB of main memory running Fedora Core 2. More details are given in Table <ref type="table" coords="3,312.58,429.82,3.77,13.74" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distributed</head><p>For the distributed run (ZETDIST) we used a cluster of eight evaluator nodes and one controller. Each evaluator node was a single-processor 2.8 GHz Intel Pentium IV with 1 GB of RAM and a single 250 GB local SATA disk. The index was partitioned document-wise; that is to say, each of the nodes held a local index for one eighth of the documents in the collection. These local indexes were essentially independent of each other, except that global term weights were used during evaluation. Each query was forwarded to each of the nodes by the cluster controller. Each node then evaluated the query against its portion of the index, using the same approach as for the monolithic run, that is, no term offsets were stored in the index. However, no stopping was performed. Once evaluated, the top results and scores were sent back to the controller. Finally, the controller merged the scores and returned the results.</p><p>The total query evaluation time on the cluster was 2901.7 seconds. We note in passing that we observed the requirement, clarified on the task mailing list, that queries be executed serially. This means that the result for one query was returned before processing on the next query began. If this requirement was relaxed, and the parallel processing of queries was allowed (still requiring, though, that queries be started in arrival order), then a significant improvement in processing time could be achieved. For comparison, we conducted (but did not submit) a run allowing up to 24 queries to be processed in parallel. This run took 2283.6 seconds, a speedup of over 25%. Allowing the parallel processing of queries is particularly necessary to achieve maximal throughput for alternative architectures based around partitioning the index by vocabulary, rather than by corpus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" coords="4,115.06,366.10,5.03,13.74" target="#tab_1">2</ref> gives a summary of the two systems that we used for the runs, as well as an overview of the range of systems that were used by other participants.</p><p>The results of our two runs are shown in Table <ref type="table" coords="4,288.15,389.98,3.77,13.74" target="#tab_2">3</ref>. Since no more than 20 results per query were listed, only the precision at 10 and 20 documents returned is comparable with the adhoc results (other measurements such as MAP are not meaningful when comparing runs against those of other tasks, where up to 1000 answers were returned). Again, both runs produced quite comparable results; while the monolithic run is slightly ahead in most effectiveness measures, the distributed run by far outperforms the former in terms of efficiency, by a factor of four. However, this increase in efficiency is coupled with a similar increase in cost for the distributed system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Named Page Finding Task</head><p>Our research group created the topics for this year's named page finding task. To avoid any possible advantage from our knowledge of the query creation process, we limited ourselves to producing runs using mostly the same configurations as submitted to last year's terabyte track.</p><p>We submitted a baseline run, one run that made use of anchor text, one that gave a higher weighting to pages that contained query terms in a small text window, and one where results were restricted to documents where all query terms appeared in the first 50 terms. These runs are briefly discussed in the following sections; for more detail, see our paper from TREC 2004 <ref type="bibr" coords="4,319.78,580.66,93.34,13.74">(Billerbeck et al., 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline</head><p>For the baseline run (ZETNP), we used the standard zettair system with Okapi BM25 (Sparck <ref type="bibr" coords="4,474.40,625.78,46.49,13.74;4,90.72,637.78,21.87,13.74" target="#b20">Jones et al., 2000)</ref>:</p><formula xml:id="formula_3" coords="4,190.80,661.65,228.84,27.06">BM 25(q, d) = tâˆˆq log N -f t + 0.5 f t + 0.5 Ã— (k 1 + 1)f d,t K + f d,t where K = k 1 Ã— (1 -b) + b Ã— |d|Ã—N iâˆˆN |di| , k1 = 1.</formula><p>2, and b = 0.75. Since we set k3 to 0, the query-term frequency component can be dropped from the typical formulation. The main reason for using Okapi is that it is easier to combine with the anchortext ranking scheme that we used, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anchortext</head><p>For the ZETNPANC run, we combined results from the full text index with an index obtained from anchor text, using the metric devised by <ref type="bibr" coords="5,202.67,174.94,85.93,13.74" target="#b10">Hawking et al. (2004)</ref>. For this scheme, the two scores are linearly interpolated, mixing the score of the full text with the anchor text score in a ratio of 4:1. This is the same setting as used last year (that is, we did not train on last year's data). This run was also used as a basis for the next run, described below.</p><p>The anchortext index was constructed from a collection of surrogate documents, where each document in the collection was replaced by the anchor text from inlinks pointing to the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fuzzy Phrase</head><p>We followed our intuition (and earlier, unpublished results) that a document may be a good match if it contains phrases that are made up of query terms, even though these query terms were not explicitly specified by the user as a phrase. We extended the concept of phrases to include fuzzy phrases; here, query terms appear in a short text window, possibly interspersed with other terms. A necessary parameter to consider then is the fuzziness between an exact phrase and its fuzzy phrase counterpart. This parameter governs how large the text window may be. In our case, we used a window size of 20 terms. A fuzzy phrase is also one where terms appear in any order other than that specified in the query, as long as there are no other terms in-between.</p><p>To arrive at the ranking for the ZETNPANCFUZZ run, we mixed the baseline results (72%) in linear combination with scores resulting from anchor text (18%) and the fuzzy phrase scores (10%). The value of 10% was derived by training using the GOV1 collection and the topics and relevance judgements for the named page finding task last year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Priority</head><p>The ZETNP50W run employs a priority scheme, for which those documents are ranked higher where all query terms appear within the first 50 terms of each document. Again, linear interpolation was used between scores derived conventionally and those based on the priority scheme, using a ratio of 9:1. Unlike last year, this year we did not make use of anchor text for this run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results for the named page finding task are shown in Table <ref type="table" coords="5,347.11,525.70,3.77,13.74" target="#tab_4">4</ref>. Our results are somewhat disappointing: even the best run is worse than the mean MRR achieved by all systems and runs. There are two possible reasons for this: we used (more or less) the same approaches as for last year, which were aimed at an adhoc task, rather than designed for a named page finding task. However, comparing our runs, the priority scheme (run ZETNP50W) was by far the best, which is surprising, since it did not make any use of anchor text, which is typically a good source of document descriptors for named page finding tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Robust Track</head><p>We submitted four title-only runs and one mandatory description-only run to the Robust track. Our runs were all automatic; details of the runs are described in the following sections, and summarised in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Adhoc Task</head><p>We used the local analysis query expansion method as proposed by <ref type="bibr" coords="6,369.01,367.30,118.65,13.74" target="#b17">Robertson and Walker (1999)</ref>. Using the setup as described in Section 2, the initial query is ranked against the collection using the Okapi BM25 similarity measure, and the top R documents are identified (see below for variations to this method). All terms from these documents are extracted and each of them is assigned a Term Selection Value:</p><formula xml:id="formula_4" coords="6,250.92,422.84,102.83,26.05">T SV t = f t N rt Ã— |R|</formula><p>r t where f t is the number of documents in the collection that contain term t, N is the number of documents in the collection, |R| is the size of the local set and r t is the the number of documents in R the contain term t. Using this formula, |E| terms with the lowest selection value are selected and appended to the query. Their weighting is determined using the Robertson/Sparck Jones weight <ref type="bibr" coords="6,378.38,489.22,61.00,13.74">(Robertson and</ref><ref type="bibr" coords="6,441.54,489.22,79.44,13.74;6,90.72,501.22,57.88,13.74" target="#b16">Sparck Jones, 1976, Robertson and</ref><ref type="bibr" coords="6,151.00,501.22,55.19,13.74" target="#b17">Walker, 1999)</ref>:</p><formula xml:id="formula_5" coords="6,186.36,522.21,238.05,23.94">w t = 1 3 Ã— log (r t + 0.5)/(f t -r t + 0.5) (|R| -r t + 0.5)/(N -f t -|R| + r t + 0.5)</formula><p>The value of 1/3 was recommended by Robertson in unpublished correspondence, and is used to dampen the impact of expansion terms on the document ranking, when compared to that of the original query terms. (We confirmed this value as suitable in unpublished experiments.) Finally, the query is rerun against the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collection Selection</head><p>In preparation for our runs, we used several collections. One is the target collection for the robust track this year, AQUAINT. It was also used for the novelty track last year and has been described in this context <ref type="bibr" coords="6,90.72,655.18,119.22,13.74" target="#b19">(Soboroff and Harman, 2003)</ref>. Another is the newswire collection used for the adhoc tracks for TREC 7 and 8 <ref type="bibr" coords="6,115.53,667.18,118.97,13.74" target="#b23">(Voorhees and Harman, 1999)</ref>. It consists of the data provided on TREC disks 4 and 5, not including the congressional record. We will refer to this collection as NW. Finally, we used the REUTERS collection, which contains the full set of newswire articles from the Reuters news agency for a one year period from August 1996 (http://www.reuters.com/researchandstandards/corpus/).</p><p>In some runs, in particular RMIT5T0530N and RMIT5T1545TD, instead of ranking initial queries against the AQUAINT collection in order to identify a local set of documents, alternative collections were used: for RMIT5T0530N, in addition to the AQUAINT collection, we also used the adhoc collection from NW; for RMIT5T1545TD we used only the latter.</p><p>The underlying idea for the use of enlarged collections or larger external collections is that retrieval effectiveness -particularly in the high ranks -is greater if a larger collection is used <ref type="bibr" coords="7,419.50,143.86,101.50,13.74;7,90.72,155.74,21.66,13.74" target="#b9">(Hawking and Robertson, 2003)</ref>. Since the local set consists of documents in the top ranks, and local analysis is based on the assumption that sourcing terms from relevant documents is useful, the more relevant documents that are included in the local set, the higher the quality of expansion terms. This approach has been used since TREC 6, see for example <ref type="bibr" coords="7,126.79,191.62,79.47,13.74" target="#b24">Walker et al. (1997)</ref> or <ref type="bibr" coords="7,219.21,191.62,71.67,13.74" target="#b0">Allan et al. (1997)</ref>.</p><p>A danger with using additional collections is that query terms might appear in different contexts than in those provided in the target collection <ref type="bibr" coords="7,259.01,215.62,101.71,13.74">(Kraaij, 2004, Chapter 3)</ref>. We therefore only experimented with newswire collections, which we assume to have a similar use of vocabulary. Although different topics are bound to be covered in different newswire collections, we hope that the mix of those might be helpful for retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training of Query Expansion Parameters and Collections</head><p>In earlier work, we found that varying the parameters |R| (the number of documents in the local set) and |E| (the number of expansion terms added to the query) can have a marked impact on retrieval effectiveness <ref type="bibr" coords="7,90.72,320.50,115.51,13.74">(Billerbeck and Zobel, 2004)</ref>. We therefore trained the local analysis parameters by way of a simple combinatorial search through the following space of parameters, using last year's robust track collection and queries as well as relevance judgements. We varied the number of expansion terms (|E|) added to the initial query through 2, <ref type="bibr" coords="7,159.74,356.38,141.35,13.74">5, 10, 15, 20, 25, 30, 60, 75, and 90</ref>. |R|, the size of the initially retrieved documents, was varied through 1, 2, 5, 10, 15, and 20. Each resulting set of parameters was tested by sourcing expansion terms from the AQUAINT, NW, or REUTERS collections, as well as any combination of these collections. The parameter settings and collection choice that showed most promise were used for the official runs submitted to the TREC robust track for 2005.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Co-derivative Document Removal</head><p>The robust track, and the gMAP measure, are designed to emphasise reasonable worst-case performance on poor queries over more fragile strategies that are capable of extremely good best-case performance but offer few guarantees in the worst case. As such, it is of greater importance to return some relevant documents consistently than to return many relevant documents occasionally.</p><p>Our intuition is that documents that are co-derived -that is, documents that share a common heritage -are more likely to either both be relevant or both be irrelevant. Given this, it is plausible to hypothesise that removing documents from the result list if they are co-derived with an earlier document will increase diversity, and hence increase the probability that at least some relevant documents are present amongst the top n documents in the result list.</p><p>We used the DECO document fingerprinting software <ref type="bibr" coords="7,318.24,557.02,58.49,13.74">(Bernstein and</ref><ref type="bibr" coords="7,379.01,557.02,76.56,13.74">Zobel, 2004, 2005)</ref> to identify pairs of documents that shared some proportion of text. We set the threshold to 0.15, meaning that a pair of documents had to share about 15% of their text before they were considered co-derivative.</p><p>The removal of co-derivative documents was done as a postprocessing step. Zettair was used to create a run with 2,000 results for each query. The run was then postprocessed so that any document that was co-derived with any document higher in the result list was removed. Removal of documents resulted in promotion of all documents lower in the list. Once this process was complete, the top 1,000 remaining documents for each query were selected to form the official run submitted.</p><p>Due to the submission limit we were not able to submit official runs for the same set of parameters with duplicates removed and not removed. However, upon release of the official relevance judgements for the robust track we evaluated the same run in which co-derivative documents had not been removed. No other parameters were tuned or changed. The results are shown in Table <ref type="table" coords="8,231.83,337.78,3.77,13.74" target="#tab_6">6</ref>. The removal of co-derivative documents from the results list was not successful in improving the average performance of the zettair search engine for this dataset. This means that the promotion of documents in the run was insufficient to compensate for the removal of relevant documents by the co-derivative removal process. This occurs, presumably, because -in an effectively functioning search-engine -pairs of co-derived documents near the top of the run are more likely to be relevant than those promoted from the bottom of the run. Thus, the net effect is a loss of effectiveness as measured. We observed the same phenomenon for the TREC 2004 terabyte track <ref type="bibr" coords="8,318.69,409.42,110.83,13.74" target="#b3">(Bernstein and Zobel, 2005)</ref>, but it is interesting to note that it is still the case even for the gMAP measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Since we experimented with different parameters and collection selections for different runs, together with novel approaches such as the duplicate detection, it is difficult to conclude from the five submitted runs alone which approaches were useful and which were not.</p><p>Results are shown in Table <ref type="table" coords="8,213.84,502.54,3.77,13.74" target="#tab_7">7</ref>. Unsurprisingly the run without expansion (RMIT5T0000) performed worst among our title-only runs for all three effectiveness measures. As discussed previously, the general TREC effectiveness evaluation framework (excluding the novelty tracks of previous years) rewards runs where multiple copies of the same (or at least co-derived) relevant document is ranked. The run which removed near duplicate documents (RMIT5T1545TD) therefore performed reasonably badly.</p><p>Our best runs were those that made use of expansion. While the run that sourced terms from the AQUAINT collection only (RMIT5T1025) achieved slightly higher mean average precision and precision at 10 figures, the run which sourced expansion terms from a larger pool of documents (RMIT5T0530N) achieved a marginally better geometric mean average precision. Both runs show comparable effectiveness.</p><p>Although we have shown in previous work that query expansion does not increase robustness for a query set on average <ref type="bibr" coords="8,150.52,622.06,114.79,13.74">(Billerbeck and Zobel, 2004)</ref>, it does seem to increase the effectiveness of those queries that achieve only low performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Topic Difficulty Prediction</head><p>One task of the robust track is topic difficulty prediction. In this task participants are asked to predict the difficulty of a run by producing a ranking from best to worst performing topic. Using the average precision of each topic, the predicted topic difficulty ranking is then compared to the actual performance over the run.</p><p>Past submissions to the robust track have typically either considered query term related statistics, or have relied on the similarity measure between the query and results <ref type="bibr" coords="9,350.11,107.98,67.79,13.74" target="#b22">(Voorhees, 2004)</ref>. It has been shown that documents within a collection have a non-uniform likelihood of retrieval <ref type="bibr" coords="9,383.65,119.98,79.12,13.74" target="#b18">(Singhal et al., 1996</ref><ref type="bibr" coords="9,462.77,119.98,58.11,13.74;9,90.72,131.86,21.66,13.74" target="#b8">, Garcia et al., 2004)</ref>. Such information can be used to construct prior probabilities of document access. Other information retrieval tasks have used prior evidence such as PageRank <ref type="bibr" coords="9,319.87,143.86,71.66,13.74" target="#b15">(Page et al., 1998)</ref> and document length to improve retrieval effectiveness <ref type="bibr" coords="9,181.46,155.74,86.32,13.74" target="#b6">(Craswell et al., 2005</ref><ref type="bibr" coords="9,267.78,155.74,83.73,13.74" target="#b12">, Kraaij et al., 2002)</ref>. However, to the best of our knowledge no-one has explored the value of document priors for topic difficulty prediction. The use of such values for prediction is appealing because, for each topic, there is minimal computational effort required. The document priors are pre-calculated at indexing time, and query term specific data is not required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed Techniques</head><p>Our approach to query difficulty prediction attempts to take advantage of the non-uniform likelihood of document access by a retrieval system. For each document in the collection, a probability is generated that represents the likelihood that the document will be retrieved by the search system. That is, for any given query we generate a probability of document access. Using these probabilities, an absolute ordering can be achieved from most likely to be accessed to least likely to be accessed. In a sense, this ordering represents a form of default ranking for documents in the collection. We label this ranked set of probabilities the retrieval-likelihood ordering.</p><p>By comparing the absolute ordering of documents based on retrieval-likelihood to the order of the those documents returned in a topic result set, we can estimate how difficult a topic was to answer. The rationale is that those queries that produce ranked result sets that contain documents in much the same order as the global ordering do not have strong discriminating power. As such, these queries are considered to be difficult to answer. Conversely, queries that produce ranked result sets that are mostly ordered in a different manner to the global ordering are considered simpler to answer by the system.</p><p>Two aspects of importance to our approach are the generation of the retrieval-likelihood values, and the method used to compare the ordering of documents by retrieval-likelihood to that of the ranked result set.</p><p>Given a collection and a query log for that collection, access-counts can be used to measure the skew of document access by a search engine <ref type="bibr" coords="9,238.73,428.14,79.32,13.74" target="#b8">(Garcia et al., 2004)</ref>. To generate our retrieval-likelihood probabilities we used an approach similar to that of access counting, but instead of processing a complete query log over a document collection, we processed a single query that was the amalgamation of every distinct term in the collection. Using the Okapi similarity metric (see Section 3.3), we generated a rank for every document in the collection based on its similarity to the current query. These ranks were then used as an indication of which documents in the collection are most likely to be retrieved. The advantage of this approach is that a result for every document in the collection can be generated with a single pass over the index. For comparison purposes, we also submitted a run using document length as the basis for our probabilities with larger documents being more likely to be retrieved. The length bias of search metrics was noted by <ref type="bibr" coords="9,490.32,523.78,30.57,13.74;9,90.72,535.78,46.97,13.74" target="#b18">Singhal et al. (1996)</ref>.</p><p>To compare the order of the ranked results with the retrieval-likelihood ordering we applied three techniques. The first was to use Kendall's Ï„ to measure the disagreement between the two orderings directly <ref type="bibr" coords="9,90.72,571.66,53.91,13.74" target="#b21">(Stuart, 1983)</ref>. The second was to use the average rank of documents in the result sets, and the third was to use product of document priors. Due to the track guidelines we were only able to submit one prediction set with each submitted run. This limitation prevents the results from being directly comparable, as each submitted run uses a different query evaluation technique (see Section 4.1) and a different difficulty prediction technique.</p><p>To compare the different techniques outlined above, we submitted the following five runs:</p><p>â€¢ as-k-1000: This run uses Kendall's Ï„ over the full 1,000 results per query, with the global ordering based on our access-count variant for the retrieval-likelihood of the documents. A low Ï„ score marked disagreement between the ranked result set and the global ordering, therefore the query is considered to be simple to answer. were submitted to TREC are marked with a â€ .</p><p>â€¢ as-k-50: As in the previous run, but here we only consider the top 50 ranked results per query for the Ï„ disagreement. This variant is based on the assumption that in a collection of this size it is unlikely that all 1,000 retrieved results will be highly relevant to the query, therefore they should not be considered in the difficulty prediction.</p><p>â€¢ as-p-1000: This run uses the product of the probabilities of documents in the result set. Our accesscount variant is used for the retrieval-likelihood probabilities. High products suggest a larger range of regularly accessed documents, therefore the query is difficult to answer. Although simplistic in design, this scheme should indicate if the number of frequently retrieved documents per query suggests topic difficulty.</p><p>â€¢ as-a-1000: It is possible that in the product of probabilities approach, a few low probability documents can significantly skew the query difficulty estimate. An alternate way of considering the amount of commonality among the per-query results is to take the average of the global ranks of each document in the result set (that is, instead of considering actual prior probabilities, the prior rank position of each document is used). Similar to the the product technique, a higher average rank suggests a difficult query.</p><p>â€¢ dl-k-1000: The previous four techniques utilise priors based on access-counts. In this run we employ a technique that uses document length for priors. This approach uses Kendall's Ï„ over the full 1,000 results per query in a similar manner to the as-k-1000 approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" coords="10,115.17,473.02,5.03,13.74" target="#tab_8">8</ref> shows the area-under the curve results for variant runs. A lower area under the curve value signifies a stronger correlation between the prediction and the actual results. Values marked with a â€  denote the variants that were submitted with each of the five submitted runs. To enable a clearer comparison between the techniques, the remaining entries in the table have been post-calculated using the relevance judgements. The AS-K-1000 method based on access-count document-likelihoods and Kendall's Ï„ was the most accurate at predicting query difficulty over the variant runs with the exception of the description only run. The DL-K-1000 based on document length and Kendall's Ï„ produced similar results to AS-K-1000, but was generally outperformed by the access-count priors.</p><p>The AS-K-50 technique, which is based only on the top 50 results per query, was unable to discriminate as effectively as using all results per query. This suggests that all documents, both likely and unlikely to be relevant, help determine the difficulty of the topic using our document-likelihood techniques.</p><p>The AS-P-1000 product of priors, and AS-A-1000 average rank techniques that were hoped to show that the fraction of frequently retrieved documents can indicate query performance, varied in effect producing only one relatively effective run of the five submissions.</p><p>While not as sophisticated as techniques such as query clarity <ref type="bibr" coords="10,361.63,640.30,127.25,13.74" target="#b7">(Cronen-Townsend et al., 2002)</ref>, which have been successfully applied by <ref type="bibr" coords="10,231.66,652.30,78.15,13.74" target="#b1">Amati et al. (2004)</ref> in a similar context, the results of these predictions show that document priors are a factor that can be considered in predicting the performance of a retrieval system.</p><p>It is promising that these results do provide some indication of query difficulty given that only the query results are considered when making the prediction and no use is made of query term information. It is our hope that, in combination with more advanced techniques, these approaches can help improve query difficulty prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year's terabyte efficiency task, we confirmed the strong RMIT tradition of efficient systems while retaining good effectiveness. The adhoc task was disappointing, with the lack of stemming giving us poor effectiveness results, but still served to validate our new accumulator limiting scheme. The bulk of our effort in the named page task was invested in co-ordination of the task.</p><p>In the robust track, we confirmed what has become clear from last year's TREC: query expansion is essential in order to increase the robustness of badly performing queries. It also seems that using document priors based on document access counts is a promising technique for predicting query difficulty, particularly when used in conjunction with other methods, as we are planning to do in future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,97.68,82.90,416.58,212.46"><head>Table 2 :</head><label>2</label><figDesc>System details for runs submitted for the efficiency task.</figDesc><table coords="4,97.68,82.90,416.58,212.46"><row><cell cols="2">Characteristic Percentage of doc collection indexed Indexing time (minutes) Av. time to return top 20 docs (secs) Total proces. time for all topics (secs) Total number of CPUs in system Total amount of RAM in system (GB) Size of on-disk file structures (GB) Year of system purchase Estimated hardware cost (US$)</cell><cell cols="4">All runs submitted Maximum Median Minimum 100 100 66 23,528 990 44 4.4 0.47 0.024 219,354 17,730 1,201 23 2 1 23 4 1 600 63 5.99 2005 2004 2002 45,000 5,000 750</cell><cell cols="2">Our runs submitted ZETDIR ZETDIST 100 100 595 64 0.23 0.06 11,565 2,901 1 8 2 8 17 19 2004 2004 1,200 6,000</cell></row><row><cell>Run ZETDIR ZETDIST</cell><cell>Technique employed Monolithic Distributed</cell><cell>MAP 0.067 0.061</cell><cell>P@10 0.570 0.574</cell><cell>P@20 0.541 0.530</cell><cell>bpref 0.053 0.052</cell><cell>R-P 0.080 0.075</cell><cell>Time (sec) 0.23 0.06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,90.72,303.34,430.16,37.10"><head>Table 3 :</head><label>3</label><figDesc>Effectiveness</figDesc><table /><note coords="4,181.59,307.48,339.29,8.97;4,90.72,319.48,430.05,8.97;4,90.72,331.48,54.03,8.97"><p><p><p>and efficiency of terabyte efficiency runs. In addition to the measurements described in Table</p>1</p>, average query times in seconds are shown. The median average query time of all systems was 0.47 seconds.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,456.90,653.38,32.00,13.74"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table coords="6,109.68,82.90,392.56,74.22"><row><cell>Run Mean ZETNP ZETNPANC ZETNPANCFUZZ ZETNP50W</cell><cell>Technique employed Plain Anchortext Anchortext, Fuzzy Phrase Priority</cell><cell>MRR 0.379 0.067 0.258 0.277 0.318</cell><cell>Found in top 10 -46.8% 44.0% 46.0% 48.4%</cell><cell>No answer found -23.8% 23.4% 23.4% 23.8%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,90.72,165.22,430.23,153.42"><head>Table 4 :</head><label>4</label><figDesc>Effectiveness of terabyte named page finding runs, showing mean reciprocal rank (MRR), the percentage of queries for which an answer was found in the top 10 documents, and the percentage of queries for which no answer was found. The mean MRR result is calculated over the median MRR of all queries submitted by all participants.</figDesc><table coords="6,116.88,232.78,378.23,85.86"><row><cell>Run ID RMIT5D1025 RMIT5T0000 RMIT5T1025 RMIT5T0530N RMIT5T1545TD</cell><cell>Run type description-only title-only title-only title-only title-only</cell><cell>Expansion parameters |R| |E| 10 25 --10 25 5 30 15 45</cell><cell>Source of expansion terms AQUAINT -AQUAINT AQUAINT, NW, REUTERS NW</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,237.96,326.62,132.91,13.74"><head>Table 5 :</head><label>5</label><figDesc>Summary of robust runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,90.72,82.90,430.27,188.94"><head>Table 6 :</head><label>6</label><figDesc>Comparison of official run with co-derivative documents removed, and a run where all documents are left in the result set. See Table7for a description of columns.</figDesc><table coords="8,148.68,82.90,314.64,188.94"><row><cell cols="3">RMIT5T1545TD without removing co-derived documents</cell><cell>MAP 0.146 0.186</cell><cell>P@10 0.410 0.416</cell><cell cols="2">gMAP 0.098 0.119</cell></row><row><cell>Run ID Median RMIT5D1025 Median RMIT5T0000 RMIT5T1025 RMIT5T0530N RMIT5T1545TD</cell><cell>Run type description-only title-only</cell><cell>MAP 0.184 0.160 0.224 0.157 0.224 0.218 0.146</cell><cell>P@10 0.386 0.368 0.434 0.398 0.432 0.424 0.410</cell><cell cols="2">gMAP 0.103 0.066 0.129 0.089 0.117 0.129 0.098</cell><cell>Area 1.226 1.447 1.425 1.633 2.487 2.118 0.946</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,90.72,279.94,430.32,48.86"><head>Table 7 :</head><label>7</label><figDesc>Summary of robust results, showing mean average precision (MAP), precision at 10 retrieved docu-</figDesc><table /><note coords="8,90.72,295.96,430.32,8.97;8,90.72,307.96,430.16,8.97;8,90.72,319.84,140.23,8.97"><p>ments (P@10) and the geometric MAP (gMAP). Also shown are the areas between the best possible ordering of predicted topic difficulty, and the difficulty we predicted. The median figures are for all runs submitted to the robust track by all participants.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,90.72,85.09,430.17,93.51"><head>Table 8 :</head><label>8</label><figDesc>Combinations of all runs and query difficulty prediction measures used. The five predictions that</figDesc><table coords="10,118.08,85.09,375.84,71.67"><row><cell>RMIT5D1025 RMIT5T0000 RMIT5T0530N RMIT5T1025 RMIT5T1545TD</cell><cell>AS-K-1000 1.447 â€  0.843 1.210 1.566 0.917</cell><cell>AS-K-50 1.683 1.633 â€  1.796 1.891 1.339</cell><cell>AS-P-1000 1.374 1.668 2.118 â€  2.478 1.203</cell><cell>AS-A-1000 1.382 1.631 2.149 2.488 â€  1.214</cell><cell>DL-K-1000 1.379 0.907 1.307 1.732 0.946 â€ </cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported by the <rs type="funder">Australian Research Council</rs>. Hardware for some experiments was provided with the support of an <rs type="funder">RMIT University</rs> <rs type="grantName">VRII grant</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uPmt223">
					<orgName type="grant-name">VRII grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,90.72,348.12,430.17,12.36;11,100.68,359.04,420.32,12.36;11,100.68,370.08,420.22,12.36;11,100.68,381.00,15.59,12.36" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,418.35,348.12,102.53,12.36;11,100.68,359.04,152.21,12.36">Okapi at TREC-6 automatic ad hoc, VLC, routing, filtering and QSDR</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno>Publication 500-240</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,425.13,359.04,95.87,12.36;11,100.68,370.08,26.44,12.36">Proc. Text Retrieval Conf. (TREC)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>Text Retrieval Conf. (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="169" to="206" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.72,399.96,430.15,12.36;11,100.68,410.88,420.22,12.36;11,100.68,421.92,113.57,12.36" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,270.49,399.96,250.39,12.36;11,100.68,410.88,13.72,12.36">Query difficulty, robustness, and selective application of query expansion</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,247.28,410.88,115.07,12.36">European Conf. on IR Research</title>
		<title level="s" coord="11,421.96,414.60,98.95,8.07;11,100.68,425.64,25.80,8.07">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tait</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2997</biblScope>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.72,440.76,430.17,12.36;11,100.68,451.80,420.19,12.36;11,100.68,462.72,11.15,12.36" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,223.00,440.76,212.61,12.36">A scalable system for identifying co-derivative documents</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,167.78,451.80,198.55,12.36">Proc. String Processing and Information Retrieval Symp</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Apostolico</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Melucci</surname></persName>
		</editor>
		<meeting>String essing and Information Retrieval Symp<address><addrLine>Padova, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="55" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.72,481.68,430.15,12.36;11,100.68,492.60,151.68,12.36" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,218.92,481.68,168.86,12.36">Redundant documents and search effectiveness</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,407.48,481.68,113.38,12.36;11,100.68,492.60,102.49,12.36">Proc. Int. Conf. on Information and Knowledge Management</title>
		<meeting>Int. Conf. on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="11,90.72,511.56,430.14,12.36;11,100.68,522.48,420.44,12.36;11,100.68,533.40,345.26,12.36" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,100.68,522.48,97.50,12.36">RMIT University at TREC</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Billerbeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cannane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chatteraj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yiannis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,387.97,522.48,124.34,12.36">Proc. Text Retrieval Conf. (TREC)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>Text Retrieval Conf. (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special</orgName>
		</respStmt>
	</monogr>
	<note>Publication 500-261</note>
</biblStruct>

<biblStruct coords="11,90.72,552.36,430.29,12.36;11,100.68,563.28,420.30,12.36;11,100.68,574.32,125.55,12.36" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,226.96,552.36,279.73,12.36">Questioning query expansion: An examination of behaviour and parameters</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Billerbeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,249.68,563.28,119.22,12.36">Proc. Australasian Database Conf</title>
		<editor>
			<persName><forename type="first">K.-D</forename><surname>Schewe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</editor>
		<meeting>Australasian Database Conf<address><addrLine>Dunedin, New Zealand</addrLine></address></meeting>
		<imprint>
			<publisher>Australian Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.72,593.28,430.12,12.36;11,100.68,604.20,420.17,12.36;11,100.68,615.12,355.92,12.36" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,327.55,593.28,189.55,12.36">Relevance weighting for query independent evidence</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,370.42,604.20,150.43,12.36;11,100.68,615.12,151.15,12.36">Proc. ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Moffat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Marchionini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tate</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ziviani</surname></persName>
		</editor>
		<meeting>ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval<address><addrLine>New York, Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.72,634.08,430.25,12.36;11,100.68,645.00,420.20,12.36;11,100.68,656.04,241.63,12.36" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,294.83,634.08,105.05,12.36">Predicting query performance</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,240.33,645.00,280.55,12.36;11,100.68,656.04,31.59,12.36">Proc. ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Myaeng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>JÃ¤rvelin</surname></persName>
		</editor>
		<meeting>ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval<address><addrLine>New York, Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.72,674.88,430.13,12.36;11,100.68,685.92,420.32,12.36;11,100.68,696.84,66.80,12.36" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,287.39,674.88,84.34,12.36">Access-ordered indexes</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cannane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,477.22,674.88,43.64,12.36;11,100.68,685.92,213.20,12.36">Proceedings of the 27th Conference on Australasian Computer Science</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Estivill-Castro</surname></persName>
		</editor>
		<meeting>the 27th Conference on Australasian Computer Science<address><addrLine>Dunedin, New Zealand</addrLine></address></meeting>
		<imprint>
			<publisher>Australian Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,85.19,430.15,12.36;12,100.68,96.11,137.56,12.36" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,247.98,85.19,157.97,12.36">On collection size and retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,415.20,88.92,105.67,8.07;12,100.68,99.84,86.95,8.07">Kluwer International Journal of Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="150" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,115.08,430.26,12.36;12,100.68,126.00,420.31,12.36;12,100.68,136.92,187.32,12.36" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,278.27,115.08,129.35,12.36">Toward better weighting of anchors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Upstill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,204.23,126.00,309.74,12.36">Proc. ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>JÃ¤rveln</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Bruza</surname></persName>
		</editor>
		<meeting>ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval<address><addrLine>New York, Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="512" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,155.88,407.24,12.36" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="12,158.11,155.88,213.34,12.36">Variations on Language Modeling for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="12,90.72,174.84,430.25,12.36;12,100.68,185.76,420.18,12.36;12,100.68,196.80,337.21,12.36" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,288.22,174.84,218.50,12.36">The importance of prior probabilities for entry page search</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,350.04,185.76,170.82,12.36;12,100.68,196.80,136.04,12.36">Proc. ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Myaeng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>JÃ¤rvelin</surname></persName>
		</editor>
		<meeting>ACM-SIGIR Int. Conf. on Research and Development in Information Retrieval<address><addrLine>New York, Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,215.64,430.14,12.36;12,100.68,226.68,282.91,12.36" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,323.23,215.64,197.63,12.36;12,100.68,226.68,26.24,12.36">Space-limited ranked query evaluation using adaptive pruning</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,146.08,226.68,229.83,12.36">Proc. of the Int. Conf. on Web Information Systems Engineering</title>
		<meeting>of the Int. Conf. on Web Information Systems Engineering</meeting>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="12,90.72,245.52,430.16,12.36;12,100.68,256.56,87.79,12.36" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,213.67,245.52,173.83,12.36">Self-indexing inverted files for fast text retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,396.62,249.24,124.26,8.07;12,100.68,260.28,28.30,8.07">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="349" to="379" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,275.39,430.30,12.36;12,100.68,286.43,229.74,12.36" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="12,304.07,275.39,212.66,12.36">The PageRank citation ranking: Bringing order to the web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Digital Library Technologies Project</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,90.72,305.27,430.26,12.36;12,100.68,316.31,131.92,12.36" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,262.20,305.27,130.91,12.36">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,402.86,309.00,118.12,8.07;12,100.68,320.04,72.31,8.07">Jour. of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,335.27,430.26,12.36;12,100.68,346.19,420.31,12.36;12,100.68,357.11,86.24,12.36" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,236.43,335.27,98.09,12.36">Okapi/Keenbow at TREC-8</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,502.10,335.27,18.88,12.36;12,100.68,346.19,100.66,12.36">Proc. Text Retrieval Conf. (TREC)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>Text Retrieval Conf. (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,376.07,430.30,12.36;12,100.68,386.99,106.02,12.36" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,305.40,376.07,112.10,12.36">Document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,427.35,379.80,93.67,8.07;12,100.68,390.72,46.29,8.07">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="619" to="633" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,405.95,430.14,12.36;12,100.68,416.87,420.20,12.36;12,100.68,427.91,125.69,12.36" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,231.13,405.95,149.30,12.36">Overview of the TREC 2003 novelty track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
		<idno>Publication 500- 255</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,121.48,416.87,124.46,12.36">Proc. Text Retrieval Conf. (TREC)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>Text Retrieval Conf. (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="38" to="53" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,446.75,430.03,12.36;12,100.68,457.79,356.06,12.36" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,304.72,446.75,216.04,12.36;12,100.68,457.79,142.87,12.36">A probabilistic model of information retrieval: Development and comparative experiments. Parts 1&amp;2</title>
		<author>
			<persName coords=""><forename type="first">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,254.65,461.52,142.24,8.07">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="779" to="840" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,476.63,298.60,12.36" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,159.75,476.63,46.77,12.36">Kendall&apos;s tau</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stuart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,215.66,480.36,129.04,8.07">Encyclopedia of Statistical Sciences</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="367" to="369" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,495.59,430.26,12.36;12,100.68,506.63,420.32,12.36;12,100.68,517.55,16.67,12.36" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,177.89,495.59,144.62,12.36">Overview of the TREC 2004 robust track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<idno>Publication 500-261</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,484.59,495.59,36.39,12.36;12,100.68,506.63,83.40,12.36">Proc. Text Retrieval Conf. (TREC)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>Text Retrieval Conf. (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,536.51,430.25,12.36;12,100.68,547.43,420.29,12.36;12,100.68,558.35,224.99,12.36" xml:id="b23">
	<analytic>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,258.00,536.51,224.12,12.36;12,227.48,547.43,123.02,12.36">Overview of the eighth Text REtrieval Conference (TREC-8)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
	<note>Proc. Text Retrieval Conf. (TREC)</note>
</biblStruct>

<biblStruct coords="12,90.72,577.31,430.17,12.36;12,100.68,588.23,420.32,12.36;12,100.68,599.27,420.22,12.36;12,100.68,610.19,15.59,12.36" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,419.56,577.31,101.33,12.36;12,100.68,588.23,152.21,12.36">Okapi at TREC-6 automatic ad hoc, VLC, routing, filtering and QSDR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jones</surname></persName>
		</author>
		<idno>Publication 500-240</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,425.13,588.23,95.87,12.36;12,100.68,599.27,26.44,12.36">Proc. Text Retrieval Conf. (TREC)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>Text Retrieval Conf. (TREC)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="125" to="136" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,90.72,629.15,430.28,12.36;12,100.68,640.07,213.37,12.36" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,213.32,629.15,301.21,12.36">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,100.68,643.80,153.88,8.07">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
