<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.64,75.53,342.71,12.58">WIDIT in TREC-2005 HARD, Robust, and SPAM tracks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.94,104.22,46.86,9.02"><forename type="first">Kiduk</forename><surname>Yang</surname></persName>
							<email>kiyang@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.11,104.22,32.31,9.02"><forename type="first">Ning</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.81,104.22,65.49,9.02"><forename type="first">Nicholas</forename><surname>George</surname></persName>
							<email>nlgeorge@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.34,104.22,61.84,9.02"><forename type="first">Aaron</forename><surname>Loehrlen</surname></persName>
							<email>aloehrle@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.95,104.22,66.18,9.02"><forename type="first">David</forename><surname>Mccaulay</surname></persName>
							<email>smccaula@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,437.57,104.22,40.86,9.02"><forename type="first">Hui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.36,115.74,61.53,9.02"><forename type="first">Shahrier</forename><surname>Akram</surname></persName>
							<email>sakram@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.45,115.74,29.85,9.02"><forename type="first">Jue</forename><surname>Mei</surname></persName>
							<email>jumei@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.47,115.74,49.21,9.02"><forename type="first">Ivan</forename><surname>Record</surname></persName>
							<email>irecord@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.64,75.53,342.71,12.58">WIDIT in TREC-2005 HARD, Robust, and SPAM tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C801F1C6B4B2F49744EEF10D637CE559</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Web Information Discovery Tool (WIDIT) Laboratory at the Indiana University School of Library and Information Science participated in the HARD, Robust, and SPAM tracks in <ref type="bibr" coords="1,490.21,209.76,31.76,9.88;1,90.00,222.42,19.79,9.88">TREC-2005</ref>. The basic approach of WIDIT is to combine multiple methods as well as to leverage multiple sources of evidence. Our main strategies for the tracks were: query expansion and fusion optimization for the HARD and Robust tracks; and combination of probabilistic, rule-based, pattern-based, and blacklist email filters for the SPAM track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">HARD track</head><p>In this year's HARD track, we explored the possibility of improving retrieval performance by taking a fusion approach that combines a variety of techniques as well as different data sources. In order to deal effectively with the "difficult" topics, we employed a variety of query expansion strategies, the results of which were combined via an automatic fusion optimization process.</p><p>We hypothesized that the "difficulty" of topics is often due to the lack of appropriate query terms and/or misguided emphasis on non-pivotal query terms by the system. Thus, our first-tier solution was to devise a wide range of query expansion methods that can not only enrich the query with useful term additions but also identify important query terms. Our automatic query expansion included such techniques as noun phrase extraction, acronym expansion, synonym identification, definition term extraction, keyword extraction by overlapping sliding window, and Web query expansion.</p><p>For synonym identification, we integrated a sense disambiguation module into WIDIT's synset identification module so that best synonym set can be selected according to the term context. To reduce the noise from word definitions, we applied the overlapping sliding window (OSW) method to multiple definitions harvested from web and extracted the overlapping terms. To extract noun phrase, we combined the results of multiple NLP taggers as well as applying the OSW method. OSW method was also applied to topic fields to identify important topic terms. The Web query expansion method was a slight modification of the PIRC approach.</p><p>To produce the optimum baseline results, we merged various combinations of query formulation results, which involved combinations of topic fields (title, description, narrative) and stemming (simple plural stemmer, combination stemmer), and the query expansion results using a weighted sum fusion formula. The fusion weights were determined using last year's Robust data to train the system via an automatic fusion optimization process. The fusion optimization involved iterations of fusion runs (i.e., result merging), where best performing systems in selected categories (e.g., short query, top 10 systems, etc.) were combined using average precision as fusion weights until the performance gain fell below a threshold.</p><p>We viewed the clarification form (CF) as both manual query expansion and relevance feedback mechanism. Our clarification form included query term synonyms, noun phrase, and best sentences from top documents of the baseline result. Since difficult topics tend to produce few relevant documents in top ranks, we clustered the results and selected the best sentence from each cluster to include in the CF. In addition to expanding the query with user-selected terms from the clarification form, we also utilized the user's best sentence selection by boosting the rank of the documents in which selected sentences occurred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">WIDIT HARD System</head><p>WIDIT HARD system consists of five main modules: indexing, retrieval, fusion (i.e. result merging), reranking, and query expansion modules. The query expansion module employs a wide range of query expansion methods that can not only enrich the query with useful term additions but also identify important query terms. The retrieval module produces multiple result sets from using different query formulations. The fusion module, which is optimized via an automatic tuning process, combines result sets using weighted sum formula, and the reranking module boosts the ranks of documents with important phrases and floats to the top ranks documents selected as relevant in CF. The overview of WIDIT HARD system architecture is displayed in Figure <ref type="figure" coords="2,177.73,232.74,4.12,9.88" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>The query expansion module consists of three submodules: Web expansion (WebX) module expands the query with terms from Google search results; NLP module finds synonyms and definitions of query terms and identifies nouns and noun phrases in the query; Overlapping Sliding Window (OSW) module extract key phrases from the query. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Module</head><p>Automatic Tuning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fusion Module</head><p>Baseline Result</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CF Terms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-CF Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-ranking Module</head><p>User Final Result</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">OSW Module</head><p>The main function of OSW module is to identify important phrases. OSW method, which is based on the assumption that phrases appearing in multiple fields/sources tend to be important, works as follows:</p><p>i. Define window size and the number or maximum words allowed between words.</p><p>ii. Slide window from the first word in the source field/source. For each of the phrase it catches, look for the same/similar phrase in the search fields/sources. iii. Produce the OSW phrases iv. Change source field/source and repeat step 1 to 3 till all the fields/sources have been used.</p><p>OSW method was applied to topic descriptions and query term definitions to identify key phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">NLP Module</head><p>WIDIT's NLP module expands acronyms using a Web-harvested acronym list, identifies nouns and noun phrases using multiple taggers, and finds synonyms and definitions via querying the Web. Two main objectives of the NLP module refinement this year were to reduce noise in query expansion and to identify key (i.e. "important") phrases. For noise reduction, we integrated a sense disambiguation<ref type="foot" coords="3,184.38,306.01,3.51,6.32" target="#foot_0">1</ref> into WIDIT's synset identification module so that best synonym set can be identified based on the term context, and refined the WIDIT's definition module by applying OSW to extract overlapping terms from the multiple Web-harvested definitions <ref type="bibr" coords="3,442.47,333.60,42.44,9.88;3,90.00,346.26,171.83,9.88">(WordIQ, Dictionary.com, Google, Answers.com)</ref>. For key phrase identification, we used a combination of NLP tools as well as WordNet to identify 4 types of noun phrases: proper names, dictionary phrases, simple phrases, complex phrases. The noun phrase identification algorithm, which is based on the UIC approach <ref type="bibr" coords="3,212.45,384.18,100.94,9.88">(Liu, Sun, &amp; Yu, 2004)</ref>, is described below and depicted graphically in Figure <ref type="figure" coords="3,132.82,396.84,8.51,9.88">2:</ref> i. Apply Minipar to identify proper names and term relations (AND, OR, NOT). ii. Apply Brill's tagger to identify part of speech. iii. Apply Collins' parser to decompose noun phrases as base phrases that cannot be decomposed by Collin's parser. iv. Query WordNet to identify proper nouns and dictionary phrases <ref type="bibr" coords="3,410.44,472.74,72.28,9.88" target="#b2">(Liu et al., 2004)</ref>. v. Categorize phrases which are not proper noun or dictionary phrases into complex or simple phrases.</p><p>The Reliable Information Access Workshop report <ref type="bibr" coords="3,334.07,523.32,115.84,9.88" target="#b7">(Harman &amp; Buckley, 2004</ref>) listed 10 reasons why a retrieval system may fail. The failure analysis of 45 TREC topics showed that missing an important aspect or term in a query contributes to the largest number of problems. In order to address this problem, we created a relation identification module that identifies terms with three types of Boolean "AND" relations (BoolAND)-parallel, verb-noun, and modifiernoun-where BoolAND terms are query terms all of which must appear in relevant documents. To identify parallel relations, we used a simple rule that selects the terms or phrases linked by "and" in the title field. To identify verb-noun and modifier-noun relations, we used an NLP parser called Minipar (http://www.cs.ualberta.ca/~lindek/minipar.htm) on the topic description. BoolAND relations were included in the clarification form (CF) for the human experts for validation, and the CF feedback was used as input to the reranking module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Noun Phrase Identification Diagram</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">WebX Module</head><p>The PIRCS group has demonstrated that web expansion is an "effective" method for improving the performance of weak (i.e. difficult) topics <ref type="bibr" coords="4,293.22,302.64,98.04,9.88" target="#b5">(Grunfeld et al., 2004;</ref><ref type="bibr" coords="4,394.03,302.64,80.20,9.88" target="#b8">Kwok et al., 2005)</ref>. WebX module, which is based on the PIRC approach, expands the query with related terms harvested from Google search results. WebX module consists of Web query construction, Web search, search result parsing and term selection. Figure <ref type="figure" coords="4,300.73,340.62,5.49,9.88">3</ref> illustrates the architecture of the WebX module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3. WebX Module Architecture</head><p>The Web query generator constructs Web queries by selecting up to 5 most salient terms from the processed HARD topics (i.e., stopped and stemmed text, nouns, phrases). The queries are then sent to Google, and subsequent search results (the snippets and the body texts) are parsed to extract up to 60 terms per topic to be used as query expansion terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Fusion Optimization</head><p>To produce the optimum baseline results, we merged various combinations of query formulation results, which involved combinations of topic fields (title, description, narrative) and stemming (simple plural stemmer, combination stemmer), and the query expansion results using a weighted sum fusion formula 2 . The conventional approaches to fusion weight determination ranges from 2 Weighted Sum formula combines document scores weighted by the relative contribution of the systems.</p><p>where wi is the weight (estimated contribution) of system i and Si is the normalized retrieval score of a document by system i. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) (</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Google Parser</head><p>Term Selector exhaustive search of weight combinations, which is computationally prohibitive when the number of parameters is large, to the use of past evidence to restrict the search space, which can be misleading at times. Last year, we devised a novel man-machine hybrid approach called the Dynamic Tuning as an alternative <ref type="bibr" coords="5,240.66,112.56,110.25,9.88">(Yang, Yu, &amp; Lee, 2005;</ref><ref type="bibr" coords="5,353.67,112.56,88.78,9.88">Yang &amp; Yu, in press</ref>). This year, we devised another alternative fusion weight determination method called Auto-Fusion Optimization. The Auto-Fusion Optimization involves iterations of fusion runs (i.e., result merging), where best performing systems in selected categories (e.g., short query, top 10 systems, etc.) are combined using average precision as fusion weights until the performance gain fell below a threshold. Figure <ref type="figure" coords="5,121.48,175.86,5.49,9.88">4</ref> illustrates the automatic fusion optimization process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4. Auto-Fusion Optimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Clarification Form</head><p>Most HARD participants have discovered that the clarification form (CF) is an effective mechanism for improving the baseline result with user feedback. The main objective of our CF design strategy this year was to obtain more accurate and diverse feedback. We extended last year's CF approach <ref type="bibr" coords="5,181.28,598.50,83.07,9.88">(Yang et al., 2005)</ref>, which served as manual query expansion and relevance feedback mechanism, to include the validation of BoolAnd relations. In addition to displaying important phrases and best sentences from top 200 retrieved documents 3 , our CF (Figure <ref type="figure" coords="5,512.92,623.82,4.58,9.88">5</ref>) included synonym sets, definition terms, and query term relations with the use of JavaScript to make the interaction more friendly and efficient. The CF terms selected by the user was used to create a CF-expanded query. Phrases, BoolAnd terms and relevant documents identified in CF 3 Since weak topics tend to retrieve non-relevant documents at top ranks, we clustered the top 200 documents and selected the best sentence from each cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results pool</head><p>Fetching result sets For different categories</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic Fusion Category 2 Category 1</head><p>Category n &gt; threshold?</p><p>Top 10 systems Best system in each query length fusion results (n) Yes No were used by the reranking module to the ranks of documents with important phrases and relevant documents identified by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5. Clarification Form</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Reranking</head><p>The objective of reranking is to float low ranking relevant documents to the top ranks based on post-retrieval analysis of reranking factors. After identifying reranking factors such as OSW terms, CF terms, and CF-reldocs, which are relevant documents identified in CF form, we computed the reranking factor scores (rf_sc) for top k documents and boosted the ranks of documents with rf_sc above a threshold score above a fixed rank R using the following formula: doc_score = rf_sc + doc_score@rankR (1)</p><p>Although reranking does not retrieve any new relevant documents (i.e. no recall improvement), it can produce high precision improvement via post-retrieval compensation (e.g. phrase matching) or force rank-boosting to accommodate trusted information (e.g. CF-reldocs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Results</head><p>Web query expansion (WebX) was the most effective method of all the query expansion methods.</p><p>WebX method showed most gain in performance for short queries (i.e. title) but had an adverse effect for longer queries (i.e. description) except when using the rotating window approach (Figure <ref type="figure" coords="6,125.21,662.10,3.98,9.88">6</ref>). Among non-WebX query expansion methods, Proper Noun Phrases, Overlapping Sliding Window (OSW), and CF Terms helped retrieval performance for longer queries. The effect of query expansion is influenced by the query length. Without query expansion, longer queries usually outperform the shorter queries (Figure <ref type="figure" coords="6,330.36,700.02,3.97,9.88">7</ref>). With query expansion, however, query length has opposite effect on WebX and methods. The composite effects of query expansion and query length suggest that WebX should be applied to short queries, which contain less noise that can be exaggerated by Web expansion, and non-WebX should be applied to longer queries, which contain more information that query expansion methods can leverage. As was the case last year, fusion (i.e. result merging) improved the retrieval performance across the board, showing that fusion optimization is a viable method to streamline the process of combining numerous result sets in an efficient manner (Table <ref type="table" coords="7,363.57,669.06,3.97,9.88" target="#tab_2">1</ref>). As for reranking factors, CFrelevant documents had the most positive effect, followed by OSW and CF Terms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Robust Track</head><p>Our Robust track approach was essentially the same as our HARD track approach except for the lack of CF component and the addition of difficulty prediction component. Our difficulty prediction methods were: average inverse collection term frequency, which assumes that performance of a query can be predicted by the average quality of its composing terms, and standard deviation of inverse document frequency (idf), which assumes that composing terms of a poorly-performing query tend to have similar idf values. However, neither method proved to be effective. We suspect that this is due to the fact that our submitted results were from fusion runs that combine the results of various query formulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SPAM Track</head><p>For SPAM track, we created a fusion filter that integrates four individual SPAM filters. The individual filters make use of an adaptive learning process that learns the features of the test corpus in real time during the filtering process. The filters consist of a naïve Bayesian (NB) filter, a pattern-based (PB) filter, a rule-based (RB) filter, and a blacklist (BL) filter.</p><p>The results of four filters are taken into consideration to generate the final result by a fusion module, which implements both rule-based and weighted sum methods. The fusion module computes a set of weighted sum scores as well as rule-based scores that determine the contribution of each filter based on factors such as training run performance, filter overlap, and filter characteristics (e.g., BL filter has no false positives). The tuning of the weighted sum formulas proved difficult due to uneven performance across collections. Furthermore, rule-based fusion method showed much superior overall performance in training runs. Figure <ref type="figure" coords="8,456.85,435.96,5.49,9.88">6</ref> describes the WIDIT SPAM system architecture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive Learning Module</head><p>Feeback Data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Naïve Bayes Filter</head><p>The WIDIT naïve filter is a modified version of Graham's bspam filter <ref type="bibr" coords="9,447.75,93.60,69.61,9.88" target="#b0">(Graham, 2002;</ref><ref type="bibr" coords="9,90.00,106.26,64.54,9.88" target="#b1">Graham, 2003)</ref>. NB filter calculates the probability of the given email being by considering the current ratio of hams to spams, the number of hams that contain the term, and the number of spams that contain the term. Since NB filter dynamically determines the spaminess of terms based on their occurrences in spam email, it has an advantage over rule-based filters that can quickly become outdated when spammers devise new ways to fool spam filters. NB filter performance was very strong (95-plus % accuracy) in preliminary tests, so minimal filter optimization was performed. The two optimization parameters were whether to train initially on a large number of emails (approx 250) or a small number of emails (approx 20) and whether to subsequently train the filter for all incoming emails or just the ones that the filter classified incorrectly. Based on the analysis of test runs, we chose to use the larger initial training data and to train on all incoming emails. NB was the most dominant filter that achieved best performance in training runs using the SpamAssassin data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pattern-based Filter</head><p>The WIDIT pattern-based (PB) filter uses a sliding window to identify sub-strings within emails that may identify it as a spam or a ham. PB filter is somewhat similar to NB filter in that it makes the spam/ham determination based on the spaminess of tokens in an email. The tokenization of email by PB filter, however, is string-based rather than word-based, which can identify spam patterns that span word boundary as well as those that are embedded inside a word. Furthermore, spam classification by PB filter is not probabilistic, but uses a simple pattern matching algorithm based on "guilt by association". We used IBM's Teiresias pattern discovery tool<ref type="foot" coords="9,443.10,363.07,3.51,6.32" target="#foot_1">4</ref> , which uses a sliding window that crosses word boundaries to extract patterns. Teiresias, originally used for genome and protein sequence research, was utilized by <ref type="bibr" coords="9,334.75,390.60,127.43,9.88" target="#b6">Rigoutsos and Huynh (2004)</ref> for SPAM filtering in the Chung-Kwei system as a part of the SpamGuru project.</p><p>The initial formulation of PB filter had poor performance, which were optimized after prototype submission by reducing the window size. The optimization involved removal of wild cards in pattern extraction (i.e., exact pattern matching only), and the shrinking of the sliding window to only three characters. The resulting PB filter produced the second best performance next to NB filter in training runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Rule-based Filter</head><p>The WIDIT rule-based (RB) filter evaluates an email according to a set of static rules constructed manually. The basic idea underlying RB filter was to manually identify email patterns not discovered by the other filters. The advantage of RB filter is its ability to leverage patterns and rules that go beyond tokens (e.g., an email is likely to be spam if its "To:" line is blank). RB filter assumes that spammers use similar techniques in their messages and relies on human intelligence, especially pattern-recognition ability, to identify patterns across all parts of email (i.e., header, subject, body) and construct a set of rules to make use of those patterns in filtering out spam emails.</p><p>Unfortunately, RB filter performance fell much below our initial expectations despite extensive data analysis to optimize the RB filter. RB filter appeared to perform unevenly across collections and it was difficult to find a balancing point between false positive and false negative optimizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Blacklist Filter</head><p>The WIDIT blacklist (BL) filter uses four blacklists (domain name, email IP address, URL), which are initially built by mining the lists of known spammers posted on SPAM resource websites <ref type="bibr" coords="10,130.65,118.92,76.12,9.88" target="#b4">(Goodman, 2004)</ref>. The blacklists updated during the adaptive learning process based on the occurrences of domain names, email and IP addresses in spam email headers and URLs in spam email body texts. A "stop list", which contains domains, such as hotmail.com, that are known to be used by spammers and non-spammers alike, is built in the same fashion to avoid possible over tuning. Although BL filter can identify only a small subset of spam emails, its spam accuracy is very high. The BL filter was optimized to produce no false positives at the cost of lower true positive identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Fusion Module</head><p>The results of four filters are taken into consideration to generate the final result by a fusion module, which implements both rule-based and weighted sum methods. The fusion module computes a set of weighted sum scores as well as rule-based scores that determine the contribution of each filter based on factors such as training run performance, filter overlap, and filter characteristics (e.g., BL filter has no false positives).</p><p>Individual spam filters have their own strengths and vulnerabilities. By combining multiple filters, we hope to create a filter that will identify a wide variety of spamming ploys with the combined strength of all the filters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,257.82,194.49,9.02"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. WIDIT HARD System Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,90.00,143.70,166.14,9.02;7,90.00,158.46,431.40,271.08"><head>Figure</head><label></label><figDesc>Figure 6. Web Query Expansion Effect</figDesc><graphic coords="7,90.00,158.46,431.40,271.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,90.00,473.04,136.44,9.02"><head>Figure</head><label></label><figDesc>Figure 6. WIDIT SPAM System</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,90.00,127.20,438.12,286.08"><head></head><label></label><figDesc></figDesc><graphic coords="6,90.00,127.20,438.12,286.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,112.92,295.76,297.28,240.34"><head>Topics WordNet NLP Module Web CF Documents OSW Module WebX Module Indexing Module</head><label></label><figDesc></figDesc><table coords="2,192.36,295.76,204.41,131.46"><row><cell></cell><cell>Inverted</cell><cell></cell></row><row><cell></cell><cell>Index</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Search</cell></row><row><cell></cell><cell></cell><cell>Results</cell></row><row><cell>Web Terms</cell><cell>Synonym Definition Noun Phrase</cell><cell>OSW Phrase</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,90.00,74.70,421.89,55.24"><head>Table 1 . Fusion Effect</head><label>1</label><figDesc></figDesc><table coords="8,90.00,93.84,421.89,36.10"><row><cell>Best MRP</cell><cell>Title</cell><cell>Desc. Only</cell><cell>Title+Desc+Narr</cell></row><row><cell cols="2">Non-fusion runs 0.2416</cell><cell>0.2395</cell><cell>0.2965</cell></row><row><cell>Fusion runs</cell><cell>0.3020 (+25%)</cell><cell>0.2625 (+10%)</cell><cell>0.3451 (+16%)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,95.28,700.35,426.70,8.10;3,90.00,710.67,77.33,8.10"><p>WordNet word sense disambiguation software developed by the Natural Language Processing Group at the University of Minnesota, Duluth</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="9,95.28,700.35,426.69,8.10;9,90.00,710.67,194.14,8.10"><p>Teiresias implements the pattern extraction algorithm developed by IBM Bioinformatics and Pattern Discovery Group circa 1998 (http://cbcsrv.watson.ibm.com/Tspd.html).</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,90.00,99.30,163.70,9.88;11,304.18,99.30,201.84,9.88;11,126.00,111.96,58.74,9.88" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Graham</surname></persName>
		</author>
		<ptr target="http://www.paulgraham.com/spam.html" />
		<title level="m" coord="11,177.33,99.30,70.82,9.88">A Plan for Spam</title>
		<imprint>
			<date type="published" when="2002-05-01">2002. May 1, 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,137.22,271.91,9.88;11,126.00,149.88,248.47,9.88" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="11,177.29,137.22,109.45,9.88">Better Bayesian Filtering</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Graham</surname></persName>
		</author>
		<ptr target="http://www.paulgraham.com/spam.html" />
		<imprint>
			<date type="published" when="2003-04-30">2003. April 30, 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,175.20,408.66,9.88;11,108.00,187.86,291.16,9.88;11,399.12,185.59,5.43,6.32;11,407.34,187.86,92.58,9.88;11,108.00,200.46,109.60,9.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,287.92,175.20,210.74,9.88;11,108.00,187.86,187.72,9.88">An effective approach to document retrieval via utilizing WordNet and recognizing phrases</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,302.88,187.86,96.28,9.88;11,399.12,185.59,5.43,6.32;11,407.34,187.86,92.58,9.88;11,108.00,200.46,104.75,9.88">Proceedings of the 27 th Annual International ACM SIGIR Conference</title>
		<meeting>the 27 th Annual International ACM SIGIR Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,225.78,404.52,9.88;11,494.58,223.51,5.43,6.32;11,502.74,225.78,18.88,9.88;11,108.00,238.50,96.42,9.88" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,241.23,225.78,149.59,9.88">UIC at TREC-2004: Robust Track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,398.34,225.78,96.18,9.88;11,494.58,223.51,5.43,6.32;11,502.74,225.78,18.88,9.88;11,108.00,238.50,91.56,9.88">Proceedings of the 13 th Text Retrieval Conference</title>
		<meeting>the 13 th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,263.70,420.34,9.88" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<title level="m" coord="11,183.43,263.70,299.47,9.88">IP Addresses in Email Clients. Conference on Email and Anti-Spam</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,289.02,420.13,9.88;11,108.00,301.68,242.84,9.88;11,350.88,299.41,5.43,6.32;11,359.10,301.68,160.36,9.88" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,346.68,289.02,163.45,9.88;11,108.00,301.68,135.60,9.88">TREC 2003 Robust, HARD, and QA track experiments using PIRCS</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dinstl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,254.64,301.68,96.20,9.88;11,350.88,299.41,5.43,6.32;11,359.10,301.68,113.27,9.88">Proceedings of the 12 th Text Retrieval Conference</title>
		<meeting>the 12 th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="510" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,326.94,390.03,9.88;11,126.00,339.60,361.38,9.88;11,126.00,352.26,169.60,9.88" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,236.63,326.94,243.41,9.88;11,126.00,339.60,244.19,9.88">Chung-Kwei: a Pattern-discovery-based System for the Automatic Ientification of Unsolicited E-mail Messages</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rigoutsos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,380.76,339.60,106.62,9.88;11,126.00,352.26,164.69,9.88">Proceedings of the First Conference on E-Mail and Anti-Spam</title>
		<meeting>the First Conference on E-Mail and Anti-Spam</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,377.58,411.77,9.88;11,108.00,390.24,96.28,9.88;11,204.24,387.97,5.43,6.32;11,212.46,390.24,247.12,9.88" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<title level="m" coord="11,245.53,377.58,256.24,9.88;11,108.00,390.24,96.28,9.88;11,204.24,387.97,5.43,6.32;11,212.46,390.24,200.03,9.88">The NRRC Reliable Information Access (RIA) workshop. Proceedings of the 27 th Annual International ACM SIGIR Conference</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="528" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,415.50,420.72,9.88;11,108.00,428.16,158.92,9.88;11,266.88,425.89,5.43,6.32;11,275.10,428.16,119.86,9.88" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,349.09,415.50,161.63,9.88;11,108.00,428.16,54.37,9.88">TREC2004 robust track experiments using PIRCS</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,170.64,428.16,96.28,9.88;11,266.88,425.89,5.43,6.32;11,275.10,428.16,115.01,9.88">Proceedings of the 13 th Text REtrieval Conference</title>
		<meeting>the 13 th Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,453.48,431.40,9.88;11,108.00,466.08,176.02,9.88" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,216.84,453.48,269.29,9.88">WIDIT: Fusion-based Approach to Web Search Optimization</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,496.32,453.48,25.08,9.88;11,108.00,466.08,148.56,9.88">Asian Information Retrieval Symposium</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,491.40,427.73,9.88;11,108.00,504.06,242.54,9.88;11,350.58,501.79,5.43,6.32;11,358.80,504.06,122.26,9.88;11,108.00,516.78,176.27,9.88" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,249.54,491.40,268.20,9.88;11,108.00,504.06,144.06,9.88">Dynamic Tuning for Fusion: Harnessing Human Intelligence to Optimize System Performance</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,259.74,504.06,90.80,9.88;11,350.58,501.79,5.43,6.32;11,358.80,504.06,122.26,9.88;11,108.00,516.78,171.82,9.88">Proceedings of the 9 th World Multi-Conference on Systemics, Cybernetics and Informatics</title>
		<meeting>the 9 th World Multi-Conference on Systemics, Cybernetics and Informatics</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,90.00,544.02,421.74,9.88;11,108.00,556.68,378.68,9.88;11,486.96,554.41,5.73,6.32;11,495.96,556.68,19.63,9.88;11,108.00,569.34,163.24,9.88" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,478.41,544.02,33.33,9.88;11,108.00,556.68,266.91,9.88">WIDIT in TREC2004 Genomics, HARD, Robust, and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wead</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>La Rowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,385.44,556.68,101.24,9.88;11,486.96,554.41,5.73,6.32;11,495.96,556.68,19.63,9.88;11,108.00,569.34,98.55,9.88">Proceedings of the 13 th Text Retrieval Conference</title>
		<meeting>the 13 th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>TREC2004</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
