<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,107.28,112.06,380.70,14.42">Meiji University HARD and Robust Track Experiments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,146.16,158.64,58.12,9.88"><forename type="first">Kazuya</forename><surname>Kudo</surname></persName>
							<email>kudo@cs.meiji.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Meiji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.48,158.64,45.54,9.88"><forename type="first">Kenji</forename><surname>Imai</surname></persName>
							<email>imai@cs.meiji.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Meiji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.37,158.64,85.16,9.88"><forename type="first">Makoto</forename><surname>Hashimoto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Meiji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,371.98,158.64,77.28,9.88"><forename type="first">Tomohiro</forename><surname>Takagi</surname></persName>
							<email>takagi@cs.meiji.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Meiji University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,107.28,112.06,380.70,14.42">Meiji University HARD and Robust Track Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E39EA13504E3A94835C9B7340C9FFC79</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participated in HARD Track and Robust Track at TREC2005. Our main challenge is to deal with expansion of a word by recognition of context. In HARD Track, we handled semantic expansion of a word. In Robust Track, we tried a challenge to new approach of "Document expansion" by context recognition.</p><p>In this paper, the next section presents HARD Track. Section 3 describes Robust Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">HARD Track</head><p>We made Clarification Form (CF) using mainly two kinds of information for Query Expansion (QE). One is Local Information, which is obtained from retrieval results like Pseudo Relevance Feedback. The other is Global Information, which is implicit in a corpus. Our system showed the two kinds of information to a user as CF, and generated new query from the CF results.</p><p>We used high-ranked documents in a retrieval result as Local Information. High-ranked documents would relate to original query. Therefore, it is useful for QE in many cases. However, there is one defect that accuracy of an initial retrieval result greatly influences the quality of the information.</p><p>We used information extracted from a whole corpus as Global Information. This information is useful for difficult query which doesn't obtain a good retrieval result. However, in the research of recent years, it is assumed that the use of Global Information is generally more difficult than the use of Local Information.</p><p>In consideration of these factors, we proposed to use the two kinds of information at the same time and to cover each other's defect. Time to evaluate items by a user in CF is limited. Consequently, to show more useful information to a user within a limited time, redundancy in question items should be weak. Our system makes sets of the documents or the words whose content or the meaning is close, and shows these sets to the user as CF.</p><p>Moreover, as a comparison with Global Information, we experimented using WordNet, the dictionary manually made.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Clarification Forms</head><p>Time to evaluate items by a user in CF is limited. Local Information and Global Information are too large to evaluate directly. So we think that it is necessary to classify each kind of information and to fix up question items in CF. In consequence, we classified the documents or the words, and made sets of documents whose content is similar or words whose meaning is close. In the approach of WordNet, Synonym set, node in the tree is considered like the cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">CF Generation using Local Information</head><p>We extracted effective information from high-ranked documents of a initial retrieval result. Our system retrieved a topic and got an initial retrieval result. Possibility that high-ranked documents are relevant to a topic is high. Therefore, we think that the documents include effective information for a topic.</p><p>Outline of CF generation using Local Information is shown in Figure2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2.1 Outline of CF Generation using Local Information</head><p>We generated query using text of title and description to retrieve a topic. And we classified the top 200 documents in an initial retrieval result to divide the topic into smaller topics. We used K-means algorithm for clustering. We used cosine measure as the distance computation between a document and a cluster.</p><p>Then, we extracted keywords from each cluster to express the cluster well. We defined the formula of a degree how much a word in a cluster expresses the cluster as follows. Cluster Word Score used the ratio of appearance probability of the word w in one cluster and appearance probability of the word w in the other clusters. A word that appears very much in one cluster and doesn't appear very much in the other cluster has the high score. We think the words are important and express the cluster well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clarification Form</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keyword Extraction</head><formula xml:id="formula_0" coords="3,158.28,99.52,324.27,174.63">( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) (<label>)</label></formula><formula xml:id="formula_1" coords="3,177.54,282.28,3.75,18.51">(</formula><p>We extract top 5 words of Cluster Word Score. Then we lay out the words to CF. CF using Local Information that we submintted is shown in Figure2.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">CF Generation using Global Information</head><p>First, we tried to extract information that is implicit in a corpus. We think that the meaning of a word would be explained by other words like dictionary. For instance, "Computer" can be semantically expressed by "PC", "Computing", and "Workstation". Relation between "Computer" and "Computer" is not treated. Additionally, a word is semantically expressible by giving the membership values of a related word. This example is shown in Table <ref type="table" coords="4,381.16,194.79,3.95,9.45" target="#tab_0">2</ref>.1. Then, we defined this membership value by using the degree of a relation between words. The degree of a relation between words is calculated based on the co-occurrence in the same sentence.</p><p>We think that if two words co-occurred frequently in the same sentence, a relation between these words is strong.</p><p>Outline of CF Generation using Global Information is shown in Figure <ref type="figure" coords="4,412.28,590.79,3.94,9.45">2</ref>.3. We calculated the degrees of relations of all words, and generated word vectors of the words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2.3 Outline of CF Generation using Global Information</head><p>There is a very serious problem to treat co-occurrence of words. This problem is that an actual relation between continuous words is infrequently weak even if these words co-occur frequently in the same sentence. One example is "Hot dog". "Hot dog" doesn't mean the relation between "Have a high temperature" and "Dog in animal", but means simply "Food". By treating these words as one word, a wrong relation between these words is not given. We called such continuous words Phrase.</p><p>We take note of the following properties to extract Phrase.  If the score is larger than threshold, the words are assumed to be Phrase and treated like one word.</p><formula xml:id="formula_2" coords="6,134.76,96.85,349.32,72.09">( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) α - = = - - = 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 df log ,</formula><p>Then, we defined the asymmetric degree of a relation between words. When word A strongly relates to word B, the following properties is effective.</p><p>a) The word B appears frequently when the word A appears.</p><p>b) The appearance probability of the word B rises by co-occurring with the word A. In other words, the appearance probability of the word B when the word A appears is larger than in a corpus.</p><p>In consideration of these properties we defined the following expressions. As a result, the degree of a relation is calculated. After generating word vectors of noun words or adjective words in a corpus, the word vectors are normalized. An element in word vector corresponds to a related word.</p><formula xml:id="formula_3" coords="6,187.56,490.76,241.17,146.15">( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ∑ ∑ ∈ = = - - = ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ = ←</formula><p>And the word vector of a topic is calculated based on the sum of the word vectors generated from words in title and description. In consequence, a word in word vector of a topic whose value is larger than a threshold was extracted as a topic's related word.</p><p>Our system classified the extracted related words. The k-means algorithm and cosine measure were used for clustering. Centers of initial clusters were selected so that all centers might mutually become sparse. The degree of a cluster's relation to a topic is calculated from the words in the cluster.</p><p>We extracted top-20 clusters, and top two or three words in each cluster and showed the words as CF.</p><p>CF using Global Information that we submintted is shown in Figure2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2.4 CF using Global Information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">CF Generation using WordNet</head><p>In this section, we tried to expand words in a topic using WordNet, the dictionary manually made.</p><p>WordNet has nodes, synonym set and tree structure. We attempted to specify the meaning by showing hyponym sets of the synonym set to a user.</p><p>Our system extracted hyponym sets of the synonym sets that respond to the words in a topic.</p><p>Finally, two or three words of 20 hyponym sets were shown to a user as CF. CF using WordNet that we submintted is shown in Figure2.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2.5 CF using WordNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Selection</head><p>Our system extracted new query from items judged to be truth in CF. Each item corresponds to a cluster or a synonym set. In the following, keyword extraction from the clusters or synonym sets judged to be truth in CF is treated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Using Local Information</head><p>After our system received the CF results, we extracted the important words from clusters judged to truth in CF to express topic well. We defined the formula of a degree how much a word expresses topic as follows.</p><p>( ) The words in title and in description were also used as Query. The word vectors of the words was TF values of the words in title and in description.</p><formula xml:id="formula_4" coords="9,178.92,122.11,280.61,155.16">( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Using Global Information</head><p>We extracted the words from CF using Global Information based on two methods. One method is using the words chosen by a user. The other is using information on the chosen clusters. Topic Word score is calculated by product of the elements in the center vectors of chosen clusters. Words whose score were higher than a threshold were adopted as Query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Using WordNet</head><p>We think that Synonym sets judged to be the truth in CF is relevant to the topic. Then, the words in this Synonym set were added to Query.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Result and Discussion</head><p>We submitted two baseline runs and seven final runs. We showed the results in Table2.2. Our system used Jakarta Lucene. Query using both Local Information and Global Information is generated from query using Local Information and query using Global Information.</p><p>In the run using Local Information, R-precision improved 18.3% in comparison with baseline run (MeijiHilBL1). In the run using Global Information, R-precision improved 2.8%. This is higher than 1.4% in the run using WordNet. So Global Information is more useful than WordNet, the dictionary manually made. In the run using Global Information and Local Information, R-precision improved 17.6%. This is lower than 18.3% in the run using Local Information. Therefore, our system using both Global Information and Local Information can't get the good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Robust Track</head><p>This is the first year that our group participates in the Robust Track of the TREC. Here we report our system and a method on the Ad Hoc Task. Our method employs Document Expansion Model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Expansion Model</head><p>Everyone characterizes a document with words actually occurring in the text of the document. We use all words related to the document in "Document Expansion Model". In other words, some words related to a document are added to the document. The association with a document is presented by "word context". We call the model "Document Expansion Model". The model is word vector model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Document Representation</head><p>Document represents words actually occurring in the text of the document and synonymy.</p><p>Synonymy is described later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Context</head><p>In the paper, we define word sequence to appear before a word "word context". This is based on a thought of N-gram which occurrence of a word depends on only words just before. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Synonymy</head><p>Synonymy in an accurate meaning is such as America, U.S.A. ,United States of America, and U.S..</p><p>We define "Synonymy" as a set of words provided from the same word context. ex)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Context Weight</head><p>It needs to weight word context. Synonymy which word context created, depends on a word actually occurring in the document with the word context. As word context's weight is original word's IDF.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Relation of Synonymy and Word Context</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,199.80,734.48,207.09,10.80;3,120.96,554.52,364.74,169.50"><head>Figure</head><label></label><figDesc>Figure 2.2 CF using Local Information</figDesc><graphic coords="3,120.96,554.52,364.74,169.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,92.16,644.79,418.31,9.45;5,113.46,662.79,163.61,9.45;5,92.22,680.79,112.49,9.45;5,93.90,716.79,416.52,9.45;5,85.08,734.79,194.03,9.45;5,150.06,166.88,25.30,9.81;5,401.22,285.62,34.80,9.81;5,383.82,203.84,69.71,9.81;5,392.88,221.84,51.61,9.81;5,405.78,139.63,24.53,9.36;5,398.46,151.63,39.16,9.36;5,250.26,133.28,69.35,9.81;5,243.60,151.28,82.69,9.81;5,235.98,258.32,102.88,9.81;5,248.52,312.32,80.19,9.81;5,136.26,403.46,49.21,9.81;5,254.52,415.16,64.78,9.81;5,384.96,317.12,67.93,9.81"><head></head><label></label><figDesc>a) Words of Phrase mutually have weak meaning relation. Therefore, these tend not to appear discontinuously in the same document. b) Phrase has generality. The following Phrase Score is defined in consideration of these properties. Co-occurrence Probability shows a) and Generality shows b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,205.86,630.69,20.31,6.21;6,196.98,630.69,4.60,6.21;6,240.54,571.11,4.60,6.21;6,232.92,616.04,7.89,10.64;6,313.14,556.46,7.89,10.64;6,219.96,616.04,7.23,10.64;6,176.10,616.04,8.54,10.64;6,234.00,599.66,8.54,10.64;6,239.16,582.80,7.89,10.64;6,226.32,582.80,7.23,10.64;6,202.14,590.30,7.89,10.64;6,175.74,590.30,22.34,10.64;6,323.04,556.46,8.54,10.64;6,300.48,556.46,7.23,10.64;6,250.44,556.46,40.72,10.64;6,315.78,538.64,8.54,10.64;6,305.88,538.64,7.89,10.64;6,293.40,538.64,7.23,10.64;6,243.36,538.64,40.72,10.64;6,211.68,547.10,8.54,10.64;6,201.78,547.10,7.89,10.64;6,175.74,547.10,22.34,10.64;6,405.78,518.42,7.89,10.64;6,379.38,518.42,22.34,10.64;6,410.16,500.66,8.54,10.64;6,400.32,500.66,7.89,10.64;6,374.22,500.66,22.34,10.64;6,352.02,509.12,15.11,10.64;6,344.76,509.12,5.91,10.64;6,331.32,509.12,8.54,10.64;6,321.42,509.12,7.89,10.64;6,295.38,509.12,22.34,10.64;6,271.26,509.12,8.54,10.64;6,246.84,509.12,7.89,10.64;6,227.88,509.12,15.10,10.64;6,175.74,509.12,51.90,10.64;6,116.94,675.17,15.94,19.30;6,120.72,682.92,7.97,10.75;6,107.76,682.92,7.30,10.75;6,139.08,683.60,187.00,9.81;6,117.00,699.46,3.93,22.02;6,139.44,699.46,3.93,22.02;6,130.08,709.44,8.63,10.76;6,120.36,709.44,7.97,10.76;6,107.82,709.44,7.30,10.76;6,149.04,710.06,342.49,9.81;6,117.30,187.67,16.12,19.30;6,121.26,195.42,7.97,10.75;6,108.12,195.42,7.30,10.76;6,139.44,195.46,190.88,10.78;6,248.34,205.23,4.32,19.99;6,286.44,205.23,4.32,19.99;6,280.14,219.89,3.61,6.49;6,260.76,219.89,3.61,6.49;6,265.86,213.25,3.09,11.13;6,219.96,213.25,26.77,11.13;6,188.46,213.25,27.47,11.13;6,108.12,213.25,65.95,11.13;6,271.20,213.25,8.25,11.13;6,252.66,213.25,8.25,11.13;6,178.50,209.27,6.78,15.14;6,296.94,214.34,95.69,9.81;6,401.82,220.12,3.48,6.27;6,394.62,213.70,82.46,10.78;6,302.28,232.10,49.01,9.81;6,361.26,237.82,3.48,6.27;6,353.22,231.40,126.34,10.78;6,119.58,241.67,16.06,19.30;6,123.48,249.40,7.99,10.78;6,107.76,249.42,9.96,10.76;6,142.44,249.46,154.57,10.78;6,107.04,263.11,7.50,15.41;6,123.42,268.28,50.37,9.81"><head>:</head><label></label><figDesc>Term frequency of word B when word A appears in the same sentence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,189.96,260.47,3.53,16.80;9,236.52,260.47,3.53,16.80;9,256.74,260.47,3.53,16.80;9,215.76,286.40,11.03,18.97;9,211.26,261.09,11.03,18.97;9,219.60,207.33,11.03,18.97;9,211.74,183.27,11.03,18.97;9,307.68,99.74,12.75,18.97;9,211.92,303.42,4.29,7.38;9,207.42,278.10,4.29,7.38;9,223.56,224.34,4.29,7.38;9,215.70,200.22,4.29,7.38;9,297.30,116.76,4.29,7.38;9,199.92,289.20,5.66,12.65;9,195.42,263.94,5.66,12.65;9,225.30,239.58,5.66,12.65;9,210.96,210.18,5.66,12.65;9,203.10,186.06,5.66,12.65;9,233.04,161.70,5.66,12.65;9,344.04,132.00,2.58,12.65;9,239.40,132.00,5.66,12.65;9,286.32,102.48,5.66,12.65;9,215.70,305.36,17.75,5.42;9,208.68,305.36,3.01,5.42;9,211.20,280.04,17.75,5.42;9,204.18,280.04,3.01,5.42;9,227.46,226.28,2.68,5.42;9,220.38,226.28,3.01,5.42;9,219.60,202.16,2.68,5.42;9,212.46,202.16,3.01,5.42;9,328.80,118.70,4.69,5.42;9,300.96,118.70,26.79,5.42;9,295.02,118.70,2.68,5.42;9,229.92,292.52,5.17,9.30;9,240.00,267.26,14.64,9.30;9,182.58,267.26,6.89,9.30;9,284.10,236.48,6.89,9.30;9,212.52,242.90,6.89,9.30;9,233.70,213.50,5.17,9.30;9,200.16,213.50,4.59,9.30;9,240.42,189.38,14.64,9.30;9,182.40,189.38,14.06,9.30;9,307.14,173.00,4.59,9.30;9,293.34,158.60,14.06,9.30;9,212.28,165.02,14.06,9.30;9,444.78,143.30,6.89,9.30;9,440.70,128.90,14.06,9.30;9,324.78,135.32,14.06,9.30;9,218.64,135.32,14.06,9.30;9,405.36,105.80,14.06,9.30;9,263.58,105.80,15.50,9.30;9,213.54,105.80,47.94,9.30;9,188.34,292.52,8.04,9.30;9,135.42,292.52,51.08,9.30;9,223.92,267.26,12.06,9.30;9,135.42,267.26,41.90,9.30;9,287.64,250.88,8.04,9.30;9,234.72,250.88,51.08,9.30;9,237.00,236.48,41.90,9.30;9,186.18,242.90,21.82,9.30;9,135.42,242.90,48.79,9.30;9,182.76,213.50,13.20,9.30;9,135.42,213.50,45.91,9.30;9,224.34,189.38,12.06,9.30;9,135.42,189.38,41.90,9.30;9,289.74,173.00,13.20,9.30;9,242.46,173.00,45.91,9.30;9,246.42,158.60,41.90,9.30;9,181.32,165.02,26.41,9.30;9,135.42,165.02,44.20,9.30;9,418.44,143.30,21.82,9.30;9,367.74,143.30,48.79,9.30;9,409.68,128.90,26.41,9.30;9,363.84,128.90,44.20,9.30;9,347.94,135.32,13.20,9.30;9,293.76,135.32,26.41,9.30;9,247.92,135.32,44.20,9.30;9,185.28,135.32,28.69,9.30;9,135.42,135.32,48.21,9.30;9,372.00,105.80,28.69,9.30;9,322.08,105.80,48.21,9.30;9,280.02,105.80,3.44,9.30;9,209.52,105.80,3.44,9.30;9,191.04,105.80,17.78,9.30;9,135.42,105.80,53.37,9.30;9,90.36,428.79,420.06,9.45;9,85.08,446.79,101.19,9.45"><head></head><label></label><figDesc>Score was comptered, Top 30 words were used as Query. The word vectors of the words were normalized.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,203.34,325.99,4.03,10.89;9,191.76,325.99,3.03,10.89;9,165.60,325.99,36.47,10.89;9,184.08,325.99,8.07,10.89;9,219.54,326.78,197.29,9.81;9,167.28,352.85,113.03,11.08;9,163.98,381.68,229.36,9.82;9,163.98,399.68,69.53,9.81"><head>:</head><label></label><figDesc>TF value of the word w in document d d : Document length TrueClusters : clusters judged to be truth in CF c : cluster c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="11,223.62,619.88,131.66,11.21"><head>Figure3. 1</head><label>1</label><figDesc>Figure 3.1 word context</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="12,239.10,316.88,118.61,11.21"><head></head><label></label><figDesc>Figure 3.2 Synonymy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="13,216.90,320.90,146.86,11.21"><head>Figure</head><label></label><figDesc>Figure 3.4 System Outline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,184.50,266.48,236.51,188.99"><head>Table 2 .1 Membership values of "computer"</head><label>2</label><figDesc></figDesc><table coords="4,254.28,302.27,103.15,153.21"><row><cell>word</cell><cell>score</cell></row><row><cell>PC</cell><cell>0.81</cell></row><row><cell cols="2">computing 0.53</cell></row><row><cell cols="2">workstation 0.51</cell></row><row><cell>processor</cell><cell>0.47</cell></row><row><cell>desktop</cell><cell>0.35</cell></row><row><cell>internet</cell><cell>0.23</cell></row><row><cell>firewall</cell><cell>0.17</cell></row><row><cell>system</cell><cell>0.16</cell></row><row><cell>apple</cell><cell>0.14</cell></row><row><cell>digital</cell><cell>0.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,50.16,100.64,485.14,247.58"><head>Table 2 .2 HARD Track Result</head><label>2</label><figDesc></figDesc><table coords="10,50.16,135.60,485.14,212.63"><row><cell>Run</cell><cell>MAP</cell><cell>R-precision</cell><cell>Improvement</cell><cell>Detail</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(Comparison with BL1)</cell><cell></cell></row><row><cell>MeijiHilBL1</cell><cell>0.1370</cell><cell>0.1966</cell><cell>Baseline</cell><cell>Title, Description</cell></row><row><cell>MeijiHilBL2</cell><cell>0.1654</cell><cell>0.2236</cell><cell>Baseline</cell><cell>Title, Description, Narrative</cell></row><row><cell>MeijiHilCWE1</cell><cell>0.1855</cell><cell>0.2326</cell><cell>18.3%</cell><cell>Local Information</cell></row><row><cell>MeijiHilRW</cell><cell>0.1451</cell><cell>0.2007</cell><cell>2.1%</cell><cell>Global Information (Word)</cell></row><row><cell>MeijiHilRC</cell><cell>0.1467</cell><cell>0.1972</cell><cell>0.3%</cell><cell>Global Information (Cluster)</cell></row><row><cell>MeijiHilRWC</cell><cell>0.1516</cell><cell>0.2021</cell><cell>2.8%</cell><cell>Global Information (Word + Cluster)</cell></row><row><cell>MeijiHilWN</cell><cell>0.1371</cell><cell>0.1993</cell><cell>1.4%</cell><cell>WordNet</cell></row><row><cell>MeijiHilMrg</cell><cell>0.1847</cell><cell>0.2312</cell><cell>17.6%</cell><cell>Local Information + Global Information</cell></row><row><cell>TREC Baseline Median</cell><cell>0.1901</cell><cell>0.2518</cell><cell></cell><cell></cell></row><row><cell>TREC Median</cell><cell>0.2071</cell><cell>0.2639</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,95.21,374.79,3.05,9.45;13,113.46,374.79,396.93,9.45;13,113.46,392.79,273.89,9.45" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,362.84,374.79,147.55,9.45;13,113.46,392.79,41.07,9.45">Query expansion with long-span collocates</title>
		<author>
			<persName coords=""><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,165.41,392.79,89.78,9.45">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2003-04">April 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.16,410.79,418.19,9.45;13,113.46,428.79,397.03,9.45;13,113.46,446.79,396.99,9.45;13,113.46,464.79,24.53,9.45" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,287.82,428.79,183.24,9.45">UMass at TREC 2004: Novelty and HARD</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nasreen</forename><surname>Abdul-Jaleel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leah</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Courtney</forename><surname>Wade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,240.56,446.79,236.03,9.45">The Thirteenth Text REtrieval Conference Proceedings</title>
		<imprint>
			<biblScope unit="page" from="500" to="261" />
		</imprint>
	</monogr>
	<note>TREC 2004</note>
</biblStruct>

<biblStruct coords="13,92.16,482.79,13.06,9.45" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Iii</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,113.46,482.79,396.96,9.45;13,113.46,500.79,396.93,9.45;13,113.46,518.79,272.69,9.45" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,468.99,482.79,41.43,9.45;13,113.46,500.79,212.30,9.45">Microsoft Cambridge at TREC-13: Web and HARD tracks</title>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suchi</forename><surname>Saria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,494.08,500.79,16.31,9.45;13,113.46,518.79,212.58,9.45">The Thirteenth Text REtrieval Conference Proceedings</title>
		<imprint>
			<biblScope unit="volume">500</biblScope>
		</imprint>
	</monogr>
	<note>TREC 2004</note>
</biblStruct>

<biblStruct coords="13,92.16,536.79,13.66,9.45" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Iv</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,113.46,536.79,396.88,9.45;13,113.46,554.79,396.90,9.45;13,113.46,572.79,396.95,9.45;13,113.46,590.79,111.47,9.45" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,210.28,554.79,300.08,9.45;13,113.46,572.79,18.85,9.45">The Robert Gordon University&apos;s HARD Track Experiments at TREC 2004</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gheorghe</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bicheng</forename><surname>Muresan1</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dietrich</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nirmalie</forename><surname>Wettschereck</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wiratunga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,315.80,572.79,194.62,9.45;13,113.46,590.79,51.42,9.45">The Thirteenth Text REtrieval Conference Proceedings</title>
		<imprint>
			<biblScope unit="page" from="500" to="261" />
		</imprint>
	</monogr>
	<note>TREC 2004</note>
</biblStruct>

<biblStruct coords="13,92.16,608.79,273.62,9.45" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="13,167.74,608.79,165.49,9.45">Computation and Language in Japanese</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">Kenji</forename><surname>Kita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.16,626.79,418.26,9.45;13,113.46,644.79,142.08,9.45" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,223.27,626.79,212.77,9.45">Word Sense Disambiguation: The State of the Art</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vi. Ide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Véronis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,448.12,626.79,62.30,9.45;13,113.46,644.79,46.71,9.45">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
