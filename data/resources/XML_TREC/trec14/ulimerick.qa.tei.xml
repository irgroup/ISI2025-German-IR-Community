<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,80.76,110.80,434.64,18.10">Question Answering using the DLT System at TREC 2005</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,120.96,142.84,123.55,13.08"><forename type="first">Richard</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,322.32,142.84,93.87,13.08"><forename type="first">Michael</forename><surname>Mulcahy</surname></persName>
							<email>michael.mulcahy@ul.iekieran.white@ul.ieigal.gabbay@ul.ieaoife.ogorman@ul.ie</email>
						</author>
						<author>
							<persName coords="1,426.00,142.84,74.11,13.08"><forename type="first">Kieran</forename><surname>White</surname></persName>
						</author>
						<author>
							<persName coords="1,327.60,158.92,64.06,13.08"><forename type="first">Igal</forename><surname>Gabbay</surname></persName>
						</author>
						<author>
							<persName coords="1,401.52,158.92,93.35,13.08"><forename type="first">Aoife</forename><surname>O'gorman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Department of Computer Science and Information Systems</orgName>
								<orgName type="laboratory">Natural Language Engineering and Documents and Linguistic Technology Group Web Applications Group</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<addrLine>Wivenhoe Park</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Limerick</orgName>
								<address>
									<postCode>CO4 3SQ</postCode>
									<settlement>Colchester, Limerick</settlement>
									<country>UK, Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,80.76,110.80,434.64,18.10">Question Answering using the DLT System at TREC 2005</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B6F0EFCA6389219253A0CCFB9AECF9E3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This article summarises our participation in the Question Answering (QA) Track at TREC. Section 2 outlines the architecture of our system. Section 3 describes the changes made for this year. Section 4 summarises the results of our submitted runs while Section 5 presents conclusions and proposes further steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Outline of System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overall Strategy</head><p>The following stages are at the core of our approach:</p><p>• Question analysis: Process the input query attempting to find its type (e.g. who or colour) and to identify significant phrases.</p><p>• Document retrieval: Formulate a search query based on the results of the previous stage. Use this together with a search engine indexed on the document collection to produce a list of candidate documents which are likely to contain answers to the question.</p><p>• Named entity recognition: Based on the query type identified in the first stage, search for corresponding named entities (NEs) in the candidate documents which co-occur with terms derived from the query.</p><p>• Answer selection: Decide which NE (or NEs) should be chosen as the answer.</p><p>These steps are very typical of first generation QA systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Factoids</head><p>Factoids were the first type of question to appear at TREC and they are still the most frequent, with 362 appearing in the current test collection. Each asks for a single piece of information such as a name or a date. The key to our strategy in processing factoids (in common with most other participants) is to predict the expected type of answer (e.g. a date) from the type of question (e.g. 'When...'). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Lists</head><p>List questions are flagged as such in the test collection and ask for a series of pieces of information all of the same type. They are essentially factoids where multiple answers are expected and this is the way they are treated in our system. We have so far devoted very little time to lists and our method of approaching them has remained the same: all results are returned whose match score exceeds a fixed threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Definitions (i.e. type 'Other')</head><p>Sadly we have also been able to devote very little time to definition questions. We first retrieve documents which contain the phrase specified in the question. We then search for instances of phrasal patterns which are intended to indicate the presence of important information about the target. Any such phrases are returned in a group as the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Question Groups</head><p>In common with last year, the questions are grouped by topic as expressed by a short phrase such as '1998 Baseball World Series'. There are 140 such topics this year. Each contains one or more factoids, lists and definitions. The markup makes it clear which of these three types each question in the group falls into.</p><p>The use of question groups is intended to stimulate research concerning the relationship between answers to different questions on the same topic. However, our approach to them is identical to the one we adopted when questions were presented in a simple list. While anaphors do occur in the questions (e.g. 71.2 (F16): 'How fast can it fly?) we do not attempt to resolve this but instead simply add the target (F16 in this case) to the end of the query before processing it.</p><p>The next section outlines particular aspects of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DLT System Components</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Summary of Enhancements</head><p>Due to shortage of time, very little was altered in our system. However, there were two major changes. Firstly, we experimented with query term expansion algorithms in the document retrieval stage. Secondly, we improved the technique used for answer selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Types and their Identification</head><p>Over the years, we have added more query types to the system. In 2003 there were 47 types plus 'unknown'. In 2004 this rose to 79 plus unknown. This year there are 82 plus unknown, a very small change. However, in 2003, 29 out of the 47 different query types were recognised in the test queries. In 2004, 28 out of the 79 were recognised. This year, 33 out of the 82 were used (see Table <ref type="table" coords="3,467.16,269.86,3.90,10.28">2</ref>). Thus, less than half of our query types are actually being used and the majority in fact occur very infrequently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Query Analysis</head><p>The following steps are carried out on the query:</p><p>• Tag the query for part-of-speech using Xelda ( <ref type="formula" coords="3,289.16,356.62,18.10,10.28">2003</ref>);</p><p>• Recognise instances of eleven different constructs;</p><p>• Weight these according to their importance;</p><p>• Order them according to weight;</p><p>• Use the conjunction of these as the initial search expression.</p><p>The eleven constructs are shown in Table <ref type="table" coords="3,254.40,458.50,5.37,10.28" target="#tab_0">1</ref> together with their weights and an example of each. Weights are assigned using a scheme reminiscent of <ref type="bibr" coords="3,258.84,471.10,89.75,10.28">Magnini et al. (2002)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Search Expression Formulation</head><p>Searches of the document collection use boolean queries. Constructs as identified in the previous stage are ordered by increasing score and then joined with AND operators to make a single boolean query. This is then used as the starting point of a search for documents.</p><p>We tried an experiment in term expansion using the Local Context Analysis (LCA) algorithm of <ref type="bibr" coords="3,494.16,569.74,31.77,10.28;3,70.44,582.46,53.41,10.28" target="#b2">Xu and Croft (2000)</ref>. The input terms were the phrases identified in the question. The top 200 documents (i.e. sentences) returned from the collection when these phrases were used as a non-Boolean query were used.</p><p>The parameter was set to 0.01. The ten best scoring terms identified in the collection by the LCA algorithm were selected and used to boost the boolean query used in document retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Document Retrieval</head><p>The entire corpus is split into individual sentences each of which is indexed separately using the Lucene system. Each 'document' retrieved by the system is thus a sentence. The complete query is submitted and the first n results found are returned (Lucene orders documents even for boolean queries). n is set to 30. If no document is found, the query is relaxed by removing the least significant term and then re-submited.</p><p>The process continues until results are returned or no further simplification is possible.</p><p>Classif. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correct Classification Incorrect Classification Total</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Named Entity Recognition</head><p>As previously, NE recognition uses our own module which is based on grammars together with some exhaustive lists. Following <ref type="bibr" coords="5,190.92,144.58,84.11,10.28" target="#b0">Clarke et al. (2003)</ref>, queries of unknown type are answered by searching for general names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Answer Selection</head><p>During this stage, each candidate NE found within a returned document is scored and the highest scoring NE is returned as the answer to the question. Scoring is done using a measure which incorporates the number of co-occurring key phrases, their assigned weights and their distance from the NE. The distance between a candidate NE and a key phrase is measured in words, e.g. if the phrase is adjacent to the NE its distance is 1, if one word separates them it is 2 and so on. Certain stop words such as prepositions do not contribute to this distance. The reciprocal of the distance is taken and this is multiplied by the weight assigned to the phrase. The sum of all such values is taken to provide an intermediate score for the NE.</p><p>The final score is this intermediate score multiplied by the Lucene score assigned to the containing document. Following this process, the highest scoring NE is returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Runs and Results</head><p>Two runs were submited. The first did not use the LCA expansion while the second did. n (see earlier) was set to 30 throughout. Run 1 was better and the analysis for it is shown in Table <ref type="table" coords="5,439.92,370.78,4.04,10.28">2</ref>. Only those query types which were actually encountered in the test collection are shown. Thus we see that 3 types were used plus unknown. Performance in query classification can be discerned from the first two columns of the table. Of the 362 factoid queries, 300 were classified correctly, i.e. 82.87%. This is a good result given our simple methods and is consistent with previous years.</p><p>Note that the types of query are not at all evenly distributed in the test collection. On the contrary, the vast majority are who (62 or 17.13%), when (54 or 14.92%), where (40 or 11.05%), how_many3 (39 or 10.77%). These four categories account for 53.87% of the queries. Following this we drop down to company (10 or 2.76%), what_country (8 or 2.21%), distance, how_old and when_year (each 7 or 1.93%), profession (5 or 1.38%) and when_date (4 or 1.10%). The remaining types each occur less than four times.</p><p>Classification accuracy on the top four categories is 85.48% for who, 98.15% for when, 97.5% for where and 100.00% for how_many3. Thus performance on who queries seems markedly worse than the others.</p><p>Concerning unknown queries, we consider a query to be correctly classified as unknown if should not in fact be classified as any other type in the system. Conversely, classification is incorrect if an existing type should have been used. 42/86 i.e. 48.84% of unknown queries were correctly classified. This means that 42/362 i.e. 11.60% of queries lie outside the designed scope of the system, a surprisingly small figure.</p><p>Turning to the 44 queries incorrectly classified as unknown, an analysis can be seen in Table <ref type="table" coords="5,483.72,635.62,4.04,10.28">3</ref>. The 44 queries should have been distributed among twenty different query types with between one and four unknown queries being assigned to each type. In other words, mis-classified unknown queries are fairly evenly distributed among the query types of the system.</p><p>A final analysis we carried out was of 'difficult' questions which are either impossible or very difficult for a system to answer. A breakdown of these is shown in Table <ref type="table" coords="8,358.44,121.66,4.04,10.28">4</ref>. The most frequent category is those queries where the type of the answer is unclear from the question. 17 of these were observed in the test collection. A typical example is 110.1 'What is the mission of the Lions Club?'. In this case we have no way of knowing what a mission is before inspecting the text. Of course, it could be a motto, an idea a theme and so forth, but these could be expressed in many ways and are not really amenable to an NEbased approach. Four queries used unusual phrasing, e.g. 81.5 'What was the track attendance for the 1998 Preakness?'. Here, track attendance is presumably the number of horses which took place but this is a very rare way of expressing this information. Four queries expressed complex notions, e.g. 72.3 'What is the Bollywood equivalent of Beverly Hills?'. Equivalence is a nebulous concept and once again it would be necessary to read and comprehend the text before understanding it. There was a definition question, a list questio and a why question. These are not strictly factoids. There was a fine-grained question 113.2 'What is his second successful career?'. This is very complex to answer since several careers for the one person are being discussed simultaneously. Finally, there was a why question which was also very general: 117.5 'Why is it a problem?'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>This year, very little time was available for our experiments and in consequence the system we used was very similar to last year. Results were also similar with an improvement on factoids of less than 1%. One major addition was the use of query expansion using Local Context Analysis (LCA). While this method is definitely very good at returning contextually related terms which moreover are guaranteed to be within the vocabulary of the corpus, our experiments did not show an improvement in QA performance, at least for the particular way in which we used it to boost certain results in Boolean searches. We need to carry out further analysis to find out exactly why this is so.</p><p>Two general themes running through our results over the years are, firstly that classification accuracy using simple keyword method is surprisingly good at 80% or more (this year 82.87%). This means that classification is not limiting the performance of our system. Secondly, queries are not evenly distributed over query types. We noticed this particularly at NTCIR this year where our performance was still 14.00% in a system which only had twelve types plus unknown. It follows from this that with limited time available, we should devote our attention to the small subset of the query types which occur frequently.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,147.48,140.98,19.01,9.05;4,209.16,140.98,6.32,9.05;4,230.88,140.98,12.68,9.05;4,265.20,140.98,6.32,9.05;4,293.40,140.98,6.32,9.05;4,321.24,140.98,6.32,9.05;4,347.04,140.98,8.76,9.05;4,377.40,140.98,6.32,9.05;4,405.48,140.98,6.32,9.05;4,433.44,140.98,6.32,9.05;4,459.12,140.98,8.76,9.05;4,100.56,157.77,23.57,9.28;4,211.08,157.44,4.38,8.38;4,239.04,157.44,4.38,8.38;4,267.12,157.44,4.38,8.38;4,295.08,157.44,4.38,8.38;4,323.16,157.44,4.38,8.38;4,351.24,157.44,4.38,8.38;4,379.20,157.44,4.38,8.38;4,407.28,157.44,4.38,8.38;4,435.24,157.44,4.38,8.38;4,463.32,157.44,4.38,8.38;4,491.40,157.44,4.38,8.38;4,100.56,172.05,24.83,9.28;4,211.08,171.84,4.38,8.38;4,239.04,171.84,4.38,8.38;4,267.12,171.84,4.38,8.38;4,295.08,171.84,4.38,8.38;4,323.16,171.84,4.38,8.38;4,351.24,171.84,4.38,8.38;4,379.20,171.84,4.38,8.38;4,407.28,171.84,4.38,8.38;4,435.24,171.84,4.38,8.38;4,463.32,171.84,4.38,8.38;4,491.40,171.84,4.38,8.38;4,100.56,186.69,35.45,9.28;4,211.08,186.36,4.38,8.38;4,239.04,186.36,4.38,8.38;4,267.12,186.36,4.38,8.38;4,295.08,186.36,4.38,8.38;4,323.16,186.36,4.38,8.38;4,351.24,186.36,4.38,8.38;4,379.20,186.36,4.38,8.38;4,407.28,186.36,4.38,8.38;4,435.24,186.36,4.38,8.38;4,463.32,186.36,4.38,8.38;4,486.96,186.36,8.82,8.38;4,100.56,201.09,31.78,9.28;4,211.08,200.76,4.38,8.38;4,239.04,200.76,4.38,8.38;4,267.12,200.76,4.38,8.38;4,295.08,200.76,4.38,8.38;4,323.16,200.76,4.38,8.38;4,351.24,200.76,4.38,8.38;4,379.20,200.76,4.38,8.38;4,407.28,200.76,4.38,8.38;4,435.24,200.76,4.38,8.38;4,463.32,200.76,4.38,8.38;4,491.40,200.76,4.38,8.38;4,100.56,215.61,16.06,9.28;4,211.08,215.40,4.38,8.38;4,239.04,215.40,4.38,8.38;4,267.12,215.40,4.38,8.38;4,295.08,215.40,4.38,8.38;4,323.16,215.40,4.38,8.38;4,351.24,215.40,4.38,8.38;4,379.20,215.40,4.38,8.38;4,407.28,215.40,4.38,8.38;4,435.24,215.40,4.38,8.38;4,463.32,215.40,4.38,8.38;4,491.40,215.40,4.38,8.38;4,100.56,230.25,50.62,9.28;4,211.08,229.92,4.38,8.38;4,239.04,229.92,4.38,8.38;4,267.12,229.92,4.38,8.38;4,295.08,229.92,4.38,8.38;4,323.16,229.92,4.38,8.38;4,351.24,229.92,4.38,8.38;4,379.20,229.92,4.38,8.38;4,407.28,229.92,4.38,8.38;4,435.24,229.92,4.38,8.38;4,463.32,229.92,4.38,8.38;4,491.40,229.92,4.38,8.38;4,100.56,244.89,47.33,9.28;4,206.64,244.56,8.82,8.38;4,239.04,244.56,4.38,8.38;4,267.12,244.56,4.38,8.38;4,295.08,244.56,4.38,8.38;4,323.16,244.56,4.38,8.38;4,346.80,244.56,8.82,8.38;4,379.20,244.56,4.38,8.38;4,407.28,244.56,4.38,8.38;4,435.24,244.56,4.38,8.38;4,463.32,244.56,4.38,8.38;4,486.96,244.56,8.82,8.38;4,100.56,259.41,73.73,9.28;4,211.08,259.20,4.38,8.38;4,239.04,259.20,4.38,8.38;4,267.12,259.20,4.38,8.38;4,295.08,259.20,4.38,8.38;4,323.16,259.20,4.38,8.38;4,351.24,259.20,4.38,8.38;4,379.20,259.20,4.38,8.38;4,407.28,259.20,4.38,8.38;4,435.24,259.20,4.38,8.38;4,463.32,259.20,4.38,8.38;4,491.40,259.20,4.38,8.38;4,100.56,274.05,62.14,9.28;4,211.08,273.72,4.38,8.38;4,239.04,273.72,4.38,8.38;4,267.12,273.72,4.38,8.38;4,295.08,273.72,4.38,8.38;4,323.16,273.72,4.38,8.38;4,351.24,273.72,4.38,8.38;4,379.20,273.72,4.38,8.38;4,407.28,273.72,4.38,8.38;4,435.24,273.72,4.38,8.38;4,463.32,273.72,4.38,8.38;4,491.40,273.72,4.38,8.38;4,100.56,288.45,33.77,9.28;4,211.08,288.12,4.38,8.38;4,239.04,288.12,4.38,8.38;4,267.12,288.12,4.38,8.38;4,295.08,288.12,4.38,8.38;4,323.16,288.12,4.38,8.38;4,351.24,288.12,4.38,8.38;4,379.20,288.12,4.38,8.38;4,407.28,288.12,4.38,8.38;4,435.24,288.12,4.38,8.38;4,463.32,288.12,4.38,8.38;4,491.40,288.12,4.38,8.38;4,100.56,302.97,34.78,9.28;4,211.08,302.76,4.38,8.38;4,239.04,302.76,4.38,8.38;4,267.12,302.76,4.38,8.38;4,295.08,302.76,4.38,8.38;4,323.16,302.76,4.38,8.38;4,351.24,302.76,4.38,8.38;4,379.20,302.76,4.38,8.38;4,407.28,302.76,4.38,8.38;4,435.24,302.76,4.38,8.38;4,463.32,302.76,4.38,8.38;4,491.40,302.76,4.38,8.38;4,100.56,317.37,40.86,9.28;4,211.08,317.04,4.38,8.38;4,239.04,317.04,4.38,8.38;4,267.12,317.04,4.38,8.38;4,295.08,317.04,4.38,8.38;4,323.16,317.04,4.38,8.38;4,351.24,317.04,4.38,8.38;4,379.20,317.04,4.38,8.38;4,407.28,317.04,4.38,8.38;4,435.24,317.04,4.38,8.38;4,463.32,317.04,4.38,8.38;4,491.40,317.04,4.38,8.38;4,100.56,331.77,47.93,9.28;4,211.08,331.44,4.38,8.38;4,239.04,331.44,4.38,8.38;4,267.12,331.44,4.38,8.38;4,295.08,331.44,4.38,8.38;4,323.16,331.44,4.38,8.38;4,351.24,331.44,4.38,8.38;4,379.20,331.44,4.38,8.38;4,407.28,331.44,4.38,8.38;4,435.24,331.44,4.38,8.38;4,463.32,331.44,4.38,8.38;4,491.40,331.44,4.38,8.38;4,100.56,346.17,37.37,9.28;4,211.08,345.84,4.38,8.38;4,239.04,345.84,4.38,8.38;4,267.12,345.84,4.38,8.38;4,295.08,345.84,4.38,8.38;4,323.16,345.84,4.38,8.38;4,351.24,345.84,4.38,8.38;4,379.20,345.84,4.38,8.38;4,407.28,345.84,4.38,8.38;4,435.24,345.84,4.38,8.38;4,463.32,345.84,4.38,8.38;4,491.40,345.84,4.38,8.38;4,100.56,360.69,41.57,9.28;4,211.08,360.48,4.38,8.38;4,239.04,360.48,4.38,8.38;4,267.12,360.48,4.38,8.38;4,295.08,360.48,4.38,8.38;4,323.16,360.48,4.38,8.38;4,351.24,360.48,4.38,8.38;4,379.20,360.48,4.38,8.38;4,407.28,360.48,4.38,8.38;4,435.24,360.48,4.38,8.38;4,463.32,360.48,4.38,8.38;4,491.40,360.48,4.38,8.38;4,100.56,375.33,40.49,9.28;4,211.08,375.00,4.38,8.38;4,239.04,375.00,4.38,8.38;4,267.12,375.00,4.38,8.38;4,295.08,375.00,4.38,8.38;4,323.16,375.00,4.38,8.38;4,351.24,375.00,4.38,8.38;4,379.20,375.00,4.38,8.38;4,407.28,375.00,4.38,8.38;4,435.24,375.00,4.38,8.38;4,463.32,375.00,4.38,8.38;4,491.40,375.00,4.38,8.38;4,100.56,389.97,36.46,9.28;4,211.08,389.64,4.38,8.38;4,239.04,389.64,4.38,8.38;4,267.12,389.64,4.38,8.38;4,295.08,389.64,4.38,8.38;4,323.16,389.64,4.38,8.38;4,351.24,389.64,4.38,8.38;4,379.20,389.64,4.38,8.38;4,407.28,389.64,4.38,8.38;4,435.24,389.64,4.38,8.38;4,463.32,389.64,4.38,8.38;4,491.40,389.64,4.38,8.38;4,100.56,404.49,22.13,9.28;4,211.08,404.28,4.38,8.38;4,239.04,404.28,4.38,8.38;4,267.12,404.28,4.38,8.38;4,295.08,404.28,4.38,8.38;4,323.16,404.28,4.38,8.38;4,351.24,404.28,4.38,8.38;4,379.20,404.28,4.38,8.38;4,407.28,404.28,4.38,8.38;4,435.24,404.28,4.38,8.38;4,463.32,404.28,4.38,8.38;4,491.40,404.28,4.38,8.38;4,100.56,419.13,18.82,9.28;4,211.08,418.80,4.38,8.38;4,239.04,418.80,4.38,8.38;4,267.12,418.80,4.38,8.38;4,295.08,418.80,4.38,8.38;4,323.16,418.80,4.38,8.38;4,351.24,418.80,4.38,8.38;4,379.20,418.80,4.38,8.38;4,407.28,418.80,4.38,8.38;4,435.24,418.80,4.38,8.38;4,463.32,418.80,4.38,8.38;4,491.40,418.80,4.38,8.38;4,100.56,433.77,14.98,9.28;4,211.08,433.44,4.38,8.38;4,239.04,433.44,4.38,8.38;4,267.12,433.44,4.38,8.38;4,295.08,433.44,4.38,8.38;4,323.16,433.44,4.38,8.38;4,351.24,433.44,4.38,8.38;4,379.20,433.44,4.38,8.38;4,407.28,433.44,4.38,8.38;4,435.24,433.44,4.38,8.38;4,463.32,433.44,4.38,8.38;4,491.40,433.44,4.38,8.38;4,100.56,448.29,43.97,9.28;4,211.08,448.08,4.38,8.38;4,239.04,448.08,4.38,8.38;4,267.12,448.08,4.38,8.38;4,295.08,448.08,4.38,8.38;4,323.16,448.08,4.38,8.38;4,351.24,448.08,4.38,8.38;4,379.20,448.08,4.38,8.38;4,407.28,448.08,4.38,8.38;4,435.24,448.08,4.38,8.38;4,463.32,448.08,4.38,8.38;4,491.40,448.08,4.38,8.38;4,100.56,462.93,37.97,9.28;4,211.08,462.60,4.38,8.38;4,239.04,462.60,4.38,8.38;4,267.12,462.60,4.38,8.38;4,295.08,462.60,4.38,8.38;4,323.16,462.60,4.38,8.38;4,351.24,462.60,4.38,8.38;4,379.20,462.60,4.38,8.38;4,407.28,462.60,4.38,8.38;4,435.24,462.60,4.38,8.38;4,463.32,462.60,4.38,8.38;4,491.40,462.60,4.38,8.38;4,100.56,477.57,53.09,9.28;4,211.08,477.24,4.38,8.38;4,239.04,477.24,4.38,8.38;4,267.12,477.24,4.38,8.38;4,295.08,477.24,4.38,8.38;4,323.16,477.24,4.38,8.38;4,351.24,477.24,4.38,8.38;4,379.20,477.24,4.38,8.38;4,407.28,477.24,4.38,8.38;4,435.24,477.24,4.38,8.38;4,463.32,477.24,4.38,8.38;4,491.40,477.24,4.38,8.38;4,100.56,492.09,59.81,9.28;4,211.08,491.88,4.38,8.38;4,239.04,491.88,4.38,8.38;4,267.12,491.88,4.38,8.38;4,295.08,491.88,4.38,8.38;4,323.16,491.88,4.38,8.38;4,351.24,491.88,4.38,8.38;4,379.20,491.88,4.38,8.38;4,407.28,491.88,4.38,8.38;4,435.24,491.88,4.38,8.38;4,463.32,491.88,4.38,8.38;4,491.40,491.88,4.38,8.38;4,100.56,506.49,86.14,9.28;4,211.08,506.16,4.38,8.38;4,239.04,506.16,4.38,8.38;4,267.12,506.16,4.38,8.38;4,295.08,506.16,4.38,8.38;4,323.16,506.16,4.38,8.38;4,351.24,506.16,4.38,8.38;4,379.20,506.16,4.38,8.38;4,407.28,506.16,4.38,8.38;4,435.24,506.16,4.38,8.38;4,463.32,506.16,4.38,8.38;4,491.40,506.16,4.38,8.38;4,100.56,521.13,35.86,9.28;4,211.08,520.80,4.38,8.38;4,239.04,520.80,4.38,8.38;4,267.12,520.80,4.38,8.38;4,295.08,520.80,4.38,8.38;4,323.16,520.80,4.38,8.38;4,351.24,520.80,4.38,8.38;4,379.20,520.80,4.38,8.38;4,407.28,520.80,4.38,8.38;4,435.24,520.80,4.38,8.38;4,463.32,520.80,4.38,8.38;4,491.40,520.80,4.38,8.38;4,100.56,535.65,54.65,9.28;4,211.08,535.44,4.38,8.38;4,239.04,535.44,4.38,8.38;4,267.12,535.44,4.38,8.38;4,295.08,535.44,4.38,8.38;4,323.16,535.44,4.38,8.38;4,351.24,535.44,4.38,8.38;4,379.20,535.44,4.38,8.38;4,407.28,535.44,4.38,8.38;4,435.24,535.44,4.38,8.38;4,463.32,535.44,4.38,8.38;4,491.40,535.44,4.38,8.38;4,100.56,550.29,20.69,9.28;4,206.64,549.96,8.82,8.38;4,239.04,549.96,4.38,8.38;4,262.68,549.96,8.82,8.38;4,295.08,549.96,4.38,8.38;4,323.16,549.96,4.38,8.38;4,346.80,549.96,8.82,8.38;4,379.20,549.96,4.38,8.38;4,407.28,549.96,4.38,8.38;4,435.24,549.96,4.38,8.38;4,463.32,549.96,4.38,8.38;4,486.96,549.96,8.82,8.38;4,100.56,564.93,41.74,9.28;4,211.08,564.60,4.38,8.38;4,239.04,564.60,4.38,8.38;4,267.12,564.60,4.38,8.38;4,295.08,564.60,4.38,8.38;4,323.16,564.60,4.38,8.38;4,351.24,564.60,4.38,8.38;4,379.20,564.60,4.38,8.38;4,407.28,564.60,4.38,8.38;4,435.24,564.60,4.38,8.38;4,463.32,564.60,4.38,8.38;4,491.40,564.60,4.38,8.38;4,100.56,579.45,42.11,9.28;4,211.08,579.24,4.38,8.38;4,239.04,579.24,4.38,8.38;4,267.12,579.24,4.38,8.38;4,295.08,579.24,4.38,8.38;4,323.16,579.24,4.38,8.38;4,351.24,579.24,4.38,8.38;4,379.20,579.24,4.38,8.38;4,407.28,579.24,4.38,8.38;4,435.24,579.24,4.38,8.38;4,463.32,579.24,4.38,8.38;4,491.40,579.24,4.38,8.38;4,100.56,594.09,23.38,9.28;4,206.64,593.76,8.82,8.38;4,239.04,593.76,4.38,8.38;4,267.12,593.76,4.38,8.38;4,295.08,593.76,4.38,8.38;4,323.16,593.76,4.38,8.38;4,346.80,593.76,8.82,8.38;4,379.20,593.76,4.38,8.38;4,407.28,593.76,4.38,8.38;4,435.24,593.76,4.38,8.38;4,463.32,593.76,4.38,8.38;4,486.96,593.76,8.82,8.38;4,100.56,608.73,53.70,9.28;4,211.08,608.40,4.38,8.38;4,239.04,608.40,4.38,8.38;4,267.12,608.40,4.38,8.38;4,295.08,608.40,4.38,8.38;4,323.16,608.40,4.38,8.38;4,351.24,608.40,4.38,8.38;4,379.20,608.40,4.38,8.38;4,407.28,608.40,4.38,8.38;4,435.24,608.40,4.38,8.38;4,463.32,608.40,4.38,8.38;4,491.40,608.40,4.38,8.38;4,100.56,623.25,16.37,9.28;4,206.64,623.04,8.82,8.38;4,239.04,623.04,4.38,8.38;4,267.12,623.04,4.38,8.38;4,295.08,623.04,4.38,8.38;4,323.16,623.04,4.38,8.38;4,346.80,623.04,8.82,8.38;4,379.20,623.04,4.38,8.38;4,407.28,623.04,4.38,8.38;4,435.24,623.04,4.38,8.38;4,463.32,623.04,4.38,8.38;4,486.96,623.04,8.82,8.38;4,100.56,637.89,35.69,9.28;4,206.64,637.56,8.82,8.38;4,234.60,637.56,8.82,8.38;4,267.12,637.56,4.38,8.38;4,295.08,637.56,4.38,8.38;4,323.16,637.56,4.38,8.38;4,346.80,637.56,8.82,8.38;4,379.20,637.56,4.38,8.38;4,407.28,637.56,4.38,8.38;4,435.24,637.56,4.38,8.38;4,458.88,637.56,8.82,8.38;4,486.96,637.56,8.82,8.38;4,100.56,652.78,19.84,9.05;4,202.20,652.68,13.26,8.38;4,234.60,652.68,8.82,8.38;4,262.68,652.68,8.82,8.38;4,295.08,652.68,4.38,8.38;4,323.16,652.68,32.46,8.38;4,379.20,652.68,4.38,8.38;4,407.28,652.68,4.38,8.38;4,435.24,652.68,4.38,8.38;4,458.88,652.68,36.90,8.38;4,105.48,680.81,385.49,10.01;4,105.48,692.49,385.42,9.28;4,105.48,703.89,385.61,9.28;4,105.48,715.29,343.46,9.28"><head></head><label></label><figDesc>by Query Type for Run 1. The columns C and NC show the numbers of queries of a particular type which were classified correctly and not correctly. Those classified correctly are then broken down into Right, ineXact, Unsupported and Wrong. Next, those classified incorrectly are also broken down. The final column shows the total number of queries for each type.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,105.48,124.97,385.38,186.55"><head>Table 1 :</head><label>1</label><figDesc>Construct Types used in Query Analysis. The second column is the integer weight assigned to the construct and the third shows a sample phrase for the type. All come from the 2005 queries except the example adverb -none were encountered this year.</figDesc><table coords="2,147.60,124.97,296.33,138.79"><row><cell>Construct</cell><cell>Weight</cell><cell>Example</cell></row><row><cell>quote</cell><cell>80</cell><cell>82.1 "Howdy Doody Show"</cell></row><row><cell>all_cap_wd</cell><cell>60</cell><cell>85.1 NCL</cell></row><row><cell>cap_dot_wd</cell><cell>1</cell><cell>108.2 U.S.</cell></row><row><cell>cap_nou_prep_det_seq</cell><cell>40</cell><cell>113.4 Hole in the Wall Foundation</cell></row><row><cell>cap_wd_seq</cell><cell>40</cell><cell>68.1 Port Arthur</cell></row><row><cell>number</cell><cell>20</cell><cell>77.3 first</cell></row><row><cell>low_adj_low_nou</cell><cell>40</cell><cell>72.2 foreign city</cell></row><row><cell>non_cap_nou_seq</cell><cell>40</cell><cell>67.4 contest</cell></row><row><cell>wd (vrb)</cell><cell>20</cell><cell>66.4 lost</cell></row><row><cell>wd (adj)</cell><cell>6</cell><cell>85.3 private</cell></row><row><cell>wd (adv)</cell><cell>5</cell><cell>* quickly</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,75.96,728.01,169.70,9.28"><p>On Sabbatical from University of Limerick.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Question answering performance is also summarised for factoids in Table <ref type="table" coords="7,410.76,569.74,4.04,10.28">2</ref>. Columns 4-7 show the number of queries of each type which were rated Right, ineXact, Unsupported and Wrong following correct type classification. Columns 8-11 show the same information for queries following incorrect type classification. Overall performance is 61+3/362 i.e. 17.68% as compared to 16.96% last year.</p><p>Performance in Run 2 using LCA (not shown in the tables) was 55/362 i.e. 15.19%. We carried out an analysis of the results to see where the differences lay. In particular, were there any queries where LCA returned the correct answer in Run 2 where the answer in Run 1 was incorrect? It turns out that there are only three such queries: 68.1, 81.3 and 123.3. Conversely there are twelve queries for which LCA causes a correct answer to be lost: <ref type="bibr" coords="7,192.60,683.26,333.33,10.28;7,70.44,695.98,22.34,10.28">82.5, 95.2, 100.2, 101.1, 111.2, 116.5, 119.2, 124.4, 127.1, 129.2, 131.3 and 134.4</ref>. Overall then, Run 2 is better by three and worse by twelve, i.e. worse by nine overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>Many thanks to Ken Litkowski for providing answer patterns and supporting documents for the question collection.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,70.44,565.66,455.45,10.28;8,70.44,578.26,455.45,10.28;8,70.44,590.98,455.49,10.28;8,70.44,603.58,455.45,10.28" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,106.80,578.26,364.40,10.28">Statistical Selection of Exact Answers (MultiText Experiments for TREC 2002)</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kemkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Laszlo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Terra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>Tilker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,239.16,591.06,286.77,10.08;8,70.44,603.66,23.04,10.08">Proceedings of the Eleventh Text REtrieval Conference (TREC 2002)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>the Eleventh Text REtrieval Conference (TREC 2002)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2003. November 19-22, 2002</date>
			<biblScope unit="page" from="500" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.44,616.18,408.65,10.28;8,70.44,632.62,166.37,10.28" xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Gaithersburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,70.44,632.62,25.77,10.28">Xelda</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Commerce, National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
	<note>www.temis-group.com</note>
</biblStruct>

<biblStruct coords="8,70.44,649.06,455.39,10.28;8,70.44,661.72,293.69,11.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,209.04,649.06,316.79,10.28;8,70.44,661.90,35.77,10.28">Improving the Effectiveness of Information Retrieval with Local Context Analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,113.40,661.98,185.98,10.08">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
