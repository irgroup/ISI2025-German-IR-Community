<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,130.42,136.50,350.43,15.11;1,216.99,158.42,177.26,15.11">DalTREC 2005 Spam Track: Spam Filtering using N-gram-based Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-02-10">February 10, 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.75,190.91,63.46,10.48"><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,220.00,190.91,83.84,10.48"><forename type="first">Evangelos</forename><surname>Milios</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.62,190.91,73.72,10.48"><forename type="first">Andrew</forename><surname>Tuttle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,395.22,190.91,61.77,10.48"><forename type="first">Singer</forename><surname>Wang</surname></persName>
							<email>swang@cs.dal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.70,204.85,65.85,10.48"><forename type="first">Roger</forename><surname>Zhang</surname></persName>
							<email>rogerz@cs.dal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,130.42,136.50,350.43,15.11;1,216.99,158.42,177.26,15.11">DalTREC 2005 Spam Track: Spam Filtering using N-gram-based Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-02-10">February 10, 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">8AA92854B8D8A6B1F56890F526D59AB0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We briefly describe DalTREC 2005 Spam submission. DalTREC is the TREC research project at Dalhousie University. Four packages were submitted and they resulted in a median performance. The results are interesting and may be seen positive in the light of simplicity of our approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>2005 is the second year that Dalhousie University participated actively in TREC. The project DalTREC<ref type="foot" coords="1,135.11,421.01,3.97,6.12" target="#foot_0">1</ref> was initiated in 2003 and serves as an umbrella for different TREC-related activities at Dalhousie. The tracks of interest were Question Answering, Spam, HARD, Genomics, and Enterprise. We submitted runs for the Question Answering (QA) track and the Spam track. This paper discusses the Spam track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background Review</head><p>Spam, sometimes more formally known as "Unsolicited Commercial Email" (UCE) or "Unsolicited Bulk Email" (UBE), has grown from being a minor nuisance into a global menace. Millions of email users world-wide waste untold thousands of hours every day sorting through incoming mailboxes cluttered with unwanted or even offensive messages. Meanwhile, the growth in network resources consumed by spam continues at an unsustainable rate. The spiralling direct and indirect costs of spam threaten the reliability and utility of the email infrastructure that has become so vital to the global economy.</p><p>At the core of the spam problem is the fact that spam allows vendors to transfer the vast majority of their marketing costs to the people they are marketing to. Even though the response rate to spam is believed to be vanishingly small, it is still large enough to overcome the even smaller costs of sending spam. Therefore, it becomes a volume-driven business-the more spam you send, the more money you make. But the real cost of the ensuing flood of junk email is not small, and it is borne by the owners of the networks and servers that must deliver the spam, and by the individual recipients who must waste valuable time sorting through it.</p><p>A variety of legal, structural, and technical solutions have been proposed; most are controversial and many suffer from glaring weaknesses. Legal solutions face daunting jurisdiction problems. Structural solutions, such as replacing SMTP, face staggering infrastructure costs. Many technical solutions are extremely high-maintenance, resulting in a never-ending "arms race" between the elusive spammers and the network administrators attempting to find new ways to block them.</p><p>While the world searches for a long-term solution, there is an urgent need for something businesses can use to protect their networks from the escalating costs of spam. This research is motivated by that need.</p><p>Example: "Valid-channel" spam. Classifying certain kinds of spam may be very subjective: some people will classify these messages as spam, which some other will classify them as ham, i.e., non-spam messages. An example is spam that we call "valid-channel" spam. Namely, some spam messages sneak through e-mail list servers and get distributed to subscribers. By content, this is clearly a spam message, but some user may decide to classify it as ham since it came through an important list form. If the e-mail server itself, removed the message as a spam, that would be correct action, but since the spam message made it through it is not to be ignored any more. This approch would be consistend with the use of white-lists, for example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Naïve Bayes Classifier (dalSPAM1 and 4)</head><p>The Naïve Bayes classifier is a simple statistical algorithm with a long history of providing surprisingly accurate results. It has been used in several spam classification studies <ref type="bibr" coords="2,448.01,359.60,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="2,462.12,359.60,7.75,8.74" target="#b4">5,</ref><ref type="bibr" coords="2,473.46,359.60,12.73,8.74" target="#b10">11,</ref><ref type="bibr" coords="2,489.78,359.60,7.01,8.74" target="#b8">9]</ref>, and has become somewhat of a benchmark. It gets its name from being based on Bayes's rule of conditional probability, combined with the "naïve" assumption that all conditional probabilities are independent (given the class) <ref type="bibr" coords="2,221.98,395.47,14.61,8.74" target="#b9">[10]</ref>.</p><p>Namely, to classify whether a message is spam or ham, we evaluate certain set of features of this message. If C is the message class (spam or ham) and the feature values are f 1 , . . . , f n , then our goal is to calculate the probability P(C = spam | f 1 , . . . , f n ), while the corresponding probability</p><formula xml:id="formula_0" coords="2,91.25,443.29,244.91,9.65">P(C = ham | f 1 , . . . , f n ) = 1 -P(C = spam | f 1 , . . . , f n ).</formula><p>Using Bayes' theorem, we have:</p><formula xml:id="formula_1" coords="2,173.05,464.21,263.95,23.23">P(C = spam | f 1 , . . . , f n ) = P(C = spam)P(f 1 , . . . , f n | spam) P(f 1 , . . . , f n )</formula><p>The Naïve Bayes assumption implies further:</p><formula xml:id="formula_2" coords="2,91.25,518.52,428.75,56.10">P(C = spam | f 1 , . . . , f n ) = P(C = spam)P(f 1 | spam) . . . P(f n | spam) P(f 1 , . . . , f n ) Knowing further that P(f 1 , . . . , f n ) = P(C = spam)P(f 1 | spam) . . . P(f n | spam) + P(C = ham)P(f 1 | ham) . . . P(f n | ham) makes it easy to compute P(C = spam | f 1 , . . . , f n )</formula><p>given trained values for P(C = spam and P(C = ham, and conditional probability tables for P(f i | spam) and P(f i | ham), which can be obtained from the training data using using maximum-likelihood estimation.</p><p>In terms of implementation, intermediate results are usually very small positive numbers, which can become a problem for finite precision of floating-point numbers. A solution is to convert the probabilities to their logarithms and use addition instead of multiplication. The Naïve Bayes model does not generally suffer from the sparse data problem, but zero conditional probabilities may still occur and they must be avoided. We use a smoothing technique known as a "Laplace estimator" to avoid this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Feature Selection</head><p>One of the difficulties in any text classification task is caused by the unstructured nature of natural language which, as opposed to highly structured database items, requires a very large number of attributes to model effectively. Among the various models developed over the last few decades, the Vector Space Model (VSM) <ref type="bibr" coords="3,212.73,157.30,10.51,8.74" target="#b2">[3]</ref> is the most popular today. In VSM, each document D is represented by a vector in m dimensional term space. The underlying term T of each dimension is often referred to as a feature or attribute and represented by the weight of T in D. Earlier models use binary term weights <ref type="bibr" coords="3,127.33,193.17,9.96,8.74" target="#b6">[7]</ref>, which are either 1 when the term is present in the document, or 0 when the term is absent. This weighting scheme is conceptually simple, and computationally cheap, however it lacks the ability to count on term importance-terms that are more important to a document often tend to occur more frequently in that document. This leads to the development of TF-IDF (term frequency and inverse document frequency) <ref type="bibr" coords="3,237.33,240.99,10.51,8.74" target="#b5">[6]</ref> based models, which assumes that term importance is directly proportional to the number of times a term occurs in a document, and inversely proportional to the number of documents in which it occurs. Given a document D and a term T, TF(D, T) is the number of times T occurred in D, and IDF(T) is the number of documents in which T occurred divide into the total number of documents in the dataset. Since not all documents are of the same length, TF(D, T) may turn out to be bigger in longer documents. In order to avoid this bias, we usually normalize it against the most frequent term in the document to get TFN(D, T), meanwhile, in order to avoid big number arithmetic, the base-2 logarithm of IDF(T) is usually used instead.</p><p>Since we incorporate two alternative feature representations in our filter, a "term" here can be either a naturally bounded word or a character N-gram. A character N-gram is simply any sequence of N consecutive characters taken from a text. For trigrams as an example, think of a width 3 sliding window moving from the beginning to the end of a text, one letter at a time, then the content of the window at each step is a trigram. N-gram representation has been shown competing word representation in text classification tasks [?]. For our submission, dalSPAM1 incorporates words as features and dalSPAM4 uses N-gram representation with N being 5.</p><p>One problem with both word representation and N-gram representation is the excessive number of features, which has the effect of slowing down the classification of the email as it requires more I/O to load the features and their weights into memory. In the two submissions, dalSPAM1 and dalSPAM4, one of the goals is to see if we can still achieve good accuracy while using a smaller number of features. As a result we use mutual information (MI) <ref type="bibr" coords="3,392.29,468.13,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="3,407.48,468.13,7.75,8.74" target="#b4">5,</ref><ref type="bibr" coords="3,419.91,468.13,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="3,432.33,468.13,7.75,8.74" target="#b8">9]</ref> to determine the best 1000 features for the classifier to work with. Our parser includes the values of all header fields, as well as the entire body text (although the Document class strips out MIME attachments before parsing, leaving only the text and HTML portions of a MIME-formatted message, along with the MIME headers for each attachment). When using word representation, the characters ,.!?-:"'&lt;&gt;*;()[] as well as the space, tab and new-line characters were used as token delimiters. Carriage returns were stripped out by the Document class before parsing. Tokens were truncated to a maximum length of 30 characters. For efficiency requirements of the TREC run, we do not use word stemming or stop word list. When using character N-gram representation, only alphabetical letters are considered significant, therefore all other characters are delimiters and are treated as spaces. Two or more consecutive spaces are treated as one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The White-list</head><p>A white-list filter was incorporated in submissions dalSPAM1 and dalSPAM4. Each time a missclassified ham message is corrected during training, the sender's address will be automatically added to the white-list together with a time stamp. The length limit of the white-list is controlled by a parameter, which can be customized according to different user needs. When the length limit is exceeded, oldest entries will be truncated. Users may also add entries manually if they want. An entry can be either an individual address-which takes the form "user@domain", or a domainwhich takes the form "@domain". Manually added entries are treated as permanent (with a special time stamp), and will never get truncated.  The program classify collects n-grams from the email file, and measure the dissimilarities of the file profile with the ham and spam profiles using the formula:</p><formula xml:id="formula_3" coords="4,163.45,500.30,356.55,33.66">d = n∈Ps∪P h f 1 (n) -f 2 (n) f1(n)+f2(n) 2 2 = n∈Ps∪P h 2 • (f 1 (n) -f 2 (n)) f 1 (n) + f 2 (n) 2<label>(1)</label></formula><p>where P s is the set of n-grams in spam profile, and P h is the set of n-grams in ham profile. If the dissimilarities of the e-mail file from the ham and spam profiles are s ham and s spam , respectively, then the score is computed using the formula: score = s ham s ham + s spam .</p><p>The message is classified as spam if score &gt; 0.5, otherwise it is classified as ham. The program classify will print the score and the classification result. The program train updates the ham or spam profile. It reads the appropriate profile, multiply all frequencies with 0.9 (which we call profile aging), collect up to 3000 most frequent n-grams from the email file with count frequencies, and add this message profile to the existing profile. It will keep only up to 3000 most frequent n-grams in the profile and save it to the class profile file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation</head><p>The main evaluation results on 53 submitted filters based on the TREC Spam overview report <ref type="bibr" coords="5,509.49,121.43,10.52,8.74" target="#b1">[2]</ref> are given in the following The reason why the lam% rank of dalSPAM3 and dalSPAM4 is significantly differs is that for those two filters we did not tune the threshold parameter, but simply used the default value of 0.5.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,91.25,360.37,8.08,12.62;4,115.45,360.37,389.84,12.62;4,91.25,385.23,428.75,8.74;4,91.25,397.19,428.75,8.74;4,91.25,409.14,428.75,8.74;4,91.25,421.10,428.74,9.02;4,91.25,433.05,428.75,9.02;4,91.25,445.01,428.76,8.74;4,91.25,456.96,241.98,8.74"><head>7 N</head><label>7</label><figDesc>-gram Based Techniques (dalSPAM2 and dalSPAM3)Both submissions dalSPAM2 and dalSPAM3 use a simple raw byte n-gram based technique. The Dal2 and Dal3 runs used a simple raw byte n-gram-based technique. The difference is only in the ngram size: dalSPAM2 uses n-grams of size 4, and dalSPAM3 uses n-grams of size 5. The programs maintains two files named ham.profile and spam.profile containing a list of up to 3000 byte n-grams with associated count frequencies. The Perl package was used Text::Ngrams to collect the n-grams. If the input message is longer than 10,000, only the first 10,000 bytes are used in order not spend too much running time on n-gram collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,112.17,133.39,159.15,86.59"><head>table :</head><label>:</label><figDesc></figDesc><table coords="5,112.17,151.07,159.15,68.91"><row><cell>Filter</cell><cell>Rank</cell><cell cols="2">Rank Rank</cell></row><row><cell></cell><cell cols="3">ROCA h=.1 lam%</cell></row><row><cell>dalSPAM3</cell><cell>28</cell><cell>26</cell><cell>40</cell></row><row><cell>dalSPAM1</cell><cell>30</cell><cell>42</cell><cell>34</cell></row><row><cell>dalSPAM2</cell><cell>31</cell><cell>29</cell><cell>41</cell></row><row><cell>dalSPAM4</cell><cell>36</cell><cell>33</cell><cell>37</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,106.49,687.56,188.10,6.99"><p>http://www.cs.dal.ca/˜trecacct -DalTREC URL</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,111.73,296.40,408.27,8.74;5,111.73,308.35,52.58,8.74" xml:id="b0">
	<monogr>
		<title level="m" coord="5,111.73,296.40,292.26,8.74">Proceedings of the Thirteenth Text REtrieval Conference (TREC-13)</title>
		<meeting>the Thirteenth Text REtrieval Conference (TREC-13)<address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,328.28,408.27,8.74;5,111.73,340.23,395.48,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,286.06,328.28,133.78,8.74">Trec 2005 spam track overview</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,441.80,328.28,78.20,8.74;5,111.73,340.23,221.62,8.74">Proceedings of the Fourtheenth Text REtrieval Conference (TREC-14)</title>
		<meeting>the Fourtheenth Text REtrieval Conference (TREC-14)<address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,360.16,408.27,8.74;5,111.73,372.11,94.09,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,190.13,360.16,201.39,8.74">A vector space model for automatic indexing</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,403.79,360.16,109.71,8.74">Communications of ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,392.04,408.27,8.74;5,111.73,403.99,408.27,8.74;5,111.73,415.95,408.27,8.74;5,111.73,427.90,186.00,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,506.99,392.04,13.01,8.74;5,111.73,403.99,205.97,8.74">An evaluation of naive bayesian anti-spam filtering</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">V</forename><surname>Chandrinos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Koutsias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,339.31,403.99,180.69,8.74;5,111.73,415.95,408.27,8.74;5,111.73,427.90,22.68,8.74">Proceedings of the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning (ECML 2000)</title>
		<meeting>the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning (ECML 2000)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,447.83,408.26,8.74;5,111.73,459.78,408.26,8.74;5,111.73,471.74,408.27,8.74;5,111.73,483.69,408.27,8.74;5,111.73,495.65,252.84,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,161.24,459.78,358.75,8.74;5,111.73,471.74,65.65,8.74">Learning to filter spam e-mail: A comparison of a Naïve Bayesian and a memorybased approach</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Karkaletsis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sakkis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Stamatopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,199.99,471.74,320.01,8.74;5,111.73,483.69,408.27,8.74;5,111.73,495.65,106.25,8.74">Proceedings of the Workshop on Machine Learning and Textual Information Access, 4th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2000)</title>
		<meeting>the Workshop on Machine Learning and Textual Information Access, 4th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2000)<address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,515.57,408.27,8.74;5,111.73,527.53,389.11,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,171.59,515.57,348.42,8.74;5,111.73,527.53,32.79,8.74">Text categorization with support vector machines: Learning with many relevant features</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,165.49,527.53,186.31,8.74">European Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,547.45,408.27,8.74;5,111.73,559.41,408.27,8.74;5,111.73,571.36,22.70,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,260.02,547.45,259.98,8.74;5,111.73,559.41,33.44,8.74">On relevance and two aspects of the organizational memory problem</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">O</forename><surname>Kimbrough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,169.57,559.41,276.06,8.74">4th Annual Workshop on Information Technology and Systems</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="302" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.73,591.29,408.26,8.74;5,111.73,603.24,408.27,8.74;5,111.73,615.20,299.20,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,415.19,591.29,104.81,8.74;5,111.73,603.24,86.23,8.74">A Bayesian approach to filtering junk e-mail</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mehran</forename><surname>Sahami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
		<idno>WS-98-05</idno>
	</analytic>
	<monogr>
		<title level="m" coord="5,221.58,603.24,293.31,8.74">Learning for Text Categorization: Papers from the 1998 Workshop</title>
		<meeting><address><addrLine>Madison, Wisconsin, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note type="report_type">AAAI Technical Report</note>
</biblStruct>

<biblStruct coords="5,111.73,635.13,408.27,8.74;5,111.73,647.08,408.28,8.74;5,111.73,659.04,143.24,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,226.78,635.13,293.23,8.74;5,111.73,647.08,32.91,8.74">A comparison of event models for Naive Bayes anti-spam e-mail filtering</title>
		<author>
			<persName coords=""><forename type="first">Karl-Michael</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,164.28,647.08,259.30,8.74">Proceedings of the 10th Conference of the European Chapter</title>
		<meeting>the 10th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.72,678.96,408.28,8.74;5,111.73,690.92,235.74,8.74" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="5,245.71,678.96,274.29,8.74;5,111.73,690.92,115.37,8.74">Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.72,99.61,408.28,8.74;6,111.73,111.57,408.27,8.74;6,111.73,123.52,340.77,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,291.35,99.61,228.66,8.74;6,111.73,111.57,64.33,8.74">A comparative study of classification based personal e-mail filtering</title>
		<author>
			<persName coords=""><forename type="first">Hongjun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanlei</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,202.69,111.57,317.31,8.74;6,111.73,123.52,118.31,8.74">Proceedings of PAKDD-00, 4th Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<meeting>PAKDD-00, 4th Pacific-Asia Conference on Knowledge Discovery and Data Mining<address><addrLine>Kyoto, JP</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="408" to="419" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
