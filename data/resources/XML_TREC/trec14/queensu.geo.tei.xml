<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,96.00,76.43,419.96,13.97;1,185.76,94.85,240.47,13.97">Applying Probabilistic Thematic Clustering for Classification in the TREC 2005 Genomics Track</title>
				<funder ref="#_vKVV82A">
					<orgName type="full">NSERC</orgName>
				</funder>
				<funder ref="#_uJGTJwX">
					<orgName type="full">Queen&apos;s ARC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,200.64,130.43,56.09,10.46"><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.36,130.43,39.67,10.46"><forename type="first">S</forename><surname>Brady</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.32,130.43,36.27,10.46"><forename type="first">A</forename><surname>Garg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,358.03,130.43,53.24,10.46"><forename type="first">H</forename><surname>Shatkay</surname></persName>
							<email>shatkay@cs.queensu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,96.00,76.43,419.96,13.97;1,185.76,94.85,240.47,13.97">Applying Probabilistic Thematic Clustering for Classification in the TREC 2005 Genomics Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">412F018CA26BED63DC75AA533AC1BD16</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our group participated in the categorization task of the TREC Genomics Track. We introduced and investigated a cluster-based approach for classifying documents. We first clustered the abstracts of the negative training examples based on their term distribution, then built a classifier to distinguish between each cluster and the set of positive examples. The large number of resulting classifiers (a total of 14-19 classifiers per domain) was combined to categorize the test set. We also conducted experiments for clusterbased feature selection; Rather than select features from the whole negative and positive training sets, we selected features from each of the clusters and took the union of these features as the selected features for representing the whole training and test data. We compared our cluster-based multi-classifier approach against a simple naïve Bayes classification. We also compared the cluster-based feature selection strategy with the commonly used Chi-square-based feature selection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Text categorization was one of the two tasks in the TREC 2005 Genomics Track. It was concerned with the classification of articles from four major categories, including alleles of mutant phenotypes, embryologic gene expression, tumor biology, and gene ontology (GO) annotation. The task was to identify documents that are relevant to these categories, using a classifier trained on the labeled data.</p><p>The full text articles for both training and test set were given, although we used only title, abstract and MeSH terms in our experiments. All articles in the training set were published in 2002, while articles in the test set were published in 2003. Therefore, both the training and test examples are not selected uniformly at random. The text categorization task provides the crosswalk files for both the training and test data as well. The corresponding PubMed ID (PMID) of each article is given in these files.</p><p>The evaluation measure for the text categorization task is the normalized utility score U norm for each category, which is defined as follows:</p><formula xml:id="formula_0" coords="1,162.00,526.29,79.79,9.47">U norm = U raw / U max ,</formula><p>where:</p><p>• U raw is the raw utility score, defined as the difference between the weighted true positives (TP) and the false positives (FP) :</p><formula xml:id="formula_1" coords="1,198.60,582.87,91.85,13.77">FP TP u U r raw - × = ) ( ,</formula><p>where r u is the relative utility of a relevant document; • U max is the best possible utility score, defined as the sum of the weighted TP and the false negatives (FN):</p><formula xml:id="formula_2" coords="1,198.54,636.61,94.49,13.45">) ( max FN TP u U r + × = .</formula><p>This evaluation measure penalizes misclassification on the relevant documents (false negatives) r u times more than misclassification of the irrelevant documents (false positives). It therefore favors high recall and compromises precision.</p><p>In our experiments, we considered the categorization task as four separate binary classification tasks. We investigated a new, cluster-based approach for classifying documents into these four categories. The observation underlying our approach is that the distribution of negative vs. positive examples, in both the training and the test data, is biased. The negative examples are abundant and may discuss a variety of topics, while the number of positive examples is small and their topic is usually focused. Hence, we first separated the abstracts in the negative training set into multiple clusters, based on their term distribution, by applying a probabilistic theme generation algorithm [Shatkay and Wilbur 00, Shatkay et al 00]. A classifier was then built to distinguish between each cluster and the set of positive examples. The resulting classifiers were combined into a single classifier. We applied the combined classifier to the test set.</p><p>We also tried to address the feature selection issue, noted as "conceptual drift" in last year's TREC <ref type="bibr" coords="2,492.53,183.93,29.49,8.74;2,90.00,195.45,34.97,8.74">[Cohen et al. 04</ref>], using cluster-based feature selection. Our experimental results suggest an improvement by selecting features that distinguish each individual cluster from the positive data set.</p><p>The rest of this paper is organized as follows: In the next section we introduce our methods, the theme generation technique, the cluster-based classification and the feature selection approach. Section 3 discusses our experimental results and a brief analysis is given. Finally, we conclude our work and suggest some future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head><p>We approached the text categorization task as four separate binary classification tasks, one for each of the four categories. For each task, the irrelevant documents were viewed as belonging to the irrelevant category. Our experiments mainly focused on the cluster-based classification approach, which will be introduced in Section 2.2. As a baseline for comparison and as a basic building block in our own categorization we use a naïve Bayes classifier. This is because the naïve Bayes technique is simple and still effective for text categorization. The version we employed is the one introduced by John and Langley <ref type="bibr" coords="2,499.97,361.29,22.27,8.74;2,90.00,372.81,53.40,8.74">[John and Langley,</ref><ref type="bibr" coords="2,147.01,372.81,11.91,8.74">95]</ref>, and implemented as WEKA's NaiveBayes utility <ref type="bibr" coords="2,372.74,372.81,90.98,8.74">[Witten and Frank 05]</ref>. This version allows both discrete and numerical features. When the classification model is built on the whole training set, without using clusters, we refer to it as the single-model classification.</p><p>We applied a cost sensitive approach <ref type="bibr" coords="2,242.10,413.31,76.88,8.74">[Breiman et al. 84]</ref> to reflect the different penalties on different types of misclassification, while using the normalized utility scoring. This formula takes into account the ratio between positive and negative data (neg#/ pos#), and the relative utility of a relevant document, u r . We introduce the variable CB into the formula so that the weight factor W p becomes adjustable. In our experiments, CB was chosen from the range [0, 5.0]. We adjust CB to find the model that produces the highest utility on the training data. The n-fold cross validation was used for the single-model classification. The number of folds (n) was set to 10 for the alleles and GO classification, and to 3 for the embryologic gene expression and tumor classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature Generation and Weighting</head><p>While the Genomics Track provided the full text for both the training and test set, we generated the features for all documents from their Medline records, including only the titles, abstracts, and MeSH terms. Using the PMIDs provided in the files train.crosswalk.txt and test.crosswalk.txt, the related Medline records were obtained directly from the Medline database. All XML tags in the Medline records were removed before the feature generation. Unlike the traditional "bag-of-word" model, by which typically only unigrams are extracted as features, we extracted both single words and 2-gram terms as features. Stop-words were removed and Porter stemming was applied to each word <ref type="bibr" coords="2,323.54,687.39,38.84,8.74">[Porter 80</ref>]. While a variety of feature weighting schemes exist, we used the simple binary weights: 1 for present and 0 for absent term. This is because our early preparatory experiments indicated that the binary weighting scheme outperformed the TF*IDF scheme for learning a naïve Bayes classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cluster-Based Classification</head><p>In the cluster-based approach, we first cluster the negative training examples into subgroups, based on their term distribution. This is done by applying a probabilistic theme generation algorithm, which is discussed in the next subsection. The generated clusters are referred to as themes. We then built a classifier to distinguish between each of the themes and the set of positive examples. Finally, we combined the large number of resulting classifiers to categorize the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Probabilistic Theme Generation</head><p>The probabilistic theme generation algorithm that we used is based on the one introduced a few years ago for retrieving Medline documents similar to a given a query document <ref type="bibr" coords="3,384.27,227.49,53.46,8.74">[Shatkay and</ref> Wilbur 00], and for finding functional relationship among genes <ref type="bibr" coords="3,272.66,238.95,71.97,8.74">[Shatkay et al 00]</ref>. A theme T is a set of documents that are likely to discuss a common topic. It is characterized by a set of term distributions. Given a database DB, the model R for a theme T consists of five components:</p><formula xml:id="formula_3" coords="3,300.60,259.34,121.60,14.31">}} { }, { }, { }, { , { i i i i d DB q p P R λ =</formula><p>where:</p><formula xml:id="formula_4" coords="3,117.00,274.81,223.85,12.97">• P d is the prior probability of any document DB d ∈</formula><p>to be in the theme T, ) Pr(</p><formula xml:id="formula_5" coords="3,439.74,275.85,52.54,13.77">T d P d ∈ =</formula><p>. It is assumed fixed by the application. • p i is the probability that the term t i occurs in a document d where d is an on-theme document,</p><formula xml:id="formula_6" coords="3,127.62,314.61,72.88,14.63">) | Pr( T d d t i ∈ ∈ .</formula><p>• q i is the probability that the term t i occurs in a document d when d is not in the theme T,</p><formula xml:id="formula_7" coords="3,117.00,342.69,405.04,46.09">) | Pr( T d d t i ∉ ∈ . • DB i is the probability that the term t i occurs in any document in the database, ) | Pr( DB d d t i ∈ ∈ . } { i</formula><p>DB can be easily estimated from the documents in the database.</p><p>• i λ is the probability that the term t i is generated according to the general database distribution DB i .</p><p>It is used as a mixture distribution between DB i and the theme-specific parameters p i and q i . The main tasks in generating a theme, based on an example document d, is to simultaneously estimate the model parameters p i , q i and i λ , while finding other documents in the database that are likely to have been generated by the same model. The latter set of documents is called the theme, while the terms with high score Log(p i /q i ) are viewed as its characteristic terms. An EM (Expectation Maximization) algorithm is used to find the most likely model R for a given example document d and a database DB. For details see earlier work <ref type="bibr" coords="3,141.13,487.35,52.44,8.74">[Shatkay and</ref> Wilbur 00, Shatkay et al 00].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Building Clusters and Classifiers</head><p>A schematic overview of the cluster-based approach is depicted in Figure <ref type="figure" coords="3,389.94,528.81,3.77,8.74">1</ref>. This approach originates from the observation that the positive training examples are few and typically focused on one topic, while the negative examples are many and may discuss a wide variety of topics. Taking the embryologic gene expression category as an example, the number of the negative examples in the training data is 5,756, while the number of the positive examples is only 81 (less than 2% of the total data). Looking at the negative examples, we observe that different examples discuss different topics. For instance, the negative example with PMID 12221087 is about the retinoblastoma tumor, while the document with PMID 12052828 discusses the role of serine proteases in erythrocyte invasion by merozoites of the malaria parasite. In this situation, the distribution of the whole negative examples becomes flat and non-specific. Therefore, trying to characterize all the negative examples with one single-model does not provide a clear distinction between the positive examples and the negative ones.</p><p>To address this problem, we apply the probabilistic theme generation algorithm to the negative training examples, sub-grouping them into disjoint thematic clusters. We expect that the negative examples within each thematic cluster are similar to each other, and that the term distribution within a cluster is more specific and well-defined than that of the whole negative example set. We therefore expect that it will be easier to determine, given a test example, with respect to each cluster separately (as opposed to with respect to the whole negative set), whether the example is inside the cluster or outside the cluster. Accordingly, we train as many classifiers as there are thematic clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. The Cluster-based Classification Process</head><p>As indicated in the Section 2.2.1, a theme is built around a single document. In our experiments, we randomly select an abstract from the negative data set as the representative document for a theme. Since we know that none of the positive examples should be a member of any cluster generated from the negative examples, we initialize the off-theme parameter q i of the model to reflect this bias. Whenever a term t i occurs in a positive example(s), q i is initialized by the number of occurrences of term t i in the positive data set divided by the total number of occurrences of any term in the positive data set. Moreover, we also impose the restriction that no abstract is associated with more than one theme. This guarantees that all thematic clusters are disjoint, although the original application [Shatkay and Wilbur 00, Shatkay et al 00] allowed overlap among themes.</p><p>To train a classifier for a particular cluster, we use the negative examples in a single cluster as the negative training set while all the positive examples are used as the positive training set. Note that each classifier is meant to determine whether an unseen example is inside or outside a specific thematic cluster. An example that is outside the cluster is not automatically placed inside the positive category, as it might be a member of another cluster.</p><p>Once all the classifiers are built from each thematic cluster, we use them to determine the membership of each example from the test data set. The classification results for an abstract d form an N-dimensional vector</p><formula xml:id="formula_8" coords="4,118.98,669.24,40.78,14.79">〉 〈 N d d T T ,... 1</formula><p>, where N is the number of themes, and → be a function mapping a document d in the database DB to the values, true or false, depending on whether d is a member of the category c. Then</p><formula xml:id="formula_9" coords="5,201.48,154.48,184.43,31.07">   ≤ ≤ = = . , , 1 , 0 , ) ( otherwise false N i i all for T if true d f i d c</formula><p>Clearly, our approach takes an alternative way to distinguish the positive documents from the negative ones, compared with the single-model classifier. Rather than directly test for membership of a document in the positive or the whole negative category, we separately test membership in each negative thematic cluster. A document is inferred to be a member of the positive category if and only if it is excluded from all the negative thematic clusters. Moreover, a document must demonstrate similarity to at least one specific negative cluster in order to be considered negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cluster-Based Feature Selection</head><p>The Chi-square test for feature selection was applied to the training set or its subsets, depending on the chosen classification method. Supervised feature selection is typically performed by considering the whole set of negative training samples vs. the whole set of positive ones; analyzing the correlation between the features and the categories, features that have significantly different distributions under different categories are selected. The assumption underlying such feature selection schemes is that the training data is a good representative of the true data, and specifically of the test data. This assumption, as reported by Cohen et al. <ref type="bibr" coords="5,90.00,363.51,70.18,8.74">[Cohen et al. 04]</ref>, and Zhang and Lee [Zhang and Lee 04], does not necessarily hold in the biomedical literature used in TREC, where the training data consist of earlier publications than the test data. Cohen et al. refer to the change in feature distribution over time as conceptual drift. That is, the topics that are discussed in the literature, the relative number of documents discussing these topics, and possibly the jargon used to discuss them, may all vary over time. Therefore, features that are selected from the whole training data may not be as useful for categorizing the "conceptually drifted" test data.</p><p>To try and overcome this drift, we have devised a cluster-based feature selection approach. We cluster the negative training set as described in Section 2.2. Then, rather than select features using the Chi-square test applied to the whole negative vs. positive training set, we apply the Chi-square test individually to each negative cluster (vs. the positive set). We then take the union of these features as the selected features and use them to represent the training and test data. The assumption is that the term distribution within each theme-cluster will remain consistent over time, while only the number of samples in each particular theme may change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>We have applied both the single naïve Bayes classification and the cluster-based classification to all the four categories included in the track. In both approaches, we trained the naïve Bayes classifiers using the cost sensitive scheme. For the cluster-based classification, numerous clusters have been built. Table <ref type="table" coords="5,517.00,575.43,5.01,8.74" target="#tab_2">1</ref> shows the number of clusters for each category. In addition to the official runs, we describe some of the unofficial runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Official Runs</head><p>The results of our official runs are presented in Table <ref type="table" coords="6,324.24,93.51,3.77,8.74" target="#tab_3">2</ref>. In the columns "Classification Method" and "Feature Selection", we use the term Single Model to denote that the classification or the feature selection is built on the whole training data, and the term Cluster-Based to denote the application of the cluster-based method to the classification or to the feature selection. The best results we achieved in the official runs, in terms of the normalized utility score, for each of the categories allele, embryologic gene expression, GO, and tumor, are 0.7760, 0.5563, 0.3763 and 0.7439, respectively. The recall is higher than the corresponding precision in all of our runs. This is partly because we have introduced a high cost to false negatives to reflect the biased penalty applied. We also note that in particular the cluster-based approach is expected to favor recall, as it requires examples to fit into specific negative-cluster models in order to be classified as negative. The highest recall we got is of 1.0 for tumor categorization in the run tQUT10, in which the cluster-based classification is applied. Overfitting is observed in both official and unofficial runs. For instance, the single-model run gQUNB12 resulted in a utility score of 0.696 for the training data, but only 0.346 for the test data. This might be partially caused by the different distributions of the training and test set, especially when the cost sensitive approach is applied. Note that the official runs from different classification methods are not directly comparable to each other because of their different feature selection schemes or different parameter settings. We have conducted some unofficial runs for a more complete comparison of different classification methods and different feature selection schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Unofficial Runs</head><p>In our unofficial runs, the best utility scores we got for the allele, embryologic gene expression, GO, and tumor categories are 0.7505, 0.6101, 0.4189 and 0.8582, respectively. These results are much better than those obtained in our official runs, except the one for allele categorization, which is 0.02 lower than the utility of our best official run. These results were obtained by either the cluster-based classification or by the single-model classification with the cluster-based feature selection. We will use bold to highlight these results in Table <ref type="table" coords="6,154.12,670.89,5.01,8.74" target="#tab_5">3</ref> and<ref type="table" coords="6,178.64,670.89,28.96,8.74" target="#tab_6">Table 4</ref>.</p><p>We performed several runs to directly compare the performance of the single-model classification and the cluster-based classification.  Our results show that, all else being equal, the cluster-based classification outperforms the single-model classification on all categorization tasks in terms of normalized utility and recall. Using the cluster-based classification, there is about 56% improvement in normalized utility. However, the precision resulting from the cluster-based approach is significantly lower than that of the single-model classification on all runs. This is because the cluster-based classification combines multiple cluster-based classifiers, each built on a separate cluster, where all these individual classifiers are biased towards avoiding false negatives. Recall that each individual cluster-based classifier is trained with respect to a single cluster of negative examples. Therefore, each such classifier has a narrow negative category associated with it, and all the documents falling outside this category are initially viewed as positive with respect to this specific classifier. This means that each cluster-based classifier initially produces a large number of false positives and relatively few false negatives. Taking our experimental result on the allele classification as an example, using sixteen clusters, the average number of the false negatives is 4, while the average number of the false positives is 4,875 (note that this is before the classification results are combined -this phase is not shown in the tables).</p><p>As discussed in Section 2.2.2, the results from the individual classifiers are combined such that a document is labeled as positive if and only if it is labeled as positive by all of the individual cluster-based classifiers. At this stage, we are left with 288 true positives and 516 false positives. While the number of the false positives has been significantly reduced when the results from the individual classifiers are combined, this number is still larger than the one resulting from the single-model classification, which is 172. Thus, many false positives still remain even after the strict positive selection induced by the combination of the individual classifiers. Trying to improve the precision under the cluster-based framework is our immediate next step. As discussed in Section 2.3, a side-effect of the cluster-based classification is an alternative method for feature selection. We have run some preliminary experiments to evaluate the performance of this method. We first collected the selected features from all the clusters that were constructed as part of the clusterbased classification. The union of the feature sets was used as features for both the training and test data.</p><p>For comparison, we applied the Chi-square test using the training data set, with no clustering, to select the same number of features. Keeping all parameters identical, single-models were constructed separately based on these two feature sets. The experimental results are presented in Table <ref type="table" coords="8,412.93,159.75,3.77,8.74" target="#tab_6">4</ref>. All experiments listed in Table <ref type="table" coords="8,116.29,171.27,5.01,8.74" target="#tab_6">4</ref> have CB value of 1. The Training Data column and the Test Data column show the normalized utility on the training set and the test set, respectively. The Difference column shows the difference in normalized utility between the training and test data. The Difference is used to evaluate the variability in the model performance between the training and the test sets. The smaller the difference is, the more consistent performance a model provides. We can clearly see that all models have better performance on the training set than on the test set. However, the models that are constructed based on the cluster-based feature selection perform more consistently than the models that are constructed based on the single-model feature selection. Our results suggest that there is less drift between test and training data when the clusterbased feature selection is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We approached the categorization task in the TREC 2005 Genomics Track as a set of separate binary classification tasks. A common characteristic of both training and test data is their relative abundance of negative examples, which typically leads to low recall. We have investigated a cluster-based classification approach, which aims to distinguish among subsets within the large set of negative examples. A comparison was made between this approach and the single-model approach. Using a basic text processing method, when all else is equal, the cluster-based classification approach outperforms the single-model approach in our experiments. We have also explored the effect of the cluster-based feature selection. Our primary finding is that the utility gap between the training data and the test data decreases when the clusterbased feature selection is applied, which suggests that the cluster-based feature selection may address the issue of "conceptual drift". We recognize the need for further improvement on the classification performance, and plan to experiment with more advanced baseline methods and feature selection in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,90.00,424.83,432.03,84.73"><head>CB is the Cost Bias for adjusting the weight factor, as explained below; • neg# is the number of negative examples in the training data; • pos# is the number of positive examples in the training data.</head><label></label><figDesc></figDesc><table coords="2,90.00,424.83,432.03,60.31"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>This was done by re-weighting the positive</cell></row><row><cell cols="16">examples in the training set with a weight factor W p . That is, each positive example is considered as W p</cell></row><row><cell cols="16">positive examples when learning the classifier. W p is calculated using the formula:</cell></row><row><cell>W</cell><cell>p</cell><cell>=</cell><cell>CB</cell><cell>×</cell><cell>u</cell><cell>r</cell><cell>×</cell><cell>(</cell><cell>neg</cell><cell>#</cell><cell>/</cell><cell>pos</cell><cell>#</cell><cell>)</cell><cell>, where:</cell></row><row><cell></cell><cell></cell><cell></cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,97.20,106.79,403.54,328.46"><head></head><label></label><figDesc>We consider an abstract to be inside the positive category if and only if it is excluded from all thematic clusters.</figDesc><table coords="4,97.20,106.79,403.54,328.46"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>d T i</cell><cell>=</cell><cell>  </cell><cell>0 1</cell><cell>∈ otherwise theme d if</cell><cell>i</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Negative Training Abstracts</cell></row><row><cell cols="2">Formally, let</cell><cell>f c</cell><cell>:</cell><cell cols="2">DB</cell><cell></cell><cell>{ true</cell><cell>,</cell><cell>} false</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Theme Generation</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>…</cell></row><row><cell></cell><cell></cell><cell cols="3">Theme 1</cell><cell></cell><cell></cell><cell>Theme 2</cell><cell>Theme N-1</cell><cell>Theme N</cell></row><row><cell>Positive</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feature Selection</cell></row><row><cell>Abstracts</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>…</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Classifiers Training</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>…</cell></row><row><cell>Test Abstracts</cell><cell cols="4">Classifier 1</cell><cell></cell><cell></cell><cell>Classifier 2</cell><cell>Classifier N-1</cell><cell>Classifier N</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Document</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Classification</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>…</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Classification Result Integration</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Result</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,148.38,620.92,315.21,53.51"><head>Table 1 :</head><label>1</label><figDesc>The number of clusters generated from the negative examples in each category</figDesc><table coords="5,155.16,620.92,298.08,30.09"><row><cell>Category</cell><cell>Allele</cell><cell>Embryologic Gene Expression</cell><cell>GO</cell><cell>Tumor</cell></row><row><cell># of clusters</cell><cell>16</cell><cell>15</cell><cell>19</cell><cell>18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,259.98,519.76,92.09,7.85"><head>Table 2 :</head><label>2</label><figDesc>The official runs</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,96.06,277.78,430.01,430.83"><head></head><label></label><figDesc>Table3shows the performance of the two classification methods under the We set the same Chi-square threshold for both methods on the same classification task. The thresholds are 7 for allele and GO, and 5 for embryologic gene expression and tumor. For each category, both methods -the single-model classification and the cluster-based classification -use the same value for CB.</figDesc><table coords="6,96.06,277.78,430.01,228.37"><row><cell cols="2">same parameter setting.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Category</cell><cell>Run</cell><cell>Classification Method</cell><cell>Terms</cell><cell>Feature Selection</cell><cell cols="3">CB Precision Recall</cell><cell>F-score</cell><cell>Normalized Utility</cell></row><row><cell></cell><cell>aQUNB8</cell><cell>Single Model</cell><cell cols="4">4487 Cluster-Based 0.54 0.3182</cell><cell>0.8464</cell><cell>0.4626</cell><cell>0.7397</cell></row><row><cell>Allele</cell><cell>aQUT11</cell><cell cols="3">Cluster-Based 10533 Single Model</cell><cell>1</cell><cell>0.3785</cell><cell>0.7741</cell><cell>0.5084</cell><cell>0.6993</cell></row><row><cell></cell><cell>aQUT14</cell><cell cols="3">Cluster-Based 4487 Cluster-Based</cell><cell>2</cell><cell>0.3582</cell><cell>0.8675</cell><cell>0.5070</cell><cell>0.7760</cell></row><row><cell>Embryologic</cell><cell cols="2">eQUNB11 Single Model</cell><cell cols="2">2228 Cluster-Based</cell><cell>1</cell><cell>0.1086</cell><cell>0.6381</cell><cell>0.1856</cell><cell>0.5563</cell></row><row><cell>Gene Expression</cell><cell cols="2">eQUNB19 Single Model</cell><cell>5155</cell><cell cols="3">Single Model 1.17 0.1132</cell><cell>0.4571</cell><cell>0.1815</cell><cell>0.4012</cell></row><row><cell></cell><cell>eQUT18</cell><cell cols="5">Cluster-Based 5155 Cluster-Based 0.10 0.0967</cell><cell>0.5238</cell><cell>0.1632</cell><cell>0.4473</cell></row><row><cell></cell><cell cols="4">gQUNB12 Single Model 13414 Single Model</cell><cell>1</cell><cell>0.1603</cell><cell>0.6602</cell><cell>0.2580</cell><cell>0.3459</cell></row><row><cell>GO</cell><cell cols="2">gQUNB15 Single Model</cell><cell cols="4">4872 Cluster-Based 0.55 0.2102</cell><cell>0.5676</cell><cell>0.3067</cell><cell>0.3763</cell></row><row><cell></cell><cell>gQUT22</cell><cell cols="3">Cluster-Based 11417 Single Model</cell><cell>4</cell><cell>0.1811</cell><cell>0.6158</cell><cell>0.2799</cell><cell>0.3628</cell></row><row><cell></cell><cell>tQUNB3</cell><cell>Single Model</cell><cell>3058</cell><cell>Single Model</cell><cell>1</cell><cell>0.0244</cell><cell>0.9000</cell><cell>0.0474</cell><cell>0.7439</cell></row><row><cell>Tumor</cell><cell>tQUT10</cell><cell cols="2">Cluster-Based 3058</cell><cell cols="3">Single Model 0.02 0.0132</cell><cell>1.0000</cell><cell>0.0260</cell><cell>0.6758</cell></row><row><cell></cell><cell>tQUT14</cell><cell cols="3">Cluster-Based 1500 Cluster-Based</cell><cell>1</cell><cell>0.3095</cell><cell>0.6500</cell><cell>0.4194</cell><cell>0.6437</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,154.20,273.34,303.65,7.85"><head>Table 3 :</head><label>3</label><figDesc>The performance of the single-model and of the cluster-based classification</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,104.58,127.54,407.59,584.32"><head>Table 4 :</head><label>4</label><figDesc>The effect of the cluster-based feature selection.</figDesc><table coords="7,104.58,127.54,407.59,135.12"><row><cell>Category</cell><cell>Classification Method</cell><cell>CB</cell><cell>TP</cell><cell>FP</cell><cell>FN</cell><cell>Precision</cell><cell>Recall</cell><cell>F-score</cell><cell>Normalized Utility</cell></row><row><cell>Allele</cell><cell>Single Model</cell><cell>2</cell><cell>160</cell><cell>100</cell><cell>172</cell><cell>0.6154</cell><cell>0.4819</cell><cell>0.5405</cell><cell>0.4642</cell></row><row><cell></cell><cell>Cluster-Based</cell><cell></cell><cell>288</cell><cell>516</cell><cell>44</cell><cell>0.3582</cell><cell>0.8675</cell><cell>0.5070</cell><cell>0.7760</cell></row><row><cell>Embryologic Gene Expression</cell><cell>Single Model Cluster-Based</cell><cell>2</cell><cell>35 84</cell><cell>71 1276</cell><cell>70 21</cell><cell>0.3302 0.0618</cell><cell>0.3333 0.8000</cell><cell>0.3318 0.1147</cell><cell>0.3228 0.6101</cell></row><row><cell>GO</cell><cell>Single Model</cell><cell>4</cell><cell>188</cell><cell>340</cell><cell>330</cell><cell>0.3561</cell><cell>0.3629</cell><cell>0.3595</cell><cell>0.3033</cell></row><row><cell></cell><cell>Cluster-Based</cell><cell></cell><cell>379</cell><cell>1782</cell><cell>139</cell><cell>0.1754</cell><cell>0.7317</cell><cell>0.2829</cell><cell>0.4189</cell></row><row><cell>Tumor</cell><cell>Single Model</cell><cell>1</cell><cell>6</cell><cell>4</cell><cell>14</cell><cell>0.6000</cell><cell>0.3000</cell><cell>0.4000</cell><cell>0.2991</cell></row><row><cell></cell><cell>Cluster-Based</cell><cell></cell><cell>13</cell><cell>29</cell><cell>7</cell><cell>0.3095</cell><cell>0.6500</cell><cell>0.4194</cell><cell>0.6437</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The work was partially supported by <rs type="funder">Queen's ARC</rs> award #<rs type="grantNumber">380-265</rs>, and <rs type="funder">NSERC</rs> Discovery Grant #<rs type="grantNumber">298292-04</rs>, awarded to HS, and <rs type="funder">NSERC</rs> summer student grants awarded to SB and AG.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uJGTJwX">
					<idno type="grant-number">380-265</idno>
				</org>
				<org type="funding" xml:id="_vKVV82A">
					<idno type="grant-number">298292-04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,90.00,528.88,432.03,7.85;8,90.00,539.20,48.08,7.85" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Olshen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<title level="m" coord="8,335.90,528.88,131.96,7.85">Classification and Regression Trees</title>
		<meeting><address><addrLine>Wadsworth, Belmont, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,552.58,431.98,7.85;8,90.00,562.90,387.96,7.85" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,196.32,552.58,325.66,7.85;8,90.00,562.90,57.83,7.85">Feature generation, feature selection, classifiers, and conceptual drift for biomedical document triage</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,156.72,562.90,71.76,7.85">Proc. of TREC 2004</title>
		<meeting>of TREC 2004<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,576.28,431.93,7.85;8,90.00,586.60,257.17,7.85" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,226.39,576.28,215.97,7.85">Estimating continuous distributions in Bayesian classifiers</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.22,576.28,69.71,7.85;8,90.00,586.60,219.26,7.85">Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Eleventh Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="338" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,599.98,278.30,7.85" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,161.54,599.98,116.81,7.85">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,287.52,599.98,30.37,7.85">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,613.30,432.00,7.85;8,90.00,623.68,15.75,7.85;8,90.00,637.00,432.04,7.85;8,90.00,647.38,232.76,7.85" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,317.25,613.30,117.14,7.85">Genes, Themes and Microarrays</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shatkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wilbur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boguski ; Shatkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wilbur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,444.96,613.30,39.57,7.85;8,227.62,637.00,294.42,7.85;8,90.00,647.38,162.29,7.85">Finding Themes in Medline Documents: Statistical Similarity Search</title>
		<imprint>
			<date type="published" when="2000">2000. 2000. 2000</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
	<note>IEEE Conference on Advances in Digital Libraries</note>
</biblStruct>

<biblStruct coords="8,90.00,660.70,431.95,7.85;8,90.00,671.08,95.11,7.85" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,215.35,660.70,268.03,7.85">Data Mining: Practical machine learning tools and techniques, 2nd Edition</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,684.40,431.98,7.85;8,90.00,694.78,290.14,7.85" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,207.34,684.40,276.05,7.85">Experimence of using SVM for the triage task in TREC2004 genomics track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,492.90,684.40,29.08,7.85;8,90.00,694.78,40.51,7.85">Proc. of TREC 2004</title>
		<meeting>of TREC 2004<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
