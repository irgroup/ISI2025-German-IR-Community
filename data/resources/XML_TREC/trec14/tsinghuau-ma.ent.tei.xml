<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.40,87.92,290.78,14.82;1,440.10,84.38,5.84,9.71">THUIR at TREC 2005: Enterprise Track 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.10,113.55,43.89,9.45"><forename type="first">Yupeng</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,209.06,113.55,28.41,9.45"><forename type="first">Wei</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.46,113.55,29.85,9.45"><forename type="first">Yize</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,280.55,113.55,41.21,9.45"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
							<email>liuyiqun03@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,328.65,113.55,44.68,9.45"><forename type="first">Min</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,380.84,113.55,56.34,9.45"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">State Key Lab of Intelligent Tech. &amp; Sys</orgName>
								<orgName type="department" key="dep2">CST Dept</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.40,87.92,290.78,14.82;1,440.10,84.38,5.84,9.71">THUIR at TREC 2005: Enterprise Track 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">607A778B4EE0AB0F66F6B7C883E84A16</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>IR group of Tsinghua University participated in the expert finding task of TREC2005 enterprise track this year. We developed a novel method which is called document reorganization to solve the problem of locating expert for certain query topics. This method collects and combines related information from different media formats to organize a document which describes an expert candidate. This method proves both effective and efficient for expert finding task. Our submitted run (THUENT0505) obtains the best performance in all participants with evaluation metric MAP. The reorganized documents are also significantly smaller in size than the original corpus.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Expert Finding is a new sub task in TREC Enterprise Track. It simulates a task that often appears in practical enterprise search applications. This Task is to find a person/group that satisfies a specific need in a multi-source database. Additionally, this person/group exists in a known list. For example, find someone in the list of employee names, who is familiar with Middle East businesses.</p><p>TREC 2005 Expert Finding Task is to help users find an expert in a certain topic of W3C organization. After user inputs a query of the topic, Expert Finding System will output a sorted name list according to persons' relevance to this query. The W3C corpus we use takes on a typical type of enterprise data, which is, not huge-scaled, with data of various kinds like Email, WEB Page and Wiki. The candidate list includes 1092 W3C experts' names. Every item of the list has an exclusive person-id, just like the name list of all employees in corporation.</p><p>A possible solution for this problem will be: Retrieve documents in the given corpus using query and then rank experts according to their appearances in result documents. This voting-based method is easy to carry out but may not fit for expert finding very much. First, top ranked documents retrieved with a certain query topic are likely to be documents which describe this topic in detail. These documents may not contain information about experts in this topic. For example, an article on an XML expert will be more useful for the query "XML" in expert finding instead of an article describing XML schema and related technologies; but the latter one is more likely to be given a higher retrieval status value using traditional IR technologies. Second, it is difficult for this method to deal with multi-source information. We are lack of reliable techniques to combine retrieval results from different types of documents <ref type="bibr" coords="1,178.36,700.99,12.13,9.88" target="#b0">[1]</ref> <ref type="bibr" coords="1,190.49,700.99,12.13,9.88" target="#b1">[2]</ref>.</p><p>In this paper we propose a new method to solve expert finding problem. The method is called "document reorganization" because it reorganizes description from all sources of information for each candidate expert. It is performed as follows:</p><p>(1) Mark up appearance of all candidates in the given corpus;</p><p>(2) Extract descriptions for candidates using different rules according to their appearances in the corpus and the document type; (3) Combine these descriptions and then get a combination of descriptions for each expert. Each newly-formed combination (also a "document") is corresponding to an entity. The key idea of this reorganization method is to assemble information. We cleanse data from different document types, and assemble information related to the candidate. This method reduces the complexity of search space and has a strong scalability for different document types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Candidate Identity Extraction and Tagging</head><p>It is important to mark up the candidate in different data sources according to the given name list. We must clarify some definitions as follows:</p><p>Candidate identity: a candidate may have one or more identities. An identity could be his email, nick, cell phone number and so on. If this identity appears in a document or somewhere, we can recognize the appearance as this candidate.</p><p>Candidate name-email relationship: a candidate may have different names and emails. While representing them, we usually use a name-email pair. This may be useful for identifying people because if we have pairs (A,B) and (B,C), we will know that (A,C) is also possible. We use this property to educe all identities of a candidate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Candidate Identity Extraction</head><p>Starting with the 1092 candidates' name-email relationships, we go through all the "from", "to", "cc" fields in the processed mail lists. Each field will contain one candidate name-email relationship. If the name and the email in the relationship are different identities of two people, then merge all the identities from the two people into a new set and make it a new candidate. With this method, we got an identity set which was made up of variants names of 1092 candidates given.</p><p>This process is sometimes difficult because of data quality problem in the corpus. For instance, some one may borrow others' Email address, or some one spell the wrong name, or some ones share the same abbreviates for their name. In order to solve these problems, several heuristics are used:</p><p>(1) Candidate identity with less than 3 letters is highly duplicated, and it is unreliable.</p><p>(2) Candidate name-email relationship with less than 3 appearances is likely to be a typo, and it is unreliable. (3) Some frequently-used names such as Tom or David have a larger opportunity to be a name in common, and it is unreliable. After that, we will get the candidate identities. The result will be all possible identities for the 1092 candidates in this corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Candidate Identity Tagging</head><p>First we build a DFA according to the Aho-Corasick by using all the candidate identities extracted. Then, we run the DFA on the document to process. On the positions where the DFA accepts, we do backtrack to find the start position of the accepted identity. At last we replace the identity with a marked identity such like &lt;candidate id="candidate-0001"&gt;dan brickley&lt;/candidate&gt;) for future use.</p><p>Elder tools such like regular expressions just can not work here because they are not optimized for matching a large set of identities in reasonable time. So we chose Aho-Corasick algorithm for this task.</p><p>Aho-Corasick algorithm <ref type="bibr" coords="3,218.49,273.78,12.90,9.88" target="#b2">[3]</ref> is an algorithm for matching a set of keywords in text. It is similar to the KMP algorithm, and run in O(m+n) time in worst case. Where n is the length of the text and m is the total length of all the keywords. The main principle of the algorithm is to build a DFA and run the DFA on the text to obtain the result. However, our task requires more than keyword matching, because both "John-smith" and "john smith" are the same as "john smith". So our algorithm must handle spaces carefully.</p><p>For the same reason, backtrack is required for the algorithm, because we do not know that where "john smith" ends, whether the end of "John-smith" or the end of "john smith". So we must do the backtrack to find the beginning of the identity.</p><p>At last, candidate identities may overlap each other. Our strategy is to accept the one ends latest but throw the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Document Reorganization</head><p>Reorganization of the description documents means reorganizing documents with information from different sources. We extract information that may be description among the candidate identity in documents and combine it to form one document. Because of the variety of data sources, the methods of information extraction are different from each other. At the same time, it is also necessary to find potential description by the characteristic of documents. In this experiment, data sources are the W3C corpus and its composition is as follows (according to <ref type="bibr" coords="3,90.00,596.22,11.70,9.88" target="#b3">[4]</ref>):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 Data Types in W3C corpus</head><p>We can see that there are mainly three types of documents in this corpus: Email, Web pages (Web, Wiki web and Misc) and text of codes. We processed Email and Web page in this task because little information on experts can be obtained from coding text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Email Processing</head><p>The purpose for this step is to get rid of redundant information and extract information on candidates in E-mails for future use.</p><p>We take all the pages from "lists-*" in w3c corpus, and perform a three-step process:</p><p>(1) Parse the document into a valid TREC Web format document.</p><p>(2) Take out the body field from the TREC Web format document, then pass it into several filters in order to extract certain fields such like the "from" field, "subject" field, and "date" field. <ref type="bibr" coords="4,111.00,289.38,12.84,9.88" target="#b2">(3)</ref> The body text of the email is extracted and all the HTML tags in it are stripped. The final result will be a combination of step 2 &amp; 3. The difficulties lie in the format of the mails. The mails are not stored according to the RFC. They are generated HTML files from the mail archives. The following points are important.</p><p>First, the encoding of the text varies. This might not be a serious problem when processing English documents. However, several candidates have non-English names. So if we cannot handle the encoding correctly, we may miss these candidates. Fortunately, all the characters in candidates' identities are in ISO-8859-1. So we can simply parse all the documents in ISO-8859-1.</p><p>In supplemental for the above point, HTML encodings also matters. "&amp;eacute;", for example, is an HTML entity for character "é". They should be the same for the program. So HTML decoding must be done before the next step.</p><p>Second, that's quite a complex problem to extract mail fields from the HTML page. The fields include mail's subject, date, from, to, cc, mail body, etc. Generated HTML pages store these fields in a variety of formats. They are similar in general, but various in details.</p><p>Our way of handling this problem is to pass the text through a set of filters. Each filter will handle only one case. And each filter may have some sub processors which just handle one or two fields in the filter's case. This way will make the problem easy to strike by using the case by case method.</p><p>At last, several trivial points must be cleared. We must mark up each mail's position in a thread, this is done by using the document tree ID file generated by Bob Allen (http://cio.nist.gov/esd/emaildir/lists/trec-ent/msg00067.html). And we should strip replies from mail bodies, I mean the lines started with "&gt;", in order to reduce redundant.</p><p>Additionally, we also pick Metadata and paragraphs in which candidate identity appears.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Web Page Processing</head><p>We extract information from documents in which candidate identities were marked. For each occurrence of the candidate in the page, we use the following sources to form a document as candidate's description.</p><p>(1) The title of the document.</p><p>(2) The head line 1, head line 2, bold character line nearest to the occurrence position;</p><p>(3) Window information: The contents around the occurrence position of the candidate name;</p><p>(4) Group information, specific treatment of some useful web page. We merged Web page information ,mail information ,in-link anchor text together as description document.</p><p>The difficulty lies in how to set range of the window. Too wide window may contain useless even wrong information, and on the other side, narrow window may lose information.</p><p>At first we tried to set the range to a default value; however, the result is coarse and not reliable. We tried several values over the training topics, and at last we retrieve 10 words ahead and 10 words after the position as window information.</p><p>Some Web pages in the corpus we found the phenomena that names always appear as groups. Some groups don't have description for individual while other groups have. So we found the groups information and retrieve the group information. In a W3C corpus, groups information frequently found and is great helpful. However, the accuracy is based on whether all the name entity is identified. If we ignore or forget to mark some name entity, the group may be parted, and the group information is lost and misleading.</p><p>We changed the data structure and greatly reduce the indexing amount. The group information improved the result to a high level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Information Extraction for Special Web Pages</head><p>Some special pages may contain more information than other pages. We do special treatments for them. The page we processed actually is http://www.w3.org/People/all. Structurally analysis is done to this page, and information about the people are all extracted, such like their positions and instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment Results</head><p>Table <ref type="table" coords="5,119.28,580.62,4.58,9.88" target="#tab_0">4</ref>.1 contains the result of comparative experiment. We use a voting-based method, which directly finds candidate identity from the first n documents returned, and then ranks candidate by the weight of returned documents. The best result is obtained when n is set to 100. Run1: This run makes use of all w3c web part information and inlink anchor text of these files. Text content are reconstructed and formed description files for each candidate person. Structure information inside web pages was also used to improve performance Run2: This run makes use of all w3c web part information and inlink anchor text of these files. Text content are reconstructed and formed description files for each candidate person. Structure information inside web pages was also used to improve performance. Words from important pages are emphasized in this run.</p><p>Run3: This run makes use of all w3c web part information and inlink anchor text of these files. Text content are reconstructed and formed description files for each candidate person. Structure information inside web pages was also used to improve performance. Words from important pages are emphasized in this run. Word pairs are also given a higher weight.</p><p>Run4: This run makes use of all w3c web part information and Email lists (the list part) together with inlink anchor text of these files. Text content are reconstructed and formed description files for each candidate person. Structure information inside web pages was also used to improve performance. Words from important pages are emphasized in this run.</p><p>Run5: This run makes use of all w3c web part information and Email lists (the list part) together with inlink anchor text of these files. Text content are reconstructed and formed description files for each candidate person. Structure information inside web pages was also used to improve performance. Words from important pages are emphasized in this run. Bi-gram retrieval was also applied.  <ref type="table" coords="6,296.16,710.70,4.58,9.88" target="#tab_0">4</ref>.1 that the document reorganization method gained much better performance than the voting-based method. The reorganization process can reduce unimportant information and combine useful description from different sources.</p><p>We also tried bi-gram retrieval in our experiments. Table <ref type="table" coords="6,374.80,757.50,4.58,9.88" target="#tab_0">4</ref>.4 and Figure <ref type="figure" coords="6,446.23,757.50,4.56,9.88">4</ref>.1 show the change of MAPs got by bi-gram retrieval on reorganized documents. Lamda is the weight of retrieval status value using bi-gram retrieval. The experiment results show that MAP will be 12.5% higher if we use bi-gram weighting and set Lamda to a proper value. It is different from retrieval experiments for traditional web search tasks such as web tracks in TREC2003 <ref type="bibr" coords="7,90.00,138.60,12.84,9.88" target="#b4">[5]</ref> and TREC2004 <ref type="bibr" coords="7,179.98,138.60,11.60,9.88" target="#b5">[6]</ref>, in which bi-gram weighting gives ranking little affection. It may be explained by the fact that the reorganized documents are much smaller than Web documents and bi-gram weighting can significantly improves retrieval precision for short documents.  Major conclusions of this paper can be concluded as follows:</p><p>(1) Document reorganization proves effective for expert finding task. It performs better than those traditional methods according to our experiment results. Our run in TREC2005 based on this method also gained the best performance in Expert Finding Task.</p><p>(2) Ranking reorganized documents by given different sources of context respective weights gets better performance than treating all sources the same. It accords our previous experiments in TREC web track <ref type="bibr" coords="7,241.69,714.54,12.81,9.88" target="#b4">[5]</ref> <ref type="bibr" coords="7,254.50,714.54,12.81,9.88" target="#b5">[6]</ref> and is a possible solution for multi-source retrieval result combination.</p><p>(3) Bi-gram retrieval method does well by increasing precision for expert search, because the size of reorganized documents is small and the query of common expert finding is professional and strongly detailed. (4) In the process of documents reorganization, lots of unimportant and redundancy information is thrown off. The scale of new document set is far smaller than the former corpus. This can be regarded as a kind of data cleansing and is useful for practical enterprise information management.</p><p>In the future, we will try to apply this method to item-finding tasks in specific fields such as software search, MP3 search and so on.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,168.30,314.28,258.63,9.88"><head>Figure 4 . 1</head><label>41</label><figDesc>Figure 4.1 Bi-gram retrieval on reorganized documents</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,194.82,643.14,205.61,122.44"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table coords="5,207.72,643.14,192.71,122.44"><row><cell></cell><cell>1 MAP of traditional search method</cell></row><row><cell>N</cell><cell>MAP</cell></row><row><cell>100</cell><cell>0.1694</cell></row><row><cell>200</cell><cell>0.1592</cell></row><row><cell>150</cell><cell>0.1643</cell></row><row><cell>120</cell><cell>0.1728</cell></row><row><cell>80</cell><cell>0.1671</cell></row><row><cell>50</cell><cell>0.1626</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,90.00,76.20,415.27,56.68"><head>Table 4 .</head><label>4</label><figDesc>2 contains information of description documents got by information extracting from all data sources. In the table, "Size" expresses the size of former document; "DesDocSize" expresses the size of description document. DesDocSize is about 4% of the original corpus size.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,151.02,138.72,288.55,109.48"><head>Table 4 .2 Information of description documents</head><label>4</label><figDesc></figDesc><table coords="6,151.02,155.34,288.55,92.86"><row><cell>SOURCE</cell><cell>Size</cell><cell>Docs</cell><cell>DesDoc</cell><cell>DesDocSize</cell></row><row><cell>WEB</cell><cell>1.043G</cell><cell>45975</cell><cell>872</cell><cell>43M</cell></row><row><cell>EMAIL</cell><cell>1.855G</cell><cell>198394</cell><cell>907</cell><cell>56M</cell></row><row><cell>PEOPLE</cell><cell>0.003G</cell><cell>1016</cell><cell>58</cell><cell>66K</cell></row><row><cell>Wiki</cell><cell>0.181G</cell><cell>19605</cell><cell>158</cell><cell>3.5M</cell></row><row><cell>Other</cell><cell>0.047</cell><cell>3538</cell><cell>558</cell><cell>1.7M</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,90.00,254.82,415.27,25.48"><head>Table 4 .</head><label>4</label><figDesc>3 contains results of searching in description documents. The five runs submitted are retrieved by our TMiner System, including:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,108.00,598.15,357.37,122.43"><head>Table 4 .3 Retrieval experiments based on document reorganization</head><label>4</label><figDesc></figDesc><table coords="6,108.00,614.23,331.37,106.35"><row><cell>Runs</cell><cell>MAP</cell><cell>Bpref</cell><cell>P@10</cell></row><row><cell>1</cell><cell>0.230</cell><cell>0.498</cell><cell>0.362</cell></row><row><cell>2</cell><cell>0.245</cell><cell>0.483</cell><cell>0.414</cell></row><row><cell>3</cell><cell>0.275</cell><cell>0.488</cell><cell>0.452</cell></row><row><cell>4</cell><cell>0.241</cell><cell>0.298</cell><cell>0.412</cell></row><row><cell>5</cell><cell>0.275</cell><cell>0.488</cell><cell>0.452</cell></row><row><cell cols="2">We can find from Table 4.3 and Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,131.22,185.52,332.92,106.66"><head>Table 4 .4 Bi-gram retrieval on reorganized documents</head><label>4</label><figDesc></figDesc><table coords="7,131.22,201.60,332.92,90.58"><row><cell>Lamda</cell><cell>MAP</cell><cell>Lamda</cell><cell>MAP</cell></row><row><cell>0</cell><cell>0.245</cell><cell>25</cell><cell>0.2683</cell></row><row><cell>5</cell><cell>0.2597</cell><cell>30</cell><cell>0.2702</cell></row><row><cell>10</cell><cell>0.2638</cell><cell>35</cell><cell>0.2714</cell></row><row><cell>15</cell><cell>0.2674</cell><cell>40</cell><cell>0.272</cell></row><row><cell>20</cell><cell>0.2673</cell><cell>45</cell><cell>0.2734</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,97.50,740.85,345.74,8.10;1,90.00,751.23,407.36,8.10;1,90.00,761.55,171.38,8.10"><p>This work is supported by the Chinese National Key Foundation Research &amp; Development Plan (2004CB318108), Natural Science Foundation (60223004, 60321002, 60303005, 60503064) and the Key Project of Chinese Ministry of Education (No. 104236)</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,111.00,258.18,352.47,9.88;8,90.00,273.90,208.61,9.88" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,249.90,258.18,213.57,9.88;8,90.00,273.90,46.34,9.88">Towards the next generation of enterprise search technology</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Ciccolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,143.69,273.90,93.71,9.88">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,289.38,389.13,9.88;8,90.00,304.98,404.62,9.88;8,90.00,320.58,38.17,9.88" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,159.57,289.38,135.50,9.88">Challenges in enterprise search</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,313.56,289.38,186.57,9.88;8,90.00,304.98,95.58,9.88">Proceedings of the fifteenth conference on Australasian database</title>
		<meeting>the fifteenth conference on Australasian database<address><addrLine>New Zealand</addrLine></address></meeting>
		<imprint>
			<publisher>Dunedin</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,336.18,379.82,9.88;8,90.00,351.78,227.08,9.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,275.94,336.18,214.88,9.88;8,90.00,351.78,26.42,9.88">Efficient string matching: an aid to bibliographic search</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Corasick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,123.60,351.78,70.85,9.88">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="333" to="340" />
			<date type="published" when="1975-06">1975. Jun. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,367.38,316.31,9.88" xml:id="b3">
	<monogr>
		<ptr target="http://www.ins.cwi.nl/projects/trec-ent/" />
		<title level="m" coord="8,111.00,367.38,137.51,9.88">TREC enterprise track web site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,382.98,380.18,9.88;8,90.00,398.58,407.15,9.88;8,90.00,414.18,116.41,9.88" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
		<title level="m" coord="8,388.36,382.98,102.82,9.88;8,90.00,398.58,109.60,9.88;8,219.29,398.58,277.86,9.88;8,90.00,414.18,50.70,9.88">NIST Special Publication 500-255: The Twelfth Text REtrieval Conference</title>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>THUIR at TREC 2003: Novelty, Robust and Web</note>
</biblStruct>

<biblStruct coords="8,111.00,429.78,382.06,9.88;8,90.00,445.38,378.57,9.88;8,90.00,460.98,395.75,9.88;8,90.00,476.58,28.47,9.88" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,345.79,429.78,147.27,9.88;8,90.00,445.38,378.57,9.88;8,90.00,460.98,104.93,9.88">Abstract Fields&quot; of Web Pages and Query Specific Retrieval--THUIR at TREC 2004 Web Track, NIST Special Publication: SP 500-261</title>
		<author>
			<persName coords=""><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Canhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,202.57,460.98,248.65,9.88">Proceedings of the Thirteenth Text Retrieval Conference</title>
		<meeting>the Thirteenth Text Retrieval Conference</meeting>
		<imprint/>
	</monogr>
	<note>Finding. TREC 2004</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
