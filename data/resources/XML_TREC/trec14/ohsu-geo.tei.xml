<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,81.60,45.02,449.84,14.82;1,172.26,63.44,268.47,14.82">A Comparison of Techniques for Classification and Ad Hoc Retrieval of Biomedical Documents</title>
				<funder ref="#_KkEw93g">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,206.10,89.51,62.72,11.72"><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics and Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.26,89.51,36.30,11.72"><forename type="first">J</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics and Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.57,89.51,60.22,11.72"><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics and Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health &amp; Science University</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,81.60,45.02,449.84,14.82;1,172.26,63.44,268.47,14.82">A Comparison of Techniques for Classification and Ad Hoc Retrieval of Biomedical Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4DA073E4FD4573FFA8FE9E4A0299BD02</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Oregon Health &amp; Science University participated in both the classification and ad hoc retrieval tasks of the TREC 2005 Genomics Track. To better understand the text classification techniques that lead to improved performance, we applied a set of general purpose biomedical document classification systems to the four triage tasks, varying one system feature or text processing technique at a time. We found that our best and most consistent system consisted of a voting perceptron classifier, chi-square feature selection on full text articles, binary feature weighting, stemming and stopping, and prefiltering based on the MeSH term Mice. This system approached, but did not surpass, the performance of the best TREC entry for each of the four tasks. Full text provided a substantial benefit over only title plus abstract. Other common techniques such as inverse-document frequency feature weighting, and cosine normalization were ineffective. For the ad hoc retrieval task, we used Zettair search engine. Both of our submissions used Okapi measure with the parameters optimized using the sample topics that were provided. Two different query sets were used in our runs; one with all the words and the other with only the keywords from the topic file. Queries with only keywords consistently outperformed queries with all words from the topic file. Optimization of the Okapi parameters improved our performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The 2005 Text Retrieval Conference (TREC) Genomics Track was divided into two main tasks: categorization, and ad-hoc retrieval. The categorization task included four subtasks that correspond to the document triage that the curators at the Mouse Genome Institute (MGI) perform to annotate genes for alleles of mutant phenotypes, embryologic expression, GO terms, and tumor biology. The ad-hoc retrieval task was composed of 50 topics in five generic topic templates (GTTs). Each GTT had ten instances that represented biologists' information needs. Oregon Health &amp; Science University (OHSU) participated in both categorization and the adhoc retrieval tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CATEGORIZATION TASK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Background</head><p>Effective biomedical document classification can be an aid to researchers and curators. However, to provide benefit, appropriate tasks must be identified, and systems with good performance must be created. To create the most effective systems, it is important to understand what algorithmic and system features improve results and which do not. To accomplish this, good training and test collections must be available in order to build and validate the performance of effective document categorization systems.</p><p>The 2005 TREC Genomics Track had four different biomedical document classification tasks using the same document training and test corpora. The four subtasks corresponded to the four sets of document triage that the curators at the Mouse Genome Institute (MGI) perform to annotate genes for alleles of mutant phenotypes, embryologic expression, GO terms, and tumor biology. The gold standard for each of the four tasks was created using the actual annotation results of curators at the MGI. This situation of having multiple tasks using the same document set and gold standards created from the same source provided an unprecedented opportunity to study the effectiveness of common text techniques when applied to biomedical text classification.</p><p>Shared-task conferences such as TREC typically include a variety of techniques used by different submitting groups Because system implementations and features vary so much between each of the submitting groups, the contributions of individual processing features cannot be easily extracted from the results.</p><p>Our group decided to create a set of baseline systems, and then change one processing feature at a time in order to compare the contributions of the individual processing features. Having four subtasks allowed us to compare processing features across tasks, enabling us to draw some general conclusions about the effectives of various techniques commonly used in biomedical text classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">System and methods</head><p>We chose our Voting Perceptron (VP) system <ref type="bibr" coords="1,526.26,657.90,31.72,9.02;1,324.00,669.90,87.82,9.02" target="#b4">(Freund and Schapire, 1999)</ref> from last year as our classifier algorithm <ref type="bibr" coords="1,365.76,681.90,79.88,9.02" target="#b1">(Cohen et al., 2004)</ref>. We have had good results with this system on several tasks in the past, and it allows Since this measure was highly asymmetric in terms of the weights for true and false positives, tuning the classifier for this was essential to obtaining good performance. As described last year, some classification systems, such as SVMLight, do not provide adequate means to address highly asymmetric utility functions.</p><p>During our initial experiments using cross validation on the training set, we found that setting the false negative learning rate (FNLR) of the VP classifier to be equal to the ratio of the number of positives to the number of negatives in the training set gave the best performance.</p><p>We used this computed learning rate for all our experiments using the VP classifier. We also tried using a publicly available rules-based classifier, Slipper <ref type="bibr" coords="2,258.76,472.74,29.40,9.02;2,54.00,484.74,72.30,9.02" target="#b3">(Cohen and Singer, 1999)</ref>, and a single "best" feature classifier.</p><p>For the latter, we gave the positive examples a weight equal to the same ratio of the number of positives to the number of negatives used for the VP classifier.</p><p>While some researchers use a full "bag of words" approach and submit all document tokens into the classifier system, we used a chi-squared based method to select features that were statistically significantly different between the positive and negative documents for each task. This significantly reduces the feature space, from tens or hundreds of thousands of features, to about 5000 features, reducing the noise introduced into the classifier, possibly improving performance when the document collection is of limited size. Chi-square feature selection also reduces classifier processing time substantially.</p><p>For the VP and Slipper classifiers studied here, the features analyzed for chi-square collection included the document text, MeSH terms, and MGI gene identifiers found in the abstract using a named entity recognition and normalization (NER+N) system we have previously described <ref type="bibr" coords="2,365.69,108.77,56.75,9.02" target="#b2">(Cohen, 2005)</ref>. A 2x2 table is then constructed (according to Table <ref type="table" coords="2,405.96,120.77,5.00,9.02" target="#tab_1">2</ref> for each feature), and the p-value is computed using chi-square. Features with p values less than our chosen alpha of 0.05 are then used as input to the classification algorithm. As the "best" single feature classifier, we simply choose the MeSH Mice tag. This was shown to have a dominant effect on the GO classification task last year, and we wanted to assess how it performed on the other tasks as well.</p><p>In particular, we were especially interested in determining the value of using full text, and the best combination of algorithmic features to use with a full text representation.</p><p>For each of the four classifier tasks, we varied several algorithmic features, one at a time. Table <ref type="table" coords="2,506.36,276.77,5.00,9.02">3</ref> shows the different algorithmic features that we varied, and how we compared them to each other. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results</head><p>The results of applying the three classifiers -VP, Slipper, and single feature -to the baseline feature set of title, abstract, MeSH terms, and MGI identifiers with Chisquare feature selection are shown in Table <ref type="table" coords="3,234.12,381.48,3.76,9.02" target="#tab_3">4</ref>. This table also includes the best results submitted to TREC for each task for comparison. Notably, the best normalized utility score for the allele, expression, and tumor biology task is much better than any of our baseline results. This is not unexpected, since our results do not include using the full article text. However, the performance differences on the GO task between the MeSH term Mice, the VP classifier, and the best submission are small.</p><p>Furthermore, the performance of the VP classifier is consistently good, whereas the performance of Slipper is poorer on the allele and GO tasks as compared to the VP classifier. For the rest of the experiments presented here, the VP classifier will be used, allowing feature-by-feature analysis of the effect of individual classifier system features.</p><p>In Table <ref type="table" coords="3,91.98,597.48,3.77,9.02" target="#tab_6">5</ref>, the baseline system is the VP classifier, with FNLR weighting as described above, and chi-square feature selection. Each entry in the table describes the other system features included in that run. The scores for the best TREC 2005 submission, as determined by utility, as well as the one feature classifier based on the MeSH term Mice, are included for comparison.</p><p>For the allele, expression, and tumor tasks, the highest scoring combination we investigated was consistently the baseline binary feature system plus full text, stemming and stopping, and the MeSH Mice term pre-filter. These runs are shown in bold. For the GO task, the baseline system using just the title and abstract, along with stemming and topping, and the Mice pre-filter, had the best performance.</p><p>The inclusion of full text provided a notable increase in performance for three of the four tasks. However, additional system features were required to bring out the full value of full text. The following three figures compare the performance of full text verses title and abstract using various system features on the four tasks.</p><p>The height of the bar above the zero line represents the percentage improvement of full text over just title and abstract; bars below the zero line show that title and abstract outperforms full text.</p><p>In Figure <ref type="figure" coords="3,369.22,288.77,3.77,9.02">1</ref>, performance of full text versus title and abstract using no additional features is compared. While the expression task improved about 23%, the allele task was essentially unchanged, and both tumor and especially GO performed much worse with this system and full text.</p><p>Figure <ref type="figure" coords="3,352.95,348.77,5.00,9.02">2</ref> shows the results of adding Porter stemming and stop-list processing to the system. The allele task was unchanged, but the expression and tumor tasks obtained modest improvements, and the performance decrease on the GO task was reduced to one-tenth what it was in Figure <ref type="figure" coords="3,353.66,408.77,3.74,9.02">1</ref>. Figure <ref type="figure" coords="3,394.26,408.77,5.00,9.02">3</ref> added the MeSH Mice prefilter to the system. The performance improvements using full text over title and abstract were larger, and the penalty on the GO task was reduced to about 3%.</p><p>The preceding figures compared the effect on utility of stemming and stopping and the pre-filter on full text verses title and abstract. Figure <ref type="figure" coords="3,453.80,492.77,5.00,9.02">4</ref> compares all systems at once. This figure clearly shows that the combination of full text with stemming and stopping, and the Mice prefilter practically equals or outperforms any title plus abstract based system or full text system without this combination of features.</p><p>For none of the four tasks did the inclusion of IDF, TF*IDF, or cosine normalization provide any benefit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Discussion</head><p>As demonstrated in our figures, especially Figure <ref type="figure" coords="3,550.55,633.90,3.76,9.02">4</ref>, stemming, stopping, and the pre-filter were effective on title plus abstract but were more effective on full text. The combination of these features resulted in a robust system that performed well on each of the four tasks, and outperformed using these features just on the title and abstract. The VP classification algorithm proved to be the most consistent and dependable for these biomedical document classification tasks.</p><p>We call the system consisting of full text, stemming and stopping, Mice pre-filter, chi-square binary feature selection and VP classification our standard system. Compared to the submitted runs the standard system would have placed 13 th out of 49 for allele, 15 th out of 47 for expression, 6 th out of 48 for GO, and 18 th out of 52 for tumor. While the system does not score above the best systems submitted for each subtask, it does perform consistently well for a generalized approach that has had no specific tuning or customization for the individual tasks. The standard system scored within 0.09 of the top scoring submitted system for all tasks: within 0.04 of the best submitted system for allele, 0.05 for expression, 0.02 for GO, and 0.09 for tumor.</p><p>Previous investigators have noted the increased amount of information available in full text verses just the title and abstract <ref type="bibr" coords="4,87.92,312.78,83.80,9.02" target="#b6">(Kostoff et al., 2004)</ref>. Therefore, it is perhaps not surprising that the inclusion of full text can improve performance over title plus abstract. However we are unaware of any prior research in classifying biomedical text that demonstrates this with comparative experiments such as we have done here. Furthermore, simply including full text is not enough; stemming and stopping are required to fully realize the potential. Again this conclusion was expected but has not previously been simultaneously demonstrated on a variety of biomedical document classification tasks as we have done here. The lack of prior studies demonstrating the benefit of full text may be due to the fact that full biomedical text has only recently been made available to researchers, and there are few full text training and test collections on which to do controlled experiments.</p><p>Rather unexpected was the finding that the various term weighting schemes, such as TF*IDF and cosine normalization, did not provide any benefit and in some cases reduced performance. While there are many other potential biomedical document classification tasks, the four tasks studied here consistently lead one to conclude that binary feature weighting is the best general purpose method.</p><p>Performance on the allele, expression, and tumor tasks was high enough to appear useful to the MGI curators.</p><p>The standard system achieved utility measures in the 0.80 and above range for these three tasks. For the tumor tasks, some TREC 2005 submissions were able better these results, achieving utility scores above 0.90. Certainly these three tasks demonstrate that text classification can be useful for biomedical document curation and annotation. Further work is needed to determine the best way to integrate classification systems into the workflow of the MGI curators for these three tasks.</p><p>From these results it seems clear that the GO task is somewhat different from the other tasks. The best utility scores that either we or the other TREC 2005 participants were able to achieve were in the 0.50-0.60 range, which were much lower than for the other three tasks. While the data presented here do not shed light on the reasons for that difference, it seems clear that full text provided a large benefit for the three other tasks and no benefit for the GO task. Furthermore, the standard system applied to title-abstract instead of full text performed essentially identically to the top scoring system. Both of these scores are about 0.03 better than simply using the MeSH term Mice, so the classifier systems are finding some additional useful classification features, but their effect is small.</p><p>One interesting observation is the u r factor for the best performing task, tumor biology at 231, was the highest among the tasks, and lowest for the worst performing task, GO, at 11. While a high u r leads to an increasing preference for high recall over precision, a u r of 11 is still substantial compared to typical, more balanced classification tasks where the goal is often to optimize Fmeasure. Furthermore, the u r for the allele task, at 17 was only a little higher, but the best TREC submission scores were in the high 0.80-0.90 range, close but not quite as good as for the tumor task. Further investigation is needed to understand why the GO task appears more difficult than the other three.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">AD-HOC RETRIEVAL TASK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background</head><p>Searching MEDLINE to answer questions encountered in biomedical research is increasingly important. The TREC Genomics Track ad hoc retrieval task allows investigation of a variety of techniques that can improve the performance of biomedical document information retrieval. This specific domain differs from many others in having a complex terminology and nomenclature system. Previously, both generic and domain-specific techniques have been applied to improve performance with variable success <ref type="bibr" coords="8,141.42,210.00,76.34,9.02" target="#b5">(Hersh et al., 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System and methods</head><p>We did not use any domain-specific approaches but instead focused on two basic general IR techniques: Okapi measure parameters optimization and common stop-word exclusion in our runs. We used Zettair 0.6.1 <ref type="bibr" coords="8,54.00,288.60,103.44,9.02" target="#b0">(Billerbeck et al., 2004)</ref> out of the box as our search engine and the ten sample topics as training dataset.</p><p>Indexing of the ten-year MEDLINE subset was done by first processing the documents to retain the fields we deemed relevant heuristically. These fields included the PubMed identifier (PMID), title, abstract, and MeSH headings. These were then indexed using, Zettair.</p><p>We used the zet_trec application to generate our automated queries. Our basic run, OHSUall, included all words in the narrative version of the topic file. The other run, OHSUkey, used only the words in the tables of the tabular version, excluding common words such as of, in, and, the, gene, etc.</p><p>Both of our runs used Okapi metric implemented in Zettair. The ranking function was <ref type="bibr" coords="8,210.21,484.08,77.77,9.02;8,54.00,495.60,21.82,9.02" target="#b0">(Billerbeck et al., 2004)</ref>:</p><p>where terms t appear in query q; N is the number of documents in the collection; term t occurs in ft documents and in a particular document fd,t times; K is k1((1b)+b*Ld/AL); Ld is the length of document d measured in bytes, and AL is the average document length over the collection. The default value of constants k1 and b were set to 1.2 and 0.75 respectively. These two parameters were adjusted using the sample topics provided to optimize the system performance, as measured by average Mean Average Precision (MAP) and mean precision at 10 documents (p10).</p><p>After the results of the official runs were released, we reran the queries with the default setting of b and k 1 , in order to verify the effect on the system performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>As shown in Figure <ref type="figure" coords="9,151.04,87.96,3.76,9.02" target="#fig_2">5</ref>, our training runs with only keywords consistently outperformed runs with all words from the topics. The average difference in MAP was about 0.10. Furthermore, when holding b constant at its default value, MAP and p10 reached a maximum at k 1 =0.2. On the other hand, holding k 1 at 0.2 while changing b provided little improvement in MAP and p10. Therefore, in both of our final runs, k1 was set to 0.2.</p><p>Table <ref type="table" coords="9,79.40,191.46,5.00,9.02" target="#tab_7">6</ref> shows the overall performance on the test data for our official submissions and later baseline default parameter runs. Queries using keywords still outperformed all-word queries, but the gap was narrower when we used the default settings for b and k 1 . In runs with keywords only, the official submission had higher MAP than run with default k 1 and b values, but the default setting faired better if we used all the words in the topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discussion</head><p>In this year's ad hoc retrieval task, we used the simple and fast Zettair search engine off the shelf, automatically generated queries from topic descriptions, and manipulated Okapi metric parameters to optimize our performance. Our best system, OHSUkey, was among the median performers. Our runs with keywords indicated that simple exclusion of common words can be very helpful. The experiments with adjusting Okapi metric parameters were inconclusive. The performance improvement in keyword searches due to lowering k 1 agreed with the intuition that high term frequency is not as important as having all the key terms in the article. On the other hand, if we used queries with the common words, higher term frequency, especially of the keywords, should have led to higher ranking of documents containing those words. The difference between training and test data may cause the adjusted parameters not as optimized in test as in training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSIONS</head><p>The TREC 2005 Genomics Track enhanced our understanding of biomedical document classification. Full text is essential for high performance classification, but stemming and stopping must be applied to the text before features are extracted. These techniques are also effective on just the title plus abstract, but do not result in the same level of performance. Binary feature weighting is adequate, as the various term weighting schemes such as IDF, TF*IDF, and cosine normalization actually decreased performance. Domain specific filtering, such as the MeSH Mice term pre-filter used here, can also increase performance. Our standard system consisting of a voting perceptron classifier, chi-square feature selection on full text articles, binary feature weighting, stemming and stopping, and pre-filtering based on the MeSH term Mice, approached, but did not surpass, the performance of the best track entry for each of the four tasks. Performance on three of the four tasks, allele, expression, and tumor biology, was high, and likely good enough to provide real-world benefit to MGI's triage process.</p><p>In the ad hoc retrieval task, we experimented with adjustment of Okapi metric parameters and contrasting keyword and plain text search. We found that simple elimination of common words helped and, in keyword search, that lowering the weight of term frequency improved performance a modest amount.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,54.00,112.71,246.86,8.10"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Figure 1. Performance comparison of Title+Abstract verses full text</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,54.00,100.71,463.92,8.10"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Figure 3. Performance comparison of Title+Abstract verses full text using stemming and stop list and MeSH term Mice prefilter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,324.00,72.69,234.05,8.95;8,324.00,83.67,52.82,8.10"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Adjusting k 1 and b of the Okapi metric to optimize MAP and p10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,54.00,216.55,206.69,72.64"><head>Table 1 .</head><label>1</label><figDesc>Ur for each of the four tasks</figDesc><table coords="2,54.00,240.01,206.69,49.18"><row><cell>Task</cell><cell>Ur</cell></row><row><cell>Alleles of Mutant Phenotypes</cell><cell>17</cell></row><row><cell>Embryologic Expression</cell><cell>64</cell></row><row><cell>GO Annotation</cell><cell>11</cell></row><row><cell>Tumor Biology</cell><cell>231</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,324.00,324.55,233.26,391.42"><head>Table 2 . 2x2 arrangement for testing feature significance Table 3. Algorithmic features studied Group Feature Description</head><label>2</label><figDesc></figDesc><table coords="2,324.00,525.31,233.26,190.66"><row><cell>Text</cell><cell>Title and Abstract</cell><cell>Title and abstract from Medline</cell></row><row><cell></cell><cell></cell><cell>record.</cell></row><row><cell></cell><cell>Full Text</cell><cell>Full text from SGML file</cell></row><row><cell></cell><cell></cell><cell>including title, abstract, body,</cell></row><row><cell></cell><cell></cell><cell>and captions.</cell></row><row><cell>Preprocessing</cell><cell>Stem &amp; Stop</cell><cell>Porter Stemming and stop word</cell></row><row><cell></cell><cell></cell><cell>list of 300 most common</cell></row><row><cell></cell><cell></cell><cell>English words.</cell></row><row><cell></cell><cell>Mice Prefilter</cell><cell>Only train on documents with</cell></row><row><cell></cell><cell></cell><cell>MeSH Mice tag, classify others</cell></row><row><cell></cell><cell></cell><cell>as negative.</cell></row><row><cell>Weighting</cell><cell>Binary</cell><cell>All features are binary, 1 or 0.</cell></row><row><cell></cell><cell>IDF</cell><cell>Use inverse document</cell></row><row><cell></cell><cell></cell><cell>frequency as feature weight.</cell></row><row><cell></cell><cell>TF*IDF</cell><cell>Use standard term frequency</cell></row><row><cell></cell><cell></cell><cell>times IDF computation as</cell></row><row><cell></cell><cell></cell><cell>feature weight.</cell></row><row><cell></cell><cell>TF*IDF, Cosine</cell><cell>TF*IDF with cosine</cell></row><row><cell></cell><cell></cell><cell>normalization.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="2,351.18,352.63,205.61,115.66"><head>Feature is the one under test? Yes No Yes</head><label></label><figDesc></figDesc><table coords="2,351.18,374.11,205.61,94.18"><row><cell>Training document is triage positive?</cell><cell>Number of times feature seen in positive documents</cell><cell>Number of times other features seen in positive documents</cell></row><row><cell></cell><cell>Number of times</cell><cell>Number of times</cell></row><row><cell></cell><cell>feature seen in</cell><cell>other features</cell></row><row><cell>No</cell><cell>negative</cell><cell>seen in</cell></row><row><cell></cell><cell>documents</cell><cell>negative</cell></row><row><cell></cell><cell></cell><cell>documents</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,54.00,98.35,225.48,208.66"><head>Table 4 .</head><label>4</label><figDesc>Three classifiers with baseline features and best TREC 2005 submission</figDesc><table coords="3,54.00,131.83,225.48,175.18"><row><cell>Task</cell><cell>Classifier</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>Un</cell></row><row><cell></cell><cell>Mice</cell><cell>0.1315</cell><cell>0.9880</cell><cell>0.2321</cell><cell>0.6042</cell></row><row><cell>Allele</cell><cell>Slipper</cell><cell>0.3448</cell><cell>0.8765</cell><cell>0.4949</cell><cell>0.7785</cell></row><row><cell></cell><cell>VP</cell><cell>0.3556</cell><cell>0.8976</cell><cell>0.5094</cell><cell>0.8019</cell></row><row><cell></cell><cell>Best</cell><cell>0.4669</cell><cell>0.9337</cell><cell>0.6225</cell><cell>0.8710</cell></row><row><cell></cell><cell>Mice</cell><cell>0.0405</cell><cell>0.9619</cell><cell>0.0777</cell><cell>0.6058</cell></row><row><cell>Expression</cell><cell>Slipper</cell><cell>0.0365</cell><cell>0.9905</cell><cell>0.0705</cell><cell>0.5824</cell></row><row><cell></cell><cell>VP</cell><cell>0.0693</cell><cell>0.7429</cell><cell>0.1267</cell><cell>0.5869</cell></row><row><cell></cell><cell>Best</cell><cell>0.1899</cell><cell>0.9333</cell><cell>0.3156</cell><cell>0.8711</cell></row><row><cell></cell><cell>Mice</cell><cell>0.1889</cell><cell>0.9093</cell><cell>0.3127</cell><cell>0.5542</cell></row><row><cell>GO</cell><cell>Slipper</cell><cell>0.2536</cell><cell>0.6429</cell><cell>0.3637</cell><cell>0.4709</cell></row><row><cell></cell><cell>VP</cell><cell>0.2308</cell><cell>0.7819</cell><cell>0.3564</cell><cell>0.5449</cell></row><row><cell></cell><cell>Best</cell><cell>0.2122</cell><cell>0.8861</cell><cell>0.3424</cell><cell>0.5870</cell></row><row><cell></cell><cell>Mice</cell><cell>0.0080</cell><cell>1.0000</cell><cell>0.0159</cell><cell>0.4645</cell></row><row><cell>Tumor</cell><cell>Slipper</cell><cell>0.0254</cell><cell>0.9000</cell><cell>0.0493</cell><cell>0.7502</cell></row><row><cell></cell><cell>VP</cell><cell>0.0237</cell><cell>0.9000</cell><cell>0.0462</cell><cell>0.7394</cell></row><row><cell></cell><cell>Best</cell><cell>0.0709</cell><cell>1.0000</cell><cell>0.1325</cell><cell>0.9433</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,135.42,178.66,301.21,488.10"><head>Full Text better, Green = Title+Abstract better Percentage Difference Title+Abstract Vs. Full Text with Stem &amp; Stop</head><label></label><figDesc></figDesc><table coords="5,135.42,178.66,301.21,488.10"><row><cell></cell><cell cols="4">Title+Abstract Vs. Full Text</cell></row><row><cell>40.00%</cell><cell></cell><cell></cell><cell>23.30%</cell><cell></cell></row><row><cell>20.00%</cell><cell>0.88%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-20.00%</cell><cell>Allele</cell><cell></cell><cell>Expression</cell><cell>GO</cell><cell>Tumor</cell></row><row><cell>-40.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-60.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-54.85%</cell></row><row><cell>-80.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-100.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-120.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-140.00%</cell><cell></cell><cell></cell><cell></cell><cell>-133.46%</cell></row><row><cell>-160.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.00% 4.00% 6.00% 8.00%</cell><cell cols="2">Task: Blue = 0.11%</cell><cell>5.29%</cell><cell></cell><cell>3.54%</cell></row><row><cell>0.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-2.00%</cell><cell>Allele</cell><cell cols="2">Expression</cell><cell>GO</cell><cell>Tumor</cell></row><row><cell>-4.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-6.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-8.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-10.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-12.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-14.00%</cell><cell></cell><cell></cell><cell></cell><cell>-12.43%</cell></row><row><cell></cell><cell>Task: Blue =</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,122.99,538.74,303.09,128.01"><head>Full Text better, Green = Title+Abstract better Percentage Difference</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,22.98,72.55,550.11,645.16"><head>Table 5 .</head><label>5</label><figDesc>Classifier system feature comparision</figDesc><table coords="7,22.98,111.31,171.86,7.18"><row><cell>Task</cell><cell>System Features</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,324.00,624.21,207.55,70.52"><head>Table 6 .</head><label>6</label><figDesc>Overall performance on 2005 test data</figDesc><table coords="8,324.00,635.59,207.55,59.14"><row><cell>Run</cell><cell>Average</cell><cell>Precision @ 10</cell></row><row><cell></cell><cell>Precision</cell><cell>documents</cell></row><row><cell>OHSUall_submission</cell><cell>0.183</cell><cell>0.3286</cell></row><row><cell>OHSUkey_submission</cell><cell>0.2233</cell><cell>0.3735</cell></row><row><cell>OHSUall_default</cell><cell>0.1981</cell><cell>0.3653</cell></row><row><cell>OHSUkey_default</cell><cell>0.2117</cell><cell>0.3755</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work was supported in part by Grant <rs type="grantNumber">ITR-0325160</rs> from the <rs type="funder">National Science Foundation</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KkEw93g">
					<idno type="grant-number">ITR-0325160</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,324.00,296.07,226.18,8.10;9,333.00,308.07,186.71,8.10;9,333.00,320.07,94.23,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,487.47,296.07,62.71,8.10;9,333.00,308.07,50.25,8.10">RMIT University at TREC 2004</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Billerbeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cannane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,399.30,308.07,120.41,8.10;9,333.00,320.07,71.75,8.10">Proceedings of the Text Retrieval Conference (TREC)</title>
		<meeting>the Text Retrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,324.00,332.07,210.07,8.10;9,333.00,344.07,188.88,8.10;9,333.00,356.07,184.16,8.10;9,333.00,368.07,216.92,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,333.00,344.07,188.88,8.10;9,333.00,356.07,171.20,8.10">Feature generation, feature selection, classifiers, and conceptual drift for biomedical document triage</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">T</forename><surname>Bhupatiraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,333.00,368.07,194.47,8.10">Proceedings of the Text Retrieval Conference (TREC)</title>
		<meeting>the Text Retrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,324.00,380.07,197.25,8.10;9,333.00,392.07,214.48,8.10;9,333.00,404.07,209.04,8.10;9,333.00,416.07,176.56,8.10;9,333.00,428.07,91.47,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,401.77,380.07,119.47,8.10;9,333.00,392.07,201.32,8.10">Unsupervised gene/protein entity normalization using automatically extracted dictionaries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,333.00,404.07,209.04,8.10;9,333.00,416.07,176.56,8.10;9,333.00,428.07,87.17,8.10">Linking Biological Literature, Ontologies and Databases: Mining Biological Semantics, Proceedings of the BioLINK2005 Workshop</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,324.00,440.07,205.74,8.10;9,333.00,452.07,191.00,8.10;9,333.00,464.07,193.08,8.10;9,333.00,476.07,72.44,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,458.46,440.07,71.28,8.10;9,333.00,452.07,79.50,8.10">A Simple, Fast, and Effictive Rule Learner</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,428.28,452.07,95.72,8.10;9,333.00,464.07,193.08,8.10;9,333.00,476.07,68.50,8.10">Proceedings of the Annual Conference of the American Association for Artificial Intelligence (AAAI)</title>
		<meeting>the Annual Conference of the American Association for Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,324.00,488.07,188.82,8.10;9,333.00,500.07,203.50,8.10;9,333.00,512.07,83.25,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,463.09,488.07,49.73,8.10;9,333.00,500.07,165.83,8.10">Large Margin Classification Using the Perceptron Algorithm</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,505.02,500.07,31.48,8.10;9,333.00,512.07,31.33,8.10">Machine Learning</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="277" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,324.00,524.07,210.35,8.10;9,333.00,536.07,213.97,8.10;9,333.00,548.07,50.49,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,432.63,524.07,101.72,8.10;9,333.00,536.07,33.52,8.10">TREC 2004 Genomic Track Overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,382.74,536.07,164.23,8.10;9,333.00,548.07,28.00,8.10">Proceedings of the Text Retrieval Conference (TREC)</title>
		<meeting>the Text Retrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,324.00,560.07,208.19,8.10;9,333.00,572.07,207.81,8.10;9,333.00,584.07,74.05,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,359.26,572.07,159.85,8.10">Information content in Medline record fields</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Kostoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Stump</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Pfeil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,524.52,572.07,16.29,8.10;9,333.00,584.07,27.45,8.10">Int J Med Inf</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="515" to="527" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
