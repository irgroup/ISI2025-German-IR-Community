<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.00,157.84,264.14,23.74;1,95.40,179.68,409.31,23.74">University of Glasgow at TREC 2005: Experiments in Terabyte and Enterprise Tracks with Terrier</title>
				<funder ref="#_9UJXqRP">
					<orgName type="full">Leverhulme Trust</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,150.48,214.37,80.61,16.49"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
							<email>craigm@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.65,214.37,33.44,16.49"><forename type="first">Ben</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.72,214.37,91.94,16.49"><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
							<email>vassilis@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.91,214.37,52.73,16.49"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<email>ounis@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<country key="GB">Scotland, UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.00,157.84,264.14,23.74;1,95.40,179.68,409.31,23.74">University of Glasgow at TREC 2005: Experiments in Terabyte and Enterprise Tracks with Terrier</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">87ABF54D9BE8AEF5954D3922D06FC487</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With our participation in TREC 2005, we continue experiments using Terrier, a modular and scalable Information Retrieval (IR) framework, in 4 tasks from the Terabyte and Enterprise tracks. In the Terabyte track, we investigate new Divergence From Randomness weighting models, and a novel query expansion approach that can take into account various document fields, namely content, title and anchor text. In addition, we test a new selective query expansion mechanism which determines the appropriateness of using query expansion on a per-query basis, using statistical information from a low-cost query performance predictor. In the Enterprise track, we investigate combining document fields evidence with other information occurring in an Enterprise setting. In the email known item task, we also investigate temporal and thread priors suitable for email search. In the expert search task, for each candidate, we generate profiles of expertise evidence from the W3C collection. Moreover, we propose a model for ranking these candidate profiles in response to a query.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In TREC 2005, we participate in the Terabyte track and the Enterprise track. For all our experiments, we used our Terrier platform <ref type="bibr" coords="1,156.64,483.20,10.60,13.74" target="#b7">[8]</ref>. In particular, we improve and refine a distributed version of Terrier that we deploy in the Terabyte track.</p><p>In the Terabyte track adhoc task, we investigate several new techniques for effective retrieval from large document sets such as the .GOV2 collection. Firstly, we define two new weighting models based on the Divergence From Randomness framework (DFR) <ref type="bibr" coords="1,227.12,530.96,10.60,13.74" target="#b0">[1]</ref>, including a variant of a parameter-free hypergeometric model. We use a method that takes document fields into account, such as content, title and anchor text, and then show how the proposed weighting models can use this field evidence. Moreover, we develop a refined query expansion mechanism that uses the fields. Finally, we propose a novel selective query expansion mechanism which helps in deciding whether to apply query expansion for a given query. For the named page finding task, we mainly focus on how to combine evidence on the Web.</p><p>Our participation in the known item task of the Enterprise track was centred on combining various types of evidence from both the Web and the email settings of the provided W3C collection. In particular, we study to which extent email evidence such as dates and threads can help in retrieval performance. Finally, for the expert search task, our objective is to identify evidence about a candidate that is appropriate for expert search and use it to suggest the right candidates for a given query.</p><p>The remainder of the paper is organised as follows: Section 2 describes our adhoc and named page finding runs in the Terabyte track. In addition to the description of our submitted runs, we also provide some additional experimentation that investigates applying full stemming and the setting of query expansion. Section 3 describes our participation in both the known item and expert search tasks of the Enterprise track. In these newly-defined tasks, we describe the sources of evidence used and how they integrate with the retrieval mechanism; Finally, in Section 4 we provide concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Terabyte Track</head><p>This year, the Terabyte track had three tasks. We participated in only the retrieval performance tasks, namely the adhoc and named page finding tasks. This section describes our proposed approaches and the results obtained.</p><p>We indexed the .GOV2<ref type="foot" coords="2,181.56,263.16,3.48,9.62" target="#foot_0">1</ref> collection using Terrier, which was parallelised by indexing the collection in 14 parts. After indexing, each pair of parts was merged, to give 7 parts (average size 3.6 million documents). We remove standard stopwords from the collection, and apply the first two steps of Porter's stemming algorithm, which we refer to as weak stemming <ref type="bibr" coords="2,182.28,299.36,10.69,13.74" target="#b2">[3]</ref>.</p><p>Following the study of Cacheda et al <ref type="bibr" coords="2,242.83,311.36,11.63,13.74" target="#b3">[4]</ref> and our experiments in the Terabyte track last year <ref type="bibr" coords="2,467.22,311.36,15.24,13.74" target="#b9">[10]</ref>, we use a distributed version of Terrier to speed up the retrieval time. This year, we use one broker, and 7 query servers, each serving one index part. Moreover, a global lexicon was created in order to speed up the retrieval process, particularly for query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Adhoc Task</head><p>In the adhoc task, we propose and test a selection of new techniques, including two new Divergence From Randomness (DFR) document weighting models, a novel query expansion mechanism using different document fields, and a selective query expansion mechanism.</p><p>Last year, the PL2 weighting model performed very well in the adhoc task. This year, we aim to improve our performance for short queries. We present two new weighting models from the DFR framework, and show how they can be applied to document fields, to give robust, effective and precise results.</p><p>Moreover, in the TREC 2004 Terabyte adhoc task, we noticed that query expansion was not particularly effective. Therefore, this year, we aim to have a refined query expansion by using more fine grained data. We propose a new query expansion mechanism, which appropriately uses the various document fields available. The queries are then re-weighted and expanded using the more refined information.</p><p>Furthermore, it is now accepted that query expansion works only on queries which have a good top-ranked document set returned by the first-pass retrieval <ref type="bibr" coords="2,270.02,525.92,10.78,13.74" target="#b1">[2,</ref><ref type="bibr" coords="2,283.80,525.92,11.86,13.74" target="#b12">13]</ref>. We hypothesise that if query expansion using the local collection (i.e. .GOV2) is predicted to degrade performance, then using an external resource to bring new information will improve retrieval effectiveness <ref type="bibr" coords="2,251.21,549.80,10.60,13.74" target="#b6">[7]</ref>. This leads us to propose a decision mechanism that involves a selective use of a high-quality external resource for query expansion, namely the English Wikipedia<ref type="foot" coords="2,479.40,561.48,3.48,9.62" target="#foot_1">2</ref> . The proposed mechanism also predicts the benefit of query expansion on the local (.GOV2) and the external collection and chooses the best option, if any.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">PLL2F and DLH13F Fields-based Document Weighting Models</head><p>The aim of this research is to devise high performance weighting models for large-scale collections of documents with less extensive tuning. We describe two weighting models, PLL2F and DLH13F which take field evidence into account. Following the convention of Zaragoza et al <ref type="bibr" coords="3,303.20,166.52,15.33,13.74" target="#b13">[14]</ref>, we suffix the name of field weighting models with 'F'. Our proposed PLL2F model is a variation of the PL2F model on fields. Using the PL2F models, the relevance score of a document d for a query Q is given by:</p><formula xml:id="formula_0" coords="3,100.20,212.83,421.59,27.49">score(d, Q) = t∈Q qtw • 1 tf n + 1 tf n • log 2 tf n λ + (λ -tf n) • log 2 e + 0.5 • log 2 (2π • tf n) (<label>1</label></formula><formula xml:id="formula_1" coords="3,521.79,216.08,3.92,13.74">)</formula><p>where λ is the mean and variance of a Poisson distribution. It is given by λ = F/N . F is the frequency of the query term in the collection and N is the number of documents in the collection. The query term weight qtw is given by qtf /qtf max . qtf is the query term frequency. qtf max is the maximum query term frequency among the query terms. In the rest of this paper, we use the same notations for these variables.</p><p>The final normalised term frequency tf n is the sum of the normalised term frequencies in the three fields:</p><formula xml:id="formula_2" coords="3,183.36,327.67,342.32,27.61">tf n = f w f • tf f • log 2 (1 + c f • avg l f l f ), (c f &gt; 0)<label>(2)</label></formula><p>where f refers to a field. l f is the length of a field in the document. avg l f is the average length of the field in the whole collection. tf f is the term frequency of term t in field f . c f is the hyper-parameter of each field.</p><p>In the TREC 2005 runs, the c f parameter of each field is set automatically using a new technique, based on the correlation between term frequency and document length, refining our previous work <ref type="bibr" coords="3,431.07,397.88,10.60,13.74" target="#b5">[6]</ref>. w f is the weight of each field. The weights used in all our experiments in different tasks are presented in the Appendix. The above described per-field normalisation is a generalisation of the method applied in <ref type="bibr" coords="3,382.80,421.76,15.33,13.74" target="#b13">[14]</ref>.</p><p>In the above PL2F model, 1 tf n+1 is an addendum to normalising the relevance score. In the PLL2F model, it is replaced with:</p><formula xml:id="formula_3" coords="3,273.12,469.03,52.89,23.52">log 2 tf n tf n + 1</formula><p>Hence, the PLL2F model is given by:</p><formula xml:id="formula_4" coords="3,93.48,526.39,432.23,27.49">score(d, Q) = t∈Q qtw • log 2 tf n tf n + 1 tf n • log 2 tf n λ + (λ -tf n) • log 2 e + 0.5 • log 2 (2π • tf n) (3)</formula><p>In PLL2F, the normalised term frequency tf n is also given by Equation <ref type="bibr" coords="3,362.91,560.60,10.69,13.74" target="#b1">(2)</ref>.</p><p>The DLH13F model is an extension of our previous work on the hypergeometric model<ref type="foot" coords="3,438.36,584.28,3.48,9.62" target="#foot_2">3</ref> . Both are generalisations of the hypergeometric model in a binomial case. The hypergeometric model assumes that the document is a sample, and the population is from the collection. Note that the hypergeometric DFR weighting model does not have any parameters that require tuning. In other words, all the variables of the hypergeometric models are automatically set from the collection statistics. DLH13F uses a different generalisation of the binomial case. The relevance score of a document d for a query Q in DLH13F is given by:</p><formula xml:id="formula_5" coords="4,120.84,136.15,404.87,27.49">score(d, Q) = t∈Q qtw • 1 tf + 0.5 • log 2 ( tf • avg l l • N F ) + 0.5 log 2 2πtf (1 - tf l )<label>(4)</label></formula><p>where avg l is the average document length in the collection. l is the document length. Note that the hypergeometric model in Equation ( <ref type="formula" coords="4,183.80,179.48,3.92,13.74" target="#formula_5">4</ref>) does not have a tf normalisation component, as it is assumed to be inherent to the model. tf is the weighted sum of the within-document frequencies in the each field:</p><formula xml:id="formula_6" coords="4,251.28,215.00,274.43,24.36">tf n = f w f • tf f (5)</formula><p>where tf f is the term frequency of term t in field f , and w f controls the contribution of the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Query Expansion on Fields</head><p>We develop a new query expansion mechanism based on fields. The query expansion mechanism refines the DFR term weighting models by a uniform combination of evidence from the three fields. In order to combine the Web evidence into the term weighting models, the variables in the models are defined upon statistics of the three fields.</p><p>In this task, we apply the Bo1 term weighting model for query expansion <ref type="bibr" coords="4,382.44,328.28,10.60,13.74" target="#b0">[1]</ref>. It is based on the Bose-Einstein statistics. Using this model, the weight of a term t in the exp doc top-ranked documents is given by:</p><formula xml:id="formula_7" coords="4,215.52,363.43,310.18,23.89">w(t) = tf x • log 2 1 + P n P n + log 2 (1 + P n )<label>(6)</label></formula><p>where tf x is the frequency of the query term in the exp doc top-ranked documents. exp doc usually ranges from 3 to 10 <ref type="bibr" coords="4,104.96,400.88,10.60,13.74" target="#b0">[1]</ref>. P n is given by F N . Terrier employs two alternate methods to determine qtw, the query term weight of a re-weighted term. The first method uses the Rocchio's beta <ref type="bibr" coords="4,221.95,424.88,10.78,13.74" target="#b0">[1,</ref><ref type="bibr" coords="4,235.25,424.88,12.04,13.74" target="#b11">12]</ref>:</p><formula xml:id="formula_8" coords="4,238.20,448.75,287.51,23.89">qtw = qtf qtf max + β • w(t) w max (t)<label>(7)</label></formula><p>where w(t) is the weight of term t and w max (t) is the maximum w(t) of the expanded query terms. β is a parameter. In all our submitted runs, β is set to 0.5. The other one is a parameter-free method, where the qtw of a re-weighted term is given by:</p><formula xml:id="formula_9" coords="4,189.60,533.47,336.11,24.01">qtw = qtf qtf max + w(t) lim F →tfx w(t)<label>(8)</label></formula><formula xml:id="formula_10" coords="4,215.40,560.71,195.36,23.89">= F max log 2 1 + P n,max P n,max + log 2 (1 + P n,max )</formula><p>where lim F →tfx w(t) is the theoretical upper bound of w(t). P n,max is given by F max /N . F max is the F of the term with the maximum w(t) in the top-ranked documents. If a query term does not appear in the most informative terms from the top-ranked documents, its query term weight remains equal to the original one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Selective Use of External Resource for Query Expansion</head><p>We propose a new low-cost selective statistical decision mechanism for the application of query expansion. The decision mechanism is based on our previously developed pre-retrieval performance prediction technique. The expansion of the query can be either local, using documents from .GOV2, or external, using an index of the English Wikipedia. As the Terabyte adhoc topics cover a wide range of general interest topics, we hypothesise that using a different high quality collection as a collection enrichment resource for automatic query expansion could bring more useful query terms and hence could retrieve more relevant documents. The selective mechanism predicts the benefit of query expansion using either options, and adopts the most effective one. If both options are predicted to lead to the degradation of the query performance, then query expansion is disabled. Note that the approach does not involve the use of an external search engine.</p><p>We use the Average Inverse Collection Term Frequency (AvICTF) <ref type="bibr" coords="5,364.87,250.16,11.75,13.74" target="#b4">[5]</ref> to infer the successfulness of query expansion. Its definition is as follows:</p><formula xml:id="formula_11" coords="5,236.40,285.95,289.31,26.60">AvICT F = log 2 Q token coll F ql<label>(9)</label></formula><p>In the above definition, token coll is the number of tokens in the whole collection. ql is the query length. Using the AvICTF as a predictor, the decision mechanism is presented in Table <ref type="table" coords="5,346.49,325.88,3.77,13.74" target="#tab_0">1</ref>. From its definition, AvICTF is comparable for different collections. Therefore, we use the same threshold setting for the two collections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Experiments and Results</head><p>We submitted 4 runs in the adhoc task. All runs used Porter's weak stemming. The first three runs use short queries (title-only) and the last run uses long queries (title+description+narrative). The four runs are as follows:</p><p>• In run uogTB05SQE, we test the PLL2F model, together with the query expansion mechanism on fields.</p><p>• The run uogTB05SQEH adopts the parameter-free DLH13F model, and the same query expansion mechanism on fields.</p><p>• Using uogTB05SQE as the baseline, in run uogTBSQES, we test the selective decision mechanism using PLL2F. The applied threshold setting for the decision mechanism is 13.5.</p><p>• Finally, in run uogTB05LQEV, we use PLL2F and the query expansion mechanism on fields. We test the usefulness of the long queries in this run.</p><p>In all the four runs, we applied the Bo1 query expansion model. For each query, we re-weight the 20 most informative terms from the top 5 returned documents in the first-pass retrieval, and add these terms to the query. Using last year's Terabyte track best setting, the Rocchio's beta is set to 0.5.</p><p>Table <ref type="table" coords="6,114.09,123.92,5.03,13.74" target="#tab_2">2</ref> presents the performance achieved by our submitted runs, along with that of the participants. According to the results:</p><p>• The performance of our submitted runs is considerably above the median of all of the submitted runs. This shows that the two newly proposed models achieved effective retrieval performance in the Terabyte track adhoc task.</p><p>• Among our four submitted runs, the run using long queries (i.e. uogTB05LQEV) does not have the best MAP but the best bpref and Pre@10. This seems to indicate that the descriptions and narratives in the topics of this task are not very useful.</p><p>• Although the run uogTB05SQES which uses the selective query expansion mechanism has a lower MAP than the baseline run uogTB05SQE, it achieves a better Pre@10 (i.e. 0.6580 against 0.6300). Our explanation is that the selective query expansion mechanism refines the top-ranked documents, while it introduces noise to the rest of the returned documents. Therefore, the selective query expansion mechanism provides a better early precision.  The mean average precision (MAP), binary preference (bpref) and precision at 10 (Pre@10) of our submitted runs, and that achieved by all participants. Pre@10 achieved by all participants is not available. The measures in bold are the best in our submitted runs.</p><p>Overall, the two newly proposed models, as well as the query expansion mechanism on fields are shown to be effective. Moreover, the selective query expansion mechanism increases the early precision performance of the system. Finally, in terms of MAP, the long queries are shown not to be useful in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">Additional Query Expansion Runs</head><p>In this section, we conduct some additional runs to further evaluate the query expansion mechanism on fields. We vary the number of re-weighted terms (exp term), the number of top-ranked documents (exp doc) from which the re-weighted terms are selected, and the Rocchio's beta value used for query expansion. We also apply the parameter-free query expansion (see Equation <ref type="formula" coords="6,263.64,521.60,3.63,13.74" target="#formula_9">8</ref>), which is an alternative to the Rocchio's beta. Tables <ref type="table" coords="6,494.38,521.60,5.03,13.74" target="#tab_3">3</ref> and<ref type="table" coords="6,520.03,521.60,5.03,13.74" target="#tab_4">4</ref> contain the MAP measures obtained using the PLL2F and DLH13F models, respectively.</p><p>According to the results in Tables <ref type="table" coords="6,230.37,545.48,5.03,13.74" target="#tab_3">3</ref> and<ref type="table" coords="6,256.13,545.48,3.77,13.74" target="#tab_4">4</ref>, the query expansion mechanism on fields is shown to be robust with various query expansion settings. With some settings, we outperform our best submitted runs. In particular, one setting achieves an MAP of 0.3816.</p><p>From Table <ref type="table" coords="6,139.03,581.36,3.77,13.74" target="#tab_3">3</ref>, note that our parameter-free query expansion mechanism achieves an MAP that is better than our best submitted run (0.3782 vs. 0.3755).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.6">Experiments with Stemming</head><p>In our previously presented experiments, Porter's weak stemming is applied, as this can increase the precision of the results without over-impacting recall. To compare with the submitted runs of other participating groups, we experiment with applying full stemming.</p><p>exp doc exp term β = 0.1 β = 0.2 β = 0.5 β = 0. Table <ref type="table" coords="7,113.49,311.48,5.03,13.74" target="#tab_6">5</ref> shows the results in terms of MAP, bpref and Pre@10 of the three runs using short queries: uogTB05SQE is the submitted run, using PLL2F and weak stemming; uogTB05SFullQE uses the same setting as uogTB05SQE but applies full Porter stemming. From the table, we can see that applying full stemming improves the bpref and Pre@10 achieved compared to weak stemming. However, as the setting of uogTB05SFullQE was determined from training on weak stemming, we also show the results for uogTB05SFullQEbis, where the setting has been trained on full stemming. This increases the performance of full stemming over all three evaluation measures. Note, that the run uogTB05SFullQEbis outperforms the best submitted short queries run of all participants, in-dri05AdmfS by the University of Massachusetts, by a 4% margin on all three evaluation measures (indri05AdmfS achieved MAP 0.3886, bpref 0.3920, and Pre@10 0.6340).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Named Page Finding Task</head><p>In the named page finding task, we focused our participation on applying and refining techniques which had successfully worked during our previous Web track participations on the .GOV collection.</p><p>As in the adhoc task, we use a combination of evidence from three fields: content, title and anchor text. However, obtaining the correct parameter settings is important in order to achieve the best retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Training</head><p>For our training, we started from the fact that the .GOV collection is a significant subset of the .GOV2 collection. We used two forms of training for our setting this year: Firstly we used 300 topics from the named page finding tasks of the 2002 and 2003 Web tracks to find a good setting for the system on the .GOV collection. We then directly transferred this setting to the .GOV2 collection. Alternatively, using the named page finding topics from the 2002-2004 Web tracks, we were able to generate 190 named page finding topics for the .GOV2 collection, by mapping the .GOV document numbers into .GOV2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Experiments and Results</head><p>We submitted 4 runs to the named page finding task. These were created using the previously described indexing method, and the distributed version of Terrier described in Section 2. The PL2F weighting model on fields, see Equations ( <ref type="formula" coords="8,120.99,216.92,3.92,13.74" target="#formula_0">1</ref>) &amp; ( <ref type="formula" coords="8,144.97,216.92,3.56,13.74" target="#formula_2">2</ref>), was used to rank documents.</p><p>• uogNP05Base is our baseline run. It uses the Porter's weak stemming index, and the best setting as found using the 300 topics on .GOV.</p><p>• uogNP05BaseN tests the difference in applying no stemming for this task. The parameter setting is taken from the best setting using the 300 topics on .GOV.</p><p>• uogNP05bis tests training a retrieval system using the topics migrated from .GOV. It also uses a Porter's weak stemming index.</p><p>• Finally, uogNP05bisP is based on uogNP05bis, but applies proximity search.</p><p>Table <ref type="table" coords="8,115.42,352.40,5.03,13.74" target="#tab_8">6</ref> shows the performance achieved by our submitted runs in terms of MRR, along with that of the participants. According to the results, all our submitted runs were above the median. The runs uogNP05Base and uogNP05BaseN perform better than the other two. We surmise that the setting migrated from .GOV performs better than training on the real collection using a smaller number of topics. Finally, applying either no stemming or proximity search produces marginal increases in performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Additional Runs</head><p>In this section, we test applying other common sources of evidence in Web IR that can improve the obtained retrieval performance. In particular, we apply PageRank <ref type="bibr" coords="8,298.88,550.28,10.69,13.74" target="#b8">[9]</ref>, and the Static Absorbing Model <ref type="bibr" coords="8,443.44,550.28,16.66,13.74" target="#b10">[11]</ref> as link analysis, the In-Degree of a document, and the length of the URL path in characters as additional sources of evidence. The baseline for all additional runs was uogNP05Base (MRR 0.400).</p><p>The results for the additional runs are shown in Table <ref type="table" coords="8,313.20,586.16,3.77,13.74" target="#tab_9">7</ref>. All forms of additional evidence produced slight increases in performance. Surprisingly, applying the In-Degree evidence produces the highest observed increase in performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Enterprise Track</head><p>In the Enterprise track, we chose to submit runs for two tasks: email known item, and expert search. Our experiments focused around the application of Web IR techniques, and the development of new techniques specific to Enterprise search tasks. In particular, we investigate the usefulness of document metadata in an email setting, as well as various sources of evidence in expert search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Email Known Item Task</head><p>Our aim in the known item task was to identify sources of evidence suitable for use in an Enterprise setting. As the W3C collection is distributed as a Web crawl, we chose firstly to use Web evidence, indexing separately content, title and anchor text fields of a document. The anchor text field of a document consisted of the anchor text from all incoming hyperlinks to the document, from any part of the collection. When indexing, we removed standard stopwords from the collection, and apply Porter's weak stemming.</p><p>In applying Enterprise evidence, we used two forms of evidence exhibited by emails to form three priors, which will be used to refine the ranking. Firstly, one from the thread structure of the emails, and two from temporal evidence that can be obtained from emails. The priors act upon the score(d, Q) of an email document d with respect to a query Q, as given by the PL2F weighting model on fields -see Equations ( <ref type="formula" coords="9,467.18,401.84,3.92,13.74" target="#formula_0">1</ref>) &amp; ( <ref type="formula" coords="9,493.08,401.84,3.56,13.74" target="#formula_2">2</ref>). The hyper-parameters and weights were trained using the provided training topics. In the following, we describe our three priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threads:</head><p>We assume that the relevant emails in a known item task will be at the start of a thread, rather than a reply. Hence, we boost the score of emails that occurred higher in the thread tree. The score of a retrieved document d is altered as follows:</p><formula xml:id="formula_12" coords="9,191.88,493.70,329.63,27.61">score(d, Q) = score(d, Q) + weight offset + Generation(d) (<label>10</label></formula><formula xml:id="formula_13" coords="9,521.50,500.84,4.19,13.74">)</formula><p>where weight and offset are two free parameters, and Generation is a function that returns the thread depth of document d. The values 2.557 and 2.2 were used for weight and offset respectively, determined using the provided training topics.</p><p>Email Dates: The topics were generated in 2004/2005 with a particular focus on more recent years of the collection. Hence, we chose to alter the scores of the retrieved documents by altering the score of a retrieved document d, as follows:</p><formula xml:id="formula_14" coords="9,216.72,613.94,308.78,20.80">score(d, Q) = score(d, Q) + g • Date(d)<label>(11)</label></formula><p>where Date(d) is the date when the email was sent. g is a free parameter, which was set to 1.154e-3 using the provided training topics.</p><p>Topics Dates: We experiment with a mechanism that boosts the retrieved documents that were sent near the date mentioned in a topic, by applying a Gaussian function to the scores of the retrieved documents. The score of retrieved document d that was sent around the topicDate is increased as follows:</p><formula xml:id="formula_15" coords="10,161.40,168.50,360.10,28.49">score(d, Q) = score(d, Q) + h √ 2π exp(- (Date(d) -topicDate) 2 2σ 2 ) (<label>12</label></formula><formula xml:id="formula_16" coords="10,521.50,175.64,4.19,13.74">)</formula><p>where h is a free parameter; Date(d) is the date when the email was sent; σ is the parameter of the Gaussian function. We use it to control the width of the temporal boosting. We apply a narrow boost (σ = 30) when the target date in the topic is a particular day, a wider boost (σ = 70) when the target date is a month, and wider still (σ = 450) when the topic mentions only a year. The value used for h was 5.99, determined using the provided training topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Experiments and Results</head><p>We submitted 4 runs to the known item email task of the Enterprise track: uogEBase is the baseline run; uogE-Dates1 applies the Topics Dates evidence to the baseline; uogEDates2 applies the Email Dates evidence to the baseline; finally uogEDates12T combines all three priors, including the Threads evidence.  Table <ref type="table" coords="10,114.09,413.00,5.03,13.74" target="#tab_11">8</ref> shows the results of the runs we submitted to the known item task, as well as the results by all participants. We can see that all 4 runs performed considerably above the median. Compared to the baseline uogEBase, run uogEDates12T, which combines all three forms of evidence, performs the best. Email Dates (uogEDates2) appears to have made a very slight improvement in retrieval performance. Topic Dates (uogEDates1) has no impact on retrieval performance.</p><p>Overall, we found that the retrieval approaches worked extremely well for this email known item task. Our best MRR (0.621) was much higher than the median of 0.4545. This was the best submitted run from all participants for this task.</p><p>In conclusion, our participation to the known item task was extremely successful. In addition to the usefulness of the Web evidence, we found that the Thread structure was the most effective evidence, while using dates appear to be less effective. Moreover, all four of our submitted runs outperformed the runs of all other participants in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Additional Runs</head><p>In our additional runs, we test two hypotheses. Firstly, whether using anchor from the entire collection is no better than using anchor text from only the lists subset of the collection. Secondly, we wanted to test the effect of stemming in this task, in particular whether weak stemming was the most effective form of stemming to apply.</p><p>To test our anchor text hypothesis, we compared runs using two different anchor text indices: the anchor text used by the submitted runs, which uses the anchor text of hyperlinks from the entire W3C collection; and anchor text of hyperlinks from only the lists subset of the collection. By excluding the 'external anchor text', the number of tokens in the anchor text field dropped significantly. Table <ref type="table" coords="10,323.58,661.52,5.03,13.74" target="#tab_13">9</ref> shows the achieved MRR results for varying the external anchor text applied -using external anchor text corresponds to the submitted run uogEBase. From this table, we can see that using the external anchor text had a small improvement (from 0.615 to 0.619 MRR). On closer inspection of these results, we determined that the improvement was not due to any different occurrences of query terms in the relevant documents, but merely two pairs of document swaps between the two rankings of the affected two topics.</p><p>To test our stemming hypothesis, we varied the stemming applied to the run uogEBase. Table <ref type="table" coords="11,472.35,183.68,10.06,13.74" target="#tab_14">10</ref> shows the results for the applied stemming. Weak stemming appears to be the best form for this task, closely followed by full stemming. No stemming performs considerably lower at MRR 0.600. Hence, it would seem that applying weak stemming is in fact a good choice for this high precision task.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Expert Search Task</head><p>Our aims in this task are two-fold: to identify important evidence for expert search; and to determine how to combine and weight the evidence. We determine documents from the W3C collection to include in the generation of an implicit profile of the expertise of each candidate. As shown below, our proposed profile is the merging of up to three sources of evidence from the collection, namely the expert's homepage, occurrences of his/her name in the collection, and email threads he/she was involved in.</p><p>Each candidate will have a unique corresponding profile. However, we assume that each of the three sources of evidence has a different importance. Therefore, when merging the sources of evidence into a single profile, each document in the profile has a weight.</p><p>Once the profile is built, for a given topic, we rank profiles as in a standard IR system. However, we have two document length normalisation problems. The obvious one is related to the fact that experts that have more presence in the collection will end up with having a much bigger profile than those who are less active. Hence, we normalise with respect to the profile length. The second normalisation accommodates the variance of document length in the W3C corpus.</p><p>We use the In expC2 DFR weighting model <ref type="bibr" coords="11,271.25,570.08,11.63,13.74" target="#b0">[1]</ref> to rank profiles. More specifically, the relevance score of a profile pro to a query Q in In expC2 is given by:</p><formula xml:id="formula_17" coords="11,150.12,605.23,375.58,30.60">score(pro, Q) = t∈Q qtw • F pro + 1 N t pro • (tf n pro + 1) tf n pro • log 2 N pro + 1 n e + 0.5<label>(13)</label></formula><p>where qtw is the query term weight as defined in Section 2.1.1, N pro is the total number of generated implicit profiles, F pro is the term frequency of t in all profiles and N t pro is the number of candidates having a profile that contains t. tf n pro is the normalised term frequency in the profile. n e is given by</p><formula xml:id="formula_18" coords="11,398.70,661.52,121.85,20.50">N pro • 1 -(1 - N tpro Npro ) Fpro .</formula><p>To accommodate both required normalisations above, for the length variation of the profiles, we use the following normalisation function:</p><formula xml:id="formula_19" coords="12,180.48,168.55,345.19,23.89">tf n pro = tf pro • log e (1 + c pro • avg l pro l pro ), (c pro &gt; 0)<label>(14)</label></formula><p>where c pro is the hyper-parameter for the profiles, l pro is the length of the profile, and avg l pro is the average length of all profiles. tf pro is the term frequency in the merged documents of that profile.</p><p>For the document length normalisation, we apply a variation of the normalisation in Equation ( <ref type="formula" coords="12,472.92,222.80,3.56,13.74" target="#formula_2">2</ref>), but rather than using fields, we use the documents of the profile. In this case, the weights are related to the importance of each source of evidence. In the next sections, we provide contents of the profiles and the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Identifying Documents for each Candidate</head><p>From the list of candidates provided by the track organisers, we determine documents that could be included in each candidate's profile, in three different ways:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Occurrences of Person in Corpus:</head><p>We generated queries which were used to identify documents that mentioned each candidate, based on the occurrences of variations of the candidate's name and email address in the collection. The documents returned form the Occurrence set of each candidate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Personal Websites:</head><p>From the candidate list, we identified the username of candidates with an email address ending '@w3.org', and used this to identify the personal website of the candidate in the collection, should it exist. From the URL list of the W3C collection, all documents under the personal website of each candidate were added to the Homepage set of each candidate.</p><p>Email Threads: We used the threading evidence of the emails in the collection to identify additional documents for each candidate's profile. For each email in the Occurrence of a candidate, the other emails in the same thread were added to the EmailT hread set of each candidate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Experiments and Results</head><p>We have submitted five runs for the expert search task. We indexed the W3C corpus by removing standard stopwords and applying Porter's weak stemming.  The mean average precision (MAP), binary preference (BPref) and precision at 10 (Pre@10) of our submitted runs, as well as that achieved by all participants. Pre@10 achieved by all participants is not available.</p><p>Run uogES05B2 is our baseline run -it only uses one source of evidence, namely the Occurrence sets, for generating the candidate profiles. All parameters were set using the provided training topics. uogES05Cbis and uogES05CbiH differ from the baseline as they use the fields of each document, as described in Section 2.1.1.</p><p>Additionally, uogES05CbiH adds the Homepage sets into the generated profiles. Compared to uogES05CbiH, uogES05CbaDT uses the EmailT hread sets rather than the Homepage sets. Finally, uogES05Cbase changes the parameter setting of uogES05Cbis by further training.</p><p>Table <ref type="table" coords="13,114.45,159.80,10.06,13.74" target="#tab_16">11</ref> shows the results of the submitted runs. Both our best runs in terms of MAP (i.e. uogES05CbiH &amp; uogES05Cbis respectively) used the Occurrence sets and fields. Comparing uogES05B2 &amp; uogES05Cbis, shows that applying fields improves Pre@10, but can degrade performance if not properly tuned (uogES05Cbase). In addition, adding the Homepage sets in the run uogES05CbiH increased MAP, but adding the EmailT hread documents into each profile did not (uogES05CbaDT).</p><p>Overall, all our runs performed above median MAP. However, we also noticed that our performance on the provided training queries was not consistent with the submitted runs. This suggests that our used setting in this task is perhaps not optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Overall, the performance we achieved in the adhoc task of the Terabyte track, and the known item task of the Enterprise track were both extremely effective. We achieved the best four submitted runs by MRR in the known item task of the Enterprise track, and the second highest run by MAP in the Terabyte track adhoc task. Moreover, in the Terabyte track, we showed that if full stemming was applied, we were able to exceed the performance of the best submitted short queries run. In the named page finding task of the Terabyte track our results were excellent, and were further improved when link or URL structure was taken into account. In the the expert search task of the Enterprise we developed a promising model that can be improved upon with additional evidence in the future. We surmise that overall our participation in TREC 2005 was very successful.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,74.88,360.45,450.30,91.25"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table coords="5,115.32,360.45,369.50,45.60"><row><cell>AvICTF GOV2&gt;threshold AvICTF Wiki&gt;threshold AvICTF GOV2&gt;AvICTF Wiki Decision True True or False True local True or False True False external False False True or False disabled</cell></row></table><note coords="5,110.01,414.08,415.10,13.74;5,74.88,425.66,450.30,14.04;5,74.88,437.66,82.09,14.04"><p>The selective query expansion mechanism. AvICTF GOV2 and AvICTF Wiki are the values of AvICTF on .GOV2 and Wikipedia, respectively. The column entitled Decision indicates if the query expansion is local, external or disabled.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,74.88,372.56,33.32,13.74"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,114.48,123.09,370.99,148.83"><head>Table 3 :</head><label>3</label><figDesc>Obtained MAP using PLL2F with Bo1 query expansion model for different settings.</figDesc><table coords="7,387.15,123.09,68.37,12.36"><row><cell>8 parameter-free</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,110.64,279.44,378.77,13.74"><head>Table 4 :</head><label>4</label><figDesc>Obtained MAP using DLH13F with Bo1 query expansion model for different settings.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,74.88,485.96,450.45,25.62"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note coords="7,110.13,485.96,415.20,13.74;7,74.88,497.84,61.48,13.74"><p>The mean average precision (MAP), binary preference (bpref) and Precision at 10 (Pre@10) of different stemming runs.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="8,74.88,457.28,450.32,37.62"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note coords="8,111.33,457.28,413.88,13.74;8,74.88,469.16,450.19,13.74;8,74.88,481.16,273.29,13.74"><p>The mean reciprocal rank (MRR) achieved by the submitted TREC Terabyte named page finding runs, and that by all participants. *Note that the submitted run uogNP05bisP was affected by a technical error. Here we show the corrected MRR for this run -the previous MRR was 0.381.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="9,74.88,123.09,450.31,59.45"><head>Table 7 :</head><label>7</label><figDesc>The mean reciprocal rank (MRR) achieved by the additional TREC Terabyte named page runs, showing the improvements in applying additional evidence.</figDesc><table coords="9,121.44,123.09,357.29,26.34"><row><cell></cell><cell cols="5">PageRank Absorbing Model In-Degree URL Scoring PageRank + URL Scoring</cell></row><row><cell>MRR</cell><cell>0.408</cell><cell>0.408</cell><cell>0.417</cell><cell>0.406</cell><cell>0.411</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="10,74.88,377.24,450.21,25.62"><head>Table 8 :</head><label>8</label><figDesc>The mean reciprocal rank (MRR) achieved by our submitted TREC Enterprise known item runs, and that achieved by all participants.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="11,102.36,276.08,395.40,60.68"><head>Table 9 :</head><label>9</label><figDesc>The mean reciprocal rank (MRR) achieved by runs using differing amounts of anchor text.</figDesc><table coords="11,180.00,310.41,240.18,26.34"><row><cell cols="2">Stemming None Weak</cell><cell>Full</cell><cell>best</cell><cell>median worst</cell></row><row><cell>MRR</cell><cell cols="4">0.600 0.619 0.616 0.7524 0.4545 0.027</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="11,101.16,344.12,397.81,13.74"><head>Table 10 :</head><label>10</label><figDesc>The mean reciprocal rank (MRR) achieved by runs applying differing levels of stemming.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" coords="12,74.88,602.36,38.00,13.74"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,89.16,605.87,271.95,10.99"><p>Further information on .GOV2 can found from http://ir.dcs.gla.ac.uk/test collections/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,89.16,615.59,89.41,10.99"><p>See http://en.wikipedia.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,89.16,664.07,170.43,10.99"><p>See http://ir.dcs.gla.ac.uk/wiki/HypergeometricModel</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Part of this work is supported by The <rs type="funder">Leverhulme Trust</rs>, grant number <rs type="grantNumber">F/00179</rs>/S, as part of the <rs type="projectName">Smooth</rs> project on length normalisation (URL: http://ir.dcs.gla.ac.uk/smooth).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_9UJXqRP">
					<idno type="grant-number">F/00179</idno>
					<orgName type="project" subtype="full">Smooth</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="14,91.43,145.94,433.65,14.04;14,91.44,158.12,260.43,13.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="14,133.14,145.94,339.88,13.93">Probabilistic Models for Information Retrieval based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="14,91.43,178.04,433.76,13.74;14,91.44,189.74,237.53,14.04" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,260.42,178.04,264.77,13.74;14,91.44,190.04,40.33,13.74">Query Difficulty, Robustness, and Selective Application of Query Expansion</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,150.28,189.74,104.78,13.93">Proceedings of ECIR 2004</title>
		<meeting>ECIR 2004<address><addrLine>Sunderland, UK</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,209.96,433.45,13.74;14,91.44,221.96,139.38,13.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="14,117.08,209.96,400.39,13.74">Belew Finding Out About: A Cognitive Perspective on Search Engine Technology and the WWW</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,241.88,433.66,13.74;14,91.44,253.46,378.94,14.04" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,255.25,241.88,269.83,13.74;14,91.44,253.76,107.94,13.74">A Case Study of Distributed Information Retrieval Architectures to Index One Terabyte of Text</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Cacheda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,206.86,253.46,207.95,14.04">In Information Processing and Management Journal</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,273.38,433.78,14.04;14,91.44,285.38,360.26,14.04" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,179.52,273.38,225.64,14.04">Query Performance Prediction. In Information Systems</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,413.14,273.38,112.07,13.93;14,91.44,285.38,277.22,13.93">Special Issue for the String Processing and Information Retrieval: 11th International Conference</title>
		<imprint>
			<date type="published" when="2004">2004. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,305.30,433.67,14.04;14,91.44,317.30,118.77,14.04" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,171.60,305.60,253.00,13.74">A study of the Dirichlet Priors for term frequency normalisation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,442.50,305.30,82.59,13.93;14,91.44,317.30,45.44,13.93">Proceedings of ACM SIGIR 2005</title>
		<meeting>ACM SIGIR 2005<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,337.22,433.63,14.04;14,91.44,349.10,433.65,14.04;14,91.44,361.40,157.45,13.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,197.61,337.52,215.05,13.74">Improving two-stage ad-hoc retrieval for short queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,431.33,337.22,93.72,13.93;14,91.44,349.10,401.12,13.93">Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 21st annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,381.32,433.63,13.74;14,91.44,393.02,290.17,14.04" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,407.10,381.32,117.96,13.74;14,91.44,393.32,33.35,13.74">Terrier Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,143.11,393.02,104.78,13.93">Proceedings of ECIR 2005</title>
		<meeting>ECIR 2005<address><addrLine>Santiago de Compostela, Spain</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,91.43,412.94,433.64,14.04;14,91.44,425.12,280.22,13.74" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="14,286.91,412.94,233.42,13.93">The PageRank citation ranking: Bringing order to the Web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Digital Library Technologies Project</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="14,96.34,445.04,428.85,13.74;14,91.44,456.74,316.92,14.04" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,239.54,445.04,285.64,13.74;14,91.44,457.04,110.18,13.74">University of Glasgow at TREC2004: Experiments in Web, Robust and Terabyte tracks with Terrier</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,219.46,456.74,106.94,13.93">Proceedings of TREC 2004</title>
		<meeting>TREC 2004<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,96.34,476.66,428.95,14.04;14,91.44,488.96,22.64,13.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,248.29,476.96,156.70,13.74">The Static Absorbing Model for the Web</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,412.39,476.66,108.56,13.93">Journal of Web Engineering</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,96.34,508.58,428.76,14.04;14,91.44,520.46,340.16,14.04" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,147.51,508.88,176.12,13.74">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,344.31,508.58,180.78,13.93;14,91.44,520.46,128.59,13.93">The Smart Retrieval system-Experiments in Automatic Document Processing</title>
		<meeting><address><addrLine>Salton, G., Ed. Prentice-Hall Englewood Cliffs. NJ</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,96.34,540.68,428.87,13.74;14,91.44,552.38,433.90,14.04;14,91.44,564.68,66.52,13.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,297.10,540.68,228.10,13.74;14,91.44,552.68,280.05,13.74">Learning to estimate query difficulty: including applications to missing content detection and distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yom-Tov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Darlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,389.65,552.38,131.16,13.93">Proceedings of ACM SIGIR 2005</title>
		<meeting>ACM SIGIR 2005<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,96.34,584.60,428.65,13.74;14,91.44,596.18,271.59,14.04" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,362.06,584.60,162.92,13.74;14,91.44,596.48,64.35,13.74">Microsoft Cambridge at TREC 13: Web and Hard Tracks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,174.26,596.18,106.94,13.93">Proceedings of TREC 2004</title>
		<meeting>TREC 2004<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
