<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,177.26,154.61,256.41,15.53">Indri at TREC 2005: Terabyte Track</title>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
				<funder>
					<orgName type="full">Advanced Research and Development Activity</orgName>
				</funder>
				<funder ref="#_8JuceCy #_JQAwWQJ #_hPy7erB">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,155.24,187.00,77.43,10.99"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.81,187.00,84.71,10.99"><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,336.35,187.00,48.08,10.99"><forename type="first">Yun</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,394.17,187.00,61.53,10.99"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,177.26,154.61,256.41,15.53">Indri at TREC 2005: Terabyte Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EA7BD3C265A091BB34EEBC3930670BFD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work details the experiments carried out using the Indri search engine during the TREC 2005 Terabyte Track. Results are presented for each of the three tasks, including efficiency, ad hoc, and named page finding. Our efficiency runs focused on query optimization techniques, our ad hoc runs look at the importance of term proximity and document quality, and our named-page finding runs investigate the use of document priors and document structure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year, the Terabyte Track was expanded from a single ad hoc task to include an efficiency and named-page finding task. These new tasks provided new and interesting environments in which to test our search engine, Indri 1 <ref type="bibr" coords="1,185.08,500.07,14.58,9.96" target="#b12">[13]</ref>. As evidenced by last year's Terabyte Track results, Indri is a highly efficient, highly effective search engine. The underlying retrieval model is based on a combination of the inference network <ref type="bibr" coords="1,145.37,547.88,15.47,9.96" target="#b14">[15]</ref> and language modeling <ref type="bibr" coords="1,271.80,547.88,10.50,9.96" target="#b2">[3]</ref> approaches to retrieval <ref type="bibr" coords="1,169.73,559.83,9.94,9.96" target="#b6">[7]</ref>. Indri supports a robust query language, based on the InQuery query language <ref type="bibr" coords="1,101.56,583.75,9.94,9.96" target="#b0">[1]</ref>. Our primary goal this year was to further tweak our system both in terms of efficiency and effectiveness in large scale retrieval settings.</p><p>The remainder of this paper details the experiments and results obtained for each of the three Terabyte Track tasks. 1 Available for download at: http://lemurproject.org/indri/ 2 Efficiency Task Indri was a brand new retrieval system at last year's TREC conference. In the past year, we have added to its capabilities and have attempted to improve its speed without sacrificing retrieval effectiveness. To this end, Indri includes new query processing techniques <ref type="bibr" coords="1,340.35,352.04,15.47,9.96" target="#b13">[14]</ref> and a new multithreaded architecture <ref type="bibr" coords="1,520.78,352.04,14.58,9.96" target="#b11">[12]</ref>.</p><p>In contrast to last year's system, Indri is now multithreaded, which allows many queries to be processed at once. Unfortunately, the rules specifically prohibited this optimization this year, so our official runs do not include this optimization. We report threaded results in this paper for comparison.</p><p>The indexing code for the system is conceptually similar to last year's system, although it has been completely rewritten. The main feature of the new code is that it is concurrent; queries can be processed while documents are being added to the system, and each document is available for query immediately after it is added, with no document batching necessary. We also separated the vocabulary structures into two B-Trees; one for frequent terms (those appearing more than 1000 times in the collection) and one for infrequent terms. The frequent terms tree is small enough that it is quickly cached into memory by the operating system; future lookups to this structure incur no disk I/O. Since most query terms come from the frequent terms list, disk I/O is reserved for the inverted lists.</p><p>Our goal this year was to try to make our current system fast while not sacrificing any of its capability. To this end, our index structures include inverted lists, direct lists, and a compressed version of the document collection. The query code and index structures are the same as those used for the effectiveness tasks, although we used more complex query formulations in the effectiveness task.</p><p>All of our machines meet the specifications in Table <ref type="table" coords="2,72.00,493.95,3.87,9.96" target="#tab_0">1</ref>. For the first run, we used a single machine (2079 mins. to build index), while for the distributed run, we used 6 of these machines in parallel (327 mins. to build index) for both indexing and retrieval. The distribution of the text for indexing was done manually, but the query processing distribution was automatic.</p><p>Tables <ref type="table" coords="2,113.41,569.64,4.97,9.96" target="#tab_1">2</ref> and<ref type="table" coords="2,141.39,569.64,4.97,9.96">3</ref> show our official (unthreaded) and unofficial (threaded) runs, respectively. The tables provide total query processing and the average time across the 50,000 efficiency queries. Distributing the index, as expected, improves our official average query time from 1.43 to 0.49s per query. We also see from our unofficial numbers that threading the query director in a fully distributed environment further improves throughput by a factor of 2-3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Ad Hoc Task</head><p>For the ad hoc retrieval task this year we extended and improved the methods we investigated during TREC 2004 <ref type="bibr" coords="2,366.94,309.07,9.94,9.96" target="#b8">[9]</ref>. We are interested in studying how traditional ad hoc retrieval models and methods scale to large, noisy web collections, and what new types of features may exist that can be exploited in such an environment. Therefore, this year we explored the use of term proximity information, pseudo-relevance feedback, and the use of a document quality prior. All of our ad hoc runs are against the entire GOV2 collection, with no special document or link structure indexed. All documents are stemmed using the Porter stemmer. Once again this year, we do not stop documents at index time. Instead, we perform queryside stopping using a list of 418 common terms. We use Bayesian smoothing, and allow single term and proximity features (i.e. #1, #uw8) to be smoothed differently. All of our runs are automatic and all the system parameters are tuned on the TREC 2004 Terabyte Track topics (701-750).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>Our baseline run this year, indri05Aql, is a simple title-only query likelihood run. For example, topic 758, "embryonic stem cells", is converted into the following Indri query: #combine( embryonic stem cells ) which produces results rank-equivalent to a simple query likelihood language modeling run. We consider this to be a strong, reasonable baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dependence Model</head><p>At least year's Terabyte Track, we developed a novel mechanism for modeling term proximity features <ref type="bibr" coords="3,287.15,157.91,9.94,9.96" target="#b8">[9]</ref>. Since then, the model has been expanded and expressed in terms of a term dependence model <ref type="bibr" coords="3,265.87,181.82,9.94,9.96" target="#b7">[8]</ref>. The use of term proximity information is not new <ref type="bibr" coords="3,269.17,193.78,9.94,9.96" target="#b1">[2]</ref>, but has never caught on. However, we feel it plays an increasingly important role in retrieval as collections get larger and noisier.</p><p>The model encodes the following two assumptions: 1) the order of query terms is important, and 2) query terms will occur within closer proximity to each other in relevant documents. The full details of the model are not given here due to space constraints. See <ref type="bibr" coords="3,289.93,289.56,10.50,9.96" target="#b7">[8]</ref> for a full treatment.</p><p>To give an idea of how the dependence model translates queries into Indri structured queries we give the following example, again for topic 758:</p><p>#weight(0.8 #combine(embryonic stem cells) 0.1 #combine(#1(stem cells) #1(embryonic stem) #1(embryonic stem cells)) 0.1 #combine(#uw8(stem cells) #uw8(embryonic cells) #uw8(embryonic stem) #uw12(embryonic stem cells)))</p><p>Our indri05Adm, indri05AdmfS, and indri05AdmfL runs employ this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pseudo-Relevance Feedback</head><p>For pseudo-relevance feedback, we use a modified version of Lavrenko's relevance model <ref type="bibr" coords="3,225.90,536.44,9.94,9.96" target="#b4">[5]</ref>. Given an initial query Q orig , we retrieve a set of N documents and form a relevance model from them. We then form Q RM by wrapping a #combine around the k most likely terms from the relevance model that are not stopwords. Finally, an expanded query is formed that has the following form:</p><formula xml:id="formula_0" coords="3,109.84,631.56,152.96,9.01">#weight( λ f b Qorig (1.0 -λ f b ) QRM )</formula><p>Last year we were disappointed with our pseudorelevance feedback results, which showed little im-provement over the baseline. We found the parameters we had tuned on the WT10g collection were ill-suited for the GOV2 collection. As we will show, the parameters found by tuning on last year's topic set proved to yield better results this year.</p><p>Two of our runs made use of this technique. First, run indri05AdmfS, a title-only run, uses a dependence model query for Q orig , N = 10, k = 50, and</p><formula xml:id="formula_1" coords="3,310.61,224.04,43.21,10.39">λ f b = 0.5.</formula><p>Next, run indri05AdmfL, a title + description + narrative run, uses a dependence model query created from only the title field combined with the description and narrative portions of the topic for Q orig , N = 10, k = 50, and λ f b = 0.6.</p><p>Current and past results indicate that the effectiveness boost from pseudo-relevance feedback techniques are amplified when used in combination with the precision-enhancing dependence model. Therefore, such a combination provides a highly effective retrieval mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Document Quality Prior</head><p>Lastly, we incorporate the notion of document quality into our retrieval models in the form of a prior probability. To achieve this, we must identify document features that are predictive of quality. We focus on two features, information-to-noise ratio and collection-document distance.</p><p>Information-to-noise ratio is simply defined as the total number of terms in the documents after indexing divided by the raw size of the document. This metric has been used with some success previously <ref type="bibr" coords="3,344.73,532.66,14.58,9.96" target="#b16">[17]</ref>. The other feature, collection-document distance, is the KL-divergence between the collection and document model.</p><p>The intuition behind this feature comes from the observation that documents, such as tables or lists, are unlikely to be relevant for ad hoc queries because relevant documents typically explain or describe some topic using well-formed English sentences. Therefore, if a document differs significantly from the collection model, the quality of this document may be low. The higher the CDD is, the more unusual the word distribution of the document is, and the more likely, according to our hypothesis, that the document is of low quality.</p><p>The quality of a document is determined using a naive Bayes classifier over the two features mentioned above, with the classes defined as high and low quality. The class priors are estimated from the training data and the class conditional distributions are estimated using a non-parametric density estimation technique with a Gaussian kernel. See <ref type="bibr" coords="4,244.13,223.11,15.47,9.96" target="#b15">[16]</ref> for more details on the training data and estimation details.</p><p>The document quality prior was applied to the indri05AdmfL run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results</head><p>The results from our official runs 2 are given in Table 5. The table includes mean average precision (MAP), precision at 10 (P@10), the term smoothing parameter (µ), and the proximity feature smoothing parameter (µ prox ).</p><p>We see that once again this year the dependence model improves effectiveness. This year it (indri05Adm) provided a 7.8%, statistically significant, increase in MAP over the baseline. Last year the increase was 6.8%. This provides further evidence of the importance of term proximity features, especially for this task.</p><p>Our best title-only run (indri05AdmfS), which combined the dependence model with pseudorelevance feedback, showed a 19.5% increase in MAP over the baseline and a 10.9% increase over the dependence model only run, both of which are statistically significant. Therefore, we see that pseudo-relevance feedback was much more effective this year than last, mostly due to better parameter tuning.</p><p>Finally, the title + description + narrative run that made use of dependence modeling, pseudorelevance feedback, and the document quality prior (indri05AdmfL) yielded our best overall MAP. Despite this, the 4.0% improvement over the title-only version of the run was not statistically significant. Interestingly, if we perform the same run without applying the document quality prior we achieve a MAP of 0.4150, which is statistically better. Further analysis must be done to determine why the document quality prior hurt performance. We also continue to look at better ways of incorporating the information from the description and narrative fields, because we feel it should translate into even better effectiveness numbers than we are currently seeing.</p><p>Therefore, our runs this year show that term proximity information and pseudo-relevance feedback can significantly improve ad hoc retrieval results on a large web collection. Results using the description/narrative fields and the document quality prior are mixed, but potential areas of future interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Named Page Finding Task</head><p>Since this was the first year that UMass participated in any type of named-page finding task, our runs were highly experimental and designed to give us a better feel for the task. Following what has been successful in the past, we used both document structure and link analysis techniques.</p><p>We indexed title, mainbody, heading, and inlink fields, where mainbody is the main text of the document and inlink consists of all the anchor text pointing to the document, if any. We also investigated the use of a number of query independent document priors, such as PageRank, inlink count, url depth, and document length. Individual priors were estimated based on empirical distributions from TREC 9 and 10 relevance judgments <ref type="bibr" coords="4,473.83,605.44,9.94,9.96" target="#b3">[4]</ref>. After some preliminary experimentation, we decided to limit our focus to PageRank and inlink count priors.</p><p>We focused on two primary named-page finding models, both of which incorporate document structure and query independent features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature-Based Model</head><p>The first is a linear, feature-based model based on the work of Nallapati <ref type="bibr" coords="5,168.98,373.85,14.58,9.96" target="#b9">[10]</ref>. The scoring function has the following form:</p><formula xml:id="formula_2" coords="5,131.54,409.78,109.52,11.51">S(D; Q) = w T f(D, Q)</formula><p>where f(•, •) is a feature function that maps query/document pairs into some d dimensional space and w is a weight vector. Given a set of training data (feature vectors plus relevance judgments), we aim to estimate the w that optimizes some metric. Rather than maximizing the likelihood or margin, as was done in previous studies, we directly maximize with respect to mean reciprocal rank using a simple hill climbing approach <ref type="bibr" coords="5,172.11,532.51,9.94,9.96" target="#b5">[6]</ref>.</p><p>For our specific instantiation of this model, we used the 6 features used in <ref type="bibr" coords="5,172.39,558.22,15.47,9.96" target="#b9">[10]</ref> for each of the four document structure fields indexed, a PageRank feature, and an inlink count feature, for a total of 26 features. Our indri05Nf run makes use of this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Mixture of Language Models</head><p>The second model combines a mixture of language models approach with document priors <ref type="bibr" coords="5,247.65,665.28,10.50,9.96" target="#b3">[4,</ref><ref type="bibr" coords="5,261.96,665.28,11.60,9.96" target="#b10">11]</ref>. The following scoring function is used to rank documents:</p><formula xml:id="formula_3" coords="5,328.94,361.50,191.90,20.80">P (D|Q, Θ) ∝ P (D) q∈Q i P (i)P (q|D, i)</formula><p>where P (i) are mixture weights, P (q|D, i) represents language model component i, and P (D) is a document prior. We use one mixture component for each indexed field, estimate P (D) using PageRank and inlink count, and hand tune the mixture weights.</p><p>Both the indri05Nmp and indri05Nmpsd runs make use of this formulation, with the latter using the sequential dependence variant of Metzler's dependence model <ref type="bibr" coords="5,368.57,487.83,9.94,9.96" target="#b7">[8]</ref>. Figure <ref type="figure" coords="5,419.14,487.83,4.97,9.96">1</ref> shows an example named page finding Indri query language formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>The results from our official runs are given in Table <ref type="table" coords="5,531.29,545.72,3.87,9.96">6</ref>. As we see, the results are much lower than most of the named page finding results obtained at the 2004 Web Track. It is not clear whether or not this is caused by a fault in our formulation or if it is an artefact of the data set (documents or queries).</p><p>However, when comparing our results, we see that the feature-based model (indri05Nf) performs the worst, which is most likely caused by the fact that we trained on the WT10g named-page finding topics, which may be inappropriate. During training, the MRR values achieved were comparable to past state of the art systems. Further tests are necessary to determine why it performed so poorly. The two mixture of language model runs (indri05Nmp and indri05Nmpsd) performed better than the feature-based model. In fact, the run that made use of the dependence model was our best run, improving the MRR of 30% of the queries and degrading 10%. This indicates that term proximity information may also be important for named page finding, as well.</p><p>Since this was our first year taking part in a named page finding task, we hope to perform a detailed failure analysis to better understand the strengths and weaknesses of our approaches. In particular, we are interested in understanding how to make better use of document priors and what potential impact term proximity information, via use of the dependence model, can help for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This year we continued to investigate how to efficiently and effectively use the Indri search engine for retrieval tasks on large scale web collections. Positive results were obtained using pseudo-relevance feedback and dependence modeling for the ad hoc task, while using document structure and link analysis techniques proved effective for the named page finding task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,80.93,322.56,448.95,9.96"><head>#Figure 1 :Table 6 :</head><label>16</label><figDesc>Figure 1: Indri query formulation for topic NP604, "stellwagen bank", used for the indri05Nmpsd run.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.00,126.10,228.42,242.52"><head>Table 1 :</head><label>1</label><figDesc>Machine configuration. Six machines at a total cost of $9000 USD, purchased in early 2004.</figDesc><table coords="2,77.98,126.10,213.69,242.52"><row><cell>CPU</cell><cell cols="3">Intel Pentium 4 2.6GHz × 1</cell></row><row><cell>Bus speed</cell><cell cols="2">800MHz</cell></row><row><cell>OS</cell><cell cols="3">Linux 2.6.10 (Fedora Core 3)</cell></row><row><cell>Memory</cell><cell>2GB</cell><cell></cell></row><row><cell cols="4">Boot volume Western Digital 40G</cell></row><row><cell></cell><cell cols="3">(WD400EB-75CPF0)</cell></row><row><cell cols="4">Work volume Western Digital 250GB × 3</cell></row><row><cell></cell><cell cols="3">(WD2500JB-00EVA0)</cell></row><row><cell></cell><cell cols="2">RAID 0</cell></row><row><cell></cell><cell cols="3">Average write seek: 10.9ms</cell></row><row><cell></cell><cell cols="3">Average read seek: 8.9ms</cell></row><row><cell></cell><cell cols="3">Rotational speed: 7200rpm</cell></row><row><cell>Network</cell><cell cols="3">1Gb/s Ethernet (Intel 82540EM)</cell></row><row><cell></cell><cell>Run ID</cell><cell cols="2">Total (s) Avg (s)</cell></row><row><cell cols="2">indri05Eql</cell><cell>71700</cell><cell>1.43</cell></row><row><cell cols="2">indri05EqlD</cell><cell>24720</cell><cell>0.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,79.55,380.52,213.33,9.96"><head>Table 2 :</head><label>2</label><figDesc>Summary of official efficiency task runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,72.00,126.10,456.33,548.65"><head>Table 5 :</head><label>5</label><figDesc>Summary of official ad hoc task runs.</figDesc><table coords="4,72.00,647.03,228.51,27.71"><row><cell>2 The</cell><cell>Indri</cell><cell>queries</cell><cell>and</cell><cell>parameter</cell><cell>files</cell><cell>used</cell></row><row><cell cols="7">for our official runs are available for download at</cell></row><row><cell cols="5">http://ciir.cs.umass.edu/∼metzler/indri-tb05.tgz</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,72.00,126.10,466.80,192.18"><head>Table 4 :</head><label>4</label><figDesc>Comparison of average precision using the query likelihood (ql) baseline and the dependence model formulation (dm). The topics that are the most helped and harmed, in terms of relative change in average precision, are shown.</figDesc><table coords="5,142.88,126.10,325.38,145.85"><row><cell>Topic</cell><cell>Query</cell><cell>ql</cell><cell>dm</cell><cell>% change</cell></row><row><cell>786</cell><cell>yew trees</cell><cell cols="2">0.4108 0.3311</cell><cell>-19.4%</cell></row><row><cell>799</cell><cell>animals alzheimers research</cell><cell cols="2">0.1560 0.1301</cell><cell>-16.6%</cell></row><row><cell>798</cell><cell>massachusetts textile mills</cell><cell cols="2">0.1535 0.1297</cell><cell>-15.5%</cell></row><row><cell>773</cell><cell cols="3">pennsylvania slot machine gambling 0.5633 0.4858</cell><cell>-13.8%</cell></row><row><cell>765</cell><cell>ephedra ma huang deaths</cell><cell cols="2">0.4653 0.4044</cell><cell>-13.1%</cell></row><row><cell></cell><cell>• • •</cell><cell></cell><cell></cell><cell></cell></row><row><cell>792</cell><cell>social security means test</cell><cell cols="2">0.1232 0.1940</cell><cell>57.5%</cell></row><row><cell>785</cell><cell>ivory billed woodpecker</cell><cell cols="2">0.3924 0.7051</cell><cell>79.7%</cell></row><row><cell>778</cell><cell>golden ratio</cell><cell cols="2">0.0981 0.2302</cell><cell>135%</cell></row><row><cell>794</cell><cell>pet therapy</cell><cell cols="2">0.0650 0.3755</cell><cell>478%</cell></row><row><cell>769</cell><cell>kroll associates employees</cell><cell cols="2">0.0132 0.0955</cell><cell>623%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs>, in part by <rs type="funder">NSF</rs> grant #<rs type="grantNumber">CNS-0454018</rs>, in part by <rs type="funder">Advanced Research and Development Activity</rs> and <rs type="funder">NSF</rs> grant #<rs type="grantNumber">CCF-0205575</rs>, and in part by <rs type="funder">NSF</rs> grant #<rs type="grantNumber">IIS-0527159</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8JuceCy">
					<idno type="grant-number">CNS-0454018</idno>
				</org>
				<org type="funding" xml:id="_JQAwWQJ">
					<idno type="grant-number">CCF-0205575</idno>
				</org>
				<org type="funding" xml:id="_hPy7erB">
					<idno type="grant-number">IIS-0527159</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,92.46,149.38,208.03,9.96;7,92.48,161.34,207.98,9.96;7,92.48,173.29,207.95,9.96;7,92.48,185.24,38.69,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,192.30,161.34,108.16,9.96;7,92.48,173.29,27.80,9.96">The INQUERY retrieval system</title>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">M</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,143.18,173.29,105.38,9.96">Proceedings of DEXA-92</title>
		<meeting>DEXA-92</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,205.76,208.00,9.96;7,92.47,217.71,207.94,9.96;7,92.47,229.67,207.96,9.96;7,92.47,241.62,82.18,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,148.19,217.71,152.23,9.96;7,92.47,229.67,121.74,9.96">Shortest substring ranking (multitext experiments for trec-4)</title>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Forbes</forename><surname>Burkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,238.37,229.67,62.07,9.96;7,92.47,241.62,50.54,9.96">Proceedings of the TREC-4</title>
		<meeting>the TREC-4</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,262.12,207.99,9.96;7,92.47,274.08,207.96,9.96;7,92.48,286.04,119.42,9.96" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,259.90,262.12,40.55,9.96;7,92.47,274.08,159.51,9.96">Language Modeling for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,306.54,208.00,9.96;7,92.48,318.50,207.94,9.96;7,92.48,330.45,207.97,9.96;7,92.48,342.41,107.19,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,138.98,318.50,161.44,9.96;7,92.48,330.45,91.22,9.96">The importance of prior probabilities for entry page search</title>
		<author>
			<persName coords=""><forename type="first">Thijs</forename><surname>Wessel Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,206.55,330.45,93.90,9.96;7,92.48,342.41,18.50,9.96">Proceedings of SIGIR 2002</title>
		<meeting>SIGIR 2002</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,362.91,207.99,9.96;7,92.48,374.87,207.94,9.96;7,92.48,386.83,117.15,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,254.15,362.91,46.31,9.96;7,92.48,374.87,96.13,9.96">Relevancebased language models</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,208.50,374.87,91.92,9.96;7,92.48,386.83,18.50,9.96">Proceedings of SIGIR 2001</title>
		<meeting>SIGIR 2001</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,407.33,207.98,9.96;7,92.47,419.28,207.96,9.96;7,92.47,431.24,134.07,9.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,170.90,407.33,129.55,9.96;7,92.47,419.28,58.92,9.96">Direct maximization of rankbased metrics</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="7,92.46,451.74,207.99,9.96;7,92.48,463.71,207.96,9.96;7,92.47,475.66,207.94,9.96;7,92.48,487.61,169.88,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,263.15,451.74,37.30,9.96;7,92.48,463.71,207.96,9.96;7,92.47,475.66,98.38,9.96">Combining the language model and inference network approaches to retrieval</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,199.66,475.66,100.76,9.96;7,92.48,487.61,72.26,9.96">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="735" to="750" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,508.12,207.99,9.96;7,92.48,520.07,207.99,9.96;7,92.48,532.02,207.93,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,257.62,508.12,42.83,9.96;7,92.48,520.07,186.80,9.96">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,92.48,532.02,112.13,9.96">Proceedings of SIGIR 2005</title>
		<meeting>SIGIR 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,552.54,207.98,9.96;7,92.48,564.49,208.00,9.96;7,92.48,576.44,202.94,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,200.78,564.49,99.70,9.96;7,92.48,576.44,47.85,9.96">Indri at trec 2004: Terabyte track</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,161.35,576.44,103.49,9.96">Proceedings TREC 2004</title>
		<meeting>TREC 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,596.95,207.97,9.96;7,92.48,608.90,207.96,9.96;7,92.48,620.86,107.19,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,184.97,596.95,115.46,9.96;7,92.48,608.90,89.39,9.96">Discriminative models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,205.85,608.90,94.59,9.96;7,92.48,620.86,18.50,9.96">Proceedings of SIGIR 2004</title>
		<meeting>SIGIR 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.46,641.37,207.97,9.96;7,92.48,653.32,207.96,9.96;7,92.48,665.28,202.10,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,231.60,641.37,68.83,9.96;7,92.48,653.32,191.44,9.96">Combining document representations for known-item search</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,92.48,665.28,103.46,9.96">Proceedings SIGIR 2003</title>
		<meeting>SIGIR 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="143" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,331.07,127.29,207.96,9.96;7,331.08,139.25,207.96,9.96;7,331.08,151.21,88.34,9.96" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,413.36,127.29,121.79,9.96">Dynamic collections in indri</title>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Center for Intelligent Information Retrieval</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="7,331.07,171.12,207.98,9.96;7,331.08,183.09,207.98,9.96;7,331.08,195.04,207.97,9.96;7,331.08,207.00,207.91,9.96;7,331.08,218.95,108.60,9.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,428.19,183.09,110.88,9.96;7,331.08,195.04,169.30,9.96">Indri: A language modelbased serach engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,519.97,195.04,19.08,9.96;7,331.08,207.00,207.91,9.96;7,331.08,218.95,78.27,9.96">Proceedings of the International Conference on Intelligence Analysis</title>
		<meeting>the International Conference on Intelligence Analysis</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,331.06,238.88,208.00,9.96;7,331.08,250.83,25.72,9.96;7,372.07,250.83,166.98,9.96;7,331.08,262.79,207.97,9.96;7,331.08,274.74,63.56,9.96" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,372.07,250.83,166.98,9.96;7,331.08,262.79,28.85,9.96">Optimization strategies for complex queries</title>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,386.51,262.79,119.02,9.96">Proceedings of SIGIR 2005</title>
		<meeting>SIGIR 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="219" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,331.06,294.67,208.00,9.96;7,331.08,306.62,207.98,9.96;7,331.08,318.57,207.97,9.96;7,331.08,330.53,110.20,9.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,511.01,294.67,28.05,9.96;7,331.08,306.62,207.98,9.96;7,331.08,318.57,24.18,9.96">Evaluation of an inference network-based retrieval model</title>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,364.86,318.57,174.20,9.96;7,331.08,330.53,18.28,9.96">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="222" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,331.06,350.46,207.98,9.96;7,331.08,362.41,207.94,9.96;7,331.08,374.36,164.52,9.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,469.60,350.46,69.44,9.96;7,331.08,362.41,151.17,9.96">Document quality models for web ad hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">Yun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,503.18,362.41,35.84,9.96;7,331.08,374.36,84.04,9.96">Proceedings of CIKM 2005</title>
		<meeting>CIKM 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="7,331.06,394.29,207.96,9.96;7,331.08,406.25,207.98,9.96;7,331.08,418.20,207.95,9.96;7,331.08,430.15,160.65,9.96" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,425.19,394.29,113.84,9.96;7,331.08,406.25,207.98,9.96;7,331.08,418.20,132.36,9.96">Incorporating quality metrics in centralized/distributed information retrieval on the world wide web</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gauch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,489.46,418.20,49.57,9.96;7,331.08,430.15,62.00,9.96">Proceedings of SIGIR 2000</title>
		<meeting>SIGIR 2000</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="288" to="295" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
