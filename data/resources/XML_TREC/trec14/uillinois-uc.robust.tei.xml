<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,205.48,107.14,184.23,12.91;1,151.64,125.07,291.89,12.91">An Axiomatic Approach to IR -UIUC TREC 2005 Robust Track Experiments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,218.50,164.56,44.66,10.76"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.37,164.56,85.32,10.76"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,205.48,107.14,184.23,12.91;1,151.64,125.07,291.89,12.91">An Axiomatic Approach to IR -UIUC TREC 2005 Robust Track Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">058E960D59E0134A32D4E017B85C05B6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report our experiments in the TREC 2005 Robust Track. Our focus is to explore the use of a new axiomatic approach to information retrieval.</p><p>Most existing retrieval models make the assumption that terms are independent of each other. Although such simplifying assumption has facilitated the construction of successful retrieval systems, the assumption is not true; words are related by use, and their similarity of occurrence in documents can reflect underlying semantic relations between terms. Our new method aims at incorporating term dependency relations into the axiomatic retrieval model in a natural way. In this paper, we describe the method and present analysis of our Robust-2005 evaluation results. The results show that the proposed method works equally well as the KL-divergence retrieval model with a mixture model feedback method. The performance can be further improved by using the external resources such as Google.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In our recent study <ref type="bibr" coords="1,144.16,523.97,10.58,8.97" target="#b2">[3]</ref>, we proposed an axiomatic approach to information retrieval, where the relevance is modeled by term-based constraints. Several retrieval functions were derived by using this approach. It has been shown that the performance of the derived function is less sensitive to the parameter setting than the existing retrieval functions with comparable optimal performance; using a fixed parameter value can often achieve near-optimal performance in many test sets. It is thus interesting to evaluate such a new retrieval function in the context of the robust track.</p><p>As in most existing retrieval functions, one drawback of the derived new retrieval function is that it makes the assumption that terms are independent of each other. Although such simplifying assumption has facilitated the construction of successful retrieval systems, the assumption is not true; words are related by use, and their similarity of occurrence in documents can reflect underlying semantic relations between terms. Thus, it would be interesting to study how to naturally incorporate such semantic relations into the axiomatic retrieval model.</p><p>In this paper, we explain how to extend the existing axiomatic model to take into consideration of the term semantic relations and demonstrate that such extension can also be regarded as a way to do feedback in the axiomatic framework. In both our preliminary experiments with last year's data and the official Robust05 experiments, this method has worked very well. As a pseudo feedback method, it works equally well as the mixture language model feedback method, but it can achieve much better performance when using external resources, such as Google.</p><p>The paper is organized as follows. In Section 2, we present the general idea and our new extension for axiomatic approach to information retrieval. In Section 3, we discuss how to implement the proposed extension. In Section 4, we analyze the results of our experiments on Robust-2004 and Robust-2005 data. Finally, we conclude with Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Axiomatic Approach to Information Retrieval</head><p>The basic idea of this axiomatic approach is to search in a space of candidate retrieval functions for one that can satisfy a set of reasonable retrieval constraints. To define an axiomatic framework for information retrieval, we need to define (1) a search space of possible retrieval functions; and (2) a set of retrieval constraints that any reasonable retrieval formula should satisfy. The assumption is that if a retrieval function satisfies all our constraints, the function would likely be effective empirically.</p><p>Our recent study <ref type="bibr" coords="1,389.76,656.38,11.62,8.97" target="#b1">[2]</ref> demonstrated that the retrieval constraints can be defined as formalized retrieval heuristics. And it demonstrates that the empirical performance of a retrieval function is tightly related to how well it satisfies these constraints. It is also shown that none of the analyzed retrieval formula can satisfy all the proposed constraints unconditionally. In this paper, we use the constraints defined in the previous work <ref type="bibr" coords="2,137.65,99.06,11.62,8.97" target="#b2">[3]</ref> and focus on the other important component in the framework (i.e. function space).</p><p>The function space must be large enough to include effective retrieval functions, yet small enough for search. So there is clearly a tradeoff. Following the current retrieval models, we assume that both the documents and the queries are a "bag of terms". Formally, let T be the set of all terms. Let query Q = {q 1 , ..., q n } and document D = {d 1 , ..., d m } be two bags of terms, where q i , d i ∈ T , and it is possible that q i = q j and d i = d j even if i = j. Our goal is to define a scoring function S(Q, D) ∈ . To help us search through this function space efficiently and define meaningful constraints on the retrieval functions, we proposed to define a retrieval function inductively <ref type="bibr" coords="2,249.32,254.49,10.58,8.97" target="#b2">[3]</ref>. Such inductive definition allows us to decompose a retrieval function into the following three subcomponent functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S({q}</head><formula xml:id="formula_0" coords="2,58.70,298.59,219.08,40.35">, {d}) = f (q, d) S(Q ∪ {q}, D) = g(S(Q, D), S({q}, D), q, Q, D) S(Q, D ∪ {d}) = h(S(Q, D), S(Q, {d}), d, Q, D)</formula><p>Function f gives the score of a one-term document and a one-term query and is referred to as the Primitive weighting function. Function g describes the score change when we add a term to a query, and is called the Query growth function. When a new term q is added to a query Q, the score of any document for the new query (i.e. S(Q ∪ {q}, D)) would be mainly determined by the score of the document for the old query (i.e. S(Q, D)), the score of the document for the added query term (i.e. S({q}, D)), and any possible score adjustment determined by D, Q and q. Similarly, function h describes the score change when we add a term to a document, and is called the Document growth function. Clearly, the performance of the axiomatic retrieval model depends on how we instantiate the three component functions. We discussed several possibilities and derived six well-performed retrieval formulas in the previous work <ref type="bibr" coords="2,271.99,531.33,10.58,8.97" target="#b2">[3]</ref>.</p><p>However, one drawback of the derived new retrieval function is that it makes the assumption that terms are independent of each other. The Primitive weighting function was defined as</p><formula xml:id="formula_1" coords="2,50.11,596.89,247.75,22.41">S({q}, {d}) = f (q, d) = weight(q) = weight(d) q = d penalty(q, d) q = d</formula><p>It rewards the document with a score of weight(q) when d matches q and gives it a penalty score of penalty(q, d) otherwise. Even if d is a synonym of q, the retrieval function still penalizes the documents containing d. In other words, the semantic relations between terms are ignored. Although such simplifying assumption has facilitated the construction of successful retrieval systems, the assumption is not true;</p><p>words are related by use, and their similarity of occurrence in documents can reflect underlying semantic relations between terms. For example, suppose we have a query with a term "car". Intuitively, a single-term document with a term "vehicle" should have a better score than one with a term "software", even though none of these documents has an exact match with the query term "car". To break the above limitation, we explored how to incorporate term dependency relations into the axiomatic retrieval model in a principled way. We can re-define the Primitive weighting function in a more general way as</p><formula xml:id="formula_2" coords="2,333.80,215.96,186.37,10.46">S(Q, D) = f (q, d) = weight(q) × sim(q, d).</formula><p>where sim(q, d) is a function that measures the similarity between the two terms q and d , 0 ≤ sim(q, d) ≤ 1 and sim(d, d) = 1. Such definition would reward the documents not only based on the matching query terms, but also the terms that are related to any query term. In this paper, we adopt the normalized mutual information metric for similarity measurement, which is defined as</p><formula xml:id="formula_3" coords="2,364.27,331.55,124.24,24.93">sim(t 1 , t 2 ) = M I(t 1 , t 2 ) M I(t 1 , t 1 ) × 1 λ</formula><p>where λ is a constant and P r(t) is a unigram probability for term t, P r(t 1 , t 2 ) is the joint probabilities for term t 1 and t 2 to co-occur in the same document, and P r(t) is the probability for term t not to occur in a document. All the probabilities can be computed by simply counting the document frequency.</p><formula xml:id="formula_4" coords="2,318.44,392.13,87.84,11.35">M I(t 1 , t 2 ) = P r(</formula><p>Note that the mutual information can be computed over either internal resources (e.g., the target collection itself) or external resource (e.g., the web data) or both. Therefore, the axiomatic framework allows us to exploit the external resources in a more principle way compared with the existing retrieval models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementation Issues</head><p>In this section, we focus on how to efficiently implement the extension proposed in the previous section.</p><p>Based on the re-defined primitive weighting function, we need to compute the similarity between every term in the document and every term in the query. So, the computational cost is high. To solve this problem, we can focus only on the terms that are most similar to a query term. Therefore, the Primitive weighting function becomes</p><formula xml:id="formula_5" coords="3,50.11,154.91,255.45,26.30">S({q}, {d}) = weight(q) • M I(q,d) M I(q,q) • 1 λ d ∈ T opKSim(q) 0 otherwise</formula><p>where λ is a constant and T opKSim(q) is the set of K most similar terms to the term q according to the function sim().</p><p>As discussed in <ref type="bibr" coords="3,127.12,231.15,10.58,8.97" target="#b2">[3]</ref>, there are several ways to instantiate the three component functions. In this paper, we used the following instantiations.</p><formula xml:id="formula_6" coords="3,50.11,274.82,240.66,82.23">S(Q ∪ {q}, D) = S(Q, D) + S(q, D) S(Q, D ∪ {d}) = t∈D∩Q-{d} S(Q, {t})λ(|D| + 1, C D t ) +S(Q, {d}) • λ(|D| + 1, C D d + 1) weight(q) = ( N df (q) ) 0.35</formula><p>where λ(x, y) = y ( s avdl x+s)+y , 0 ≤ s ≤ 1, N is the number of documents in the collection, df (t) is the document frequency of t, and C D t is the term count of t in D. Based on the above instantiations, it is not hard to prove that such a way to incorporate the term dependence information can also be regarded as the following way to do pseudo/relevance feedback.</p><p>1. Find the top K = 1000 most similar terms for every query term based on sim.</p><p>2. Pool all the top K similar terms for all the query terms together.</p><p>3. Exclude the terms that are only related to one query term if the query length is larger than 2.</p><p>4. Add a certain number of terms from the pool to the original query. If all the terms are excluded in the Step 3, then no term will be added to the original query.</p><p>5. Compute the weight of the added terms based on the redefined primitive weighting function.</p><p>Step 3 is used to guarantee that the added terms will not be biased by the related terms of one query term. In Step 1, the similarity between terms can be computed over any reasonable resources. We consider the following two choices. First, for each query, we use the original axiomatic function to rank the documents and pool the top documents together as a resource. This method will be referred to as pseudo </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>There were two sub-tasks in this year and last year's Robust track: (1) improve the effectiveness for topics that are known to be difficult; (2) predict the query difficulty. For the first task, we only focus on title-only queries, since they are more similar to the actual queries from the web users. For the second task, we ranked all the topics based on the average relevance score returned by the system and the performance of our submitted runs is around the average among all the runs in this year's track.</p><p>Our focus is to improve the effectiveness for title-only queries, so we will only present the experiment results for these queries. In our experiments, we used the Web as an external resource. The idea of using web as external resources to improve the performance is not new. Many previous works in Robust track are along this line <ref type="bibr" coords="3,492.79,453.23,10.79,8.97" target="#b6">[7,</ref><ref type="bibr" coords="3,505.66,453.23,7.47,8.97" target="#b5">6,</ref><ref type="bibr" coords="3,515.22,453.23,7.47,8.97" target="#b3">4,</ref><ref type="bibr" coords="3,524.77,453.23,7.47,8.97" target="#b0">1,</ref><ref type="bibr" coords="3,534.32,453.23,7.19,8.97" target="#b4">5]</ref>. But unlike some of them <ref type="bibr" coords="3,415.04,465.19,10.79,8.97" target="#b3">[4,</ref><ref type="bibr" coords="3,429.38,465.19,7.19,8.97" target="#b4">5]</ref>, we did not use any NLP techniques to construct the queries for Google.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preliminary Experiments</head><p>In the preliminary experiments, we compared the performance of pseudo/web-based feedback methods for KLdivergence <ref type="bibr" coords="3,354.81,548.78,11.62,8.97" target="#b7">[8]</ref> and F2EXP <ref type="bibr" coords="3,418.65,548.78,12.57,8.97" target="#b2">[3]</ref>(one retrieval function in the axiomatic retrieval model). In order to compare the performance for a query set over different collections, we tested the robust05 topics over robust2004 data collection and summarized the results in Table <ref type="table" coords="3,437.83,596.60,3.74,8.97" target="#tab_1">1</ref>.</p><p>There is no principled approach to use external resources (i.e. Web-based FB) in KL-divergence method. In our experiment, we first used mixture langauge model feedback method to generate an expanded query over the top K Google snippets and ranked the documents in the target collection based on the expanded query.</p><p>As seen from the table, the pseudo feedback method in axiomatic framework works equally well as the mixture language model feedback method, but it can achieve much </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments on Robust 2005</head><p>We conducted three sets of experiments on Robust2005 data set.</p><p>First, we examined the parameter sensitivity for the proposed method. As mentioned in Section 3, there are three major parameters in the feedback method for axiomatic framework. The parameters are (1)the number of top documents to be included in the resource; (2) the number of terms to be added to the query; (3) λ in the primitive weighting function. Our preliminary experiments show that the optimal value of λ for pseudo feedback method is 0.5 and the optimal value of λ for web-based feedback method is 0.3. Table <ref type="table" coords="4,93.69,536.31,4.98,8.97" target="#tab_3">3</ref> summarizes the performance (based on MAP) when we change the value for the other two parameters. It shows that the performance is sensitive to the parameter values and the performance is better when the number of document is equal to 20.</p><p>Second, we compared the performance of pseudo feedback methods between KL-Divergence and F2EXP. Table <ref type="table" coords="4,281.38,608.56,4.98,8.97" target="#tab_2">2</ref> summarizes the results when the number of feedback documents is 20. One interesting observation is that the performance of AX+PFB is better than KL+PFB based on MAP, while the performance is worse based on gMAP(i.e. geometric MAP <ref type="bibr" coords="4,103.31,668.33,10.45,8.97" target="#b6">[7]</ref>). It might indicate that AX+PFB tends to improve the performance for easy topics instead of difficult ones. But we need to do more experiments and analysis in order to further clarify this. Finally, we report the performance of web-based feedback method in axiomatic framework. Table <ref type="table" coords="4,489.81,275.55,4.98,8.97">4</ref> summarizes the results. Similar to preliminary experiment results, the web-based feedback method can improve the performance significantly. And the performance is sensitive to both the value of λ and the number of added terms. Further performance improvement can be achieved by further expanding the queries, already expanded with the web resource, with a second pseudo-feedback over the target collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4. Experiment Results of Web-based FB in Axiomatic Framework on Robust05</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we studied how to extend the existing axiomatic model to incorporate the term dependency relations and demonstrated that such extension can also be regarded as a way to do the feedback in the axiomatic framework. In both our preliminary experiments with last year's data and the official Robust05 experiments, this method has worked very well. As a pseudo feedback method, it works equally well as the mixture language model feedback method, but it can achieve much better performance when using external resources, such as Google.</p><p>For the future work, we plan to do more experiments on other data sets to find out whether the proposed extension could work consistently well. We will also explore how to tune the parameters for obtaining the optimal results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,472.08,118.28,21.59,8.97;4,508.94,118.28,26.57,8.97;4,343.75,130.63,85.78,8.97;4,469.18,130.63,66.75,8.97;4,318.05,141.32,217.88,10.63;4,318.05,153.28,217.88,10.63;4,318.05,165.23,217.88,10.63;4,318.05,177.58,217.88,10.63;4,344.20,189.54,84.89,10.63;4,469.18,191.20,66.75,8.97;4,341.71,201.49,89.88,10.63;4,469.18,203.15,66.75,8.97;4,318.05,215.84,217.88,10.63;4,347.58,229.46,78.12,8.97;4,469.18,229.46,66.75,8.97"><head></head><label></label><figDesc>= 0.3, #Term=20) 0.2677 0.1884 UIUCrAXt2 (λ = 0.5, #Term=20) 0.2592 0.1827 UIUCrAXt3 (λ = 0.8, #Term=20) 0.2460 0.1741 UIUCrAXt1 (λ = 0.3, #Term=20) 0.2677 0.1884 (λ = 0.3,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,308.87,86.06,236.26,157.06"><head>Table 1 . Performance Comparison on Ro- bust04</head><label>1</label><figDesc>Second, for each query, we use the results returned by Google and pool the top snippets together as a resource. This method will be referred as web-based feedback in axiomatic framework.</figDesc><table coords="3,308.87,118.28,228.16,88.97"><row><cell></cell><cell cols="2">KL-Divergence</cell><cell cols="2">F2EXP</cell></row><row><cell></cell><cell>MAP</cell><cell>gMAP</cell><cell>MAP</cell><cell>gMAP</cell></row><row><cell>No FB</cell><cell cols="4">0.0955 0.0591 0.0973 0.0629</cell></row><row><cell>Pseudo FB</cell><cell cols="4">0.1010 0.0609 0.1173 0.0678</cell></row><row><cell cols="5">Web-based FB 0.1047 0.0634 0.1544 0.0964</cell></row><row><cell cols="3">feedback in axiomatic framework.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,58.09,86.06,239.53,95.46"><head>Table 2 . Performance Comparison (PFB) on Robust05</head><label>2</label><figDesc></figDesc><table coords="4,58.09,118.26,239.53,63.26"><row><cell></cell><cell cols="2">KL-Divergence</cell><cell cols="2">F2EXP</cell></row><row><cell></cell><cell>MAP</cell><cell>gMAP</cell><cell>MAP</cell><cell>gMAP</cell></row><row><cell>No FB</cell><cell cols="2">0.1942 0.1275</cell><cell cols="2">0.1924 0.1223</cell></row><row><cell>Pseudo FB (#Term=20)</cell><cell cols="2">0.2389 0.1398</cell><cell cols="2">0.2582 0.1235</cell></row><row><cell>Pseudo FB (#Term=50)</cell><cell cols="2">0.2550 0.1465</cell><cell cols="2">0.2629 0.1272</cell></row><row><cell>Pseudo FB (#Term=100)</cell><cell cols="2">0.2606 0.1523</cell><cell cols="2">0.2639 0.1279</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,50.11,211.31,236.25,149.02"><head>Table 3 . Parameter Sensitivity of PFB in Ax- iomatic Framework on Robust05</head><label>3</label><figDesc></figDesc><table coords="4,50.11,243.53,236.25,116.81"><row><cell cols="4">#Term=20 #Term=50 #Term=100</cell></row><row><cell>#Doc=20</cell><cell>0.2582</cell><cell>0.2629</cell><cell>0.2639</cell></row><row><cell>#Doc=100</cell><cell>0.2401</cell><cell>0.2452</cell><cell>0.2468</cell></row><row><cell>#Doc=500</cell><cell>0.2103</cell><cell>0.2137</cell><cell>0.2132</cell></row><row><cell cols="4">better performance when using external resources, such as</cell></row><row><cell cols="4">Google. It demonstrates that the axiomatic framework can</cell></row><row><cell cols="4">offer a more principled and effective way to incorporate the</cell></row><row><cell>external resources.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,325.46,623.97,219.66,8.97;4,325.46,635.93,219.66,8.97;4,325.46,647.88,212.26,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,498.77,623.97,46.35,8.97;4,325.46,635.93,98.74,8.97">Fondazione ugo bordoni at trec 2004</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,445.98,635.93,99.14,8.97;4,325.46,647.88,182.50,8.97">Proceedings of the Thirteenth Text REtrieval Conference (TREC2004)</title>
		<meeting>the Thirteenth Text REtrieval Conference (TREC2004)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,325.46,668.33,219.66,8.97;4,325.46,680.29,219.65,8.97;4,325.46,692.24,219.66,8.97;4,325.46,704.19,124.10,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,447.91,668.33,97.21,8.97;4,325.46,680.29,102.88,8.97">A formal study of information retrieval heuristics</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,447.60,680.29,97.52,8.97;4,325.46,692.24,219.66,8.97;4,325.46,704.19,95.31,8.97">Proceedings of the 2004 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 2004 ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,66.71,75.16,219.65,8.97;5,66.71,87.11,219.66,8.97;5,66.71,99.06,219.66,8.97;5,66.71,111.03,155.92,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,157.00,75.16,129.36,8.97;5,66.71,87.11,128.68,8.97">An exploration of axiomatic approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,212.55,87.11,73.81,8.97;5,66.71,99.06,219.66,8.97;5,66.71,111.03,127.13,8.97">Proceedings of the 2005 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 2005 ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,66.71,130.95,219.65,8.97;5,66.71,142.91,219.67,8.97;5,66.71,154.86,126.36,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,122.27,130.95,164.09,8.97;5,66.71,142.91,18.22,8.97">Trec2004 robust track expeirments using pircs</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,105.73,142.91,180.64,8.97;5,66.71,154.86,45.57,8.97">Proceedings of the Thirteenth Text REtrieval Conference</title>
		<meeting>the Thirteenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>TREC2004</note>
</biblStruct>

<biblStruct coords="5,66.71,174.79,219.66,8.97;5,66.71,186.74,219.66,8.97;5,66.71,198.69,78.31,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,181.82,174.79,64.82,8.97">Uic at trec-2004</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,268.55,174.79,17.82,8.97;5,66.71,186.74,219.66,8.97">Proceedings of the Thirteenth Text REtrieval Conference</title>
		<meeting>the Thirteenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>TREC2004</note>
</biblStruct>

<biblStruct coords="5,66.71,218.62,219.65,8.97;5,66.71,230.57,219.65,8.97;5,66.71,242.54,154.71,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,137.76,218.62,148.59,8.97;5,66.71,230.57,47.39,8.97">Overview of the trec 2003 robust retrieval track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,137.57,230.57,148.79,8.97;5,66.71,242.54,124.96,8.97">Proceedings of the Twelfth Text REtrieval Conference (TREC2003)</title>
		<meeting>the Twelfth Text REtrieval Conference (TREC2003)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,66.71,262.46,219.65,8.97;5,66.71,274.41,219.65,8.97;5,66.71,286.37,154.71,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,137.76,262.46,148.59,8.97;5,66.71,274.41,46.18,8.97">Overview of the trec 2004 robust retrieval track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,131.27,274.41,155.09,8.97;5,66.71,286.37,73.92,8.97">Proceedings of the Thirteenth Text REtrieval Conference</title>
		<meeting>the Thirteenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,66.71,306.29,219.65,8.97;5,66.71,318.25,219.65,8.97;5,66.71,330.20,219.66,8.97;5,66.71,342.15,168.24,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,168.54,306.29,117.82,8.97;5,66.71,318.25,121.24,8.97">Model-based feedback in the KL-divergence retrieval model</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,209.01,318.25,77.35,8.97;5,66.71,330.20,219.66,8.97;5,66.71,342.15,74.02,8.97">Tenth International Conference on Information and Knowledge Management (CIKM 2001)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
