<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,77.04,91.00,442.26,12.93">Classifying Biomedical Articles by Making Localized Decisions</title>
				<funder ref="#_7WkVpbk #_PHbtpq3">
					<orgName type="full">NIH/NLM</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,55.44,143.78,70.04,8.88;1,125.52,142.21,1.54,6.40"><forename type="first">Thomas</forename><surname>Brow</surname></persName>
							<email>tebrow@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Medical Informatics</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,55.44,167.66,66.44,8.88;1,121.92,166.09,1.54,6.40"><forename type="first">Mark</forename><surname>Craven</surname></persName>
							<email>craven@biostat.wisc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Medical Informatics</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,77.04,91.00,442.26,12.93">Classifying Biomedical Articles by Making Localized Decisions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DBB4D0637D5F6B1CC8C4CDD735D2746C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a system developed for the Categorization task of the Text Retrieval Conference (TREC) 2005 Genomics track, and experiments we conducted in the process of developing our system. Our research effort for this task explored the hypothesis that more accurate predictions could be achieved by considering only selected passages in the documents being processed. We investigated methods that involve (i) basing classifications on selected passages from test articles, and (ii) adjusting the classifier training process such that certain putatively relevant passages affect the learned model more than other passages. Whereas the first approach was effective at improving predictive accuracy in our experiments, the latter approach was not.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There are now more than 700 on-line, publicly available databases focusing on some aspect of molecular biology <ref type="bibr" coords="1,89.96,519.45,71.42,9.96" target="#b0">(Bateman, 2005)</ref>. Most of these databases require a high degree of continual effort by scientists to curate them. For example, most of the modelorganism databases, such as the Mouse Genome Informatics (MGI) databases <ref type="bibr" coords="1,165.38,567.21,84.75,9.96" target="#b3">(Eppig et al., 2005)</ref>, employ a team of PhD-level biologists to read the scientific literature and then manually enter relevant information into the databases. The Categorization task of the 2005 TREC Genomics track was aimed at investigating methods that might help these human curators filter the scientific literature to identify articles relevant to the curation process. In this paper we describe the approaches we investigated in the course developing a Appears in Proceedings of the 2005 Text Retrieval Conference (TREC).</p><p>system for the Categorization task.</p><p>The Categorization task involves making the following decisions. Given the full text of a scientific article, a system should decide whether the article would support curation in each the following four categories:</p><p>(1) Gene Ontology annotation (The Gene Ontology <ref type="bibr" coords="1,307.44,353.13,82.58,9.96">Consortium, 2000)</ref>, (2) the Mouse Tumor Biology Database (3) the Gene Expression Database, and (4) the Alleles and Phenotypes category of the Mouse Genome Database. Since the categories are not mutually exclusive, an article may be classified into any number of categories between zero and four. The training set consists of 5,837 articles from Journal of Biological Chemistry, Journal of Cell Biology, and Proceedings of the National Academy of Science. The test set consists of 6,403 articles from the same journals.</p><p>Our research effort for this task is based on the conjecture that, for most of these curation decisions, only a fraction of each given document is relevant to the classification. Therefore, we investigate methods that involve (i) basing classifications on selected passages from test articles, and (ii) adjusting the classifier training process such that certain putatively relevant passages affect the learned model more than other passages. We consider as a baseline a method that makes classifications by considering the entirety of each article, and is trained by equally weighting all parts of all training articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Making Classifications with Selected Paragraphs</head><p>In this section, we present our approach and experiments for categorizing articles by having the classifier base its decisions only on selected passages from a test article. The hypothesis motivating this line of research is that we can attain more accurate classifications by making such "localized" decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Methods</head><p>Our approach for classifying an article using selected paragraphs involves four steps:</p><p>1. The article is segmented into paragraphs using SGML tags and regular expressions.</p><p>2. The content of each paragraph is described using a bag-of-words representation.</p><p>3. A learned statistical model is used to compute the probability that each paragraph belongs to the positive class.</p><p>4. From a subset of these paragraph-level probabilities, the probability of the positive class for the document as a whole is computed.</p><p>After segmenting a given article into paragraphs, each paragraph is processed in the following manner. We strip away all remaining SGML tags and replace Unicode entities by ASCII equivalents or representative strings. The resulting plain text is tokenized using a regular expression that allows words to include hyphens and numeric characters. To reduce the size of our vocabulary, we ignore case and remove stopwords. We then represent each paragraph using a bagof-words representation.</p><p>We train our classification models using a maximum entropy method <ref type="bibr" coords="2,126.66,485.13,84.37,9.96" target="#b5">(Nigam et al., 1999)</ref>. In these models, the probability of class c for document d is defined as:</p><formula xml:id="formula_0" coords="2,105.12,518.25,134.49,27.37">P (c|d) = 1 Z d exp( i λ i f i (d, c))</formula><p>where Z d is a normalizing factor over all possible labelings of d (to ensure a proper probability in the range [0,1]), and each λ i is a real-valued weight associated with feature f i .</p><p>The key idea of maximum entropy methods is that the model should prefer the most uniform distribution that satisfies given constraints. In this case, maximum entropy enforces the constraint that the model has the same expected value for each feature as does the training set:</p><formula xml:id="formula_1" coords="2,76.32,692.37,193.29,27.61">1 |D| d∈D f i (d, c d ) = 1 |D| d∈D c P (c|d)f i (d, c).</formula><p>Here, D represents the training set, c d is the class of document d, and P (c|d) represents the model's estimation of the conditional probability of class c given document d. For training, we use a quasi-Newton method called L-BFGS that converges to a global optimum. Since the classes of interest are not mutually exclusive, we train a separate model for each class.</p><p>We hypothesize that, in any given document, some paragraphs contain more information pertaining to the correct labeling of the document than do others. We investigate this possibility by considering systems that select the most informative paragraphs from full-text articles and make document-level predictions based on these selections. The metric we use for identifying informative paragraphs is the posterior probability for the positive class predicted by our maximum entropy models. In particular, we consider an approach that classifies articles by considering the top-n paragraphs, ranked according to the posterior probability of the positive class. The estimated probability that an article belongs to the positive class, under this approach, is the average probability across these top-n paragraphs.</p><p>Our implementation was written in Java and Perl, and included classes from the MALLET library <ref type="bibr" coords="2,505.66,356.49,30.62,9.96;2,307.44,368.49,45.54,9.96" target="#b4">(McCallum, 2002)</ref>. MALLET implements the maximum entropy classification model as well as several of the preprocessing pipelines we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Empirical Evaluation</head><p>We evaluate our approach using four-fold crossvalidation within the training set. For each of the classification tasks, we consider the following three approaches:</p><p>• A baseline approach that involves training and classifying articles without any regard for paragraph boundaries. Specifically, documents are not segmented in this approach, and document-level class probabilities are computed in the same manner as paragraph-level class probabilities in the other approaches. We refer to this baseline as the Fulltext approach.</p><p>• An approach that trains paragraph-level models and classifies a test article using the Top-n procedure described above. For most experiments reported here, n = 5.</p><p>• An approach that operates similarly, but that sets n = L, where L is the number of paragraphs in a given test document. In other words, these models consider the classification decisions made for all paragraphs in a given test document. We refer to this as the All paragraphs method.</p><p>As in the official TREC evaluation, we measure classifier performance by computing utility, defined as</p><formula xml:id="formula_2" coords="3,99.84,358.05,145.18,10.33">U raw = (u r × T P ) + (u nr × F P ),</formula><p>where T P is the count of true positives and F P is the count of false positives. The coefficients u r and u nr are category-specific weights (or "relative utilities") chosen to account for the varying number of positive instances across categories. These weights are defined as follows:</p><formula xml:id="formula_3" coords="3,100.08,464.71,144.60,22.74">u nr = -1, u r = AN AP ,</formula><p>where AN and AP are the total counts of actual negative and positive instances, respectively.</p><p>Figure <ref type="figure" coords="3,86.61,526.17,5.03,9.96" target="#fig_0">1</ref> shows the measured utility of these three approaches for all four classification tasks. The Top-n classifiers provide better utility than the baseline models for all tasks. This result supports our hypothesis. The results for the All-paragraphs control (Top-n with n = L) indicate that success of the Top-n method is due to its focus on a small number of paragraphs, rather than some other aspect of its paragraph-based representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Making Classifications using Paragraph Distributions</head><p>Representing the collection of paragraph-level probabilities by their mean discards information about the distribution of those probabilities. Analysis of the training data suggests that the shape of this distribution might be informative in predicting class labels. Figure <ref type="figure" coords="3,374.24,309.21,5.03,9.96" target="#fig_2">2</ref> compares the average distribution of paragraph-level probabilities in positive documents against the average distribution in negative documents for the Allele task. The graph on the left illustrates that these average distributions differ in shape as well as mean. The graph on the right shows the plain contrast that appears when we plot distributions for only the top five paragraphs, as considered in the previous section. We hypothesize that using a representation of this entire distribution for a given documents may be more predictive of class labels than the Top-n approach presented in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Methods</head><p>To try to take advantage of this difference in distributions for positive and negative articles, we train a secondary statistical model to discriminate between the two. The feature vector for this "metaclassifier" is generated by using an integer-valued feature to represent each bin in a discrete representation of the distribution. The value of the feature is the count of paragraphs that have probabilities in the corresponding interval. The metaclassifier models, like the paragraph classification models, are trained using a maximum entropy approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Empirical Evaluation</head><p>Figure <ref type="figure" coords="3,340.05,647.85,5.03,9.96" target="#fig_1">3</ref> compares the performance of this strategy, with and without paragraph selection, to those of the baseline and the simple mean approach of the previous section. We consider two variants of the metaclassifier: one that represents the distribution of all paragraphs in a given document, and one that repre- sents the distribution of only the top-four paragraphs as determined by a ranking on the predicted posterior probability of the positive class. The results in Figure <ref type="figure" coords="4,86.97,316.65,5.03,9.96" target="#fig_1">3</ref> show that the distribution metaclassifiers do not result in higher utilities than the simple Top-n approach for any of the tasks. This result suggests that the metaclassifier models are susceptible to overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Training Classifiers with Selected Paragraphs</head><p>So far, we have discussed making localized decisions by focusing the models' attention on important passages during classification. Another way of localizing the classifier is to focus the models' attention to important passages during training. One way of accomplishing this is by employing an expectation-maximization (EM) algorithm <ref type="bibr" coords="4,129.07,486.09,101.64,9.96" target="#b1">(Dempster et al., 1977)</ref>, which is an approach to finding likelihood estimates for parameters in probabilistic settings with hidden variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Methods</head><p>In our setting, the hidden variables represent the extent to which individual paragraphs should be treated as a positive instances during training. Our approach employs one hidden variable for each paragraph in a positive document. We assume that all paragraphs in a negative document really are negative, and thus there are no hidden variables for these cases.</p><p>In the E-step, we use the current model to estimate the probability that each paragraph in a given document is positive (i.e., contains text relevant to the document being positive). Formally, we compute:</p><formula xml:id="formula_4" coords="4,120.36,702.17,104.16,12.17">z ij = P (c ij = 1|d ij ; θ (t) )</formula><p>where z ij is the hidden variable associated with the jth paragraph in the ith positive document, c ij is the unknown class label of the paragraph (1 for positive, 0 for negative), d ij represents the text of the paragraph, and θ (t) represents the model parameters on the tth iteration of the EM procedure.</p><p>Occasionally, there may be no paragraphs that appear positive for a given training document that is known to be positive. To test and correct for this, we sum the model's output for all paragraphs in a document. If the sum is less than some threshold k, we re-normalize weights to sum to k. In other words, we enforce the constraint:</p><formula xml:id="formula_5" coords="4,384.36,451.77,80.14,20.65">∀ i∈pos j z ij ≥ k.</formula><p>The assumption here is that a positive document has at least k paragraphs that are relevant to its class. For the experiments reported here, we set k = 2.</p><p>In the M-step, the classifier is re-trained using paragraph instances subject to the newly estimated weights. This entails the following optimization:</p><formula xml:id="formula_6" coords="4,307.44,568.61,237.95,91.49">θ (t+1) = arg max θ di∈pos j z ij log(P (c ij = 1|θ)P (d ij |c ij = 1; θ)) + (1 -z ij ) log(P (c ij = 0|θ)P (d ij |c ij = 0; θ)) + di∈neg j log(P (c ij = 0|θ)P (d ij |c ij = 0; θ)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Empirical Evaluation</head><p>We conduct an experiment in which we evaluate models trained with this EM approach using, as before, a four-fold cross-validation methodology. The models are initialized by training with the standard maximum entropy approach described in Section 2. Before each subsequent iteration of EM, the classifiers are applied to the test fold, using both the Fulltext and Top-n classification methods, as described in Section 2. For these experiments, n = 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalized</head><p>Figure <ref type="figure" coords="5,88.78,426.57,5.03,9.96" target="#fig_3">4</ref> shows the classification utility realized by these two classification methods as a function of the number of EM training iterations. Utility generally drops immediately after EM re-weighting begins, and while subsequent iterations show gradual improvement, the models appear to converge before reaching even the initial model's utility. This result indicates that the EM algorithm, as used here, either is not effective at identifying the most relevant paragraphs or that there is no benefit in doing so during training. We also note that the Top-n method of evaluation outperforms the Fulltext method in this context as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Official TREC Evaluation Results</head><p>To generate our final classifications for a given category, we select those documents whose probability for the positive label exceeds a fixed threshold. We choose this threshold for each category by averaging the five thresholds that yield the greatest normalized utility from our four-fold cross-validated experiments.</p><p>We submitted runs from the Top-n classification approach described in Section 2 as an official run along with the metaclassifier variation described in Section 3 and the baseline Fulltext system. Table <ref type="table" coords="5,488.60,241.17,5.03,9.96">5</ref> shows the results of these methods as well as the minimum, median, and maximum scores from the official task evaluation. These results are consistent with the results of the cross-validation experiments reported in Sections 2 and 3 in that the Top-5 models outperform the Fulltext and Metaclassifier models. The utility achieved by our Top-5 models is close to the median score across all four tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and Future Work</head><p>We investigated three hypotheses in our efforts for the Categorization task of the TREC Genomics track. The first hypothesis, that we could get more accurate classifications by basing classification decisions on selected paragraphs in test articles, was well supported by our experiments. The second hypothesis was that we could achieve more accurate classifications by employing a rich representation of predicted paragraph-level class probabilities. The third hypothesis was that we could learn more accurate models by having the training process put more emphasis on some paragraphs than others. Neither of these latter two hypotheses were supported by our experimental results.</p><p>It is encouraging that we were able to successfully select relevant paragraphs using the crude metric of label probabilities assigned by a statistical model, given that the model was trained on un-segmented documents marked only as positive or negative. In future work we plan to explore an approach in which we consider additional paragraph features, such as location, context and rhetorical role, in deciding on the relevance of the paragraph to the classification task at hand.</p><p>We also plan to investigate a multiple-instance approach <ref type="bibr" coords="5,339.69,671.73,102.49,9.96" target="#b2">(Dietterich et al., 1997)</ref> to the task of training models for this task. The application of this type of approach is motivated by the belief that, many of the paragraphs in positive articles should not be treated as being representative of the positive class. This was the same motivation that prompted our investigation of the EM approach. In contrast the EM method, however, the multiple-instance approach would identify putatively relevant paragraphs in a more supervised manner.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,55.44,222.36,233.71,8.97;3,55.44,233.28,233.79,8.97;3,55.44,244.20,233.81,8.97;3,55.44,255.24,233.68,8.97;3,55.44,266.16,47.37,8.97"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. Classifier utilities for models that make classifications based on whole articles (Fulltext and All paragraphs) and selected paragraphs (Top-5 paragraphs). The reported values are average test-set utilities from a cross-validation experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,307.44,222.00,233.70,8.97;3,307.44,233.04,233.80,8.97;3,307.44,243.96,164.86,8.97"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Results of metaclassifier experiments (Metaclassifier:All and Metaclassifier:Top-4) compared to simple mean results from Figure 1 (Top-5 paragraphs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,55.44,228.00,485.60,8.97;4,55.44,238.92,485.64,8.97;4,55.44,249.96,183.56,8.97"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The average distribution of paragraphs in positive and negative documents for the Allele task, with respect to classifier output. The left side of the figure shows the distributions for all paragraphs and the right side of the figure shows the distributions for Top-5 paragraphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,55.44,252.84,233.84,8.97;5,55.44,263.76,233.82,8.97;5,55.44,274.80,233.70,8.97;5,55.44,285.72,233.79,8.97;5,55.44,296.64,46.99,8.97"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The effects of ten EM iterations on utility measure for the Allele task. The results are similar for the other categories. Classifiers are trained using EM-weighted paragraphs and evaluated against both full-text and Top-n paragraphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,307.44,69.67,233.97,138.01"><head>Table 1 .</head><label>1</label><figDesc>Normalized utility scores of the three systems for which we submitted runs on official TREC data. Also presented are the minimum, median, and maximum scores for participants in each category.</figDesc><table coords="5,313.44,69.67,224.79,84.14"><row><cell>Description</cell><cell>Allele</cell><cell>Expr.</cell><cell>GO</cell><cell>Tumor</cell></row><row><cell>Fulltext</cell><cell cols="4">0.7434 0.6012 0.4287 0.8160</cell></row><row><cell cols="5">Metaclassifier 0.7736 0.6548 0.4386 0.7833</cell></row><row><cell>Top-5</cell><cell cols="4">0.7725 0.7304 0.4572 0.8242</cell></row><row><cell>Track min</cell><cell cols="4">0.2009 -0.0074 -0.0342 0.0413</cell></row><row><cell cols="5">Track median 0.7785 0.6548 0.4575 0.7610</cell></row><row><cell>Track max</cell><cell cols="4">0.8710 0.8711 0.5870 0.9433</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported in part by <rs type="funder">NIH/NLM</rs> grant <rs type="grantNumber">T15 LM007359</rs> and by <rs type="funder">NIH/NLM</rs> grant <rs type="grantNumber">R01 LM07050-01</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7WkVpbk">
					<idno type="grant-number">T15 LM007359</idno>
				</org>
				<org type="funding" xml:id="_PHbtpq3">
					<idno type="grant-number">R01 LM07050-01</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,55.44,230.52,233.69,8.97;6,65.40,240.48,42.07,8.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,146.46,230.52,142.68,8.97;6,65.40,240.48,23.01,8.96">Database issue. Nucleic Acids Research</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bateman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,55.44,258.36,233.85,8.97;6,65.40,268.32,223.63,8.97;6,65.40,278.28,223.69,8.96;6,65.40,288.24,20.74,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,248.64,258.36,40.65,8.97;6,65.40,268.32,219.51,8.97">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,65.40,278.28,203.01,8.96">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,55.44,306.24,233.61,8.97;6,65.40,316.20,223.63,8.97;6,65.40,326.16,177.07,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,65.40,316.20,223.63,8.97;6,65.40,326.16,38.48,8.97">Solving the multiple-instance problem with axis-parallel rectangles</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lozano-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,112.05,326.16,83.21,8.96">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,55.44,344.04,233.83,8.97;6,65.40,354.00,223.75,8.97;6,65.40,363.96,223.86,8.97;6,65.40,373.92,199.13,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,282.08,344.04,7.19,8.97;6,65.40,354.00,145.20,8.97;6,244.77,354.00,44.37,8.97;6,65.40,363.96,223.86,8.97;6,65.40,373.92,27.96,8.97">The Mouse Genome Database (MGD): Integrating biology with the genome</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Eppig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bult</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kadin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,102.22,373.92,91.27,8.96">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="471" to="D475" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>&amp; the Mouse Genome Database Group</note>
</biblStruct>

<biblStruct coords="6,55.44,391.92,233.73,8.97;6,65.40,401.88,190.65,8.97" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<title level="m" coord="6,146.46,391.92,142.71,8.97;6,65.40,401.88,71.77,8.97">MALLET: A MAchine Learning for LanguagE Toolkit</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,55.44,419.76,233.85,8.97;6,65.40,429.72,223.73,8.97;6,65.40,439.68,223.82,8.96;6,65.40,449.64,68.34,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,266.51,419.76,22.78,8.97;6,65.40,429.72,157.13,8.97">Using maximum entropy for text classification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,229.67,429.72,59.46,8.96;6,65.40,439.68,223.82,8.96;6,65.40,449.64,64.63,8.96">Working Notes of the IJCAI Workshop on Machine Learning for Information Filtering</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,55.44,467.64,233.70,8.97;6,65.40,477.60,223.72,8.97;6,65.40,487.56,25.29,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,225.47,467.64,63.67,8.97;6,65.40,477.60,133.35,8.97">Gene Ontology: Tool for the unification of biology</title>
	</analytic>
	<monogr>
		<title level="j" coord="6,55.44,467.64,131.66,8.97;6,206.77,477.60,63.15,8.96">The Gene Ontology Consortium</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Nature Genetics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
