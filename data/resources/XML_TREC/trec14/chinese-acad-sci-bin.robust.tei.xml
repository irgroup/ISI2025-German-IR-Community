<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.54,97.06,360.18,14.42;1,101.70,115.06,391.90,14.42;1,145.44,133.06,304.40,14.42">CAS-ICT at TREC 2005 Robust Track: Using Query Expansion and RankFusion to Improve Effectiveness and Robustness of Ad Hoc Information Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,201.06,167.06,69.29,10.80"><forename type="first">Guodong</forename><surname>Ding</surname></persName>
							<email>dingguodong@software.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Software Division</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.75,167.06,47.77,10.80"><forename type="first">Bin</forename><surname>Wang</surname></persName>
							<email>wangbin@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Software Division</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.86,167.06,44.35,10.80"><forename type="first">Shuo</forename><surname>Bai</surname></persName>
							<email>sbai@sse.com.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Software Division</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.54,97.06,360.18,14.42;1,101.70,115.06,391.90,14.42;1,145.44,133.06,304.40,14.42">CAS-ICT at TREC 2005 Robust Track: Using Query Expansion and RankFusion to Improve Effectiveness and Robustness of Ad Hoc Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">39DBD9A7A95B2FC41A516F48447D7B5B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our participation in this year's robust track aims to: (1) test how to improve the effectiveness of IR (according to MAP) using different retrieval methods with different local analysis-based query expansion methods; (2) test how to improve the retrieval robustness (according to gMAP) using RankFusion, a novel fusion technique proposed in our experiments. Our results show that although query expansion can improve the effectiveness of IR significantly, it hurts the robustness of IR seriously. However, with appropriate parameters setting, using RankFusion for merging multiple retrieval results can improve the robustness significantly while not harming the average precision too much or even increasing it in some cases.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The robust retrieval track is a traditional ad hoc retrieval task where the evaluation methodology emphasizes a system's least effective topics. The goal of the track is to improve the consistency of retrieval technology by focusing on poorly performing topics. This year is the first time for LCC (Large-scale Content Computing) group in ICT to participate in the robust track. The last two years since 2003 showed that the most promising approach to improving poorly performing topics is to utilize external text collections such as the web other than the target collection <ref type="bibr" coords="1,245.48,513.87,11.19,9.45" target="#b0">[1]</ref>. But we didn't exploit web-assisted tools such as Google for query expansion, which has been viewed as a very effective strategy for improving retrieval performances <ref type="bibr" coords="1,150.01,541.89,11.81,9.45" target="#b0">[1]</ref>[2] <ref type="bibr" coords="1,173.62,541.89,11.81,9.45" target="#b2">[3]</ref>. We argue that Google can be only viewed as web-assisted tool rather than an external web collection, because we don't know any mechanism or retrieval procedure behind Google and what we can do is just to use its retrieval results for enhancing the original query.</p><p>In the robust track, we focus on how to effectually improve the retrieval performances (effectiveness and robustness measured by MAP and gMAP <ref type="foot" coords="1,364.14,595.27,3.51,6.32" target="#foot_0">1</ref>  <ref type="bibr" coords="1,373.80,597.87,11.16,9.45" target="#b0">[1]</ref>, respectively) by merging multiple retrieval ranks produced by multiple retrieval methods with or not with query expansion. To rank the documents, we utilize five document scoring functions, called OKAPI-BM25, LMIR-JM, LMIR-DIR, LMIR-ABS, LMIR-GJM2, respectively. To expand the original query, we use three local-analysis based expansion methods, named as LOCOOC, LOCFB, and KLD, 1 exp log ( ) 0.00001 0.00001</p><formula xml:id="formula_0" coords="1,187.98,712.99,188.48,26.81">N i gMAP AvgPrec i N = ⎛ ⎞ = + ⎜ ⎟ ⎝ ⎠ ∑ - respectively.</formula><p>A novel fusion method ----RankFusion, which is independent of the retrieval methods and document score, is proposed for merge multiple runs. The remainder of our paper is organized as follows. In Section 2 we present the basic retrieval architecture of our IR system and summary the five retrieval methods and the three query expansion methods used in the track. In Section 3 we give a formal description of RankFusion. In Section 4 we introduce our query difficulty prediction method. Official submissions and results are presented in Section 5. Conclusions of our work are summarized in Section 6. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval Methods and Query Expansion Methods</head><p>The architecture of our IR system is illustrated in Fig. <ref type="figure" coords="2,321.56,438.87,3.92,9.45" target="#fig_0">1</ref>, where retrieval module, query expansion module and RankFusion module are the main parts of the system. In retrieval module, we exploit five retrieval methods (OKAPI-BM25, LMIR-JM, LMIR-DIR, LMIR-ABS, LMIR-GJM2), according to the following uniform document scoring form:</p><formula xml:id="formula_1" coords="2,198.78,495.09,296.69,18.09">) | ( ) | ( ) , ( D t W Q t W Q D Sim Q t ⋅ = ∑ ∈ (1)</formula><p>where Sim(D,Q) is the relevance score of document D given query Q, W(t|Q) and W(t|D) are the weights of term t in Q and in D, respectively.</p><p>In the five retrieval methods, OKAPI-BM25 originates from the popular 2-possion based probability retrieval model <ref type="bibr" coords="2,208.19,568.11,11.19,9.45" target="#b3">[4]</ref>. The other four methods are derived from the language modeling approach to IR <ref type="bibr" coords="2,156.45,582.09,11.66,9.45" target="#b4">[5]</ref> <ref type="bibr" coords="2,168.11,582.09,11.66,9.45" target="#b5">[6]</ref>, each using a different smoothing method: JM denotes Jelinek-Mercer, DIR denotes Dirichlet Priors, ABS denotes absolute discounting, and GJM2 denotes GJM-2 smoothing method <ref type="bibr" coords="2,124.10,610.11,11.19,9.45" target="#b5">[6]</ref>. The five retrieval methods are summarized in Table <ref type="table" coords="2,361.45,610.11,5.25,9.45" target="#tab_0">1</ref> in terms of W(t|Q) and W(t|D) in the uniform form. Table <ref type="table" coords="2,193.23,624.09,5.25,9.45" target="#tab_0">1</ref> also gives the default values of parameters in each retrieval method.</p><p>In query expansion module, we exploit three local-analysis based expansion methods, which use a local document set (generally composed of the top-ranked n documents retrieved by original query) to extract most appropriate terms to expand the query. The core of query expansion is the term ranking function Score(t,Q|C,S) <ref type="bibr" coords="2,248.73,680.07,12.58,9.45" target="#b6">[7]</ref>, which indicates the correlation degree of term t with original query Q given the document collection C and the local document set S. According to Score(t,Q|C,S), the top-scored k terms are added to the query. Table <ref type="table" coords="2,401.13,708.08,5.25,9.45">2</ref> summarizes the three expansion methods, named as LOCOOC <ref type="bibr" coords="2,252.79,722.06,17.40,9.45" target="#b6">[7]</ref>, LOCFB <ref type="bibr" coords="2,305.75,722.06,16.26,9.45" target="#b6">[7]</ref>, KLD <ref type="bibr" coords="2,345.60,722.06,15.63,9.45" target="#b7">[8]</ref>, in terms of Score(t,Q|C,S).</p><p>For reweighting the terms in the expanded query Q exp , we use the following function <ref type="bibr" coords="3,468.64,97.65,11.35,9.45" target="#b6">[7]</ref>:</p><formula xml:id="formula_2" coords="3,180.96,110.96,314.51,27.58">( ) ( | ) ( | ) exp Score t W t Q W t Q MaxScore α β = ⋅ + ⋅<label>(2)</label></formula><p>where W(t|Q) is the weight of term t in original query Q, Score(t) is equivalent to Score(t,Q|C,S),</p><p>and MaxScore is the maximum score of all the selected expansion terms. The coefficient α and β are both set to 1.0 in all experiments. </p><formula xml:id="formula_3" coords="3,87.12,282.57,418.28,170.34">OKAPI-BM25 ) | ( ) | ( ) 1 ( 3 3 Q t tf k Q t tf k + ⋅ + 5 . 0 ) | ( 5 . 0 ) | ( log ) | ( ) ( ) ( ) 1 ( ) | ( ) 1 ( 1 1 + + - ⋅ + ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ ⋅ + - ⋅ + C t df C t df N D t tf C avdl D dl b b k D t tf k k 1 = 1.2 k 3 = 1000 b = 0.75 rm2: LMIR-JM tf(w|Q) )) | ( ) 1 ( ) | ( log( C t p D t p ML ML λ λ - + λ = 0.6 (Title),or λ = 0.4 (Desc) rm3: LMIR-DIR tf(w|Q) ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ + + µ µ | | ) | ( ) | ( log D C w p D t tf ML µ = 1000 rm4: LMIR-ABS tf(w|Q) ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ + - ) | ( | | | | | | ) 0 , ) | ( max( log C t p D D D D t tf ML u δ δ δ = 0.8 rm5: LMIR-GJM2 tf(w|Q) µ = 1000 ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ + - + + ) | ( ) | | | | 1 ( ) | ( | | | | log C w p D D D w p D D ML u u ML u u µ µ</formula><p>Table <ref type="table" coords="3,115.57,473.28,3.76,9.02">2</ref>. Summary of the three query expansion methods used for the robust track. idf(•|C) is inverse document frequency of a term in the collection. cood(t,q|S) is the co-occurrence degree of the term t and the query term q in S, see <ref type="bibr" coords="3,214.04,497.28,11.54,9.02" target="#b6">[7]</ref>. W(t|D) is the weight of term t in document D, generally using the weighting form in OKAPI-BM25. p(t|S) and p(t|C) are the probabilities of term t occurring in S and in collection C, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QE Method</head><p>Score(t,Q|C,S) qe1: LOCOOC</p><formula xml:id="formula_4" coords="3,150.36,557.73,252.98,87.31">( ) ∑ ∈ + Q q S q t cood C t idf C q idf 0 . 1 ) | , ( log ) | ( ) | ( qe2: LOCFB ∑ ∈S D D t W n ) | ( 1 qe3: KLD ) | ( ) | ( log ) | ( C t p S t p S t p ⋅</formula><p>Table <ref type="table" coords="3,141.18,666.45,5.25,9.45">3</ref> gives the retrieval performances of the three expansion methods and their improvements over the initial retrieval results (i.e. no expansion is used) for each retrieval method. From the table we can see that in all retrieval methods, although query expansion can improve average precision (MAP) significantly, it can usually hurt retrieval robustness (measured by gMAP) seriously. These observations are also testified in previous robust tracks <ref type="bibr" coords="3,427.43,722.43,11.18,9.45" target="#b0">[1]</ref>. Table <ref type="table" coords="4,116.78,96.36,3.77,9.02">3</ref>. The retrieval performances (MAP and gMAP) of the three expansion methods and their improvements over the initial retrieval results (i.e. no expansion is used) for each retrieval method. The document collection is Disk4&amp;Disk5-CR, with queries constructed only using the title of topics exploited in this year's robust track. Stop-words are removed and Porter-stemming is applied. The "rmX" column is ID of retrieval method X(see Table <ref type="table" coords="4,313.93,144.36,3.62,9.02" target="#tab_0">1</ref>). "rmX.qeY <ref type="bibr" coords="4,364.25,144.36,17.85,9.02" target="#b9">(10,</ref><ref type="bibr" coords="4,382.10,144.36,13.38,9.02">80)</ref>.run" denotes the retrieval result using retrieval method "rmX" and query expansion method "qeY" (see Table <ref type="table" coords="4,425.74,156.36,3.76,9.02">2</ref>, "qe0" denotes no expansion). The expansion parameters are set to <ref type="bibr" coords="4,294.00,168.36,16.67,9.02" target="#b9">(10,</ref><ref type="bibr" coords="4,310.66,168.36,12.50,9.02">80)</ref> for all expansion methods, where 10 is the number of top-retrieval documents and 80 is the number of expansion terms. rmX.qe0.run rmX.qe1 <ref type="bibr" coords="4,253.55,200.64,17.72,9.02" target="#b9">(10,</ref><ref type="bibr" coords="4,271.26,200.64,13.29,9.02">80)</ref>.run rmX.qe2 <ref type="bibr" coords="4,348.78,200.64,17.72,9.02" target="#b9">(10,</ref><ref type="bibr" coords="4,366.49,200.64,13.29,9.02">80)</ref>.run rmX.qe3 <ref type="bibr" coords="4,443.95,200.64,17.72,9.02" target="#b9">(10,</ref><ref type="bibr" coords="4,461.66,200.64,13.29,9.02">80)</ref>  <ref type="table" coords="4,115.69,363.78,3.76,9.02">4</ref>. The influences of RankFusion to MAP and gMAP. The data set is the same as that used in Table <ref type="table" coords="4,114.60,375.78,3.76,9.02">3</ref>. The "rmX" column is ID of retrieval method X(see Table <ref type="table" coords="4,354.39,375.78,3.62,9.02" target="#tab_0">1</ref>). The "rmX.qe0.run" column shows the performances for retrieval method "rmX" with no query expansion. Other columns which contain "rf" show the performances after using RankFusion for combination: rmX.qeYrf.run = 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Merging Multiple Results with RankFusion</head><p>Previous studies indicate that retrieval performances can often be improved by using a number of different retrieval algorithms and combining the results, in contrast to using just a single retrieval algorithm <ref type="bibr" coords="5,135.75,97.65,12.17,9.45" target="#b7">[8]</ref>[9] <ref type="bibr" coords="5,160.09,97.65,16.23,9.45" target="#b9">[10]</ref>. This is because different retrieval algorithms, or retrieval experts, often emphasize different document and query features when determining relevance and therefore retrieve different sets of documents <ref type="bibr" coords="5,241.14,125.67,11.18,9.45" target="#b8">[9]</ref>.</p><p>Many combination methods took a linear combination of the relevance scores, based on Saracevic and Kantor's early observation that the more runs a document is retrieved by the more likely it is that the document is relevant <ref type="bibr" coords="5,284.70,167.67,16.11,9.45" target="#b11">[12]</ref>. However the relevance scores may be not comparable across the runs. Some other combination methods tried normalization of relevance scores prior to combination and got very little success, probably due to the different distribution of the scores in each run <ref type="bibr" coords="5,183.59,209.67,11.18,9.45" target="#b7">[8]</ref>.</p><p>In the robust track, the method proposed for results combination is named as RankFusion, which computes the rank score for each retrieved document based on the document's rank order in its result list, and then uses the rank score to reorder all the documents in the combined retrieved document set. Formally, suppose we have m rank lists of retrieved documents for query Q:</p><formula xml:id="formula_5" coords="5,90.00,279.63,415.25,46.58">{L 1 (Q),…,L i (Q),…,L m (Q)}. Each rank list L i (Q) has n i retrieved documents (n i is usually equal to 1000 in TREC-style result): ,1<label>,1 ,2 ,2 , , , , ( ) ((</label></formula><p>, ), ( , ),..., ( , ),..., ( , ))</p><formula xml:id="formula_6" coords="5,133.62,309.78,351.21,17.82">i i i i i i i i j i j i n i L Q D s D s D s D s ≡ n , 1 ≤ i ≤ m, 1 ≤ j ≤ n i</formula><p>where s i,j is the relevance score of document D i,j in L i (Q), and s i,j &gt; s i,j+1 . For the query Q, suppose the final combined rank list L(Q) is ( ) (( , ), ( , ),..., ( , ),..., ( , ))</p><formula xml:id="formula_7" coords="5,186.18,368.96,213.49,16.47">j j n n L Q D s D s D s D s ≡</formula><p>where each document D j occurs at least one list in the m rank lists and s j is the relevance score of document D j . How do we merge the m rank lists {L</p><formula xml:id="formula_8" coords="5,305.88,413.97,148.96,10.19">1 (Q),…,L i (Q),…,L m (Q)} into L(Q)?</formula><p>In our combination method, we assign a rank score RankScore(D|L i (Q)) to each document D in the rank list L i (Q). The rank score is computed based on the reciprocal of the rank order 2 RankOrder(D|L i (Q)). That is,</p><formula xml:id="formula_9" coords="5,160.38,473.76,335.09,16.69">( | ( )) 1/ ( | ( )) i i RankScore D L Q RankOrder D L Q = (3)</formula><p>For any document that is not in the list</p><formula xml:id="formula_10" coords="5,254.82,502.47,153.71,10.19">L i (Q), RankOrder(D|L i (Q)) is (n i +1).</formula><p>To get the final combined rank list L(Q), we first use the following formula to compute the combined rank score ComRankScore(D|Q) of any document D that occurs at least one list in the m rank lists:</p><formula xml:id="formula_11" coords="5,158.94,558.35,336.53,24.45">)) ( | ( ) | ( 1 Q L D RankScore Q D re ComRankSco i m i i ⋅ = ∑ = α (4)</formula><p>where α i is a positive coefficient to control the confidence in each rank list.</p><p>The ComRankScore(D|Q) reflects integrative estimate of the document D being relevant to the query and can be directly used for measuring the relevance score of D in the final combined list. We reorder all the unique documents in the m rank list according to ComRankScore(D|Q) and return the top-ordered n documents to the user, where the relevance score s j of document D j in the final combined list is equal to ComRankScore(D j |Q). For the sake of simplicity, we introduce an operator "♁" to denote the combination of multiple results (or runs) in the remainder of the paper: 2 The rank order of the ith retrieved document in the result list is i.</p><formula xml:id="formula_12" coords="6,168.60,100.15,326.87,19.33">m m i i m i Run Run Run Run Run α α α α ⊕ ⊕ ⊕ = ⊕ = = ... 2 2 1 1 1 (5)</formula><p>where each combination coefficient α i is set empirically in our experiments.</p><p>In our experiments we exploited various fusion strategies with RankFusion and found that in most cases RankFusion can improve gMAP significantly while not hurting MAP too much. Our experiments showed that for each retrieval method, with appropriate setting of the combination coefficients, using RankFusion to merge the initial retrieval result with the result after query expansion can improve the robustness significantly though it sometimes has some harm for the average precision when compared with query expansion. In addition, merging the results produced by different retrieval methods can also achieve better gMAP, as indicated in Table <ref type="table" coords="6,436.63,226.83,3.95,9.45">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Query Difficulty Prediction with KL-divergence</head><p>Our prediction of query-difficulty is based on the assumption that if there is a significant divergence of query-term distribution in the top-ranked documents and in the total document collection, then we make the hypothesis that this divergence is caused by the query which is easy-defined. That is to say, we can use the negative KL-divergence to predict the query difficulty.</p><formula xml:id="formula_13" coords="6,181.62,356.15,313.85,24.40">∑ ∈ - = Q w C w p S w p S w p Score Difficulty ) | ( ) | ( log ) | (<label>(6)</label></formula><p>where p(w|S) is the probability of term w in the document set S composed of top-ranked documents:</p><p>∑ ∑ ∑ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Official Submissions and Results</head><p>In our experiments, according to whether Port-Stemming is used or not, two kinds of indexes are built: STEMMED and UNSTEMMED. We think that using RankFusion to merge the results on STEMMED data set with the results on UNSTEMMED data set other than on a single data set, the retrieval robustness can be improved further. In the robust track, we exploited five retrieval methods (Table <ref type="table" coords="6,157.50,624.15,3.80,9.45" target="#tab_0">1</ref>), with the retrieval parameters being set to default values.</p><p>For each retrieval method rmX (X denotes the id of the retrieval method, see Table <ref type="table" coords="6,457.24,638.13,3.80,9.45" target="#tab_0">1</ref>), we used the three query expansion methods (Table <ref type="table" coords="6,287.07,652.17,4.38,9.45">2</ref>) with appropriate parameter settings to obtain multiple retrieval resultsd. For each query expansion method, we experimented with various setting of expansion parameters, primarily including n and k, where n is the number of top retrieved documents and k is the number of expansion terms. We found that in most cases the appropriate values of (n,k) are <ref type="bibr" coords="6,219.81,708.15,17.52,9.45" target="#b9">(10,</ref><ref type="bibr" coords="6,237.33,708.15,13.14,9.45">80)</ref> or (30,80) on STEMMED data set. On UNSTEMMED data set, the good setting of (n,k) is (20,60) or (30,60).</p><p>For each retrieval method rmX, suppose "rmX.qe0.run" is the run ID of the retrieval result with the original query (i.e. no query expansion is applied), "rmX.qeY(n,k).run" is the run ID of the retrieval result using query expansion method Y (see Table <ref type="table" coords="7,373.00,125.67,3.79,9.45">2</ref>), with expansion parameters being (n,k). As <ref type="bibr" coords="7,158.67,139.65,12.28,9.45" target="#b0">[1]</ref> mentioned, collection enrichment is a good strategy to improve the retrieval performances of difficult topics. We used GOV data set as an alternative external collection for collection enrichment. First we utilized OKAPI-BM25 to retrieve the GOV collection and extracted 50 terms from the top-ranked 10 documents to form an expanded query. Then for each retrieval method rmX, a new result "rmX.qe-gov.run" was retrieved using the expanded query. Thus we had total 8 temporary runs for each retrieval method rmX, on STEMMED data set and UNSTEMMED data set, respectively. The temporary runs on STEMMED data set are: rmX.qe0.run, rmX.qe-gov.run, rmX.qe1 <ref type="bibr" coords="7,293.19,237.63,18.17,9.45" target="#b9">(10,</ref><ref type="bibr" coords="7,311.36,237.63,13.62,9.45">80)</ref>.run, rmX.qe1(30,80).run, rmX.qe2 <ref type="bibr" coords="7,163.79,251.67,18.17,9.45" target="#b9">(10,</ref><ref type="bibr" coords="7,181.96,251.67,13.63,9.45">80)</ref>.run, rmX.qe2(30,80).run, rmX.qe3 <ref type="bibr" coords="7,341.66,251.67,18.17,9.45" target="#b9">(10,</ref><ref type="bibr" coords="7,359.83,251.67,13.63,9.45">80)</ref>.run, rmX.qe3 <ref type="bibr" coords="7,431.37,251.67,18.59,9.45">(30,</ref><ref type="bibr" coords="7,449.96,251.67,13.95,9.45">80)</ref>.run Runs on UNSTEMMED data set are very similar to them, except the QE parameter (n,k) is set to (20,60) and (30,60). Using these temporary runs for RankFusion, we submitted 2 title-only (ICT05qerfT.run, ICT05qerfTg.run) and 2 description-only (ICT05qerfD.run, ICT05qerfDg.run) runs. The runs whose names contain the label "g" are those that use external collection in a first-pass retrieval. Table <ref type="table" coords="7,198.58,321.62,5.25,9.45" target="#tab_3">5</ref> shows the performances of the final submitted runs. Appendix 1 gives an exhaustive description of the temporary merged runs and their retrieval performances for title-only task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This is the first time for LCC (Large-scale Content Computing) group in ICT to participate in the robust track. We focus on using different retrieval methods and query expansion methods for improving the retrieval effectiveness. Our experiments show that query expansion can hurt robustness seriously while it improves the average precision. We propose a novel combination method -RankFusion, for merging multiple retrieval results. The experimental results show that with appropriate parameters setting, using RankFusion for merging runs can improve the robustness significantly while not harming the average precision too much or even increasing the average precision in some cases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,212.82,366.00,179.20,9.02;2,144.66,208.56,305.88,150.06"><head>Fig. 1</head><label>1</label><figDesc>Fig.1 Retrieval architecture of our IR system</figDesc><graphic coords="2,144.66,208.56,305.88,150.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,271.20,434.18,3.77,6.48;6,292.02,434.18,3.77,6.48;6,282.06,419.66,3.77,6.48;6,249.42,418.83,5.32,11.88;6,274.74,435.88,2.65,4.76;6,267.66,435.88,3.82,4.76;6,295.68,435.88,3.82,4.76;6,289.02,435.88,3.53,4.76;6,285.66,421.36,2.65,4.76;6,278.52,421.36,3.82,4.76;6,324.36,429.45,7.01,8.74;6,312.36,429.45,6.47,8.74;6,300.84,429.45,5.40,8.74;6,313.50,414.93,7.01,8.74;6,301.50,414.93,6.47,8.74;6,289.92,414.93,5.40,8.74;6,238.08,421.95,4.85,8.74;6,226.26,421.95,6.47,8.74;6,217.32,421.95,4.85,8.74;6,331.80,429.45,3.23,8.74;6,320.34,429.45,1.94,8.74;6,308.70,429.45,3.23,8.74;6,320.88,414.93,3.23,8.74;6,309.42,414.93,1.94,8.74;6,297.78,414.93,3.23,8.74;6,243.96,421.95,3.23,8.74;6,234.18,421.95,1.94,8.74;6,222.54,421.95,3.23,8.74;6,483.24,423.87,12.23,9.45;6,90.00,446.79,280.07,9.45;6,257.82,479.11,32.50,17.01;6,269.04,463.81,9.89,17.01;6,271.56,489.11,3.96,6.80;6,293.52,489.11,3.96,6.80;6,282.78,473.87,3.96,6.80;6,249.12,473.00,5.58,12.47;6,274.98,490.90,3.71,5.00;6,267.90,490.90,4.01,5.00;6,297.30,490.90,4.01,5.00;6,290.40,490.90,3.71,5.00;6,286.14,475.66,3.71,5.00;6,279.12,475.66,4.01,5.00;6,326.82,484.20,7.36,9.17;6,314.46,484.20,6.80,9.17;6,302.58,484.20,5.67,9.17;6,315.60,468.90,7.36,9.17;6,303.24,468.90,6.80,9.17;6,291.36,468.90,5.67,9.17;6,236.04,476.28,6.80,9.17;6,224.28,476.28,6.80,9.17;6,215.10,476.28,5.10,9.17;6,334.44,484.20,3.39,9.17;6,322.62,484.20,2.04,9.17;6,310.68,484.20,3.39,9.17;6,323.22,468.90,3.39,9.17;6,311.40,468.90,2.04,9.17;6,299.46,468.90,3.39,9.17;6,243.54,476.28,3.39,9.17;6,232.44,476.28,2.04,9.17;6,220.50,476.28,3.39,9.17;6,483.24,478.47,12.23,9.45"><head></head><label></label><figDesc>w|C) is the probability of term w in the document collection:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,87.12,199.14,418.25,95.18"><head>Table 1 .</head><label>1</label><figDesc>Summary of the five retrieval methods used for the robust track. tf(t|Q) and tf(t|D) are the frequencies of term t occurring in query Q and document D, respectively. dl(D) is the length of document D, |D| = dl(D). avdl(C) is the average length of all the documents in collection C. p ML (t|D) and p ML (t|C) are the maximum likelihood estimators of the probabilities of term t occurring in document D and collection C, respectively. |D| u is the number of unique terms in document D.</figDesc><table coords="3,87.12,269.16,405.60,25.16"><row><cell>Retrieval Method W(t|Q)</cell><cell>W(t|D)</cell><cell>Param Values</cell></row><row><cell>rm1:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,90.00,372.45,413.87,79.00"><head>Table 5 .</head><label>5</label><figDesc>Retrieval Performances of the submitted runs Run id Comment MAP gMAP R-Prec Recall ICT05qerfTg Title-only, collection enrichment with Gov 0.2707 0.1888 0.3168 5078/6561 ICT05qerfT Title-only, no collection enrichment 0.2856 0.1789 0.3259 4967/6561 ICT05qerfDg Description-only, collection enrichment with Gov 0.2386 0.1425 0.2876 4692/6561 ICT05qerfD Description -only, no collection enrichment 0.2594 0.1553 0.3053 4807/6561</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,96.60,690.48,409.09,9.02;1,90.00,702.48,203.26,9.02"><p>In our experiments, the computation of gMAP is based on<ref type="bibr" coords="1,331.44,690.48,10.61,9.02" target="#b0">[1]</ref>. Suppose the number of topics is N, and the average precision of topic i is AvgPrec(i), then:</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="7,95.28,731.55,346.09,8.10"><p>Lemur is a great platform for IR experiments. See http://www.lemurproject.org for more details.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The index of document collection was built using Lemur 3 (version: 3.0) toolkit. We also used some API functions of Lemur for index accessing.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head><p>1. Performances of temporary and submitted runs for title-only task on STEMMED and UNSTEMMED indexes. The above half part shows temporary results on STEMMED index, while the below half part shows temporary results on UNSTEMMED index. The last two rows give the performances of the submitted runs for title-only. rmX denotes the retrieval method with id being "X"(see Table <ref type="table" coords="8,150.84,183.27,3.80,9.45">1</ref>). qeY denotes the query expansion method with id being "Y"(see Table <ref type="table" coords="8,457.57,183.27,3.80,9.45">2</ref>). </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,103.56,144.63,401.83,8.10;9,90.00,157.65,153.12,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,177.60,144.63,194.37,8.10">Overview of the TREC 2004 Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,389.40,144.63,115.99,8.10;9,90.00,157.65,77.94,8.10">Proceedings of the Twelfth Text REtrieval Conference</title>
		<meeting>the Twelfth Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2003">2003. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.71,170.61,400.56,8.10;9,90.00,183.63,278.88,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,300.07,170.61,188.90,8.10">TREC2004 robust track experiments using PIRCS</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,90.00,183.63,252.44,8.10">Proceedings of the Thirteenth Text REtrieval Conference (TREC 2004)</title>
		<meeting>the Thirteenth Text REtrieval Conference (TREC 2004)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,103.63,196.65,401.70,8.10;9,90.00,209.61,278.88,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,342.05,196.65,148.53,8.10">Fondazione Ugo Bordoni at TREC 2004</title>
		<author>
			<persName coords=""><forename type="first">Giambattista</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudio</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,90.00,209.61,203.71,8.10">Proceedings of the Thirteenth Text REtrieval Conference</title>
		<meeting>the Thirteenth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>TREC 2004</note>
</biblStruct>

<biblStruct coords="9,103.51,222.63,401.88,8.10;9,90.00,235.65,415.38,8.10;9,90.00,248.61,66.81,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,427.49,222.63,62.64,8.10">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,90.00,235.65,235.24,8.10">Proceedings of the Third Text Retrieval Conference (TREC-3)</title>
		<meeting>the Third Text Retrieval Conference (TREC-3)<address><addrLine>Gaithersberg, Md</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,103.00,261.63,402.31,8.10;9,90.00,274.65,219.20,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,176.96,261.63,303.56,8.10">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,486.30,261.63,19.01,8.10;9,90.00,274.65,132.15,8.10">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,102.74,287.61,402.71,8.10;9,90.00,300.63,415.39,8.10;9,90.00,313.65,106.75,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,201.49,287.61,303.96,8.10;9,90.00,300.63,136.55,8.10">GJM-2: A Special Case of General Jelinek-Mercer Smoothing Method for Language Modeling Approach to Ad Hoc IR</title>
		<author>
			<persName coords=""><forename type="first">Guodong</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,248.05,300.63,257.35,8.10;9,90.00,313.65,40.61,8.10">Proceedings of the Second Asia Information Retrieval Symposium (AIRS2005)</title>
		<meeting>the Second Asia Information Retrieval Symposium (AIRS2005)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="9,103.21,326.61,401.99,8.10;9,90.00,339.63,415.29,8.10;9,90.00,352.65,90.78,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,242.89,326.61,258.79,8.10">Local Co-occurrence based Query Expansion for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Guodong</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuo</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,100.80,339.63,400.19,8.10">Proceedings of the 2nd National Conference on Information Retrieval and Content Security (NCIRCS&apos;2005)</title>
		<meeting>the 2nd National Conference on Information Retrieval and Content Security (NCIRCS&apos;2005)<address><addrLine>Beijing</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="9,105.31,365.61,400.05,8.10;9,90.00,378.63,415.32,8.10;9,90.00,391.65,32.28,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,369.34,365.61,136.03,8.10;9,90.00,378.63,168.88,8.10">Improving Retrieval Feedback with Multiple Term-Ranking Function Combination</title>
		<author>
			<persName coords=""><forename type="first">Claudio</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vittorio</forename><surname>Giannini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,265.68,378.63,155.43,8.10">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="290" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,103.09,404.61,402.26,8.10;9,90.00,417.63,415.27,8.10;9,90.00,430.66,261.19,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,349.94,404.61,155.41,8.10;9,90.00,417.63,60.30,8.10">Automatic combination of multiple ranked retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">Brian</forename><forename type="middle">T</forename><surname>Bartell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Garrison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><forename type="middle">K</forename><surname>Cottrell</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,168.48,417.63,336.79,8.10;9,90.00,430.66,188.50,8.10">proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval(SIGIR&apos;94</title>
		<meeting>the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval(SIGIR&apos;94<address><addrLine>Dublin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.25,443.62,397.19,8.10;9,90.00,456.64,152.77,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,302.79,443.62,202.65,8.10;9,90.00,456.64,29.02,8.10">On linear mixture of expert approaches to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Weiguo</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Praveen</forename><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,124.56,456.64,91.79,8.10">Decision Support Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.30,469.66,395.01,8.10;9,90.00,482.62,151.00,8.10" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Thistlewaite</surname></persName>
		</author>
		<title level="m" coord="9,315.95,469.66,189.36,8.10;9,90.00,482.62,124.55,8.10">Merging Results From Isolated Search Engines. Australasian Database Conference</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,107.65,495.64,397.77,8.10;9,90.00,508.66,158.57,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,234.34,495.64,271.08,8.10;9,90.00,508.66,25.62,8.10">A study of information seeking and retrieving. III. Searchers, seaches, and overlap</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Saracevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kantor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,121.50,508.66,70.11,8.10">J. Am. Soc. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="197" to="216" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
