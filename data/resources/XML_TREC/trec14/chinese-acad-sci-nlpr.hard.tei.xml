<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,133.02,81.73,329.22,16.20">NLPR at TREC 2005: HARD Experiments</title>
				<funder ref="#_C3bve2r #_xmyQc3b #_y6P5UMM #_bzcjyQa #_a2Jwfe9 #_9fMDjPG #_YHwuSwD #_GFCAkJA #_aFyN4Rg">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,249.66,107.24,38.36,10.80"><forename type="first">Bibo</forename><surname>Lv</surname></persName>
							<email>bblv@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.71,107.24,48.94,10.80"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
							<email>jzhao@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,133.02,81.73,329.22,16.20">NLPR at TREC 2005: HARD Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F8998A902E3137FA0B144166D094457B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is the third time that Chinese Information Processing Group of NLPR takes part in TREC. In the past, we participated in Novelty track and Robust track, in which we had evaluated our two key notions: Window-based Retrieval Algorithm and Result Emerging Strategy [1][2]. This year we focus on investigating the significance of relevance feedback, so HARD track is our best choice.</p><p>HARD2005 is very different from that in the past two years. Firstly, Metadata is removed from topic description so that the topic description in HARD is the same as that of Robust track. Secondly, passage retrieval is cancelled this year.</p><p>The paper introduces our work on HARD Track in TREC 2005, mainly (1) we propose a new feature selection method for query expansion in relevance feedback; (2) we adopt some query expansion methods.</p><p>Our paper is organized as follows. Section 2 introduces our system, a new term selection algorithm for query expansion, and our clarification forms. Section 3 presents our query expansion methods. In section 4 experimental results are given, and finally we conclude our work in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results &amp; Analysis</head><p>We submitted 10 runs in all. All the queries are constructed from all fields of given topics automatically. The following table describes all the submitted runs. NLPRB is our baseline which uses pseudo feedback, the others are final runs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Retrieval Model</head><p>As to the retrieval model, Lemur toolkit developed by UMASS and CMU includes six different retrieval models <ref type="bibr" coords="1,220.33,653.06,12.75,10.80">[3]</ref>. In order to facilitate our work, we use Okapi BM25 <ref type="bibr" coords="1,90.00,668.66,13.97,10.80" target="#b3">[4]</ref>[5] as the retrieval model, which is based on the probability model of Robertson and Sparck Jones. The formula is described as follow:</p><formula xml:id="formula_0" coords="1,112.98,701.61,284.30,64.41">3 1 2 3 ( 1) ( 1) | | k qtf k tf avdl dl w k Q K tf k qtf avdl dl + + - = + ⋅ ⋅ + + + (1) 1 ((1 ) / ) K k b b dl avdl = -+ ⋅</formula><p>Where, Q is a query, containing several query terms. w is the weight of a term in the query. tf is the frequency of a term in a specific document. qtf is the initial weight of the term. avdl is the average document length. dl s document length.</p><p>Others are parameters which depend on the query and testing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A New Method for Term Extraction in Relevance Feedback</head><p>As we know, pseudo relevance feedback can improve the performance of IR system. Unfortunately, much noise will also be introduced which will decrease the performance of IR system based on pseudo relevance feedback Therefore, term selection is very important in IR model. (</p><p>(1 )</p><formula xml:id="formula_2" coords="2,112.98,359.58,273.32,32.21">p p p p sv t p p r p p p p - - = - ≈ - -<label>(2)</label></formula><p>,</p><formula xml:id="formula_3" coords="2,114.30,399.03,83.07,31.71">r n r p p R N R - = = -</formula><p>Where: t is a term. sv(t) is RSV of t. r is the number of relevant documents containing the term. R is the number of relevant documents. n is the number of documents containing the term. N is the number of documents within testing data. p denotes the probability of the term in relevant documents. denotes the probability of the term in non-relevant documents.</p><p>In Robertson Selection Value Model, terms have the same weight if they appear in a document no matter how many times. But sometimes this is not the truth. If a term appears with higher frequency in a relevant document, this term may carry more important information than lower frequent ones. For example, I googled "Kaifulee" when he just left Microsoft. The first ten results returned from Google only contain one web page which told me Kaifulee joined Google. Obviously, the term frequency of "google" in the retrieved documents is higher than other words. But when we use the probability model for query expansion which only considering whether the term appears in the document, the term "google" can be hardly used as expanded term, which is not our expectation. To solve the problem of RSV Model, we propose a novelty query expansion algorithm based on language model <ref type="bibr" coords="2,424.38,746.65,14.01,10.83" target="#b6">[7]</ref> which term p frequency is took into account, which can be expressed in the following fomula. </p><formula xml:id="formula_4" coords="3,112.98,343.96,186.08,32.23">p p sv t r p p - = -<label>(3)</label></formula><p>Where: sv(t)' is selection value of t. r denotes term coverage in relevant documents. the rest denotes the relevance to relevant documents. As showed in Figure <ref type="figure" coords="4,193.23,91.45,4.51,10.82" target="#fig_0">1</ref>, two sets of clarification forms were submitted. One set is used to get feedback information from relevant documents within the AQUAINT corpus, the other is set up to get feedback information returned from Google. The information submitted to assessors is mainly composed of two forms. One is key words that may be relevant to the given topic and the other is sentences extracted from the headline field of relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Clarification Form</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementation of Query Expansion in Our Experiment</head><p>The general idea of query expansion in relevance feedback is to re-estimate query based on the distribution of terms in relevant documents and irrelevant documents, next re-estimate the query to form a new query, and last put the new query into information retrieval system to get the final results. Two expansion strategies are proposed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Using Relevant Words for Query Expansion</head><p>As told in section 2.3, after clarification forms' return-back, what we can obtain from CF1 are the sentences and the keywords that are relevant to its topic. One direct way for estimating the new query is combination of the original query and some key words judged by assessors. This is regarded as expansion 1.</p><p>CF2 contains information gotten from WEB, which provides us many resources. How to make full use of them to improve IR system is a challenge. Google is a powerful search engine which retrieves relevant pages in Internet according to the query. Many researchers have studied how to make use of Google to improve their own IR systems <ref type="bibr" coords="4,90.00,528.25,12.71,10.82" target="#b7">[8]</ref>.</p><p>In our experiments, we only put the words in title field of topic into Google and fetch the top 20 web pages given by Google. Then 10 terms are extracted from relevant pages according to the number of returned pages containing the term. These words are extracted from WEB. After getting rid of noises by assessors and adding additional keywords, we combine original query with key words obtained from CF2 to form a new query. This is regard as expansion 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Using Relevant Sentences for Query Expansion</head><p>In CF1, there are sentences that are relevant to the given topic and extracted from field HeadLine of retrieved documents based on original query. That is to say, if a sentence is judged as relevant, its document is relevant too.</p><p>In order to make use of the relevant documents judged by assessors for query expansion, our basic idea is to extract expanded words from these documents based on formula (3). This is regarded as expansion 3.</p><p>In the method of expansion 3, it is possible that r in formula (3) is not took into account for some topics, because nearly all the relevant document candidates are judged as noise by assessors. Therefore, in order to make good use of formula (3) for query expansion, new relevant documents must be found based on the given relevant ones. The method that we adopt is as follows.</p><p>First, we convert documents into vectors in the vector space model: i i 1 i 2 d =(t ,t ...) , next, compute the centroid of the relevant documents according to formula 4, and then score the documents in cosine similarity, the relevant documents from which the new query is built are excluded from ranking.</p><p>i Re</p><formula xml:id="formula_5" coords="5,112.62,337.04,277.64,86.39">d centroid i d l e v a n t D o c s R ∈ = ∑ (4) d centroid (centroid, d ) | d || centroid | i i i i score sim ⋅ = =<label>(5)</label></formula><p>Finally, Key words are extracted from top 10 documents according to formula (3) and this is regarded as expansion 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Run Description</head><p>The performances of 10 Runs are shown in Figure <ref type="figure" coords="6,346.35,199.22,4.50,10.80">4</ref>. Note that, the parameters 1 k , </p><formula xml:id="formula_6" coords="6,91.80,230.41,68.26,12.84">2 k , 3 k , b of</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3. Run Results</head><p>From the comparative results of the 10 submitted runs, we can get some conclusions from the following 4 aspects: a) In comparison with the baseline, R-Precison, P@10 and Average Precison of NLPRCF1W Run are improved by 7.2%, 3.3% and 1.7% respectively. We believe that the reason lies in that noise removal for query expansion conducted by assessors. b) NLPRCF2 shows that the external information can improve the system performance. But the improvement is not as well as it was expected. In fact, two approaches can be adopted to improve the performances. Firstly, maybe we should not only put the words within title into Google, because information from other fields may also contribute to better performance. Secondly, merging the retrieval results from many searching engines may be also useful, because many search engines will give you different top N pages for a specific query. c) NLPRCF1S2 outperforms NLPRCF1S1, this validate our comparison of expansion 3 and expansion 4. However, there is an interesting phenomenon that when they are combined with CF2, the results are hard to explain. We do not know clearly what it happens. d) NLPRCF1CF2 outperforms others in all the 10 runs which combine the information obtained from relevant documents and retrieval results from Google. It gets increases of 19.4% for R-Precision, 25.2% for P@10 and 22.9% for Average Precision. It is obviously that the more information we use the better performance we will obtain.</p><p>Because the best, median and worst results of all 50 topics are not given, we choose first 10 topics to compare. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4. R-Precision Comparison</head><p>Figure <ref type="figure" coords="7,124.37,497.06,6.00,10.80">4</ref> tells us that our result is only above median and there is a lot of work to do in the future. We should pay special attention to the following three key points from comparison: a) Query expansion should be in the form of not only words but also phrases such as baseNP, which often improves the performance of system significantly. b) New feature selection function which removes noise in relevant documents should be studied. c) Further research will be focused on mining web resources for information retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions</head><p>We propose a new feature select function and evaluate two kinds of query expansion methods, all of which can improve our system performance to some extent via relevance feedback. The experiments show that all these techniques are effective, especially combination of query expansion based on relevant information from web and testing data.</p><p>Future work will focus on query expansion based on phrase and more effective feature selection methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledge</head><p>This work was supported by the Natural Sciences Foundation of China under grant No. 60372016, the Natural Science Foundation of Beijing under grant No. 4052027.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,236.16,746.84,122.97,10.80"><head>Figure 1</head><label>1</label><figDesc>Figure 1 CF Generation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,90.42,404.19,285.74"><head></head><label></label><figDesc>the probability of the term in relevant documents. denotes the probability of the term in non-relevant documents. In formula (3), we use p' and to replace p and in formula (2) respectively, and the new function is what we use in HARD track.</figDesc><table coords="3,90.00,90.42,244.23,285.74"><row><cell>p</cell><cell>'</cell><cell>=</cell><cell>d</cell><cell>Re Re levantDocs levantDocs tf t ( ) | | d d ∈ d ∈ ∑ ∑</cell></row><row><cell>p</cell><cell>'</cell><cell>=</cell><cell cols="2">( ) | | d tf t d FeedbackDocs d FeedbackDocs d ∈ ∈ ∑ ∑</cell></row><row><cell cols="2">Where:</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">tf d (t) is term frequency in a specific document.</cell></row><row><cell cols="5">d is a document.</cell></row><row><cell cols="6">|d| is document length.</cell></row><row><cell cols="5">p' denotes '(1 ( ) ' log( '(1</cell><cell>') ')</cell><cell>)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,91.32,230.42,391.63,265.86"><head></head><label></label><figDesc>the model are set as 1.2, 0, 7 and 0.75 respectively.</figDesc><table coords="6,91.32,278.84,391.63,217.44"><row><cell>ID Tag</cell><cell>R-Precision</cell><cell>P@10</cell><cell>Average Precision</cell></row><row><cell>NLPRB</cell><cell>0.2942</cell><cell>0.4840</cell><cell>0.2586</cell></row><row><cell>NLPRCF1</cell><cell>0.3336</cell><cell>0.5820</cell><cell>0.3007</cell></row><row><cell>NLPRCF1CF2</cell><cell>0.3514</cell><cell>0.6060</cell><cell>0.3179</cell></row><row><cell>NLPRCF1S1</cell><cell>0.3074</cell><cell>0.5440</cell><cell>0.2745</cell></row><row><cell>NLPRCF1S1CF2</cell><cell>0.3429</cell><cell>0.5800</cell><cell>0.3105</cell></row><row><cell>NLPRCF1S2</cell><cell>0.3186</cell><cell>0.5620</cell><cell>0.2818</cell></row><row><cell>NLPRCF1S2CF2</cell><cell>0.3441</cell><cell>0.5840</cell><cell>0.3088</cell></row><row><cell>NLPRCF1W</cell><cell>0.3154</cell><cell>0.5000</cell><cell>0.2631</cell></row><row><cell>NLPRCF1WCF2</cell><cell>0.3318</cell><cell>0.5600</cell><cell>0.2876</cell></row><row><cell>NLPRCF2</cell><cell>0.3234</cell><cell>0.5440</cell><cell>0.2745</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><head>ID Tag Expansion 1 Expansion 3 Expansion</head><p>4 Expansion 2 NLPRB No No No No <rs type="grantNumber">NLPRCF1</rs> Yes <rs type="person">Yes Yes</rs> no <rs type="grantNumber">NLPRCF1CF2</rs> No Yes No yes <rs type="grantNumber">NLPRCF1S1</rs> No Yes No No <rs type="grantNumber">NLPRCF1S1CF2</rs> Yes No No Yes <rs type="grantNumber">NLPRCF1S2</rs> No <rs type="person">No Yes</rs> no <rs type="grantNumber">NLPRCF1S2CF2</rs> No No Yes Yes <rs type="grantNumber">NLPRCF1W</rs> Yes No No No <rs type="grantNumber">NLPRCF1WCF2</rs> Yes No No Yes <rs type="grantNumber">NLPRCF2</rs> No No No Yes</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_C3bve2r">
					<idno type="grant-number">NLPRCF1</idno>
				</org>
				<org type="funding" xml:id="_xmyQc3b">
					<idno type="grant-number">NLPRCF1CF2</idno>
				</org>
				<org type="funding" xml:id="_y6P5UMM">
					<idno type="grant-number">NLPRCF1S1</idno>
				</org>
				<org type="funding" xml:id="_bzcjyQa">
					<idno type="grant-number">NLPRCF1S1CF2</idno>
				</org>
				<org type="funding" xml:id="_a2Jwfe9">
					<idno type="grant-number">NLPRCF1S2</idno>
				</org>
				<org type="funding" xml:id="_9fMDjPG">
					<idno type="grant-number">NLPRCF1S2CF2</idno>
				</org>
				<org type="funding" xml:id="_YHwuSwD">
					<idno type="grant-number">NLPRCF1W</idno>
				</org>
				<org type="funding" xml:id="_GFCAkJA">
					<idno type="grant-number">NLPRCF1WCF2</idno>
				</org>
				<org type="funding" xml:id="_aFyN4Rg">
					<idno type="grant-number">NLPRCF2</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,96.01,269.56,78.42,14.42" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Reference</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,309.86,394.35,10.80;8,111.00,325.46,345.25,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,256.48,309.86,243.71,10.80">NLPR at TREC 2003 -Novelty and Robust Track</title>
		<author>
			<persName coords=""><forename type="first">Qianli</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,111.00,325.46,194.19,10.80">Text Retrieval Conference (TREC-2003)</title>
		<meeting><address><addrLine>NIST, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,341.06,394.31,10.80;8,111.00,356.66,394.34,10.80;8,111.00,372.26,56.95,10.80" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<title level="m" coord="8,235.35,341.06,269.96,10.80;8,111.00,356.66,301.66,10.80">Chinese Academy of Science NLPR at TREC 2004: Robust Experiments. Text Retrieval Conference (TREC-2004)</title>
		<meeting><address><addrLine>NIST, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,403.46,394.38,10.80;8,111.00,419.06,394.39,10.80;8,111.00,434.66,109.61,10.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,311.52,403.46,193.86,10.80;8,111.00,419.06,154.84,10.80">Okapi at TREC-7: Automatic Ad Hoc, Filtering, VLC and Interactive</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>S E Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,276.85,419.06,134.20,10.80">Text Retrieval Conference</title>
		<meeting><address><addrLine>TREC-7), NIST, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,450.26,394.36,10.80;8,111.00,465.86,304.35,10.80" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<title level="m" coord="8,265.90,450.26,239.46,10.80;8,111.00,465.86,153.26,10.80">Okapi/Keenbow at TREC-8. The Eighth Text REtrieval Conference (TREC-8)</title>
		<meeting><address><addrLine>NIST, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,481.46,394.34,10.80;8,111.00,497.06,168.31,10.80" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,207.36,481.46,227.38,10.80">On Term Selection for Query Expansion</title>
		<author>
			<persName coords=""><surname>S E Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,450.06,481.46,55.27,10.80;8,111.00,497.06,71.44,10.80">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="359" to="364" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,512.66,394.26,10.80;8,111.00,535.94,107.82,12.78;8,218.88,534.00,5.39,6.24;8,232.32,537.92,210.94,10.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,253.28,512.66,207.19,10.80">A Language Modeling Approach to IR</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,490.59,512.66,14.67,10.80;8,111.00,535.94,107.82,12.78;8,218.88,534.00,5.39,6.24;8,232.32,537.92,117.66,10.80">the Proceedings of the 12 th ACM SIGIR Conference</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.00,559.46,394.39,10.80;8,111.00,575.06,394.30,10.80;8,111.00,590.66,109.61,10.80" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<title level="m" coord="8,477.41,559.46,27.97,10.80;8,111.00,575.06,351.98,10.80">Track Experiments Using PIRCS. Text Retrieval Conference (TREC-2004)</title>
		<meeting><address><addrLine>NIST, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
