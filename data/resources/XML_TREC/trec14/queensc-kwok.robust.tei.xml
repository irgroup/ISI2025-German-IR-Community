<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.64,87.33,312.64,12.64">TREC2005 Robust Track Experiments using PIRCS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,189.24,122.45,50.82,10.80"><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Queens College</orgName>
								<address>
									<postCode>11367</postCode>
									<settlement>CUNY Flushing</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.64,122.45,54.44,10.80"><forename type="first">L</forename><surname>Grunfeld</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Queens College</orgName>
								<address>
									<postCode>11367</postCode>
									<settlement>CUNY Flushing</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.35,122.45,43.96,10.80"><forename type="first">N</forename><surname>Dinstl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Queens College</orgName>
								<address>
									<postCode>11367</postCode>
									<settlement>CUNY Flushing</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.62,122.45,38.63,10.80"><forename type="first">P</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Queens College</orgName>
								<address>
									<postCode>11367</postCode>
									<settlement>CUNY Flushing</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.64,87.33,312.64,12.64">TREC2005 Robust Track Experiments using PIRCS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5DAB9D9E62F0810034FA8670F6DF120B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The two tasks in the TREC2005 Robust track were as follows: given a set of topics, A) predict their ranking according to average precision; and B) improve the effectiveness of their ad hoc retrieval, in particular the weakest topics and if possible with the help of what has been found in task A. The difference from last year is that the test collection (ACQUAINT) is different from the training collection (from TREC2004). The evaluation measures for these tasks have also changed from TREC2004. For task A, it is the difference in area (diff-area) between the observed and the predicted MAP plots when the worst performing topic is successively removed from the set. For task B, it is the GMAP, which is roughly the geometric mean of the average precision of all topics <ref type="bibr" coords="1,132.78,340.06,72.35,9.94" target="#b7">(Voorhees 2005)</ref>.</p><p>We do not believe our techniques for predicting topic average precision is sufficiently accurate to be applied to task B, and treat the two tasks independently. For task A, two methods of predicting topic behavior were tried: i) predicting the weakest and strongest n topics by SVM regression; and ii) ranking topics by retrieved document similarity. For task B, we followed the strategy introduced by us before to improve ad-hoc retrieval via the web as an external thesaurus to supplement a given topic's representation, followed with data fusion. A new method of salient term selection from longer description queries based on SVM classification was employed to define web probes for these queries.</p><p>Five runs were submitted: two for title (pircRB05t2 and -t3), two for description queries (pircRB05d1 and -d3), and one for the combination of the two (pircRB05td3). Section 2 describes our experiments for topic prediction; section 3 describes our weak query effectiveness improvements; and section 4 has our conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Topic Rank Prediction</head><p>We have employed two methods for this task. One uses regression on a reduced problem of predicting only the strongest and weakest topics, and another attempts to do rank prediction based on similarity between retrieved documents. The first method does not rely on a retrieval, and we assume that the ACQUAINT and TREC2004 collections have similar (news-feed) properties, and that trained models from TREC2004 can be transferred to ACQUAINT. The respective methods and their results are discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Top-n and Bot-n Objectives for Prediction</head><p>A number of attempts were tried to predict the ranking of a set of topics before retrieval based on training and regression, particularly for the weakest topics. The end result was that we were rather pessimistic that such total order prediction can be accomplished with much accuracy. The reasons for a topic to return low effectiveness can be very many and varied. There are only a few hundred evaluated topics (and tens of weak ones) for training which is clearly insufficient.</p><p>Even if training data is increased substantially, there is still difficulty in identifying the right features that can differentiate which one topic should be ranked ahead of another, or discriminate weak topics from strong ones. We finally decided to reduce this prediction to (perhaps) an easier problem as discussed below.</p><p>The idea is that given a set of N topics, the n strongest (top-n) and the n weakest topics (bot-n) should have the largest differences in behavior, and hence features to characterize these differences may be easier to apply or identify. During training, we reduce the objective of predicting total ordering of topics to one of predicting only the identity of the top-n and bot-n topics, and ignoring all intermediate ones. We presume that what is learnt can then be applied to predict a rough ranking for all the topics. We define new objectives for training as follows. Suppose we have N=10 queries (labeled a to j), and the focus is on the n=3 worst and best ones. Assume that a system produces a topic ranking as indicated in the 'observed' row (the gold standard), and an algorithm predicts ranking results in the 'predicted' row as shown in Table <ref type="table" coords="2,499.97,226.18,4.31,9.94">1</ref>: bot(weakest) top(strongest) rank-&gt; 1 2 3 4 5 6 7 8 9 10 observed-&gt; a b c d e f g h i j predicted-&gt; i c b a f e j d g h</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: 'Observed' and 'Predicted' Ranking of Topics</head><p>This example shows agreement in bot-3 is 2 (topics b, c), while that for top-3 is 1 (topic h). These are our primary objective; the larger these values are the better. In addition, one can see where the unmatched 'gold standard' topics go in the predicted list: e.g. topic a is ranked 4 by prediction (distance 1 from the bot-3 region), while topics i, j are ranked 1 and 7 (distances 7 and 1 respectively from top-3). An average observed distance 'obs.dis' can be used to characterize these mis-matches: 1/3 and (7+1)/3=2.67 respectively (see Table <ref type="table" coords="2,355.14,405.22,32.45,9.94" target="#tab_1">2 below</ref>). The smaller these distances are the better, and they can be employed to break ties when the primary metric values are equal for two different predicted runs. Similarly, one can also ask where do the unmatched 'predicted' topics come from the observed list: e.g. topic i is ranked 9 by observation (distance 6 from bot-3) and topics d, g are ranked 4 and 7 by observation (distances 4 and 1 from top-3). An average predicted distance 'pre.dis' can also be calculated as 6/3=2 and (4+1)/3=1.67 respectively. In Table <ref type="table" coords="2,167.26,624.34,5.52,9.94" target="#tab_1">2</ref> are also shown the perfect prediction, and others that agree on only 2 or 1 in bot-3 and top-3 respectively, and their best 'distance' values. 'obs.dis' informs us where unmatched 'gold standard' topics have ended up in the predicted list, and 'pre.dis' informs us where the replacements come from the observed list. These can be compared with the 'best-n' distances, and displayed in the δ (difference from best) row to show how far these distances are from the 'best-n' values. One can focus only on the bot-3 with an evaluation measure for this prediction of &lt;bot-3, δ&gt; = &lt;2,1.67&gt;, or on the top-3 with measure &lt;1, 2.34&gt;. Clearly the bot-3 prediction is much better than top-3 for this example. One can also combine both bot-3 and top-3 together with measure &lt;bot-3+top-3, δ&gt; = &lt;3, 4.01&gt;. For this, the perfect prediction has measure &lt;6,0&gt;, and the best with 3 matches is &lt;3,0&gt;. Our objective is to maximize 'bot-3+top-3' and minimize δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prediction by Regression</head><p>We continue to use the LIBSVM software <ref type="bibr" coords="3,315.58,164.02,85.51,9.94" target="#b0">(Chang &amp; Lin 2004</ref>) to define a support vector regressor based on training and prediction using TREC2004 data with 249 topics. The features we employed include:</p><p>(a) idf k = log(Nd/df k ) for the top three terms in a query. 'top' is defined later, and Nd = number of documents, df k = document frequency of term k;</p><p>(b) 5-interval 'average term frequency' (v k ) distribution of all query terms. v k = (Cf k /df k ) 1.5 /[log max(constant, df k )], defined in <ref type="bibr" coords="3,302.75,239.98,58.15,9.94" target="#b5">(Kwok 1996)</ref>, and Cf k = collection frequency of term k;</p><p>Here, idf k (or its variants) is the basis of term weighting for many retrieval algorithms and is a natural choice. We choose the top three terms based on sorting by v k . This seems to give better results than via sorting by idf k . v k has the (Cf k /df k ) factor which is similar to term burstiness used in computational linguistics <ref type="bibr" coords="3,238.92,315.82,53.06,9.94">(Katz 1997)</ref> and can be useful for indicating whether a term has important content value. We modified it by a 1/[log max(constant, df k )] factor in <ref type="bibr" coords="3,461.93,328.54,55.04,9.94" target="#b5">(Kwok 1996</ref>) that depresses the value for high df k terms. The 5-interval v k distribution of terms intends to capture the quality of the whole query through its term importance. The intervals are chosen as: df k &lt; 2000, df k &gt;40000, v k &lt;.24, v k &lt;.3, v k &gt;=.3. The high and low thresholds are defined by frequencies instead, because some terms in these ranges may have abnormal high or low v k values. Terms satisfying these thresholds sequentially have their v k values summed for each of the intervals. These features have been shown to provide reasonable prediction of bot-n and top-n <ref type="bibr" coords="3,90.00,417.10,57.08,9.94" target="#b2">(Kwok 2005)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weak Topic Improvement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results of Prediction by Regression</head><p>pircRB05t2, pircRB05d3 are runs with the above bot-n/top-n prediction procedures. Their results are tabulated in Table <ref type="table" coords="4,221.93,114.58,5.52,9.94" target="#tab_3">3</ref> under the 'Topic Ranking Prediction' columns. They return 'diffarea' values of 1.4823 and 1.2092 respectively. The best and median values for title runs are .0016 and 1.4250, while those for description runs are .4049 and 1.2262. The best values may be biased by some runs that have low or close to zero average precision values for their topics. Prediction for our title run is below median; description prediction is above. For pircRB05td3, because of time constraint, the pircRB05d3 ranking was used for its prediction ('Method' svm-). Its 'diff-area' value of 1.6065 is below the median of 1.4093 for 'other' runs.</p><p>For the two SVM prediction runs, we also show in Table <ref type="table" coords="4,381.51,203.14,5.52,9.94" target="#tab_5">4</ref> predictions of bot-6 and top-6 values. The '-04' attached to a Run-ID means using the TREC-2004 robust collection for the same procedures trained (with 199 topics) and testing on TREC-2005 robust topics. On average there were about 8/24=1/3 correct predictions. The 'diff-area' values are also good: about .7-.8. However, the trained regression model has problem generalizing to the ACQUAINT collection. Correct predictions now drop by half to an average of 4/24=1/6. Moreover, all the secondary observed and predicted 'distance-difference-from-best' measures increase also, except for top-6 'pre.dis'. Even if one stays with the TREC-2004 collection, i.e. without the complication of cross-collection generalization, the 1/3 accuracy rate is probably too low for any real application of this prediction process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Prediction by Retrieved Document Similarity</head><p>A query q retrieves ordered documents d i from a collection C. Each d i can be represented by a vector of weights corresponding to each term. We assume these documents can characterize the query and the quality of the retrieval. The rationale for our approach is as follows: 1) in a 'good' retrieval the relevant documents are concentrated towards the top ranking positions; 2) relevant documents are more similar to each other than non-relevant documents; 3) a strong query retrieves a more cohesive group of documents; a weak query does not represent a well-defined concept and will retrieve many diverse, unrelated documents.</p><p>Our method consists of the following steps, which measures the similarity of the top group of retrieved documents to the remainder:</p><p>1) Divide the ranked retrieved documents into m groups, by rank.</p><p>2) Combine each group into one large document vector.</p><p>3) Measure the vector similarity of each group to the top group. 4) Combine the similarities by calculating the average, or some weighted formula, where higher ranked groups may be considered more important.</p><p>To test the algorithm we used the top 200 documents retrieved for each query by our PIRCS engine. m, the number of groups was set to 5 after experimenting with values between 4 and 20. Two common similarity measures were tried, vector product and covariance. No appreciable difference was detected and we selected the vector measure. The number of terms used for the groups was set to 40 after experimenting with values between 20 and 200. We tested whether to compare the top group to the others or to compare all groups to each other, with the result that comparing the top group seems to be a better predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Results of Prediction by Retrieved Document Similarity</head><p>The runs that make use of this method are pircRB05t3 and pircRB05d1. The 'diff-area' values are 1.9402 and 1.7325 which are disappointing. Their correlation between the predicted query rank and the actual rank was negligible. We are currently reviewing the results to determine whether the problem lies in our algorithm or the experimental procedure, or perhaps the distributions of retrieval results from the two collections are very different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Improving Ad Hoc Retrieval</head><p>Our results for this year's robust tasks are also summarized in Table <ref type="table" coords="5,448.28,267.46,4.15,9.94" target="#tab_3">3</ref>. GMAP is the geometric mean average precision specially designed to evaluate low performing topics with heavier emphasis. The method is similar to last year's: construct web probes from a given query, use the web as an all-domain thesaurus to define alternate queries, combine retrieval lists from original and alternate queries after retrieval from ACQUAINT collection. The sub-sections below discussed our procedures for the different topic types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Title Queries</head><p>Title (1 to 4 words long) or title words and phrases (formed via MINIAPR parsing <ref type="bibr" coords="5,503.13,384.70,19.04,9.94;5,90.00,397.42,19.61,9.94" target="#b6">(Lin 1994</ref>)) defined the web probes. Three alternate queries were formed from web output of full pages, snippets or both. Retrieval lists from ACQUAINT collection were combined two by two with coefficients trained via TREC2004 collection. This is our pircRB05t2 submission. pircRB05t3 makes use of only one alternate query that combines with the original title retrieval list. We like to see how results from this much simpler procedure differ from the more elaborate one of combining four lists.</p><p>Results show that pircRB05t2 attains GMAP, MAP and P10 values of 0.1957, 0.2798 and 0.5420 respectively, while the corresponding values for pircRB05t3 are 0.1905, 0.2769 and 0.5380. pircRB05t3 provides slightly weaker effectiveness than the more elaborate pircRB05t2. However, the decrease for GMAP is nearly 3%, more than the 1% decrease for the other traditional metrics. Combining more different lists can provide opportunity for more weak queries to get improved <ref type="bibr" coords="5,162.39,536.50,83.98,9.94" target="#b2">(Kwok et. al. 2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Description Queries</head><p>To select salient terms from a description query as web probe, we introduced term classification based on a SVM model trained via the paired title words as positive samples <ref type="bibr" coords="5,491.54,603.22,30.79,9.94;5,90.00,615.82,51.45,9.94" target="#b2">(Kwok et. al. 2005)</ref>. The selected terms are used in two ways: i) to enhance the original query by double weighting the selected terms (enhanced description query); ii) used for web probing and form alternate queries. In addition, two other alternate queries were formed via term selection by MINIPAR-tagged POS. pircRB05d1 combines 4 lists and pircRB05d3 combines 2 lists, similar to title runs.</p><p>Again, pircRB05d1 gives better GMAP results of .1252 vs. .1205 for pircRB05d3, a decrease of nearly 4%. MAP and P10 measures decrease less similar to the behavior of title queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Title + Description Queries</head><p>Our best submitted result is obtained by combining the pircRB05t3 and pircRB05d3, which involves combining four lists, two from title and two from description runs. In terms of combination complexity, it is the same as a pricRB05t2 or -d1 runs. It's GMAP, <ref type="bibr" coords="6,457.86,127.30,43.39,9.94">MAP and</ref><ref type="bibr" coords="6,504.74,127.30,17.20,9.94;6,90.00,139.90,102.11,9.94">P10 values are .2047, .2813</ref> and .5440 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Collection Effect on Topic Strength</head><p>In our experiments, the same queries were derived and trained from the TREC2004 collection and transferred to ACQUAINT for retrieval. Thus, we have comparable results from the two collections, and their effects on how queries behave can be ascertained. Fig. <ref type="figure" coords="6,481.05,219.22,9.29,9.94" target="#fig_0">1a</ref> shows results of retrieval from the two collections sorted according to the weakness of title queries (pircRB05t2), and Fig. <ref type="figure" coords="6,192.79,244.54,9.49,9.94" target="#fig_0">1b</ref> for the title+description run (pircRB05td3). It is seen that in both plots, results from TREC2004 are inferior to those from ACQUAINT except for the one weakest query in Fig. <ref type="figure" coords="6,121.12,269.86,8.92,9.94" target="#fig_0">1b</ref>. This accounts for the difference of GMAP values for pircRB05t2: .1958 vs. .1308 (TREC2004) and for pircRB05td3: .2047 vs. .1456 (TREC2004). Some eleven individual queries perform worse in ACQUAINT than in TREC2004 with decrease of average precision of .1180, while thirty nine improve with average precision of .1432. Topic difficulty is thus a relative concept: the same query may be weak for collection TREC2004 but reasonable or even strong for collection ACQUAINT. If one makes use of multiple external collections as aids for target retrieval (e.g. collection enrichment <ref type="bibr" coords="6,255.24,559.90,97.55,9.94" target="#b4">(Kwok &amp; Chan 1998)</ref>), the probability of improving weak query effectiveness should be higher. This indirectly also shows that our procedure of appealing to the web as an all-domain thesaurus to help target retrieval via alternate queries is a step in the right direction for the objective of the robust track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We investigated an approach of training an SVM-based regression model for predicting query performance by trying to predict only the best (top-6) and the worst (bot-6) topics from an initial retrieval in the TREC-2004 collection, and allowing the model to forecast the performance of the same topic set in the ACQUAINT collection. The result of this cross-collection prediction is much worse than predictions within the TREC-2004 collection.</p><p>For the improvement of query performance, our procedure of defining alternate queries via web-assistance and later combining their retrieval lists with the original one continue to deliver above average results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,119.64,534.82,372.64,9.94"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1: Effect of Collections on Query Weakness. a) pircRB05t2; b) pircRB05td3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,162.60,494.50,286.89,88.90"><head>bot-3 pre.dis obs.dis top-3 pre.dis obs.dis predicted</head><label></label><figDesc></figDesc><table coords="2,168.36,507.46,274.56,75.94"><row><cell></cell><cell>2(bc)</cell><cell>2</cell><cell>.33</cell><cell>1(h)</cell><cell>1.67</cell><cell>2.67</cell></row><row><cell>δ</cell><cell>2</cell><cell>1.67</cell><cell>0</cell><cell>1</cell><cell>.67</cell><cell>1.67</cell></row><row><cell cols="7">Perfect and Best Predictions with Agreements 2 and 1</cell></row><row><cell>perfect</cell><cell>3</cell><cell>0</cell><cell>0</cell><cell>3</cell><cell>0</cell><cell>0</cell></row><row><cell>best-2</cell><cell>2</cell><cell>.33</cell><cell>.33</cell><cell>2</cell><cell>.33</cell><cell>.33</cell></row><row><cell>best-1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,132.24,599.26,347.55,9.94"><head>Table 2 : Evaluation of 'Predicted' by top-3/bot-3 Agreements &amp; Distances</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,142.08,456.82,327.98,219.82"><head>Topic Ranking Prediction RunID GMAP MAP P10 'diff-area' Method Title pircRB05t2</head><label></label><figDesc></figDesc><table coords="3,142.08,496.06,323.36,180.58"><row><cell></cell><cell>.1957</cell><cell>.2798</cell><cell>.5420</cell><cell>1.4823</cell><cell>svm</cell></row><row><cell>pircRB05t3</cell><cell>.1905</cell><cell>.2769</cell><cell>.5380</cell><cell>1.9402</cell><cell>similarity</cell></row><row><cell>best</cell><cell>.2326</cell><cell>.3323</cell><cell cols="2">.5920 0.0016</cell><cell></cell></row><row><cell>median</cell><cell>.1293</cell><cell>.2239</cell><cell cols="2">.4340 1.4250</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Description</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">pircRB05d1 .1252</cell><cell>.2303</cell><cell>.4660</cell><cell>1.7325</cell><cell>similarity</cell></row><row><cell cols="2">pircRB05d3 .1208</cell><cell>.2228</cell><cell>.4640</cell><cell>1.2092</cell><cell>svm</cell></row><row><cell>best</cell><cell>.1784</cell><cell>.2891</cell><cell cols="2">.5360 0.4049</cell><cell></cell></row><row><cell>median</cell><cell>.1028</cell><cell>.1839</cell><cell cols="2">.3860 1.2262</cell><cell></cell></row><row><cell></cell><cell cols="3">Title+Description</cell><cell></cell><cell></cell></row><row><cell cols="2">pircRB05td3 .2047</cell><cell>.2813</cell><cell>.5440</cell><cell>1.6065</cell><cell>copy from</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>pircRB05d3</cell></row><row><cell>best</cell><cell>.2326</cell><cell>.3323</cell><cell cols="2">.6280 0.0016</cell><cell></cell></row><row><cell>median</cell><cell>.1256</cell><cell>.2182</cell><cell cols="2">.4320 1.4093</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,135.00,692.50,341.91,9.94"><head>Table 3 : Results of Title, Description, and Title+Description Submissions</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,119.64,343.06,372.81,62.50"><head>bot-6 pre.dis obs.dis top-6 pre.dis obs.dis 'diff-area</head><label></label><figDesc></figDesc><table coords="4,119.64,343.06,372.81,62.50"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>'</cell></row><row><cell>pircRB05t2-04</cell><cell>2</cell><cell>10.0</cell><cell>2.0</cell><cell>1</cell><cell>13.3</cell><cell>10.5</cell><cell>.7112</cell></row><row><cell>pircRB05d3-04</cell><cell>3</cell><cell>10.3</cell><cell>4.8</cell><cell>2</cell><cell>5.7</cell><cell>10.0</cell><cell>.7888</cell></row><row><cell>pircRB05t2</cell><cell>1</cell><cell>14.0</cell><cell>12.7</cell><cell>1</cell><cell>3.8</cell><cell>17.5</cell><cell>1.4823</cell></row><row><cell>pircRB05d3</cell><cell>0</cell><cell>16.7</cell><cell>10.7</cell><cell>2</cell><cell>3.0</cell><cell>11.5</cell><cell>1.2092</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,128.64,421.42,354.63,9.94"><head>Table 4 : Bot-6 and Top-6 Predictions for Title and Description Submissions</head><label>4</label><figDesc></figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,90.00,151.42,428.95,9.94;7,90.00,164.02,183.37,9.94" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,237.70,151.42,216.96,9.94">LIBSVM: a Library for Support Vector Machines</title>
		<author>
			<persName coords=""><forename type="first">C-C And</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,189.34,428.62,9.94;7,90.00,202.06,171.34,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,160.07,189.34,317.75,9.94">Distribution of content words and phrases in text and language modeling</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,485.52,189.34,33.10,9.94;7,90.00,202.06,97.94,9.94">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="59" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,227.26,431.90,9.94;7,90.00,239.98,431.99,9.94;7,90.00,252.58,91.48,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,178.44,227.26,231.86,9.94">An attempt to identify weakest and strongest queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<ptr target="http://www.haifa.il.ibm.com/sigir05-qp/papers/kwok.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,429.73,227.26,92.17,9.94;7,90.00,239.98,254.89,9.94">Proc. of SIGIR 2005 Workshop on Predicting Query Difficulty. 2005</title>
		<meeting>of SIGIR 2005 Workshop on Predicting Query Difficulty. 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,277.90,432.28,9.94;7,90.00,290.62,432.05,9.94;7,90.00,303.22,174.71,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,350.46,277.90,171.82,9.94;7,90.00,290.62,151.00,9.94">Improving Weak Ad-Hoc Retrieval by Web Assistance and Data Fusion</title>
		<author>
			<persName coords=""><forename type="first">Kui-</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Grunfeld</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">&amp;</forename><surname>Laszlo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,266.91,290.62,225.87,9.94">Proc. of Asian Information Retrieval Symposium</title>
		<meeting>of Asian Information Retrieval Symposium</meeting>
		<imprint>
			<publisher>Springer-Verlag LNCS</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">3689</biblScope>
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,328.54,432.18,9.94;7,90.00,341.14,248.24,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,236.29,328.54,235.04,9.94">Improving two-stage ad-hoc retrieval for short queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,478.56,328.54,43.63,9.94;7,90.00,341.14,188.97,9.94">Proc. 21st Ann. Intl. ACM SIGIR Conf. on R&amp;D in IR</title>
		<meeting>21st Ann. Intl. ACM SIGIR Conf. on R&amp;D in IR</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,366.46,432.14,9.94;7,90.00,379.06,224.08,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,177.48,366.46,259.37,9.94">A new method of weighting query terms for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,443.23,366.46,78.91,9.94;7,90.00,379.06,164.93,9.94">Proc. 19th Annual Intl. ACM SIGIR Conf. on R&amp;D in IR</title>
		<meeting>19th Annual Intl. ACM SIGIR Conf. on R&amp;D in IR</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="187" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,404.38,432.07,9.94;7,90.00,417.10,110.88,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,167.29,404.38,309.73,9.94">PRINCIPAR -an efficient, broad-coverage, principle-based parser</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,486.72,404.38,35.35,9.94;7,90.00,417.10,52.06,9.94">Proc of COLING-94</title>
		<meeting>of COLING-94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="482" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,90.00,442.30,432.07,9.94;7,90.00,455.02,432.12,9.94;7,90.00,467.62,408.36,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,205.08,442.30,239.58,9.94">Overview of the TREC 2004 Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,469.65,442.30,52.42,9.94;7,90.00,455.02,432.12,9.94;7,90.00,467.62,39.98,9.94">Information Technology: The Thirteenth Text REtrieval Conference, TREC 2004. E.M. Voorhees &amp; L.P. Buckland</title>
		<meeting><address><addrLine>US GPO; Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
