<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.19,115.96,304.98,12.62">L3S at the TREC 2022 CrisisFACTS Track</title>
				<funder ref="#_JZevjjj">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_JCFusSh">
					<orgName type="full">German Research Foundation (DFG)</orgName>
				</funder>
				<funder ref="#_fgP8ay4">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_VzgT7ED">
					<orgName type="full">Science and Engineering Research Board, Department of Science and Tech-nology, Government of India</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,217.03,153.75,83.02,8.74"><forename type="first">Thi</forename><forename type="middle">Huyen</forename><surname>Nguyen</surname></persName>
							<email>nguyen@l3s.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">L3S Research Center</orgName>
								<address>
									<settlement>Hannover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.21,153.75,66.64,8.74"><forename type="first">Koustav</forename><surname>Rudra</surname></persName>
							<email>koustav@iitism.ac.in</email>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology (Indian School of Mines</orgName>
								<address>
									<settlement>Dhanbad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.19,115.96,304.98,12.62">L3S at the TREC 2022 CrisisFACTS Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">184BA6209202F881EB4D70DC4BA0A5CB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Crisis events</term>
					<term>summarization</term>
					<term>retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our proposed approach for the multistream summarization of the crisis-related events in the TREC 2022 CrisisFACTS track [2]. We apply a retrieval and ranking-based two-step summarization approach. First, we employ a sparse retrieval framework where content texts from multiple online streams are treated as a document corpus, and a term matching-based retrieval strategy is used to retrieve relevant contents, so-called facts, to the set of queries in a given event day. Next, we use several pre-trained models to measure semantic similarity between query-fact or fact-fact pairs, score and rank the facts for the extraction of daily event summaries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Summarization has been a topic of increasing interest in recent years. During crises, it is important to generate short, informative, and non-redundant summaries of the events to help local communities and stakeholders obtain prompt updates and react accordingly. Many recent works have proposed various summarization approaches <ref type="bibr" coords="1,236.75,476.67,10.52,8.74" target="#b3">[5,</ref><ref type="bibr" coords="1,248.93,476.67,4.54,8.74" target="#b6">[8]</ref><ref type="bibr" coords="1,253.47,476.67,4.54,8.74" target="#b7">[9]</ref><ref type="bibr" coords="1,258.01,476.67,13.62,8.74" target="#b8">[10]</ref><ref type="bibr" coords="1,273.28,476.67,11.62,8.74" target="#b10">12]</ref>. However, these studies assume that all the input texts of the summarization models are relevant to the event. Some of them filter out irrelevant content by applying classification methods, yet it requires labeled data for training the classifiers. Besides, previous studies mainly focus on specific traits of a certain data source, such as Twitter or news articles, but not multi-stream data for summarization.</p><p>This work focuses on summarization of multi-stream datasets that are suitable to the information needs of emergency responders. We take advantage of both sparse and dense representation techniques to find the most relevant, important, and diverse facts as event summaries. More specifically, we apply a sparse retrieval framework that allows quick indexing and retrieval of facts for a given query set. However, this step only relies on simple term-based matching and does not capture the semantic matching among queries and facts. Hence, we further employ multiple language models pre-trained on various sentence similarity tasks (details Section 2) to extract semantic representations of queries and facts for ranking and extracting daywise event summaries. Earlier, Akula et al <ref type="bibr" coords="1,470.08,656.12,10.52,8.74" target="#b1">[3]</ref> showed that a combination of different semantic representation approaches gives effective results in summarization. Hence, we use an ensemble of different semantic similarity scores to get the final scores of facts obtained in the term-based matching stage. In this paper, we propose two different ranking approaches to retrieve the event summary. First, we rely on the semantic similarity scores between query-fact pairs and retrieve facts that have the highest mean similarity scores with queries as the summary. In the second approach, we only consider fact-fact pairs to form a graph based on the semantic similarity among the facts and retrieve the final summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>Given a list of content text T = {t 1 , t 2 , .., t n } from multiple streams (i.e., Twitter, Reddit, Web News) and a set of queries Q = {q 1 , q 2 , .., q k } defining the information needs of stakeholders in a specific event day, our aim is to return a list of maximum K relevant content texts, so-called facts (S ⊂ T ), along with their importance scores as our daywise system summary. In this section, we introduce our proposed summarization approach, which consists of two stages -(i). Relevant Fact Retrieval, (ii). Ranking and Summarization. We elaborate our retrieval and two different ranking approaches to extract informative and diverse daywise summaries of disaster events in the following parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Fact Retrieval</head><p>During crisis events, human organizations or stakeholders want to receive a summary with respect to specific information needs. However, CrisisFACTS dataset contains information from different sources such as Twitter, Reddit, Facebook, etc., and many contents do not satisfy the specific requirements mentioned in queries. Side by side, the collection of content texts is significantly large, which may hamper the fast functioning of the summarization step (Section 2.2). Hence, we first apply a term-based matching approach to gather the relevant content (so-called facts) for a given query set. We use pyTerrier <ref type="bibr" coords="2,383.72,514.93,9.96,8.74" target="#b4">[6]</ref>, which is a Python retrieval framework. It provides the implementation of several term-based matching models, but we choose to use DFReeKLIM <ref type="bibr" coords="2,336.11,538.85,10.52,8.74" target="#b2">[4]</ref> due to its effectiveness in short document retrieval tasks <ref type="bibr" coords="2,246.08,550.80,9.96,8.74" target="#b5">[7]</ref>. Given a set of texts T from multiple streams and a list of queries Q in each event day, we obtain a subset of facts RF ⊂ T , which consists of relevant content texts to the query set Q. These facts are then used as input to our summarization methods described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ranking and Summarization</head><p>In this section, we propose two different summarization approaches based on facts retrieved in the first phase.</p><p>Query-based Summarization DFreeKLIM model retrieves a set of relevant content with respect to each query in the query set (Q) from the entire text corpus (T ). Hence, we obtained a set of facts for each of the queries. Let's say, for query q, the set of facts is presented via set RF q . However, semantic aspects are missing in this step.</p><p>First, we calculate the semantic score between queries q ∈ Q and all the facts f ∈ RF, RF = ∪ q∈Q RF q . To compute the score, we extract contextual embeddings of facts and queries using multiple language models that were pre-trained on several sentence pair tasks, such as semantic text similarity, paraphrase detection, natural language inference, and passage retrieval. Given M pre-trained models, we compute M cosine similarity scores between embeddings of a fact and a query. The final similarity score between a fact and a query is the average of M similarity scores. Our aim is to extract the most relevant and important facts with respect to queries of the event day as a summary. The importance score of a fact is the average similarity score between the fact and all the queries. Figure <ref type="figure" coords="3,166.20,298.72,4.98,8.74" target="#fig_0">1</ref> illustrates steps to compute importance score of facts in an event day.</p><p>We select facts gradually and in chronological order for our final summary. At each step, we select a fact with the highest importance score. Whenever a fact is selected, we compare the Simpson [1] similarity score of the fact with all the chosen ones from the same and previous days. If the Simpson overlapping score between the current fact and any chosen one exceeds a threshold α, we ignore the fact and select the next important fact for consideration. The process stops when we reach a pre-defined number of K facts in the final summary. Graph-based summarization In this summarization approach, we assume that all the facts returned by DFReeKLIM are somewhat relevant to queries the event day. We focus on finding the most informative and diverse facts based on a semantic graph. Similar to the previous approach, we employ M language models pre-trained on sentence similarity tasks to extract contextualized semantic embeddings of facts.</p><p>Next, we construct a graph G = (V, E, W ) of facts, where the node set V represents fact texts from previous summaries and all facts of the current event day. An edge (v i , v j ) ∈ E connects two nodes v i and v j in the graph. w ij ∈ W is the average cosine similarity scores between different embedding representations of two facts v i , v j . We zero out the weight of an edge if it connects a chosen node v i from any previous summary and a node v j , and w ij &gt; β. Then, a centrality score is computed for every node in the graph.</p><formula xml:id="formula_0" coords="4,247.91,189.45,232.69,20.53">centrality(v i ) = j∈{V \i} w ij (1)</formula><p>We consider all facts of the current event day in chronological order. First, a node with the highest centrality score is included in our summary. Whenever a node v i is selected, we zero out all the edge weights from v i to any node v j if w ij &gt; β and update the centrality The selection process stops when we reach a pre-defined number of K facts in the final summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental setup</head><p>We run our experiments on the dataset provided by CrisisFACTS track <ref type="bibr" coords="4,450.79,343.51,9.96,8.74" target="#b0">[2]</ref>. We consider all content texts from Twitter, Reddit, and Web News. The following models pre-trained on various sentence similarity tasks <ref type="bibr" coords="4,378.60,367.42,15.50,8.74" target="#b9">[11]</ref> are used to extract semantic representations of facts and queries.</p><p>-Semantic Text Similarity: stsb-roberta-large, stsb-distilroberta-base-v2 -Paraphrase Detection: paraphrase-xlm-r-multilingual-v1, paraphrase-distilroberta-base-v2 -Natural Language Inference: nli-roberta-large -Passage Retrieval: bert-base-nli-max-tokens, msmarco-roberta-base-v2 Thresholds α and β in our query-based and graph-based summarization methods are set to 0.75 and 0.95, respectively. Besides, we select maximum K = 200 facts as a final summary for each event day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Metrics</head><p>We report our results using two sets of metrics introduced by CrisisFACTS track:</p><p>-Metric 1 (Standard metrics): The top-k facts of system summaries for each system's event-day pair are compared against extant summaries using ROUGE or BERTScore metrics. The extant summaries include the summaries extracted from Wikipedia articles, ICS209 reports, or NIST-based summaries. k is defined by CrisisFACTS organizers. -Metric 2 (Fact-matching): Given S and F are the set of ranked facts in a system summary, and the gold summary produced by NIST assessors. the comprehensiveness and redundancy ratio metrics are defined as below:</p><p>• Comprehensiveness: Amount of gain for each unique fact in the gold summary f ∈ F covered by our system summary.</p><formula xml:id="formula_1" coords="5,237.60,147.45,242.99,27.27">C(S) = 1 sum f ∈F R(f ) f ∈F :M (f,S) / ∈∅ R(f )<label>(2)</label></formula><p>where M (f, S) is the list of system facts that match the fact f . R(f ) is the gain assigned to the fact f , which is set to 1 for this year. • Redundancy ratio: number of unique facts that match a gold-standard fact divided by the total number of fact matches present. Fig. <ref type="figure" coords="5,153.45,451.65,3.87,8.74">2</ref>: Evaluation of our system summaries using standard metrics. ics, nist and wiki denotes summaries extracted from ICS209 reports, NIST-based assessments and Wikipedia articles.</p><formula xml:id="formula_2" coords="5,259.00,237.76,221.59,26.60">R(S) = f ∈F :M (f,S) / ∈∅ R(f ) f ∈F R(f ).|M (f, S)|<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Figure <ref type="figure" coords="5,181.96,512.66,4.98,8.74">2</ref> illustrates the average results of our system summaries across all event-day pairs under standard metrics. Our query-based and graph-based summarization models obtain competitive performance in terms of both BERTScore and ROUGE-2, and across all extant summaries. The query-based method tends to show slightly better results compared to the graph-based model.</p><p>In Figure <ref type="figure" coords="5,193.59,572.43,3.87,8.74">3</ref>, we compare performance of our two proposed approaches using fact-matching metrics. It is evident that the graph-based model retrieves a significantly higher number of matched facts compared to the query-based method. However, the set of facts returned by the graph-based method is less comprehensive and more redundant. It indicates that the model fails to cover diverse facts in the gold summaries. This could be influenced by our hyper-parameter setup and the ignorance of query-fact relevance scores in graph building and facts ranking. Fig. <ref type="figure" coords="6,154.96,256.42,3.87,8.74">3</ref>: Evaluation of our system summaries using fact-matching-based metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This study introduces two different approaches to generate temporal summaries of crisis events from multi-streams. We apply two-step summarization methods. First, we employ a sparse retrieval method to retrieve relevant facts. Then, we rely on semantic similarity between or fact pairs computed using different pre-trained models trained on various sentence similarity tasks to extract event summaries. In the future, we will investigate various traits of different streams to fine-tune our summarization results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,168.51,515.04,278.35,8.74"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Overview of steps to compute importance scores of facts.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work is partially funded by the <rs type="funder">German Research Foundation (DFG)</rs>, project <rs type="person">Managed Forgetting</rs> (<rs type="grantNumber">NI-1760/1-1</rs>), and the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs>, <rs type="projectName">CRiTERIA</rs> project, under grant agreement No. <rs type="grantNumber">101021866</rs>. Further, this work is supported in part by the <rs type="funder">Science and Engineering Research Board, Department of Science and Tech-nology, Government of India</rs>, under Project <rs type="grantNumber">SRG/2022/001548</rs>. <rs type="person">Koustav Rudra</rs> is a recipient of the <rs type="grantName">DST-INSPIRE Faculty Fellowship</rs> [<rs type="grantNumber">DST/INSPIRE/04/ 2021/003055</rs>] in the year 2021 under Engineering Sciences.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JCFusSh">
					<idno type="grant-number">NI-1760/1-1</idno>
				</org>
				<org type="funded-project" xml:id="_fgP8ay4">
					<idno type="grant-number">101021866</idno>
					<orgName type="project" subtype="full">CRiTERIA</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
				<org type="funding" xml:id="_VzgT7ED">
					<idno type="grant-number">SRG/2022/001548</idno>
					<orgName type="grant-name">DST-INSPIRE Faculty Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_JZevjjj">
					<idno type="grant-number">DST/INSPIRE/04/ 2021/003055</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,580.02,286.55,7.86" xml:id="b0">
	<analytic>
		<title/>
		<ptr target="https://crisisfacts.github.io/" />
	</analytic>
	<monogr>
		<title level="j" coord="6,173.02,580.02,108.04,7.86">TREC CrisisFACTS Track</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,591.01,337.64,7.86;6,151.52,601.97,329.07,7.86;6,151.52,612.93,329.07,7.86;6,151.52,623.89,69.25,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,245.93,591.01,234.67,7.86;6,151.52,601.97,158.84,7.86">Sentence pair embeddings based evaluation metric for abstractive and extractive summarization</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Akula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Garibay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,334.01,601.97,146.58,7.86;6,151.52,612.93,226.90,7.86">Proceedings of the Thirteenth Language Resources and Evaluation Conference, LREC 2022</title>
		<meeting>the Thirteenth Language Resources and Evaluation Conference, LREC 2022<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-06">June 2022 (2022</date>
			<biblScope unit="page" from="20" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,634.88,337.64,7.86;6,151.52,645.84,329.07,7.86;6,151.52,656.80,329.07,7.86;7,151.52,119.67,329.07,7.86;7,151.52,130.63,131.45,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,372.28,645.84,108.31,7.86;6,151.52,656.80,115.92,7.86">Fub, iasi-cnr, UNIVAQ at TREC 2011 microblog track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amodeo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marcone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">U</forename><surname>Bordoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gaibisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gambosi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Nicola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flammini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,290.62,656.80,189.97,7.86;7,151.52,119.67,42.62,7.86">Proceedings of The Twentieth Text REtrieval Conference</title>
		<meeting>The Twentieth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="2011-11-15">2011. November 15-18, 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,141.59,337.64,7.86;7,151.52,152.55,329.07,7.86;7,151.52,163.51,329.07,7.86;7,151.52,174.47,250.50,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,233.17,141.59,179.61,7.86">Text summarization with pretrained encoders</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,432.51,141.59,48.08,7.86;7,151.52,152.55,329.07,7.86;7,151.52,163.51,329.07,7.86;7,151.52,174.47,53.52,7.86">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">November 3-7, 2019 (2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,185.43,337.64,7.86;7,151.52,196.39,329.07,7.86;7,151.52,207.34,329.07,7.86;7,151.52,218.30,320.77,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,392.21,185.43,88.38,7.86;7,151.52,196.39,226.44,7.86">Pyterrier: Declarative experimentation in python from BM25 to dense retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,398.27,196.39,82.32,7.86;7,151.52,207.34,304.95,7.86">CIKM &apos;21: The 30th ACM International Conference on Information and Knowledge Management</title>
		<meeting><address><addrLine>Queensland, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">November 1 -5, 2021. 2021</date>
			<biblScope unit="page" from="4526" to="4533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,229.26,337.63,7.86;7,151.52,240.22,329.07,7.86;7,151.52,251.18,272.81,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,278.80,229.26,201.79,7.86;7,151.52,240.22,116.35,7.86">Relevance in microblogs: enhancing tweet retrieval using hyperlinked documents</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,290.81,240.22,189.78,7.86;7,151.52,251.18,43.80,7.86">Open research Areas in Information Retrieval, OAIR 2013</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">May 15-17, 2013. 2013</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,262.14,337.63,7.86;7,151.52,273.10,329.07,7.86;7,151.52,284.06,329.07,7.86;7,151.52,295.02,136.15,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,284.93,262.14,195.66,7.86;7,151.52,273.10,234.37,7.86">Summarunner: A recurrent neural network based sequence model for extractive summarization of documents</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,406.88,273.10,73.71,7.86;7,151.52,284.06,224.33,7.86">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">February 4-9, 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,305.98,337.63,7.86;7,151.52,316.93,329.07,7.86;7,151.52,327.89,329.07,7.86;7,151.52,338.85,134.42,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,257.71,305.98,222.88,7.86;7,151.52,316.93,190.39,7.86">Rationale aware contrastive learning based approach to classify and summarize crisis-related microblogs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Rudra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,362.74,316.93,117.85,7.86;7,151.52,327.89,269.36,7.86">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 31st ACM International Conference on Information &amp; Knowledge Management<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">October 17-21, 2022 (2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,349.81,337.98,7.86;7,151.52,360.77,329.07,7.86;7,151.52,371.73,310.44,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,257.48,349.81,223.11,7.86;7,151.52,360.77,146.18,7.86">Towards an interpretable approach to classify and summarize crisis events from microblogs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Rudra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,320.04,360.77,160.55,7.86;7,151.52,371.73,77.73,7.86">WWW &apos;22: The ACM Web Conference 2022, Virtual Event</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">April 25 -29, 2022. 2022</date>
			<biblScope unit="page" from="3641" to="3650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,382.69,337.97,7.86;7,151.52,393.65,329.07,7.86;7,151.52,404.61,300.74,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,257.91,382.69,222.68,7.86;7,151.52,393.65,33.97,7.86">Sentence-bert: Sentence embeddings using siamese bertnetworks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,205.56,393.65,275.03,7.86;7,151.52,404.61,82.56,7.86">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,415.56,337.97,7.86;7,151.52,426.52,329.07,7.86;7,151.52,437.48,329.07,7.86;7,151.52,448.44,56.00,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,247.58,415.56,233.01,7.86;7,151.52,426.52,14.75,7.86">Sentence centrality revisited for unsupervised summarization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,186.64,426.52,293.95,7.86;7,151.52,437.48,88.58,7.86">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-08-02">July 28-August 2, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
