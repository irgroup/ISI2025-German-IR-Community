<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.29,81.01,361.41,12.81">Non-Neural Baseline Experiments for CLIR at TREC 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,266.99,133.82,78.01,10.68"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.29,81.01,361.41,12.81">Non-Neural Baseline Experiments for CLIR at TREC 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E421E6507529797B1255630E3A733801</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Language Information Retrieval</head><p>(CLIR) returned to TREC with the advent of the NeuCLIR track in 2022. The track provided document collections in three languages: Chinese, Farsi, and Russian, and the principal task involved ranking documents in response to English language queries. Our goal in participating in the NeuCLIR track was to provide a statistical baseline for retrieval, for which we used the HAIRCUT retrieval engine. Experiments included use of character n-gram indexing, use of pseudo-relevance feedback, and application of collection enrichment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>All of the experiments we conducted made use of the HAIRCUT retrieval engine described by <ref type="bibr" coords="1,253.39,508.74,45.44,9.92;1,72.00,522.29,90.02,9.92">McNamee and Mayfield (2004)</ref>. One of HAIRCUT's distinctive traits is support for flexible tokenization, and this has enabled the study of character n-grams as indexing terms, which have proven to be effective for controlling the effects of morphological variation <ref type="bibr" coords="1,92.30,590.04,103.93,9.92" target="#b2">(McNamee et al., 2009)</ref>. Despite HAIRCUT's multilingual support, we did not undertake any experiments requiring indexing of the native language collections -all of our experiments relied on the track-provided document translations into English.</p><p>The main motivation for our submissions was to field a statistical system as a comparison to the neural rankers expected in the track. Our runs were produced over a period of several days right before the submission deadline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Submissions</head><p>We submitted the maximum number of permitted runs, four, in each of the three document collections in the Adhoc CLIR task. Each run used the same 'language model' approach to retrieval, but varied in the type of indexing terms, use or non-use of automated relevance feedback, and incorporation of a feedback method known as collection enrichment <ref type="bibr" coords="1,313.20,362.50,105.64,9.92" target="#b1">(Kwok and Chan, 1998)</ref>. All submissions used the title and description topic fields under the supposition that this might work better than use of either title or description alone, or with the addition of the narrative.</p><p>A unigram statistical language model for retrieval was employed <ref type="bibr" coords="1,379.29,444.32,160.73,9.92">(Hiemstra, 2001; Miller et al., 1999)</ref> and smoothing was accomplished using linear interpolation:</p><formula xml:id="formula_0" coords="1,325.78,487.76,214.22,33.36">P (D|Q) ∝ ∏ t∈Q λP (t|D) + (1 -λ)P (t|C) (1)</formula><p>Relative document term frequency was used to estimate P (t|D), as is standard. P (t|C) was based on the mean relative document term frequency from documents in the collection. The two probabilities were evenly weighted (i.e., a constant of λ = 0.5 was used) in all conditions. With this model we have generally observed retrieval performance to be insensitive to changes in the smoothing parameter λ, although others have reported differently <ref type="bibr" coords="1,497.35,644.17,42.68,9.92;1,313.20,657.71,63.76,9.92" target="#b4">(Zhai and Lafferty, 2004)</ref>.</p><p>The indexing terms were either unnormalized words, or overlapping, word-spanning, character ngrams using n = 4 or n = 5. When automated relevance feedback was applied, terms were weighted </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Official Results</head><p>NIST provided results by email for each of our official runs, and we report aggregate results over the set of topics in Table <ref type="table" coords="2,165.47,405.88,4.09,9.92" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We downloaded the "3-2-1-0" multi-grade relevance judgments from the NIST website on 11/7/22 and scored several runs that we had prepared during the evaluation window, but did not submit. In the sections below we compare the effects of differing choices of indexing terms, topic fields, and methods of query expansion using forms of automated feedback. Metrics were computed using trec_eval -M 1000 -l2 -m ndcg -m official qrels runfile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Tokenization</head><p>Based on the official submissions, which all used T+D topic fields, there is a lack of consensus about the best choice of indexing term. On average, character 4-grams appear best for Persian, character 5-grams were best for Chinese, and words outperformed for Russian. These are all machinetranslated runs with English text. Based on the results in Table <ref type="table" coords="2,133.57,712.44,5.45,9.92" target="#tab_1">2</ref> the choice between the best method and second-best method is usually less than a 5% relative difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Relevance Feedback</head><p>Automated relevance feedback is one of the most successful techniques for improving query performance in text retrieval. While the technique is not guaranteed to improve any particular query, average query performance benefits, typically with a relative gain in mean average precision of about 25%. One of the Russian topics is showcased in Figure <ref type="figure" coords="2,531.82,210.74,4.09,9.92">1</ref>, Topic #109, where a word-based run using TDN fields is expanded to 60 query terms. Mean average precision on that particular query rises from 0.1916 to 0.2891 (a 51% relative improvement). On other queries, performance decreases with the use of automated feedback. The method relies on finding some relevant documents or at least documents with term distributions similar to relevant documents in the top ranks.</p><p>Table <ref type="table" coords="2,350.80,346.37,5.45,9.92" target="#tab_2">3</ref> calculates the differences in P@10, MAP, and NDCG between most of our official submissions and a corresponding run that did not use automated relevance feedback. Left out are runs that made use of collection enrichment, as they are discussed below in Section 4.4. All of these runs used the title and description fields.</p><p>Differences in P@10 were not especially pronounced. For the Persian collection, several runs did better in P@10 without relevance feedback. In Russian and Chinese use of RF always improved P@10 -the largest case was a 15% gain <ref type="bibr" coords="2,457.45,495.54,40.91,9.92">(Russian,</ref> Average values for MAP and NDCG always improved with use of relevance feedback. In Persian and Chinese changes were generally moderate, yielding about 6 -10% relative improvements. Gains were largest for the Russian collection, with many relative improvements of about 25%.</p><p>The size of the collection could matter -the Russian document collection was over twice the size of the Persian one, though many factors other than the size of the collection could be responsible for the varied effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Topic Fields</head><p>In Tables <ref type="table" coords="2,356.93,685.34,8.18,9.92" target="#tab_3">4,</ref><ref type="table" coords="2,368.39,685.34,4.09,9.92" target="#tab_4">5</ref>, and 6 we compare title-only (T) and title+description+narrative (TDN) runs to runs using title+description (TD).  Table <ref type="table" coords="4,103.98,218.63,4.24,9.92">6</ref>: Comparing topic field usage on the three collections. Each run used unstemmed words with RF.</p><p>On the Farsi collection it is clear that TDN runs are best, and that both TD and TDN runs substantially outperform title-only runs. These trends hold across all three types of indexing terms.</p><p>The picture is less clear on the Russian collection. Differences appear to be less pronounced, although the best combination was character 5-gram indexing with TDN queries.</p><p>On the Chinese collection TDN was better with 4-gram indexing, but TD runs were better with 5grams and words. Title-only runs were clearly less effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Collection Enrichment</head><p>The idea of collection enrichment is that the documents used for expanding queries and reweighting query terms do not need to be the same documents which are being ranked. It is possible that a different collection, a larger collection, or a targeted sample of a collection may yield better expansion terms, and make relevance feedback more effective on the document collection that is being ranked. For the NeuCLIR 2022 track, the documents in the three different languages are contemporaneous, and translations of each document collection into English were provided by the track. Thus it is straightforward to build a combined "English" collection by combining the translations of the Persian, Russian, and Chinese collections. This collection can be searched and used for expansion, and the revised query can then be applied to just the English translations of interest (i.e., say the Russian subset).</p><p>In practice what we did was just rank the aggregate collection of machine translated documents to rank 5,000 and then filtered out the docids from the non-targeted collections. In some cases this left us with less than 1,000 documents per topic in our submissions.</p><p>Results are shown in Table <ref type="table" coords="4,450.14,292.52,5.45,9.92" target="#tab_5">7</ref> using character 5gram indexing with TD queries. Performance using collection enrichment with the larger collection generally appears to be worse in MAP and NDCG compared to use of traditional relevance feedback using only the specific target language collection, however, P@10 is slightly improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Differences were fairly modest between the type of tokenization used across the three collections, however, our best performing runs used character ngrams. Automated relevance feedback was performance enhancing, but gains were significantly larger for the Russian dataset, than for the Persian and Chinese collections. We found that using TD or TDN topic fields was better than title alone, and that differences between TD and TDN were fairly small, with TDN probably being best, especially in Persian. When unstemmed words were used we saw that TD tended to outperform TDN in Russian and Chinese, but generally using the TDN topic fields was best. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,159.14,80.62,293.71,273.87"><head>Table 2 :</head><label>2</label><figDesc>Performance of officially submitted runs.</figDesc><table coords="3,159.14,80.62,293.71,273.87"><row><cell></cell><cell cols="2">Lang Run</cell><cell></cell><cell cols="2">relret</cell><cell>P@10</cell><cell>MAP NDCG</cell></row><row><cell></cell><cell>fa</cell><cell cols="2">jhumc.fa4.td.rf</cell><cell></cell><cell cols="2">1098 0.3196 0.2291</cell><cell>0.5463</cell></row><row><cell></cell><cell>fa</cell><cell cols="2">jhumc.fa5.td.rf</cell><cell></cell><cell cols="2">994 0.2587 0.2154</cell><cell>0.5220</cell></row><row><cell></cell><cell>fa</cell><cell cols="3">jhumc.fa5.td.ce.rf</cell><cell cols="2">912 0.2870 0.2089</cell><cell>0.4556</cell></row><row><cell></cell><cell>fa</cell><cell cols="3">jhumc.fawords.td.rf</cell><cell cols="2">1070 0.2435 0.2077</cell><cell>0.5177</cell></row><row><cell></cell><cell>ru</cell><cell cols="2">jhumc.ru4.td.rf</cell><cell></cell><cell cols="2">1159 0.2978 0.1983</cell><cell>0.4704</cell></row><row><cell></cell><cell>ru</cell><cell cols="2">jhumc.ru5.td.rf</cell><cell></cell><cell cols="2">1294 0.2800 0.1989</cell><cell>0.4836</cell></row><row><cell></cell><cell>ru</cell><cell cols="3">jhumc.ru5.td.ce.rf</cell><cell cols="2">954 0.2911 0.2253</cell><cell>0.4395</cell></row><row><cell></cell><cell>ru</cell><cell cols="3">jhumc.ruwords.td.rf</cell><cell cols="2">1192 0.3089 0.2016</cell><cell>0.4860</cell></row><row><cell></cell><cell>zh</cell><cell cols="2">jhumc.zh4.td.rf</cell><cell></cell><cell cols="2">1391 0.3122 0.2558</cell><cell>0.5405</cell></row><row><cell></cell><cell>zh</cell><cell cols="2">jhumc.zh5.td.rf</cell><cell></cell><cell cols="2">1575 0.3265 0.2746</cell><cell>0.5730</cell></row><row><cell></cell><cell>zh</cell><cell cols="3">jhumc.zh5.td.ce.rf</cell><cell cols="2">1344 0.3367 0.2581</cell><cell>0.4963</cell></row><row><cell></cell><cell>zh</cell><cell cols="3">jhumc.zhwords.td.rf</cell><cell cols="2">1451 0.3224 0.2423</cell><cell>0.5579</cell></row><row><cell cols="3">Lang Terms</cell><cell>P@10</cell><cell>∆</cell><cell cols="2">MAP</cell><cell>∆ NDCG</cell><cell>∆</cell></row><row><cell>fa</cell><cell cols="3">4-grams 0.2870</cell><cell cols="3">-0.0326 0.2120 -0.0171</cell><cell>0.5091 -0.0372</cell></row><row><cell>fa</cell><cell cols="6">5-grams 0.2696 +0.0109 0.1902 -0.0252</cell><cell>0.4898 -0.0322</cell></row><row><cell>fa</cell><cell>words</cell><cell></cell><cell cols="4">0.2543 +0.0108 0.1840 -0.0237</cell><cell>0.4744 -0.0433</cell></row><row><cell>ru</cell><cell cols="3">4-grams 0.2578</cell><cell cols="3">-0.0400 0.1548 -0.0435</cell><cell>0.3786 -0.0921</cell></row><row><cell>ru</cell><cell cols="3">5-grams 0.2622</cell><cell cols="3">-0.0178 0.1554 -0.0435</cell><cell>0.3939 -0.0897</cell></row><row><cell>ru</cell><cell>words</cell><cell></cell><cell>0.2467</cell><cell cols="3">-0.0622 0.1523 -0.0493</cell><cell>0.4376 -0.0484</cell></row><row><cell>zh</cell><cell cols="3">4-grams 0.3041</cell><cell cols="3">-0.0081 0.2289 -0.0269</cell><cell>0.5158 -0.0247</cell></row><row><cell>zh</cell><cell cols="3">5-grams 0.3204</cell><cell cols="3">-0.0061 0.2299 -0.0447</cell><cell>0.5269 -0.0461</cell></row><row><cell>zh</cell><cell>words</cell><cell></cell><cell>0.2918</cell><cell cols="3">-0.0306 0.2268 -0.0155</cell><cell>0.5295 -0.0284</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,72.00,366.90,468.69,323.44"><head>Table 3 :</head><label>3</label><figDesc>Corresponding runs for our official TD submissions, without automated feedback. Nearly all changes are negative, showing that relevance feedback improved average performance.</figDesc><table coords="3,458.53,494.64,74.23,8.15"><row><cell>найти информацию</cell></row></table><note coords="3,79.23,414.14,108.25,8.15;3,79.23,424.10,103.43,8.15;3,79.23,434.46,384.47,8.15;3,79.23,444.43,325.80,8.15;3,79.23,454.79,453.60,8.15;3,79.23,464.75,453.60,8.15;3,79.23,474.71,219.63,8.15;3,79.23,484.68,453.56,8.15;3,79.23,494.64,377.49,8.15"><p>Title: Researching dead zones Исследование мертвых зон Description: I am looking for articles on researching zones in the Ocean that are devoid of oxygen and life. Я ищу статьи, исследующие зоны в океане, лишенные кислорода и океанской жизни. Narrative: Dead zones in the ocean are typically created when too much nitrogen, usually from fertilizer runoff, enters the ocean and displaces the oxygen in the water. These areas are devoid of life: no fish, no animal life at all. I would like to find information on these zones and how they are being managed. Мертвые зоны в океане обычно образуются, когда слишком много азота, обычно из стоков удобрений, попадает в океан и вытесняет кислород в воде. Эти районы лишены жизни: ни рыбы, ни животного мира. Я хотел бы</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,77.80,702.77,456.47,9.92"><head>Table 4 :</head><label>4</label><figDesc>Comparing topic field usage on the three collections. Each run used character 4-grams with RF.</figDesc><table coords="4,77.98,73.16,462.72,48.80"><row><cell></cell><cell></cell><cell cols="2">Farsi collection</cell><cell></cell><cell></cell><cell cols="2">Russian collection</cell><cell></cell><cell></cell><cell>Chinese collection</cell></row><row><cell>Fields</cell><cell>relret</cell><cell>P@10</cell><cell cols="2">MAP NDCG</cell><cell>relret</cell><cell>P@10</cell><cell cols="2">MAP NDCG</cell><cell>relret</cell><cell>P@10</cell><cell>MAP NDCG</cell></row><row><cell>T</cell><cell cols="3">1009 0.2413 0.1937</cell><cell>0.4977</cell><cell cols="3">1238 0.2467 0.2308</cell><cell>0.4630</cell><cell cols="2">1535 0.3286 0.2627</cell><cell>0.5493</cell></row><row><cell>TD</cell><cell cols="3">994 0.2587 0.2154</cell><cell>0.5220</cell><cell cols="3">1294 0.2800 0.1989</cell><cell>0.4836</cell><cell cols="2">1575 0.3265 0.2746</cell><cell>0.5730</cell></row><row><cell>TDN</cell><cell cols="3">1120 0.2783 0.2322</cell><cell>0.5554</cell><cell cols="3">1309 0.3667 0.2268</cell><cell>0.5107</cell><cell cols="2">1550 0.3653 0.2680</cell><cell>0.5701</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,77.80,134.38,462.90,71.83"><head>Table 5 :</head><label>5</label><figDesc>Comparing topic field usage on the three collections. Each run used character 5-grams with RF.</figDesc><table coords="4,77.98,157.41,462.72,48.80"><row><cell></cell><cell></cell><cell cols="2">Farsi collection</cell><cell></cell><cell></cell><cell cols="2">Russian collection</cell><cell></cell><cell></cell><cell>Chinese collection</cell></row><row><cell>Fields</cell><cell>relret</cell><cell>P@10</cell><cell cols="2">MAP NDCG</cell><cell>relret</cell><cell>P@10</cell><cell cols="2">MAP NDCG</cell><cell>relret</cell><cell>P@10</cell><cell>MAP NDCG</cell></row><row><cell>T</cell><cell cols="3">927 0.1783 0.1532</cell><cell>0.4659</cell><cell cols="3">1173 0.2956 0.2006</cell><cell>0.4560</cell><cell cols="2">1407 0.3184 0.2295</cell><cell>0.5297</cell></row><row><cell>TD</cell><cell cols="3">1070 0.2435 0.2077</cell><cell>0.5177</cell><cell cols="3">1192 0.3089 0.2016</cell><cell>0.4860</cell><cell cols="2">1451 0.3224 0.2423</cell><cell>0.5579</cell></row><row><cell>TDN</cell><cell cols="3">1083 0.2674 0.2125</cell><cell>0.5173</cell><cell cols="3">1296 0.3267 0.1871</cell><cell>0.4741</cell><cell cols="2">1399 0.3204 0.2143</cell><cell>0.5121</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,77.98,73.16,476.66,71.14"><head>Table 7 :</head><label>7</label><figDesc>Collection enrichment runs using character 5-grams and TD topic fields.</figDesc><table coords="5,77.98,73.16,476.66,48.80"><row><cell></cell><cell></cell><cell cols="2">Farsi collection</cell><cell></cell><cell></cell><cell cols="2">Russian collection</cell><cell></cell><cell></cell><cell>Chinese collection</cell></row><row><cell>Feedback</cell><cell>relret</cell><cell>P@10</cell><cell cols="2">MAP NDCG</cell><cell>relret</cell><cell>P@10</cell><cell cols="2">MAP NDCG</cell><cell>relret</cell><cell>P@10</cell><cell>MAP NDCG</cell></row><row><cell>None</cell><cell cols="3">907 0.2696 0.1902</cell><cell>0.4898</cell><cell cols="3">988 0.2622 0.1554</cell><cell>0.3939</cell><cell cols="2">1267 0.3204 0.2299</cell><cell>0.5269</cell></row><row><cell>RF</cell><cell cols="3">994 0.2587 0.2154</cell><cell>0.5220</cell><cell cols="3">1294 0.2800 0.1989</cell><cell>0.4836</cell><cell cols="2">1575 0.3265 0.2746</cell><cell>0.5730</cell></row><row><cell>CE</cell><cell cols="3">912 0.2870 0.2089</cell><cell>0.4556</cell><cell cols="3">954 0.2911 0.2253</cell><cell>0.4395</cell><cell cols="2">1344 0.3367 0.2581</cell><cell>0.4963</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,72.00,185.91,226.80,9.07;5,82.91,196.87,215.88,9.07;5,82.91,207.84,31.68,9.06" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,182.47,185.91,116.32,9.07;5,82.91,196.87,87.41,9.07">Using Language Models for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>University of Twente</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="5,72.00,227.76,226.80,9.06;5,82.91,238.71,215.90,9.07;5,82.91,249.67,215.90,9.07;5,82.91,260.63,215.89,9.07;5,82.91,271.60,215.87,9.06;5,82.91,282.56,25.19,9.06;5,72.00,302.48,226.81,9.06;5,82.91,313.44,215.92,9.06;5,82.91,324.39,150.49,9.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,201.83,227.76,96.97,9.06;5,82.91,238.72,119.01,9.06;5,267.28,302.48,31.53,9.06;5,82.91,313.44,215.92,9.06;5,82.91,324.40,24.45,9.06">Character n-gram tokenization for European language text retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,223.18,238.71,75.63,9.07;5,82.91,249.67,215.90,9.07;5,82.91,260.63,215.89,9.07;5,82.91,271.60,42.62,9.06">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;98</title>
		<editor>
			<persName><forename type="first">Acm</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</editor>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;98<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998. 2004</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
	<note>Improving two-stage adhoc retrieval for short queries</note>
</biblStruct>

<biblStruct coords="5,72.00,344.32,226.82,9.06;5,82.91,355.28,215.91,9.06;5,82.91,366.23,215.90,9.07;5,82.91,377.19,215.90,9.07;5,82.91,388.15,215.89,9.07;5,82.91,399.12,25.19,9.06" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,112.91,355.28,185.91,9.06;5,82.91,366.24,59.28,9.06">Addressing morphological variation in alphabetic languages</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,160.02,366.23,138.79,9.07;5,82.91,377.19,215.90,9.07;5,82.91,388.15,154.17,9.07">Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.00,419.04,226.82,9.06;5,82.91,430.00,215.91,9.06;5,82.91,440.95,215.90,9.07;5,82.91,451.91,215.91,9.07;5,82.91,462.87,215.88,9.07;5,82.91,473.84,92.63,9.06" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,111.63,430.00,187.19,9.06;5,82.91,440.96,25.86,9.06">A hidden Markov model information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,131.40,440.95,167.41,9.07;5,82.91,451.91,215.91,9.07;5,82.91,462.87,126.40,9.07">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.00,493.76,226.81,9.06;5,82.91,504.72,215.91,9.06;5,82.91,515.67,215.88,9.07;5,82.91,526.64,43.45,9.06" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,255.04,493.76,43.77,9.06;5,82.91,504.72,215.91,9.06;5,82.91,515.68,73.85,9.06">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,163.90,515.67,84.66,9.07">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004-04">2004. April</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
