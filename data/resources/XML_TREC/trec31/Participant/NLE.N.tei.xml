<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.41,99.67,269.18,14.93;1,221.46,119.60,169.07,14.93">NAVER LABS EUROPE (SPLADE) @ TREC NEUCLIR 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,228.09,184.61,67.37,8.96"><forename type="first">Carlos</forename><surname>Lassance</surname></persName>
							<email>carlos.lassance@naverlabs.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Naver Labs Europe</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.53,184.61,83.87,8.96"><forename type="first">Stephane</forename><surname>Clinchant</surname></persName>
							<email>stephane.clinchant@naverlabs.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Naver Labs Europe</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.41,99.67,269.18,14.93;1,221.46,119.60,169.07,14.93">NAVER LABS EUROPE (SPLADE) @ TREC NEUCLIR 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">35E77C47DADB082FAB0D625774373C6D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the 2022 TREC NeuCLIR challenge. We submitted runs to two out of the three languages (Farsi and Russian), with a focus on first-stage rankers and comparing mono-lingual strategies to Adhoc ones. For monolingual runs, we start from pretraining models on the target language using MLM+FLOPS and then finetuning using the MSMARCO translated to the language either with ColBERT or SPLADE as the retrieval model. While for the Adhoc task we test both query translation (to the target language) and backtranslation of the documents (to english). Initial result analysis shows that the monolingual strategy is strong, but that for the moment Adhoc achieved the best results, with back-translating documents being better than translating queries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we detail our TREC 2022 NeuCLIR track submission, based on the latest improvements of the SPLADE model <ref type="bibr" coords="1,232.90,458.89,56.71,8.64">[Lassance and</ref><ref type="bibr" coords="1,292.10,458.89,146.67,8.64">Clinchant, 2022, Formal et al., 2022]</ref>, with the main factor being the MLM+FLOPS pretraining (for monolingual runs) and distillation (for the Adhoc runs). In total, we submitted 7 runs per language, being 3 baselines based solely on SPLADE (monolingual, Adhoc via query translation and Adhoc via document back-translation 1 ) and 4 main runs (divided into monolingual/Adhoc and reranked/ensemble of the first stage rankers).</p><p>Compared to our TREC DL 2021 notebook, we decided to make this notebook more streamlined compared to last year (and more drafty). For a more thorough introduction of the models used here, we invite the reader to check the following articles: SPLADE training <ref type="bibr" coords="1,419.48,540.73,80.23,8.64">[Formal et al., 2022]</ref>, MLM+FLOPS pretraining <ref type="bibr" coords="1,217.37,551.64,124.37,8.64">[Lassance and Clinchant, 2022]</ref>, <ref type="bibr" coords="1,349.37,551.64,150.34,8.64">ColBERT[Khattab and Zaharia, 2020]</ref>, Rocchio <ref type="bibr" coords="1,143.63,562.55,66.82,8.64" target="#b3">[Joachims, 1996]</ref>, Training style we used for our rerankers <ref type="bibr" coords="1,378.61,562.55,70.00,8.64" target="#b2">[Gao et al., 2021]</ref> and T5 based reranking <ref type="bibr" coords="1,148.67,573.46,88.67,8.64">[Nogueira et al., 2020]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In the following, we introduce the models we consider for both candidate generation as well as re-ranking. We also describe our training procedure and detail the submitted runs. SPLADE and pretrained language models are made available at https://huggingface.co/naver/\{name\} with the models being named: neuclir22-{pretrained, splade}-{fa,ru,zh}. Note that even if we did not participate in zh, we trained models a posteriori and made them available.</p><p>1 Throughout this notebook we use back-translation as the translation from the target language to English TREC NeuCLIR 2022 -SPLADE</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">First Stage</head><p>For the first stage this year we separate models into two avenues: trained on the target language and on English. For the latter we always use the Splade++ CoCondenser Self Distil<ref type="foot" coords="2,422.27,105.06,3.49,6.05" target="#foot_0">2</ref> and for the former:</p><p>1. We pre-train 6L DistilBERT base models from scratch using MLM+FLOPS <ref type="bibr" coords="2,211.51,138.43,89.91,8.64">[Lassance et al., 2023]</ref> on the target language using a combination of the target documents, translated MSMARCO <ref type="bibr" coords="2,389.75,149.34,114.25,8.64" target="#b1">[Bonifacio et al., 2021] and</ref><ref type="bibr" coords="2,143.87,160.25,113.48,8.64">Mr.Tydi [Zhang et al., 2021]</ref> depending on their availability for the language.</p><p>2. We then finetune those models with <ref type="bibr" coords="2,340.70,175.96,163.31,8.64">ColBERT [Khattab and Zaharia, 2020]</ref> and <ref type="bibr" coords="2,170.47,186.87,131.87,8.64">SPLADE [Formal et al., 2022]</ref> style training on the translated MS-MARCO <ref type="bibr" coords="2,182.89,197.78,90.79,8.64" target="#b1">[Bonifacio et al., 2021]</ref>.</p><p>(a) For SPLADE we use the negatives from https://huggingface.co/datasets/ sentence-transformers/msmarco-hard-negatives drawn from a multitude of models on the English version of the corpus. Note that we tried using distillation with the English scores (which we already had tested on other languages with positive results), but the better results came from non-distillation training. (b) While for ColBERT we use the traditional English BM25 negatives. In order to maximize ColBERT performance we remove the last layer (which reduces the dimensionality from 768 to 128) and inference is done using brute-force retrieval instead of an approximate <ref type="bibr" coords="2,216.08,303.18,158.28,8.64">ANN (following [Lassance et al., 2021]</ref>).</p><p>3. For completeness, we also include BM25 in our first stage ensembling. However, in hindsight, we should have used the run provided by the organizers as the last piece of the ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Second Stage</head><p>As per last year's competition we use a mix of different PLMs as rerankers for which training is inspired by<ref type="foot" coords="2,156.59,395.68,3.49,6.05" target="#foot_1">3</ref>  <ref type="bibr" coords="2,163.84,397.35,70.00,8.64" target="#b2">[Gao et al., 2021]</ref> and using negatives from SPLADE. For the monolingual runs we used InfoXLM and XLM-Roberta-Large as the PLMs, while for the Adhoc runs we consider only rerankers trained on english, using Electra-Large, Deberta-v3-Large and Deberta-v2-xxLarge<ref type="foot" coords="2,479.75,417.50,3.49,6.05" target="#foot_2">4</ref> (and thus apply them using the back-translated documents). We also add the pretrained MonoT5-3B <ref type="bibr" coords="2,108.00,440.99,88.67,8.64">[Nogueira et al., 2020]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ensembling</head><p>We also have applied ensembling in order to improve our results. This year we used ranx <ref type="bibr" coords="2,129.42,497.63,114.01,8.64" target="#b0">[Bassani and Romelli, 2022]</ref> to generate all our ensembles, using average normalized score over the ensembles, unless explicitly noted. The normalized score uses the min and max values of the query so that, for each model, the best score is 1 and the lowest one 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Runs submitted to TREC</head><p>We submitted a total of 14 runs, 7 for Farsi and 7 for Russian. Of the 7 runs, we submitted 3 baselines (human query translation, machine query translation, machine document translation) and 4 main runs (combination of monolingual/Adhoc with first-stage only/reranked). Namely: • MSMARCO translated dev set: While MSMARCO is a good avenue for training, we were afraid that the translated dev set could be biased to the translation and thus make the results less viable (we also would not have a human translated development set). • Mr.TyDi dev/test set: Discarded because it is not available in Farsi.</p><p>• Full HC4 dev set: Discarded due to its size (larger than the filtered one) and the fact that it did not focus on the same documents as the test set.</p><p>We shared our results on the HC4-filtered dev with other participants and it seemed like a solid baseline, we thus shared some run files so that other participants could use our SPLADE as their first-stage rankers. Results are made available in Table <ref type="table" coords="3,329.61,381.59,4.98,8.64" target="#tab_3">3</ref> (monolingual) and Table <ref type="table" coords="3,438.57,381.59,4.98,8.64" target="#tab_3">3</ref> (Adhoc), from which we take the following initial conclusions:</p><p>• In almost all considered tasks we had a hierarchy of SPLADE ≥ ColBERT ≥ BM25, but their ensemble seemed more stable than individual runs (even if not always better). • However the precision boost for first-stage rankers over BM25 vary depending on language, while it is almost double in Farsi, in Russian it is of only a few points. However, in terms of Recall, there's a larger gap. • Also, we noticed that SPLADE+Rocchio almost always improved over SPLADE by itself, something we also noticed on the TREC DL challenge. • Differently from English, monolingual runs did not always improve after reranking. However, the ensembling of rerankers and first-stage rankers was always better than the firststage ranking by itself. One thing that we missed is that we could have used our first-stage rankers to initialize the rerankers, which could have improved the results. • The best AdHoc ensemble varied by language, with Russian using all available models and Farsi focusing only on the T5 reranked runs. In hindsight, this might not have been the best decision. • Continuing on possibly bad decisions, the first stage AdHoc ensembles did not agree if we should include or not the document back translated ones. • The results seem to indicate that monolingual vs AdHoc seems to be language and stage dependent. For first stage, Farsi obtained the best results on monolingual, while Russian was on Adhoc (using back-translated documents). For reranking results were always better using back-translated documents, which is expected because the PLMs are not as good (and hyperparameters have not been tuned as well). • It would have been nice to compare with SPLADE-X <ref type="bibr" coords="3,356.89,668.72,71.10,8.64">[Nair et al., 2022]</ref> a CLIR model that came out after the competition (and one of its baselines PSQ). However, the authors only compared on CLEF datasets and as far as we are aware the models are not available.   <ref type="table" coords="4,278.92,558.80,3.74,8.64">4</ref>. We drew some initial conclusions and are still analyzing the results:</p><p>• In the end the dev set we used was not that good. For example on the first stage runs, the best run (mono vs AdHoc) was the exact opposite of the devset. • The Farsi monolingual reranked run was worse than the not reranked one, kinda the opposite of the dev set. • The gap between the baselines and the first stage runs was increased in the TREC set, further showing the advantage of ensembling first-stage rankers. • Of the reranked runs, the Adhoc was always better, achieving good results compared to the rest of the runs. • The mAP achieved in the Russian TREC set and the Recall@1k for both sets seem to confirm that our models are good at selecting good candidates, but are not as good at pushing them to the top. This is similar to what we observed in TREC DL 21 and 22.</p><p>• Looking at the queries, there is a very large gap on how they are structured and how MS-MARCO ones are. This probably impacted most runs of the competition, but it is especially critical on ours, where all runs are based on MSMARCO. The inclusion of training on HC4 is a probable step for next year.</p><p>• Analyzing the hardest queries (c.f. Appendix), it seems that one problem was looking into the "wrong" database, by looking at questions for one nation/nationality/language on another. This makes us think of how a full-blown CLIR could happen (instead of English to one language, English to many languages).</p><p>• Given the smaller gap in the effectiveness of mono vs adhoc in Farsi compared to Russian it is not unreasonable to imagine that it comes from the fact that machine translation from English to Farsi are worse than the English to Russian. Studying this is left as future work. TREC HC4 TREC NDCG@20 mAP@1k NDCG@20 mAP@1k Recall@1k NDCG@20 mAP@1k NDCG@20 mAP@1k Recall@1k We also include some query analysis in the appendix (quite long so we preferred to keep it outside the "main" analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>For the TREC NeuCLIR 22 competition, we submitted runs in an effort to compare monolingual and AdHoc strategies. From the results, it seems that there is an interest in focusing on monolingual retrievers, however, given the larger literature and experiments in English, the AdHoc strategy is cheaper and as good/better than monolingual. Also much to our dismay, document translation worked the best out of all tested strategies. Finally, we also noticed that there's a need for a better development set in order to continue the efforts in this direction.</p><p>[ <ref type="bibr" coords="6,112.36,75.48,108.52,8.64">Khattab and Zaharia, 2020]</ref>   <ref type="formula" coords="6,383.64,160.04,16.60,8.64">2023</ref>). An experimental study on pretraining transformers from scratch for ir.</p><p>[Lassance et al., 2021] Lassance, C., Maachou, M., Park, J., and Clinchant, S. ( <ref type="formula" coords="6,430.10,185.95,16.60,8.64">2021</ref>). A study on token pruning for colbert. arXiv preprint arXiv:2112.06540.</p><p>[Lawrie et al., 2022] Lawrie, D., Mayfield, J., Oard, D. W., and Yang, E. ( <ref type="formula" coords="6,405.50,211.87,16.60,8.64">2022</ref>). Hc4: A new suite of test collections for ad hoc clir.</p><p>[Nair et al., 2022] Nair, S., Yang, E., Lawrie, D., Mayfield, J., and Oard, D. W. ( <ref type="formula" coords="6,432.05,237.79,16.60,8.64">2022</ref>). Learning a sparse representation model for neural clir.</p><p>[Nogueira et al., 2020] Nogueira, R., Jiang, Z., and Lin, J. ( <ref type="formula" coords="6,351.92,263.70,16.60,8.64">2020</ref>). Document ranking with a pretrained sequence-to-sequence model. arXiv preprint arXiv:2003.06713.</p><p>[ <ref type="bibr" coords="6,112.80,289.62,74.06,8.64">Zhang et al., 2021]</ref> Zhang, X., Ma, X., Shi, P., and Lin, J. (2021). Mr. tydi: A multi-lingual benchmark for dense retrieval. arXiv preprint arXiv:2108.08787.</p><p>A Initial query analysis (nDCG values come from an older version of the qrels)</p><p>A.1 Topic 0</p><p>Why we selected it: Highest difference between median and max nDCG@20 in Russian (0.8983 vs 0.2732).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title: Iranian female athletes refugees</head><p>Description: I am looking for stories about Iranian female athletes who seek asylum in other countries.</p><p>Narrative: Find articles that identify female athletes who refused to return to Iran after competition and slam government by seeking asylum from other countries. Relevant documents must identify the athlete by name, and spell out the reason for seeking asylum and if they joined Refugee Team in Olympic competition. "Official" or unofficial reasons are equally acceptable, as long as the document gives some reason that the athlete refused to return after the competition,name of the countries that accepted their request, and Iran government reaction.</p><p>Why we think it is hard: This query is directly meant for Iranian data, which probably makes it more sparse in Russian-based data. This is confirmed by the number of related documents found (12 in Russian and 99 in Farsi).</p><p>How did our methods perform: Looking at our methods it seemed that we found most of the related docs (11 out of 12) and effectively place them at the top (0.88 nDCG for our best model).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Topic 4</head><p>Why we selected it: Worst median mAP for Farsi (only 0.0024).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title: Corruption during construction of Vostochny Cosmodrome</head><p>Description: I am looking for reports on officials convicted of corruption in the construction of the Russian Space launch Complex at Vostochny in the Far East.</p><p>Narrative: Find articles on corruption and conviction of Russian officials and businessmen involved in the construction of the Russian Space launch Complex in Vostochny in the Far East. Relevant articles are to include information on Individuals, their duties, the crimes they are accused of, and plans by Roscosmos to alleviate the damage they did to the project. Issues not attributed to corruption are not relevant.</p><p>Why we think it is hard: As the previous query, this deals with information mostly from a Russian point of view, thus making it normal to be very sparse in Farsi. Again this is confirmed by the number of related documents found (12 in Russian and 10 in Farsi). Another problem is on the entity (Vostochny Cosmodrome), it poses problems both for monolingual (tokenization may break the name) and for Adhoc (translation may remove the name).</p><p>How did our methods perform: Our monolingual Farsi first stage achieved the best mAP, but all our other runs suffered, especially the reranked ones (probably due to the entity problem).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Topic 18</head><p>Why we selected it: Worst median nDCG@10 on Farsi (0 median, 0.74 max).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title:</head><p>The situation of myopia rate among K12 students in China Description: I am interested in finding information about the situation of myopia among K12 students in China.</p><p>Narrative: Find articles carry information about the situation of myopia rate among K12 students in China. Relevant documents should include information about the current situation and/or changes of the myopia rate, factors that affect the eyesight of K12 students, and the trend. Articles about the prevention and treatment of myopia, the research in the area of vision health, are not considered relevant.</p><p>Why we think it is hard: As per the previous queries, this searches for Chinese information in the Farsi database, thus making judgments very sparse (only 5 positives). However, it is not as hard on the Russian database, pointing possibly to a language drift (K12 could have another name in Farsi).</p><p>How did our methods perform: Our monolingual runs completely failed on this query (0.08 and 0.09 nDCG), but our Adhoc reranked got a very good result (0.6510). Looking at the baselines we confirm that only the document-translated runs could get a good result, pointing to the treatment of the Farsi language as the probable cause of trouble in this query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Topic 19</head><p>Why we selected it: No related documents found in Russian and not present in Farsi Title: Cases of formaldehyde related pollution in household products Description: I am interested in finding information about the situation of myopia among K12 students in China.</p><p>Narrative: Find articles carry information about cases of formaldehyde related pollution in household products in China. Relevant articles should mention specific events that involve the pollution with information about the harms resulted in. Articles that discuss about the pollution of excessive formaldehyde, the harms and remedies, without mentioning any specific cases, are not considered relevant. Articles that discuss other types of pollutions found in household products are not considered relevant Why we think it is hard: This query misses the "In China" part when looking at just the title, which can cause problems with runs that only include the title. Moreover, as per the previous queries, this searches for Chinese information in the Russian database.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,131.41,608.67,372.59,73.12"><head></head><label></label><figDesc>In order to generate our final runs, we needed to set a development set. During the challenge period, we tested many different development sets, but in the end, we focused on what we called HC4filtered dev. The HC4-filtered dev is the HC4[Lawrie et al., 2022]  dev set, filtered to include only the documents present in the competition's test set (NeuCLIR1)5 . Other possibilities we rejected were:</figDesc><table coords="2,131.41,608.67,372.59,73.12"><row><cell>4. NLE {language} mono: Monolingual ensemble of first-stage rankers on human translated</cell></row><row><cell>queries</cell></row><row><cell>5. NLE {language} mono rr: Monolingual ensemble of first-stage and rerankers on human</cell></row><row><cell>translated queries</cell></row><row><cell>6. NLE {language} adhoc: Ad-hoc ensemble of first-stage rankers on machine-translated</cell></row><row><cell>queries and/or machine-back-translated documents</cell></row><row><cell>7. NLE {language} adhoc rr: Ad-hoc ensemble of first-stage and rerankers on machine-</cell></row><row><cell>translated queries and/or machine-back-translated documents</cell></row><row><cell>3 Analysis on Filtered HC4</cell></row><row><cell>1. splade {language} ht: Baseline monolingual first-stage ranking with SPLADE and human</cell></row><row><cell>translated queries</cell></row><row><cell>2. splade {language} mt: Baseline Ad-hoc first-stage ranking with SPLADE and machine-</cell></row><row><cell>translated queries</cell></row><row><cell>3. splade {language} dt: Baseline Ad-hoc first-stage ranking with SPLADE and machine-</cell></row><row><cell>translated documents</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,108.00,72.31,396.00,217.66"><head>Table 1 :</head><label>1</label><figDesc>MonoLingual results on HC4-filtered dev. Lines containing submissions are bolded. nDCG@20 multiplied by 100 for ease of presentation.</figDesc><table coords="4,111.74,102.79,386.98,187.18"><row><cell>#</cell><cell>Model</cell><cell>Rerank or Ensemble</cell><cell cols="6">Farsi nDCG@20 mAP@1k Recall@1k nDCG@20 mAP@1k Recall@1k Russian</cell><cell>Name</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">First stage Rankers</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>a</cell><cell>BM25</cell><cell></cell><cell>19.7</cell><cell>13.4</cell><cell>79.9%</cell><cell>19.1</cell><cell>13.5</cell><cell>67.4%</cell><cell></cell></row><row><cell>b</cell><cell>SPLADE</cell><cell></cell><cell>29.8</cell><cell>20.4</cell><cell>89.5%</cell><cell>21.9</cell><cell>16.5</cell><cell>75.2%</cell><cell></cell></row><row><cell>c</cell><cell>SPLADE + Rocchio</cell><cell></cell><cell>31.6</cell><cell>22.1</cell><cell>91.4%</cell><cell>22.5</cell><cell>16.5</cell><cell>70.4%</cell><cell>splade {} ht</cell></row><row><cell>d</cell><cell>ColBERT</cell><cell></cell><cell>30.3</cell><cell>21.2</cell><cell>89.4%</cell><cell>21.2</cell><cell>14.6</cell><cell>81.3%</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">First Stage Ensembles</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>e</cell><cell>First stage Ensemble</cell><cell>a+c+d</cell><cell>31.5</cell><cell>21.2</cell><cell>91.9%</cell><cell>25</cell><cell>17.8</cell><cell>78.4%</cell><cell></cell></row><row><cell>f</cell><cell>First stage Ensemble</cell><cell>a+b+d</cell><cell>30.7</cell><cell>20.8</cell><cell>91.4%</cell><cell>25</cell><cell>18.6</cell><cell>78.0%</cell><cell></cell></row><row><cell cols="2">g First stage Ensemble</cell><cell>a+b+c+d</cell><cell>31.9</cell><cell>22.6</cell><cell>92.2%</cell><cell>23.8</cell><cell>17.4</cell><cell>80.7%</cell><cell>NLE {} mono</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rerankers</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>h</cell><cell>InfoXLM</cell><cell>c</cell><cell>30.3</cell><cell>20.9</cell><cell>91.4%</cell><cell>20.1</cell><cell>13.1</cell><cell>70.4%</cell><cell></cell></row><row><cell>i</cell><cell>InfoXLM</cell><cell>e</cell><cell>30.5</cell><cell>21.2</cell><cell>91.9%</cell><cell>20.7</cell><cell>13.6</cell><cell>78.4%</cell><cell></cell></row><row><cell>j</cell><cell>InfoXLM</cell><cell>g</cell><cell>30.5</cell><cell>21.1</cell><cell>92.2%</cell><cell>20.6</cell><cell>13.5</cell><cell>80.7%</cell><cell></cell></row><row><cell>k</cell><cell>XLM-Roberta-Large</cell><cell>c</cell><cell>31</cell><cell>22.2</cell><cell>91.4%</cell><cell>19.9</cell><cell>12.7</cell><cell>70.4%</cell><cell></cell></row><row><cell>l</cell><cell>XLM-Roberta-Large</cell><cell>e</cell><cell>31.4</cell><cell>22.1</cell><cell>91.9%</cell><cell>20.8</cell><cell>13.2</cell><cell>78.4%</cell><cell></cell></row><row><cell cols="2">m XLM-Roberta-Large</cell><cell>g</cell><cell>31</cell><cell>22.2</cell><cell>92.2%</cell><cell>20.6</cell><cell>13</cell><cell>80.7%</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Final Ensembles</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>n</cell><cell>Final Ensemble</cell><cell>a+b+c+d+j+m</cell><cell>34</cell><cell>25.5</cell><cell>92.2%</cell><cell>25.1</cell><cell>17.6</cell><cell>80.7%</cell><cell></cell></row><row><cell>o</cell><cell>Final Ensemble</cell><cell>c+d+i+l</cell><cell>35.6</cell><cell>26.1</cell><cell>91.9%</cell><cell>25.8</cell><cell>17.8</cell><cell>78.4%</cell><cell></cell></row><row><cell>p</cell><cell>Final Ensemble</cell><cell>c+d+j+m</cell><cell>35.6</cell><cell>26.1</cell><cell>92.2%</cell><cell>25.8</cell><cell>17.8</cell><cell>80.7%</cell><cell>NLE {} mono rr</cell></row><row><cell>q</cell><cell>Final Ensemble</cell><cell>j+m</cell><cell>32.1</cell><cell>22.6</cell><cell>92.2%</cell><cell>23.1</cell><cell>15.2</cell><cell>80.7%</cell><cell></cell></row><row><cell>r</cell><cell>Final Ensemble</cell><cell>g+j+m</cell><cell>35.4</cell><cell>25.7</cell><cell>92.2%</cell><cell>25.1</cell><cell>17.6</cell><cell>80.7%</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,108.00,303.71,396.00,263.73"><head>Table 2 :</head><label>2</label><figDesc>Adhoc results on HC4-filtered dev. Lines containing submissions are bolded. QT: Machine translated queries, DT: Machine translated documents. nDCG@20 multiplied by 100 for ease of presentation.</figDesc><table coords="4,108.00,345.10,390.71,199.93"><row><cell>#</cell><cell>Model</cell><cell>Rerank or Ensemble</cell><cell cols="6">Farsi nDCG@20 mAP@1k Recall@1k nDCG@20 mAP@1k Recall@1k Russian</cell><cell>Name</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">First Stage Rankers</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>a</cell><cell>BM25 MT</cell><cell></cell><cell>17,2</cell><cell>11,6</cell><cell>81,50%</cell><cell>20</cell><cell>14,8</cell><cell>68,90%</cell><cell></cell></row><row><cell>b</cell><cell>SPLADE++ MT</cell><cell></cell><cell>29,4</cell><cell>20,5</cell><cell>91,20%</cell><cell>21,6</cell><cell>16,8</cell><cell>69,90%</cell><cell>splade {} mt</cell></row><row><cell>c</cell><cell>SPLADE++ DT</cell><cell></cell><cell>27,4</cell><cell>18,3</cell><cell>91,50%</cell><cell>23,6</cell><cell>16</cell><cell>74,20%</cell><cell>splade {} dt</cell></row><row><cell>d</cell><cell>ColBERT MT</cell><cell></cell><cell>28,1</cell><cell>19,3</cell><cell>89,10%</cell><cell>22,4</cell><cell>16,3</cell><cell>77,30%</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">First Stage Ensembles</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>e</cell><cell>Ensemble</cell><cell>a+b+c</cell><cell>29,3</cell><cell>20,4</cell><cell>92,00%</cell><cell>26</cell><cell>20,4</cell><cell>77,00%</cell><cell>NLE {} adhoc</cell></row><row><cell>f</cell><cell>Ensemble</cell><cell>a+b+c+d</cell><cell>31,1</cell><cell>21,2</cell><cell>92,80%</cell><cell>25,8</cell><cell>19,7</cell><cell>76,70%</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Rerankers over english translated docs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>g</cell><cell>Electra-large</cell><cell>f</cell><cell>25,2</cell><cell>18,3</cell><cell>92,80%</cell><cell>18,3</cell><cell>11,8</cell><cell>76,70%</cell><cell></cell></row><row><cell>h</cell><cell>Deberta-v3-Large</cell><cell>f</cell><cell>28,3</cell><cell>18,9</cell><cell>92,80%</cell><cell>22,6</cell><cell>13,3</cell><cell>76,70%</cell><cell></cell></row><row><cell cols="2">i Deberta-v2-xxLarge</cell><cell>f</cell><cell>28,4</cell><cell>19,8</cell><cell>92,80%</cell><cell>25</cell><cell>17,4</cell><cell>76,70%</cell><cell></cell></row><row><cell>j</cell><cell>T5-3b</cell><cell>c</cell><cell>36,8</cell><cell>27,3</cell><cell>91,20%</cell><cell>25</cell><cell>19,4</cell><cell>69,90%</cell><cell></cell></row><row><cell>k</cell><cell>T5-3b</cell><cell>f</cell><cell>36,3</cell><cell>27,5</cell><cell>92,80%</cell><cell>26,1</cell><cell>20,6</cell><cell>76,70%</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Final ensembles</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>l</cell><cell>Ensemble</cell><cell>a+b+c+d+g+h+i</cell><cell>33,4</cell><cell>23,9</cell><cell>92,80%</cell><cell>28,4</cell><cell>21,1</cell><cell>76,70%</cell><cell></cell></row><row><cell>m</cell><cell>Ensemble</cell><cell>l+j+k</cell><cell>35</cell><cell>25</cell><cell>94,00%</cell><cell>27,2</cell><cell>20,4</cell><cell>78,90%</cell><cell></cell></row><row><cell>n</cell><cell>Ensemble</cell><cell>j+k</cell><cell>36,6</cell><cell>27,4</cell><cell>94,40%</cell><cell>25</cell><cell>19,5</cell><cell>78,90%</cell><cell>NLE fa adhoc rr</cell></row><row><cell>o</cell><cell>Ensemble</cell><cell>a+b+c+d+g+h+i+j+k</cell><cell>34,9</cell><cell>25,3</cell><cell>93,50%</cell><cell>28,1</cell><cell>20,7</cell><cell>76,70%</cell><cell>NLE ru adhoc rr</cell></row><row><cell cols="6">4 TREC NeuCLIR 2022 -initial analysis</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="4,108.00,558.80,168.46,8.64"><p>TREC Results are made available in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,119.27,226.99,373.46,31.60"><head>Table 3 :</head><label>3</label><figDesc>Results for our group submissions. Bolded values are the best value for the subgroup</figDesc><table coords="5,126.11,246.53,300.20,12.06"><row><cell></cell><cell>Farsi</cell><cell>Russian</cell></row><row><cell>Name</cell><cell>HC4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,108.00,75.48,396.00,93.20"><head></head><label></label><figDesc>Khattab, O. and Zaharia, M. (2020). Colbert: Efficient and effective passage search via contextualized late interaction over bert. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '20, page 39-48, New York, NY, USA. Association for Computing Machinery. [Lassance and Clinchant, 2022] Lassance, C. and Clinchant, S. (2022). An efficiency study for splade models. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2220-2226. [Lassance et al., 2023] Lassance, C., Déjean, H., and Clinchant, S. (</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,124.14,692.41,318.95,7.83"><p>Available at https://huggingface.co/naver/splade-cocondenser-selfdistil</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,124.14,703.29,217.43,7.83"><p>code available at https://github.com/luyug/Reranker</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="2,124.14,714.16,313.03,7.77"><p>Which are similar to the ones used on TREC-DL22 and made available on huggingface</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="3,124.14,714.16,180.06,7.77"><p>This include both in the collection and in the qrels</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How did our methods perform: No related documents were found, however, nDCG is not 0 which we found very weird.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Topic 20</head><p>Why we selected it: Worst median mAP in Russian (median 0.0006 and max 0.2778) Title: Are AIDS patients discriminated against in China Description: I am interested in finding out if AIDS patients are discriminated against in China.</p><p>Narrative: Find articles that carry information about whether AIDS patients in China face any discrimination in the country. Relevant articles would be those that provide information about the situation in China from the following perspectives: discussions about discriminations that are found to exist, cases of discriminations and efforts to eliminate discriminations. Articles that discuss about AIDS and AIDS patients from the perspectives of medicine and public health including treatment are not relevant. Articles about discriminations that AIDS patients face in other countries are not relevant.</p><p>Why we think it is hard: As per the previous queries, this searches for Chinese information in the Russian database and it is not even evaluated in Farsi. Also as before, tokenization may cause problems with AIDS (Especially with case insensitive, with AIDS the disease vs aids the word).</p><p>How did our methods perform: Our methods suffered on this task, the monolingual run had the best effectiveness out of the methods, but far from the best overall (0.04), but the reranker made it lose. The reranked Adhoc is slightly better. Looking at the baseline runs, it seems that the problem came from the machine translation of the query, as both DT and HT had decent mAP (0.04)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Topic 24</head><p>Why we selected it: Highest difference between median and max on both nDCG@20 and mAP in Farsi (Some methods reached mAP=1 and nDCG=1, but median is around 0.1 for both) Title: Wind energy in Russia Description: I am looking for articles on the growth of wind energy in Russia.</p><p>Narrative: Find articles on the development and growth of wind energy in Russia. Include information on joint ventures with foreign firms for the production of wind turbines and related equipment. Include information on the planned outputs of windmill parks. Information on wind energy in other countries not involving cooperation with Russian entities is not required. Neither is information on other renewable or non-renewable energy resources in Russia.</p><p>Why we think it is hard: As per the previous queries, this searches for Russian information in the Farsi database. Also, methods that use the title only would miss the need of "growth".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How did our methods perform:</head><p>A.7 Topic 26 Why we selected it: Worst best recall on Russian (81.58%) Title: Ukrainian Presidential Candidate Zelenskiy Description: I am looking for articles that reflect Russia's attitude towards Ukrainian Presidential Candidate Volodymyr Zelenskiy Narrative: Find articles that reveal the Russian perspective of then presidential candidate Volodymyr Zelenskiy for the 2019 election. Include articles that highlight what Ukrainian officials say that Russian media circulates about Zelenskiy as that reveals what Russians want readers to be aware of. Russian perspective as to his ability to win, who might be supporting him, how seriously they should be taking him, and so forth. Did not include articles that discussed subsequent elections, local or parliamentary elections, or any actions Zelenskiy took once he became president. Did not include Zelenskiys recommendations on how elections in Donbass should be run. Articles purely about the polls and statistics were not included.</p><p>Why we think it is hard: There's a problem with transliteration for translations, where term-based methods may miss documents due to it having written Zelenski or Zelensky or Zelenskyy (found all these variants after a quick google search).</p><p>How did our methods perform: Our final methods got decent results (78.95% the best), but not because of SPLADE, which had very bad recall: DT: 21.05% , MT:15.79%, HT: 7.89%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.8 Topic 52</head><p>Why we selected it: Worst median nDCG@20 on Russian (0.1095, with a max of 0.6723) Title: Tourism in Beijing under the Covid-19 pandemic Description: I am interested in finding information about the tourism industry in Beijing amid the Covid-19 pandemic.</p><p>Narrative: Find stories about the situation of the tourism industry in Beijing under the Covid-19 pandemic. Relevant articles are those that would cover any aspect of the industry in the city, like the situation of museums and other attractions, restaurants, tour operators, etc. during the time when the pandemic remained a concern. Stories about outbound travel from Beijing would not be considered relevant. Only the actual situations would be of interest for the information search. Articles of analysis of the industry and projections, unless they do mention the actual situation, would not be considered relevant Why we think it is hard: Again, the title misses a keyword (industry) and asks for details of China in a Russian base, with the Farsi base also not as effective (0.2321, with a max of 0.5379).</p><p>How did our methods perform: Our best method was almost as effective as the best (0.59 vs 0.67), but looking into our first stage rankers, we have a very large drop on the document backtranslation (0.2551) compared to the query translations (0.5334) A.9 Topic 67 Why we selected it: Highest difference between median and max mAP on Russian (max mAP=1, median mAP=0.0606)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title: Reasons people become virtual streamers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description:</head><p>I'm looking for reasons why people choose to stream online virtually behind an avatar.</p><p>Narrative: Find articles explaining why people choose to stream online virtually behind a 2D or 3D avatar. Relevant articles shoud provide attribute or positive aspects of streaming virtually that are superior to traditional live-person broadcast.</p><p>Why we think it is hard: This is the first topic from the set we analyzed that is not dependent on a language (or focused on a local subject). The lack of the Vtuber (or V-tuber) keyword could be something problematic here, but actually, the main problem is that there's only one positive.</p><p>How did our methods perform: All methods found the only positive, but only the SPLADE DT had it at the first position, with the other methods putting it at best at 5th.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.10 Topic 72</head><p>Why we selected it: Not evaluated in Farsi Title: Playing games could effectively prevent dementia Description: I'm looking for articles on whether playing games could prevent or delay the onset of dementia.</p><p>Narrative: Find articles that mention playing games could prevent or delay the onset of dementia. Why we think it is hard: Like the previous one, this one does not necessarily focus on a particular language, but it could be that no results exist on the database, as it seems to be the case for Farsi. In Russian, there were some results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.11 Topic 118</head><p>Why we selected it: Worst best nDCG@20 on Russian (0.4967, with a median of 0.2607) and also the worst best Recall@1k on Farsi (85.02%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Title: Arbitrary detention of foreigners and Iranian dual nationals by Iran</head><p>Description: I'm looking for articles reporting on the arbitrary detention of foreigners and Iranian dual nationals by Iran.</p><p>Narrative: Find articles that show whether the arbitrary detention of foreign nationals and dual nationals by Iran is for political or economic gain or whether they are allegedly spies for Iran. What is the reaction of governments and international institutions? Is this a government hostage-taking.</p><p>Why we think it is hard: Again, we have the problem of looking for pieces of information of "one" base in another. However, it also "caused problems" on Farsi, but for the opposite reason: there were too many positives (287).</p><p>How did our methods perform: In Farsi we are able to achieve the best possible Recall on the Adhoc but slightly less on the monolingual task. While in Russian we are almost able to match the best nDCG@20 (0.4955 vs 0.4967) and have similar effects on both Adhoc and monolingual.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="5,112.29,546.62,391.71,8.64;5,119.62,557.35,384.39,8.82;5,119.62,568.26,150.49,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,375.70,546.62,128.31,8.64;5,119.62,557.53,43.00,8.64">ranx. fuse: A python library for metasearch</title>
		<author>
			<persName coords=""><forename type="first">Romelli ;</forename><surname>Bassani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bassani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,180.91,557.35,323.10,8.59;5,119.62,568.26,70.57,8.59">Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 31st ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="4808" to="4812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.00,585.61,396.00,8.64;5,119.62,596.34,384.38,8.82;5,119.62,607.25,75.27,8.59;5,108.00,624.61,396.00,8.64;5,119.62,635.34,384.38,8.82;5,119.62,646.25,110.05,8.59" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><surname>Bonifacio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.13897</idno>
		<idno>arXiv:2205.04733</idno>
		<title level="m" coord="5,190.16,596.52,250.28,8.64;5,482.41,624.61,21.59,8.64;5,119.62,635.52,351.35,8.64">From distillation to hard negative sampling: Making sparse neural ir models more effective</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Lassance</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Piwowarski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Clinchant</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>A multilingual version of the ms marco passage ranking dataset</note>
</biblStruct>

<biblStruct coords="5,108.00,663.61,396.00,8.64;5,119.62,674.52,117.10,8.64" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><surname>Gao</surname></persName>
		</author>
		<title level="m" coord="5,354.40,663.61,149.61,8.64;5,119.62,674.52,113.26,8.64">Rethink training of bert rerankers in multi-stage retrieval pipeline</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,108.00,691.70,396.00,8.64;5,119.62,702.61,384.39,8.64;5,119.62,713.51,31.81,8.64" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,268.63,691.70,235.38,8.64;5,119.62,702.61,87.60,8.64">A probabilistic analysis of the rocchio algorithm with tfidf for text categorization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims ; Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<publisher>Carnegie-mellon univ pittsburgh pa dept of computer science</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
