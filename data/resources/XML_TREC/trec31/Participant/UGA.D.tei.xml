<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.60,117.75,254.15,12.62;1,189.22,135.68,236.92,12.62">Université Grenoble Alpes / LIG at TREC Deep Learning Track 2022</title>
				<funder>
					<orgName type="full">Austrian Science Fund (FWF)</orgName>
				</funder>
				<funder ref="#_cmWB7fJ">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">French Agence Nationale de la Recherche</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.75,173.51,79.38,8.74"><forename type="first">Petra</forename><surname>Galuščáková</surname></persName>
						</author>
						<author>
							<persName coords="1,232.21,173.51,65.34,8.74"><forename type="first">Lucas</forename><surname>Alberede</surname></persName>
						</author>
						<author>
							<persName coords="1,305.50,173.51,131.06,8.74"><forename type="first">Gabriela</forename><forename type="middle">Nicole</forename><surname>Gonzalez Saez</surname></persName>
						</author>
						<author>
							<persName coords="1,444.31,173.51,26.29,8.74;1,209.71,185.46,36.08,8.74"><forename type="first">Aidan</forename><surname>Mannion</surname></persName>
						</author>
						<author>
							<persName coords="1,254.26,185.46,72.69,8.74"><forename type="first">Philippe</forename><surname>Mulhem</surname></persName>
						</author>
						<author>
							<persName coords="1,335.76,185.46,69.90,8.74"><forename type="first">Georges</forename><surname>Quénot</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">LIG</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP ⋆⋆</orgName>
								<address>
									<postCode>38000</postCode>
									<settlement>Grenoble</settlement>
									<region>Inria</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">MRIM research Group/Laboratoire d&apos;Informatique de Grenoble from the Université Greno-ble Alpes</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.60,117.75,254.15,12.62;1,189.22,135.68,236.92,12.62">Université Grenoble Alpes / LIG at TREC Deep Learning Track 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">23FAE4672ACE457BF1AD246AA3FDF3BB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>at the TREC Deep Learning Track 2022. We participated in both fullranking and reranking sub-tasks in the passages ranking task. We proposed several ways to combine neural and non-neural runs using reciprocal-rank based fusion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This report describes the submissions of the Modeling and Retrieval of Multimedia Information research Group at Université Grenoble Alpes team at the TREC Deep Learning Track 2022. We have participated in the passages ranking task, in both fullranking and reranking sub-tasks.</p><p>For the fullranking sub-task, we used several ranking models for the first stage retrieval and an index of the full collection. We subsequently applied reranking on top of the outputs of this ranking. Last, we combined the outputs of multiple rankers and re-rankers into a single output. We comprehensively experimented with a range of first stage retrieval models, rerankers, and architectures and selected 3 runs which we submitted and which were used in the pooling and 4 additional runs, which we submitted but which were not used in the pooling.</p><p>In the reranking sub-task, we applied three reranking approaches to the provided list of passages and we either combined them or we chained them on the top of each other.</p><p>In the submissions selection process, we used the test collection used at TREC Deep Learning 2021 Passage ranking task, which in terms of collection statistics, should well correspond to this year track's collection. This collection contains 477 queries, for 53 out of which there are provided the relevance judgements. As this number is relatively small, in the selection we aimed for both good performance and robustness of the submitted system.</p><p>In the following section, we cover the basic blocks which we used in the submissions. We review the fullranking models used for getting the top relevant passages from the full passage collection and the models for reranking which we applied to the passages retrieved by these fullranking models. We then review ⋆⋆ Institute of Engineering Univ. Grenoble Alpes our fullranking submissions in the Section 3 and the reranking submissions in Section 4. All the scripts used in our submissions are freely available 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Basic Building Blocks</head><p>We use full ranking models for ranking all the passages available in the collection as the first stage of the retrieval. We experimented with a range of full ranking models from which we selected 5 well performing and diverse models, as such systems might be expected to perform well in a combination. We eventually use following full ranking models in all our submissions:</p><p>-BM25: The standard BM25 retrieval model with default parameters, using the index and implementation provided by Anserini <ref type="bibr" coords="2,381.04,272.80,14.61,8.74" target="#b10">[11]</ref>. In addition to the index of passages, we also use the index of documents, which are further used in the reranking using the Graph Model (see below). If not stated otherwise, we further refer to the retrieval of passages in this report. -Expanded BM25: BM25 with document expansion using docT5query <ref type="bibr" coords="2,470.07,320.84,10.52,8.74" target="#b5">[6]</ref> and RM3 blind relevance feedback. We used the index and implementation provided by Anserini. -DPH: DPH <ref type="bibr" coords="2,208.72,356.93,10.52,8.74" target="#b3">[4]</ref> is a well performing and a parameter free scoring technique derived from the Divergence from Randomness model. In this approach, we indexed and retrieved the segments using Terrier v5.0 framework <ref type="bibr" coords="2,467.31,380.84,9.96,8.74" target="#b7">[8]</ref>. DPH was used with stemming and with blind relevance feedback 2 , as this is expected to increase a diversity of the performance of the models. -Colbert: A BERT-based passage retrieval model <ref type="bibr" coords="2,374.17,416.93,9.96,8.74" target="#b1">[2]</ref>. Specifically, we used the TCT-ColBERTv2 model fine-tuned on MS MARCO v2 provided by Anserini.</p><p>-uniCOIL: A model that integrates BERT embeddings into a sparse representation <ref type="bibr" coords="2,194.38,464.98,9.96,8.74" target="#b2">[3]</ref>. Specifically, we used Castorini unicoil-msmarco-passage model pre-trained on MS MARCO v2 Passage Corpus, along with on-the-fly docT5query query inference. We used an index provided by Anserini.</p><p>Passages returned by these models which were ranked at the top positions are in some cases further reranked. Reranking is done by calculating the similarity between the query and retrieved passage and reordering the passages based on this similarity. Specifically, we use following approaches:</p><p>-BERT: We used the monoBERT model <ref type="bibr" coords="2,329.96,570.61,10.52,8.74" target="#b6">[7]</ref> from Castorini, available in Pygaggle 3 , which was finetuned on MS MARCO v1. -T5: We used the monoT5 model <ref type="bibr" coords="2,303.51,594.75,10.52,8.74" target="#b4">[5]</ref> from Castorini available in Pygaggle which was finetuned on MS MARCO v1.</p><p>-MiniLM: Cross-encoders are transformer models <ref type="bibr" coords="3,378.37,119.99,15.50,8.74" target="#b9">[10]</ref> fine-tuned for sentence similarity calculation, which are widely used in semantic search as they compute attention weights across the query and the document together. We used the MiniLM architecture provided by the sentence-transformers library <ref type="foot" coords="3,180.81,166.24,3.97,6.12" target="#foot_0">4</ref> , which have been pre-trained on the MS MARCO v2 passage reranking dataset. -Graph Model: We use Heterogeneous Graph Attention Networks (HGATs).</p><p>Document retrieval (BM25) is applied as a first stage retrieval returning the top 1000 documents. Every passage from these documents is then reranked using HGATs to leverage its relations with other passages in a graph-based document representation <ref type="bibr" coords="3,263.66,239.59,9.96,8.74" target="#b0">[1]</ref>. Passage and query embeddings are computed using a multiple-representation embedding encoder similar to the one in the Colbert architecture <ref type="bibr" coords="3,243.11,263.50,9.96,8.74" target="#b1">[2]</ref>.</p><p>Finally, for the combination of the ranked and reranked runs, we used reciprocal rank-based (RR) fusion implemented in TrecTools<ref type="foot" coords="3,377.99,296.01,3.97,6.12" target="#foot_1">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fullranking Submissions</head><p>All our submissions consisted of a combination of fullranking and reranking models. We submitted three runs which were further used in the pooling: hierarchical combination, flat combination and double reranking. A graphical view of the submissions is displayed in Figure <ref type="figure" coords="3,314.32,389.76,3.87,8.74" target="#fig_2">1</ref>. Flat Combination: This combination consists of 6 rankers, rerankers and combinations which all together form the final combination. Due to the diversity of the combined models, this system is also supposed to be robust. Following models are combined:  In addition to these runs, we submitted other four runs which were officially evaluated by the task organizers, but were not included in the evaluation pool.</p><p>Graph: This system is simply the Graph Model described in Section 2 which uses a BM25 ranking of the documents followed by reranking done using the Graph Attention Networks. The official run name used in the submissions is graph colbert.</p><p>Reranked Unicoil: This system also does not use any reciprocal rank-based combination. Instead, it only uses double reranking of the UniCOIL system, first by MiniLM model [top 100 documents] and then by T5 model [top 10 documents]. The system is thus the same as the Double Reranking system which was submitted for the pooling, but without the expanded BM25 model applied. The official run name used in the submissions is unicoil reranked. The official run name used in the submissions is c47.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Official Evaluation Results</head><p>The evaluation of these submitted systems is displayed in Table <ref type="table" coords="6,411.78,142.78,3.87,8.74" target="#tab_0">1</ref>. Based on this table we see that the single Graph-based reranking and the Hierarchical Combination outperform the other combinations for the measures taking into account top 1000 results (MAP, nDCG@1000 and Recall@1000). The 4-way combinations perform the worst according to these measures. As the Hierarchical Combination also includes the Graph-based reranking as one of the combined systems and as they perform similarly in terms of retrieving the top 1000 documents, we can claim, that the additional systems in the combination add no extra improvement to the Graph system. However, the Hierarchical Combination performs better than the Graph in terms of the measures working only with top 10 documents (nDCG@10 and P@10). The additional systems added to the Graph system thus do not change the performance of the retrieval on the top 1000 documents, but leads to improvement for the top 10 documents retrieval. However, clearly the best performance in terms of retrieving top 10 documents is achieved by the Double Reranking system (in terms of nDCG@10 and P@10 measures), followed by the Reranked Unicoil. This might confirm the usefulness of the duo architecture, especially for the retrieval on the top positions and it should lead to further experimentation with different cascading setups and rerankers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run name</head><p>Pooling MAP nDCG@10 nDCG@1000 P@10 Recall@1000 Hierarchical Combination Yes 0.166 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reranking submissions</head><p>In the reranking submissions, we only used the reranking methods described above and we either combined them using a fusion or using a chain of double reranking. The graphical overview of all submissions is displayed in Figure <ref type="figure" coords="6,463.03,600.45,3.87,8.74">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3-way Combination:</head><p>We reranked the original run by the MiniLM model, T5 model and BERT model. Then we combined all three reranked runs into a single run. The official run name for this submission is fused 3runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2-way Combination:</head><p>We reranked the original run by the MiniLM model and T5 model. Then we combined both reranked runs into a single run. This run might be directly compared with the double reranking run, which uses the same rerankers, but combined together in a different architecture and to the 3-way combination that uses one additional reranker. The official run name for this submission is fused 2runs.</p><p>Double Reranking: Similarly, as in the full reranking run, we used the duo architectures and stacked two rerankers on a top of each other. We first reranked all 100 passages by the MiniLM model and then reranked again the top 10 passages by the T5 model. The official run name for this submission is hierarchical 2runs.</p><p>Official evaluation results: The evaluation of our reranking submitted systems is displayed in Table <ref type="table" coords="8,253.30,131.95,3.87,8.74" target="#tab_1">2</ref>. Compared to Table <ref type="table" coords="8,353.82,131.95,3.87,8.74" target="#tab_0">1</ref>, we do not present the Recall@1000 values as reranking has no effect on it and the Recall@1000 for all the systems is 0.138. Clearly, these results are lower than the results for the fullranking task, in terms of all considered measures. This shows the importance of using adequate and varied inputs for the reranking step. What we also notice is that all three runs achive very similar results. The only exception is the hierarchical combination of 3 systems (3-way Combination) which performs better than both combinations of 2 systems (2-way Combination and Double Reranking) in terms of the P@10 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run name</head><p>Pooling MAP nDCG10 nDCG@1000 P@10 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We described our submissions for the fullranking and reranking sub-tasks of TREC Deep Learning 2022 Passage Retrieval Task. For the fullranking subtask, a graph-based reranking of the passages identified using document ranking performs especially well for retrieving top 1000 documents. Its combination with additional well performing systems then further leads to a strong performance on the top 10 documents. The best performing system for the retrieval of the top 10 documents combines double reranked UniCOIL system with reranked BM25 system with query and document expansions applied. Our experiments thus lead to further questions about how to best combine multiple rankers and rerankers, which we plan to explore in future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,419.88,345.82,8.77;3,134.77,431.87,345.82,8.74;3,134.77,443.82,346.48,8.74;3,134.77,455.78,345.82,8.74;3,134.77,467.73,345.82,8.74;3,134.77,479.69,345.83,8.74;3,134.77,491.64,201.94,8.74"><head></head><label></label><figDesc>Hierarchical Combination: First, Colbert, UniCOIL and Expanded BM25 rankers were combined and then reranked by BERT [top 10 documents]. Then, this combination was further combined with UniCOIL reranked by dense MiniLM model [top 100 documents] and with BM25 reranked by the Graph Model [top 100 document]. This system achieved the highest performance on our training data in terms of nDCG@10, nDCG@1000 and MAP. The official run name used in the submissions is hierarchical combination.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,140.99,579.81,51.25,8.77;3,140.99,591.81,274.28,8.77;3,415.27,590.27,3.97,6.12;3,140.99,603.82,205.40,8.77;3,140.99,615.83,245.50,8.77;4,140.99,119.96,261.79,8.77;4,140.99,133.15,333.72,8.77;4,149.71,160.05,253.85,8.74"><head>-</head><label></label><figDesc>UniCOIL -UniCOIL reranked by a MiniLM model [top 100 documents] 6 -Colbert reranked by T5 [top 100 documents] -Expanded BM25 reranked by T5 [top 100 documents] -BM25 reranked by the Graph Model [top 100 documents] -BM25 and DPH first combined, then reranked by T5 [top 100 documents]The official run name used in the submissions is 6systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.77,629.62,345.83,8.74;4,134.77,641.57,345.82,8.74;4,134.77,653.53,67.33,8.74;4,246.88,474.35,121.60,126.80"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Full ranking architectures. Ranking models are in blue, reranking models in rose, and fusions in yellow. The number of reranked passages/documents is in the brackets.</figDesc><graphic coords="4,246.88,474.35,121.60,126.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,134.77,415.39,345.83,8.77;5,134.77,427.38,194.16,8.74;5,140.99,450.05,51.25,8.77;5,140.99,462.17,264.43,8.77;5,140.99,474.28,235.65,8.77;5,140.99,486.39,251.93,8.77;5,149.71,508.97,253.85,8.74;5,134.77,539.62,345.83,8.77;5,134.77,551.61,345.83,8.74;5,134.77,563.56,345.83,8.74;5,134.77,575.52,175.09,8.74;5,140.99,598.19,51.25,8.77;5,140.99,610.31,274.28,8.77;5,140.99,622.42,245.50,8.77;5,140.99,634.53,333.72,8.77"><head>4</head><label></label><figDesc>Systems with Graph: This combination contains a subset of 4 systems which are included in the Flat Combination: -UniCOIL -UniCOIL reranked by a MiniLM model [top 100 passages] -Expanded BM25 reranked by T5 [top 100 passages] -BM25 reranked by the Graph Model [top 100 passages] The official run name used in the submissions is 4systems. 4 Systems with DPH: This combination again contains a subset of 4 systems which are included in the Flat Combination. Comparing with 4 Systems with Graph, the BM25 model reranked by the graph model is here replaced by a combination of BM25 and DPH models: -UniCOIL -UniCOIL reranked by a MiniLM model [top 100 documents] -Expanded BM25 reranked by T5 [top 100 documents] -BM25 and DPH first combined, then reranked by T5 [top 100 documents]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,239.53,461.96,136.29,8.74;7,275.95,330.90,63.45,102.60"><head>(a) 3 -Fig. 2 :</head><label>32</label><figDesc>Fig. 2: Reranking architectures.</figDesc><graphic coords="7,275.95,330.90,63.45,102.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,391.46,345.82,97.45"><head>Table 1 :</head><label>1</label><figDesc>Full ranking sub-task UGA official results. The highest scores for each measure are highlighted.</figDesc><table coords="6,312.98,391.46,151.54,7.89"><row><cell>0.570</cell><cell>0.330</cell><cell>0.492</cell><cell>0.327</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,269.00,345.83,53.61"><head>Table 2 :</head><label>2</label><figDesc>Reranking sub-task UGA official results. The highest scores for each measure are highlighted.</figDesc><table coords="8,178.75,269.00,257.85,29.81"><row><cell cols="2">3-way Combination Yes 0.090 0.509</cell><cell>0.209</cell><cell>0.391</cell></row><row><cell cols="2">2-way Combination Yes 0.090 0.506</cell><cell>0.210</cell><cell>0.374</cell></row><row><cell>Double Reranking</cell><cell>Yes 0.089 0.500</cell><cell>0.210</cell><cell>0.368</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,636.52,283.44,7.47"><p>https://www.sbert.net/docs/pretrained-models/ce-msmarco.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,647.48,188.29,7.47"><p>https://github.com/joaopalotti/trectools</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="3,144.73,657.79,242.68,7.86"><p>The number of reranked documents is given in the brackets.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work is supported by the <rs type="funder">ANR</rs> <rs type="programName">Kodicare bi-lateral project</rs>, grant <rs type="grantNumber">ANR-19-CE23-0029</rs> of the <rs type="funder">French Agence Nationale de la Recherche</rs>, and by the <rs type="funder">Austrian Science Fund (FWF)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cmWB7fJ">
					<idno type="grant-number">ANR-19-CE23-0029</idno>
					<orgName type="program" subtype="full">Kodicare bi-lateral project</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,635.88,337.64,7.86;8,151.52,646.84,329.07,7.86;8,151.52,657.79,329.07,7.86;9,151.52,120.67,329.07,7.86;9,151.52,131.63,329.07,7.86;9,151.52,142.59,329.07,7.86;9,151.52,153.55,114.26,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,229.44,646.84,251.15,7.86;8,151.52,657.79,53.95,7.86">Passage retrieval on structured documents using graph attention networks</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Albarede</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Pape-Gardeux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chardin-Segui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,292.87,120.67,187.72,7.86;9,151.52,131.63,189.57,7.86;9,176.93,142.59,80.55,7.86">Advances in Information Retrieval -44th European Conference on IR Research, ECIR 2022</title>
		<title level="s" coord="9,334.16,142.59,142.40,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Verberne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Nørvåg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Setty</surname></persName>
		</editor>
		<meeting><address><addrLine>Stavanger, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">April 10-14, 2022. 2022</date>
			<biblScope unit="volume">13186</biblScope>
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct coords="9,142.96,164.51,337.63,7.86;9,151.52,175.46,329.07,7.86;9,151.52,186.42,319.38,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,276.36,164.51,204.23,7.86;9,151.52,175.46,157.60,7.86">Colbert: Efficient and effective passage search via contextualized late interaction over bert</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,326.79,175.46,150.22,7.86">Proceedings of SIGIR 2020, SIGIR &apos;20</title>
		<meeting>SIGIR 2020, SIGIR &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,197.38,106.71,7.86;9,272.51,197.38,208.08,7.86;9,151.52,208.34,329.07,7.86;9,151.52,219.30,137.61,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,272.51,197.38,208.08,7.86;9,151.52,208.34,296.75,7.86">A Few Brief Notes on DeepImpact, COIL, and a Conceptual Framework for Information Retrieval Techniques</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.14807" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,230.26,337.63,7.86;9,151.52,241.22,329.07,7.86;9,151.52,252.18,329.07,7.86;9,151.52,263.14,329.07,7.86;9,151.52,274.09,329.07,7.86;9,151.52,285.05,55.80,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,450.62,230.26,29.97,7.86;9,151.52,241.22,227.99,7.86">University of glasgow at TREC 2009: Experiments with terrier</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,248.93,252.18,227.37,7.86">Proceedings of The Eighteenth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>The Eighteenth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-11-17">2009. November 17-20, 2009. 2009</date>
			<biblScope unit="volume">500</biblScope>
		</imprint>
		<respStmt>
			<orgName>NIST Special Publication. National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,296.01,337.64,7.86;9,151.52,306.97,329.07,7.86;9,151.52,317.93,329.07,7.86;9,151.52,328.89,123.38,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,354.18,296.01,126.41,7.86;9,151.52,306.97,141.71,7.86">Document ranking with a pretrained sequence-to-sequence model</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,313.14,306.97,167.45,7.86;9,151.52,317.93,130.98,7.86">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,339.85,337.64,7.86;9,151.52,350.81,114.00,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,253.68,339.85,148.01,7.86">From doc2query to docTTTTTquery</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>University of Watrloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="9,142.96,361.77,337.64,7.86;9,151.52,372.73,193.79,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1910.14424" />
		<title level="m" coord="9,330.88,361.77,149.72,7.86;9,151.52,372.73,22.42,7.86">Multi-Stage Document Ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,383.68,337.64,7.86;9,151.52,394.64,329.07,7.86;9,151.52,405.60,329.07,7.86;9,151.52,416.56,60.45,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,402.86,383.68,77.74,7.86;9,151.52,394.64,72.46,7.86">Terrier Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johnson</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,241.50,394.64,239.09,7.86;9,151.52,405.60,51.05,7.86">Proceedings of the 27th European Conference on IR Research (ECIR 2005)</title>
		<title level="s" coord="9,273.34,405.60,140.31,7.86">Lecture Notes in Computer Science</title>
		<meeting>the 27th European Conference on IR Research (ECIR 2005)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3408</biblScope>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,427.52,337.64,7.86;9,151.52,438.48,260.58,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,308.47,427.52,172.12,7.86;9,151.52,438.48,232.16,7.86">The expando-mono-duo design pattern for text ranking with pretrained sequence-to-sequence models</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,449.44,337.98,7.86;9,151.52,460.40,329.07,7.86;9,151.52,471.36,103.55,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,234.54,460.40,102.24,7.86">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,348.23,460.40,132.36,7.86;9,151.52,471.36,75.17,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,482.31,337.98,7.86;9,151.52,493.27,329.07,7.86;9,151.52,504.23,329.07,7.86;9,151.52,515.19,316.30,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,272.80,482.31,207.79,7.86;9,151.52,493.27,68.86,7.86">Anserini: Enabling the use of lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,245.69,493.27,234.90,7.86;9,151.52,504.23,303.45,7.86">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
