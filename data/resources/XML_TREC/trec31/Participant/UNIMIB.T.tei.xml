<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,211.70,85.16,171.88,12.62;1,225.87,103.09,143.54,12.62">UNIMIB at TREC 2022 Clinical Trials Track</title>
				<funder ref="#_etyGKuz">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_ge74H3v">
					<orgName type="full">EU Horizon 2020 ITN/ETN on Domain Specific Systems for Information Extraction and Retrieval -DoSSIER</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.22,140.78,68.70,8.74"><forename type="first">Georgios</forename><surname>Peikos</surname></persName>
							<email>georgios.peikos@unimib.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems, and Communication (DISCo)</orgName>
								<orgName type="laboratory">Information and Knowledge Representation, Retrieval, and Reasoning (IKR3) Lab</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.60,140.78,61.46,8.74"><forename type="first">Gabriella</forename><surname>Pasi</surname></persName>
							<email>gabriella.pasi@unimib.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems, and Communication (DISCo)</orgName>
								<orgName type="laboratory">Information and Knowledge Representation, Retrieval, and Reasoning (IKR3) Lab</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,211.70,85.16,171.88,12.62;1,225.87,103.09,143.54,12.62">UNIMIB at TREC 2022 Clinical Trials Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">02D819EF0493209E86FC38ABD0B9FCD9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This notebook summarizes our participation as the UNIMIB team in the TREC 2022 Clinical Trials Track. In this work, we extend our last year's participation by further investigating the retrieval performance achieved by our decision-theoretic model for relevance estimation. Specifically, our objective was to investigate the effectiveness of our decisiontheoretic model by heavily penalizing those clinical trials for which the patient has high topical similarity to the exclusion criteria. The model has been employed to estimate relevance in two retrieval settings, ranking and re-ranking. The obtained results showed that the proposed model performs equally well in both of them, while the best results in terms of precision were achieved in the re-ranking setting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2022 Clinical Trials track is a continuation of the 2021 Clinical Trials track, which uses the same document collection and follows the same search task definition. Specifically, given a patient's synthetic case in the form of an admission note, the system's goal is to retrieve eligible clinical trials, i.e., those for which the patient meets the inclusion criteria and not the exclusion criteria. However, a trial's eligibility criteria (inclusion and exclusion) are semi-structured, while the provided synthetic cases (queries) are unstructured. This retrieval task is complex since the topical relevance to a document's part, the one that mentions the exclusion criteria, contributes negatively to the overall document's relevance.</p><p>This report outlines our team's (UNIMIB) submission to TREC 2022 Clinical Trials Track, a continuation of our last year's participation <ref type="bibr" coords="1,279.48,488.66,9.96,8.74" target="#b0">[1]</ref>. It presents the experimental setup and compares our results to the reported TREC's median performance. This year, we investigated the retrieval performance achieved by our decision-theoretic model introduced in <ref type="bibr" coords="1,384.12,512.57,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>This section describes our methodology that comprises three steps, including (i) an information extraction step, in which valuable information present in a clinical trial document is extracted and indexed; (ii) a step that involves the estimation of three topical relevance scores that are associated with each clinical trial; and (iii) a score aggregation step, from which the final document ranking is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Information Extraction &amp; Indexing</head><p>Clinical trials are structured documents with various fields such as title, summary, studied condition, among others. In addition, in this task, a trial's inclusion and exclusion criteria are mentioned in a semi-structured format within its eligibility section, holding great importance.</p><p>Our methodology exploits four document representations, each containing different document information. In detail, using a set of regex rules that leverage the semi-structured format of the inclusion and exclusion criteria, we extract them to create two distinct indices. Specifically, the I in index contains only a trial's inclusion criteria, and the I ex index only the trial's exclusion criteria. In the cases where their extraction was not feasible, the whole eligibility section has been indexed in both indices, i.e., the I in and I ex. In addition to those two indices, we construct a third one. Here, the title, description, studied condition, and summary sections were combined in a single text and indexed; this index will be referred to as I main. Lastly, we indexed all document sections to create the I comb representation used in one of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relevance Estimation &amp; Score Aggregation</head><p>During retrieval, given a query, we estimate for each document three topical relevance scores using the I in, I ex, and I main indices. These scores represent the degree to which a patient's information is met in a document's inclusion and exclusion criteria, and in its main fields.</p><p>Then, the final stage of our methodology involves aggregating the obtained topical relevance scores by explicitly considering their independent contribution to relevance. Specifically, we employed TOPSIS <ref type="bibr" coords="2,156.27,248.10,9.96,8.74" target="#b1">[2]</ref>, a multi-criteria decision-making method, to obtain a final document ranking. This method associates three weights with the distinct topical relevance scores obtained in the previous stage. These weights indicate how significant the similarity to the associated document's part is for the document's overall relevance. In addition, this method associates to each distinct topical relevance score an objective. This objective is either positive or negative; a positive objective indicates that this score impacts positively a document's overall relevance, i.e., the higher the score the better, while a negative objective is the exact opposite. In this work, the topical relevance score obtained from the similarity to a trials main parts and inclusion criteria are assigned a positive objective, while the topical relevance score obtained from the similarity to a trials exclusion criteria a negative objective. Therefore, due to the associated objectives, the employed aggregation method always penalizes a clinical trial for which the topical relevance score associated with its exclusion criteria is high. As a result, documents that have high topical relevance scores to a trial's exclusion criteria will obtain a lower ranking position. Considering an example, setting the importance weight of the inclusion criteria equal to .2, the exclusion criteria equal to .6 and the main parts equal to .2 leads to a retrieval system that heavily penalizes those trials for which a patient's information has high similarity to their exclusion criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We have submitted five runs to investigate the impact of importance weights in the relevance estimation. To index the collection and estimate the topical relevance scores for each document representation, we have employed PyTerrier <ref type="bibr" coords="2,286.19,520.27,10.52,8.74" target="#b2">[3]</ref> and the ln expB2 divergence from randomness model <ref type="bibr" coords="2,114.73,532.23,9.96,8.74" target="#b3">[4]</ref>. For preprocessing, we have used the standard PyTerrier pipeline, i.e., porter-stemming and stopwords removal.</p><p>The first run, namely IKR3 BSL exploits the ln expB2 model and the I comb index. In the IKR3 BSL TT HW experiment, we employ the ln expB2 model and the I comb index to retrieve two thousand documents per query. Then, using the I in and the I ex indices and the aggregation model with weight main = .1, weight in = .4, and weight in = .5 we re-rank the top-1000 documents. These weights are selected manually based on the intuition that clinical trials with high similarity to the exclusion section should be heavily penalized. Following a similar intuition, the IKR3 BSL TT MW experiment also re-ranks the top-1000 documents of the IKR3 BSL. However, in this case, the selected weights are weight main = .23, weight in = .33, and weight in = .44. In this case, the system considers almost equally the importance of the similarity to a trial's main fields and inclusion criteria. However, again it penalizes those trials for which the patient has a high similarity to their exclusion criteria.</p><p>Lastly, in the IKR3 TT BW and the IKR3 TT MW experiments, we estimate the three topical relevance scores using the I main, I in, and I ex for every document in the collection, and then we aggregate these scores. In the IKR3 TT BW experiment, the weights were found via an exhaustive search conducted using last year's queries; as optimal weights were selected those that optimized P@10 measure. For the IKR3 TT MW, the weights were equally allocated to the three similarity scores, i.e., equal to .33. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="3,114.24,245.86,4.98,8.74" target="#tab_0">1</ref> presents the results obtained from the five submitted runs. A general observation is that none of the implemented experiments outperforms the baseline run (IKR3 BSL) in terms of NDCG@10. That is a reasonable outcome as the proposed methods aim at improving the task of finding eligible clinical trials for a patient; therefore, they penalize possible "excluded" trials. Specifically, the contribution of the similarity to a trial's exclusion criteria is always regarded negatively by the models. That is why one observes low NDCG scores but, at the same time, high precision-oriented scores. To improve the NDCG@10 measure, the model should consider the contribution of the similarity to a trial's exclusion criteria also positively, but with lower importance (i.e., weight ex &lt;&lt; weight in and weight ex &lt;&lt; weight main). The highest PREC@10 and Reciprocal Rank values are obtained by the IKR3 BSL TT MW experiment in which the importance of the similarity obtained from the document parts that contribute positively to its overall relevance (i.e., similarity to main and inclusion parts) is almost equal to the importance of the one that contributes negatively (weight main = .23, weight in = .33, and weight in = .44). This finding suggests that one should consider the impact of the similarity to the main and inclusion parts. That is also supported in the IKR3 BSL TT HW experiments in which the positive contribution coming from the main document parts is almost neglected, and the relevance estimation relies on the similarity to the inclusion and the exclusion parts. Lastly, the IKR3 TT BW and IKR3 TT MW experiments suggest that the aggregation schema can be employed directly for document ranking, as the obtained results are close to the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper presents the results of our participation in the TREC 2022 Clinical Trials Track. Our objective was to investigate the effectiveness of our decision-theoretic model by heavily penalizing those clinical trials with which the patient has high topical similarity to their exclusion criteria. We experimented with weights that indicate how hard or soft the model should penalize those trials in two retrieval approaches, a full ranking and a re-ranking. The proposed methodology works similarly in both of them; however, its effectiveness is highly related to the selected weights. In conclusion, as the re-ranking approach yields greater performance, we aim to investigate the impact of the re-ranking depth, along with the selected weights.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,171.19,90.10,252.90,106.88"><head>Table 1 .</head><label>1</label><figDesc>Overall comparison with the TREC's median values.</figDesc><table coords="3,175.91,102.84,243.45,94.14"><row><cell></cell><cell cols="3">NDCG@10 PREC@10 Reciprocal Rank</cell></row><row><cell>TREC's Median</cell><cell>.392</cell><cell>.258</cell><cell>.411</cell></row><row><cell>IKR3 BSL</cell><cell>.415</cell><cell>.282</cell><cell>.529</cell></row><row><cell>IKR3 BSL TT HW</cell><cell>.352</cell><cell>.254</cell><cell>.506</cell></row><row><cell>IKR3 BSL TT MW</cell><cell>.405</cell><cell>.288</cell><cell>.539</cell></row><row><cell>IKR3 TT BW</cell><cell>.395</cell><cell>.286</cell><cell>.513</cell></row><row><cell>IKR3 TT MW</cell><cell>.408</cell><cell>.286</cell><cell>.535</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This work was supported by the <rs type="funder">EU Horizon 2020 ITN/ETN on Domain Specific Systems for Information Extraction and Retrieval -DoSSIER</rs> (<rs type="grantNumber">H2020-EU.1.3.1</rs>., ID: <rs type="grantNumber">860721</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ge74H3v">
					<idno type="grant-number">H2020-EU.1.3.1</idno>
				</org>
				<org type="funding" xml:id="_etyGKuz">
					<idno type="grant-number">860721</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,88.62,718.27,405.52,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,307.93,718.27,158.30,7.86">Unimib at trec 2021 clinical trials track</title>
		<author>
			<persName coords=""><forename type="first">Georgios</forename><surname>Peikos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oscar</forename><surname>Espitia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gabriella</forename><surname>Pasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,88.62,728.81,421.61,7.86;3,97.19,739.77,413.05,7.86;3,97.19,750.73,60.45,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,259.79,728.81,250.44,7.86;3,97.19,739.77,111.37,7.86">Multiple Attribute Decision Making: Methods and Applications -A State-of-the-Art Survey</title>
		<author>
			<persName coords=""><forename type="first">Ching-Lai</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kwangsun</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="3,279.18,739.77,226.74,7.86">Lecture Notes in Economics and Mathematical Systems</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<date type="published" when="1981">1981</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.62,88.88,421.62,7.86;4,97.19,99.84,188.76,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,273.17,88.88,237.07,7.86;4,97.19,99.84,33.70,7.86">Declarative experimentation ininformation retrieval using pyterrier</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,150.23,99.84,107.37,7.86">Proceedings of ICTIR 2020</title>
		<meeting>ICTIR 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.62,110.80,421.62,7.86;4,97.19,121.75,315.41,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,255.77,110.80,254.47,7.86;4,97.19,121.75,128.00,7.86">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,233.80,121.75,89.66,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
