<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,133.26,88.80,328.75,15.12">CFDA &amp; CLIP at TREC 2022 NeuCLIR Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.12,121.29,59.17,10.48"><forename type="first">Jia-Huei</forename><surname>Ju</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,199.18,121.29,78.69,10.48"><forename type="first">Wei-Chih</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.75,121.29,80.64,10.48"><forename type="first">Heng-Ta</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,382.27,121.29,76.90,10.48"><forename type="first">Cheng-Wei</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.14,135.24,80.54,10.48"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.33,135.24,83.07,10.48"><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,133.26,88.80,328.75,15.12">CFDA &amp; CLIP at TREC 2022 NeuCLIR Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">897A7B43219C6D5D0E888306E408C46D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this notebook paper, we report our methods and submitted results for the NeuCLIR track in TREC 2022. We adopt the common multi-stage pipeline for the cross-language information retrieval task (CLIR). The pipeline includes machine translation, sparse passage retrieval, and cross-language passage re-ranking. Particularly, we fine-tune cross-language passage re-rankers with different settings of query formulation. In the empirical evaluation on the HC4 dataset, our passage re-rankers achieved better passage re-ranking effectiveness compared to the baseline multilingual re-rankers. The evaluation results of our submitted runs in NeuCLIR are also reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Methods</head><p>Our multi-stage pipeline is comprised of three stages: (i) machine translation, (ii) sparse passage retrieval and (ii) cross-language passage Re-ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The Multi-stage Pipeline</head><p>Machine Translation. Before retrieval, we first translate the query q from the source language (i.e., English) to the machine-generated query ql in the target language l. We have tried different sets of machine translation methods, including mT5 <ref type="bibr" coords="1,309.47,459.48,10.52,8.74" target="#b5">[6]</ref> and NLLB <ref type="bibr" coords="1,371.94,459.48,9.96,8.74" target="#b4">[5]</ref>. <ref type="foot" coords="1,385.22,457.91,3.97,6.12" target="#foot_0">1</ref> However, we found that the officially provided translation via the Google Translation API shows the highest recall among these variants. Finally, we use the Google-translated query for passage candidate retrieval and passage re-ranking.</p><p>Sparse Retrieval. With the machine-translated queries, we can regard the CLIR task as a monolingual ad-hoc passage retrieval task. For each language l, we retrieve the top-1000 relevant documents Dl via BM25 search as Dl = ϕ BM25 (q l , Dl ), <ref type="bibr" coords="1,500.91,557.11,12.73,8.74" target="#b0">(1)</ref> where ϕ BM25 indicates the sparse passage retrieval model. Additionally, following <ref type="bibr" coords="1,438.78,575.04,9.96,8.74" target="#b3">[4]</ref>, we use sparse retrieval with pseudo relevance feedback technique; we use the query expansion approach (RM3) built in Pyserini <ref type="bibr" coords="1,155.75,598.95,10.52,8.74" target="#b2">[3]</ref> to increase the recall in this stage.</p><p>Cross-language Passage Re-ranking We further re-rank the retrieved candidate passages using cross-encoder models. Particularly, we aim to leverage the semantic meaning in the original query q as well as the translated query q l for more effective passage re-ranking, as we hypothesize that the underlying information loss in machine translation may negatively affect the effectiveness. Our passage re-rankers are fine-tuned with mT5 models <ref type="bibr" coords="1,308.06,672.67,9.96,8.74" target="#b5">[6]</ref>, and can be formulated as</p><formula xml:id="formula_0" coords="1,244.15,692.07,269.49,12.17">R = ϕ mT5 (q; q l , d l ∈ Dl ),<label>(2)</label></formula><p>where ϕ mT5 is one of our re-rankers (see details in Section 1.2). d l represents the documents retrieved from the last stage, and R is a final ranked list with re-ordered passages d l ∈ Dl .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Fine-tuning Cross-language Passage Ranking</head><p>In this section, we introduce passage re-rankers with different settings that can achieve cross-language passage ranking. Following the baseline mT5 re-ranker <ref type="bibr" coords="2,323.92,82.26,9.96,8.74" target="#b0">[1]</ref>, the text-to-text formulation is:</p><p>Query: q l Document: d l Relevant:.</p><p>where the query and document are in the same language l as described in Eq. 2. Moreover, we recast the text-to-text formulations with two different query settings:</p><p>1. Bilingual query: In addition to the monolingual query-passage pair (q l , d l ), we concatenate the original English query q in the beginning.</p><p>Query: q Query Translation: q l Document: d l Relevant:</p><p>2. Crosslingual query: This setting is similar to end-to-end CLIR objectives <ref type="bibr" coords="2,441.61,217.10,10.52,8.74" target="#b3">[4]</ref> and is formulated with query and passage in different languages.</p><p>Query: q Document: d l Relevant:.</p><p>We further use the training triplets in mMARCO <ref type="bibr" coords="2,308.01,276.59,10.52,8.74" target="#b0">[1]</ref> (i.e., the translated MSMARCO in 14 languages). The triplet data includes query and positive/negative passages; it can thereby be formulated as the yes/no tokens generation tasks <ref type="bibr" coords="2,277.62,300.50,9.96,8.74" target="#b0">[1]</ref>. All the other settings are identical to the original mT5 passage re-ranker, such as batch size, training steps, learning rate, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experiments</head><p>In the experiments, we focus on passage re-ranking and validate the effectiveness of proposed crosslanguage passage re-ranking. We report the settings with empirical results on HC4 testing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Settings</head><p>Dataset. As for training data, we use the mMARCO dataset <ref type="bibr" coords="2,351.70,425.41,10.52,8.74" target="#b0">[1]</ref> to construct the training examples.</p><p>Unlike the original mT5 re-ranking model <ref type="bibr" coords="2,265.69,437.37,10.52,8.74" target="#b0">[1]</ref> which uses 9 languages, we only use Russian, Chinese, and English as our fine-tuning triplets because we think that using fewer languages can help us analyze the experiment results more clearly. As for evaluation, we use the CLIR Common Crawl Collection (HC4) <ref type="bibr" coords="2,159.00,473.23,10.52,8.74" target="#b1">[2]</ref> as our testing data; this testing data has 50, 50, and 62 queries respectively, in Chinese, Persian, and Russian languages.</p><p>Sparse Retrieval with Machine Translation. Before using BM25 search, we use Google Translate (G-Trans) as our first-stage machine translation. <ref type="foot" coords="2,317.02,521.44,3.97,6.12" target="#foot_1">2</ref> With the original English query q and G-Trans query ql , we retrieve the top 1000 relevance passage candidates and pass them to the compared re-rankers.</p><p>Compared Re-rankers. We regard two re-ranker baselines in our experiments, including:</p><p>1. mT5-orig, the original baseline re-ranker fine-tuned on nine languages with randomly distributed monolingual triplets. We directly use the fine-tuned checkpoints in our experiments<ref type="foot" coords="2,506.40,603.00,3.97,6.12" target="#foot_2">3</ref> .</p><p>2. mT5-mono, we randomly distributed monolingual triples among three languages (English, Chinese, and Russian) since there are only two target languages (Russian and Chinese) matched in mMARCO and this track.</p><p>As mentioned in Section 1.2, we use the other two cross-language query settings to fine-tune the cross-language passage re-rankers. Particularly, for both of the settings, we randomly select Chinese or Russian as the target language l with the cross-language query q l and formulate the source input instead of a monolingual manner (see Section 1.2). The mT5 re-rankers fine-tuned with bilingual query and cross-lingual query are named mT5-bi and mT5-cl, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Re-ranking results on HC4</head><p>We report the empirical results of the re-rankers on the HC4 testing dataset in Table <ref type="table" coords="3,451.09,344.40,3.87,8.74" target="#tab_1">2</ref>, with Recall, nDCG, and MAP at different cut-offs. We separate our results into three blocks for different target languages (e.g. Persian, Russian, and Chinese). The numbers in boldface indicate the highest among our compared methods.</p><p>Zero-shot Effectiveness (Persian Query). In the first block of Table <ref type="table" coords="3,420.13,406.16,3.87,8.74" target="#tab_1">2</ref>, we can regard the Persian (fas) language settings as a zero-shot CLIR task since the Persian text is not included in our fine-tuning triples. We observe that both of our proposed cross-language passage re-rankers (mT5-bi, mT5-cl) outperform the baselines (mT5-orig and mT5-mono) at shallower depths, which implies that the cross-language query (e.g. bilingual query or crosslingual query) can potentially guide the representation of query-passage pairs in different languages.</p><p>Effectiveness of Cross-language Query. As for the cross-language effectiveness, we compare our results in the last two blocks (i.e., Russian and Chinese). For the Russian CLIR task, we observe that the bilingual query setting (mT5-bi) outperforms the other re-rankers. However, for the Chinese CLIR task, we observe only minor improvements of our proposed approaches compared to the baseline mT5-mono. We hypothesize that the inconsistent improvements between languages are derived from the inherent linguistic gap of different languages. Particularly, we find that mT5-bi performs totally opposite in Russian and Chinese (the highest in Russian, yet lowest in Chinese).</p><p>As far as our understanding, the English-Chinese gap is inherently larger than the English-Russian gap; therefore, the performance is relatively poor when we fine-tune our re-ranker with bilingual query (i.e., mT5-bi), implying the linguistic gap between the source and target language is larger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results on NeuCLIR</head><p>We also report the evaluation results of our submitted runs in NeuCLIR. Interestingly, we can observe that the bilingual query (i.e., run name with dq) is the best among all of the other settings. Although these results are not consistent with the evaluation on HC4 testing set, we can still conclude that the bilingual query setting is a promising approach for passage re-ranking. This result also shows that encoding query in multiple languages contextually as a single input can bring signals for passage re-rankers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusion</head><p>We evaluate the effectiveness of cross-language query-passage pairs and aim to explore better practices for fine-tuning text ranking models for ad-hoc cross-language information retrieval. In our empirical evaluation, we suggest that it is easier to achieve decent performance when the sourcetarget language gap is smaller in CLIR. As our future work, we will conduct a more comprehensive evaluation on different languages and different benchmark datasets to learn more about the gaps between different languages. Additionally, we will further apply our settings to the self-supervised pre-training tasks for CLIR, which we aim to explore effective multi-lingual pre-trained language models beyond those trained in a monolingual manner.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,81.64,58.83,432.00,239.93"><head>Table 1 :</head><label>1</label><figDesc>The results of passage re-ranking on HC4 testing set, including Persian, Chinese and Russian. For re-rankers other than mT5-cl, we use the human translated query for BM25 search and re-rankers.</figDesc><table coords="3,123.49,95.69,348.29,203.07"><row><cell>re-rankers</cell><cell cols="6">Size R@100 nDCG@20 mAP@20 MAP@100 MAP@1K</cell></row><row><cell cols="2">Persian (fas)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mT5-orig</cell><cell>base</cell><cell>0.7175</cell><cell>0.4726</cell><cell>0.3311</cell><cell>0.3626</cell><cell>0.3666</cell></row><row><cell cols="3">mT5-mono large 0.7602</cell><cell>0.5488</cell><cell>0.3987</cell><cell>0.4253</cell><cell>0.4285</cell></row><row><cell>mT5-bi</cell><cell cols="2">large 0.7600</cell><cell>0.5644</cell><cell>0.4123</cell><cell>0.4411</cell><cell>0.4442</cell></row><row><cell>mT5-cl</cell><cell cols="2">large 0.7648</cell><cell>0.5491</cell><cell>0.4078</cell><cell>0.4296</cell><cell>0.4330</cell></row><row><cell cols="2">Russian (rus)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mT5-orig</cell><cell>base</cell><cell>0.5923</cell><cell>0.2946</cell><cell>0.2016</cell><cell>0.2512</cell><cell>0.2599</cell></row><row><cell cols="3">mT5-mono large 0.6752</cell><cell>0.3698</cell><cell>0.2564</cell><cell>0.3168</cell><cell>0.3243</cell></row><row><cell>mT5-bi</cell><cell cols="2">large 0.6860</cell><cell>0.3822</cell><cell>0.2768</cell><cell>0.3377</cell><cell>0.3450</cell></row><row><cell>mT5-cl</cell><cell cols="2">large 0.6595</cell><cell>0.3757</cell><cell>0.2603</cell><cell>0.3172</cell><cell>0.3251</cell></row><row><cell cols="2">Chinese (zho)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mT5-orig</cell><cell>base</cell><cell>0.7374</cell><cell>0.4928</cell><cell>0.3574</cell><cell>0.3949</cell><cell>0.4004</cell></row><row><cell cols="3">mT5-mono large 0.7826</cell><cell>0.5778</cell><cell>0.4473</cell><cell>0.4817</cell><cell>0.4851</cell></row><row><cell>mT5-bi</cell><cell cols="2">large 0.7623</cell><cell>0.5743</cell><cell>0.4246</cell><cell>0.4574</cell><cell>0.4621</cell></row><row><cell>mT5-cl</cell><cell cols="2">large 0.7838</cell><cell>0.5924</cell><cell>0.4450</cell><cell>0.4794</cell><cell>0.4823</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,81.64,58.83,432.00,194.05"><head>Table 2 :</head><label>2</label><figDesc>The results of the full ranking results on NeuCLIR evaluation set. For the re-rankers involved translated query, we use the Google translated query for BM25 search and re-rankers.</figDesc><table coords="4,144.75,85.68,305.79,167.20"><row><cell>re-rankers</cell><cell cols="5">Runs nDCG@20 mAP@20 MAP@100 MAP@1K</cell></row><row><cell cols="4">Persian -run prefix: CFDP CLIP fas</cell><cell></cell><cell></cell></row><row><cell cols="2">mT5-mono (L)</cell><cell>0.4876</cell><cell>0.2644</cell><cell>0.3178</cell><cell>0.3435</cell></row><row><cell>mT5-bi</cell><cell>(dq)</cell><cell>0.5077</cell><cell>0.2797</cell><cell>0.3398</cell><cell>0.3639</cell></row><row><cell>mT5-cl</cell><cell>(clf)</cell><cell>0.4681</cell><cell>0.2480</cell><cell>0.3034</cell><cell>0.3298</cell></row><row><cell cols="4">Russian -run prefix: CFDP CLIP rus</cell><cell></cell><cell></cell></row><row><cell cols="2">mT5-mono (L)</cell><cell>0.4693</cell><cell>0.2212</cell><cell>0.3102</cell><cell>0.3486</cell></row><row><cell>mT5-bi</cell><cell>(dq)</cell><cell>0.5126</cell><cell>0.2553</cell><cell>0.3480</cell><cell>0.3862</cell></row><row><cell>mT5-cl</cell><cell>(clf)</cell><cell>0.5071</cell><cell>0.2534</cell><cell>0.3465</cell><cell>0.3829</cell></row><row><cell cols="4">Chinese -run prefix: CFDP CLIP zho</cell><cell></cell><cell></cell></row><row><cell cols="2">mT5-mono (L)</cell><cell>0.4808</cell><cell>0.2402</cell><cell>0.3157</cell><cell>0.3454</cell></row><row><cell>mT5-bi</cell><cell>(dq)</cell><cell>0.4838</cell><cell>0.2570</cell><cell>0.3293</cell><cell>0.3603</cell></row><row><cell>mT5-cl</cell><cell>(clf)</cell><cell>0.4790</cell><cell>0.2448</cell><cell>0.3187</cell><cell>0.3494</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,96.88,747.39,202.70,6.99"><p>https://github.com/facebookresearch/fairseq/tree/nllb</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,96.88,734.86,416.75,7.01;2,81.64,744.34,432.00,6.99;2,81.64,753.81,333.94,6.99"><p>Note that we use the human-translated query on HC4 evaluation; while we use the G-trans query in our submitted runs for this track. We hypothesize the human-translated query can alleviate the information loss of translation, making it easier for us to analyze the effectiveness of our proposed re-rankers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,96.88,763.89,222.17,6.64"><p>https://huggingface.co/unicamp-dl/mt5-base-mmarco-v2</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 483-498, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.41. URL https://aclanthology.org/2021. naacl-main.41.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="4,97.14,438.69,416.50,8.74;4,97.14,450.65,416.50,9.02;4,97.14,463.32,138.76,8.30" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bonifacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jeronymo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Q</forename><surname>Abonizio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Campiotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fadaee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.13897" />
		<title level="m" coord="4,140.12,450.65,280.71,8.74">A multilingual version of the ms marco passage ranking dataset</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,97.14,481.83,416.50,8.74;4,97.14,493.78,416.51,8.74;4,97.14,505.74,416.50,8.74;4,97.14,517.69,416.50,8.74;4,97.14,529.65,259.25,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,334.70,481.83,178.94,8.74;4,97.14,493.78,46.40,8.74">Hc4: A new suite of test collections for ad hoc clir</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-99736-624</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-99736-6_24" />
	</analytic>
	<monogr>
		<title level="m" coord="4,165.14,493.78,348.50,8.74;4,97.14,505.74,47.61,8.74;4,329.29,505.74,83.20,8.74">Advances in Information Retrieval: 44th European Conference on IR Research, ECIR 2022</title>
		<meeting><address><addrLine>Stavanger, Norway; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2022">April 10-14, 2022. 2022</date>
			<biblScope unit="page" from="351" to="366" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct coords="4,97.14,548.87,416.50,8.74;4,97.14,560.82,416.50,8.74;4,97.14,572.78,416.50,8.74;4,97.14,584.73,416.50,8.74;4,97.14,596.69,416.50,9.02;4,97.14,609.36,107.37,8.30" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,385.28,548.87,128.36,8.74;4,97.14,560.82,347.38,8.74">Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463238</idno>
		<ptr target="https://doi.org/10.1145/3404835.3463238" />
	</analytic>
	<monogr>
		<title level="m" coord="4,463.98,560.82,49.65,8.74;4,97.14,572.78,416.50,8.74;4,97.14,584.73,88.90,8.74">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2356" to="2362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,97.14,627.87,416.50,8.74;4,97.14,639.82,416.51,8.74;4,97.14,652.49,170.14,8.30" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,97.14,639.82,354.48,8.74">Transfer learning approaches for building cross-language dense retrieval models</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.08471" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,97.14,671.00,416.50,8.74;4,97.14,682.95,416.50,8.74;4,97.14,694.91,416.50,8.74;4,97.14,706.86,416.50,8.74;4,97.14,718.82,416.51,8.74;4,97.14,730.77,377.70,8.74" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Nllb Team</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>¸elebi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Elbayad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Youngblood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Akula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mejia-Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hansanti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sadagopan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spruit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">F</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ayan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mourachko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ropers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>No language left behind: Scaling human-centered machine translation</note>
</biblStruct>

<biblStruct coords="4,97.14,750.00,416.51,8.74;4,97.14,761.95,416.50,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,97.14,761.95,293.20,8.74">mT5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,411.74,761.95,101.90,8.74">Proceedings of the 2021</title>
		<meeting>the 2021</meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
