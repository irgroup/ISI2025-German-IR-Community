<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.24,84.23,302.03,15.44">HLTCOE at TREC 2022 NeuCLIR Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,199.02,110.40,60.51,10.59"><forename type="first">Eugene</forename><surname>Yang</surname></persName>
							<email>eugene.yang@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.85,110.40,63.31,10.59"><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
							<email>lawrie@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.33,110.40,74.65,10.59"><forename type="first">James</forename><surname>Mayfield</surname></persName>
							<email>mayfield@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.24,84.23,302.03,15.44">HLTCOE at TREC 2022 NeuCLIR Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5CED09EB3C189CBC0350E2788082EF2A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cross language information retrieval</term>
					<term>neural methods</term>
					<term>translated training data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The HLTCOE team applied ColBERT-X to the TREC 2022 NeuCLIR track with two training techniques -translate-train (TT) and multilingual translate-train (MTT). TT trains ColBERT-X with English queries and passages automatically translated into the document language from the MS-MARCO v1 collection. This results in three cross-language models for the track, one per language. MTT creates a single model for all three document languages by combining the translations of MS-MARCO passages in all three languages into mixed language batches. Thus the model learns about matching queries to passages simultaneously in all languages. While TT is more effective than MTT in each individual language due to its specificity, MTT still outperforms a strong baseline of BM25 with document translation. On average, MTT and TT perform 34% and 48% higher than the median in MAP with title queries, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>ColBERT-X <ref type="bibr" coords="1,97.03,394.64,14.60,7.94" target="#b17">[18]</ref> generalizes the state-of-the-art monolingual dense retrieval model, ColBERT <ref type="bibr" coords="1,154.81,405.60,13.49,7.94" target="#b13">[14]</ref>, to cross-language retrieval and achieves state-of-the-art effectiveness on various benchmark collections, such as HC4 <ref type="bibr" coords="1,122.05,427.52,14.59,7.94" target="#b15">[16]</ref> and CLEF <ref type="bibr" coords="1,175.60,427.52,7.11,7.94" target="#b4">[5]</ref><ref type="bibr" coords="1,182.71,427.52,3.56,7.94" target="#b5">[6]</ref><ref type="bibr" coords="1,186.27,427.52,7.11,7.94" target="#b6">[7]</ref>. The key to such successful generalization is not only replacing the underlying language model with a multilingual one but also the translate-train (TT) training procedure. In the NeuCLIR track, the HLTCOE team applied ColBERT-X with TT and performed, on average, 48% and 54% above the submission median on MAP with title and title+description queries, respectively. In terms of nDCG@20, which focuses at top of the ranking, TT outperforms the median by 20% and 35% with title and title+description queries, respectively.</p><p>With an eye toward multilingual retrieval (MLIR) in which the collection consists of documents in multiple languages, the HLT-COE team also experimented with multilingual translate-train (MTT), an extension of TT for multilingual retrieval, on the NeuCLIR CLIR tasks. Instead of training a specialized model for each querydocument language pair, MTT results in a single model capable of retrieving documents in any language it has been trained on (Chinese, Persian, and Russian, in this case). Although MTT is designed for retrieving documents from a mixed-language collection, we evaluated its CLIR capability with the NeuCLIR collection as unofficial runs.</p><p>Beyond automatic runs, we also recruited human assessors to perform manual searches in the language of the collection using BM25. The assessors developed multiple manual queries by interacting with the search engine for each topic after reading the topic's title, description, and narrative. Interactive search is as effective as searching with the official human query translation using BM25. However, we believe the manual effort provides a more diverse set of relevant documents that improve the reusability of the NeuCLIR-1 collection.</p><p>In this notebook paper, we document the model architecture and the training procedure of our automatic runs. For the manual interactive search run, we document how the interactive search was performed and how we created a track submission from each interactive multiple-query session. Note that the members of the HLTCOE team are also co-organizers of the NeuCLIR tracks. Our runs are all marked as manual for fair comparison with other teams, since it is possible that prior exposure to choices made for the track affected our system choices, which then improved our scores. That said, we froze our systems prior to the release of the NeuCLIR topics and made no changes to the systems after topic release.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">AUTOMATIC RUNS WITH COLBERT-X</head><p>This section discusses automatic CLIR runs using the official English title and perhaps description to formulate the queries. We present a more detailed description of ColBERT-X and then present the results with comparisons to our BM25 baselines that we submitted as baseline runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Design</head><p>ColBERT-X <ref type="bibr" coords="1,362.72,415.31,14.80,7.94" target="#b17">[18]</ref> generalizes the ColBERT-v1 <ref type="bibr" coords="1,484.94,415.31,14.80,7.94" target="#b13">[14]</ref> retrieval model for CLIR. This retrieval architecture consists of an encoder that embeds the documents as token representations, and a late interaction mechanism that scores each document given a query by summing over each query token the maximum similarity score with any document token. Late interaction enables the classic separation between indexing and query serving found in sparse retrieval systems such as BM25, since it allows document representations to be generated offline.</p><p>The ColBERT-X model exploits the late-interaction architecture and instantiates the cross-language ability by using a multilingual pretrained language model, and training with the translate-train (TT) <ref type="bibr" coords="1,335.46,546.81,14.59,7.94" target="#b18">[19]</ref> technique. Translate-train uses existing monolingual training resources, such as MS-MARCO <ref type="bibr" coords="1,447.48,557.77,9.36,7.94" target="#b2">[3]</ref>, by translating the training documents to match the desired query/document language pair. The model learns retrieval from the translated training collection, providing state-of-the-art effectiveness in CLIR benchmarks.</p><p>While TT is effective in CLIR, it requires a document collection in a single language. With an eye toward multilingual retrieval (MLIR), we would like the model to be capable of retrieving documents in a set of languages. The HLTCOE team evaluated a ColBERT-X MLIR model trained with multilingual translate-train (MTT) in the NeuCLIR tasks as an unofficial run. MTT <ref type="bibr" coords="2,222.14,361.60,14.82,7.94" target="#b16">[17]</ref> generalizes TT by translating the documents into each target language to equip the model with the ability to retrieve content expressed in these languages.</p><p>Unlike training one ColBERT-X CLIR model with TT for each language pair (resulting in three models), we apply the same ColBERT-X MLIR model trained with MTT to all three language pairs simultaneously. This produces a single model capable of participation in each of the NeuCLIR tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">System Pipeline</head><p>Both TT and MTT models are trained with translations of MS-MARCO, produced in-house by the HLTCOE. Our translation model is built on top of a transformer base architecture (six-layer encoder/decoder) using Sockeye <ref type="bibr" coords="2,160.70,548.07,13.22,7.94" target="#b10">[11]</ref>. We split the original MS-MARCO passages using ersatz <ref type="bibr" coords="2,131.31,559.03,14.60,7.94" target="#b20">[21]</ref> to produce sentences. We then translated the passages into target languages sentence by sentence.</p><p>The ColBERT-X models use XLM-RoBERTa Large <ref type="bibr" coords="2,257.16,580.94,10.68,7.94" target="#b7">[8]</ref> for its effectiveness in IR and multilingual tasks <ref type="bibr" coords="2,202.04,591.90,13.40,7.94" target="#b17">[18,</ref><ref type="bibr" coords="2,217.49,591.90,10.05,7.94" target="#b21">22]</ref>. The models were fine-tuned on MSMARCO with translated passages for 200,000 steps with a batch of 64 using four NVIDIA V100 GPUs and a learning rate of 5 × 10 -6 .</p><p>Table <ref type="table" coords="2,85.46,635.74,4.10,7.94" target="#tab_0">1</ref> summarizes the statistics of the indexes. The documents in the NeuCLIR collection were tokenized by the XLM-RoBERTa tokenizer and separated into overlapping passages of length 180 tokens with a stride of 90. Indexing uses four GPUs in parallel. The ColBERT-X models retrieve passages, not full documents; the document score is the maximum score of its component passages <ref type="bibr" coords="2,285.80,690.53,9.23,7.94" target="#b3">[4,</ref><ref type="bibr" coords="2,53.59,701.49,10.13,7.94" target="#b9">10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results</head><p>Table <ref type="table" coords="2,338.96,298.59,4.09,7.94" target="#tab_1">2</ref> presents the aggregated results of the ColBERT-X automatic runs. For both title (T) and title concatenated with description (T+D) as queries, end-to-end ColBERT-X trained with TT provides better effectiveness at the top of the ranking than MTT and BM25 in all three languages as shown by nDCG@20. Interestingly, BM25 with query translation is above the median in Chinese and Persian when using title queries. However, adding the description to the title has mixed results for BM25, which is contrary to what is seen in many collections. This may be due to BM25 failing to utilize the additional information in the description, likely due to query drift from the stop structure in the descriptions. This is also the case for ColBERT-X with MTT but not TT. TT with T+D queries provides even stronger effectiveness compared to its title query variant.</p><p>Since both TT and MTT use machine translated MS MARCO during training, differences in translation quality appear to have a significant impact on model effectiveness <ref type="bibr" coords="2,477.09,462.97,13.34,7.94" target="#b17">[18]</ref>. Among the three NeuCLIR languages, the quality of translated MS MARCO is worse for Persian, for which the MT model was trained on at most 2/3 of the parallel text of the other models and yields a BLEU score of 20.2 compared to 35.9 and 38.6 for Chinese and Russian, respectively.</p><p>ColBERT-X models have lower recall than our statistical model using BM25, especially for title queries. These discrepancies indicate room for improvement on the first phase FAISS <ref type="bibr" coords="2,513.98,539.68,14.85,7.94" target="#b11">[12]</ref> nearest neighbor retrieval in ColBERT-X. Simply retrieving documents that contain tokens similar to the query tokens might not be sufficient for retrieving a wide range of relevant documents, resulting in worse recall at 1000 than BM25.</p><p>The MLIR variant of ColBERT-X that was trained with MTT performs slightly worse than its TT counterpart. However, it is still more effective than half of the track submissions when evaluated using nDCG@20 or MAP. Note that the median scores presented in Table <ref type="table" coords="2,339.03,638.31,4.09,7.94" target="#tab_1">2</ref> average the median score for each topic, which is a different and potentially a much higher baseline than the median system score, which is an average of that system over all topics.</p><p>Although TT and MTT seem equally good at ranking given that their scores on precision-oriented metrics are similar, TT produces higher Recall@1000. Thus the approximate nearest neighbor search used for the first retrieval stage appears to be working better using the TT model than it does using the MTT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MANUAL MONOLINGUAL RUNS WITH HUMAN QUERIES</head><p>We had access to two sources of human-generated queries. The first source was the human translations of the title and description that were provided to all NeuCLIR participants. We ran these as queries against a BM25 retrieval model using the Patapsco framework <ref type="bibr" coords="3,282.91,465.97,9.39,7.94" target="#b8">[9]</ref>. The second source was bilingual speakers that used the English title, description, and narrative to write their own queries in the document language to find relevant documents using interactive search. This section describes this second source in more detail and then presents the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Interactive Runs</head><p>It has been shown during the development of prior TREC collections, e.g., TREC Robust, that manual runs where a person issues queries to find relevant documents not discovered by automatic runs helps to make collections more robust <ref type="bibr" coords="3,216.63,591.90,13.61,7.94" target="#b12">[13,</ref><ref type="bibr" coords="3,232.48,591.90,10.21,7.94" target="#b19">20]</ref>. This may be in part because automatic runs are limited in their expression of the query to variants of the title and description. As Alaofi et al. <ref type="bibr" coords="3,283.62,613.82,10.43,7.94" target="#b1">[2]</ref> discuss, query variance can be larger than system variance. To perform manual runs in NeuCLIR, one needs access to people with the necessary language skills. We used an assessor pool of bilingual speakers. A majority of these assessors were native English speakers, although a few were native speakers of the language of the documents. While some were proficient in more than two languages, no one was proficient in more than one of Chinese, Persian and Russian.</p><p>Using a Mechanical Turk-style platform, Turkle<ref type="foot" coords="3,497.95,368.78,3.38,6.44" target="#foot_0">1</ref> , assessors were shown the topic title, description, and narrative. For search the interface provided a monolingual BM25 search engine using the Patapsco framework. Assessors created queries for the search engine and then viewed and judged documents using the interface shown in Figure <ref type="figure" coords="3,379.70,425.72,3.08,7.94" target="#fig_0">1</ref>. The left panel allows assessors to select any of the top 100 documents. Labels associated with their judgments are added. This helps assessors to quickly see whether the same judged documents are being returned from different query variants.</p><p>HiCAL <ref type="bibr" coords="3,355.54,469.56,10.47,7.94" target="#b0">[1]</ref> is an active learning system that helps an interactive user identify relevant documents. Once assessors identified at least one relevant document, they could optionally use HiCAL to recommend additional documents to judge by switching to the "JUDGE" tab in the interface shown in Figure <ref type="figure" coords="3,449.69,513.39,3.03,7.94" target="#fig_1">2</ref>. The "next" button was used to ask for more documents from HiCAL. The Turkle platform captured the queries issued to the search engine as well as translations provided by the assessors, the top 1000 document returned by each search, relevance judgements, and whether each document was identified by interactive search or HiCAL. Assessors were given the same graded relevance scale and instructions as NIST assessors for judging documents.</p><p>From these assessments, we assembled a single baseline run for each annotated topic. Each run had as its top-rated documents those judged very valuable by the assessor; these documents were given a score of 2000. They were followed by documents judged as somewhat valuable, which were given a score of 1500. The remainder of the required 1000 documents were selected round-robin over the documents for the issued queries that were not examined by the assessor. The order of the queries for the round-robin assembly  The top document from this process received a score of 1000 and each subsequent document received a score of one less than its predecessor. No duplicates were allowed. An additional baseline run was constructed using the query translations. Each English version of the query was issued to ColBERT-X.</p><p>Although not necessary, we only ran queries issued by an annotator for a particular language against the corresponding document collection; queries created by the Chinese assessor were used for the Chinese collection and so on. Because we were using a languageagnostic CLIR system, all queries for a topic no matter the language of the assessor could have been used in this baseline run. A single manual run was submitted by using a round-robin assembly of results from multiple queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Table <ref type="table" coords="4,74.79,690.53,4.09,7.94" target="#tab_2">3</ref> shows the results of our monolingual runs. For official translations, the title queries were more effective than title+description queries, although title+description queries led to the highest recall at 1000. This is likely an indication that the stop structure in the descriptions depressed performance, and the descriptions rarely added helpful vocabulary to the queries.</p><p>The assessors' interactive searches were more effective than the description queries, but only in Persian were they more effective than the title queries. Part of this lack of effectiveness came from disagreement about relevance between the interactive searchers and NIST assessors. There was more agreement between Chinese assessors (65%) than between Persian (45%) and Russian (52%) assessors, which is also in alignment with the inner-annotator assessment performed by NIST <ref type="bibr" coords="4,390.58,617.61,13.33,7.94" target="#b14">[15]</ref>. Including documents that were retrieved during the interactive search but not viewed by the assessor had a small impact; of such documents, only 14% of Chinese, 14% of Persian, and 18% of Russian documents were judged relevant.</p><p>While interactive search demonstrated effectiveness competitive with automatic runs, the interactive search queries created for BM25 and run with ColBERT-X TT models were not as effective. One cause may have been that keyword-style queries were not encoded as effectively by ColBERT-X. The importance of longer queries for ColBERT-X can be observed in Table <ref type="table" coords="5,202.70,98.75,4.15,7.94" target="#tab_1">2</ref> where title+description queries generally perform better than title queries. Another hypothesis is that the round-robin assembly of multiple queries into a single run could have prevented documents for better expressions of the topic from being judged. More analysis is needed to understand these effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>The HLTCOE team participated in both automatic and manual runs (officially all of our runs are manual). The ColBERT-X models outperform the BM25 baselines by a large margin. Although the manual runs performed only on par with title queries, we believe that it is due to the disagreement on document relevance between our searchers and NIST's assessors, which of course is expect since relevance is an opinion, not a fact. There are several directions of future research including more investigation into the query variants provided by interactive search as well as better understanding of first stage retrieval by ColBERT-X MTT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,187.41,342.96,237.18,7.70;3,126.00,83.68,360.01,245.28"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Interface used by assessors for interactive search.</figDesc><graphic coords="3,126.00,83.68,360.01,245.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,209.24,342.96,193.51,7.70;4,126.00,83.68,360.01,245.28"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Interface used by assessors for HiCAL.</figDesc><graphic coords="4,126.00,83.68,360.01,245.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,317.66,599.72,242.14,104.15"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table coords="1,317.96,599.72,241.85,104.15"><row><cell cols="4">ColBERT-X Index Statistics. The index sizes are iden-</cell></row><row><cell cols="4">tical between ColBERT-X trained with TT and MTT because</cell></row><row><cell>of the identical indexing setting.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Chinese Persian Russian</cell></row><row><cell># Passages (Millions)</cell><cell>19.8</cell><cell>14.0</cell><cell>25.1</cell></row><row><cell>Index Size (TB)</cell><cell>0.9</cell><cell>0.6</cell><cell>1.1</cell></row><row><cell>TT Indexing Time (Hours)</cell><cell>9.13</cell><cell>6.48</cell><cell>10.04</cell></row><row><cell>MTT Indexing Time (Hours)</cell><cell>7.81</cell><cell>6.34</cell><cell>12.18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,53.50,85.73,504.70,176.63"><head>Table 2 :</head><label>2</label><figDesc>Effectiveness Summary of ColBERT-X Automatic Runs. The highest scores using the same query type are bold. MTT is marked with * since they are unofficial runs.</figDesc><table coords="2,62.39,122.62,487.22,139.74"><row><cell cols="2">Query System Type</cell><cell>Query Lang.</cell><cell cols="10">Doc Lang. nDCG@20 MAP R@1000 nDCG@20 MAP R@1000 nDCG@20 MAP R@1000 Chinese Persian Russian</cell></row><row><cell cols="4">Mean of Submission Medians</cell><cell>0.281</cell><cell>0.185</cell><cell>0.727</cell><cell>0.320</cell><cell>0.198</cell><cell>0.820</cell><cell>0.373</cell><cell>0.258</cell><cell>0.759</cell></row><row><cell></cell><cell>BM25</cell><cell>MT Native</cell><cell>Native MT</cell><cell>0.328 0.356</cell><cell>0.261 0.281</cell><cell>0.781 0.805</cell><cell>0.334 0.341</cell><cell>0.221 0.232</cell><cell>0.786 0.797</cell><cell>0.365 0.327</cell><cell>0.287 0.238</cell><cell>0.757 0.771</cell></row><row><cell>T</cell><cell cols="3">MTT* Native Native</cell><cell>0.388</cell><cell>0.289</cell><cell>0.725</cell><cell>0.372</cell><cell>0.269</cell><cell>0.736</cell><cell>0.412</cell><cell>0.292</cell><cell>0.735</cell></row><row><cell></cell><cell>TT</cell><cell cols="2">Native Native</cell><cell>0.439</cell><cell>0.332</cell><cell>0.781</cell><cell>0.395</cell><cell>0.273</cell><cell>0.773</cell><cell>0.456</cell><cell>0.335</cell><cell>0.771</cell></row><row><cell></cell><cell>BM25</cell><cell>MT Native</cell><cell>Native MT</cell><cell>0.331 0.340</cell><cell>0.258 0.264</cell><cell>0.768 0.781</cell><cell>0.326 0.355</cell><cell>0.234 0.253</cell><cell>0.785 0.829</cell><cell>0.360 0.292</cell><cell>0.281 0.216</cell><cell>0.770 0.774</cell></row><row><cell>T+D</cell><cell cols="3">MTT* Native Native</cell><cell>0.379</cell><cell>0.282</cell><cell>0.755</cell><cell>0.403</cell><cell>0.285</cell><cell>0.772</cell><cell>0.402</cell><cell>0.277</cell><cell>0.744</cell></row><row><cell></cell><cell>TT</cell><cell cols="2">Native Native</cell><cell>0.446</cell><cell>0.350</cell><cell>0.811</cell><cell>0.404</cell><cell>0.291</cell><cell>0.808</cell><cell>0.451</cell><cell>0.328</cell><cell>0.784</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,53.47,365.87,501.32,150.10"><head>Table 3 :</head><label>3</label><figDesc>Effectiveness Summary of Monolingual Baselines and Manual Runs.</figDesc><table coords="4,53.47,391.81,501.32,124.16"><row><cell>System</cell><cell>Query</cell><cell cols="2">Chinese nDCG@20 AP</cell><cell cols="2">R@1000 nDCG@20</cell><cell>Persian AP</cell><cell cols="2">R@1000 nDCG@20</cell><cell>Russian AP</cell><cell>R@1000</cell></row><row><cell>BM25</cell><cell>Title</cell><cell>0.416</cell><cell>0.320</cell><cell>0.778</cell><cell>0.326</cell><cell>0.222</cell><cell>0.788</cell><cell>0.363</cell><cell>0.288</cell><cell>0.759</cell></row><row><cell>with official</cell><cell>Description</cell><cell>0.332</cell><cell>0.266</cell><cell>0.735</cell><cell>0.281</cell><cell>0.197</cell><cell>0.742</cell><cell>0.273</cell><cell>0.196</cell><cell>0.701</cell></row><row><cell cols="2">human translation Title+Description</cell><cell>0.368</cell><cell>0.296</cell><cell>0.794</cell><cell>0.309</cell><cell>0.212</cell><cell>0.773</cell><cell>0.363</cell><cell>0.279</cell><cell>0.766</cell></row><row><cell>BM25</cell><cell>Manual Queries</cell><cell>0.398</cell><cell>0.273</cell><cell>0.687</cell><cell>0.337</cell><cell>0.231</cell><cell>0.795</cell><cell>0.347</cell><cell>0.254</cell><cell>0.680</cell></row><row><cell>ColBERT-X(TT)</cell><cell>Manual Queries</cell><cell>0.036</cell><cell>0.025</cell><cell>0.571</cell><cell>0.032</cell><cell>0.022</cell><cell>0.705</cell><cell>0.049</cell><cell>0.036</cell><cell>0.663</cell></row><row><cell cols="5">was determined by the number of documents the assessor said</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">were very valuable or somewhat valuable in the retrieval results.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,320.88,702.79,91.52,6.18"><p>https://github.com/hltcoe/turkle</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,70.23,320.23,224.04,6.18;5,70.23,328.20,223.81,6.18;5,70.23,336.12,224.51,6.23;5,70.23,344.09,135.11,6.23" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,192.57,328.20,101.48,6.18;5,70.23,336.17,23.81,6.18">A System for Efficient High-Recall Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Mustafa</forename><surname>Abualsaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nimesh</forename><surname>Ghelani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maura</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,105.82,336.12,188.92,6.23;5,70.23,344.09,81.22,6.23">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1317" to="1320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,352.11,224.58,6.18;5,70.23,360.08,223.81,6.18;5,70.23,368.00,223.81,6.23;5,70.23,375.97,223.81,6.23;5,69.48,383.94,225.63,6.23;5,70.23,391.96,113.14,6.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,239.00,360.08,55.04,6.18;5,70.23,368.05,35.69,6.18">Where Do Queries Come From?</title>
		<author>
			<persName coords=""><forename type="first">Marwah</forename><surname>Alaofi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dana</forename><surname>Mckay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lauren</forename><forename type="middle">L</forename><surname>Saling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Falk</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Damiano</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<idno type="DOI">10.1145/3477495.3531711</idno>
		<ptr target="https://doi.org/10.1145/3477495.3531711" />
	</analytic>
	<monogr>
		<title level="m" coord="5,119.93,368.00,174.11,6.23;5,70.23,375.97,155.94,6.23;5,278.99,375.97,15.05,6.23;5,69.48,383.94,9.61,6.23">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Madrid, Spain; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2850" to="2862" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;22)</note>
</biblStruct>

<biblStruct coords="5,70.23,399.93,223.81,6.18;5,70.23,407.90,224.89,6.18;5,70.23,415.87,224.89,6.18;5,70.23,423.79,108.23,6.23" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<title level="m" coord="5,87.39,415.87,205.00,6.18">Ms marco: A human generated machine reading comprehension dataset</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,70.23,431.81,223.81,6.18;5,70.23,439.73,224.89,6.23;5,70.23,447.75,52.14,6.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,199.06,431.81,94.98,6.18;5,70.23,439.78,84.58,6.18">Utilizing passage-based language models for document retrieval</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,166.64,439.73,125.89,6.23">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="162" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,455.67,223.81,6.23;5,70.23,463.64,209.97,6.23" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,141.02,455.72,94.05,6.18">CLEF 2001-Overview of Results</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,247.86,455.67,46.18,6.23;5,70.23,463.64,162.70,6.23">Workshop of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="9" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,471.61,223.81,6.23;5,70.23,479.58,209.97,6.23" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,141.73,471.66,93.05,6.18">CLEF 2002-Overview of results</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,247.61,471.61,46.43,6.23;5,70.23,479.58,162.70,6.23">Workshop of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="9" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,487.55,223.81,6.23;5,70.23,495.52,205.31,6.23" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,142.35,487.60,91.99,6.18">CLEF 2003-Overview of results</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,247.40,487.55,46.65,6.23;5,70.23,495.52,154.97,6.23">Workshop of the cross-language evaluation forum for european languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="44" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,503.54,224.99,6.18;5,70.23,511.51,224.58,6.18;5,70.23,519.48,223.81,6.18;5,70.23,527.40,133.13,6.23" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,150.12,519.48,143.92,6.18;5,70.23,527.45,19.90,6.18">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,70.23,535.42,224.64,6.18;5,69.99,543.39,225.13,6.18;5,70.23,551.31,224.58,6.23;5,70.23,559.28,224.89,6.23;5,70.23,567.30,129.66,6.18" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,265.45,535.42,29.42,6.18;5,69.99,543.39,221.96,6.18">Patapasco: A Python Framework for Cross-Language Information Retrieval Experiments</title>
		<author>
			<persName coords=""><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-99739-7_33</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-99739-7_33" />
	</analytic>
	<monogr>
		<title level="m" coord="5,77.94,551.31,216.87,6.23;5,70.23,559.28,28.60,6.23">Advances in Information Retrieval: 44th European Conference on IR Research, ECIR 2022</title>
		<meeting><address><addrLine>Stavanger, Norway; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="276" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,575.27,223.81,6.18;5,70.23,583.19,223.81,6.23;5,70.23,591.16,224.89,6.23;5,70.23,599.18,24.81,6.18" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,180.81,575.27,113.24,6.18;5,70.23,583.24,106.47,6.18">Deeper text understanding for IR with contextual neural language modeling</title>
		<author>
			<persName coords=""><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,189.52,583.19,104.52,6.23;5,70.23,591.16,222.23,6.23">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="985" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,607.15,223.81,6.18;5,70.23,615.12,223.81,6.18;5,69.99,623.04,224.06,6.23;5,70.23,631.01,223.81,6.23;5,70.02,639.03,130.88,6.18" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,140.71,615.12,153.34,6.18;5,69.99,623.09,32.43,6.18">The Sockeye 2 Neural Machine Translation Toolkit at AMTA 2020</title>
		<author>
			<persName coords=""><forename type="first">Tobias</forename><surname>Domhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Felix</forename><surname>Hieber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,114.59,623.04,179.45,6.23;5,70.23,631.01,75.93,6.23;5,225.04,631.06,69.01,6.18;5,70.02,639.03,101.63,6.18">Proceedings of the 14th Conference of the Association for Machine Translation in the Americas</title>
		<meeting>the 14th Conference of the Association for Machine Translation in the Americas</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="110" to="115" />
		</imprint>
		<respStmt>
			<orgName>Research Track</orgName>
		</respStmt>
	</monogr>
	<note>Association for Machine Translation in the Americas, Virtual</note>
</biblStruct>

<biblStruct coords="5,70.23,647.00,224.00,6.18;5,70.23,654.92,197.95,6.23" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,228.56,647.00,65.67,6.18;5,70.23,654.97,49.05,6.18">Billion-scale similarity search with GPUs</title>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,125.34,654.92,84.33,6.23">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,662.94,224.58,6.18;5,70.23,670.91,224.89,6.18;5,70.23,678.83,223.81,6.23;5,70.23,686.80,79.16,6.23" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,151.87,670.91,139.94,6.18">Overview of IR tasks at the first NTCIR workshop</title>
		<author>
			<persName coords=""><forename type="first">Noriko</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kazuko</forename><surname>Kuriyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Toshihiko</forename><surname>Nozue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Koji</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hiroyuki</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Souichiro</forename><surname>Hidaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,77.87,678.83,216.17,6.23;5,70.23,686.80,56.40,6.23">Proceedings of the first NTCIR workshop on research in Japanese text retrieval and term recognition</title>
		<meeting>the first NTCIR workshop on research in Japanese text retrieval and term recognition</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="11" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.23,694.82,223.81,6.18;5,70.23,702.74,223.81,6.23;5,334.39,89.05,223.81,6.23;5,334.39,97.02,46.11,6.23" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="5,181.88,694.82,112.16,6.18;5,70.23,702.79,147.41,6.18">ColBERT: Efficient and effective passage search via contextualized late interaction over BERT</title>
		<author>
			<persName coords=""><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,230.55,702.74,63.50,6.23;5,334.39,89.05,223.81,6.23;5,334.39,97.02,23.44,6.23">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,105.04,224.89,6.18;5,334.39,113.01,223.81,6.18;5,334.18,120.93,141.37,6.23" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="5,456.05,113.01,102.15,6.18;5,334.18,120.98,14.91,6.18">Overview of the TREC 2022 NeuCLIR Track</title>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglasw</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,361.41,120.93,93.91,6.23">The 31st Text REtrieval Conference</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,128.95,224.63,6.18;5,334.14,136.87,224.06,6.23;5,334.39,144.84,174.27,6.23" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="5,544.51,128.95,14.51,6.18;5,334.14,136.92,141.47,6.18">HC4: A New Suite of Test Collections for Ad Hoc CLIR</title>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
		<idno>ECIR 2022</idno>
	</analytic>
	<monogr>
		<title level="m" coord="5,488.47,136.87,69.73,6.23;5,334.39,144.84,140.24,6.23">Advances in Information Retrieval: 44th European Conference on IR Research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,152.86,223.81,6.18;5,334.14,160.78,224.06,6.23;5,334.39,168.75,174.27,6.23" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="5,539.27,152.86,18.93,6.18;5,334.14,160.83,142.54,6.18">Neural Approaches to Multilingual Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<idno>ECIR 2023</idno>
	</analytic>
	<monogr>
		<title level="m" coord="5,488.85,160.78,69.36,6.23;5,334.39,168.75,140.24,6.23">Advances in Information Retrieval: 45th European Conference on IR Research</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,176.77,224.99,6.18;5,334.39,184.74,223.81,6.18;5,334.39,192.66,223.81,6.23;5,334.39,200.63,222.24,6.23" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="5,474.22,184.74,83.98,6.18;5,334.39,192.71,142.71,6.18">Transfer learning approaches for building cross-language dense retrieval models</title>
		<author>
			<persName coords=""><forename type="first">Suraj</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,489.60,192.66,68.60,6.23;5,334.39,200.63,166.98,6.23">Advances in Information Retrieval: 44th European Conference on IR Research, ECIR 2022</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="382" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,208.65,224.89,6.18;5,334.39,216.57,108.33,6.23" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="5,397.79,208.65,158.89,6.18">Cross-lingual relevance transfer for document retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02989</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,334.39,224.59,224.99,6.18;5,334.39,232.51,223.81,6.23;5,334.39,240.48,66.99,6.23" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11086</idno>
		<title level="m" coord="5,500.19,224.59,59.19,6.18;5,334.39,232.51,223.81,6.23">Can Old TREC Collections Reliably Evaluate Modern Neural Retrieval Models? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,248.50,223.81,6.18;5,334.39,256.42,223.82,6.23;5,334.39,264.39,223.81,6.23;5,334.39,272.36,223.81,6.23;5,334.39,280.38,142.45,6.18" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="5,432.12,248.50,126.08,6.18;5,334.39,256.47,104.22,6.18">A unified approach to sentence segmentation of punctuated text in many languages</title>
		<author>
			<persName coords=""><forename type="first">Rachel</forename><surname>Wicks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,450.78,256.42,107.42,6.23;5,334.39,264.39,223.81,6.23;5,334.39,272.36,120.02,6.23">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3995" to="4007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.39,288.35,223.81,6.18;5,334.39,296.32,224.00,6.18;5,334.39,304.24,223.81,6.23;5,334.39,312.21,223.81,6.23;5,334.39,320.18,224.89,6.23;5,334.39,328.20,113.14,6.18" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="5,409.40,296.32,148.98,6.18;5,334.39,304.29,145.43,6.18">C3: Continued Pretraining with Contrastive Weak Supervision for Cross Language Ad-Hoc Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suraj</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ramraj</forename><surname>Chandradevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rebecca</forename><surname>Iglesias-Flores</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<idno type="DOI">10.1145/3477495.3531886</idno>
		<ptr target="https://doi.org/10.1145/3477495.3531886" />
	</analytic>
	<monogr>
		<title level="m" coord="5,492.73,304.24,65.48,6.23;5,334.39,312.21,223.81,6.23;5,334.39,320.18,25.00,6.23">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<title level="s" coord="5,412.93,320.18,24.68,6.23">SIGIR &apos;22</title>
		<meeting>the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Madrid, Spain; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2507" to="2512" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
