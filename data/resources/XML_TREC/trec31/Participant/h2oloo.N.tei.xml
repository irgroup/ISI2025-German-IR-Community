<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,64.80,84.23,482.41,15.44;1,150.05,104.15,311.91,15.44">Simple Yet Effective Neural Ranking and Reranking Baselines for Cross-Lingual Information Retrieval</title>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-04-03">3 Apr 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,116.68,136.69,51.16,5.45"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.02,136.69,116.96,5.45"><forename type="first">David</forename><surname>Alfonso-Hermelo</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">UNICAMP</orgName>
								<address>
									<country>Canada Vitor Jeronymo, Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,102.38,171.11,78.94,5.45"><forename type="first">Ehsan</forename><surname>Kamalloo</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.01,171.11,77.97,5.45"><forename type="first">Carlos</forename><surname>Lassance</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Naver Labs Europe</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,426.62,171.11,87.06,5.45;1,434.16,183.97,40.08,4.54"><roleName>UNICAMP</roleName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,482.46,183.97,23.67,4.54;1,92.49,205.58,44.82,5.45"><forename type="first">Odunayo</forename><surname>Brazil</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,140.30,205.58,50.91,5.45"><surname>Ogundepo</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.92,205.58,110.17,5.45"><forename type="first">Mehdi</forename><surname>Rezagholizadeh</surname></persName>
							<affiliation key="aff5">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,431.65,205.58,77.23,5.45"><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,180.63,240.00,86.40,5.45"><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.54,240.00,64.68,5.45"><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff8">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,64.80,84.23,482.41,15.44;1,150.05,104.15,311.91,15.44">Simple Yet Effective Neural Ranking and Reranking Baselines for Cross-Lingual Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-03">3 Apr 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">B7F43D92C66DDD6945B0A6085D8E14AA</idno>
					<idno type="arXiv">arXiv:2304.01019v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The advent of multilingual language models has generated a resurgence of interest in cross-lingual information retrieval (CLIR), which is the task of searching documents in one language with queries from another. However, the rapid pace of progress has led to a confusing panoply of methods and reproducibility has lagged behind the state of the art. In this context, our work makes two important contributions: First, we provide a conceptual framework for organizing different approaches to cross-lingual retrieval using multi-stage architectures for mono-lingual retrieval as a scaffold. Second, we implement simple yet effective reproducible baselines in the Anserini and Pyserini IR toolkits for test collections from the TREC 2022 NeuCLIR Track, in Persian, Russian, and Chinese. Our efforts are built on a collaboration of the two teams that submitted the most effective runs to the TREC evaluation. These contributions provide a firm foundation for future advances.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Cross-lingual information retrieval (CLIR) is the task of searching documents in one language with queries from a different languagefor example, retrieving Russian documents using English queries. Typically, a CLIR system exists as part of an overall pipeline involving machine translation, related human language technologies, and sometimes human experts, that together help users satisfy information needs with content in languages they may not be able to read. Research on cross-lingual information retrieval dates back many decades <ref type="bibr" coords="1,108.54,570.69,13.60,4.09" target="#b10">[11,</ref><ref type="bibr" coords="1,124.39,570.69,10.35,4.09" target="#b15">16,</ref><ref type="bibr" coords="1,137.00,570.69,10.35,4.09" target="#b30">31,</ref><ref type="bibr" coords="1,149.60,570.69,10.20,4.09" target="#b42">43]</ref>, but there has been a recent revival of interest in this challenge <ref type="bibr" coords="1,154.34,581.65,13.42,4.09" target="#b12">[13,</ref><ref type="bibr" coords="1,170.02,581.65,10.07,4.09" target="#b48">49]</ref>, primarily due to the advent of multilingual pretrained transformer models such as mBERT <ref type="bibr" coords="1,279.19,592.61,14.85,4.09" target="#b9">[10]</ref> and XLM-R <ref type="bibr" coords="1,98.24,603.57,9.39,4.09" target="#b5">[6]</ref>.</p><p>A nexus of recent research activity for cross-lingual information retrieval is the TREC NeuCLIR Track, which ran for the first time at TREC 2022 but has plans for continuing in 2023 and perhaps beyond. The track provides a forum for a community-wide evaluation of CLIR systems in the context of modern collections and systems, dominated today by neural methods. NeuCLIR topics (i.e., information needs) are expressed in English, and systems are tasked with retrieving relevant documents from corpora in Chinese, Persian, and Russian.</p><p>Perhaps as a side effect of the breakneck pace at which the field is advancing, we feel that there remains a lack of clarity in the IR community about the relationship between different retrieval methods (e.g., dense vs. sparse representations, "learned" vs. "heuristic" vs. "unsupervised", etc.) and how they should be applied in different retrieval settings. Furthermore, the increasing sophistication of today's retrieval models and the growing complexity of modern software stacks create serious challenges for reproducibility efforts. This not only makes it difficult for researchers and practitioners to compare alternative approaches in a fair manner, but also creates barriers to entry for newcomers. These issues already exist for mono-lingual retrieval, where documents and queries are in the same language. With the added complexity of cross-lingual demands, the design choices multiply (choice of models, training regimes, application of translation systems, etc.), further muddling conceptual clarity and experimental reproducibility.</p><p>Contributions. Our work tackles these challenges, specifically focused on helping both researchers and practitioners sort through the panoply of CLIR methods in the context of modern neural retrieval techniques dominated by deep learning. Our contributions can be divided into a "conceptual" and a "practical" component:</p><p>Conceptually, we provide a framework for organizing different approaches to cross-lingual retrieval based on the general design of multi-stage ranking for mono-lingual retrieval. These architectures comprise first-stage retrievers that directly perform top-𝑘 retrieval over an arbitrarily large collection of documents, followed by one or more reranking stages that refine the rank order of candidates generated by the first stage.</p><p>Recently, Lin <ref type="bibr" coords="1,376.06,590.98,14.59,4.09" target="#b22">[23]</ref> proposed that retrieval techniques can be characterized by the representations that they manipulate-whether dense semantic vectors or sparse lexical vectors-and how the weights are assigned-whether heuristically, as in the case of BM25, or by a neural network that has been trained with labeled data. Translated into the cross-lingual case, this leads naturally to three main approaches to first-stage retrieval: document translation, query translation, and use of language-independent representations. While these approaches date back many decades, there are "modern twists" based on learned representations that take advantage of powerful pretrained transformer models. For mono-lingual retrieval, a standard multi-stage architecture applies rerankers to the output of first-stage retrievers, like those discussed above. In a cross-lingual context, we describe how crosslingual rerankers can be designed and built using existing multilingual models. Results fusion forms the final component of our conceptual framework. Within a multi-stage architecture, there arises a natural question of when fusion should be performed: this manifests in the early vs. late fusion techniques that we examine.</p><p>Practically, we provide a number of reproducible baselines in the context of the above conceptual framework for the TREC 2022 NeuCLIR test collection, including variants of the highest-scoring runs that were submitted to the evaluation. These reproducible baselines have been incorporated into the Anserini and Pyserini IR toolkits. Our efforts are built on a collaboration of the two teams that submitted the most effective runs to the TREC evaluation.</p><p>We hope that this work provides a solid foundation for future work, both in terms of offering a conceptual framework and reference implementations that the community can further build on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MONO-LINGUAL RETRIEVAL OVERVIEW</head><p>Since mono-lingual retrieval architectures provide the starting point for cross-lingual retrieval, it makes sense to begin with an overview of modern mono-lingual methods. Here, we adopt the standard formulation of the (mono-lingual) retrieval task (also called ad hoc retrieval). From a finite but arbitrarily large collection of documents C = {𝑑 1 , 𝑑 2 . . . , 𝑑 𝑛 }, the system's task, given query 𝑞, is to return a top-𝑘 ranking of documents that maximizes some metric of quality such as nDCG or average precision.</p><p>Rerankers. The earliest applications of neural networks to tackle ad hoc retrieval in a data-driven manner date back to the mid 2000s in the context of learning to rank <ref type="bibr" coords="2,209.36,680.35,9.52,4.09" target="#b4">[5]</ref>. Since then, search engine design has been dominated by multi-stage ranking architectures <ref type="bibr" coords="2,86.48,702.27,13.61,4.09" target="#b29">[30,</ref><ref type="bibr" coords="2,103.10,702.27,10.21,4.09" target="#b43">44]</ref>, where a first-stage retriever (often, just BM25 retrieval) generates candidate documents that are then reranked by one or more stages, typically by machine-learned models. In the "transformer era", for example, BERT <ref type="bibr" coords="2,471.14,362.02,13.53,4.09" target="#b31">[32,</ref><ref type="bibr" coords="2,486.92,362.02,11.55,4.09" target="#b33">34]</ref> and T5 <ref type="bibr" coords="2,528.34,362.02,14.75,4.09" target="#b32">[33]</ref> can be used in exactly this manner. Use of pretrained transformers for reranking requires feeding the model both the query and the candidate text, and this style of model application is known as a cross-encoder.</p><p>Bi-encoder architectures. An important recent innovation for passage retrieval was the introduction of so-called dense retrieval models that take advantage of a bi-encoder design (contrasted with the cross-encoder design discussed above): DPR <ref type="bibr" coords="2,488.07,459.84,14.60,4.09" target="#b18">[19]</ref> and ANCE <ref type="bibr" coords="2,543.61,459.84,14.59,4.09" target="#b44">[45]</ref> are two early examples. With sufficient labeled data, we can learn encoders (typically, transformer-based models) that project queries and documents into a dense (semantic) representation space (e.g., 768 dimensions) where relevance ranking can be recast as nearestneighbor search over representation vectors.</p><p>After the introduction of dense retrieval models, researchers soon realized that transformer-based encoders could also be coaxed to generate sparse representations, where the vector basis, for example, spans the input vocabulary space. Another way to view these so-called sparse retrieval models is to contrast them with BM25: whereas BM25 term weights are assigned using a heuristic scoring function, sparse retrieval models assign term weights that are learned using pretrained transformers such as BERT. Examples of these learned sparse retrieval models include DeepImpact <ref type="bibr" coords="2,542.41,613.27,13.42,4.09" target="#b28">[29]</ref>, uniCOIL <ref type="bibr" coords="2,351.73,624.23,13.50,4.09" target="#b23">[24,</ref><ref type="bibr" coords="2,367.48,624.23,10.13,4.09" target="#b52">53]</ref>, SPLADE <ref type="bibr" coords="2,416.91,624.23,13.36,4.09" target="#b11">[12]</ref>, as well as many others.</p><p>Recently, Lin <ref type="bibr" coords="2,375.89,635.19,14.60,4.09" target="#b22">[23]</ref> made the observation that dense retrieval models, sparse retrieval models, and traditional bag-of-words models (e.g., BM25) are all parametric variations of a bi-encoder architecture, which is shown in Figure <ref type="figure" coords="2,433.11,668.06,12.57,4.09" target="#fig_0">1(a)</ref>. In all three classes of models, "encoders" take queries or documents and generate vector representations. There are two major axes of differences, the first of which lies in the basis of the representation vector: dense retrieval models generate dense (semantic) representations whereas sparse retrieval models and bag-of-words model ground their representation vectors in lexical space. The other major axis of variation is whether these representations are learned: yes in the case of dense and sparse retrieval models, but no in the case of traditional bag-of-words models. The conceptual framework for mono-lingual retrieval provides us with a basis for organizing cross-lingual retrieval approaches, which we discuss next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CROSS-LINGUAL RETRIEVAL METHODS</head><p>The cross-lingual information retrieval task is formalized in a similar manner as the mono-lingual retrieval task. We assume a collection of documents C 𝑓 in language 𝑓 comprised of {𝑑 1 , 𝑑 2 . . . , 𝑑 𝑛 }.</p><p>The system is given a query 𝑞 in language 𝑒, which we denote 𝑞 𝑒 for clarity, and its task is to return a top-𝑘 ranking of documents from C 𝑓 that maximizes some metric of quality such as nDCG or average precision. Throughout this work, 𝑒 refers to English and 𝑓 refers to some non-English language (e.g., Russian), but this need not be the case in general.</p><p>Building from the design of the mono-lingual retrieval architecture presented in the previous section, our discussions begin with three possible designs for first-stage retrieval: document translation, query translation, and the use of language-independent representations. We then overview cross-encoders for reranking the output of first-stage retrievers and finally conclude with some thoughts about fusion techniques.</p><p>To further ground cross-lingual retrieval techniques, we provide some details about the TREC 2022 NeuCLIR evaluation. Given English queries, participants are tasked with retrieving from three separate corpora comprising Persian, Russian, and Chinese newswire documents curated from the Common Crawl between August 1, 2016 and July 31, 2021. The corpora are modest in size, with 2.23 million documents in Persian, 4.63 million documents in Russian, and 3.18 million documents in Chinese.</p><p>Information needs (i.e., topics, in TREC parlance) were developed following a standard process for building retrieval test collections <ref type="bibr" coords="3,74.18,488.88,13.50,4.09" target="#b14">[15,</ref><ref type="bibr" coords="3,89.92,488.88,10.13,4.09" target="#b41">42]</ref>. The organizers released 114 topics, originally developed in English, which were then translated into Persian, Russian, and Chinese-both by humans and automatically by Google Translate. The topics comprise "title" and "description" fields, where the former are akin to keyword queries and the latter are roughly sentence-long articulations of the information need. By design, all topics are aligned, in the sense that for each topic, we have translations in all three languages. However, it was not the case that all topics were evaluated for all languages: In total, the organizers released relevance judgments for 46 topics in Persian, 45 topics in Russian, and 49 topics in Chinese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Translation</head><p>A very simple approach to cross-lingual information retrieval is known as document translation: Given 𝑞 𝑒 in language 𝑒 and the corpus C 𝑓 in language 𝑓 , we can translate the entire corpus into language 𝑒, i.e., {Translate(𝑑 𝑖 )}, and then perform mono-lingual retrieval in language 𝑒. This design is shown in Figure <ref type="figure" coords="3,253.18,679.98,12.75,4.09" target="#fig_0">1(b)</ref>, where the primary addition is a document translation phase that feeds into the document side of the bi-encoder architecture.</p><p>While translating the entire corpus can be time-consuming, it only needs to be performed once and can be viewed as an expensive pre-processing step, like other computationally demanding document expansion techniques such as doc2query <ref type="bibr" coords="3,483.87,122.46,13.22,4.09" target="#b34">[35]</ref>. Any translation technique can be used, including off-the-shelf MT systems. Generally, since documents are comprised of well-formed sentences, automatic translation output can be quite fluent, depending on the quality of the underlying system. This stands in contrast to query translation (see below), where quality often suffers because queries are usually much shorter (hence lacking context) and systems are not usually trained on such inputs.</p><p>Once C 𝑓 has been translated into C 𝑒 , we now have a monolingual retrieval task since queries are also in 𝑒. In our case, the three corpora are in Persian, Russian, and Chinese, and we used the English translations provided by the NeuCLIR Track organizers, generated by the SockEye MT system. From the NeuCLIR topics, we extracted three types of English queries: only the "title" field, only the "description" field, and both. Our experiments used two retrieval models and pseudo-relevance feedback: BM25. Despite the advent of numerous neural ranking models, this traditional "bag-of-words" model remains a robust baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPLADE.</head><p>We chose SPLADE++ Ensemble Distil <ref type="bibr" coords="3,506.60,332.20,14.85,4.09" target="#b11">[12]</ref> due to its zero-shot capabilities. The SPLADE family of models is a sparse neural retrieval model that learns both document and query expansion controlled by a regularization term.</p><p>Pseudo-relevance feedback (PRF). On top of results from both BM25 and SPLADE, we apply pseudo-relevance feedback. While RM3 is a popular choice and has been well studied in the context of neural methods <ref type="bibr" coords="3,390.59,415.15,13.49,4.09" target="#b47">[48]</ref>, in this work we instead apply Rocchio feedback, for two reasons: First, Rocchio feedback has been demonstrated to be an effective pseudo-relevance feedback approach for dense vector representations, and applying Rocchio to lexical representations provides conceptual unity. In contrast, there is no equivalent RM3 variant for dense vectors, which makes comparing sparse and dense PRF more difficult. Second, previous work has shown that Rocchio is at least as effective as RM3 <ref type="bibr" coords="3,500.45,491.86,13.32,4.09" target="#b25">[26]</ref>, so we gain simplicity and consistency without sacrificing effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Translation</head><p>The flip side of document translation is known as query translation: Given 𝑞 𝑒 in language 𝑒 and the corpus C 𝑓 in language 𝑓 , we can translate the query into language 𝑓 , i.e., Translate(𝑞 𝑒 ) = 𝑞 𝑓 , and then perform mono-lingual retrieval in language 𝑓 . This design is shown in Figure <ref type="figure" coords="3,378.25,582.35,11.89,4.09" target="#fig_0">1(c)</ref>, where we add a query translation component that feeds the query side of the bi-encoder architecture.</p><p>Query translation is much more computationally efficient than document translation, but has the disadvantages already discussedqueries may be more difficult to translate given that they may not be well-formed sentences. However, this approach enables more rapid experimentation since the introduction of a new translation model does not require re-translation of the entire corpus.</p><p>One challenge of query translation is that we need a good monolingual retrieval model in 𝑓 , which by definition is non-English. While BM25 can provide a baseline (in the bag-of-words space of language 𝑓 ), effective learned retrieval models are more difficult to come by since less manually labeled data are available in non-English languages.</p><p>Our experiments consider both human and machine translations of the topics provided by the track organizers. From each type of translation, we can create three types of queries: "title", "description", and "both" (similar to the document translation case above). Thus, we have a total of six variations: {human translation, machine translation} × {title, description, both}. With these conditions, we experimented with two different retrieval models as well as pseudo-relevance feedback: BM25. Again, this traditional "bag-of-words" model remains a robust baseline. SPLADE. To build SPLADE models in non-English languages, we first need to start with a good pretrained language model for that language. Thus, the models used here are first trained from scratch with the MLM+FLOPS loss <ref type="bibr" coords="4,156.91,268.16,14.85,4.09" target="#b19">[20]</ref> using a corpus concatenation of (i) the NeuCLIR corpus of the target language, (ii) the MS MARCO translations <ref type="bibr" coords="4,99.22,290.08,10.55,4.09" target="#b3">[4]</ref> for the target language, and (iii) the Mr. TyDi <ref type="bibr" coords="4,279.33,290.08,14.72,4.09" target="#b50">[51]</ref> corpus of the target language (if available). Finally, we fine-tuned on the target language version of MS MARCO, expecting to have similar zero-shot properties as similar experiments in English. A separate model was created for each language. <ref type="foot" coords="4,223.74,331.43,3.38,3.32" target="#foot_0">1</ref>Pseudo-relevance feedback. As in the document translation case, we can apply pseudo-relevance feedback on top of either BM25 or SPLADE. For the same reasons discussed above, Rocchio was chosen as the feedback method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Language-Independent Representations</head><p>Starting from the bi-encoder design for mono-lingual retrieval shown in Figure <ref type="figure" coords="4,115.42,432.30,3.09,4.09" target="#fig_0">1</ref>(a), one might wonder if it were possible for the document and query encoders to generate some sort of languageindependent semantic representation that would support direct relevance matching across languages. With the advent of pretrained multilingual transformers, this is indeed possible. For example, we can apply the document encoder to documents in C 𝑓 (in language 𝑓 ), and apply the query encoder to a query in 𝑒, and directly conduct relevance ranking on the representations. Thus, we can perform cross-lingual retrieval without explicit query or document translation. This is shown in Figure <ref type="figure" coords="4,160.81,530.95,12.70,4.09" target="#fig_0">1(d)</ref>.</p><p>The most straightforward implementation of this approach is to train a DPR model <ref type="bibr" coords="4,134.24,552.87,13.48,4.09" target="#b18">[19]</ref>, but starting from a multilingual transformer backbone such as mBERT. To our knowledge, Asai et al. <ref type="bibr" coords="4,283.49,563.83,10.55,4.09" target="#b0">[1]</ref> was the first to propose such an approach. More recently, Zhang et al. <ref type="bibr" coords="4,74.78,585.75,14.72,4.09" target="#b51">[52]</ref> built on this basic design and introduced different approaches to exploit cross-lingual transfer by "pre-fine-tuning" on English data before further fine-tuning on the target languages using non-English data. Although Zhang et al. focused on monolingual retrieval in non-English languages, many of the lessons learned are applicable to the cross-lingual case as well.</p><p>Specifically, for this work, we pre-fine-tuned a multilingual DPR model initialized from an XLM-R <ref type="bibr" coords="4,173.35,662.46,10.43,4.09" target="#b5">[6]</ref> backbone,<ref type="foot" coords="4,221.74,659.97,3.38,3.32" target="#foot_1">2</ref> dubbed xDPR. The model was trained on the MS MARCO passage dataset <ref type="bibr" coords="4,520.45,89.58,9.43,4.09" target="#b1">[2]</ref>, where both query and passage encoders share parameters.</p><p>With this trained model, we separately encoded the corpora in Persian, Russian, and Chinese. It is perhaps worth emphasizing that the same model was used in all three cases. For query encoding, we have a number of design choices. Similar to document translation and query translation, we can use "title", "description", or "both". Furthermore, we can encode queries either in 𝑒 or 𝑓 . In the first case, we are asking the encoder to directly project 𝑒 queries into the semantic space occupied by the 𝑓 documents. In the second case, the query starts off in 𝑓 , so the model is encoding a sequence in 𝑓 into the semantic space occupied by 𝑓 documents. Thus, for each language, we arrive at a total of nine variations: {original query, human translation, machine translation} × {title, description, both}.</p><p>Finally, on top of xDPR retrieved results, we can apply pseudorelevance feedback using Rocchio's method, following the work of Li et al. <ref type="bibr" coords="4,358.08,264.92,13.54,4.09" target="#b20">[21,</ref><ref type="bibr" coords="4,374.09,264.92,10.16,4.09" target="#b21">22]</ref>. Thus, combined with Liu <ref type="bibr" coords="4,486.50,264.92,13.39,4.09" target="#b25">[26]</ref>, we are able to implement Rocchio feedback consistently across both dense and sparse retrieval models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reranking</head><p>In a standard multi-stage ranking architecture, the first-stage retriever generates a ranked list of candidates that are then processed by one or more reranking stages that aim to improve the ranking. Reranking is also applicable in the cross-lingual case, but depending on the first-stage retriever, the candidate query/document pairs may either be in 𝑒 or 𝑓 . In cases where both the queries and documents are in 𝑒, we can use a mono-lingual English reranker.</p><p>For the first-stage retrievers based on document translation, our experiments used monoT5, which is based on T5 <ref type="bibr" coords="4,494.31,412.72,13.22,4.09" target="#b36">[37]</ref>. Reranking is performed in English with the following prompt:</p><p>Query: {query_text} Document: {doc_text} Relevant:</p><p>The model is asked to generate either the "true" or "false" token, from which we can extract the probability of relevance used to sort the candidates. When the monoT5 model is fine-tuned on the MS MARCO passage dataset, it achieves state-of-the-art results on the TREC Deep Learning Tracks <ref type="bibr" coords="4,423.30,509.97,9.27,4.09" target="#b7">[8,</ref><ref type="bibr" coords="4,434.81,509.97,6.18,4.09" target="#b8">9]</ref>, as well as impressive zero-shot effectiveness on BEIR <ref type="bibr" coords="4,398.90,520.93,14.72,4.09" target="#b16">[17]</ref> and many other datasets <ref type="bibr" coords="4,507.91,520.93,11.47,4.09" target="#b37">[38]</ref><ref type="bibr" coords="4,519.37,520.93,3.82,4.09" target="#b38">[39]</ref><ref type="bibr" coords="4,523.20,520.93,11.47,4.09" target="#b39">[40]</ref><ref type="bibr" coords="4,536.91,520.93,10.13,4.09" target="#b49">50]</ref>.</p><p>For reranking first-stage retrievers based on query translation, we used a variant based on the multilingual version of T5 called mT5, which was pretrained on the multilingual mC4 dataset <ref type="bibr" coords="4,541.94,553.81,13.52,4.09" target="#b45">[46]</ref>; otherwise, we use the same reranking approach. To fine-tune mT5 for reranking, we employed a similar strategy as Bonifacio et al. <ref type="bibr" coords="4,317.96,586.68,10.55,4.09" target="#b3">[4]</ref> using mMARCO, the multilingual version of the MS MARCO dataset. For our experiments, we used the XXL model with 13B parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Fusion</head><p>Researchers have known for many decades that fusion techniques, which combine evidence from multiple individual runs, can improve effectiveness <ref type="bibr" coords="4,366.34,668.73,9.27,4.09" target="#b2">[3,</ref><ref type="bibr" coords="4,377.85,668.73,10.08,4.09" target="#b40">41]</ref>. Fusion works particularly well when the individual runs are based on different underlying techniques, such as in the case of dense vs. sparse retrieval models <ref type="bibr" coords="4,488.64,690.65,13.44,4.09" target="#b13">[14,</ref><ref type="bibr" coords="4,504.33,690.65,10.08,4.09" target="#b26">27]</ref>. Given that our first-stage retrievers are all based on very different approaches, we would expect fusion to yield substantial boosts in effectiveness, although this does not appear to be borne out experimentally.</p><p>Within a multi-stage architecture, there arises a natural question of when fusion should be performed. One possible approach is to independently rerank the output of each first-stage retriever, and then fuse those results; we call this late fusion. Another possible approach is to first fuse the output of the first-stage retrievers, and then rerank the combined results; we call this early fusion. The effectiveness difference between the two approaches is an empirical question, but late fusion is more computationally intensive because it requires more reranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION DETAILS</head><p>All the first-stage and fusion retrieval conditions described in this paper are implemented in Anserini <ref type="bibr" coords="5,180.90,247.79,14.60,4.09" target="#b46">[47]</ref> and Pyserini <ref type="bibr" coords="5,244.41,247.79,13.22,4.09" target="#b24">[25]</ref>. Anserini is a Java-based toolkit built around the open-source Lucene search library to support reproducible information retrieval research. Pyserini provides a Python interface to Anserini and further augments its capabilities by including support for dense retrieval models. Together, the toolkits are widely adopted by researchers in the IR and NLP communities.</p><p>For document translation using BM25, our implementation uses Lucene's default analyzer for English, which performs tokenization, stemming, etc. Retrieval is performed with Pyserini's default BM25 parameters (𝑘 1 = 0.9, 𝑏 = 0.4). For query translation, note that since we are indexing non-English text, analyzers in 𝑓 are required. Fortunately, Lucene already has analyzers implemented for all three languages, which we used out of the box. The same BM25 parameters were used.</p><p>All SPLADE models were implemented in Lucene using the standard "fake documents" trick <ref type="bibr" coords="5,178.09,423.13,13.49,4.09" target="#b27">[28]</ref>. Token weights were used to generate synthetic documents where the token was repeated a number of times equal to its weight (after quantizing into integers). For example, if "car" receives a weight of ten from the encoder, we simply repeat the token ten times. These fake documents are then indexed with Anserini as usual, where the weight is stored in the term frequency position of the postings in the inverted index. Top-𝑘 retrieval is implemented by using a "sum of term frequency" scoring function in Lucene, which produces exactly the same output as ranking by the inner product between query and document vectors. Anserini provides the appropriate abstractions that hide all these implementation details.</p><p>Support for dense retrieval is provided in Pyserini with the Faiss toolkit <ref type="bibr" coords="5,80.75,565.59,13.61,4.09" target="#b17">[18]</ref>; all xDPR runs were conducted with flat indexes. For both BM25 and SPLADE models, Anserini exposes the appropriate bindings for performing retrieval in Python, and Pyserini provides appropriate interfaces that abstract over and unify retrieval using dense and sparse models (i.e., they are merely parametric variations in the command-line arguments). Pyserini additionally provides implementations of reciprocal rank fusion, and thus the entire infrastructure makes mixing-and-matching different experimental conditions quite easy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>Our results are organized into following progression: first-stage retrievers, reranking, and fusion. We report retrieval effectiveness in terms of nDCG@20, the official metric of the NeuCLIR evaluation, and recall at a cutoff of 1000 hits (recall@1000), which quantifies the effectiveness upper bound of reranking. The organizers also measured mean average precision (MAP) as a supplemental metric; we followed this procedure as well. Overall, the findings from nDCG@20 and MAP were consistent, and so for brevity we omit the MAP results in our presentation.</p><p>In Section 3, we describe a vast design space for first-stage variants that can feed many reranking and fusion approaches. It is not practical to exhaustively examine all possible combinations, and thus our experiments were guided by progressive culling of "uninteresting" settings, as we'll describe.</p><p>Finally, a word on significance testing: We are of course cognizant of its importance, but we are equally aware of the dangers of multiple hypothesis testing. Due to the large number of conditions we examine, a standard technique such as the Bonferroni correction is likely too conservative to detect significant differences, especially given the relatively small topic size of NeuCLIR. For most of our experiments, we did not perform significance testing and instead focused on general trends that are apparent from our large numbers of experimental conditions. We applied significance testing more judiciously, to answer targeted research questions. To be clear, the results we report are the only tests we conducted-that is, we did not cherry-pick the most promising results. In all cases, we used paired 𝑡-tests (𝑝 ≤ 0.05) with the Bonferroni correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">First-Stage Retrievers</head><p>We begin by examining the output of individual first-stage retrievers. Tables <ref type="table" coords="5,359.75,400.98,4.25,4.09" target="#tab_1">1</ref> and<ref type="table" coords="5,382.73,400.98,4.25,4.09" target="#tab_0">2</ref> present results in terms of nDCG@20 and recall@1000, respectively. Each block of rows is organized by the general approach. The columns show metrics grouped by language, and within each block, we report the results of using queries comprised of the "title" field, the "description" field, and both. Document translation. Recall that in the document translation condition, we are indexing the machine-translated documents provided by the NeuCLIR organizers, which are in English. The BM25 conditions in rows (1ab) and the SPLADE conditions in rows (2ab) differ only in the retrieval model applied to the translated corpus. For BM25, we see that "title" and "both" query conditions yield about the same effectiveness (both metrics) on Persian and Chinese, but "both" is worse on Russian. For all languages, it appears that "description" queries perform worse. For SPLADE, interestingly, for Persian and Chinese, there does not appear to be much of an effectiveness gap between the three types of queries for both metrics. This is likely because the retrieval model includes query expansion, and so the benefits from having richer descriptions of the information need diminish.</p><p>The comparisons between (a) vs. (b) rows highlight the impact of pseudo-relevance feedback. We see that, at best, PRF yields a small improvement for BM25 in terms of nDCG@20, and for SPLADE, PRF actually decreases effectiveness. However, looking at the recall figures in and Chinese for both metrics. For SPLADE, shown in rows (4a)-(4d), there does not appear to be a consistent finding: in some cases, "both" beats "title", and the opposite in other cases. However, it does appear that "description" alone is generally less effective in terms of nDCG@20. With query translation, there is a natural comparison between human translations and machine translations. In rows (3) and ( <ref type="formula" coords="6,286.32,506.05,2.90,4.09">4</ref>), these are the (a) and (c) conditions versus the (b) and (d) conditions. It does not appear that for Persian and Russian, machine-translated queries are consistently less effective than human translations, for both BM25 and SPLADE. In some cases, we actually observe machine-translated queries outperforming their human-translation counterparts. For BM25, note that since the queries are bags of words, the fluency of the translations is not important, so long as the correct content terms are present. For SPLADE, the model appears to be robust to possibly disfluent translations. In Chinese, however, there does seem to be a noticeable gap between human and machine translations, with the human translations generally yielding better results.</p><p>Finally, consistent with the document translation case, pseudorelevance feedback does not appear to improve nDCG@20, but does improve recall. Once again, this is expected.</p><p>Language-Independent Representations. The final blocks in Tables 1 and 2 show the effectiveness of xDPR. Recall our experimental design: on the document end, the original corpus in 𝑓 is encoded with the model. On the query end, there are three options: directly encode the English query, encode the human-translated (HT) query, or encode the machine-translated (MT) query. These are shown in rows (5a), (5b), and (5c), respectively. We see quite a big difference in effectiveness between row (5a) and row (5b), which indicates that there is a big loss in trying to encode queries in 𝑒 directly into the semantic space occupied by documents in 𝑓 , compared to encoding queries in 𝑓 . Clearly, the model is not able to adequately encode text with the same meaning in different languages (the query translations) into the same semantic space. Regardless of configuration, the dense retrieval models appear to be far less effective than the BM25 and SPLADE models, for both translation types, across both metrics. However, we see that pseudo-relevance feedback does appear to increase effectiveness, which is consistent with previous work <ref type="bibr" coords="6,338.94,604.68,13.50,4.09" target="#b20">[21,</ref><ref type="bibr" coords="6,354.68,604.68,11.53,4.09" target="#b21">22]</ref> on vector PRF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reranking</head><p>In the previous section, we examined first-stage retrieval settings for 18 × 3 = 54 different conditions, for each language. It is impractical to report reranking results for every single condition, and thus we made a few choices to focus our attention: We considered only conditions that take advantage of both title and description fields, which appear to be more robust than title-only queries. We language-independent representations -xDPR (5a) ⟨d: original corpus, q: English⟩ ✗ 0.4910 0.5445 0.5393 0.5704 0.5627 0.5834 0.4161 0.4359 0.4386 (5b) ⟨d: original corpus, q: HT⟩ ✗ 0.6288 0.6780 0.7088 0.6196 0.5825 0.6368 0.5773 0.5841 0.6031 (5c) ⟨d: original corpus, q: MT⟩ ✗ 0.6333 0.6453 0.6850 0.6285 0.5649 0.6300 0.5420 0.5382 0.5873 (5d) ⟨d: original corpus, q: English⟩ ✓ 0.4702 0.4981 0.5347 0.6251 0.5971 0.6212 0.4330 0.4714 0.4593 (5e) ⟨d: original corpus, q: HT⟩ ✓ 0.6409 0.6612 0.7212 0.6541 0.5915 0.6346 0.6088 0.5939 0.6310 (5f) ⟨d: original corpus, q: MT⟩ ✓ 0.6686 0.6516 0.7071 0.6784 0.6032 0.6475 0.5744 0.5375 0.6109 Table <ref type="table" coords="7,164.05,398.58,3.45,7.70" target="#tab_0">2</ref>: Main results table reporting recall@1000 for various first-stage retrievers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall</head><p>also focused on runs without PRF, since PRF represents additional computational costs (both latency and index size).</p><p>For each language, this reduces the number of first-stage retrievers under consideration to nine. We applied reranking on these runs, including the title and description fields in the input template to the reranking models. We informally, but not exhaustively, examined other conditions, but they did not appear to alter our overall findings. For example, we tried reranking the first-stage retrieval results with pseudo-relevance feedback, but the results were not noticeably better (even though they exhibited higher recall).</p><p>Reranking results are shown in Table <ref type="table" coords="7,201.00,549.88,3.04,4.09" target="#tab_4">3</ref>. Under the effectiveness of the first-stage retriever ("1st" columns), we report (nDCG@20, recall@1000): the first quantifies candidate ranking quality and the second quantifies the upper bound effectiveness of a reranker. We see that reranking improves effectiveness by large margins, but this is expected as the effectiveness of cross-encoders in various settings is well known (see Section 3.4).</p><p>One interesting observation, however, is that reranking reduces the effectiveness gap between the best and worst first-stage retrievers. For example, starting with BM25, which is clearly less effective than SPLADE, the reranker is able to "make up" for the lower quality candidates, such that the end-to-end effectiveness is relatively close to reranking SPLADE results (at least in terms of nDCG). In fact, in some cases, reranking xDPR results yields scores that are even higher than reranking BM25 results. While "coupling effects" between the first-stage retriever and reranker have been previously noted in the literature <ref type="bibr" coords="7,404.36,462.21,13.61,4.09" target="#b13">[14,</ref><ref type="bibr" coords="7,420.78,462.21,10.21,4.09" target="#b35">36]</ref>, this finding affirms the need for further explorations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Fusion</head><p>With fusion, the design space of possible combinations is immense and impractical to exhaustively explore. To provide continuity, we focus only on the first-stage retrievers in the reranking experiments. In the space of fusion techniques, we settled on reciprocal rank fusion, which is a simple, effective, and robust approach <ref type="bibr" coords="7,524.92,572.44,9.39,4.09" target="#b6">[7]</ref>.</p><p>With these considerations, we experimented with the following fusion conditions in From these results, it appears that for Persian and Russian, the best effectiveness can be achieved by fusing both document translation and query translation SPLADE models, row (6d), although for Chinese, the same fusion is a bit worse than just document translation SPLADE. Fusing all the lexical runs, row (6e), is a bit worse than fusing just SPLADE runs in Persian and Russian, but it improves Chinese. Finally, incorporating evidence from the languageindependent dense retrieval techniques appears to provide value over simply fusing the lexical results, as we see comparing (6g) and (6e). This is surprising given that by themselves, the dense retrieval runs are quite poor.</p><p>Overall, we were somewhat surprised by the finding that fusion did not improve effectiveness as robustly as we had hoped. In Table <ref type="table" coords="8,340.23,655.28,3.13,4.09" target="#tab_3">4</ref>, the figures in red represent all the cases in which fusion actually hurt effectiveness, i.e., fusion performed worse than the best single input run. We attribute this finding to the large differences in effectiveness between the runs, in that RRF does not work as well if one of the fusion inputs is much better than the others. To more rigorously test this observation, we performed significance testing comparing the document translation SPLADE model, row (2a) in Table <ref type="table" coords="9,120.74,265.34,3.13,4.09" target="#tab_3">4</ref>, against fusion of SPLADE models, row (6d), fusion of all lexical models, row (6e), and fusion of all lexical and dense models, row (6g). These comparisons answer the following questions, starting from the single best first-stage retriever: Does SPLADE fusion provide any additional value? What about BM25? Dense retrieval?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Persian</head><p>The conclusion, reported in Table <ref type="table" coords="9,192.12,331.10,4.25,4.09" target="#tab_3">4</ref> with the symbol † , is that most of the fusion combinations are not statistically significantly better than document translation with SPLADE, the single best first-stage retriever. For nDCG@20, the largest ensemble is significantly better than DT-SPLADE only on Russian; for recall@1000 we see more significant improvements, but only on Persian and Chinese. Notably, combining evidence from both document and query translation with SPLADE, row (6d), is not significantly better than DT-SPLADE alone.</p><p>In our final set of experiments, we compared the effectiveness between early and late fusion for a subset of the conditions in Table <ref type="table" coords="9,77.05,451.64,3.13,4.09" target="#tab_3">4</ref>. These results are reported in Table <ref type="table" coords="9,224.48,451.64,3.13,4.09" target="#tab_6">5</ref>. In this case, we use QT-SPLADE as the point of comparison, which appears to provide the best single-stage retriever and reranking combination. For Persian, late fusion appears to be either about the same or slightly better, with the exception of (6f); this appears to be the case for Russian also, although the late fusion margin of improvement seems to be smaller. Chinese results are a bit more mixed, with early beating late in some cases. To more rigorously compare early vs. late fusion, we performed significance tests comparing all pairs. Only a few of these differences are significant, and they only happen for cases where early fusion is better than late fusion. Two of the three cases, however, occurred for the dense models, which are less effective to begin with. Overall, these experiments are inconclusive with respect to the question of which fusion strategy is better.</p><p>To provide additional context, the best runs from the NeuCLIR 2022 evaluation were from members of our group, but were generated under the time pressure of deadlines and thus it was not possible to carefully consider all configurations as we did in Table <ref type="table" coords="9,289.41,637.94,3.01,4.09" target="#tab_6">5</ref>. The best runs were (nDCG@20 scores): (i) Persian: p2.fa.rerank, 0.588; (ii) Russian: p3.ru.mono, 0.567; (iii) Chinese: p2.zh.rerank, 0.516. Comparing those runs to the best conditions reported here, we verify that just by carefully studying the various effects of different system components, improvements are possible across all languages, achieving new state-of-the-art effectiveness with (i) Persian: 6d late-fusion 0.612 (+0.024); (ii) Russian: 6d late-fusion 0.592 (+0.025); (iii) Chinese: 6e early-fusion 0.539 (+0.023).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>The NeuCLIR evaluation at TREC 2022 represents a "revival" of interest in the cross-lingual information retrieval challenge in the "neural era". As a high-level summary, this work captures a collaboration between two teams that submitted the most effective runs and a research group that is experienced in building retrieval toolkits to support research. Together, we take a more principled approach to the panoply of methods that were deployed in the evaluation and provide an organizing conceptual framework based on mono-lingual retrieval.</p><p>What are the high-level takeaways? It appears that query translation and document translation, general approaches dating back decades, adapt well to the neural age. In particular, SPLADE appears to be highly effective, demonstrating the promise of sparse learned representations. Although language-independent representations do not appear to be as effective as either query or document translation, we have only begun to scratch the surface of this class of techniques, as xDPR can only be considered a baseline. But if one considers that the same xDPR model works for all three languages, we can see tremendous potential.</p><p>Across the NLP and IR communities, we have only begun to explore the application of large pretrained transformer models. We find future prospects very exciting, and believe that our conceptual framework, experimental results, and software infrastructure offer a solid foundation for further exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,53.80,277.47,504.40,7.70;2,53.80,288.43,504.41,7.70;2,53.80,299.39,504.41,7.70;2,54.25,310.34,474.38,7.70"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Different retrieval architectures: (a) a mono-lingual bi-encoder architecture that captures both dense and sparse retrieval methods; (b) bi-encoder adapted for document translation, where all documents are translated into 𝑒 and queries remain in 𝑒; (c) bi-encoder adapted for query translation, where query 𝑒 is translated into 𝑓 and issued against documents in 𝑓 ; (d) bi-encoder where the encoders can project content from multiple languages into the same representation space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,317.96,661.08,241.63,45.01"><head>Table 2 ,</head><label>2</label><figDesc>it does appear that PRF boosts recall. This behavior is expected, as PRF is primarily a recall-enhancing device.</figDesc><table coords="5,317.96,689.19,240.25,16.89"><row><cell>Query translation. With BM25, shown in rows (3a)-(3d), we see</cell></row><row><cell>that "title" and "both" conditions are generally on par for Russian</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,143.15,398.58,325.40,7.70"><head>Table 1 :</head><label>1</label><figDesc>Main results table reporting nDCG@20 for various first-stage retrievers.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,317.69,594.36,241.90,102.72"><head>Table 4</head><label>4</label><figDesc>The top block of Table4repeats the effectiveness of the first-stage retrievers for convenience. In the bottom block of the table, cases in which the fusion results are worse than the best input are shown in red. In these cases, fusion provides no value over just selecting the best individual run.</figDesc><table coords="7,317.69,594.36,241.15,58.88"><row><cell>: (6a) document translation combining</cell></row><row><cell>BM25 and SPLADE; (6b) query translation combining BM25 and</cell></row><row><cell>SPLADE; (6c) combining document and query translation with</cell></row><row><cell>BM25; (6d) combining SPLADE document and query translation;</cell></row><row><cell>(6e) combining all lexical approaches; (6f) combining both dense</cell></row><row><cell>approaches; (6g) combining everything.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,53.50,299.95,505.79,233.34"><head>Table 3 :</head><label>3</label><figDesc>Results of reranking various first-stage retrievers (nDCG@20). Under the column "1st" we repeat the (nDCG@20, Recall@1000) metrics from the first-stage retriever for convenience. In all cases we used both titles and descriptions as queries in first-stage retrieval (with no pseudo-relevance feedback) and reranking.</figDesc><table coords="8,274.52,359.96,241.37,22.97"><row><cell>nDCG@20</cell><cell>Recall@1000</cell></row><row><cell cols="2">Persian Russian Chinese Persian Russian Chinese</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,53.50,547.53,504.70,29.91"><head>Table 4 :</head><label>4</label><figDesc>Results of different fusion combinations. Scores of individual first-stage retrievers are repeated for convenience. In all cases we used both titles and descriptions as queries, with no pseudo-relevance feedback. Red shows cases where fusion performed worse than the best single input run. † represents a significant improvement over (2a).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,67.88,88.94,474.00,120.47"><head>Table 5 :</head><label>5</label><figDesc>Comparisons between early and late fusion. † represents a significant improvement over late fusion.</figDesc><table coords="9,379.02,88.94,133.05,7.70"><row><cell>Russian</cell><cell>Chinese</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,56.84,686.99,237.65,3.18;4,56.84,693.73,227.88,5.61"><p>SPLADE and pretrained models are made available at https://huggingface.co/naver/ modelname with modelname = neuclir22-{pretrained,splade}-{fa,ru,zh}</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,56.84,703.37,117.27,3.18"><p>https://huggingface.co/xlm-roberta-large</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This research was supported in part by the <rs type="funder">Natural Sciences and Engineering Research Council (NSERC) of Canada</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,333.39,632.23,224.81,3.18;9,333.39,640.20,224.81,3.18;9,333.39,646.73,224.81,6.23;9,333.39,654.70,224.94,6.23;9,333.39,664.11,125.95,3.18" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,380.65,640.20,166.85,3.18">XOR QA: Cross-lingual Open-Retrieval Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,333.39,646.73,176.33,6.23">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="547" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,672.08,224.81,3.18;9,333.39,680.05,224.94,3.18;9,333.39,688.02,225.88,3.18;9,333.39,695.99,225.88,3.18;9,333.39,702.52,73.36,6.23" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,333.39,695.99,222.97,3.18">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName coords=""><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alina</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268v3</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,90.48,224.81,3.18;10,69.23,97.02,224.81,6.23;10,69.23,104.99,224.81,6.23;10,69.23,112.96,169.27,6.23" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,263.64,90.48,30.40,3.18;10,69.23,98.45,147.31,3.18">Automatic Combination of Multiple Ranked Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">Brian</forename><forename type="middle">T</forename><surname>Bartell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Garrison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><forename type="middle">K</forename><surname>Cottrell</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,229.34,97.02,64.70,6.23;10,69.23,104.99,224.81,6.23;10,69.23,112.96,59.26,6.23">Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994. 1994</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,122.36,225.58,3.18;10,69.23,130.33,225.99,3.18;10,69.23,136.87,224.81,6.23;10,69.03,146.27,18.66,3.18" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Luiz</forename><surname>Bonifacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitor</forename><surname>Jeronymo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Queiroz Abonizio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Israel</forename><surname>Campiotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marzieh</forename><surname>Fadaee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.13897</idno>
		<title level="m" coord="10,242.91,130.33,52.32,3.18;10,69.23,138.30,173.17,3.18">mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,154.24,225.58,3.18;10,69.23,162.21,224.81,3.18;10,69.23,168.75,224.81,6.23;10,68.81,176.72,103.40,6.23" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,198.04,162.21,96.00,3.18;10,69.23,170.18,20.94,3.18">Learning to Rank Using Gradient Descent</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tal</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erin</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicole</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,102.39,168.75,191.66,6.23">Proceedings of the 22nd International Conference on Machine Learning</title>
		<meeting>the 22nd International Conference on Machine Learning<address><addrLine>Bonn, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,186.12,225.99,3.18;10,69.23,194.09,225.58,3.18;10,69.23,202.06,225.99,3.18;10,69.23,208.60,224.81,6.23;10,69.23,216.57,225.57,6.23;10,69.23,225.97,31.30,3.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,150.52,202.06,144.70,3.18;10,69.23,210.03,33.16,3.18">Unsupervised Cross-lingual Representation Learning at Scale</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,115.81,208.60,178.23,6.23;10,69.23,216.57,73.43,6.23">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,233.94,224.81,3.18;10,69.23,241.91,224.81,3.18;10,69.23,248.45,224.81,6.23;10,69.23,256.42,225.58,6.23;10,69.07,265.82,24.81,3.18" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,264.47,233.94,29.57,3.18;10,69.23,241.91,214.04,3.18">Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Büttcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,69.23,248.45,224.81,6.23;10,69.23,256.42,118.66,6.23">Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,273.79,225.07,3.18;10,69.23,280.33,224.81,6.23;10,69.23,288.30,200.48,6.23" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,267.03,273.79,27.27,3.18;10,69.23,281.77,109.71,3.18">Overview of the TREC 2020 Deep Learning Track</title>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,191.23,280.33,102.81,6.23;10,69.23,288.30,126.12,6.23">Proceedings of the Twenty-Ninth Text REtrieval Conference Proceedings (TREC 2020)</title>
		<meeting>the Twenty-Ninth Text REtrieval Conference Proceedings (TREC 2020)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,297.71,225.88,3.18;10,69.00,304.24,225.04,6.23;10,69.23,312.21,225.99,6.23;10,69.23,321.62,45.70,3.18" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,114.47,305.68,136.12,3.18">Overview of the TREC 2019 Deep Learning Track</title>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,262.47,304.24,31.57,6.23;10,69.23,312.21,195.56,6.23">Proceedings of the Twenty-Eighth Text REtrieval Conference Proceedings (TREC 2019)</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference Proceedings (TREC 2019)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,329.59,225.64,3.18;10,69.23,337.56,224.81,3.18;10,69.23,344.09,224.81,6.23;10,69.23,352.06,224.81,6.23;10,69.23,360.03,225.58,6.23;10,69.07,369.44,31.30,3.18" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,277.34,329.59,17.53,3.18;10,69.23,337.56,214.32,3.18">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,69.23,344.09,224.81,6.23;10,69.23,352.06,166.76,6.23">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s" coord="10,269.83,352.06,24.21,6.23;10,69.23,360.03,31.50,6.23">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,377.41,225.99,3.18;10,69.23,383.94,224.81,6.23;10,69.23,391.91,224.81,6.23;10,69.23,399.88,134.71,6.23" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,194.85,377.41,100.38,3.18;10,69.23,385.38,129.62,3.18">Statistical Cross-Language Information Retrieval using N-Best Query Translations</title>
		<author>
			<persName coords=""><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,210.65,383.94,83.40,6.23;10,69.23,391.91,224.81,6.23;10,69.23,399.88,24.51,6.23">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,409.29,225.88,3.18;10,69.23,417.26,224.81,3.18;10,69.23,423.79,224.81,6.23;10,69.23,431.76,225.58,6.23;10,69.23,441.17,31.30,3.18" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,89.59,417.26,204.45,3.18;10,69.23,425.23,72.96,3.18">From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective</title>
		<author>
			<persName coords=""><forename type="first">Thibault</forename><surname>Formal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Lassance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Clinchant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,155.03,423.79,139.01,6.23;10,69.23,431.76,180.30,6.23">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2353" to="2359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,449.14,224.81,3.18;10,69.23,455.67,132.51,6.23" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Petra</forename><surname>Galuscáková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suraj</forename><surname>Nair</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.05988</idno>
		<title level="m" coord="10,249.02,449.14,45.03,3.18;10,69.23,457.11,60.25,3.18">Cross-language Information Retrieval</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,465.08,224.81,3.18;10,69.12,473.05,226.10,3.18;10,69.23,479.58,224.81,6.23;10,68.81,487.55,78.79,6.23" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,123.39,473.05,171.84,3.18;10,69.23,481.02,21.20,3.18">Complementing Lexical Retrieval with Semantic Residual Embedding</title>
		<author>
			<persName coords=""><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tongfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,102.74,479.58,191.30,6.23;10,68.81,487.55,50.49,6.23">Proceedings of the 43rd European Conference on Information Retrieval (ECIR 2021), Part I</title>
		<meeting>the 43rd European Conference on Information Retrieval (ECIR 2021), Part I</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="146" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,495.52,224.81,6.23;10,69.23,504.93,31.08,3.18" xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,136.92,495.52,92.11,6.23">Information Retrieval Evaluation</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,512.90,225.06,3.18;10,69.23,519.43,225.51,6.23;10,69.23,527.40,224.81,6.23;10,69.23,535.37,220.85,6.23" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,204.79,512.90,89.50,3.18;10,69.23,520.87,189.57,3.18">Querying Across Languages: A Dictionary-Based Approach to Multilingual Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">A</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,271.06,519.43,23.68,6.23;10,69.23,527.40,224.81,6.23;10,69.23,535.37,104.10,6.23">Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Zürich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,544.78,225.58,3.18;10,69.12,552.75,226.10,3.18;10,69.23,559.28,224.81,6.23;10,69.23,567.25,67.08,6.23" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="10,198.81,552.75,96.42,3.18;10,69.23,560.72,176.61,3.18">InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Vitor</forename><surname>Jeronymo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luiz</forename><surname>Bonifacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Abonizio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marzieh</forename><surname>Fadaee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakub</forename><surname>Zavrel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.01820</idno>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,69.23,576.66,224.99,3.18;10,69.23,583.19,197.95,6.23" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,228.47,576.66,65.76,3.18;10,69.23,584.63,49.05,3.18">Billion-scale similarity search with GPUs</title>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,124.34,583.19,84.33,6.23">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,592.60,224.99,3.18;10,69.23,600.57,225.99,3.18;10,69.23,607.10,224.81,6.23;10,69.23,615.07,224.81,6.23;10,69.23,624.48,88.04,3.18" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,198.13,600.57,97.10,3.18;10,69.23,608.54,80.82,3.18">Dense Passage Retrieval for Open-Domain Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,162.57,607.10,131.48,6.23;10,69.23,615.07,109.83,6.23">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,632.45,224.81,3.18;10,69.23,638.98,223.08,6.23" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Lassance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Déjean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Clinchant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10444</idno>
		<title level="m" coord="10,246.21,632.45,47.84,3.18;10,69.23,640.42,152.25,3.18">An Experimental Study on Pretraining Transformers from Scratch for IR</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,648.39,225.99,3.18;10,69.23,656.36,224.81,3.18;10,69.23,662.89,164.29,6.23" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Mourad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shengyao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bevan</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.11044</idno>
		<title level="m" coord="10,99.89,656.36,194.15,3.18;10,69.23,664.33,92.43,3.18">Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,69.23,672.30,224.99,3.18;10,69.23,680.27,224.81,3.18;10,69.23,686.80,224.81,6.23;10,69.23,694.77,225.88,6.23;10,69.23,704.18,74.29,3.18" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,156.21,680.27,137.83,3.18;10,69.23,688.24,59.10,3.18">To Interpolate or not to Interpolate: PRF, Dense and Sparse Retrievers</title>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shengyao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Mourad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,140.26,686.80,153.78,6.23;10,69.23,694.77,223.15,6.23">Proceedings of the 45th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2022)</title>
		<meeting>the 45th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2022)<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2495" to="2500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,90.48,224.81,3.18;10,333.15,97.02,194.82,6.23" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="10,386.61,90.48,171.59,3.18;10,333.15,98.45,97.51,3.18">A Proposed Conceptual Framework for a Representational Approach to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,435.87,97.02,35.20,6.23">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,106.42,224.81,3.18;10,333.39,112.96,224.81,6.23;10,333.18,122.36,18.66,3.18" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.14807</idno>
		<title level="m" coord="10,433.36,106.42,124.84,3.18;10,333.39,114.39,173.87,3.18">A Few Brief Notes on DeepImpact, COIL, and a Conceptual Framework for Information Retrieval Techniques</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,130.33,225.58,3.18;10,333.39,138.30,225.99,3.18;10,333.39,144.84,224.81,6.23;10,333.39,152.81,224.81,6.23;10,333.39,160.78,136.87,6.23" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="10,412.92,138.30,146.46,3.18;10,333.39,146.27,174.49,3.18">Pyserini: A Python Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,519.78,144.84,38.41,6.23;10,333.39,152.81,224.81,6.23;10,333.39,160.78,98.47,6.23">Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021</title>
		<meeting>the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2356" to="2362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,168.75,224.81,6.23;10,333.39,176.72,208.74,6.23" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="10,380.74,168.75,177.46,6.23;10,333.39,176.72,137.77,6.23">Simple Yet Effective Pseudo Relevance Feedback with Rocchio&apos;s Technique and Text Classification. Master&apos;s thesis</title>
		<author>
			<persName coords=""><forename type="first">Yuqi</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,186.12,225.99,3.18;10,333.39,194.09,224.81,3.18;10,333.39,200.63,225.57,6.23;10,333.39,208.60,100.50,6.23" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="10,548.29,186.12,11.08,3.18;10,333.39,194.09,214.13,3.18">Another Look at DPR: Reproduction of Training and Replication of Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minghan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,333.39,200.63,225.57,6.23;10,333.39,208.60,14.99,6.23">Proceedings of the 44th European Conference on Information Retrieval (ECIR 2022), Part I</title>
		<meeting>the 44th European Conference on Information Retrieval (ECIR 2022), Part I<address><addrLine>Stavanger, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="613" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,218.00,224.81,3.18;10,333.39,225.97,224.99,3.18;10,333.39,232.51,101.78,6.23" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Joel</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.11540</idno>
		<title level="m" coord="10,504.06,218.00,54.14,3.18;10,333.39,225.97,224.99,3.18;10,333.39,233.94,29.26,3.18">Wacky Weights in Learned Sparse Representations and the Revenge of Score-at-a-Time Query Evaluation</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,241.91,225.99,3.18;10,333.39,248.45,224.81,6.23;10,333.39,256.42,224.81,6.23;10,333.39,264.39,94.84,6.23" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="10,540.93,241.91,18.46,3.18;10,333.39,249.88,120.79,3.18">Learning Passage Impacts for Inverted Indexes</title>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Mallia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Torsten</forename><surname>Suel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,468.14,248.45,90.06,6.23;10,333.39,256.42,224.81,6.23;10,333.39,264.39,59.12,6.23">Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)</title>
		<meeting>the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1723" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,273.79,225.88,3.18;10,333.39,280.33,224.81,6.23;10,333.39,288.30,224.81,6.23;10,333.39,296.27,183.17,6.23" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="10,349.81,281.77,148.20,3.18">High Accuracy Retrieval with Multiple Nested Ranker</title>
		<author>
			<persName coords=""><forename type="first">Irina</forename><surname>Matveeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timo</forename><surname>Burkard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andy</forename><surname>Laucius</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leon</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,509.89,280.33,48.31,6.23;10,333.39,288.30,224.81,6.23;10,333.39,296.27,59.26,6.23">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="437" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,304.24,224.81,6.23;10,333.39,313.65,31.08,3.18" xml:id="b30">
	<monogr>
		<title level="m" type="main" coord="10,390.28,304.24,105.52,6.23">Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,321.62,225.89,3.18;10,333.39,328.15,67.15,6.23" xml:id="b31">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="10,467.59,321.62,88.07,3.18">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,337.56,225.99,3.18;10,333.39,344.09,224.81,6.23;10,333.39,352.06,182.25,6.23" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="10,541.57,337.56,17.81,3.18;10,333.39,345.53,172.22,3.18">Document Ranking with a Pretrained Sequence-to-Sequence Model</title>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,518.03,344.09,40.17,6.23;10,333.39,352.06,152.91,6.23">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,361.47,224.81,3.18;10,333.39,368.00,159.10,6.23" xml:id="b33">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14424</idno>
		<title level="m" coord="10,525.64,361.47,32.56,3.18;10,333.39,369.44,86.04,3.18">Multi-Stage Document Ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,377.41,224.81,3.18;10,333.39,383.94,160.52,6.23" xml:id="b34">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08375</idno>
		<title level="m" coord="10,528.69,377.41,29.51,3.18;10,333.39,385.38,88.06,3.18">Document Expansion by Query Prediction</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,393.35,225.88,3.18;10,333.39,401.32,224.81,3.18;10,333.39,407.85,224.81,6.23;10,333.39,415.82,225.58,6.23;10,333.39,425.23,11.26,3.18" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="10,352.03,401.32,206.17,3.18;10,333.39,409.29,120.84,3.18">Squeezing Water from a Stone: A Bag of Tricks for Further Improving Cross-Encoder Effectiveness for Reranking</title>
		<author>
			<persName coords=""><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,466.70,407.85,91.50,6.23;10,333.39,415.82,151.58,6.23">Proceedings of the 44th European Conference on Information Retrieval (ECIR 2022), Part I</title>
		<meeting>the 44th European Conference on Information Retrieval (ECIR 2022), Part I<address><addrLine>Stavanger, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="655" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,433.20,225.58,3.18;10,333.39,441.17,224.81,3.18;10,333.39,447.70,224.81,6.23;10,333.39,455.67,134.54,6.23" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="10,517.83,441.17,40.37,3.18;10,333.39,449.14,191.46,3.18">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName coords=""><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,530.41,447.70,27.80,6.23;10,333.39,455.67,76.00,6.23">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,465.08,225.58,3.18;10,333.39,473.05,225.88,3.18;10,333.39,479.58,224.81,6.23;10,333.39,487.55,222.44,6.23" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="10,349.88,481.02,148.06,3.18">Overview of the TREC 2019 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shubham</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Funda</forename><surname>Meric-Bernstam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,509.82,479.58,48.39,6.23;10,333.39,487.55,113.40,6.23">Proceedings of the Twenty-Eighth Text REtrieval Conference</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,496.96,224.81,3.18;10,333.39,504.93,224.81,3.18;10,333.18,512.90,226.09,3.18;10,333.39,519.43,67.09,6.23" xml:id="b38">
	<monogr>
		<title level="m" type="main" coord="10,442.96,504.93,115.24,3.18;10,333.18,512.90,223.15,3.18">Billions of Parameters Are Worth More Than In-domain Training Data: A case study in the Legal Case Entailment Task</title>
		<author>
			<persName coords=""><forename type="first">Guilherme</forename><surname>Moraes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rosa</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luiz</forename><surname>Bonifacio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitor</forename><surname>Jeronymo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Abonizio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.15172</idno>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,528.84,225.58,3.18;10,333.39,536.81,224.94,3.18;10,333.39,543.34,224.81,6.23;10,333.39,551.31,120.07,6.23" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="10,479.85,528.84,79.12,3.18;10,333.39,536.81,224.94,3.18;10,333.39,544.78,62.08,3.18">Roberto de Alencar Lotufo, and Rodrigo Nogueira. 2021. To Tune or Not To Tune? Zero-shot Models for Legal Case Entailment</title>
		<author>
			<persName coords=""><forename type="first">Guilherme</forename><surname>Moraes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rosa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,407.76,543.34,150.44,6.23;10,333.39,551.31,90.18,6.23">Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Eighteenth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<publisher>Ruan Chaves Rodrigues</publisher>
			<biblScope unit="page" from="295" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,560.72,225.99,3.18;10,333.39,567.25,167.86,6.23" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="10,481.62,560.72,77.76,3.18;10,333.39,568.69,44.48,3.18">Fusion Via a Linear Combination of Scores</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Garrison</forename><forename type="middle">W</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,383.21,567.25,59.26,6.23">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="151" to="173" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,576.66,224.81,3.18;10,333.39,583.19,224.81,6.23;10,333.39,591.16,224.81,6.23;10,333.39,599.13,40.48,6.23" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="10,404.17,576.66,143.68,3.18">The Philosophy of Information Retrieval Evaluation</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,333.39,583.19,224.81,6.23;10,333.39,591.16,103.46,6.23">Evaluation of Cross-Language Information Retrieval Systems: Second Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="10,441.80,591.16,116.40,6.23">Lecture Notes in Computer Science Volume</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="355" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,608.54,224.81,3.18;10,333.39,615.07,224.81,6.23;10,333.39,623.04,224.81,6.23;10,333.39,631.01,183.17,6.23" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="10,456.42,608.54,101.78,3.18;10,333.39,616.51,163.06,3.18">Combining Bidirectional Translation and Synonymy for Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jianqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,508.52,615.07,49.67,6.23;10,333.39,623.04,224.81,6.23;10,333.39,631.01,78.71,6.23">Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR</title>
		<meeting>the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="202" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,640.42,225.88,3.18;10,333.39,646.95,224.81,6.23;10,333.39,654.92,225.58,6.23;10,333.23,664.33,24.81,3.18" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="10,478.65,640.42,77.44,3.18">Learning to Efficiently Rank</title>
		<author>
			<persName coords=""><forename type="first">Lidan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,340.72,646.95,217.48,6.23;10,333.39,654.92,158.45,6.23">Proceedings of the 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2010)</title>
		<meeting>the 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2010)<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,333.39,672.30,225.58,3.18;10,333.28,680.27,225.06,3.18;10,333.39,686.80,224.81,6.23;10,333.39,694.77,183.30,6.23" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="10,466.02,680.27,92.32,3.18;10,333.39,688.24,153.95,3.18">Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,499.18,686.80,59.02,6.23;10,333.39,694.77,147.84,6.23">Proceedings of the 9th International Conference on Learning Representations</title>
		<meeting>the 9th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>ICLR 2021</note>
</biblStruct>

<biblStruct coords="11,69.23,90.48,224.81,3.18;11,69.23,98.45,224.81,3.18;11,69.23,104.99,224.81,6.23;11,69.23,112.96,224.81,6.23;11,69.23,120.93,225.57,6.23;11,69.07,130.33,11.26,3.18" xml:id="b45">
	<analytic>
		<title level="a" type="main" coord="11,97.90,98.45,196.14,3.18;11,69.23,106.42,102.16,3.18">Aditya Barua, and Colin Raffel. 2021. mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer</title>
		<author>
			<persName coords=""><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,183.46,104.99,110.59,6.23;11,69.23,112.96,67.60,6.23">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Online</publisher>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,138.30,224.81,3.18;11,69.23,144.84,225.58,6.23;11,68.99,154.24,29.24,3.18" xml:id="b46">
	<analytic>
		<title level="a" type="main" coord="11,200.92,138.30,93.13,3.18;11,69.23,146.27,66.78,3.18">Anserini: Reproducible Ranking Baselines Using Lucene</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,142.29,144.84,115.97,6.23">Journal of Data and Information Quality</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,162.21,224.81,3.18;11,68.45,170.18,225.60,3.18;11,69.23,176.72,224.81,6.23;11,69.23,184.69,224.81,6.23;11,69.23,192.66,88.84,6.23" xml:id="b47">
	<analytic>
		<title level="a" type="main" coord="11,225.40,162.21,68.65,3.18;11,68.45,170.18,225.60,3.18;11,69.23,178.15,67.26,3.18">Critically Examining the &quot;Neural Hype&quot;: Weak Baselines and the Additivity of Effectiveness Gains from Neural Ranking Models</title>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kuang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,149.61,176.72,144.43,6.23;11,69.23,184.69,204.86,6.23">Proceedings of the 42nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1129" to="1132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,202.06,224.94,3.18;11,69.23,208.60,224.81,6.23;11,69.23,216.57,220.90,6.23" xml:id="b48">
	<analytic>
		<title level="a" type="main" coord="11,175.56,202.06,118.61,3.18;11,69.23,210.03,45.23,3.18">A Study of Neural Matching Models for Cross-lingual IR</title>
		<author>
			<persName coords=""><forename type="first">Puxuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,126.44,208.60,167.60,6.23;11,69.23,216.57,150.56,6.23">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1637" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,225.97,225.89,3.18;11,69.23,233.94,224.81,3.18;11,69.23,240.48,219.34,6.23" xml:id="b49">
	<analytic>
		<title level="a" type="main" coord="11,84.95,233.94,209.09,3.18;11,69.23,241.91,20.16,3.18">Rapidly Deploying a Neural Search Engine for the COVID-19 Open Research Dataset</title>
		<author>
			<persName coords=""><forename type="first">Edwin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikhil</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,101.61,240.48,171.30,6.23">Proceedings of the 1st Workshop on NLP for COVID-19 at ACL</title>
		<meeting>the 1st Workshop on NLP for COVID-19 at ACL</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,249.88,225.99,3.18;11,69.23,256.42,225.51,6.23;11,69.23,264.39,213.91,6.23" xml:id="b50">
	<analytic>
		<title level="a" type="main" coord="11,242.38,249.88,52.84,3.18;11,69.23,257.85,108.68,3.18">Mr. TyDi: A Multilingual Benchmark for Dense Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,189.89,256.42,104.85,6.23;11,69.23,264.39,86.97,6.23">Proceedings of 1st Workshop on Multilingual Representation Learning</title>
		<meeting>1st Workshop on Multilingual Representation Learning<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,273.79,224.81,3.18;11,69.23,280.33,224.81,6.23;11,69.03,289.74,18.66,3.18" xml:id="b51">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kelechi</forename><surname>Ogueji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02363</idno>
		<title level="m" coord="11,256.60,273.79,37.44,3.18;11,69.23,281.77,170.80,3.18">Towards Best Practices for Training Multilingual Dense Retrieval Models</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,69.23,297.71,225.99,3.18;11,69.23,304.24,224.81,6.23;11,69.03,313.65,18.66,3.18" xml:id="b52">
	<monogr>
		<title level="m" type="main" coord="11,190.45,297.71,104.77,3.18;11,69.23,305.68,173.73,3.18">Fast Passage Re-ranking with Contextualized Exact Term Matching and Efficient Passage Expansion</title>
		<author>
			<persName coords=""><forename type="first">Shengyao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.08513</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
