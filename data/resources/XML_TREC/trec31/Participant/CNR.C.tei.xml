<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,169.14,116.95,277.08,12.62;1,243.45,134.89,128.47,12.62;1,182.47,154.73,250.41,10.86">Context Propagation in Conversational Search Utterances Participation of the CNR Team in CAsT 2022</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,227.48,190.76,38.19,8.74"><forename type="first">Ida</forename><surname>Mele</surname></persName>
							<email>ida.mele@iasi.cnr.it</email>
							<affiliation key="aff0">
								<orgName type="institution">IASI-CNR</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.22,190.76,104.42,8.74"><forename type="first">Cristina</forename><forename type="middle">Ioana</forename><surname>Muntean</surname></persName>
							<email>cristina.muntean@isti.cnr.it</email>
							<affiliation key="aff1">
								<orgName type="institution">ISTI-CNR</orgName>
								<address>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.49,202.71,94.87,8.74"><forename type="first">Franco</forename><forename type="middle">Maria</forename><surname>Nardini</surname></persName>
							<email>francomaria.nardini@isti.cnr.it</email>
							<affiliation key="aff1">
								<orgName type="institution">ISTI-CNR</orgName>
								<address>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.91,202.71,67.28,8.74"><forename type="first">Raffaele</forename><surname>Perego</surname></persName>
							<email>raffaele.perego@isti.cnr.it</email>
							<affiliation key="aff1">
								<orgName type="institution">ISTI-CNR</orgName>
								<address>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,369.13,202.71,75.27,8.74"><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
							<email>nicola.tonellotto@unipi.it</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,169.14,116.95,277.08,12.62;1,243.45,134.89,128.47,12.62;1,182.47,154.73,250.41,10.86">Context Propagation in Conversational Search Utterances Participation of the CNR Team in CAsT 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D1CB0FA08870276119F29E3C06474933</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Every year, NIST organizes the Text REtrieval Conference (TREC) which gathers competitions for forecasting research on text retrieval. Since 2019, it has included a contest on conversational assistant systems, called Conversational Assistant Track (CAsT) with the purpose of helping research on conversational information systems. CAsT provides test collections for open-domain conversational seeking where the users can ask multiple questions to the system and get answers like in a multi-turn conversation. For our participation in CAsT 2022, we implemented an architecture consisting of two steps: utterance rewriting and passage retrieval. Each run is based on a different utterance rewriting technique for enriching the raw utterance with context extracted from the previous utterances and/or from the replies in the conversation. Three of our approaches are completely automatic, while another one uses the manually rewritten utterances provided by the organizers of TREC CAsT 2022.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Conversational Information Seeking (CIS) is an emerging area of research that poses new challenges in information retrieval both in terms of effectiveness <ref type="bibr" coords="1,470.07,537.56,10.52,8.74" target="#b6">[7]</ref> and efficiency <ref type="bibr" coords="1,198.90,549.52,9.96,8.74" target="#b1">[2]</ref>. The increasing popularity of CIS is due to the advances in automatic speech recognition and understanding tools that are largely employed in smart home assistants, smartphones, and wearable devices.</p><p>Thanks to TREC CAsT <ref type="bibr" coords="1,254.15,585.38,9.96,8.74" target="#b0">[1]</ref>, the researchers can experiment with their methodologies that aim to improve the automatic understanding of the users' requests and to find relevant responses using contextual information. The typical scenario is a conversational system that helps the user to fulfill her information need by answering vocal questions. The search goes on as a multi-turn dialogue between the user and the system, where the requests are often general and vague due to the ambiguity of natural language as well as the lacking of context. The missing context is often a subject mentioned before in the conversation (e.g., in the previous requests or replies), and the user refers to it indirectly with pronouns. The operation of adding context to ambiguous and incomplete requests is challenging due to the complexity of understanding the semantic meaning of previous questions and their answers. Furthermore, another challenge is represented by the fact that the system response is not just a list of relevant documents, but, rather it is constrained to a short text passage, which can be a summary of sentences extracted from the documents relevant to the user request. The text passage must be brief as it is returned to the user through a voice interface or a small screen of a mobile.</p><p>This year, CAsT proposes two tasks. The primary task is response retrieval focusing on providing fluent and relevant responses that may summarize more passages coming from different documents. Plus, a novel mixed-initiative subtask where, for each conversation turn, the system may reply to a user request or may ask a question for clarification. This question is chosen from a pool of questions for each turn, resulting in a dialogue tree representing all the possible conversations. Compared to last year, CAsT 2022 provides a series of text responses for each turn. Each response can be a passage or a summary generated from one or more passages and has at least one passage called provenance for evaluating the provenance ranking. Instead of one conversation per topic, each topic has multiple conversations and information needs on a shared topic (i.e., a dialogue tree). Lastly, the mixed-initiative sub-task evaluates the ability of systems to use mixed-initiative. As a consequence, CAsT allowed three submission classes: (1) automatic, where raw utterances are reformulated with automatic rewriting or expansion methods, (2) automatic MI, where the response ranking is from the mixed-initiative sub-task after using feedback, clarification, etc., and (3) manual, where human assessors manually rewrite raw utterances.</p><p>We only participate in the primary task for information-seeking conversations and submitted one manual run and 3 automatic runs explained in Sec. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>TREC CAsT 2022 has provided a dataset including evaluation topics (i.e., search conversations), a mixed-initiative question pool for the mixed-initiative subtask, and three document collections.</p><p>For each evaluation topic, CAsT 2022 provides a dialogue tree representing all possible conversations between the user and the system.</p><p>The three document collections are: The core task of the system is to return a response after every turn using context extracted from the previous-turn utterances or replies. For each turn, the system returns a response that is fluent and suitable for the users. It should not contain irrelevant information or repetitions, and it should be short so that it can be shown on a small screen or read vocally to the user (e.g., response text is limited to a maximum of 250 words as measured by SpaCy v3.3). Each response can have one or more source passages as provenance and this information is used for evaluating the retrieval performance of the system.</p><p>The documents are split into passages (up to 250 words), and the passage segmentation is performed using SpaCy's SentenceRecognizer pipeline component for sentence detection with a fixed non-overlapping passage size. CAsT organizers gave to the participants the option of processing the collection themselves to generate passage splits using the provided tools or requesting the processed corpus from the organizers. We requested the processed corpus and run our experiments on it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodologies</head><p>Our framework consists of two steps: utterance rewriting and passage retrieval. All our methods rely on a Python NLP toolkit for extracting various linguistic features from the utterances <ref type="bibr" coords="3,263.10,347.27,9.96,8.74" target="#b2">[3]</ref>. We perform utterance rewriting to enrich the raw utterance with the missing context, then we use the rewritten utterances to retrieve the passages. For indexing and querying the collections, we used PyTerrier 0.7.1, based on Terrier 5.6, employing traditional unsupervised sparse retrieval (e.g., DPH hypergeometric weighting model).</p><p>We assume that a user has an information need that intends to fulfill by asking questions (a.k.a. utterances) to a conversational search system. A raw utterance, u i , represents the natural language question issued by the user to the system. This is the input of our automatic utterance rewriting module whose output is an enriched utterance, ûi , used to retrieve passages from the document collections. The purpose of the utterance rewriting module is to add missing context to the raw utterance so that the user can get a good answer to her request. Our runs are inspired by our previous works on topic propagation in multi-turn conversational searches <ref type="bibr" coords="3,286.95,503.06,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="3,298.76,503.06,7.01,8.74" target="#b4">5]</ref>.</p><p>-CNR-run1. This run automatically rewrites the current utterance by adding the topics extracted from the previous automatically rewritten utterance provided by CAsT 2022. -CNR-run2. This run adds to the current utterance the topics extracted from the previous manually rewritten utterance provided by CAsT 2022. -CNR-run3. This run enriches the current utterance with the first sentence of the response to the previous utterance. -CNR-run4. This run enriches the current utterance with the top-5 frequent terms extracted from the response to the previous utterance.</p><p>In all our runs, the topics are extracted from utterances using SpaCy noun chunks (objects or subjects).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>CAsT 2022 provided for the runs two different evaluations: a lenient evaluation where passages at least "slightly meet" the need of the request at that turn (relevance level 1), and a strict evaluation where passages must "moderately meet" the need of the request at that turn (relevance level 2).</p><p>In Table <ref type="table" coords="4,190.77,189.04,3.87,8.74" target="#tab_0">1</ref>, we report the values of the Mean Average Precision (MAP) and the normalized Discounted Cumulative Gain (nDCG@20) for our four runs. Plus, we report the worst, median, and best performances provided by CAsT 2022 for each query and averaged over all the queries.</p><p>As expected, the worst results are achieved by CNR-run1 as it enriches the current utterance with context extracted from the previous automatically rewritten utterance, and it does not take into account the response. On the other hand, CNR-run2 performs pretty well as it uses context from the previous manually rewritten utterance provided by CAsT 2022. We can also notice that the values of nDCG@20 achieved by our runs are close to the median values. Overall, this performance could benefit from a further step of re-ranking. Re-ranking. We used the model by Nogueira and Cho <ref type="bibr" coords="4,376.06,485.53,10.52,8.74" target="#b5">[6]</ref> to re-rank the results from the previous stage. The model fine-tunes the BERT base pre-trained model for re-ranking on the MSMARCO passage retrieval dataset. For each query, we used as input for the re-ranking step the top 200 results. The performance of our runs after re-ranking is shown in Table <ref type="table" coords="4,325.46,533.35,3.87,8.74" target="#tab_1">2</ref>. We have presented the methodologies implemented for our participation in CAsT 2022. Our approaches aim to enrich the raw utterances using topical keywords extracted from the previous utterances or from their responses.</p><p>As future work we would like to improve the utterance-dependency understanding in order to better capture the dependencies between the current utterance and those of the previous turns as well as their responses with the purpose of improving the automatic rewriting and enrichment of raw utterances.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,303.69,573.22,186.50,8.74;2,134.77,585.17,345.82,8.74;2,134.77,597.13,345.83,8.74;2,134.77,609.09,345.82,8.74;2,134.77,621.04,345.82,8.74;2,134.77,633.00,101.04,8.74"><head>( 1 )</head><label>1</label><figDesc>KILT Wikipedia dump from 2019/08/01 consisting of 5M articles, (2) MS MARCO V2 document corpus used in the 2021 TREC Deep Learning Track and consisting of 11.9M documents from Bing search, and (3) TREC Washington Post collection (V4 2020) consisting of 728,626 news articles from 2012 to 2020 (this data requires a signed license agreement with NIST).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,170.50,333.07,274.37,129.77"><head>Table 1 .</head><label>1</label><figDesc>Performance of CAsT 2022 runs: averaged over all queries</figDesc><table coords="4,183.88,357.05,238.38,105.79"><row><cell></cell><cell></cell><cell>Lenient</cell><cell></cell><cell>Strict</cell></row><row><cell></cell><cell>MAP</cell><cell>nDCG@20</cell><cell>MAP</cell><cell>nDCG@20</cell></row><row><cell>CNR-run1</cell><cell>0.0796</cell><cell>0.1524</cell><cell>0.0593</cell><cell>0.1524</cell></row><row><cell>CNR-run2</cell><cell>0.0951</cell><cell>0.1832</cell><cell>0.0758</cell><cell>0.1832</cell></row><row><cell>CNR-run3</cell><cell>0.0867</cell><cell>0.1671</cell><cell>0.0679</cell><cell>0.1671</cell></row><row><cell>CNR-run4</cell><cell>0.0843</cell><cell>0.1710</cell><cell>0.0717</cell><cell>0.1710</cell></row><row><cell>Avg-Min</cell><cell>0.018</cell><cell>0.035</cell><cell>0.012</cell><cell>0.035</cell></row><row><cell cols="2">Avg-Median 0.176</cell><cell>0.320</cell><cell>0.147</cell><cell>0.320</cell></row><row><cell>Avg-Max</cell><cell>0.439</cell><cell>0.667</cell><cell>0.426</cell><cell>0.667</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,181.52,557.84,247.30,80.94"><head>Table 2 .</head><label>2</label><figDesc>Performance of our runs after re-ranking</figDesc><table coords="4,181.52,582.47,247.30,56.31"><row><cell>MAP</cell><cell>nDCG@20</cell><cell>recip-rank</cell><cell>P@1</cell></row><row><cell>CNR-run1 0.0844</cell><cell>0.1847</cell><cell>0.5069</cell><cell>0.4198</cell></row><row><cell>CNR-run2 0.1037</cell><cell>0.2200</cell><cell>0.5730</cell><cell>0.4568</cell></row><row><cell>CNR-run3 0.0875</cell><cell>0.1917</cell><cell>0.5222</cell><cell>0.4259</cell></row><row><cell>CNR-run4 0.0802</cell><cell>0.1851</cell><cell>0.5051</cell><cell>0.4074</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,271.11,179.33,8.12" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Trec Cast</surname></persName>
		</author>
		<ptr target="http://www.treccast.ai/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,282.07,342.24,7.86;5,146.91,293.02,333.67,7.86;5,146.91,303.98,84.90,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,146.91,293.02,227.24,7.86">Caching historical embeddings in conversational search</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">I</forename><surname>Muntean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,386.28,293.02,71.49,7.86">ACM Trans. Web</title>
		<imprint>
			<date type="published" when="2022-12">dec 2022</date>
		</imprint>
	</monogr>
	<note>Just Accepted</note>
</biblStruct>

<biblStruct coords="5,138.35,314.94,271.56,8.12" xml:id="b2">
	<monogr>
		<ptr target="https://spacy.io/usage/linguistic-features" />
		<title level="m" coord="5,146.91,314.94,54.56,7.86">SpaCy library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,325.90,342.24,7.86;5,146.91,336.86,333.68,7.86;5,146.91,347.82,48.38,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,146.91,336.86,181.52,7.86">Topic Propagation in Conversational Search</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">I</forename><surname>Muntean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,353.60,336.86,47.75,7.86">SIGIR 2020</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2057" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,358.78,342.24,7.86;5,146.91,369.74,333.68,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,146.91,369.74,214.23,7.86">Adaptive utterance rewriting for conversational search</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">I</forename><surname>Muntean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,378.69,369.74,37.75,7.86">IPM 2021</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,380.70,342.24,7.86;5,146.91,391.65,97.10,7.86" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="5,270.20,380.70,132.91,7.86">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,138.35,402.61,342.25,7.86;5,146.91,413.57,193.78,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Trippas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08808</idno>
		<title level="m" coord="5,370.80,402.61,109.80,7.86;5,146.91,413.57,27.60,7.86">Conversational information seeking</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
