<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,234.59,17.85,140.46,23.06;1,80.20,55.87,449.03,17.27">IIT at TREC 2004 Standard Retrieval Models over Partitioned Indices for the Terabyte Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,116.26,85.23,84.60,14.80"><forename type="first">Jefferson</forename><surname>Heard</surname></persName>
							<email>heard@ir.iit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Technology Chicago</orgName>
								<orgName type="laboratory">Information Retrieval Laboratory Illinois</orgName>
								<address>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.83,85.23,70.01,14.80"><forename type="first">Ophir</forename><surname>Frieder</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Technology Chicago</orgName>
								<orgName type="laboratory">Information Retrieval Laboratory Illinois</orgName>
								<address>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,406.72,85.23,88.70,14.80"><forename type="first">David</forename><surname>Grossman</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Technology Chicago</orgName>
								<orgName type="laboratory">Information Retrieval Laboratory Illinois</orgName>
								<address>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,234.59,17.85,140.46,23.06;1,80.20,55.87,449.03,17.27">IIT at TREC 2004 Standard Retrieval Models over Partitioned Indices for the Terabyte Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8E899F409A0C9A1D23B4524BCE95FA6E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For TREC-2004, we participated in the Terabyte track. We focused on partitioning the data in the GOV2 collection across a homogeneous cluster of machines and indexing and querying the collection in a distributed fashion using different standard retrieval models on a single system, such as the Robertson BM25 probabilistic measure and a vector space measure. Our partitioned indices were each independent of each other, with independent collection statistics and lexicons. We combined the results as if all indices were the same, however, not weighing any one result set more or less than another.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>For the TREC 2004 Terabyte track, we focused on indexing and querying the data with our existing AIRE engine <ref type="bibr" coords="1,53.80,361.26,9.20,8.97" target="#b3">[3]</ref>. We partitioned the 480GB GOV2 data across fourteen machines and built independent indices for each segment. We then analyzed the statistics for each of these independent indices to make sure that the collections were roughly equal in size and characteristics. After satisfying ourselves that this was the case, we issued each query on each system and combined the results to get the required number of documents for each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The hardware for our tests consisted of fourteen machines networked on a dedicated switch. Each machine was equipped with 2 10,000 RPM 78 GB SCSI drives, 2 AMD K7 Athlon MP 2400+ processors, 2GB of RAM, and RedHat Linux Advanced Server 2.1. The indexing of the system was done using the BEA JRockit JVM, while the querying was done using the Sun JDK 1.4.2 04. The system for this set of experiments was very much like last year's, with no changes introduced in order to be able to index or query the large amount of data needed for the Terabyte track.</p><p>The indexing engine was set up in as simple a way as possible to ensure maximum indexing speed and that it would run to completion. No stemming was done, nor was any link information or entity extraction mechanism used. Phrasing was used, with a limit of two words per phrase and a minimum of 25 occurrences of a phrase to be entered in the lexicon.</p><p>The data was partitioned out across each machine roughly equally, and left compressed in gzip format. No directory in the collection was split out across two separate machines, however. Documents were chosen for each machine by picking directories of the GOV2 collection sequentially as listed by ls and trying to fit them together so that each machine had roughly 34GB of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Querying</head><p>The query engine was set up to do no stemming nor use any link information. We ran two query runs: one with the IIT vector-space similarity function <ref type="bibr" coords="1,467.15,298.99,9.20,8.97" target="#b3">[3]</ref>, and one with the Robertson BM25 probabilistic similarity function <ref type="bibr" coords="1,519.15,309.45,9.20,8.97" target="#b4">[4]</ref>. Only the query title was included in the query.</p><p>Since all queries were issued to each machine, we needed a way to combine the the independent results to come up with one master result set. Since the sets of collection statistics were similar, we decided to treat each result set equally for each query and combine them by simply concatenating the results and sorting them based on non-normalized relevance score, as in the section on "perfect merge" in <ref type="bibr" coords="1,543.42,393.14,9.20,8.97" target="#b1">[1]</ref>. Not normalizing the score was important, since normalizing would have caused the top documents from each index to be treated equally by virtue of having the highest score for the index rather than the highest score overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing</head><p>Indexing the entire GOV2 collection took 8.2 hours from the first machine to start until the last machine to end. Each index was approximately 4GB in total. The lexicon took up an average of 260 MB, while the posting lists took an average of 3.05GB. The document data averaged 600 MB. Each lexicon had between 5.8 and 6.9 million words, between 1.4 and 1.8 million phrases. Standard deviation was 5% of the mean number of words for all lexica on all machines, and 7% for phrases. For document count and posting entry count, the deviation was a mere 2% of the mean number of documents. The average number of distinct terms per document in the collection (see Table <ref type="table" coords="1,471.76,608.39,4.09,8.97" target="#tab_1">2</ref>) was similar across the cluster, with a meager standard deviation of 7 versus a mean of 221.53 distinct terms per document. Similarly, the average total number of terms per document varies only slightly across collections.</p><p>The only statistics that really vary widely are the maxi- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Querying</head><p>Querying the whole collection took one hour from the first machine to start until the last machine to end. Query performance was hampered by the fact that a configuration error caused the entire lexicon to be loaded into memory. This caused our memory footprint for the query engine to jump to around 1.6GB -almost the full extent of RAM. Since this meant that garbage collection had to be done for almost every posting list, each query took between 15 seconds and 5 minutes to perform, when retrieving the top 10,000 documents. Subsequent experiments with the lexicon in the proper format confirm that when our system is configured optimally, the memory footprint and query timings are much more reasonable, 160MB heap size and around 5 seconds per query. However this mistake confirms that it is, if not practical, possible to load the entire lexicon into memory at once for such a large collection.</p><p>Most query result sets on the individual machines provided the maximum number of scored documents each, 10,000. After the query engines on each machine finished, we copied the results to a single machine and used the UNIX sort utility to combine them, and then a short perl script to delete any results beyond the 10,000 highest ranked for each query. This process took 15 minutes for the entire result set. The simple vector-space and probability rankings with no relevance feedback returned enough results that only one query had few (less than 3,000) results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSIONS</head><p>In our experimental runs for this year's Terabyte track, we distributed the collection across a homogenous cluster and treated each node in the cluster has having an independent index. We then ran probabilistic and vector space models and merged the independent results on each node as if they were one result set in order to create two master result sets: one for the probabilistic model and one for the vector space model. In the future, we will experiment with creating a consolidated collection statistics structure and lexicon with the intent of providing the same relevance rankings for any document regardless of which sub-index it is found in. We will also experiment with different document distributions to see if term statistics change noticeably for a round-robin or random distribution of documents across our cluster and if this changes our effectiveness score. We will also work to make sure that relevance feedback is available in our next year's track.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,142.07,13.81,325.44,69.94"><head>Table 1 :</head><label>1</label><figDesc>Mean Collection Statistics Across All Indices</figDesc><table coords="2,142.07,22.08,325.44,61.67"><row><cell></cell><cell>num docs</cell><cell cols="3">num ents max(nidf) min(nidf)</cell><cell cols="2">words phrases</cell></row><row><cell>Max</cell><cell cols="2">1795443 400094218</cell><cell>14.4</cell><cell cols="3">0.79 6924754 1816753</cell></row><row><cell>Min</cell><cell cols="2">1631840 377033932</cell><cell>14.31</cell><cell cols="3">0.7 5820360 1479404</cell></row><row><cell>Mean</cell><cell cols="2">1743419 385991502</cell><cell>14.37</cell><cell cols="3">0.74 6348646 1633945</cell></row><row><cell>Max-Min</cell><cell>163603</cell><cell>23060286</cell><cell>0.1</cell><cell cols="2">0.09 1104394</cell><cell>337349</cell></row><row><cell>Std Dev</cell><cell>43443</cell><cell>7832298</cell><cell>0</cell><cell>0</cell><cell>340602</cell><cell>112354</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,53.80,105.91,452.08,174.60"><head>Table 2 :</head><label>2</label><figDesc>Mean Term Statistics Across All Indices avg dist terms min dist terms max dist terms avg terms min terms max terms</figDesc><table coords="2,53.80,125.04,452.08,155.47"><row><cell>Max</cell><cell>239.53</cell><cell>0</cell><cell>38249</cell><cell>960.24</cell><cell>0</cell><cell>84337</cell></row><row><cell>Min</cell><cell>213.79</cell><cell>0</cell><cell>17788</cell><cell>804.15</cell><cell>0</cell><cell>61069</cell></row><row><cell>Mean</cell><cell>221.53</cell><cell>0</cell><cell>23642.73</cell><cell>857.42</cell><cell>0</cell><cell>68056.33</cell></row><row><cell>Max-Min</cell><cell>25.74</cell><cell>0</cell><cell>20461</cell><cell>156.09</cell><cell>0</cell><cell>23268</cell></row><row><cell>Std Dev</cell><cell>7</cell><cell>0</cell><cell>5774</cell><cell>46</cell><cell>0</cell><cell>6970</cell></row><row><cell cols="3">mum terms per document and maximum number of distinct</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">terms per document. Most indexes have in the 60,000-70,000</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">range for maximum non-distinct terms, with two machines</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">having a maximum of 83-84,000. The global maximum for</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">number of non-distinct terms in a document was 84,337</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">terms. Considering that the average number of terms in</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">a document was only 857 terms, this would suggest that</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">long documents were spread across the cluster fairly evenly.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">ACKNOWLEDGEMENTS</head><p>Special thanks to <rs type="person">Tristan Sloughter</rs> (<rs type="affiliation">IIT Information Retrieval Lab</rs>) for his work in distributing data and running tests tirelessly.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="2,321.28,379.87,96.71,15.55" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="2,331.01,397.77,195.50,8.97;2,331.02,408.23,187.02,8.97;2,331.02,418.69,67.08,8.97" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="2,383.26,397.77,143.25,8.96;2,331.02,408.23,31.88,8.96">Methods for distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>The Australian National University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="2,331.01,430.15,201.77,8.97;2,331.02,440.61,221.11,8.97;2,331.02,451.07,220.54,8.97;2,331.02,461.53,199.96,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="2,501.49,440.61,50.64,8.97;2,331.02,451.07,139.33,8.97">IIT TREC-9 -entity based feedback with fusion</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mccabe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Beitzel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saelee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,488.72,451.07,62.84,8.96;2,331.02,461.53,128.15,8.96">Overview of the Ninth Text Retrieval Conference</title>
		<imprint>
			<date type="published" when="2000-11">November 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,331.01,472.99,209.60,8.97;2,331.02,483.45,193.00,8.97;2,331.02,493.91,189.80,8.97;2,331.02,504.37,135.87,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="2,505.57,472.99,35.04,8.97;2,331.02,483.45,193.00,8.97;2,331.02,493.91,41.04,8.97">Okapi at TREC-7: Automatic ad hoc, filtering, VLC and interactive</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,390.39,493.91,130.43,8.96;2,331.02,504.37,83.29,8.96">Proceeedings of the Seventh Text Retrieval Conference</title>
		<meeting>eeedings of the Seventh Text Retrieval Conference</meeting>
		<imprint/>
	</monogr>
	<note>TREC) [5</note>
</biblStruct>

<biblStruct coords="2,331.01,515.83,214.76,8.97;2,331.02,526.29,174.33,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="2,400.66,515.83,145.11,8.97;2,331.02,526.29,8.44,8.97">The probability ranking principle in IR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="2,346.75,526.29,103.46,8.96">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
