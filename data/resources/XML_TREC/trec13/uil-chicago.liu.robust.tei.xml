<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,203.04,83.12,205.70,15.41">UIC at TREC-2004: Robust Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,208.56,113.68,46.53,11.42"><forename type="first">Shuang</forename><surname>Liu</surname></persName>
							<email>sliu@cs.uic.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Database and Information System Lab Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.56,113.68,54.78,11.42"><forename type="first">Chaojing</forename><surname>Sun</surname></persName>
							<email>csun@cs.uic.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Database and Information System Lab Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.56,113.68,50.53,11.42"><forename type="first">Clement</forename><surname>Yu</surname></persName>
							<email>yu@cs.uic.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Database and Information System Lab Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,203.04,83.12,205.70,15.41">UIC at TREC-2004: Robust Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F0EF9ECEBD87A7C62AB56DDCE39782D0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2004, the Database and Information System Lab (DBIS) at University of Illinois at Chicago (UIC) participates in the robust track, which is a traditional ad hoc retrieval task. The emphasis is based on average effectiveness as well as individual topic effectiveness.</p><p>In our system, noun phrases in the query are identified and classified into 4 types: proper names, dictionary phrases, simple phrases and complex phrases. A document has a phrase if all content words in a phrase are within a window of a certain size. The window sizes for different types of phrases are different. We consider phrases to be more important than individual terms. As a consequence, documents in response to a query are ranked with matching phrases given a higher priority. WordNet is used to disambiguate word senses. Whenever the sense of a query term is determined, its synonyms, hyponyms, words from its definition and its compound concepts are considered for possible additions to the query. The newly added terms are used to form phrases during retrieval. Pseudo feedback and web-assisted feedback are used to help retrieval. We submit one title run this year.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Our recent work <ref type="bibr" coords="1,141.23,441.71,28.67,10.89" target="#b10">[LL04]</ref> shown that phrase and word sense disambiguation can help improve retrieval effectiveness in text retrieval. Component content words in a phrase can be used to disambiguate other component words in the same phrase. This allows selective synonyms, hyponyms, words from the definition, and compound concepts to be added for improving retrieval results.</p><p>To recognize different type of phrases, the strengths of several existing software and dictionary tools, namely Minipar [Lin94, Lin98], Brill's tagger <ref type="bibr" coords="1,228.20,533.87,23.95,10.89">[Brill]</ref>, Collins' parser <ref type="bibr" coords="1,320.84,533.87,32.84,10.89" target="#b3">[Coll97,</ref><ref type="bibr" coords="1,356.68,533.87,28.74,10.89" target="#b4">Coll99]</ref>, WordNet <ref type="bibr" coords="1,432.39,533.87,32.02,10.89" target="#b5">[Fell98]</ref> and web feedback are fully utilized. Furthermore, additional techniques are introduced to improve the accuracy of recognition.</p><p>The recognition of each type of phrases in documents is dependent on having windows of different sizes. Specifically, a proper noun would have the component words in adjacent locations; a dictionary phrase in a document may have its component content words separated by a distance of no more than w1 words; a simple phrase in a document may have its component content words separated by a distance of no more than w2 words, with w2 &gt; w1; similarly, a window containing the component content words of a complex phrase should have a size no larger than w3, with w3 &gt; w2.</p><p>We consider phrases to be more important than individual content words when retrieving documents <ref type="bibr" coords="1,480.32,683.87,28.90,10.89" target="#b11">[LY03,</ref><ref type="bibr" coords="1,512.18,683.87,23.18,10.89" target="#b10">LL04]</ref>.</p><p>Consequently, the similarity measure between a query and a document has two components (phrase-sim, term-sim), where phrase-sim is the similarity obtained by matching the phrases of the query against those in the document and term-sim is the usual similarity between the query and the document based on term matches. The latter similarity can be computed by the standard Okapi similarity function <ref type="bibr" coords="2,315.63,82.43,30.10,10.89" target="#b14">[RW00]</ref>. Documents are ranked in descending order of (phrase-sim, term-sim). That is, documents with higher phrase-sim will be ranked higher. When documents have the same phrase-sim, they will be ranked according to term-sim.</p><p>WordNet is used for word sense disambiguation. For words in one phrase or adjacent query words, the following information from WordNet is utilized: synonym sets, hyponym sets, and their definitions. When the sense of a query word is determined, its synonyms, words or phrases from its definition, its hyponyms and its compound concepts are considered for possible addition to the query. If a synonym, hyponym, word/phrase in the definition of a synonym set, or compound concept is brought in by a query term and this term forms a phrase with some other query terms, new phrases can be generated.</p><p>Feedback terms are brought in by pseudo-feedback <ref type="bibr" coords="2,284.06,249.71,29.87,10.89" target="#b11">[LY03]</ref> and web-assisted feedback <ref type="bibr" coords="2,428.63,249.71,32.33,10.89" target="#b7">[GW03,</ref><ref type="bibr" coords="2,464.27,249.71,24.67,10.89" target="#b16">YC03]</ref>. Additional weights are assigned to the top ranked feedback terms, if they can be related to the original query terms through different WordNet relations.</p><p>In the remaining part of this paper, how phrases in a query are recognized and how they are classified into different types are discussed in section 2. Section 3 presents how WordNet can be utilized to disambiguate word sense and bring in new terms. Section 4 describes pseudo feedback and web-assisted feedback, and how we assign weights to terms brought in by feedbacks. In section 5 we analyze the run we submitted this year. Section 6 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Phrase Recognition</head><p>Noun phrases in a query are classified into proper names, dictionary phrases, simple phrases and complex phrases.</p><p>Existing tools including Brill's tagger, Minipar, Collins' parser, WordNet and web retrieval feedback are used to recognized different type of phrases. They are utilized in such a way that their strengths are fully made use of.</p><p>Proper nouns include names of people, organizations, places etc. Dictionary phrases are noun phrases which can be found in a dictionary such as WordNet. A simple phrase contains exactly two content words. A complex phrase contains three or four content words. Phrases involving more than four content words are unlikely to be useful in document retrieval, as very few, if any, documents contain all these content words. The four types of phrases are ordered from low to high, for example proper noun is the lowest type. If a phrase belongs to multiple types, it will be classified to the lowest type of the four types indicated above. For example, if a simple phrase is a dictionary phrase, then it is classified as a dictionary phrase.</p><p>In the phrase recognition system, Brill's tagger is used to assign a Part-of-Speech (POS) to each query word. The name entity finder Minipar is used for the purpose of recognition of proper nouns. The Collins' parser is used to obtain a parse tree for a query and the base noun phrases discovered by Collins' parser are used in further detailed analysis. We use WordNet to recognize dictionary phrases and some proper nouns; additionally, web retrieval feedback provides more contexts for short queries.</p><p>To recognize phrases in a query, the query is first fed into Minipar for proper name recognition. Next, each word in a query is assigned a POS by using Brill's tagger, After the query is parsed by Collins' parser <ref type="bibr" coords="3,469.95,82.43,33.23,10.89" target="#b3">[Coll97,</ref><ref type="bibr" coords="3,506.84,82.43,29.08,10.89" target="#b4">Coll99]</ref>, certain noun phrases are recognized as base noun phrases that is they cannot be decomposed by Collins' parser. A base noun phrase may be decomposed into smaller phrases using Minipar or by a statistical analysis process. Each noun phrase which is recognized by Collins' parse or by the statistical analysis process is passed to WordNet for further proper noun or dictionary phrase recognition. A noun phrase which is not a proper noun or a dictionary phrase is classified to be a simple phrase or a complex phrase based on the number of content words it contains.</p><p>Phrases which are coordinate noun phrases (involving "and" or "or") or have embedded coordinate noun phrases are processed to yield implicit phrases. For example, in the phrase "physical or mental impairment", "physical impairment" is an implicit phrase. These newly generated phrases also undergo a similar procedure to determine its type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Word Sense Disambiguation</head><p>Word sense disambiguation makes use of content words in the same phrase or adjacent words in the query. When a given query q is parsed, the POS of each word as well as the phrases in q are recognized. Suppose two adjacent terms t 1 and t 2 in q form a phrase p. From WordNet, the following information can be obtained. Each of t 1 and t 2 has (I) one or more synsets; (II) a definition for each synset in (I); (III) one or more hyponym synsets of each synset in (I) (containing IS-A relationships; for example, the synset {male child, boy} is a hyponym synset of {male, male person}); (IV) definitions of the synsets of the hyponyms in (III). Suppose S i is a synset of t i ; SD i is the definition of</p><formula xml:id="formula_0" coords="3,72.00,394.43,237.90,11.61">S i ; H i is a hyponyms synset of S i ; HD i is the definition of H i .</formula><p>These four items (I), (II), (III) and (IV) can be used in 16 disambiguation rules. During disambiguation, conflicts may arise if different rules determine different senses for a query word. Experimental data provide some relative degrees of accuracy or weights of the individual rules. If multiple rules determine different senses for a word, then the sense of the word is given by the set of rules with the highest sum of weights, which determines the same sense for the word. Terms are added to the query after word sense disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Disambiguation Rules</head><p>Rule 1. If S 1 and S 2 ---synsets of t 1 and t 2 ---have synonyms in common and S 1 and S 2 have the same POS, then S 1 is determined to be the sense of t 1 and S 2 is determined to be the sense of t 2 .</p><p>Rule 2. If t, a synonym of t 1 (other than t 1 ) in synset S 1 , is found in SD 2 , and t has the same POS in both S 1 and SD 2 , S 1 is determined to be the sense of t 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 3.2: A query is "pheromone scents work". A synset of the verb "work" is {influence, act upon, work}.</head><p>"influence" is in the definition of "pheromone", which is "a chemical substance secreted externally by some animals (especially insects) that influences the physiology or behavior of other animals of the same species". The word "influence" is a verb in both the synset {influence, act upon, work} and the definition of "pheromone". Rule 3. If t, a synonym of t 1 (other than t 1 ) in synset S 1 , is found in H 2 or S 1 and H 2 are the same synset and S 1 and H 2 have the same POS, then S 1 is determined to be the sense of t 1 .</p><p>Example 3.3: A query is "Greek philosophy stoicism", a synset of "stoicism" is a hyponym synset of "philosophy"; "philosophy" and "stoicism" have the same POS. The sense of "stoicism" is determined.</p><p>Rule 4. If t, a synonym of t 1 (other than t 1 ) in synset S 1 , is found in HD 2 and t has the same POS in both S 1 and HD 2 , S 1 is determined to be the sense of t 1 .</p><p>Example 3.4: A query is "Toronto Film Awards". A synonym "motion picture" in a synset of "film" appears in the definition of "Oscar" ---a hyponym of "award". The POSs of "motion picture" in the definition and in the synset of "film" are the same. Thus, the sense of film is determined.</p><p>Rule 5. If SD 1 contains t 2 or synonyms of t 2 and t 2 or each synonym of t 2 in SD 1 has the same POS with t 2 . Then S 1 is determined to be the sense of t 1 .</p><p>Example 3.5: Suppose a query contains the phrase "incandescent light". In WordNet, the definition of a synset of "incandescent" contains the word "light". Thus, this synset of "incandescent" is used. Rule 6. If SD 1 and SD 2 have the maximum positive number of content words in common, and for each common word, it has the same POS in SD 1 and SD 2 , then the senses of t 1 and t 2 are S 1 and S 2 respectively.</p><p>Example 3.6: Suppose a query is "induction and deduction". Each of the two terms has a number of senses. The definitions of the two terms which have the maximum overlap of two content words, namely "general" and "reasoning" are their determined senses. For "induction" and "deduction", the definitions of the determined synsets are "reasoning from detailed facts to general principles" and "reasoning from the general to the particular (or from cause to effect)", respectively. Rule 7. If SD 1 contains the maximum positive number of content words being hyponyms of S 2 , and for each of these contained words in SD 1 , it has the same POS in SD 1 and hyponyms synsets of S 2 , then S 1 is determined to be the sense of t 1 .</p><p>Example 3.7: This is a continuation of Example 3.3. The definition of synset 2 of "stoicism" is "the philosophical system of the Stoics following the teachings of the ancient Greek philosopher ZenoContain" which contains "teaching" ---a hyponym of "philosophy", so the sense of "stoicism" can also be determined by this rule.</p><p>Rule 8. If SD 1 has the maximum positive number of content words with the hyponyms synsets' definitions of S 2 , and for each common word between SD 1 and some hyponyms synset definition of t 2 , it has the same POS in both definitions, then S 1 is determined to be the sense of t 1 .</p><p>Example 3.8: A query is "Iraq Turkey water". The definition of a synset of Turkey has the common word "Asia" with the definitions of "Black Sea" and "Euxine Sea", where "Black Sea" and "Euxine Sea" are hyponyms of "water", so the sense of "Turkey" can be determined.</p><p>Rule 9. If S 1 has the maximum positive number of hyponyms synsets which have common synonyms with S 2 or H 1 and S 2 are the same synset and S 1 and S 2 have the same POS, the sense of t 1 is determined to be S 1 .</p><p>Example 3.9: A query is "Tobacco cigarette lawsuit", where synset {butt, cigarette, cigaret, coffin mail, fag} is a hyponym synset of a sense of "tobacco", and they are all nouns, so the sense of "Tobacco" is determined.</p><p>Rule 10. If S 1 has the maximum positive number of hyponyms synsets which have synonyms appearing in SD 2 , and for each H 1 having synonyms appearing in SD 2 , the POSs of the matching content words are the same, then the sense of t 1 is determined to be S 1 .</p><p>Example 3.10: A query is "heroic acts". "Action" is in a hyponyms synset of the second sense of "act". "Action" also appears in the definition of a sense of "heroic", which is "showing extreme courage; especially of actions courageously undertaken in desperation as a last resort". So the sense of "act"and the sense of "heroic"are determined.</p><p>Rule 11. If S 1 has the maximum positive number of hyponyms synsets which have common synonyms with S 2 's hyponym synsets, and hyponym synsets of S 1 and hyponym synsets of S 2 have the same POS, then the sense of t 1 is determined to be S 1 .</p><p>Example 3.11: This is a continuation of Example 3.9, where "Tobacco" and "cigarette" have common hyponyms, so the sense of both words can be determined.</p><p>Rule 12. If S 1 has the maximum positive number of hyponym synsets which have synonyms appearing in the definition of S 2 's hyponym synsets and for each H 1 having synonyms appearing in HD 2 , the POSs of the synonyms' content words are the same as they are in H 1 , then the sense of t 1 is determined to be S 1 .</p><p>Example 3.12: A query is "alcohol consumption", a hyponym "drinking" of a sense of "consumption" appears in several definitions of hyponym synsets of "alcohol", such as "brew", "brewage", so the sense of "consumption" is determined.</p><p>Rule 13. If S 1 has the maximum positive number of hyponym synsets whose definitions contain t 2 or its synonym in some synset, say S 2 , and for each HD 1 containing synonyms of t 2 , every contained synonym has the same POS in both HD 1 and S 2 , then the sense of t 1 is determined to be S 1 .</p><p>Example 3.13: Suppose the query is "tropical storm". A hyponym of the synset {storm, violent storm} is "hurricane" whose definition contains the word "tropical". As a result, the sense of "storm" is determined. Rule 14. If S 1 has the maximum positive number of hyponym synsets whose definitions have content words in common with SD 2 , and for each HD 1 and SD 2 having words in common, a common word has the same POS in both HD 1 and SD 2 , then the sense of t 1 is determined to be S 1 .</p><p>Example 3.14: A query is "transportation tunnel disaster". "Tunnel" is used to disambiguate the senses of "transportation". The first sense of "transportation" has a hyponym synset {mass rapic transit, rapid transit} whose definition has the common word "underground" with the first definition of "tunnel". As a result, the sense of "transportation" is determined.</p><p>Rule 15. If S 1 has the maximum positive number of hyponym synsets whose definitions contain S 2 's hyponyms, and for each HD 1 containing synonyms in H 2 , a contained word has the same POS in HD 1 and H 2 , the sense of t 1 is determined to be S 1 .</p><p>Example 3.15: A query is "foreclose on property"; "salvage" is a hyponym of sense 2 of "property", whose definition contains verb "save" which is a troponym of "foreclose". (troponym is the hyponym of the verb), so the sense of "property" is determined.</p><p>Rule 16. If S 1 has the maximum positive number of hyponyms synsets whose definitions have content words in common with hyponyms synsets's definitions of S 2 , and for each HD 1 and HD 2 having common words, a common word has the same POS in both HD 1 and HD 2 , then the sense of t 1 is determined to be S 1 .</p><p>Example 3.16: A query is "cancer cell reproduction"; "lymphoma" is a hyponym of "cancer", "osteoclast" is a hyponym of cell,and their definitions have the common word "tissue", so the sense of cancer and cell can be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Choosing Word Sense</head><p>An ambiguous word may have multiple senses when different rules are applied. An algorithm is developed to select the best sense from the multiple choices. In this algorithm we first assign different degree of accuracies or weights to different rules based on historical data. The weight of each rule w Rj is given in Table <ref type="table" coords="6,406.31,296.03,3.83,10.89">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Query Expansion by Using WordNet</head><p>Whenever the sense of a given term is determined to be the synset S, its synonyms, words or phrases from its definition, its hyponyms and compound words (see case (4)) of the given term are considered for possible addition to the query as shown in the following four cases, respectively. Additionally, terms t 1 and t 2 in q are adjacent and they form a phrase p.</p><p>(1) Add Synonyms.</p><p>Whenever the sense of term t 1 is determined, we examine the possibility of adding the synonyms of t 1 in its synset S to the query.</p><p>For any term t' except t 1 in S, if t' is a single term or a phrase not containing t 1 , t' is added to the query if either (a) S is a dominant synset of t' or (b) t' is highly globally correlated with t 2 , and the correlation value between t' and t 2 is greater than the value between t 1 and t 2 . The weight of t' is given by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W(t') = f(t', S)/F(t')</head><p>(1)</p><p>where f(t', S) is the frequency value of t' in S, and F(t') is the sum of frequency values of t' in all synsets which contain t' and have the same POS as t'. We interpret the weight of t' to be the likelihood that t' has the same meaning as t.</p><p>Example 4.1: In Example 4.1, the synset containing "incandescent" also contains "candent". It can be verified that the synset is dominant for "candent" and therefore "candent" is added to the query.</p><p>(2) Add Definition Words.</p><p>We select words from the definition of S. If t 1 is a single sense word, the first shortest noun phrase from the definition can be added to the query if it is highly globally correlated with t 1 .</p><p>Example 4.2: For query term "euro" whose definition is "the basic monetary unit of …", the noun phrase "monetary unit" from the definition can be added to the query if it is highly globally correlated with "euro".</p><p>(3) Add Hyponyms.</p><p>Suppose U is a hyponym synset of t 1 . A synonym in U is added to the query if one of the following conditions is satisfied:</p><p>(a) U is the unique hyponym synset of the determined synset of t 1 . For each term t' in U, t' is added to the query, with a weight similar to that given by the Formula (3), if U is dominant in the synsets of t'.</p><p>(b) U is not a unique hyponym synset of the determined synset of t 1 , but the definition of U contains term t 2 or its synonyms. For each term t' in U, if U is dominant in the synsets of t'; t' is added to the query with a weight given by Formula (3).</p><p>Example 4.3: In Example 4.3, the definition of the hyponym synset of "hurricane" contains "tropical", and "hurricane" is the only element in this synset. Thus, "hurricane" is added to the query.</p><p>(4) Add Compound Concepts.</p><p>Given a term t, we can retrieve its compound concepts using WordNet. A compound concept is either a word having term t as a sub-string or a dictionary phrase containing term t.</p><p>Suppose c is a compound concept of a query term t 1 and c has a dominant synset V. The compound concept c can be added to the query if it satisfies one of the following conditions:</p><p>(a) The definition of V contains t 1 as well as all terms that form a phrase with t 1 in the query.</p><p>Example 4.4: A term is "nobel", and a query is "Nobel Prize winner". Both "nobelist" and "nobel laureate" are compound words of "nobel". Their definition (they are synonyms) is "winner of a Nobel Prize", which contains all query terms in the phrase "Nobel Prize Winner".</p><p>(b) The definition of V contains term t 1 , and c relates to t 1 through a "member of" relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Pseudo Feedback and Web-assisted Feedback</head><p>Pseudo feedback in our system has been described in <ref type="bibr" coords="8,304.86,65.15,28.36,10.89" target="#b10">[LL04,</ref><ref type="bibr" coords="8,337.51,65.15,24.55,10.89" target="#b11">LY03]</ref>. In this section, we discuss web-assisted feedback and how pseudo feedback and web-assisted feedback are combined together to assign weights to the newly added terms.</p><p>Last year, two groups which had the best performance in robust task used the web or massive data to improve retrieval performance. This year, beside the pseudo feedback process, we adopt web-assisted feedback to help us find useful terms. Terms from pseudo feedback and web-assisted feedback are combined together. Term's weights are added together if it appears in both pseudo feedback and web-assisted feedback. Additional weights are assigned to feedback (pseudo and web) terms, if they are related to the original query terms through WordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Web-assisted Feedback</head><p>We use Google to help us do the web retrieval, the procedure is as follows:</p><p>(1) A query with the recognized phrase is submitted to Google to get the top ranked 100 documents.</p><p>(2) Get the top Google retrieved pages. If a page and its cache page doesn't contain any query term, ignore it and skip to the next page; otherwise, it is analyzed by the next step..</p><p>(3) Assign a "degree of satisfaction" to each retrieved web page according to the following criteria: Suppose the number of content words of the query submitted to Google is k. A general query phrase p containing x content words has a weight x/k, an individual word in the phrase has a weight 1/(2k). An individual query word which is not a part of a query phrase has a weight 1/k. The "degree of satisfaction" of a web page with respect to a query is given by the sum of the weights of the terms and the phrases which appear in a web retrieved page.</p><p>(4) Assign a weight to each term which appear in a web retrieved page is as follows:</p><formula xml:id="formula_1" coords="8,122.24,441.98,369.47,32.03">∑ = × × = n i di i t tf di ratio d ion satisficat t weight selection 1 ) ( ) ( ) deg( _ ) ( _ (2)</formula><p>where satisfaction_deg(d i ) is the satisfaction degree of document d i , ratio(d i ) is 1 if the document length dl(d i ) is less than or equals to the average document length avgdl, otherwise it is given by avgdl/dl(di). tf di (t) is the term frequency of term t in document d i . The sum is over all top ranked documents.</p><p>(5). Terms are ranked in descending order of selection weight, and the top ranked 20 terms are chosen as candidates.</p><p>(6). The selection weight of each candidate is normalized between 0 and 0.5 by following the following criterion: if the selection weight is greater or equals to 3, its weight is 0.5, otherwise its weight is given by selection_weight/(3.0*2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Combine Pseudo Feedback and Web-assisted Feedback Results</head><p>Each of the terms brought in by one of the two processes (pseudo-feedback and web-assisted feedback) will initially be given a weight which is dependent on its correlation with the query terms. When a term is brought in by both processes, their weights are added together.</p><p>A term t appears frequently in the top retrieved documents either in the initial retrieval of documents in the given collection of documents or in a web search. By using technique described above, it is not known which query term brings in t. However t may be related to some query term t 1 (i) by being a synonym of t 1 ; (ii) by being a hyponym of t 1 ; (iii) by being a coordinate term of t 1 ; (iv) by being a direct hypernym of t 1 ; (v) having a definition which contains t 1 or (vi) a definition of t 1 contains t. In the cases of (i) and (ii), t is a non-dominant of t 1 ; otherwise, it is brought in by Wordnet in previous phrase. In all these cases, the weight of t is given by how it relates to t 1 , using the same computation as given by formula (1). In case (iv), the weight is f(t, S)/F(t) * 1/h, where S is the synset containing t and h is the number of direct hypernyms of t 1 .</p><p>The weight of t that based on its correlation with the query in the top retrieved documents in the given collection of documents or web documents, and the weight that based on its relation with a query term t 1 are added together but the sum is bounded by 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Robust Track</head><p>In the robust track, we submit only 1 run to test our system. This run use title only. WordNet is used to disambiguate word senses and supply synonyms, hyponyms, definition words, and compound concepts. Pseudo-feedback and web-assisted feedback are applied. Table <ref type="table" coords="9,249.96,331.55,4.92,10.89" target="#tab_1">2</ref> gives the average precisions of the run over the entire 249 topics consisting of 200 old topics, the 50 hard topics, and the 49 new topics. The average precision gives the overall performance. The individual effectiveness is measured by the (a) number of topics with no relevant document retrieved in the top 10 positions and (b) the area under MAP(X)-vs-X measure where X is the number of topics (queries) having the worst mean precision and MAP(X) is the mean precision of the Xth worst topic <ref type="bibr" coords="9,139.04,477.23,33.32,10.89">[Robust]</ref>. These two measures reflect the robustness of any given retrieval strategy. Table <ref type="table" coords="9,510.66,477.23,4.92,10.89" target="#tab_2">3</ref> gives the number of topics with no relevant document in the top 10 positions for the old, the hard, the new and overall queries sets. Table <ref type="table" coords="9,97.66,585.71,4.92,10.89" target="#tab_2">3</ref> lists the area under MAP(X)-vs-X statistic information. For the entire set of 249 topics, X ranges from 1 to 62. For the set of 200 old topics, X ranges from 1 to 50. For two sets of 50 and 49 topics (50 hard and 49 new), X ranges from 1 to 12. The Kendall correlation between predicted and actual difficulty of our estimation is 0.623.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Our TREC-2004 experiment shows that robust retrieval result can be achieved by: (1) effective use of phrases, (2) a new similarity function capturing the use of phrases, (3) word sense disambiguation and the utilization of synonyms, hyponyms, definition words and compound concepts which are properly chosen. (4) Web does help retrieval. We are experimenting with more complicated techniques of word senses disambiguation in the document retrieval, and the use of more phrases in feedback retrieval which hopefully will yield much better effectiveness in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,72.00,296.03,468.07,150.42"><head></head><label></label><figDesc>:</figDesc><table coords="6,72.00,319.31,414.30,125.83"><row><cell></cell><cell cols="10">Table 1. Weights of Disambiguation Rules</cell><cell></cell></row><row><cell>Rule #</cell><cell>1, 3, 9, 11</cell><cell cols="4">2, 4, 5, 7, 10, 12, 13, 15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>6</cell><cell></cell><cell>8, 14</cell><cell>16</cell></row><row><cell>Weight</cell><cell>0.1875</cell><cell cols="2">0.125</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.075</cell><cell></cell><cell>0.0625</cell><cell>0.005</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">disam</cell><cell>_</cell><cell>wt</cell><cell>t (</cell><cell cols="2">Si</cell><cell>)</cell><cell></cell><cell>w</cell><cell>Rj</cell><cell>.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">rule</cell><cell>j</cell><cell>disambigua</cell><cell>te</cell><cell>t</cell><cell>to</cell><cell>Si</cell></row><row><cell cols="3">The sense having the maximum total weight is chosen. It is</cell><cell>sense</cell><cell>( t</cell><cell>)</cell><cell cols="3">arg</cell><cell cols="2">max[ t</cell><cell cols="2">disam</cell><cell>_</cell><cell>wt</cell><cell>( t</cell><cell>Si</cell><cell>)]</cell></row></table><note coords="6,72.00,364.43,204.36,10.89;6,276.48,368.87,1.80,7.17;6,281.64,364.43,70.95,10.89;6,353.04,368.87,1.80,7.17;6,358.20,364.43,181.87,10.89;6,72.00,385.31,213.14,10.89;6,285.36,389.75,1.80,7.17;6,287.28,385.31,19.96,10.89;6,423.02,384.28,12.83,18.01;6,383.92,385.71,6.58,12.00;6,376.95,440.95,3.89,5.51;6,346.79,425.49,6.59,11.95"><p><p>If term t is disambiguated by different rules and S i is a synset of t, S i is given a total weight that is the sum of the weights of the rules which determine t to have sense S i . It is</p>∑ = Si =</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,108.00,372.11,391.02,45.21"><head>Table 2 .</head><label>2</label><figDesc>Mean Average Precision for TREC2004 Robust Track    </figDesc><table coords="9,108.00,390.83,391.02,26.49"><row><cell>Topics</cell><cell>200 Old Queries</cell><cell>50 Hard Queries</cell><cell>49 New Queries</cell><cell>249 Queries</cell></row><row><cell>MAP</cell><cell>0.3047</cell><cell>0.1942</cell><cell>0.3250</cell><cell>0.3087</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,110.16,535.07,388.86,42.57"><head>Table 3 .</head><label>3</label><figDesc>Number of Topics with no Relevant Document in the Top 10 Positions</figDesc><table coords="9,110.16,553.79,388.86,23.85"><row><cell>Topics</cell><cell>200 Old Queries</cell><cell>50 Hard Queries</cell><cell>49 New Queries</cell><cell>249 Queries</cell></row><row><cell>no-re-l0</cell><cell>11</cell><cell>2</cell><cell>3</cell><cell>16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,106.32,643.55,397.26,39.45"><head>Table 3</head><label>3</label><figDesc></figDesc><table coords="9,106.32,643.55,397.26,39.45"><row><cell></cell><cell cols="3">. Area under MAP(X)-vs-X evaluation</cell><cell></cell></row><row><cell>Topics</cell><cell>200 Old Queries</cell><cell>50 Hard Queries</cell><cell>49 New Queries</cell><cell>249 Queries</cell></row><row><cell>MAP(X)-vs-X</cell><cell>0.0265</cell><cell>0.0263</cell><cell>0.0466</cell><cell>0.0284</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,103.98,193.55,416.50,10.89" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m" coord="10,252.64,193.55,117.76,10.89">Modern Information Retrieval</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,102.89,214.67,387.26,10.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,208.39,214.67,172.12,10.89">Optimization of relevance feedback weights</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,387.11,214.67,58.12,10.89">ACM SIGIR</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="351" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,99.06,236.03,354.74,10.89" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,140.88,236.03,312.92,10.89">Penn Treebank Tagger, Copyright by M.I.T and the University of Pennsylvania</title>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,109.29,257.39,430.67,10.89;10,72.00,274.43,468.05,10.89;10,72.00,291.71,219.76,10.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,235.26,257.39,169.84,10.89">Lexicalized Models for Statistical Parsing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Three</forename><surname>Generative</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,412.56,257.39,127.39,10.89;10,72.00,274.43,468.05,10.89">Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter</title>
		<meeting>the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,111.65,313.07,428.11,10.89;10,72.00,330.35,79.54,10.89" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="10,165.14,313.07,255.22,10.89">Head-driven statistical models for natural language parsing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,106.16,351.47,308.25,10.89" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,159.60,351.47,161.98,10.89">WordNet An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.85,368.99,434.04,10.89;10,72.00,386.27,110.41,10.89" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,261.11,368.99,240.73,10.89">Ad Hoc Information Retrieval: Algorithms and Heuristics</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ophir</forename><surname>Frieder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.88,403.55,431.92,10.89;10,72.00,420.83,222.49,10.89" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,290.26,403.55,249.53,10.89;10,72.00,420.83,24.84,10.89">TREC 2003 Robust, HARD and QA Track Experiments using PIRCS</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dinstl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<idno>TREC-12</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">510</biblScope>
			<pubPlace>Queens College, CUNY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,106.12,441.95,433.75,10.89;10,72.00,459.23,142.12,10.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,139.22,441.95,276.16,10.89">PRINCIPAR---An Efficient, broad-coverage, principle-based parser</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,434.58,441.95,105.30,10.89;10,72.00,459.23,8.20,10.89">Proceedings of COLING-94</title>
		<meeting>COLING-94<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="42" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.29,480.59,432.70,10.89;10,72.00,497.87,169.98,10.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,142.20,480.59,221.39,10.89">Using collocation statistics in information extraction</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,384.48,480.59,155.51,10.89;10,72.00,497.87,105.75,10.89">Proceedings of the Seventh Message Understanding Conference</title>
		<meeting>the Seventh Message Understanding Conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,103.84,518.99,436.10,10.89;10,72.00,536.27,208.53,10.89" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,253.63,518.99,286.32,10.89;10,72.00,536.27,76.89,10.89">An effective approach to document retrieval via utilizing Wordnet and recognizing phrases</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>ACM SIGIR</publisher>
			<biblScope unit="page" from="266" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,103.97,557.63,283.45,10.89" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<title level="m" coord="10,178.05,557.63,182.18,10.89">UIC at TREC-2003: Robust Task, TREC-2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,109.31,578.75,430.61,10.89;10,72.00,596.03,22.14,10.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,153.31,578.75,160.96,10.89">WordNet: An On-line Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,322.03,578.75,152.77,10.89">International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.06,617.15,356.27,10.89" xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Porter</forename><surname>Stemmer</surname></persName>
		</author>
		<ptr target="http://www.tartarus.org/~martin/PorterStemmer/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,106.71,638.51,276.32,10.89" xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Walker</forename><forename type="middle">S</forename><surname>Okapi</surname></persName>
		</author>
		<idno>TREC-8. TREC-8</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.90,659.87,339.46,10.89" xml:id="b15">
	<monogr>
		<ptr target="http://trec.nist.gov/act_part/tracks/robust/04.guidelines.html" />
		<title level="m" coord="10,108.90,659.87,96.75,10.89">Robust Track Guidelines</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,680.99,432.48,10.89;10,72.00,698.27,350.93,10.89" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Terra</surname></persName>
		</author>
		<idno>TREC-12</idno>
		<title level="m" coord="10,406.91,680.99,133.17,10.89">Task-Specific Query Expansion</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">810</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note>MultiText Experiments for TREC 2003</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
