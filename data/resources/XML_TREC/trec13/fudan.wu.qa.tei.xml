<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.82,132.11,277.65,17.49">FDUQA on TREC2004 QA Track</title>
				<funder ref="#_55pkjZM">
					<orgName type="full">NSF of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,122.76,175.19,36.18,9.45"><forename type="first">Lide</forename><surname>Wu</surname></persName>
							<email>ldwu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.93,175.19,74.74,9.45"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<email>xjhuang@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.26,175.19,36.82,9.45"><forename type="first">Lan</forename><surname>You</surname></persName>
							<email>lan_you@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.23,175.19,73.81,9.45"><forename type="first">Zhushuo</forename><surname>Zhang</surname></persName>
							<email>zs_zhang@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,378.43,175.19,26.68,9.45"><forename type="first">Xin</forename><surname>Li</surname></persName>
							<email>lixin@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.81,175.19,60.63,9.45"><forename type="first">Yaqian</forename><surname>Zhou</surname></persName>
							<email>zhouyaqian@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.82,132.11,277.65,17.49">FDUQA on TREC2004 QA Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DF69E03C74C1F512E3E9F39491D91B76</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this year's QA Track, we process factoid questions in a way that is slightly different from our previous system <ref type="bibr" coords="1,153.45,268.86,10.33,8.77" target="#b0">[1]</ref>. The most significant difference is that we developed a new answer type category, and trained a classifier for answer type classification. To answer list questions, we use a pattern-based method to find more answers other than those found in the processing of factoid question. And an algorithm that uses some knowledge bases answers definition questions. This algorithm achieves a promising result.</p><p>In our system, external knowledge is widely used, which includes WordNet and Internet. The ontology in WordNet is used in the answer type classification, and its synsets are used to do query extension. Internet is used not only to find factoid question answers, but also as knowledge base for definition questions.</p><p>In the following, Section 2, 3, 4 will separately introduce our algorithm to solve factoid, list and definition questions. Section 5 will present our results in TREC2004. Answer Type</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocess</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aquaint Corpus</head><p>The above figure describes the process of our factoid question answering. Details about each module will be introduced in the latter subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Question Preprocess</head><p>In TREC2004, a set of questions is about a certain target so that anaphora is used in questions. For example, target 1 is "Crips", question 1.5 is about it: "What is their gang color?" In this question, "their" refers to "Crips'". So each question should be preprocessed first to replace these pronouns with their references. A simple algorithm is used here to solve this anaphora. We replace the pronoun and some short form like "the group", "the comet" etc. with the question's target. Then in the following, we can process questions in a traditional way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Question Analysis</head><p>We do question analysis by LinkParser <ref type="bibr" coords="2,279.86,331.47,11.38,9.61" target="#b1">[2]</ref>, an English parser based on link grammar. In this step, constituents are extracted from the question sentence. For example: "When was the Hale Bopp comet discovered?" Its constituents are: "the Hale Bopp comet" -subject; "was discovered"predicate. This constituents information, as we will see in the following, is used in answer type classification, query generation, as well as answer generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Answer Type Classification</head><p>In the answer type classification step, FDUQA system determines the answer type of the input question based on some ordered list of rules obtained by machine learning. We adopt a thirty-one-class answer type classification system, illustrated in table1. Different types of the questions are treated differently in the following answer generation module.</p><p>Besides POS and interrogative, WordNet is used as an external resource in our question classifier. Meantime, constituents of question sentences obtained in parsing above are used too. They are crucial for classification processes. The classifier and focus words decision algorithm are both based on Transformation-Based error-Driven learning (TBL) <ref type="bibr" coords="3,210.94,125.01,11.34,9.61" target="#b2">[3]</ref>. TBL is an approach to corpus -based natural language processing. By using TBL, a rule-based question classifier is developed to determine the question focus and answer type.</p><p>Firstly, we use TBL to get the focus in the question. The question focus is a word or a phrase, which indicates what the question is looking for, or what the question is all about. It emphasizes on the type of answer expected. Especially, it should be existed in WordNet, or else there is no focus in the question.</p><p>An example of a rewrite rule for focus: Change the tag from 'NN_0 to 'NN_1' And an example of its triggering environment is: what $$ WP_0 NN_0.</p><p>This rule means if the interrogative of a question is 'what' and following word is a noun, the noun will be tagged as a focus candidate. When all the transformations have been used, we get the focus of the input question.</p><p>Secondly, we search the Wordnet and get the focus word's sense. All its Hypernyms in WordNet and other information are input into another TBL classifier, and then we get the category of a question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An example of a rewrite rule for category: Change the tag from '_#' to _TIM' And an example of its triggering environment is: what nil $$ clock time, time $$ _#</head><p>This rule means if the interrogative of a question is 'what', the verb of question is not 'be' (nil) and the question do not have a category (_# ) also, but the focus is a Hyponyms of clock time, time. The question has the candidate category TIM. After every transformation is used, we will get the final category of a input question.</p><p>The questions of TREC8-11 are used as training set, and TREC12 questions are used as test. We get about 700 rules for focus and 500 rules for category. They are used to the input questions one after another. The precision of answer type classification over questions of TREC12 is 84.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Query Generation and Web Retrieval</head><p>We find answers from Internet using Google search engine. Query generation is subject to the characteristics of Google Search such as phrase search. To utilize this characteristic, we combine constituents in such way:</p><p>In the last example, "When was the Hale Bopp comet discovered?" has constituents: "the Hale Bopp comet" -subject, "was discovered" -predicate. Queries for this question are: "the Hale Bopp comet was discovered" and "the Hale Bopp comet" "was discovered".</p><p>Upon the basic queries, we also do some query extension. Here are some rules for this extension:</p><p>Synonym extension -to replace the noun in the query with its synonym, which is found in WordNet.</p><p>Preposition extension -to add some prepositions to queries when the question asks for location or time.</p><p>Unit extension -to add some units to queries when the question asks for measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Answer Generation and Support Document Retrieval</head><p>Answer generation is based on the answer type category. We first extract candidate answers in snippets returned by Google using an NE tagger. Then each answer will be given a score according to its context. Now we obtain a list of answers from Internet. The support documents are retrieved in Aquaint Corpus with the answers obtained and the question target as queries. By measuring the distance between the answer and key words, we will get the best answer and its support document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">List Question</head><p>This year, we use patterns to extract answers for list questions. The answers of a list question always appear in a paratactic structure like "… and …". We obtained these structures from the past TREC list questions, and built a knowledge base for them.</p><p>Here are some examples from our knowledge base: These patterns are expressed in regular expression. &lt;A&gt; here means the answer. The answer found by factoid question processing module is used as a seed in pattern matching.</p><p>For example: "Name cities that have an Amtrak terminal."</p><p>We first treat it as a factoid question and answer "New York" was found. Then we use "New York" as a seed that must appear at &lt;A&gt; in patterns. Now we find the following context match the pattern "(&lt;A&gt;)+ and &lt;A&gt;" with the seed of "New York":</p><p>We found the following sentence matched the pattern: Preliminary plans by Amtrak that were released yesterday call for stops of its high-speed express service in Boston , Providence , R.I. , New Haven , Conn. , New York , Philadelphia , Baltimore and Washington . So "Boston", "Providence", "R.L.", "New Haven", "Conn.", "Philadelphia", "Baltimore", "Washington" will be extracted. And then we validate whether these phrases are noun phrases as "New York". If yes, they will be put into answer list.</p><p>This algorithm depends not only on patterns, but the seed answer as well.</p><p>If the seed answer is wrong, it's almost impossible to find right answers.</p><p>As for answering definition question, we develop a method based on online knowledge bases. Many question answering systems have showed the importance of resource on the Web for answering factoid questions <ref type="bibr" coords="5,208.32,161.13,11.38,9.61" target="#b3">[4]</ref>, and the results of our system reveal that the Web-based knowledge bases are also quite helpful to answering definition questions.</p><p>The flow chart for definition question of FDUQA is in figure2.</p><p>Figure2. Flow Chart for Definition Question of FDUQA</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Target Expansion</head><p>Usually, a target to a definition question may have several different forms. We use synsets in WordNet to find them and expand the "target" into a "target set". For example, the target "Khmer Rouge" can be expanded into {"Khmer Rouge", "KR", "Party of Democratic Kampuchea", "Communist Party of Kampuchea"}. This expansion can make us both retrieve more in the corpus and get more knowledge from knowledge bases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Document Retrieval and Candidate Answer Generation</head><p>We get the documents about the target in the AQUAINT corpus. Search engine OKAPI is used for this purpose. For a question, each element in the "target set" was submitted to the search engine as a query one time. All the search results are kept for candidate answer generation later. There are about 100 documents for each question. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Internet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aquaint Corpus</head><p>Then we cut the documents into sentences, and delete the sentences that have no relation with the target using a few heuristic rules. For example, we delete all the sentences that contain no element of the "target set". We also delete the redundancy. For two arbitrary sentences, if their content words overlap above 65%, we drop one of them. The sentences remained form the candidate answer set, which can be expressed as S A {A 1 , A 2 ,…, A m }, where A k (k=1..m) is a candidate answer in the set and m is the total number of the candidate answer..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Web Knowledge Acquisition and Definition Extraction</head><p>We first search the definitions about the target from a number of online knowledge bases. These knowledge bases are the WordNet glosses and other online dictionaries such as the biography dictionary at www.encyclopedia.com. For each target, these definitions from different knowledge bases form its "definition set", which is expressed as S D {D 1 , D 2 ,...,D n }, where D k (k=1..n) are definitions about the target from different resources, and n is the definitions' number.</p><p>Different definitions in the "definition set" may overlap in some degree, and one definition may have some information that is not very important. So we extract the essential information from the "definition set" to form the "essential definition set". We hope that this set may cover all the most important information about the target and little redundancy. The extraction is based on a summary technique. S ED {d 1 , d 2 ,…,d l } is the "essential definition set" to the target, where each element d i is an essential information about the target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Candidate Answering Ranking</head><p>In this module, we have tried two methods to rank the candidate answer set. They use the "definition set" and the "essential definition set" separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Ranking with Definition Set</head><p>Let S ij be the similarity of D i and A j , where the similarity is the tf-idf score, with D i and A j treating as a bag of word. We get the score of each candidate answer A i as follows:</p><formula xml:id="formula_0" coords="6,111.00,545.16,127.46,27.65">∑ = = n j ij j i S w score 1 ( ∑ = = n j j w 1 1 )</formula><p>The weights j w are fixed based on the experiment on TREC2003 definition question set. Rank the set S A based on i score , and choose the top ones as the answer. This method is used in the run FDUQA13a and FDUQA13b with slightly different weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Ranking with Essential Definition Set</head><p>FDUQA13c was generated using this ranking method. The following algorithm was executed to get the answer set of a definition question:</p><p>1. Initially set the answer set A={} 2. For each element d i (i=1..l) in the set S ED : we first get the similarity between d i and A j (j=1..m), which is expressed as S ij and calculated as the same as in 4.4.1. Then find the candidate answer in the set S A as follows: if } ,..., , max{ The parameters max_answer_length and minsim were empirically set based on TREC12's 50 definition questions. The last result set is A {A 1 , A 2 ,…, A m' }.</p><p>The performance of this module can be found from Table <ref type="table" coords="7,355.90,291.87,5.34,9.61" target="#tab_1">2</ref> in section 5. The F-measure score of the former ones are slightly higher than the latter. The simple method may get the better result.</p><p>However, the result of the latter one is also encouraging. Since it has the potential to get the answers, which are not only brevity but also have wide coverage about the target. Of course it depends on the quality and the coverage of the essential definition set. We believe that the performance may be boosted after improving the extracting method of essential definition set, and we will try it in the future.</p><p>We think that the methods presented give an appropriate framework for answering definition questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We submitted three runs for the main task of TREC13 QA Track: fduqa13a, fduqa13b and fduqa13c. In these three runs, the algorithms used to answer factoid questions are merely different in some parameters. The results of list questions in the runs are just the same. As to definition questions, difference between these three runs is described above. From this table, we can see that the algorithm we use to answer definition questions is quite promising. The list questions are answered not so well. It's maybe due to the patterns we use are not enough, and the correctness of seed answers is doubtable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,185.70,725.03,223.85,9.19"><head>Figure. 1 .</head><label>1</label><figDesc>Figure. 1. Flow Chart of FDUQA on Factoid Question</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,106.86,390.24,374.20,8.77;4,106.86,405.42,117.60,8.77;4,106.86,420.60,107.57,8.77;4,106.86,435.72,86.30,8.77;4,106.86,450.90,110.19,8.77"><head></head><label></label><figDesc>P1. (including|include|included|includes|involve|involving|involves|involved) (&lt;A&gt;)+ and &lt;A&gt; P2. such as (&lt;A&gt;)+ and &lt;A&gt; P3. between &lt;A&gt; and &lt;A&gt; P4. (&lt;A&gt;)+ and &lt;A&gt; P5. (&lt;A&gt;)+ as well as &lt;A&gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,298.02,159.93,2.70,4.86;7,284.40,159.93,2.70,4.86;7,318.90,159.93,5.40,4.86;7,295.98,159.93,1.50,4.86;7,282.96,159.93,1.50,4.86;7,243.84,159.93,3.90,4.86;7,314.16,155.37,4.42,7.95;7,291.24,155.37,4.42,7.95;7,278.22,155.37,4.42,7.95;7,239.10,152.52,17.26,10.81;7,334.86,154.17,23.94,9.61;7,358.80,158.26,5.32,6.12;7,364.14,154.17,90.09,9.61;7,454.26,158.26,3.40,6.12;7,460.26,154.17,48.18,9.61;7,87.42,170.49,53.36,9.61;7,140.88,174.58,3.40,6.12;7,145.98,170.49,59.71,9.61;7,205.68,174.58,4.91,6.12;7,213.30,170.49,2.67,9.61;7,108.84,200.55,19.98,9.61;7,135.36,195.40,10.43,17.93;7,139.08,211.47,3.75,8.37;7,170.82,198.03,5.35,11.95;7,141.84,191.31,0.88,4.39;7,142.14,213.67,3.42,6.15;7,227.58,201.17,4.88,8.79;7,177.90,201.17,21.69,8.79;7,165.72,201.17,3.25,8.79;7,151.80,201.17,3.25,8.79;7,137.04,193.03,4.93,6.15;7,135.48,213.67,3.03,6.15;7,160.98,205.63,3.03,6.15;7,233.70,201.17,24.41,8.79;7,199.50,201.17,28.21,8.79;7,155.70,201.17,5.97,8.79;7,146.64,201.17,5.43,8.79;7,263.10,200.55,244.89,9.61;7,87.42,230.01,130.08,9.61;7,225.66,225.19,15.35,14.68;7,233.88,235.84,2.35,4.77;7,228.96,231.37,5.30,7.81;7,220.56,231.37,4.83,7.81;7,246.06,230.01,143.32,9.61;7,389.40,234.07,3.42,6.15;7,395.10,230.01,82.85,9.61;7,477.78,227.77,2.28,6.15;7,483.90,230.01,24.00,9.61;7,87.42,246.33,123.08,9.61"><head></head><label></label><figDesc>&gt;minsim , then add A k to the set A and delete A k from the set S A . is found in step 2, the algorithm ends; otherwise, go to step2, where ( )k A Lrepresents the length of string A k in character and m ' is the number of elements in set A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,115.86,579.05,359.27,134.41"><head>Table 1 .</head><label>1</label><figDesc>Answer</figDesc><table coords="2,316.12,579.05,58.52,9.19"><row><cell>Type concepts</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,100.86,537.05,384.85,181.39"><head>Table 2 .</head><label>2</label><figDesc>Performance of FDUQA Runs in TREC13</figDesc><table coords="7,291.12,552.71,182.85,9.19"><row><cell>Fduqa13a</cell><cell>Fduqa13b</cell><cell>Fduqa13c</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research was partly supported by <rs type="funder">NSF of China</rs> under contracts of <rs type="grantNumber">60103014</rs>, as well as the 863 National High-tech Promotion Project of China under contracts of 2001AA114120. We are very thankful to <rs type="person">Yongping Du</rs>, <rs type="person">Ningyu Chen</rs>, <rs type="person">Feng Ji</rs>, <rs type="person">Feng Lin</rs> and <rs type="person">Jian Huang</rs> for their contributions in our work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_55pkjZM">
					<idno type="grant-number">60103014</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,104.94,296.09,402.91,9.19;8,103.92,311.27,157.22,9.19" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,410.46,296.09,97.39,9.19;8,103.92,311.27,32.52,9.19">FDUQA on TREC2003 QA Task</title>
		<author>
			<persName coords=""><forename type="first">Lide</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yaqian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yongping</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lan</forename><surname>You</surname></persName>
		</author>
		<idno>the TREC-12</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,143.22,311.27,60.87,9.19">Proceedings of</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,104.94,334.01,403.04,9.19;8,103.92,349.19,201.44,9.19" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,302.64,334.01,171.29,9.19">Parsing English with a Link Grammar</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Sleator</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Davy</forename><surname>Temperley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,485.22,334.01,22.76,9.19;8,103.92,349.19,197.06,9.19">Third International Workshop on Parsing Technologies</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,104.94,371.93,387.51,9.19;8,103.92,387.11,314.77,9.19" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,128.74,371.93,363.71,9.19;8,103.92,387.11,152.08,9.19">Eric Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part of Speech Tagging</title>
	</analytic>
	<monogr>
		<title level="j" coord="8,262.98,387.11,107.16,9.19">Computational Linguistics</title>
		<imprint>
			<date type="published" when="1995-12">Dec. 1995</date>
			<publisher>Brill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,104.94,409.85,375.18,9.19;8,103.92,425.03,261.13,9.19" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,154.50,409.85,310.29,9.19">The Web as a resource for question answering: Perspectives and challenges</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,103.92,425.03,261.13,9.19">Proceedings of the Third International Conference on Language</title>
		<meeting>the Third International Conference on Language</meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
