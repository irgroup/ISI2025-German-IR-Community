<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.09,85.88,432.11,16.73">Using Clustering and Blade Clusters in the TeraByte task</title>
				<funder ref="#_QchmF2M">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.29,106.91,80.69,10.80"><forename type="first">Giuseppe</forename><surname>Attardi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution">Università di Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.61,106.91,61.38,10.80"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution">Università di Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,353.61,106.91,62.38,10.80"><forename type="first">Chirag</forename><surname>Patel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution">Università di Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.09,85.88,432.11,16.73">Using Clustering and Blade Clusters in the TeraByte task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C41FDB10D2A1183F19B84072702B29E6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>unique</term>
					<term>1023)</term>
					<term>// indexed</term>
					<term>value is unique VARKEY(text</term>
					<term>Filed::fulltext</term>
					<term>65535)</term>
					<term>// indexed full-text FIELD(links))); // persistent</term>
					<term>but not indexed };</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Web search engines exploit conjunctive queries and special ranking criteria which differ from the disjunctive queries typically used for ad-hoc retrieval. We wanted to asses the effectiveness of those techniques in the TeraByte task, in particular scoring criteria like: link popularity, proximity boosting, home page score, descriptions and anchor text. Since conjunctive queries sometimes produce low recall, we tested a new approach to query expansion, which extracts additional query terms from a clustering of the snippets from the first query. The technique proved effective, almost doubling the Mean Average Precision. However, the improvement was just enough to compensate for the drop that was introduced, contrary to our expectations, by the proximity boost.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Search System Architecture</head><p>For handling queries in the TeraByte track we built a high performance distributed search service on the GOV2 collection, based on a cluster of Linux blade servers.</p><p>The hardware consists of an RLX 300X chassis, filled with 24 800xi blades, whose total cost is about $ 25,000.</p><p>Each blade consists of an 800 MHz Pentium III processor, 1 GB of RAM, one 60 GB 2.5" hard disk (at only 4200 rpm) and three 100 Mbps network adapters. One of the blades is dedicated to the role of control tower and is used to manage the cluster. The remaining 23 blades are used as server blades for indexing and search: they run the Linux Fedora Core 1 release. The overall amount of disk available is about 1.3 TB and the amount of RAM is 23 GB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">The IXE Search Engine</head><p>IXE (IndeXing and search Engine) is a C++ library for developing search applications. IXE provides a wide range of facilities for document handling, from tokenization to regular expressions, to multiple encoding, which can be extended through its pluggable document-reader architecture. IXE allows creating high throughput search services by means of integrated threading and HTTP support. The library has been designed for implementing high performance full-text search services, but is capable of handling more complex structures than pure text documents by supporting persistent C++ objects. Support for persistency is provided through a mechanism of reflection, implemented using C++ meta-template programming <ref type="bibr" coords="1,212.97,676.52,12.87,11.48" target="#b1">[1]</ref>. Reflection creates a metaclass for each class of objects, where properties of object fields can be stored, such as the maximum size of a field value or indexing properties.</p><p>The META construct is used to annotate the class definition with attributes, which are exploited in serialization and indexing: for instance whether a field has unique values in a collection or whether a full-text index must be created for the field.</p><p>Objects are stored in persistent object relational tables. Objects can be retrieved from tables by means of cursors: access operations on cursors return real objects, not ResultSets or similar data structures (as in ADO, or JDBC), from which the program must extract values for each field with explicit access operations.</p><p>A sequential cursor can be created on any indexed field. Query cursors instead can be used to select objects which match conditions expressed in a SQL-like query language. A query expression is a logic combination of conditions on object attributes. Queries are compiled before execution and results are obtained scanning the query cursor on demand, rather that as a bulk operation that fills a whole table of results. The application is so given the possibility of performing decisions on how to use the results, without having to wait for all of them to be collected. For instance, a heap structure can be used to sort the results as they are generated, keeping just the top k <ref type="bibr" coords="2,186.09,453.32,12.78,11.48" target="#b1">[1]</ref>, rather than having to sort them all: this reduces the complexity to n log(k), rather than n log(n) and reduces the amount of space required to O(k) which can results in significant savings when n &gt;&gt; k.</p><p>Matching conditions on full-text attributes varies from matching simple list of words, to phrase matching, to proximity matching, and to any combination thereof.</p><p>Here is a sample of queries on a collection of Page objects:</p><p>text matches sun moon // pages containing sun and moon text matches 'sun flower' // pages with the phrase 'sun flower' text matches proximity 20 ['sun flower' moon] // moon must appear within 20 words from 'sun flower' links &gt; 8 and text matches 'moon light' // combination of conditions Results from queries on full-text indices are assigned a relevance score based on a classical cosine measure, augmented by a factor for proximity and by a weight according to the "color" of term, which represents term features like capitalization or appearance in certain areas of the document (title, heading, anchor, etc). Computation of the relevance score can be customized for each application to take into account additional factors, as described later for the GOV2 collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Distribution of the GOV2 collection</head><p>The GOV2 collection consists of over 80 GB of compressed documents (426 GB uncompressed) split into 273 directories, each one containing 350 MB of documents, stored in one hundred files in gzip format.</p><p>We divided the collection into 23 shards, one for each blade. Each shard consists of 12 subcollections, corresponding to directories in the distribution, for a total of around 1 million documents each, taking 4 GB of disk space.</p><p>The documents are kept compressed on disk: during indexing one file at a time is uncompressed and its content piped to the indexing program.</p><p>For convenience, we also shared data among the servers using NFS: each blade exports its /export directory to the other blades and mounts in the /import directory the directories exported by the other blades, obtaining this view: </p><formula xml:id="formula_0" coords="3,107.01,275.09,6.00,8.10">/</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Preparation of support data</head><p>For properly cross referencing documents, in particular for link analysis, we needed to assign a global ID to each unique URL in the collection. To accomplish this efficiently we partitioned the URLs according to a hash code and on each blade we created a table for its partition, eliminating duplicates present in the original collection. The various tables are accessed as a single table, by using the same hash code to select which partition to search. Building the URL tables in this distributed fashion took about one hour.</p><p>A table of citations (the text inside an anchor tag) was used during indexing to enrich the document's content with the often meaningful text extracted from other documents that point to it. For example, a document containing the text of a law about "Federal welfare reform" (topic 720) may not contain these terms, while other documents may mention it using those words.</p><p>Citations were extracted analyzing all documents in the collection. A citation consists of: the referrer URL id; the target URL id; and the citation text. A compact encoding was used for being able to handle large document collections. We created on each blade a table of citations to documents in other shards, making up in total a 23 × 23 matrix of citation tables.</p><p>The citation tables for each shard were then merged into a single table, containing all citations to documents in that shard. While a single centralized citations table would have had a size of around 28 GB, with this approach we created instead a citation table of 1.2 GB on each blade with only the required data for indexing the shard on that particular blade.</p><p>Creating citations tables in a distributed way allowed us to reduce the processing time to less than 5 hours.</p><p>Additional descriptive text to be added to each document contents was obtained from the Dmoz archive.</p><p>The Dmoz <ref type="bibr" coords="4,131.37,73.64,14.08,11.48" target="#b6">[6]</ref> archive is a hand made Web directory, that contains over 3 million URLs classified within several hundred categories. We extracted the description associated to each URL and its classification categories and stored them in an IXE table. During indexing, the text of the description extracted from this table is added in a field of the PageInfo object that represents the URL. The text in this description gets indexed as part of the document, but it is given a special color that produces a higher weight in the retrieval score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Indexing</head><p>A separate index is built for each sub-collection. The indexing process parses the document, creates a PageInfo object to represent that document and adds it to the object store. The main fields of PageInfo are the following: url:</p><p>extracted from the document docno:</p><p>the TREC document number description: retrieved from Dmoz text of all the citations referring to the document Indexing required several preliminary steps: assigning unique doc IDs (avoiding duplicates), extracting page descriptions and categories from Dmoz, collecting links and anchor texts.</p><p>Citations tables where built in parallel on 23 server blades: the process took 3.5 days. This includes the time to decompress documents and parse them: in a production system this step will be performed during crawling</p><p>The index is stored as compressed tables on disk that can be directly mapped to memory during search. Posting List compression uses variable byte coding, which we called eptacode, since it uses 7 bits per byte and a continuation bit, and is similar to the vbyte coding in <ref type="bibr" coords="4,487.77,445.16,12.87,11.48" target="#b8">[8]</ref>. In our experiments eptacode produced 23% smaller postings than those achieved with techniques like local Bernoulli with Golomb encoding as reported in <ref type="bibr" coords="4,343.05,472.76,18.53,11.48" target="#b12">[12]</ref>. Posting lists contain both position information and color tagging, that can be used to specify properties of text, like occurrence within specific zones of the document (title, anchor, heading), lexical features like size, capitalization or semantic tags like part-of-speech, name-entity tags, etc.</p><p>Documents are described as objects with several fields extracted from various sources and stored in the IXE object store. The indexer uses a specific document reader for HTML, which extracts additional fields like title and description.</p><p>Tokenization by the document reader assigns a different token type ('color') to each term that is used for weighting. These colors include:</p><p>1. Textual tokens: extracted from the document's text and divided into: a) Title -extracted from the document title b) Heading -extracted from the document's headers c) Anchor -extracted from the document's anchor elements d) Regular tokens -all the rest 2. Anchor tokens: extracted from the anchors of document's in-links 3. Description tokens: extracted from the description of the document, either from Dmoz or from the META description tag 4. URL tokens: extracted from the document' s URL.</p><p>Indexing was performed in parallel on all blades, building 23 shards, each containing ~1 million documents, with an index size of 4.2 GB, and an additional 4.3 GB for a compressed copy of the documents. A document cache contains compressed copies of all the original documents.</p><p>Overall the index size is 92 GB, made up of three parts as listed in Table <ref type="table" coords="5,434.49,168.44,4.50,11.48" target="#tab_2">1</ref>. Indexing the whole collection took ~12 hours, 2/3 of which was due to uncompressing the collection, which was done on the fly to overcome disk space limitations. Furthermore we employed an HTML document reader that performs full HTML structure analysis, in order to assign colors to terms. Skipping this extra analysis further increases indexing performance to 24 GB per hour on a single PC. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5.">Search</head><p>The retrieval score computed by the search engine combines the following factors:</p><p>1. classical cosine measure based on tf and idf 2. term color weighting, i.e. text occurrence in title, heading, anchor within the document, occurrence in url or description (either from an HTML meta tag or from Dmoz listing) and occurrence in the anchor of a referring document 3. a proximity boost for terms appearing closer within a document 4. number of incoming links 5. ratio of non content links (IMG, INPUT, etc.) to document length 6. URL path length.</p><p>The score for a page p was computed as in <ref type="bibr" coords="5,284.97,518.24,14.08,11.48" target="#b1">[1]</ref> according to the number n of links pointing to p, by the formula:</p><formula xml:id="formula_1" coords="5,237.33,549.27,137.45,36.52">   ≥ = otherwise N n N n p Lr / 0 . 1 ) (</formula><p>where N is an upper bound on a page' s in-link number.</p><p>The content rate was computed as follows:</p><formula xml:id="formula_2" coords="5,264.09,635.52,82.18,30.06">z o p Cr 10 4 1 + + =</formula><p>where |p| is the length of the document in words, o is the number of out-links and z is the number of non-content tags.</p><p>Each blade runs a search service on its shard of the collection. The service is accessible remotely in two forms:</p><p>• as an XML Web Service,</p><p>• through an internal binary communication protocol.</p><p>In both cases queries are submitted using the syntax for HTTP query strings, i.e. as a '?" followed by a series of parameter=value pairs each of which is URL-encoded.</p><p>For instance a query for the words "oil" and "industry", asking for the first 10 results is expressed as:</p><p>?q=oil+industry&amp;start=0&amp;num=10</p><p>where q is the parameter for the query itself, num is the parameter for the number of results and start the parameter for the position of first result requested.</p><p>In the case of Web Service, responses are sent back as SOAP messages. The binary communication protocol is used for instance by a query broker that collects results from other query servers. The binary protocol exploits the serialization of C++ objects provided by the reflection facility in IXE. This serialization is much more compact than using the SOAP protocol: for instance a single query result requires just 28 bytes, hence a query server can return over 50 results in a single Ethernet packet.</p><p>The search service exposes three methods:</p><p>1. search(query, start, num): returns the top start+num ranking documents for the given query 2. getDoc(ID): returns the document identified by the given ID 3. getDocInfo(ID, terms): returns the PageInfo representing the document, including the snippets containing the given terms A query broker runs on one of the blades: its task is to accept queries, dispatch them to the query servers, collect all results and merge them into a single result list. The broker communicates with the query servers by asynchronous IO, to reduce wait and latency. The broker can be invoked in batch mode to produce the TREC runs. A broker module instead gets instantiated within a thread pool through a Web interface to provide a query interface typical of Web search engines. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>…</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MultiThreaded</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Performance</head><p>Search in IXE exploits the Small Adaptive Set Intersection algorithm <ref type="bibr" coords="7,411.21,98.00,13.12,11.48" target="#b5">[5]</ref>: posting lists are sorted by docid, stored compressed and use skip lists to optimize the handling of frequent words (for the GOV2 collection we indexed without removing stop words). A separate index file contains position information for handling proximity queries: this file is also mapped to memory during search, but only piecewise, since it may be larger than the 4 GB limit on 32-bit architectures.</p><p>Search is performed in parallel: each blade runs a search service on its shard; a broker collects and sorts the results. Snippet extraction is also distributed.</p><p>A search for 10,000 results for a single proximity query on the whole collection takes an average of 0.3 sec.</p><p>We compared the performance of IXE with two other systems, Zettair <ref type="bibr" coords="7,437.01,240.20,20.08,11.48" target="#b11">[11]</ref>  Times are in milliseconds and were obtained after repeating the query twice, in order to allow for the effects of memory caching.</p><p>For queries with large number of results, the use of skip lists by IXE proves indeed effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TeraByte track</head><p>For ad-hoc retrieval, it is generally accepted that an approach based on the vector space model, combined with suitable ranking formula (e.g. BM25), is suitable to achieve high precision scores. The benefits of using proximity operators or phrase matching are instead controversial since their use has rarely shown substantial improvements of retrieval results. On the other hand, these methods dominate Web search: Boolean AND queries are the default and proximity is accounted in ranking of results. This may be explained by the peculiar requirements for Web search: the expected response time even on a huge collection is very short, hence it is impossible to examining all possible results of a disjunctive query; queries contain very few keywords, hence other criteria must be exploited to guess relevance.</p><p>We wished to assess the effectiveness of the techniques used by Web search engines in the TeraByte task, including in particular conjunctive queries and scoring exploiting: link popularity, proximity boost, home page score, descriptions and anchor text.</p><p>Since we expected conjunctive queries to be subject to lower recall than disjunctive queries, we explored a new method for query expansion, based on clustering snippets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The baseline approach</head><p>In the experiments we tried to evaluate the effectiveness of this approach to query expansion and rewriting using phrase and proximity queries on retrieval from a large collection.</p><p>We built queries starting from the title of each topic and extracting name entities and noun phrases. For example for topic 701 (oil industry history) the phrase " oil industry" and the term " history" are extracted. These elements are combined to form a proximity query like this:</p><p>text matches proximity 20 [ 'oil industry' history ]</p><p>Simple stemming was applied to add as an alternative in the query the singular form of plural terms. This processing produced an overall list of 114 queries for the 50 topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Query expansion through Web snippet clustering</head><p>The queries generated in the first step sometimes retrieve too few results, since topics titles are short, sometimes too many, since they include terms with broad meaning (history, issue, example). More effective queries can be produced using techniques of query expansion.</p><p>Relevance feedback can be used as for query modification in two ways: expanding the query by adding new terms from relevant documents <ref type="bibr" coords="8,286.29,403.88,18.80,11.48" target="#b15">[15]</ref>; adjusting the individual term weights based on the user relevance judgments <ref type="bibr" coords="8,214.65,417.68,18.53,11.48" target="#b14">[14]</ref>. Query expansion is more appropriate to our goal of increasing recall.</p><p>Query expansion through local clustering, as discussed in <ref type="bibr" coords="8,368.85,451.28,12.87,11.48" target="#b2">[2]</ref>, expands the query with terms correlated to the query terms, selected from clusters built from the documents retrieved for the original query. Retrieving and clustering all or even the top hundred ranking documents is considered too expensive.</p><p>Query expansion through local context analysis is based on the use of noun groups, instead of single words, as document concepts. Concepts for query expansion are selected from the top ranked documents based on their co-occurrence within passages in these documents.</p><p>Our approach is similar to local context analysis, except that we use a global collection (the Web), we use clustering of result snippets to select new query terms and when appropriate such terms are used as replacements for query terms rather than additions.</p><p>To generate new queries for a topic we performed two steps:</p><p>• finding new terms related to the topic (e.g. petroleum),</p><p>• combining these terms into meaningful queries for a topic (e.g. substituting " petroleum" for " oil" , while keeping the other terms " industry history" ).</p><p>For finding additional terms for query expansion, we exploited clustering on an enriched collection, in this case the whole Web collection. We submitted the queries to the Vivisimo clustering engine <ref type="bibr" coords="8,158.97,703.88,20.08,11.48" target="#b10">[10]</ref> and we extracted the labels for the first level clusters (called " candidate labels" ) from the response; for example, for topic 701 the query consisted of the terms "oil industry" AND history and produced the following labels: Petroleum, Oil and Gas, Texas, Books, Market, Standard Oil, Collection, Drake, Iraq, Profiles.</p><p>In order to select suitable labels for query expansion, we used an intuitive heuristics. A further query was submitted to Vivisimo for each of the candidate labels: if it produced clusters whose labels contained a term present in the original topic, then the label was considered suitable for query expansion, otherwise it was discarded. In the above example, labels like " Market" and " Books" were considered unrelated and hence discarded.</p><p>The labels deemed related were used to generate expanded queries as follows: terms in a candidate label replace the terms that appeared in the matching cluster label. For example, the query for the candidate label " Petroleum" produces a cluster with the term " oil" in its label, so the query " petroleum industry" AND history is obtained by replacing " oil" with " Petroleum" in the original query.</p><p>Through this process a total of 210 related labels were selected, generating additional query terms that were used to produce two (or more) variants of the original queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Merging query results</head><p>For each query in a topic up to 10,000 query results were retrieved and merged in a single list for the topic. Query results are a list of document IDs ordered by their retrieval score computed as described above. Instead of simply merging these lists and selecting the top ranking 10,000 documents, we classify queries into four categories:</p><p>• Original proximity queries: the ones directly extracted from topics, with a strict proximity constraint. • Original non-proximity queries: the ones directly extracted from topics, with a loose proximity constraint. • Generated proximity queries: the ones generated using clustering, with a strict proximity constraint. • Generated non-proximity queries: the ones generated using clustering, with a loose proximity constraint. Results obtained from queries in each category are expected to be more relevant than those from later categories. To take this into account, the overall score used in merging results from all queries involves a weight that decreases from the first to the last category. Weights have been assigned manually.</p><p>When a document is retrieved through more than one query, it gets the maximum of its scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Screening Results by means of Clustering</head><p>Identifying the subject of a document may be useful to sift them, distinguishing those most relevant to a topic. For example, for topic 702 (pearl farming), a number of retrieved documents were about child labor, and pearl farming was cited in passing among the sectors where child labor is exploited.</p><p>We experimented with the use of clustering to group documents and to screen them according to which cluster they belong to, lowering their rank if they appear in a cluster with little relation to the topic, raising their rank if the cluster had a title that appeared relevant to the topic being searched.</p><p>We extracted from each document in the result list a few snippets containing the topic query terms (those terms used in retrieving the documents for a given topic). For example, for topic 701 (US oil industry history), the topic query terms included also Drake, obtained from query expansion, and the following snippets were extracted from one of the result documents:</p><p>Mr. Peterson speaks about the need for Energy Independence during an Energy Town Hall at Drake's Well... In August 1859, Colonel Edwin L. Drake completed the world's first successful oil well near Titusville and changed the course of history</p><p>The snippets from the results of each topic are passed to the clustering engine. Resulting clusters are processed similarly as it was done for queries generation: if a cluster label contains at least one topic query term, then the score for each document in that cluster is increased by the following factor:</p><formula xml:id="formula_3" coords="10,200.97,280.79,210.28,11.57">log (resultsSize / (resultsSize -clusterSize))</formula><p>where resultsSize is the number of results retrieved for the topic and clusterSize is the size of the cluster. This boosting is not applied to small clusters (those containing less than 10% of the total results). Clusters whose label does not match any topic query term are instead considered unrelated and the score of their documents is decreased by a 0.01 factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Combining results</head><p>We submitted four runs to the TREC 2004 TeraByte track.</p><p>The first run is our baseline run and was produced using a set of 552 queries: 114 extracted from the TeraByte topics title and 438 produced through query expansion by means of clustering. The latter set contained two variants for each query: one with a proximity 20 constraint and a 0.8 weight, and one without proximity and a 0.4 weight. The queries produced a total of 488,866 results, reduced to 225,445 after duplicate removal; no boosting was applied. This run took 161 seconds to complete, with an average time of 0.3 second per query (3.2 seconds per topic).</p><p>For the second run we reindexed the collection, adding a count of the number of informative and non-informative links in a page, which was used to lower the rank of documents having little contents: in particular pages describing single items like book library cards.</p><p>The queries were changed by adding non-proximity versions for queries that had returned few results, in an attempt to increase recall. This run used a set of 669 queries that produced 1,352,910 results, 275,741 after merge. This run took 296 seconds to complete, with an average time of 0.4 second per query (5.9 seconds per topic).</p><p>In the third run non-proximity queries were replaced with proximity queries with a wider proximity limit (from 20 to 200), to discard documents that contained the query terms in unrelated sections. The run consisted of 682 queries that produced 428,208 results, 148,156 after merging. This run took 190 seconds to complete, with an average time of 0.3 second per query (3.8 seconds per topic).</p><p>The fourth run was devised to measure the effects of relevance screening by clustering. The screening step was applied to the results obtained from the previous run. Extracting the snippets for all the results is more time consuming than processing the queries and takes about 40 minutes overall. This operation consisted in sending the request for snippet, composed of the document ID and the terms to be used for snippet extraction, to the server that holds the document. The server retrieves the document from its local cache, uncompresses it, extracts the snippet and sends it back. Snippets for each topic are then processed by the clustering engine to produce clusters. The time required to produce the clusters varies from a few seconds for smaller result sets up to 20 minutes for the largest clusters of 10,000 documents. After this, calculating the boost factors and merge sorting the results required about 12 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>For comparison purposes we report the result of two unofficial runs: one that uses just topic title words and Okapi BM25 ranking, without the additional weights for link popularity and content rate; and a second one that uses conjunctions of the topic title words as queries, also without additional weights and without the boost for proximity that IXE normally applies to conjunctive queries. The first runs achieves a better than median score, while using conjunctive queries produces a 18% drop in precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>The drop is more drastic in run pisa1, which uses proximity queries instead of conjunctions. Only relaxing the proximity constraints, in run pisa3, precision raises back to the level of simple conjunctions.</p><p>As expected, query expansion has a significant effect on recall, with an overall increase of over 50%.</p><p>The marginal improvements in run pisa4 lead us to conclude that the effects of screening by clustering are not worth the effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We built a distributed search engine that applies the strategies typically used by Web Search engines (conjunctive queries and ranking based on a combination of criteria) and compared its effectives to the techniques typically used for ad-hoc retrieval. Contrary to expectations, certain criteria, like boosting the rank for documents where query terms appear closer, have a negative effect on precision. We explored a new approach to query expansion, based on extracting terms from the clustering of snippets returned from the first query. The approach is effective and increases precision significantly and recall even more.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,85.17,267.68,259.00,66.68"><head>table (</head><label>(</label><figDesc></figDesc><table coords="4,85.17,267.68,259.00,66.68"><row><cell></cell><cell>if available)</cell></row><row><cell>global ID:</cell><cell>retrieved from URL table</cell></row><row><cell>title:</cell><cell>title from the document</cell></row><row><cell>text:</cell><cell>content of document</cell></row><row><cell>citations:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,188.73,260.01,234.92,89.14"><head>Table 1 .</head><label>1</label><figDesc>Size of the index files for the GOV2 collection.</figDesc><table coords="5,188.73,260.01,234.92,70.51"><row><cell>Structure</cell><cell>Size</cell></row><row><cell>Lexicon</cell><cell>4.2 GB</cell></row><row><cell>Posting Lists (including positions)</cell><cell>62.0 GB</cell></row><row><cell>Metadata</cell><cell>26.0 GB</cell></row><row><cell>Document cache (optional)</cell><cell>84.0 GB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,126.21,553.87,358.31,102.64"><head>HTTP Server Query Server query Shard index Query Server</head><label></label><figDesc></figDesc><table coords="6,224.97,575.97,259.55,70.93"><row><cell></cell><cell>Async</cell></row><row><cell>Broker</cell><cell>I/O</cell></row><row><cell>Module Broker</cell><cell></cell></row><row><cell>Module</cell><cell>Shard</cell></row><row><cell></cell><cell>index</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,71.01,240.20,470.36,238.64"><head></head><label></label><figDesc>a search engine written in C by the Search Engine Group at RMIT University, and Lucene<ref type="bibr" coords="7,446.49,254.00,14.08,11.48" target="#b8">[8]</ref> a search engine written entirely in Java. The benchmarks were run on a single 800 MHz Pentium III, with 1 GB of memory, on the directory GX000 of the GOV2 collection, which consists of 89,771 documents with 719,670 distinct terms. Index sizes were 207 MB for IXE, 183 MB for Zettair and 332 MB for Lucene. Indexing times were 13 min. for IXE, 6 min. for Zettair and 4 hours for Lucene.Since IXE performs proximity calculations also for AND queries in order to boost rank, the comparison was done on phrase searches.</figDesc><table coords="7,97.77,365.37,407.40,113.47"><row><cell>Query</cell><cell>Results</cell><cell>IXE</cell><cell>Zettair</cell><cell>Lucene</cell></row><row><cell>" click here"</cell><cell>4932</cell><cell>10</cell><cell>15</cell><cell>37</cell></row><row><cell>" personal information"</cell><cell>901</cell><cell>12</cell><cell>32</cell><cell>37</cell></row><row><cell>" united states"</cell><cell>14052</cell><cell>17</cell><cell>39</cell><cell>57</cell></row><row><cell>" site map"</cell><cell>14492</cell><cell>25</cell><cell>41</cell><cell>88</cell></row><row><cell>" privacy policy"</cell><cell>13418</cell><cell>27</cell><cell>39</cell><cell>55</cell></row><row><cell>" contact us"</cell><cell>19311</cell><cell>36</cell><cell>68</cell><cell>112</cell></row><row><cell>" home page"</cell><cell>14668</cell><cell>46</cell><cell>57</cell><cell>141</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgements</head><p>This research was supported in part by the Italian MIUR ministry as part of project <rs type="projectName">Grid</rs>.it. <rs type="person">Maria Simi</rs> provided comments on a draft of the paper.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_QchmF2M">
					<orgName type="project" subtype="full">Grid</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,77.67,135.56,101.10,16.73" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,156.68,443.28,11.48;12,98.01,170.39,407.04,11.57" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,183.45,156.68,357.84,11.48;12,98.01,170.48,108.13,11.48">Juru at TREC 2003 -Topic Distillation using Query-Sensitive Tuning and Cohesiveness Filtering</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amitay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,213.57,170.39,256.22,10.80">Text REtrieval Conference (TREC) 2003 Proceedings</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,184.19,443.28,11.57;12,98.01,198.08,108.24,11.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,220.53,184.28,211.85,11.48">Local feedback in full-text retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Attar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Fraenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,441.09,184.19,93.12,10.80">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="397" to="4117" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,211.88,443.28,11.48;12,98.01,225.59,443.28,10.80;12,98.01,239.39,419.88,11.57" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,234.69,211.88,300.87,11.48">Reflection support by means of template metaprogramming</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Attardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cisternino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,98.01,225.59,443.28,10.80;12,98.01,239.39,102.81,10.80">Proceedings of Third International Conference on Generative and Component-Based Software Engineering</title>
		<meeting>Third International Conference on Generative and Component-Based Software Engineering<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001-09">September 2001</date>
			<biblScope unit="volume">2186</biblScope>
			<biblScope unit="page" from="178" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,253.28,443.33,11.48;12,98.01,266.99,443.16,11.57;12,98.01,280.79,238.20,11.57" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,219.69,253.28,321.65,11.48;12,98.01,267.08,85.13,11.48">Enabling Web Information Retrieval through Query Expansion via Contrast Analysis</title>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-C</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,207.21,266.99,333.96,10.80;12,98.01,280.79,40.22,10.80">Proc. of the seventh International Conference on World Wide Web (WWW7)</title>
		<meeting>of the seventh International Conference on World Wide Web (WWW7)<address><addrLine>Brisbane, Queensland, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,294.68,443.26,11.48;12,98.01,308.39,443.42,11.57;12,98.01,322.19,360.00,11.57" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,386.97,294.68,154.30,11.48;12,98.01,308.48,192.15,11.48">Experiments on Adaptive Set Intersections for Text Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">Erik</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lopez-Ortiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J Ian</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,311.61,308.39,229.82,10.80;12,98.01,322.19,141.03,10.80">Proceedings of the 3rd Workshop on Algorithm Engineering and Experiments</title>
		<meeting>the 3rd Workshop on Algorithm Engineering and Experiments<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">January 5-6, 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,336.08,141.48,11.48" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Dmoz</surname></persName>
		</author>
		<ptr target="http://www.dmoz.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,349.79,443.40,11.57;12,98.01,363.68,286.00,11.48" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,287.97,349.79,130.31,11.57">Heap Ltd., Dr Dobb&apos;s</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gontmakher</surname></persName>
		</author>
		<ptr target="http://www.cs.technion.ac.il/~gabr/papers/limited_heap.pdf" />
	</analytic>
	<monogr>
		<title level="j" coord="12,429.57,349.79,35.39,10.80">Journal</title>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,378.08,198.84,11.48" xml:id="b8">
	<monogr>
		<ptr target="http://jakarta.apache.org/lucene/" />
		<title level="m" coord="12,98.01,378.08,32.71,11.48">Lucene</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,391.88,443.32,11.48;12,98.01,405.68,443.16,11.48;12,98.01,419.39,443.28,11.57;12,98.01,433.19,274.56,11.57" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,357.45,391.88,183.88,11.48;12,98.01,405.68,110.20,11.48">Compression of Inverted Indexes For Fast Query Evaluation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yiannis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,145.77,419.39,395.52,10.80;12,98.01,433.19,102.59,10.80">Proc. ACM-SIGIR International Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Jarvelin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Myaeng</surname></persName>
		</editor>
		<meeting>ACM-SIGIR International Conference on Research and Development in Information Retrieval<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,447.08,147.96,11.48" xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Vivisimo</surname></persName>
		</author>
		<ptr target="http://vivisimo.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,460.88,390.84,11.48" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="http://www.seg.rmit.edu.au/zettair" />
		<title level="m" coord="12,189.09,460.88,123.84,11.48">The Zettair Search Engine</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,474.59,443.27,11.57;12,98.01,488.39,299.64,11.57" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="12,243.69,474.59,297.59,10.80;12,98.01,488.39,114.37,11.57">Managing Gigabytes: Compressing and Indexing Documents and Images, 2nd edition</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,502.19,443.20,11.57;12,98.01,515.99,443.16,11.57;12,98.01,529.88,123.00,11.48" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,192.81,502.28,281.81,11.48">Query expansion using local and global document analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,482.37,502.19,58.84,10.80;12,98.01,515.99,395.63,10.80">Proc. ACM-SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>ACM-SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Zurich, Switseraland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,543.59,443.21,11.57;12,98.01,557.39,309.48,11.57" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,269.13,543.68,190.70,11.48">Relevance Weighting of Search Terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,470.25,543.59,70.97,10.80;12,98.01,557.39,199.18,10.80">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,571.19,443.35,11.57;12,98.01,584.99,370.32,11.57" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="12,163.29,571.28,218.51,11.48;12,482.61,571.19,58.75,10.80;12,98.01,584.99,77.98,10.80">Relevance Feedback in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
		<editor>Salton G.</editor>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>Prentice-Hall, Inc</publisher>
			<biblScope unit="page" from="313" to="323" />
			<pubPlace>Englewood Cliffs, N.J.</pubPlace>
		</imprint>
	</monogr>
	<note>The SMART Retrieval System</note>
</biblStruct>

<biblStruct coords="12,98.01,598.88,443.26,11.48;12,98.01,612.68,342.84,11.48" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,229.41,598.88,267.85,11.48">Improving retrieval performance by relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,505.89,598.88,35.38,11.48;12,98.01,612.68,232.45,11.48">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="288" to="297" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.01,626.48,443.28,11.48;12,98.01,640.28,341.28,11.48" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Mccarley</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ward</forename></persName>
		</author>
		<ptr target="http://trec.nist.gov/pubs/trec8/papers/t8_ibm_hlt.pdf" />
		<title level="m" coord="12,242.37,626.48,298.92,11.48;12,98.01,640.28,77.85,11.48">Ad hoc, Cross-language and Spoken Document Information Retrieval at IBM</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
