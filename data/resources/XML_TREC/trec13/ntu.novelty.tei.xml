<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,167.64,106.22,260.44,15.13">Similarity Computation in Novelty Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,182.04,134.75,67.00,11.89"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
							<email>mftsai@nlg.csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<addrLine>1, Section 4, Roosevelt Road</addrLine>
									<postCode>106</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.96,134.75,68.02,11.89"><forename type="first">Ming-Hung</forename><surname>Hsu</surname></persName>
							<email>mhhsu@nlg.csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<addrLine>1, Section 4, Roosevelt Road</addrLine>
									<postCode>106</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.80,134.75,64.05,11.89"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
							<email>hh_chen@csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<addrLine>1, Section 4, Roosevelt Road</addrLine>
									<postCode>106</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,167.64,106.22,260.44,15.13">Similarity Computation in Novelty Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">29E6D94935364925873C79D10616A1DE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The novelty track was first introduced in TREC 2002. Given a TREC topic, the goal of this task in 2004 is to locate relevant and new information from a set of documents. From the results in TREC 2002 and 2003, we realized the major challenging issue of recognizing relevant sentences is the lack of information used in similarity computation among sentences. In this year, we utilized the method based on variants of employing an information retrieval (IR) system to find relevant and novel sentences. This methodology is called IR with reference corpus, which can also be considered as an information expansion of sentences. A sentence is considered as a query of a reference corpus, and similarity between sentences is measured in terms of the weighting vectors of document lists ranked by IR systems. Basically, relevant sentences are extracted by comparing their results on a certain information retrieval system. Two sentences are regarded as similar if their corresponding returned document lists by the IR system are similar. In novelty parts, we used similar approach to extract novel sentences from the sentences of the relevant part. An effectively dynamic threshold setting approach that is based on what percentage of relevant sentences is within a relevant document is presented. In this paper, we paid attention to three points: first, how to utilize the results of an IR system to compare the similarity between sentences; second, how to filter out the redundant sentences; third, how to determine appropriate relevance and novelty threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Procedure</head><p>The flow of our proposed method, called IR with reference corpus, is illustrated in Figure <ref type="figure" coords="1,500.52,540.35,3.98,11.89">1</ref>, which contains an IR system and a reference corpus inside. To begin with, each sentence from the given documents is treated as a query to a certain IR system that retrieves documents from the reference corpus. Then, a sentence can be translated into a vector that uses each document of whole reference corpus as one dimension and sets the relevant weight assigned by the IR system as the weight of each dimension, where the weight of a dimension is zero if the IR system does not retrieve that document. For example, a reference corpus may contain m documents, then each sentence of given documents can be regarded as a vector with m dimensions those weight is the relevant score returned by the IR system. Finally, a similarity metric, such as cosine similarity, is utilized to measure the similarity between vectors. The threshold technique is applied to the following operation, retrieval or filter. In the following, we will discuss this approach in detail.</p><p>Figure <ref type="figure" coords="2,214.32,343.31,4.20,11.89">1</ref>: Flow of IR with reference corpus approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">IR System and Reference Corpus</head><p>In the experiments, the document sets used in TREC-6 text collection (Voorhees and Harman, 1997) were considered as a reference corpus. It consists of 556,077 documents. Okapi IR system (Robertson, Walker and Beaulieu, 1998) was adopted in out experiment. In the initial experiments, Okapi was in the option of bm25, and it got average precision of 0.2181 on TREC-6 text collection.</p><p>In order to investigate the influence of the reference corpus, we utilized the document segmentation tool to separate each document of TREC-6 text collection into several coherent paragraphs. It totally contained 3,614,500 paragraphs after segmentation. This year, we used this segmented corpus as the reference corpus to experiment further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Similarity Computation</head><p>The cosine similarity computation is considered appropriate for our task. The metric is shown as follows.</p><p>, , 1 cos( , )</p><formula xml:id="formula_0" coords="2,247.32,583.78,251.02,30.47">|| || || || l i k j k k i j i j v v s s s s = × = (1)</formula><p>where s i is represented as a sentence-vector (v i,1 , v i,2 , …, v i,l ), l denotes the number of documents retrieved from the reference corpus by the IR system; s j is another sentence-vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Threshold Setting</head><p>In this phase, we considered that what percentage of sentences was relevant within a document. In TREC 2002, Larkey et al. showed that about 5% of the sentences contained relevant materials for average topic. In TREC 2003, however, the percentage was soared by 40% of total sentences.</p><p>Therefore, we applied the collection of statistics in 2003 to relevant and novel threshold setting. We also discovered the percentage of relevant sentences became less when total number of given sentences was more. Therefore, we used logarithmic regression as follows to simulate the relationship between total number of the given sentences and percentage of the relevant sentences.</p><p>A dynamic threshold-setting model is proposed as follows. Assume normal distribution with mean µ and standard deviation 3 is adopted to specify the similarity distribution of the given sentences with a topic. We compute the cosine of a topic vector T and a given sentence vector S i (1 i m), where m denotes total number of the given sentences. The percentage n denotes that top n percentage of the given sentences will be reported. Similarity thresholds (TH relevance ) are determined by the percentage.  <ref type="figure" coords="3,281.23,323.57,12.56,10.78">( ,</ref><ref type="figure" coords="3,303.12,323.57,3.24,10.78">)</ref> )</p><formula xml:id="formula_1" coords="3,226.44,317.38,271.66,99.52">m i i T S m µ = = (3) relevance TH = +z µ (4) 2 / 2 1 ( ) 1 2 z y z e d y n = =<label>(5)</label></formula><p>We first compute the percentage n, and then derive z by Formula (5). Finally, TH relevance is computed by Formula (4). Therefore, the relevance threshold is determined by the total amounts of given sentences.</p><p>In the novelty part, a threshold of novelty decision, TH novelty , determines the degree of redundancy. If the similarity score of two sentences is larger than TH novelty , then one of them has to be filtered out depending on their appearing order in the context. For example, if the fifth sentence is similar to the second sentence, then the fifth one will be filtered out. In this way, the redundant sentences are filtered out and only the novel sentences are kept. The remaining sentences are the result of the novelty detector. Two algorithms are proposed as follows. Assume there are r relevant sentences, s 1 , s 2 , …, s r , for topic t.</p><p>(1) Static threshold approach Let T be a set containing novel sentences found up to know. Initially, we take T = {s 1 }. For each relevant sentence s i (2 i r), if there exists a sentence in T whose similarity with s i is larger than a predefined threshold, then s i is not a novel sentence and is removed; otherwise, s i is kept in T.</p><p>(2) Dynamic threshold approach Assume s 1 is a novel sentence. First compute the similarities between s 1 and s i (2 i r). Then, determine the novelty threshold, TH novelty , in the same way as TH relevance .</p><p>Filter out the top n percentage of sentences with the higher similarities with s 1. Let R be the remaining sentences. If the number of sentences in R is less than 30<ref type="foot" coords="3,448.92,667.72,3.39,7.50" target="#foot_0">1</ref> , then regard these sentences as novel sentences and stop. Otherwise, select the first sentence in R, regard it as a novel sentence and repeat the same filtering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Finding Relevant Sentences</head><p>Given the set of documents for each topic, this part is to identify all relevant sentences from them. We first treated each given sentence as a query to the IR system, and then got a vector of document weight assigned by the IR system. Next, we applied the cosine function to measure similarity between sentences. In the part of threshold setting, we used the statistics in TREC 2002 novelty track to simulate the relation of total number of given sentences and percentage of relevant sentences. Formula 6 and Figure <ref type="figure" coords="4,277.56,224.87,5.37,11.89" target="#fig_1">2</ref> showed the trend. Because some topics might get less percentage, we applied a parameter to multiply the percentage calculated by Formula ( <ref type="formula" coords="4,488.35,237.11,4.15,11.89">6</ref>) to retrieve more sentences. Take Ln-4 as an example. That means that it multiplies 4 to the calculated percentage. Figure <ref type="figure" coords="4,135.84,520.31,5.37,11.89" target="#fig_2">3</ref> shows the experimental results of relevance detection in TREC 2003. These results are totally different from those in TREC 2002, because the number of qrels of relevance information in 2003 is dramatically more than that in 2002. In TREC 2002, the percentage of relevant sentences within the whole given sentences was about 5%, but in TREC 2003 some topics even had about 50 percent of relevant sentences. Therefore, our average recall gets lower since our relevance threshold is too high. That demonstrates the issue of identifying an appropriate threshold in the novelty detection is very important. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Finding Novel Sentences</head><p>This part is to identify sentences that include new information among the relevant sentences. In other words, this part will filter out the redundant sentences. The key issue of finding novel sentences is how to differentiate the meaning of sentences accurately. We extended the idea, i.e., employing IR with reference corpus approach to expand a sentence, to find novel sentences. We made an experiment with two novelty threshold-setting algorithms: static and dynamic settings.</p><p>In order to test this model, we used the perfect relevance results to experiment. The number of consulted paragraphs retrieved by IR system was set to 1000. Figure <ref type="figure" coords="5,137.76,393.47,5.37,11.89">4</ref> demonstrates the results of finding novelty with static threshold setting. When novelty threshold is 1, it does not filter out any sentences. The performance gets better as the novelty threshold is higher. Figure <ref type="figure" coords="5,259.80,418.19,5.37,11.89" target="#fig_3">5</ref> shows the results of finding novelty with dynamic threshold setting. The result reveals that when the more percentage filtered, the worse the performance is. From these results, the performance will be better if we filter out fewer sentences. Therefore, we set the novelty threshold higher in the submitted runs to achieve better performance. 4 Runs Submitted</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task1</head><p>Given the full set of documents for each topic, the task 1 is to identify all relevant and novel sentences. Table <ref type="table" coords="6,168.48,359.51,5.37,11.89">1</ref> shows the runs we submitted in task 1. In the runs, the number of consulted paragraphs was set to 1000, the dynamic relevance threshold used Ln-1 and Ln-2, and all runs only used the topic description. In the novelty part of task 1, all runs used the static threshold setting where NTU11, NTU13 and NTU15 were set to 0.8; NTU12 and NTU14 were set to 0.9.</p><p>Table <ref type="table" coords="6,247.44,419.39,4.13,11.89">1</ref>: Submitted results in task 1.</p><p>Relevant Detection Novelty Detection Avg P Avg R Avg F Avg P Avg R Avg F NTU11 0.25 0.77 0.357 0.11 0.74 0.186 NTU12 0.22 0.88 0.336 0.10 0.85 0.174 NTU13 0.26 0.69 0.344 0.12 0.65 0.184 NTU14 0.25 0.74 0.345 0.11 0.71 0.182 NTU15 0.25 0.78 0.352 0.11 0.74 0.183</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task2</head><p>Given all relevant sentences, the task 2 of Novelty Track is to identify all novel sentences. Table <ref type="table" coords="6,87.48,579.35,5.37,11.89" target="#tab_0">2</ref> shows the submitted results in task 2. We used two novelty algorithms to find novelty sentences. In task 2, NTU21, NTU22 and NTU23 used the static threshold setting; NTU24 and NTU25 used the globe threshold setting. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,200.64,491.03,194.21,11.89"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustration of logarithmic trend.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,182.88,255.71,229.85,11.89"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Experimental results of relevance detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,126.96,628.07,341.68,11.89"><head>Figure 5 :</head><label>5</label><figDesc>Figure 4: Experimental results of novelty detection with static threshold setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,221.04,626.87,153.53,106.21"><head>Table 2 :</head><label>2</label><figDesc>Submitted results in task 2.</figDesc><table coords="6,228.12,646.07,146.25,87.01"><row><cell></cell><cell cols="3">Novelty Detection</cell></row><row><cell></cell><cell cols="3">Avg P Avg R Avg F</cell></row><row><cell>NTU21</cell><cell>0.45</cell><cell>0.99</cell><cell>0.6</cell></row><row><cell>NTU22</cell><cell>0.44</cell><cell cols="2">0.99 0.598</cell></row><row><cell>NTU23</cell><cell>0.44</cell><cell cols="2">0.99 0.598</cell></row><row><cell>NTU24</cell><cell>0.49</cell><cell cols="2">0.57 0.495</cell></row><row><cell>NTU25</cell><cell>0.50</cell><cell cols="2">0.52 0.477</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,95.52,725.48,317.80,10.73"><p>A sample size of at least 30 has been found to be adequate for normal distribution</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
