<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.62,109.35,356.75,18.08;1,112.38,131.27,234.96,18.08;1,347.35,129.50,22.11,12.55;1,376.41,131.27,123.20,18.08">Robust, Web and Terabyte Retrieval with Hummingbird SearchServer TM at TREC 2004</title>
				<funder ref="#_QgchF7T #_KjWcTYm">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-02-06">February 6, 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,264.32,166.33,83.36,10.46"><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
							<email>stephen.tomlinson@hummingbird.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hummingbird Ottawa</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.62,109.35,356.75,18.08;1,112.38,131.27,234.96,18.08;1,347.35,129.50,22.11,12.55;1,376.41,131.27,123.20,18.08">Robust, Web and Terabyte Retrieval with Hummingbird SearchServer TM at TREC 2004</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-02-06">February 6, 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">3FCFEB797DFB8CAFF89634146B1DF7F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hummingbird participated in 3 tracks of TREC 2004: the ad hoc task of the Robust Retrieval Track (find at least one relevant document in the first 10 rows from 1.9GB of news and government data), the mixed navigational and distillation task of the Web Track (find the home or named page or key resource pages in 1.2 million pages (18GB) from the .GOV domain), and the ad hoc task of the Terabyte Track (find all the relevant documents with high precision from 25.2 million pages (426GB) from the .GOV domain). In the robustness task, SearchServer found a relevant document in the first 10 rows for 46 of the 49 new short (Title-only) topics. In the web task, SearchServer returned a desired page in the first 10 rows for more than 75% of the 225 queries. In the terabyte task, SearchServer found a relevant document in the first 10 rows for 45 of the 49 short topics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Hummingbird SearchServer<ref type="foot" coords="1,192.71,443.39,3.97,7.32" target="#foot_0">1</ref> is a toolkit for developing enterprise search and retrieval applications. The SearchServer kernel is also embedded in other Hummingbird products for the enterprise.</p><p>SearchServer works in Unicode internally <ref type="bibr" coords="1,276.89,468.37,10.52,10.46" target="#b2">[3]</ref> and supports most of the world's major character sets and languages. The major conferences in text retrieval experimentation (TREC <ref type="bibr" coords="1,426.41,480.33,9.96,10.46" target="#b5">[6]</ref>, CLEF <ref type="bibr" coords="1,473.56,480.33,10.52,10.46" target="#b0">[1]</ref> and NTCIR <ref type="bibr" coords="1,72.00,492.28,10.79,10.46" target="#b3">[4]</ref>) have provided opportunities to objectively investigate SearchServer's support for more than a dozen languages.</p><p>This paper looks at experimental work with SearchServer (experimental 6.0 builds) for robust retrieval (robustness of ad hoc search across topics), mixed web navigation and distillation (find the one page the user wanted, i.e. a known-item search task, or find key resource pages for broad topics), and terabyte retrieval (ad hoc search on terabyte scales).</p><p>2 Robust Retrieval For the TREC 2004 Robust Retrieval Track, there were 50 new topics and 200 old topics. The collection to be searched was the same as last year: a subset of the news and government data of TREC Disks 4 and 5 (FBIS, Federal Register 94, Financial Times, LA Times). It consisted of 528,155 documents totaling 1,997,002,586 bytes (1.9 GB). The average document size was 3781 bytes, though some documents were hundreds of kilobytes.</p><p>While the general objective was to find all the relevant documents for the topic and return them at the top of the list, participants were asked to focus not just on mean average precision but on at least one other measure indicative of "robustness" across topics, such as the Success@10 measure (percentage of topics for which at least one relevant was retrieved in the first 10 rows).</p><p>Each topic contained a "Title" (subject of the topic, e.g. "killer bee attacks"), "Description" (a onesentence specification of the information need, e.g. "Identify instances of attacks on humans by Africanized (killer) bees.") and "Narrative" (more detailed guidelines for what a relevant document should or should not contain, e.g. "Relevant documents must cite a specific instance of a human attacked by killer bees. Documents that note migration patterns or report attacks on other animals are not relevant unless they also cite an attack on a human.").</p><p>It turned out one of the new topics had no relevant documents, leaving 249 topics in total. For these, there were on average 70 relevant documents per topic (low 3, high 448, median 41).</p><p>For the submitted runs due in August 2004, it was requested that at least one run just use the Title field as the basis of the query and at least one run just use the Description field.</p><p>More information on this task is expected to be in the track overview paper of the TREC proceedings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>Our indexing approach was mostly the same as last year <ref type="bibr" coords="2,315.37,265.93,14.61,10.46" target="#b11">[12]</ref>. We used a SearchServer index which supported both exact matching (after some Unicode-based normalizations, such as decompositions and conversion to upper-case) and matching of inflections based on English lexical stemming (i.e. stemming based on a dictionary or lexicon for the language). For example, in English, "baby", "babied", "babies", "baby's" and "babying" all have "baby" as a stem. Some stop words were excluded from indexing (e.g. "the", "by" and "of" in English); we used a smaller stopfile than last year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Searching</head><p>Unlike previous years, this year we experimented with SearchServer's CONTAINS predicate (instead of the IS ABOUT predicate); for short boolean-OR queries, CONTAINS should produce the same ranking as IS ABOUT. Our test application specified SearchSQL to perform a boolean-OR or boolean-AND of the query words. For example, for topic 430 whose Title was "killer bee attacks", a corresponding SearchSQL query with a boolean-OR of the Title words would be:</p><p>SELECT RELEVANCE('2:3') AS REL, DOCNO FROM ROBUST04 WHERE FT TEXT CONTAINS 'killer'|'bee'|'attacks' ORDER BY REL DESC;</p><p>For a boolean-AND, the CONTAINS list would be changed from 'killer'|'bee'|'attacks' to 'killer'&amp;'bee'&amp;'attacks', and only documents containing all of the specified words (or an inflection of each of them) would be retrieved. Most aspects of SearchServer's '2:3' relevance value calculation are the same as described last year <ref type="bibr" coords="2,521.73,541.87,14.61,10.46" target="#b11">[12]</ref>. Briefly, SearchServer dampens the term frequency and adjusts for document length in a manner similar to Okapi <ref type="bibr" coords="2,100.06,565.77,10.52,10.46" target="#b4">[5]</ref> and dampens the inverse document frequency using an approximation of the logarithm. When doing morphological searching (i.e. when SET TERM GENERATOR 'word!ftelp/inflect' was previously specified), these calculations are based on the stems of the terms (roughly speaking). This year's experimental SearchServer version contains an enhancement for handling multiple stemming interpretations (e.g. in English, "axes" has both "axe" and "axis" as stems). For each document, only the interpretation that produces the highest score for the document is used in the relevance calculation (but all interpretations are still used for matching and search term highlighting). Sometimes this enhancement causes the original query form of the word to get more weight than some of its inflections (and it never gets less weight). This enhancement typically makes little difference for English (an exception is topic 379 (mainstreaming) discussed below). More details were in our CLEF paper this year <ref type="bibr" coords="2,435.45,673.37,14.61,10.46" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relevance Options Compared</head><p>For ranking, SearchServer has several options, including 5 different RELEVANCE METHOD settings ('2:1', '2:2', '2:3', '2:4', '2:5') and a RELEVANCE DLEN IMP setting for controlling document length normalization (scale 0 to 1000). There is also a TERM GENERATOR option to control whether or not inflections of query terms are matched.</p><p>Using the full set of 249 topics, we looked at whether the impacts of SearchServer's ranking and matching options for English ad hoc search were the same for boolean-AND queries as for boolean-OR queries. For these tests, just the Title field of the topic was used (typically 3 words).</p><p>For each approach (boolean-OR and boolean-AND), there was a "baseline" run using the options expected to score highest based on past experience (SET RELEVANCE METHOD '2:3', SET RELE-VANCE DLEN IMP 500, SET TERM GENERATOR 'word!ftelp/inflect'). The other diagnostic runs differed from the baseline as follows:</p><p>• "2:1": The run used relevance method '2:1', "hits count", i.e. a simple count of all of the matches in a document (so repeated matches count multiple times). Note that document length normalization is ignored by this method.</p><p>• "2:2": The run used relevance method '2:2', "terms count", i.e. a count of the number of query terms matched (so if the query contains 3 words, the maximum score for a document is 3). Since inflections were enabled, a query term would count if any inflection of it was matched (but different inflections of the same word would not count for more than 1). Document length normalization is ignored by this method.</p><p>• "2:3": This is the baseline run using relevance method '2:3', "terms ordered". A formula which incorporates term frequency, inverse document frequency and document length normalization is applied as described earlier (Section 2.2).</p><p>• "2:3 with no stemming": Inflections were disabled for this run (i.e. SET TERM GENERATOR '').</p><p>• "2:3 with no dlen": Document length normalization was disabled for this run (i.e. SET RELE-VANCE DLEN IMP 0).</p><p>• "2:4": The run used relevance method '2:4', "critical terms ordered", which squares the importance of inverse document frequency compared to '2:3' (i.e. less common terms get even stronger weight).</p><p>• "2:5": The run used relevance method '2:5', "consistent terms ordered", which is an experimental new relevance method that is the same as '2:3' except that it does not include inverse document frequency (all the query terms are treated as being equally important).</p><p>Table <ref type="table" coords="3,113.65,521.90,4.98,10.46" target="#tab_0">1</ref> lists the mean scores of the diagnostic runs (see the glossary at the end of the paper for definitions of the measures). It appears that either '2:3' or '2:4' is a good choice on average. For boolean-AND, '2:5' (which treats each term as equally important) also appears to be a reasonable choice, though it scores a little lower (on average) for boolean-OR queries. The simple hits count strategy ('2:1'), which is relatively poor with boolean-OR (Success@10 just 39%), is reasonably successful with boolean-AND (Success@10 of 76%). Where they differ, the results for boolean-AND seem to agree more with reports from the field than the results for boolean-OR. Perhaps some of the differences between past TREC results and field preferences has been from users preferring boolean-AND queries.</p><p>Table <ref type="table" coords="3,114.92,617.54,4.98,10.46">2</ref> shows more details of how each OR run differs from the baseline OR run and how each AND run differs from the baseline AND run in the average precision measure (see Section 6.1 for an explanation of the table columns). Tables <ref type="table" coords="3,202.17,641.45,4.98,10.46">3</ref> and<ref type="table" coords="3,229.33,641.45,4.98,10.46">4</ref> do the same for the Success@1 and Success@10 measures respectively. The followng subsections look at these differences in more detail. Topic 366 (commercial cyanide uses): Table <ref type="table" coords="5,264.08,310.33,4.98,10.46">2</ref> shows that '2:5' scored 46 points lower than '2:3' for this topic when boolean-OR was used. Relevant documents typically used the uncommon word "cyanide", and '2:3' gave such documents high scores from the word's high inverse document frequency, while the common words "commercial" and "use" had low inverse document frequencies and hence little impact. '2:5' had no preference for the "cyanide" term and retrieved a lot of documents with just lots of occurrences of "commercial" and "use", so it scored a lot lower on this topic. Boolean-AND does poorly on this topic with either relevance method because few of the relevant documents actually contained an inflection of "commercial". In practice, a user might realize this and change the query to just "cyanide" and get good results with either method. Topic 622 (price fixing): '2:5' scored 26 points lower than '2:3' for this topic when using boolean-AND (as per Table <ref type="table" coords="5,115.31,417.93,3.87,10.46">2</ref>). SearchServer's lexical stemmer produced two stems for "fixing" ("fixing" and "fix", presumably because the inflectional stem depends on whether "fixing" is a noun or a verb). The recent enhancement for alternative stems in effect weighted terms which share the "fixing" stem higher because that stem was less common (i.e. produced a higher inverse document frequency), and that was helpful for this topic. The '2:5' method disabled inverse document frequency so this benefit was lost. In practice, a user could workaround the issue with '2:5' by just disabling inflections for this query or by searching for "price fixing" as a phrase.</p><p>Topic 379 (mainstreaming): '2:5' scored 25 points lower than '2:3' for this topic when using boolean-AND (as per Table <ref type="table" coords="5,162.87,501.61,3.87,10.46">2</ref>). The reason was similar to what happened in the "fixing" query. SearchServer's lexical stemmer produced two stems for "mainstreaming" ("mainstreaming" and "mainstream"). '2:5' lost the benefit of inverse document frequency in effect preferring the original query form. The '2:4' method, which gives even more weight to inverse document frequency than '2:3', scored 5 points higher than '2:3' for this topic. In practice, a user could workaround the issue with '2:5' by just disabling inflections for this query.</p><p>Topic 339 (Alzheimer's Drug Treatment): For this topic '2:5' scored 11 points higher than '2:3', and '2:4' scored 7 points lower than '2:3', when using boolean-AND (as per Table <ref type="table" coords="5,414.32,585.31,3.87,10.46">2</ref>). The methods which used inverse document frequency favored documents with lots of occurrences of "Alzheimer's" and did not give as much weight to whether there were enough occurences of "drugs" or "treatment" for the document to be considered on topic. This topic is a case for which using inverse document frequency hurt the results of a boolean-AND query.</p><p>Overall, it appears inverse document frequency is useful for "noisy" queries because it often helps the important terms to stand out, but if the query is well-constructed (e.g. specifies only terms that really need to match, specifies only related inflections) then inverse document frequency might not be of much value and can sometimes be detrimental.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Impact of Document Length Normalization</head><p>For both boolean-AND and boolean-OR, enabling document length normalization was of statistically significant benefit for both mean average precision and Success@1 (as per the confidence intervals of the "no dlen" rows of Tables <ref type="table" coords="6,164.29,115.98,4.98,10.46">2</ref> and<ref type="table" coords="6,191.96,115.98,3.87,10.46">3</ref>). Here we focus on the extreme differences for boolean-AND in Table <ref type="table" coords="6,506.43,115.98,3.87,10.46">2</ref>:</p><p>Topic 679 (opening adoption records): This topic scored 65 points lower when not enabling document length normalization. The query words were fairly common (e.g. one can "adopt" new technologies, not just children) and the collection had a lot of long documents (100-700KB) which contained inflections of all 3 query words. The shorter documents (1-7KB) containing all 3 words were often relevant.</p><p>Topic 338 (Risk of Aspirin): For this topic, the score was 18 points higher without document length normalization. One of the relevant documents was fairly long (160KB), and there were just 4 relevants in total.</p><p>Overall, it appears that document length normalization is a helpful technique on average when the collection has a lot of long documents, and it probably won't make much difference if all the documents are short, so it seems safe to enable it by default (though note that looking up the document lengths may add modestly to search time in the current implementation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Impact of Stemming</head><p>Enabling inflections from stemming produced statistically significant increases in mean average precision for both boolean-OR and boolean-AND (as per Table <ref type="table" coords="6,293.30,303.72,4.43,10.46">2</ref>) and also for Success@10 when using boolean-AND (as per Table <ref type="table" coords="6,116.86,315.67,3.87,10.46">4</ref>).</p><p>Topic 328 (Pope Beatifications): This topic benefited from stemming because most relevants just used the singular form "Beatification". One relevant actually just used a derivation ("beatified", different part of speech) instead of an inflection and so was still not matched in the boolean-AND case.</p><p>Topic 648 (family leave law): This topic was hurt by stemming because it was better not to match inflections of "leave" such as "left" or "leaving". Note that SearchServer supports controlling inflections on a per-term basis (not just on the per-query basis investigated in this experiment).</p><p>Overall, for English, while enabling inflections may be a better default on average, it's advisable for the application to let the user control inflections on a per-query-word basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Simple Hits Count</head><p>In Table <ref type="table" coords="6,113.17,455.60,3.87,10.46">2</ref>, the topics on which the '2:1' method scored lower were mostly the same as those for the "no dlen" row. The simple count of all the hits appears to be particularly vulnerable to long documents.</p><p>In the boolean-OR case, '2:1' was particularly unsuitable for this task because a lot of occurrences of just one of the terms can dominate ('2:1' was the one method for which boolean-OR queries scored lower in mean average precision than boolean-AND). For boolean-AND, '2:1' was reasonably effective on average (though still less effective than the '2:3' method which dampens extra hits from the same term). '2:1' has the advantage of being easier for users to understand, so it's not surprising that some applications use it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5">Simple Terms Count</head><p>The '2:2' method should never score lower with boolean-OR than boolean-AND. All results which satisfy the boolean-AND will have the same '2:2' score (which is the number of query words minus stop words). With '2:2', a boolean-OR will start with all the same results as boolean-AND and then follow with the results of fewer matching terms.</p><p>Topic 677 (Leaning Tower of Pisa): The '2:2' method gives the same score to any document mentioning the tower, regardless of how often the tower is mentioned. Documents with more references are more likely to be on topic, so '2:3' was more effective.</p><p>Topic 615 (timber exports Asia): The '2:2' method scored higher than '2:3' for this topic from what seems to be a chance result. In the boolean-AND case, '2:2' in effect returned the matches in the order they were cataloged. LA Times articles were inserted first, and those matches happened to have most of the relevants for this topic.</p><p>Overall, it's not surprising that we seldom hear of the '2:2' method being used in practice. humR04t1 was the same as humR04t5 except that document length normalization was set to just 100 (which produced higher Success@n scores on the old 200 topics, but this did not carry over to the new topics).</p><p>humR04t1i was the same as humR04t1 except that the '2:5' relevance method was used (no inverse document frequency). As expected for boolean-OR, mean average precision was significantly lower. The Success@n scores were still respectable.</p><p>humR04t1m was the same as humR04t1 except that inflections from stemming were disabled. humR04t5e1 used the top row of humR04t1 as an expansion query (because it had a high Success@1 score on the old 200 topics) and merged with the result of humR04t5 (highest MAP on the old 200 topics). Compared to humR04t5, the MAP score was a little higher and the Success@n scores were a little lower, but these results were not statistically significant.</p><p>humR04d5 was the same as humR04t5 except that the Description field was used instead of the Title field. Note that for descriptions we automatically removed "query stop words" such as "find", "relevant" and "document" before giving the query to SearchServer (based on looking at some older topic lists). The mean scores were not significantly different when using the description instead of the title.</p><p>humR04d5i was the same as humR04d5 except that the '2:5' relevance method was used (no inverse document frequency). Mean average precision dropped significantly. Inverse document frequency may be more important for longer boolean-OR queries because it tends to help the more important terms to stand out. (All of the submitted runs used boolean-OR.) humR04d5m was the same as humR04d5 except that inflections from stemming were disabled. The drop in mean average precision was statistically significant.</p><p>humR04d4 was the same as humR04d5 except that the '2:4' relevance method was used (squared importance of inverse document frequency). The increase in mean average precision was statistically significant. humR04d4e5 used the top row of humR04d5 as an expansion query (because it had a higher Success@1 score on the old 200 topics than humR04d4, but this did not carry over) and merged the result with humR04d4 (highest MAP on the old 200 topics). While mean average precision went up, the decline in the Success@10 score (compared to humR04d4) was statistically significant. Blind expansion seems likely to help just when help is least needed, i.e. when there already is some success at the top of the list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Predicting Topic Difficulty</head><p>For the submitted runs, the participants were asked to append a ranking of the system's confidence of how well it did on the topic. For each run, we just used the relevance value (i.e. the number returned by the SearchServer RELEVANCE() function) of the top-retrieved row as our basis for ranking the topics. A higher relevance value was considered to mean a higher confidence in the relevance of the document.</p><p>The organizers computed Kendall's tau (τ ), a measure of rank correlation, between the predicted rank and the actual rank of the topics (based on the run's average precision score for each topic); see the track overview paper for more details. This value is denoted as τ 249 in Table <ref type="table" coords="8,380.98,163.80,4.98,10.46" target="#tab_1">5</ref> to emphasize that it is based on all 249 topics (but we did no tuning for this measure on the older 200 topics). Kendall's τ can range from -1 to +1, where +1 would mean perfect agreement between the rankings, 0 is the expected value if the prediction was random, and -1 would mean an exactly opposite ranking. The positive values for τ 249 (0.23 to 0.43 in Table <ref type="table" coords="8,99.43,211.61,4.43,10.46" target="#tab_1">5</ref>) suggest that SearchServer's RELEVANCE() values may have some relative meaning across topics. Hence normalizing them (by dividing each value by the first row's value) may lose information.</p><p>The lowest τ 249 scores (0.23 and 0.26) were for the runs which used the '2:5' relevance method (inverse document frequency replaced by a fixed constant). SearchServer's relevance value, roughly speaking, is the average inverse document frequency of the query terms, weighted by dampened term frequency of the matches. Intuitively, it makes sense that a system can be more confident of relevance when a rare term was found in a document.</p><p>For the other runs, the τ 249 scores were higher for those using the (one-sentence) Description as the query (0.40 to 0.43) than those using the (short) Title (0.29 to 0.35).</p><p>Note that we have not computed confidence intervals for the τ scores (or for the differences between them), so we should be particularly cautious of conclusions based on them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Web Retrieval</head><p>For the "mixed query" task of the TREC 2004 Web Track, there were 225 queries: 75 topic distillation queries, 75 home-page finding queries and 75 named page finding queries. But the queries were not labelled by their type (until after the submitted runs were due in September 2004).</p><p>The collection to be searched was the same .GOV collection as the previous two years. It consisted of pages downloaded from the .gov domain of the World Wide Web in early 2002. Uncompressed, it was 19,455,030,550 bytes (18.1 GB) and a total of 1,247,753 documents. The average document size was 15,592 bytes.</p><p>For topic distillation queries (e.g. "science"), the objective was to find home pages of sites in .GOV relevant to the topic (e.g. "www.nsf.gov" (National Science Foundation), "www.house.gov/science/welcome.htm" (House Committee on Science), etc.). This year, it turned out that there were on average 21 right answers per query (low 1, high 147, median 13).</p><p>For home-page finding queries (e.g. "Internal Revenue Service"), the objective was to find the home page of the named site (e.g. "www.irs.gov"). This year, 69 of the 75 queries had just one right answer (and none had more than four, presumably duplicates).</p><p>For named page finding queries (e.g. "passport application form"), the objective was to find the named page (which would not be a home page, e.g. "travel.state.gov/dsp11.pdf"). This year, 71 of the 75 queries had just one right answer (and none had more than three, presumably duplicates).</p><p>More information on this task is expected to be in the track overview paper of the TREC proceedings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing</head><p>The indexing approach was the same as the previous two years (described in detail in <ref type="bibr" coords="8,461.89,631.98,10.79,10.46" target="#b8">[9]</ref>) except that a newer version of the software was used which may have contained an updated English lexicon for stemming. Briefly: in addition to full-text indexing, the custom text reader cTREC populated particular columns such as TITLE (if any), URL, URL TYPE and URL DEPTH. The URL TYPE was set to ROOT, SUB-ROOT, PATH or FILE, based on the convention which worked well in TREC 2001 for the Twente/TNO group <ref type="bibr" coords="8,100.68,691.76,15.50,10.46" target="#b12">[13]</ref> on the entry page finding task (also known as the home page finding task). The URL DEPTH was set to a term indicating the depth of the page in the site. example URLs, and Table <ref type="table" coords="9,187.60,371.85,4.98,10.46" target="#tab_4">7</ref> shows the number of .GOV pages of each URL type and depth. The exact rules we used are given in <ref type="bibr" coords="9,163.68,383.80,9.96,10.46" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Searching</head><p>humW04l: The submitted humW04l run was a plain content search including linguistic expansion from English inflectional stemming. This run was the analog of the baseline ('2:3') run of the Robust track, including document length normalization (SET RELEVANCE DLEN IMP 500). The IS ABOUT predicate was used instead of the CONTAINS predicate (and hence the VECTOR GENERATOR was set to enable inflections instead of the TERM GENERATOR), but the relevance calculation was the same. This run used the same approach as the submitted humNP03l run of last year <ref type="bibr" coords="9,360.03,492.36,15.50,10.46" target="#b11">[12]</ref> (except that the software was newer and had minor updates for inflections). humW04pl: The submitted humW04pl run was the same as humW04l except that it put additional weight on matches in the title, url, first heading and some meta tags, including extra weight on matching the query as a phrase in these fields. Below is an example SearchSQL query. The searches on the ALL PROPS column (which contained a copy of the title, url, etc. as described in <ref type="bibr" coords="9,365.57,552.14,10.79,10.46" target="#b8">[9]</ref>) are the difference from the humW04l run. Note that the FT TEXT column indexed the content and also all of the non-content fields except for the URL. This run used the same approach as the submitted humNP03pl of last year, and last year's paper <ref type="bibr" coords="9,72.00,588.01,15.50,10.46" target="#b11">[12]</ref> explains some of the syntax in more detail: SELECT RELEVANCE('2:3') AS REL, DOCNO FROM GOV WHERE (ALL_PROPS CONTAINS 'visiting pandas national zoo' WEIGHT 1) OR (ALL_PROPS IS_ABOUT 'visiting pandas national zoo' WEIGHT 1) OR (FT_TEXT IS_ABOUT 'visiting pandas national zoo' WEIGHT 10) ORDER BY REL DESC; humW04dpl: The submitted humW04dpl run was the same as humW04pl except that it put additional weight on urls of depth 4 or less (but not on the url type, though url types were still listed with weight 0 as a way to prevent urls of depth greater than 4 from being excluded). Less deep urls also received higher weight from inverse document frequency because they are less common as per Table <ref type="table" coords="10,439.54,97.58,3.87,10.46" target="#tab_4">7</ref>. Below is an example WHERE clause: humW04dp: The submitted humW04dp run was the same as humW04dpl except that linguistic expansion (inflections) from English stemming was disabled by "SET VECTOR GENERATOR '' ".</p><p>SearchServer's relevance value calculation was the same as described for the Robust track. When multiple predicates are combined, as was done for some of the web approaches, SearchServer currently does not normalize by query length. For example, the URL TYPE clauses would have a lot less relative impact if the topic query contained 5 words instead of 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Table <ref type="table" coords="10,100.12,608.87,4.98,10.46" target="#tab_5">8</ref> lists the scores of the 5 submitted runs (see the glossary section for definitions of the measures). The first group is the scores on the 75 topic distillation (TD) queries. The next two groups are for the 75 home-page finding (HP) and 75 named page finding (NP) queries respectively. The final group is the scores over all 225 queries.</p><p>The 'p' technique (extra weight for phrases in the Title and other properties plus extra weight for vector search on properties) increased the mean scores for all 3 query types (compare 'pl' to 'l'). Tables 9, 10, 11 and 12 show that the increases from the 'p' technique were statistically significant for the mean reciprocal rank, mean average precision, Success@1 and Success@10 measures respectively. (See Section 6.1 for an explanation of the columns of Tables 9-12.) The 'd' technique (modest extra weight for less deep urls) increased the mean scores for the 2 types which wanted home pages (TD and HP) and had little impact on the mean scores for the non-homepage type (NP) (compare 'dpl' to 'pl'). The increases on the TD and HP types were statistically significant (as per Tables <ref type="table" coords="11,72.00,644.17,4.15,10.46" target="#tab_6">9</ref><ref type="table" coords="11,76.15,644.17,4.15,10.46" target="#tab_7">10</ref><ref type="table" coords="11,76.15,644.17,4.15,10.46" target="#tab_0">11</ref><ref type="table" coords="11,80.30,644.17,8.30,10.46" target="#tab_8">12</ref>).</p><p>The 'l' technique (linguistic expansion from English inflectional stemming) modestly increased most of the mean scores (compare 'dpl' to 'dp'). However, the only statistically significant impact was on mean average precision for distillation queries (as per Table <ref type="table" coords="11,308.97,680.03,8.30,10.46" target="#tab_7">10</ref>).</p><p>The 'r' technique (strong extra weight for urls of root, subroot or path types) substantially increased the mean scores for topic distillation and also increased the mean scores for home-page finding, but decreased most of the mean scores for named page finding (compare 'rdpl' to 'dpl'). The increases for topic distillation were statistically significant, but the increases for home-page finding were not. Some of the decreases for named page finding were statistically significant. (See Tables <ref type="table" coords="12,341.24,430.51,4.15,10.46" target="#tab_6">9</ref><ref type="table" coords="12,345.39,430.51,4.15,10.46" target="#tab_7">10</ref><ref type="table" coords="12,345.39,430.51,4.15,10.46" target="#tab_0">11</ref><ref type="table" coords="12,349.54,430.51,8.30,10.46" target="#tab_8">12</ref>.) So the 'p', 'd' and 'l' techniques appear to be generally useful for web search, while the 'r' technique may be useful if queries for home pages are expected to be relatively frequent.</p><p>Overall, the web search task was apparently more challenging than the ad hoc task of the Robust track. The content search technique that produced a Success@10 of more than 90% in the Robust track had a Success@10 of less than 50% in the web task. However, by using SearchServer's ability to take advantage of various kinds of structure in the data, Success@10 for the mixed web task was increased to more than 75% and for the broad topic (distillation) queries to more than 90%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Terabyte Retrieval</head><p>The Terabyte Track was new to TREC this year. The collection to be searched was the GOV2 collection, a crawl of most of the .gov domain in early 2004. Once binaries (such as images) were removed, its size was less than half a terabyte. The GOV2 distribution was 457,165,206,582 bytes uncompressed (426 GB) and consisted of 25,205,179 documents. More than 90% of the documents were html, 8% were (extracted text from) pdf, and the rest were extracted text from other formats (plain text, msword, postscript, etc.). The collection was 86,594,814,080 bytes gzip-compressed and distributed on a hard drive. The hard drive contained 273 directories, each typically containing 100 .gz files of 3GB in size. Uncompressed, the average document size was 18,137 bytes. Even though the data was like that of the Web Track, the task was more like that of the Robust Retrieval Track. There were 50 new topics, each with a Title, Description and Narrative, and the objective was to find all the relevant documents for the topic and return them at the top of the list. It turned out one of the topics had no relevant documents, leaving 49 topics in total. For these, there were on average 217 relevant documents per topic (low 7, high 617, median 167).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Indexing</head><p>The indexing approach was the same as described for the Web Track (i.e. not just the content was indexed but separate columns were created for the title, url, some meta fields, etc.).</p><p>For the diagnostic runs in January 2005, the entire collection was indexed in one SearchServer table. But for the submitted runs in September 2004, lack of resources led to the collection being indexed in 137 parts, and for the record this approach is described here. The 600MHz lab machine available at the time did not have enough disk space remaining for this task. There was a network server with enough disk space to hold the indexes but its processor was not available full-time for this task (and our experimental version of SearchServer was not installed on it). There was also a 2.4GHz desktop machine which was sometimes available. For the submitted runs, most of the indexing was done in pieces on the 2.4GHz machine, 2 directories at a time into separate tables. The tables (indexes) were moved to the network server when it was available. The result was 137 small tables, each indexing about 3GB of the collection. This approach was convenient for getting the data indexed but made searching less efficient. Most of the index was positioning information for supporting proximity searches, a feature that was not actually used for our submitted (or diagnostic) Terabyte runs. The on-disk structures also included other table files such as the catalog which stored the titles, urls, some meta fields, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Submitted Runs</head><p>While the diagnostic runs in January 2005 simply searched one table, the submitted runs in September 2004 searched 137 small tables, and for the record that approach is described here. The search approaches were intended to be similar to those done for the Web Track. The FROM clause of the searches specified a union of the 137 small tables (GOV000 UNION GOV001 UNION ... GOV136). The experimental version of SearchServer did not calculate global inverse document frequencies for the terms. For each document, it would use the inverse document frequencies based on just the table containing the document. To make the relevance calculation more consistent with a one-table ranking, for most runs the test application looked up the number of occurrences of the terms and their inflections in each table (using the SEARCH TERMS system table) so that a global inverse document frequency could be computed using the most common inflection. This value was then assigned to the term in the SearchSQL query using the WEIGHT clause. The '2:5' relevance method was used (instead of '2:3') so that the per-table inverse document frequencies were ignored (just the specified WEIGHT was used). This approach would not take advantage of the enhancement for multiple stemming interpretations described in the Robust section. It turned out that the experimental lookup phase was not well-optimized and added a lot to the search times, particularly when the QUERY TERM() function was used to look up the inflections. The runs retrieving the top-20 rows were done by the 2.4GHz machine reading the indexes via a Windows network drive. The searches also read a lot of positioning information which actually was not used to produce the results. Some of the submitted runs, which retrieved 10,000 rows per query, were done with the 600MHz machine.</p><p>The submitted runs all just used the Title field of the topic. humT04l: This run was a plain content run (i.e. just searched FT TEXT) and included inflections from English stemming. It was the analog of the humW04l run described in the Web section. The document length importance was set to 750 instead of 500 (just from an oversight).</p><p>humT04: This run was the same as humT04l except that inflections were not included. The experimental lookup phase described earlier had a lot less to do.</p><p>humT04vl: This run was the same as humT04l except that it put additional weight on matches in the title, url and some meta tags (i.e. the ALL PROPS column). The weight for ALL PROPS was one-tenth the weight used for FT TEXT. A difference from the analogous web run (humW04pl) was that the phrase search on ALL PROPS was omitted (in part because it would have been extra effort to get the test application to weight it in an analogous way, and in part because we verified last year ('v' and 'q' experiments in <ref type="bibr" coords="14,499.37,496.27,15.50,10.46" target="#b11">[12]</ref>) that the phrase search was of less importance for non-homepage searches anyway). Also, the humT04vl weighting for ALL PROPS was in effect based on inverse document frequencies calculated from FT TEXT because of the '2:5' workaround, unlike for humW04pl which used the '2:3' relevance method.</p><p>humT04dvl: This run was the same as humT04vl except that it put additional weight on less deep urls. The weights were analogous to those used in Web run humW04dpl but, as '2:5' was used, the SearchSQL needed to explicitly multiply in the weight from inverse document frequency.</p><p>humT04l3: This run was the same as humT04l except that it did not do the lookup phase to calculate  <ref type="table" coords="15,113.95,327.82,9.96,10.46" target="#tab_9">13</ref> lists the scores of the 5 submitted runs (see the glossary section for definitions of the measures). Note that the mean average precision (MAP) scores are based on just the first 1000 documents retrieved (as per the usual convention for MAP), even though the submissions included up to 10,000 rows per topic.</p><p>The 'l' technique (linguistic expansion from English inflectional stemming) modestly increased most of the mean scores (compare 'humT04l' to 'humT04'). The increase in mean average precision was statistically significant (as per Table <ref type="table" coords="15,180.35,387.58,8.30,10.46" target="#tab_10">15</ref>), like it was for the Robust diagnostic task and the Web Distillation subtask.</p><p>The 'v' technique (extra weight for matches in the title, url and some meta tags) made little difference to the mean scores (compare 'humT04vl' to 'humT04l'). Note that the individual reciprocal rank scores could be impacted substantially in either direction (ranging from a decrease of 0.80 on topic 727 to an increase of 0.50 on topic 739 as per Table <ref type="table" coords="15,210.03,435.41,8.30,10.46" target="#tab_0">14</ref>). The 'v' technique did not have the consistent beneficial impact of the analogous 'p' technique for the Web task, evidence that the Web and Terabyte tasks are quite different.</p><p>The 'd' technique (modest extra weight for less deep urls) decreased most of the mean scores (compare 'humT04dvl' to 'humT04vl'). The decreases for mean reciprocal rank and mean average precision were statistically significant (as per Tables <ref type="table" coords="15,240.03,483.23,9.96,10.46" target="#tab_0">14</ref> and<ref type="table" coords="15,273.58,483.23,8.30,10.46" target="#tab_10">15</ref>). This impact is the opposite of the 'd' technique for the Web task.</p><p>The '3' technique (use local inverse document frequencies) decreased all of the mean scores (compare 'humT04l3' to 'humT04l'). The decreases for mean reciprocal rank and mean average precision were statistically significant (as per Tables <ref type="table" coords="15,226.94,531.05,9.96,10.46" target="#tab_0">14</ref> and<ref type="table" coords="15,260.37,531.05,8.30,10.46" target="#tab_10">15</ref>). This result suggests that for multi-table searches, the '2:5' relevance method (which ignores inverse document frequency) should be considered.</p><p>Overall, the results of the submitted experiments suggest that the Terabyte task is much more like the Robust task than the Web task, as far as relevance-ranking is concerned. The Web task was searching for particular named pages or for home pages, and favoring the document title or less deep urls was helpful. The Terabyte task, though it is also searching web data, is looking for any document relevant to the topic (as in the Robust task), and the web techniques did not (on average) improve on a plain content search. The diagnostic runs focus on plain content search techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Diagnostic Runs</head><p>For the diagnostic runs in January 2005, the GOV2 collection was indexed in one SearchServer table. Table <ref type="table" coords="15,530.04,663.53,9.96,10.46" target="#tab_3">16</ref> shows the same diagnostic runs as were done for the Robust task (Table <ref type="table" coords="15,386.38,675.48,4.43,10.46" target="#tab_0">1</ref>) except that the document length importance setting (RELEVANCE DLEN IMP) was set to 250 instead of 500 (250 produced a little higher scores on this collection, perhaps because there were more long relevant documents). Also, the experimental version of SearchServer used for these diagnostic runs had an updated English inflection module. Unlike in the Robust section, mean reciprocal rank (MRR) of the first relevant retrieved is included in Table <ref type="table" coords="16,99.56,526.16,8.49,10.46" target="#tab_3">16</ref>. (When the Robust tables were produced, we were using an older version of the trec eval utility.) Although the '2:4' method scored higher than '2:3' in MRR in the Terabyte task (for both OR and AND), Table <ref type="table" coords="16,99.39,550.07,9.96,10.46" target="#tab_11">17</ref> shows the differences were not statistically significant.</p><p>Table <ref type="table" coords="16,115.63,562.02,9.96,10.46" target="#tab_5">18</ref> compares each run to its '2:3' baseline in average precision. The results were very similar to the results in the Robust track in its analogous Table <ref type="table" coords="16,328.50,573.97,3.87,10.46">2</ref>. One difference is that for the Terabyte task, the decrease in mean average precision when using the experimental '2:5' method with boolean-AND was statistically significant, but the mean decrease was small (just 1 point) and the confidence interval was not wide (0 to 2 points). Table <ref type="table" coords="16,214.55,609.84,9.96,10.46" target="#tab_5">18</ref> shows the largest decrease was the 14 point drop on topic 749 (Puerto Rico state), for which it seems that not down-weighting the common word 'state' brought in a lot of long documents with relatively few references to 'Puerto Rico'. In practice, a user might use a proximity query ('Puerto Rico' near 'state') to avoid this issue.</p><p>In the Robust ad hoc search task, we found that some conclusions were different for boolean-AND queries than for boolean-OR. A simple count of all the matches, which did poorly with boolean-OR (Success@10 of just 39%), was reasonably effective with boolean-AND (Success@10 of 76%). Weighting terms by inverse document frequency was of less value on average for boolean-AND queries than for boolean-OR. The results for boolean-AND seem to agree more with user impressions of the merits of the ranking schemes.</p><p>A technique that improved robustness was an enhancement for handling multiple stemming interpretations (we originally developed it for languages other than English). A few problem topics for stemming approaches (e.g. "mainstreaming", "price fixing") were found to be improved by this technique. The approach of selecting alternatives on a per-document basis may generalize to incorporating phrase groups, synonyms, etc. for unstructured queries, but further research is needed.</p><p>The Web Track showed that there are different search tasks which require different techniques. The content search technique that produced a Success@10 of more than 90% in the Robust task had a Success@10 of less than 50% in the Web task. The Web task was searching not for any relevant document, but for particular named pages or home pages. By using SearchServer's ability to assign extra weight to particular columns, such as columns containing the document title or the depth of a url, Success@10 for the mixed web task was increased to more than 75% and for the broad topic (distillation) queries to more than 90%.</p><p>In the Terabyte Track, we found that SearchServer's ad hoc search techniques successfully scaled and Success@10 exceeding 90% was achieved. Generally speaking, the conclusions of the Robust task carried over to the Terabyte task. Even though its data was like that of the Web task, the web techniques were not beneficial for the Terabyte task, presumably because its task definition was like that of the Robust task. It would be good if a standard test for known-item search was created for this data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Glossary</head><p>• "Precision" is the percentage of retrieved documents which are relevant.</p><p>• "Precision@n" is the precision after n documents have been retrieved.</p><p>• "Recall" is the percentage of relevant documents which have been retrieved.</p><p>• "Average precision" for a topic is the average of the precision after each relevant document is retrieved (using zero as the precision for relevant documents which are not retrieved). In this paper, it is based on the first 1000 retrieved documents for the topic. The score ranges from 0.0 (no relevants found) to 1.0 (all relevants found at the top of the list). Average precision takes into account both precision and recall, and it is very good for detecting retrieval differences because even small differences in the ranks of relevant documents affect the score.</p><p>• "Mean Average Precision" (MAP) is the mean of the average precision scores over all of the topics (i.e. all topics are weighted equally).</p><p>• "Reciprocal Rank" for a topic is one divided by the rank of the first row for which a desired page is found, or zero if a desired page was not found.</p><p>• "Mean Reciprocal Rank" (MRR) is the average of the reciprocal ranks over all the topics.</p><p>• "Success@n" is the percentage of topics for which at least one relevant document was returned in the first n rows. This measure hides a lot of retrieval differences (particularly in recall), but it may be an indicator of a user's impression of a method's robustness across topics. This paper lists Success@1, Success@5 and Success@10.</p><p>Note that Success@1 is the same as Precision@1, but for n&gt;1, Success@n does not have the same definition as Precision@n. Success@1 seems likely to correlate well with MAP for recall-oriented methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,86.61,81.95,438.77,618.28"><head>Table 1 :</head><label>1</label><figDesc>Scores of Diagnostic Robust Retrieval Runs, Short (Title-only) Queries</figDesc><table coords="4,86.61,97.19,438.77,603.04"><row><cell>Run</cell><cell></cell><cell></cell><cell>MAP</cell><cell></cell><cell>Success@1</cell><cell>Success@5</cell><cell>Success@10</cell></row><row><cell cols="2">OR: "2:3" (normal idf)</cell><cell></cell><cell>0.255</cell><cell cols="2">141/249 (57%)</cell><cell>214/249 (86%)</cell><cell>227/249 (91%)</cell></row><row><cell cols="2">OR: "2:4" (idf squared)</cell><cell></cell><cell>0.250</cell><cell cols="2">144/249 (58%)</cell><cell>210/249 (84%)</cell><cell>223/249 (90%)</cell></row><row><cell cols="3">OR: "2:3 with no stemming"</cell><cell>0.228</cell><cell cols="2">132/249 (53%)</cell><cell>213/249 (86%)</cell><cell>223/249 (90%)</cell></row><row><cell cols="2">OR: "2:5" (no idf)</cell><cell></cell><cell>0.220</cell><cell cols="2">137/249 (55%)</cell><cell>209/249 (84%)</cell><cell>224/249 (90%)</cell></row><row><cell cols="2">OR: "2:3 with no dlen"</cell><cell></cell><cell>0.215</cell><cell cols="2">120/249 (48%)</cell><cell>194/249 (78%)</cell><cell>220/249 (88%)</cell></row><row><cell cols="2">OR: "2:2" (terms count)</cell><cell></cell><cell>0.114</cell><cell cols="2">46/249 (18%)</cell><cell>122/249 (49%)</cell><cell>151/249 (61%)</cell></row><row><cell cols="2">OR: "2:1" (hits count)</cell><cell></cell><cell>0.048</cell><cell cols="2">23/249 ( 9%)</cell><cell>74/249 (30%)</cell><cell>97/249 (39%)</cell></row><row><cell cols="2">AND: "2:3" (normal idf)</cell><cell></cell><cell>0.179</cell><cell cols="2">138/249 (55%)</cell><cell>205/249 (82%)</cell><cell>215/249 (86%)</cell></row><row><cell cols="2">AND: "2:4" (idf squared)</cell><cell></cell><cell>0.177</cell><cell cols="2">142/249 (57%)</cell><cell>203/249 (82%)</cell><cell>214/249 (86%)</cell></row><row><cell cols="2">AND: "2:5" (no idf)</cell><cell></cell><cell>0.176</cell><cell cols="2">135/249 (54%)</cell><cell>201/249 (81%)</cell><cell>215/249 (86%)</cell></row><row><cell cols="2">AND: "2:3 with no dlen"</cell><cell></cell><cell>0.153</cell><cell cols="2">116/249 (47%)</cell><cell>186/249 (75%)</cell><cell>207/249 (83%)</cell></row><row><cell cols="3">AND: "2:3 with no stemming"</cell><cell>0.142</cell><cell cols="2">128/249 (51%)</cell><cell>196/249 (79%)</cell><cell>204/249 (82%)</cell></row><row><cell cols="2">AND: "2:1" (hits count)</cell><cell></cell><cell>0.132</cell><cell cols="2">90/249 (36%)</cell><cell>156/249 (63%)</cell><cell>188/249 (76%)</cell></row><row><cell cols="2">AND: "2:2" (terms count)</cell><cell></cell><cell>0.092</cell><cell cols="2">44/249 (18%)</cell><cell>120/249 (48%)</cell><cell>147/249 (59%)</cell></row><row><cell cols="6">Table 2: Relevance Methods Compared to '2:3' Baseline, Average Precision Measure</cell></row><row><cell>Expt</cell><cell>MAP Diff</cell><cell></cell><cell>95% Conf</cell><cell></cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>OR: 2:4</cell><cell>-0.005</cell><cell cols="3">(-0.011, 0.001)</cell><cell>90-133-26</cell><cell>-0.18 (311), -0.15 (665), 0.15 (444)</cell></row><row><cell>OR: no stem</cell><cell>-0.027</cell><cell cols="3">(-0.039,-0.016)</cell><cell>95-137-17</cell><cell>-0.63 (328), -0.46 (326), 0.21 (648)</cell></row><row><cell>OR: 2:5</cell><cell>-0.034</cell><cell cols="3">(-0.046,-0.023)</cell><cell>87-157-5</cell><cell>-0.46 (366), -0.46 (302), 0.13 (621)</cell></row><row><cell>OR: no dlen</cell><cell>-0.039</cell><cell cols="3">(-0.050,-0.029)</cell><cell>62-184-3</cell><cell>-0.65 (679), -0.38 (601), 0.21 (338)</cell></row><row><cell>OR: 2:2</cell><cell>-0.140</cell><cell cols="3">(-0.158,-0.123)</cell><cell>23-226-0</cell><cell>-0.72 (679), -0.59 (677), 0.20 (615)</cell></row><row><cell>OR: 2:1</cell><cell>-0.206</cell><cell cols="3">(-0.231,-0.183)</cell><cell>15-233-1</cell><cell>-0.91 (679), -0.84 (410), 0.10 (325)</cell></row><row><cell>AND: 2:4</cell><cell>-0.002</cell><cell cols="3">(-0.004, 0.000)</cell><cell>67-96-86</cell><cell>-0.07 (339), -0.06 (334), 0.05 (379)</cell></row><row><cell>AND: 2:5</cell><cell>-0.002</cell><cell cols="3">(-0.007, 0.001)</cell><cell>79-110-60</cell><cell>-0.26 (622), -0.25 (379), 0.11 (339)</cell></row><row><cell>AND: no dlen</cell><cell>-0.026</cell><cell cols="3">(-0.036,-0.017)</cell><cell>62-149-38</cell><cell>-0.65 (679), -0.38 (601), 0.18 (338)</cell></row><row><cell>AND: no stem</cell><cell>-0.037</cell><cell cols="3">(-0.051,-0.025)</cell><cell>59-133-57</cell><cell>-0.75 (679), -0.74 (328), 0.14 (648)</cell></row><row><cell>AND: 2:1</cell><cell>-0.047</cell><cell cols="3">(-0.060,-0.035)</cell><cell>45-166-38</cell><cell>-0.81 (679), -0.53 (601), 0.21 (361)</cell></row><row><cell>AND: 2:2</cell><cell>-0.087</cell><cell cols="3">(-0.104,-0.071)</cell><cell>28-191-30</cell><cell>-0.72 (679), -0.58 (677), 0.22 (615)</cell></row><row><cell cols="6">Table 3: Relevance Methods Compared to '2:3' Baseline, Success@1 Measure</cell></row><row><cell>Expt</cell><cell>S@1 Diff</cell><cell></cell><cell>95% Conf</cell><cell></cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>OR: 2:4</cell><cell>0.012</cell><cell cols="2">(-0.017, 0.041)</cell><cell></cell><cell>8-5-236</cell><cell>1.00 (332), 1.00 (670), -1.00 (684)</cell></row><row><cell>OR: 2:5</cell><cell>-0.016</cell><cell cols="2">(-0.057, 0.025)</cell><cell></cell><cell>11-15-223</cell><cell>-1.00 (303), -1.00 (435), 1.00 (438)</cell></row><row><cell>OR: no stem</cell><cell>-0.036</cell><cell cols="2">(-0.081, 0.009)</cell><cell></cell><cell>11-20-218</cell><cell>-1.00 (639), -1.00 (306), 1.00 (632)</cell></row><row><cell>OR: no dlen</cell><cell>-0.084</cell><cell cols="3">(-0.145,-0.024)</cell><cell>20-41-188</cell><cell>-1.00 (331), -1.00 (374), 1.00 (387)</cell></row><row><cell>OR: 2:2</cell><cell>-0.382</cell><cell cols="3">(-0.454,-0.309)</cell><cell>12-107-130</cell><cell>-1.00 (303), -1.00 (440), 1.00 (612)</cell></row><row><cell>OR: 2:1</cell><cell>-0.474</cell><cell cols="3">(-0.543,-0.405)</cell><cell>8-126-115</cell><cell>-1.00 (425), -1.00 (317), 1.00 (413)</cell></row><row><cell>AND: 2:4</cell><cell>0.016</cell><cell cols="2">(-0.009, 0.041)</cell><cell></cell><cell>7-3-239</cell><cell>1.00 (332), 1.00 (445), -1.00 (318)</cell></row><row><cell>AND: 2:5</cell><cell>-0.012</cell><cell cols="2">(-0.049, 0.025)</cell><cell></cell><cell>9-12-228</cell><cell>-1.00 (303), -1.00 (307), 1.00 (447)</cell></row><row><cell>AND: no stem</cell><cell>-0.040</cell><cell cols="2">(-0.085, 0.005)</cell><cell></cell><cell>11-21-217</cell><cell>-1.00 (636), -1.00 (306), 1.00 (632)</cell></row><row><cell>AND: no dlen</cell><cell>-0.088</cell><cell cols="3">(-0.149,-0.028)</cell><cell>19-41-189</cell><cell>-1.00 (374), -1.00 (385), 1.00 (384)</cell></row><row><cell>AND: 2:1</cell><cell>-0.193</cell><cell cols="3">(-0.262,-0.124)</cell><cell>17-65-167</cell><cell>-1.00 (318), -1.00 (357), 1.00 (413)</cell></row><row><cell>AND: 2:2</cell><cell>-0.378</cell><cell cols="3">(-0.446,-0.305)</cell><cell>11-105-133</cell><cell>-1.00 (303), -1.00 (440), 1.00 (429)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,72.00,80.60,408.55,195.96"><head>Table 5 :</head><label>5</label><figDesc>Scores of Submitted Robust Retrieval Runs</figDesc><table coords="7,72.00,93.35,408.55,183.21"><row><cell>Run</cell><cell>MAP</cell><cell>Success@1</cell><cell>Success@5</cell><cell>Success@10</cell><cell>τ 249</cell></row><row><cell>humR04t5e1</cell><cell>0.298</cell><cell>31/49 (63%)</cell><cell>42/49 (86%)</cell><cell>43/49 (88%)</cell><cell>0.33</cell></row><row><cell>humR04t5</cell><cell>0.286</cell><cell>32/49 (65%)</cell><cell>44/49 (90%)</cell><cell>45/49 (92%)</cell><cell>0.30</cell></row><row><cell>humR04t1</cell><cell>0.266</cell><cell>31/49 (63%)</cell><cell>44/49 (90%)</cell><cell>46/49 (94%)</cell><cell>0.35</cell></row><row><cell>humR04t1m</cell><cell>0.254</cell><cell>28/49 (57%)</cell><cell>44/49 (90%)</cell><cell>46/49 (94%)</cell><cell>0.29</cell></row><row><cell>humR04t1i</cell><cell>0.228</cell><cell>30/49 (61%)</cell><cell>43/49 (88%)</cell><cell>44/49 (90%)</cell><cell>0.23</cell></row><row><cell>humR04d4e5</cell><cell>0.320</cell><cell>31/49 (63%)</cell><cell>41/49 (84%)</cell><cell>41/49 (84%)</cell><cell>0.42</cell></row><row><cell>humR04d4</cell><cell>0.299</cell><cell>35/49 (71%)</cell><cell>43/49 (88%)</cell><cell>46/49 (94%)</cell><cell>0.42</cell></row><row><cell>humR04d5</cell><cell>0.281</cell><cell>31/49 (63%)</cell><cell>46/49 (94%)</cell><cell>47/49 (96%)</cell><cell>0.43</cell></row><row><cell>humR04d5m</cell><cell>0.261</cell><cell>27/49 (55%)</cell><cell>42/49 (86%)</cell><cell>44/49 (90%)</cell><cell>0.40</cell></row><row><cell>humR04d5i</cell><cell>0.163</cell><cell>23/49 (47%)</cell><cell>37/49 (76%)</cell><cell>44/49 (90%)</cell><cell>0.26</cell></row><row><cell>2.4 Submitted Runs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,72.00,287.91,468.01,70.24"><head>Table 5</head><label>5</label><figDesc>lists the MAP, S1, S5 and S10 scores of the runs submitted in August 2004 over just the 49 new topics because some of the decisions on the parameters used were based on the older 200 topics. (The τ 249 correlation measure is based on all 249 topics as explained in Section 2.4.1.) humR04t5 was the same as the diagnostic '2:3' boolean-OR baseline run (including inflections and a document length normalization setting of 500). Possibly there were differences from an older version of SearchServer being used.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,349.40,703.72,190.60,10.46"><head>Table 6 :</head><label>6</label><figDesc>Table 6 contains URL types and depths for Examples of URL Type and Depth Values</figDesc><table coords="9,145.45,95.28,317.79,112.48"><row><cell>URL</cell><cell>Type</cell><cell cols="2">Depth Depth Term</cell></row><row><cell>http://nasa.gov/</cell><cell>ROOT</cell><cell>1</cell><cell>URLDEPTHA</cell></row><row><cell>http://www.nasa.gov/</cell><cell>ROOT</cell><cell>1</cell><cell>URLDEPTHA</cell></row><row><cell>http://jpl.nasa.gov/</cell><cell>ROOT</cell><cell>2</cell><cell>URLDEPTHAB</cell></row><row><cell>http://fred.jpl.nasa.gov/</cell><cell>ROOT</cell><cell>3</cell><cell>URLDEPTHABC</cell></row><row><cell>http://nasa.gov/jpl/</cell><cell>SUBROOT</cell><cell>2</cell><cell>URLDEPTHAB</cell></row><row><cell>http://nasa.gov/jpl/fred/</cell><cell>PATH</cell><cell>3</cell><cell>URLDEPTHABC</cell></row><row><cell>http://nasa.gov/index.html</cell><cell>ROOT</cell><cell>1</cell><cell>URLDEPTHA</cell></row><row><cell>http://nasa.gov/fred.html</cell><cell>FILE</cell><cell>2</cell><cell>URLDEPTHAB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,141.68,243.62,328.65,91.86"><head>Table 7 :</head><label>7</label><figDesc>Number of Pages of each URL Type and Depth (.GOV collection)</figDesc><table coords="9,164.26,258.87,283.50,76.62"><row><cell>Type</cell><cell>#Pages</cell><cell>Depth</cell><cell>#Pages</cell><cell>Depth</cell><cell>#Pages</cell></row><row><cell>ROOT</cell><cell>6,906</cell><cell>1</cell><cell>635</cell><cell>6</cell><cell>269,949</cell></row><row><cell>SUBROOT</cell><cell>18,179</cell><cell>2</cell><cell>16,792</cell><cell>7</cell><cell>136,513</cell></row><row><cell>PATH</cell><cell>55,332</cell><cell>3</cell><cell>128,898</cell><cell>8</cell><cell>44,960</cell></row><row><cell>FILE</cell><cell>1,167,336</cell><cell>4</cell><cell>282,086</cell><cell>9</cell><cell>15,289</cell></row><row><cell></cell><cell></cell><cell>5</cell><cell>344,694</cell><cell>10+</cell><cell>7,937</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,99.82,80.60,409.40,281.05"><head>Table 8 :</head><label>8</label><figDesc>Scores of Submitted Web Track Runs</figDesc><table coords="11,99.82,93.35,409.40,268.29"><row><cell>Run</cell><cell>MRR</cell><cell>Success@1</cell><cell>Success@5</cell><cell>Success@10</cell><cell>MAP</cell></row><row><cell>TD: humW04rdpl</cell><cell>0.553</cell><cell>28/75 (37%)</cell><cell>59/75 (79%)</cell><cell>68/75 (91%)</cell><cell>0.163</cell></row><row><cell>TD: humW04dpl</cell><cell>0.394</cell><cell>16/75 (21%)</cell><cell>45/75 (60%)</cell><cell>54/75 (72%)</cell><cell>0.109</cell></row><row><cell>TD: humW04dp</cell><cell>0.351</cell><cell>14/75 (19%)</cell><cell>43/75 (57%)</cell><cell>52/75 (69%)</cell><cell>0.098</cell></row><row><cell>TD: humW04pl</cell><cell>0.260</cell><cell>6/75 ( 8%)</cell><cell>35/75 (47%)</cell><cell>44/75 (59%)</cell><cell>0.079</cell></row><row><cell>TD: humW04l</cell><cell>0.131</cell><cell>2/75 ( 3%)</cell><cell>22/75 (29%)</cell><cell>27/75 (36%)</cell><cell>0.046</cell></row><row><cell>HP: humW04rdpl</cell><cell>0.479</cell><cell>28/75 (37%)</cell><cell>44/75 (59%)</cell><cell>52/75 (69%)</cell><cell>0.482</cell></row><row><cell>HP: humW04dpl</cell><cell>0.437</cell><cell>27/75 (36%)</cell><cell>38/75 (51%)</cell><cell>46/75 (61%)</cell><cell>0.438</cell></row><row><cell>HP: humW04dp</cell><cell>0.422</cell><cell>25/75 (33%)</cell><cell>38/75 (51%)</cell><cell>46/75 (61%)</cell><cell>0.421</cell></row><row><cell>HP: humW04pl</cell><cell>0.316</cell><cell>17/75 (23%)</cell><cell>29/75 (39%)</cell><cell>36/75 (48%)</cell><cell>0.318</cell></row><row><cell>HP: humW04l</cell><cell>0.187</cell><cell>10/75 (13%)</cell><cell>18/75 (24%)</cell><cell>22/75 (29%)</cell><cell>0.187</cell></row><row><cell>NP: humW04rdpl</cell><cell>0.484</cell><cell>27/75 (36%)</cell><cell>48/75 (64%)</cell><cell>56/75 (75%)</cell><cell>0.485</cell></row><row><cell>NP: humW04dpl</cell><cell>0.559</cell><cell>36/75 (48%)</cell><cell>47/75 (63%)</cell><cell>57/75 (76%)</cell><cell>0.559</cell></row><row><cell>NP: humW04dp</cell><cell>0.554</cell><cell>35/75 (47%)</cell><cell>49/75 (65%)</cell><cell>61/75 (81%)</cell><cell>0.555</cell></row><row><cell>NP: humW04pl</cell><cell>0.569</cell><cell>36/75 (48%)</cell><cell>50/75 (67%)</cell><cell>57/75 (76%)</cell><cell>0.570</cell></row><row><cell>NP: humW04l</cell><cell>0.466</cell><cell>28/75 (37%)</cell><cell>42/75 (56%)</cell><cell>49/75 (65%)</cell><cell>0.466</cell></row><row><cell>ALL: humW04rdpl</cell><cell>0.505</cell><cell>83/225 (37%)</cell><cell>151/225 (67%)</cell><cell>176/225 (78%)</cell><cell>0.376</cell></row><row><cell>ALL: humW04dpl</cell><cell>0.463</cell><cell>79/225 (35%)</cell><cell>130/225 (58%)</cell><cell>157/225 (70%)</cell><cell>0.368</cell></row><row><cell>ALL: humW04dp</cell><cell>0.443</cell><cell>74/225 (33%)</cell><cell>130/225 (58%)</cell><cell>159/225 (71%)</cell><cell>0.358</cell></row><row><cell>ALL: humW04pl</cell><cell>0.382</cell><cell>59/225 (26%)</cell><cell>114/225 (51%)</cell><cell>137/225 (61%)</cell><cell>0.322</cell></row><row><cell>ALL: humW04l</cell><cell>0.261</cell><cell>40/225 (18%)</cell><cell>82/225 (36%)</cell><cell>98/225 (44%)</cell><cell>0.233</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,111.06,393.96,389.88,180.97"><head>Table 9 :</head><label>9</label><figDesc>Impact of Submitted Web Techniques on Reciprocal Rank</figDesc><table coords="11,111.06,408.65,389.88,166.28"><row><cell>Expt</cell><cell>MRR Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>r-TD</cell><cell>0.159</cell><cell>( 0.066, 0.253)</cell><cell>38-20-17</cell><cell>0.99 (111), 0.96 (50), -0.80 (191)</cell></row><row><cell>d-TD</cell><cell>0.134</cell><cell>( 0.068, 0.205)</cell><cell>45-15-15</cell><cell>0.95 (63), 0.93 (41), -0.50 (101)</cell></row><row><cell>p-HP</cell><cell>0.130</cell><cell>( 0.067, 0.198)</cell><cell>57-7-11</cell><cell>0.99 (118), 0.98 (67), -0.50 (217)</cell></row><row><cell>p-TD</cell><cell>0.129</cell><cell>( 0.080, 0.184)</cell><cell>57-9-9</cell><cell>0.99 (177), 0.98 (12), -0.45 (79)</cell></row><row><cell>d-HP</cell><cell>0.121</cell><cell>( 0.058, 0.189)</cell><cell>41-12-22</cell><cell>0.96 (224), 0.93 (9), -0.67 (51)</cell></row><row><cell>p-NP</cell><cell>0.103</cell><cell>( 0.044, 0.169)</cell><cell>32-8-35</cell><cell>0.97 (208), 0.93 (39), -0.50 (28)</cell></row><row><cell>l-TD</cell><cell>0.043</cell><cell>(-0.013, 0.100)</cell><cell>17-23-35</cell><cell>1.00 (63), 0.89 (170), -0.99 (207)</cell></row><row><cell>r-HP</cell><cell>0.042</cell><cell>(-0.030, 0.114)</cell><cell>31-19-25</cell><cell>0.91 (54), 0.90 (161), -0.88 (78)</cell></row><row><cell>l-HP</cell><cell>0.015</cell><cell>(-0.010, 0.047)</cell><cell>14-23-38</cell><cell>0.75 (213), 0.67 (78), -0.17 (51)</cell></row><row><cell>l-NP</cell><cell>0.004</cell><cell>(-0.027, 0.035)</cell><cell>10-19-46</cell><cell>-0.67 (114), 0.50 (187), 0.50 (34)</cell></row><row><cell>d-NP</cell><cell>-0.011</cell><cell>(-0.041, 0.019)</cell><cell>12-16-47</cell><cell>-0.50 (150), -0.50 (208), 0.50 (28)</cell></row><row><cell>r-NP</cell><cell>-0.075</cell><cell>(-0.131,-0.022)</cell><cell>7-33-35</cell><cell>-0.83 (55), -0.67 (38), 0.67 (114)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,113.83,80.60,384.34,292.63"><head>Table 10 :</head><label>10</label><figDesc>Impact of Submitted Web Techniques on Average Precision</figDesc><table coords="12,113.83,95.28,384.34,277.95"><row><cell>Expt</cell><cell>MAP Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>r-TD</cell><cell>0.054</cell><cell>( 0.034, 0.074)</cell><cell>57-17-1</cell><cell>0.29 (8), 0.28 (99), -0.16 (5)</cell></row><row><cell>p-TD</cell><cell>0.033</cell><cell>( 0.022, 0.045)</cell><cell>66-8-1</cell><cell>0.21 (74), 0.18 (81), -0.05 (209)</cell></row><row><cell>d-TD</cell><cell>0.030</cell><cell>( 0.020, 0.041)</cell><cell>59-15-1</cell><cell>0.18 (134), 0.16 (21), -0.03 (47)</cell></row><row><cell>l-TD</cell><cell>0.011</cell><cell>( 0.000, 0.024)</cell><cell>32-31-12</cell><cell>0.35 (170), 0.11 (160), -0.14 (207)</cell></row><row><cell></cell><cell cols="4">Table 11: Impact of Submitted Web Techniques on Success@1</cell></row><row><cell>Expt</cell><cell>S@1 Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>r-TD</cell><cell>0.160</cell><cell>( 0.026, 0.294)</cell><cell>19-7-49</cell><cell>1.00 (50), 1.00 (111), -1.00 (10)</cell></row><row><cell>d-HP</cell><cell>0.133</cell><cell>( 0.053, 0.227)</cell><cell>11-1-63</cell><cell>1.00 (6), 1.00 (218), -1.00 (51)</cell></row><row><cell>d-TD</cell><cell>0.133</cell><cell>( 0.039, 0.227)</cell><cell>12-2-61</cell><cell>1.00 (191), 1.00 (99), -1.00 (101)</cell></row><row><cell>p-NP</cell><cell>0.107</cell><cell>( 0.026, 0.187)</cell><cell>9-1-65</cell><cell>1.00 (39), 1.00 (208), -1.00 (28)</cell></row><row><cell>p-HP</cell><cell>0.093</cell><cell>( 0.013, 0.187)</cell><cell>9-2-64</cell><cell>1.00 (78), 1.00 (118), -1.00 (217)</cell></row><row><cell>p-TD</cell><cell>0.053</cell><cell>( 0.013, 0.107)</cell><cell>4-0-71</cell><cell>1.00 (177), 1.00 (81), 0.00 (221)</cell></row><row><cell>l-HP</cell><cell>0.027</cell><cell>(-0.001, 0.067)</cell><cell>2-0-73</cell><cell>1.00 (78), 1.00 (213), 0.00 (224)</cell></row><row><cell>l-TD</cell><cell>0.027</cell><cell>(-0.041, 0.094)</cell><cell>4-2-69</cell><cell>1.00 (141), 1.00 (63), -1.00 (97)</cell></row><row><cell>l-NP</cell><cell>0.013</cell><cell>(-0.027, 0.067)</cell><cell>2-1-72</cell><cell>1.00 (34), 1.00 (187), -1.00 (114)</cell></row><row><cell>r-HP</cell><cell>0.013</cell><cell>(-0.094, 0.121)</cell><cell>8-7-60</cell><cell>1.00 (59), 1.00 (54), -1.00 (49)</cell></row><row><cell>d-NP</cell><cell>0.000</cell><cell>(-0.054, 0.054)</cell><cell>2-2-71</cell><cell>1.00 (187), 1.00 (28), -1.00 (150)</cell></row><row><cell>r-NP</cell><cell>-0.120</cell><cell>(-0.201,-0.039)</cell><cell>1-10-64</cell><cell>-1.00 (132), -1.00 (222), 1.00 (114)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,118.53,517.08,374.93,177.98"><head>Table 12 :</head><label>12</label><figDesc>Impact of Submitted Web Techniques on Success@10</figDesc><table coords="12,118.53,531.77,374.93,163.28"><row><cell>Expt</cell><cell>S@10 Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>p-TD</cell><cell>0.227</cell><cell>( 0.133, 0.334)</cell><cell>18-1-56</cell><cell>1.00 (99), 1.00 (189), -1.00 (79)</cell></row><row><cell>p-HP</cell><cell>0.187</cell><cell>( 0.106, 0.281)</cell><cell>14-0-61</cell><cell>1.00 (78), 1.00 (118), 0.00 (224)</cell></row><row><cell>r-TD</cell><cell>0.187</cell><cell>( 0.106, 0.281)</cell><cell>14-0-61</cell><cell>1.00 (107), 1.00 (111), 0.00 (221)</cell></row><row><cell>d-HP</cell><cell>0.133</cell><cell>( 0.066, 0.214)</cell><cell>10-0-65</cell><cell>1.00 (117), 1.00 (49), 0.00 (118)</cell></row><row><cell>d-TD</cell><cell>0.133</cell><cell>( 0.026, 0.241)</cell><cell>14-4-57</cell><cell>1.00 (79), 1.00 (160), -1.00 (57)</cell></row><row><cell>p-NP</cell><cell>0.107</cell><cell>( 0.013, 0.201)</cell><cell>11-3-61</cell><cell>1.00 (44), 1.00 (120), -1.00 (88)</cell></row><row><cell>r-HP</cell><cell>0.080</cell><cell>(-0.014, 0.174)</cell><cell>10-4-61</cell><cell>1.00 (149), 1.00 (162), -1.00 (32)</cell></row><row><cell>l-TD</cell><cell>0.027</cell><cell>(-0.067, 0.121)</cell><cell>7-5-63</cell><cell>1.00 (63), 1.00 (58), -1.00 (157)</cell></row><row><cell>d-NP</cell><cell>0.000</cell><cell>(-0.067, 0.067)</cell><cell>3-3-69</cell><cell>1.00 (151), 1.00 (43), -1.00 (116)</cell></row><row><cell>l-HP</cell><cell>0.000</cell><cell>n/a</cell><cell>0-0-75</cell><cell>0.00 (117), 0.00 (7), 0.00 (224)</cell></row><row><cell>r-NP</cell><cell>-0.013</cell><cell>(-0.081, 0.054)</cell><cell>3-4-68</cell><cell>-1.00 (62), -1.00 (70), 1.00 (26)</cell></row><row><cell>l-NP</cell><cell>-0.053</cell><cell>(-0.121, 0.001)</cell><cell>1-5-69</cell><cell>-1.00 (26), -1.00 (27), 1.00 (151)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="14,111.34,80.60,389.32,202.96"><head>Table 13 :</head><label>13</label><figDesc>Scores of Submitted Terabyte Track Runs</figDesc><table coords="14,111.34,95.28,389.32,188.28"><row><cell>Run</cell><cell></cell><cell>MRR</cell><cell cols="2">Success@1</cell><cell cols="2">Success@5</cell><cell>Success@10</cell><cell>MAP</cell></row><row><cell cols="2">humT04l</cell><cell>0.673</cell><cell cols="2">27/49 (55%)</cell><cell cols="2">40/49 (82%)</cell><cell>44/49 (90%)</cell><cell>0.224</cell></row><row><cell cols="2">humT04vl</cell><cell>0.664</cell><cell cols="2">26/49 (53%)</cell><cell cols="2">43/49 (88%)</cell><cell>45/49 (92%)</cell><cell>0.221</cell></row><row><cell cols="2">humT04</cell><cell>0.637</cell><cell cols="2">24/49 (49%)</cell><cell cols="2">42/49 (86%)</cell><cell>42/49 (86%)</cell><cell>0.196</cell></row><row><cell cols="2">humT04dvl</cell><cell>0.606</cell><cell cols="2">22/49 (45%)</cell><cell cols="2">41/49 (84%)</cell><cell>45/49 (92%)</cell><cell>0.212</cell></row><row><cell cols="2">humT04l3</cell><cell>0.544</cell><cell cols="2">18/49 (37%)</cell><cell cols="2">39/49 (80%)</cell><cell>40/49 (82%)</cell><cell>0.155</cell></row><row><cell cols="7">Table 14: Impact of Submitted Terabyte Techniques on Reciprocal Rank</cell></row><row><cell cols="2">Expt MRR Diff</cell><cell cols="2">95% Conf</cell><cell>vs.</cell><cell></cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>l</cell><cell>0.036</cell><cell cols="2">(-0.061, 0.131)</cell><cell cols="2">13-9-27</cell><cell>0.97 (716), -0.86 (706), -0.92 (714)</cell></row><row><cell>v</cell><cell>-0.009</cell><cell cols="2">(-0.081, 0.060)</cell><cell cols="2">9-9-31</cell><cell>-0.80 (727), -0.67 (735), 0.50 (739)</cell></row><row><cell>d</cell><cell>-0.058</cell><cell cols="2">(-0.112,-0.013)</cell><cell cols="2">5-14-30</cell><cell>-0.75 (747), -0.50 (722), 0.25 (720)</cell></row><row><cell>3</cell><cell>-0.129</cell><cell cols="2">(-0.243,-0.013)</cell><cell cols="2">12-22-15</cell><cell>-0.96 (740), -0.86 (735), 0.86 (706)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="14,114.04,618.70,383.92,79.35"><head>Table 15 :</head><label>15</label><figDesc>Impact of Submitted Terabyte Techniques on Average Precision</figDesc><table coords="14,114.04,633.39,383.92,64.66"><row><cell cols="2">Expt MAP Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>l</cell><cell>0.027</cell><cell>( 0.013, 0.042)</cell><cell>34-14-1</cell><cell>0.16 (733), 0.13 (738), -0.06 (714)</cell></row><row><cell>v</cell><cell>-0.003</cell><cell>(-0.008, 0.003)</cell><cell>21-28-0</cell><cell>0.08 (748), -0.04 (749), -0.05 (726)</cell></row><row><cell>d</cell><cell>-0.009</cell><cell>(-0.015,-0.004)</cell><cell>13-35-1</cell><cell>-0.10 (749), -0.04 (748), 0.02 (741)</cell></row><row><cell>3</cell><cell>-0.069</cell><cell>(-0.089,-0.049)</cell><cell>7-42-0</cell><cell>-0.22 (704), -0.19 (726), 0.03 (746)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="16,87.72,80.60,436.55,388.28"><head>Table 17 :</head><label>17</label><figDesc>Relevance Methods Compared to Terabyte '2:3' Baseline, Reciprocal Rank Measure</figDesc><table coords="16,87.72,95.28,436.55,373.59"><row><cell>Expt</cell><cell>MRR Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>OR: 2:4</cell><cell>0.023</cell><cell>(-0.031, 0.080)</cell><cell>9-7-33</cell><cell>0.50 (715), 0.50 (728), -0.50 (716)</cell></row><row><cell>OR: 2:5</cell><cell>-0.052</cell><cell>(-0.118, 0.010)</cell><cell>4-13-32</cell><cell>-0.75 (748), -0.67 (716), 0.67 (746)</cell></row><row><cell>OR: no stem</cell><cell>-0.055</cell><cell>(-0.131, 0.022)</cell><cell>5-14-30</cell><cell>-0.80 (716), -0.50 (733), 0.80 (714)</cell></row><row><cell>OR: no dlen</cell><cell>-0.139</cell><cell>(-0.239,-0.043)</cell><cell>10-18-21</cell><cell>-0.90 (704), -0.90 (701), 0.67 (746)</cell></row><row><cell>OR: 2:2</cell><cell>-0.564</cell><cell>(-0.674,-0.451)</cell><cell>2-43-4</cell><cell>-1.00 (723), -1.00 (749), 0.47 (741)</cell></row><row><cell>OR: 2:1</cell><cell>-0.646</cell><cell>(-0.745,-0.543)</cell><cell>0-48-1</cell><cell>-1.00 (708), -1.00 (701), 0.00 (710)</cell></row><row><cell>AND: 2:4</cell><cell>0.042</cell><cell>(-0.004, 0.093)</cell><cell>9-5-35</cell><cell>0.50 (715), 0.50 (731), -0.50 (710)</cell></row><row><cell>AND: no stem</cell><cell>-0.038</cell><cell>(-0.107, 0.032)</cell><cell>6-11-32</cell><cell>0.80 (714), -0.50 (722), -0.50 (720)</cell></row><row><cell>AND: 2:5</cell><cell>-0.057</cell><cell>(-0.109,-0.013)</cell><cell>4-11-34</cell><cell>-0.75 (748), -0.50 (720), 0.25 (743)</cell></row><row><cell>AND: no dlen</cell><cell>-0.155</cell><cell>(-0.248,-0.067)</cell><cell>9-18-22</cell><cell>-0.90 (704), -0.90 (701), 0.50 (728)</cell></row><row><cell>AND: 2:1</cell><cell>-0.352</cell><cell>(-0.463,-0.241)</cell><cell>5-32-12</cell><cell>-0.99 (701), -0.96 (732), 0.75 (743)</cell></row><row><cell>AND: 2:2</cell><cell>-0.583</cell><cell>(-0.690,-0.472)</cell><cell>2-43-4</cell><cell>-1.00 (723), -1.00 (749), 0.47 (741)</cell></row><row><cell cols="5">Table 18: Relevance Methods Compared to Terabyte '2:3' Baseline, Average Precision Measure</cell></row><row><cell>Expt</cell><cell>MAP Diff</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>OR: 2:4</cell><cell>-0.016</cell><cell>(-0.026,-0.005)</cell><cell>11-36-2</cell><cell>-0.12 (707), -0.08 (733), 0.08 (705)</cell></row><row><cell>OR: no stem</cell><cell>-0.027</cell><cell>(-0.044,-0.012)</cell><cell>14-35-0</cell><cell>-0.21 (745), -0.19 (733), 0.09 (723)</cell></row><row><cell>OR: 2:5</cell><cell>-0.033</cell><cell>(-0.062,-0.010)</cell><cell>17-32-0</cell><cell>-0.49 (736), -0.26 (731), 0.09 (746)</cell></row><row><cell>OR: no dlen</cell><cell>-0.093</cell><cell>(-0.125,-0.059)</cell><cell>10-39-0</cell><cell>0.34 (745), -0.29 (728), -0.30 (710)</cell></row><row><cell>OR: 2:2</cell><cell>-0.215</cell><cell>(-0.264,-0.164)</cell><cell>3-46-0</cell><cell>-0.53 (710), -0.50 (739), 0.21 (745)</cell></row><row><cell>OR: 2:1</cell><cell>-0.249</cell><cell>(-0.301,-0.199)</cell><cell>0-49-0</cell><cell>-0.69 (709), -0.60 (737), -0.00 (729)</cell></row><row><cell>AND: 2:4</cell><cell>-0.006</cell><cell>(-0.011, 0.000)</cell><cell>19-30-0</cell><cell>-0.06 (707), -0.05 (723), 0.03 (701)</cell></row><row><cell>AND: 2:5</cell><cell>-0.011</cell><cell>(-0.022,-0.002)</cell><cell>19-30-0</cell><cell>-0.14 (749), -0.12 (732), 0.06 (707)</cell></row><row><cell>AND: no stem</cell><cell>-0.037</cell><cell>(-0.059,-0.018)</cell><cell>11-38-0</cell><cell>-0.35 (745), -0.23 (726), 0.09 (723)</cell></row><row><cell>AND: no dlen</cell><cell>-0.082</cell><cell>(-0.108,-0.058)</cell><cell>9-40-0</cell><cell>-0.30 (710), -0.26 (749), 0.11 (745)</cell></row><row><cell>AND: 2:1</cell><cell>-0.138</cell><cell>(-0.178,-0.101)</cell><cell>5-44-0</cell><cell>-0.49 (710), -0.43 (737), 0.08 (743)</cell></row><row><cell>AND: 2:2</cell><cell>-0.195</cell><cell>(-0.240,-0.152)</cell><cell>1-48-0</cell><cell>-0.53 (710), -0.51 (709), 0.00 (729)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.24,690.95,452.82,9.50;1,72.00,701.54,266.38,8.37"><p>SearchServer TM , SearchSQL TM and Intuitive Searching TM are trademarks of Hummingbird Ltd. All other copyrights, trademarks and tradenames are the property of their respective owners.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>WHERE ((<rs type="programName">ALL_PROPS CONTAINS 'visiting pandas national zoo' WEIGHT 1) OR (ALL_PROPS IS_ABOUT 'visiting pandas national zoo' WEIGHT 1) OR (FT_TEXT IS_ABOUT 'visiting pandas national zoo' WEIGHT 10) ) AND ( (URL_TYPE CONTAINS 'ROOT' WEIGHT 0) OR (URL_TYPE CONTAINS 'SUBROOT' WEIGHT 0) OR (URL_TYPE CONTAINS 'PATH' WEIGHT 0) OR (URL_TYPE CONTAINS 'FILE' WEIGHT 0) OR (URL_DEPTH CONTAINS 'URLDEPTHA' WEIGHT 5) OR (URL_DEPTH CONTAINS 'URLDEPTHAB' WEIGHT 5) OR</rs> (<rs type="grantNumber">URL_DEPTH CONTAINS 'URLDEPTHABC' WEIGHT 5) OR (URL_DEPTH CONTAINS 'URLDEPTHABCD' WEIGHT 5)</rs> )</p><p>humW04rdpl: The submitted humW04rdpl run was the same as humW04dpl except that it put additional weight on the url type. This run used the same approach as the successful humTD03upl run of last year (u = r+d). Below is an example WHERE clause: <rs type="programName">WHERE ((ALL_PROPS CONTAINS 'visiting pandas national zoo' WEIGHT 1) OR (ALL_PROPS IS_ABOUT 'visiting pandas national zoo' WEIGHT 1) OR (FT_TEXT IS_ABOUT 'visiting pandas national zoo' WEIGHT 10) ) AND ( (URL_TYPE CONTAINS 'ROOT' WEIGHT 10) OR (URL_TYPE CONTAINS 'SUBROOT' WEIGHT 10) OR (URL_TYPE CONTAINS 'PATH' WEIGHT 10) OR (URL_TYPE CONTAINS 'FILE' WEIGHT 0) OR (URL_DEPTH CONTAINS 'URLDEPTHA' WEIGHT 5) OR (URL_DEPTH CONTAINS 'URLDEPTHAB' WEIGHT 5) OR</rs> (<rs type="grantNumber">URL_DEPTH CONTAINS 'URLDEPTHABC' WEIGHT 5) OR (URL_DEPTH CONTAINS 'URLDEPTHABCD' WEIGHT 5)</rs> )</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QgchF7T">
					<idno type="grant-number">URL_DEPTH CONTAINS &apos;URLDEPTHABC&apos; WEIGHT 5) OR (URL_DEPTH CONTAINS &apos;URLDEPTHABCD&apos; WEIGHT 5)</idno>
					<orgName type="program" subtype="full">ALL_PROPS CONTAINS &apos;visiting pandas national zoo&apos; WEIGHT 1) OR (ALL_PROPS IS_ABOUT &apos;visiting pandas national zoo&apos; WEIGHT 1) OR (FT_TEXT IS_ABOUT &apos;visiting pandas national zoo&apos; WEIGHT 10) ) AND ( (URL_TYPE CONTAINS &apos;ROOT&apos; WEIGHT 0) OR (URL_TYPE CONTAINS &apos;SUBROOT&apos; WEIGHT 0) OR (URL_TYPE CONTAINS &apos;PATH&apos; WEIGHT 0) OR (URL_TYPE CONTAINS &apos;FILE&apos; WEIGHT 0) OR (URL_DEPTH CONTAINS &apos;URLDEPTHA&apos; WEIGHT 5) OR (URL_DEPTH CONTAINS &apos;URLDEPTHAB&apos; WEIGHT 5) OR</orgName>
				</org>
				<org type="funding" xml:id="_KjWcTYm">
					<idno type="grant-number">URL_DEPTH CONTAINS &apos;URLDEPTHABC&apos; WEIGHT 5) OR (URL_DEPTH CONTAINS &apos;URLDEPTHABCD&apos; WEIGHT 5)</idno>
					<orgName type="program" subtype="full">WHERE ((ALL_PROPS CONTAINS &apos;visiting pandas national zoo&apos; WEIGHT 1) OR (ALL_PROPS IS_ABOUT &apos;visiting pandas national zoo&apos; WEIGHT 1) OR (FT_TEXT IS_ABOUT &apos;visiting pandas national zoo&apos; WEIGHT 10) ) AND ( (URL_TYPE CONTAINS &apos;ROOT&apos; WEIGHT 10) OR (URL_TYPE CONTAINS &apos;SUBROOT&apos; WEIGHT 10) OR (URL_TYPE CONTAINS &apos;PATH&apos; WEIGHT 10) OR (URL_TYPE CONTAINS &apos;FILE&apos; WEIGHT 0) OR (URL_DEPTH CONTAINS &apos;URLDEPTHA&apos; WEIGHT 5) OR (URL_DEPTH CONTAINS &apos;URLDEPTHAB&apos; WEIGHT 5) OR</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For tables comparing 2 runs (such as Table <ref type="table" coords="18,263.95,95.49,3.87,10.46">2</ref>), the columns are as follows:</p><p>• "Expt" specifies the experiment. The table's heading may need to be consulted to know details such as the baseline run or the evaluation measure.</p><p>• "Diff" is the difference of the mean scores of the two runs being compared (the table or column heading says which evaluation measure is being compared).</p><p>• "95% Conf" is an approximate 95% confidence interval for the difference calculated using Efron's bootstrap percentile method <ref type="bibr" coords="18,226.85,186.20,10.52,10.46" target="#b1">[2]</ref> (using 100,000 iterations). If zero is not in the interval, the result is "statistically significant" (at the 5% level), i.e. the feature is unlikely to be of neutral impact on average, though if the average difference is small (e.g. &lt;0.020) it may still be too minor to be considered "significant" in the magnitude sense.</p><p>• "vs." is the number of topics on which the experimental run scored higher, lower and tied (respectively) compared to the baseline run. These numbers should always add to the number of topics.</p><p>• "3 Extreme Diffs (Topic)" lists 3 of the individual topic differences, each followed by the topic number in brackets. The first difference is the largest for any topic (based on the absolute value). The third difference is the largest difference in the other direction (so the first and third differences give the range of differences observed in this experiment). The middle difference is the largest of the remaining differences (based on the absolute value).</p><p>See <ref type="bibr" coords="18,104.41,336.68,10.52,10.46" target="#b7">[8]</ref> for some comparisons of confidence intervals from the bootstrap percentile, Wilcoxon signed rank and standard error methods for both average precision and Precision@10.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="18,86.70,396.74,307.16,9.41" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><surname>Cross-Language</surname></persName>
		</author>
		<ptr target="http://www.clef-campaign.org/" />
		<title level="m" coord="18,153.48,396.74,107.58,9.41">Evaluation Forum web site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,414.44,427.81,9.41" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="18,253.15,414.44,134.13,9.41">An Introduction to the Bootstrap</title>
		<author>
			<persName coords=""><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,432.13,453.11,9.41;18,82.51,443.09,20.98,9.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="18,160.00,432.13,196.90,9.41">Converting the Fulcrum Search Engine to Unicode</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Hodgson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,363.50,432.13,172.04,9.41">Sixteenth International Unicode Conference</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,460.78,397.57,9.41" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="18,124.28,460.78,154.77,9.41">NII-Test Collection for IR) Home Page</title>
		<author>
			<persName coords=""><surname>Ntcir</surname></persName>
		</author>
		<ptr target="http://research.nii.ac.jp/∼ntcadm/index-en.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,478.48,453.10,9.41;18,82.51,489.44,60.64,9.41" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<title level="m" coord="18,400.81,478.48,139.00,9.41;18,82.51,489.44,31.36,9.41">Okapi at TREC-3. Proceedings of TREC-3</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,507.14,280.97,9.41" xml:id="b5">
	<monogr>
		<ptr target="http://trec.nist.gov/" />
		<title level="m" coord="18,86.70,507.14,190.80,9.41">Text REtrieval Conference (TREC) Home Page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,524.82,453.10,9.41;18,82.51,535.78,31.21,9.41" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="18,246.22,524.82,196.28,9.41">Hummingbird&apos;s Fulcrum SearchServer at TREC-9</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,450.12,524.82,89.68,9.41;18,82.51,535.78,3.58,9.41">Proceedings of TREC-9</title>
		<meeting>TREC-9</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,553.48,376.75,9.41;18,463.60,552.20,11.73,6.28;18,479.25,553.48,60.72,9.41;18,82.51,564.44,381.18,9.41" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<ptr target="http://clef.isti.cnr.it/workshop2002/WN/26.pdf" />
		<title level="m" coord="18,170.13,553.48,293.32,9.41;18,463.60,552.20,11.73,6.28;18,479.25,553.48,60.72,9.41;18,82.51,564.44,180.29,9.41">Experiments in 8 European Languages with Hummingbird SearchServer TM at CLEF 2002. Working Notes for the CLEF 2002 Workshop</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,86.70,582.13,453.10,9.41;18,82.51,593.09,51.51,9.41;18,134.04,591.81,11.73,6.28;18,149.33,593.09,176.76,9.41" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="18,179.18,582.13,360.62,9.41;18,82.51,593.09,51.51,9.41;18,134.04,591.81,11.73,6.28;18,149.33,593.09,57.47,9.41">Experiments in Named Page Finding and Arabic Retrieval with Hummingbird SearchServer TM at TREC 2002</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,214.07,593.09,87.96,9.41">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,91.30,610.78,395.87,9.41;18,487.34,609.51,11.73,6.28;18,503.33,610.78,36.65,9.41;18,82.51,621.75,209.10,9.41" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Finnish</surname></persName>
		</author>
		<title level="m" coord="18,212.05,610.78,275.12,9.41;18,487.34,609.51,11.73,6.28;18,503.33,610.78,36.65,9.41;18,82.51,621.75,204.34,9.41">Portuguese and Russian Retrieval with Hummingbird SearchServer TM at CLEF 2004. Working Notes for the CLEF 2004 Workshop</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,91.30,639.44,193.35,9.41;18,284.73,638.17,11.73,6.28;18,300.02,639.44,176.76,9.41" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="18,174.01,639.44,110.64,9.41;18,284.73,638.17,11.73,6.28;18,300.02,639.44,37.61,9.41">Hummingbird SearchServer TM at TREC</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,364.76,639.44,87.96,9.41">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,91.30,657.13,370.06,9.41;18,461.52,655.86,11.73,6.28;18,477.31,657.13,62.66,9.41;18,82.51,668.09,112.02,9.41" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="18,210.10,657.13,251.27,9.41;18,461.52,655.86,11.73,6.28;18,477.31,657.13,58.46,9.41">Web and Genomic Retrieval with Hummingbird SearchServer TM at TREC 2003</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Robust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,82.51,668.09,107.82,9.41">Proceedings of TREC 2003</title>
		<meeting>TREC 2003</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,91.30,685.79,448.50,9.41;18,82.51,696.75,150.47,9.41" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="18,315.58,685.79,224.21,9.41;18,82.51,696.75,30.96,9.41">Retrieving Web Pages using Content, Links, URLs and Anchors</title>
		<author>
			<persName coords=""><forename type="first">Thijs</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,120.96,696.75,87.97,9.41">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
