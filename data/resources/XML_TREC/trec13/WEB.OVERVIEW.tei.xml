<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="es">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,166.16,154.89,278.92,15.49">Overview of the TREC-2004 Web Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,192.08,187.37,68.73,10.76"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
							<email>nickcr@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">MSR Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.62,187.37,75.61,10.76"><forename type="first">David</forename><surname>Hawking</surname></persName>
							<email>david.hawking@csiro.au</email>
							<affiliation key="aff1">
								<orgName type="institution">CSIRO</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,166.16,154.89,278.92,15.49">Overview of the TREC-2004 Web Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7D0131EE1DCC608380702702AE7A40E3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>no no MSRAx2 0.96 0.99 (0.177) 0.92 (0.672) 0.97 (0.729) yes yes yes yes yes no uogWebSelAn 0.86 0.92 (0.166) 0.84 (0.615) 0.82 (0.617) yes no yes yes no yes UAmsT04MWScb 0.84 0.82 (0.146) 0.85 (0.624) 0.86 (0.645) yes yes yes yes no no THUIRmix045 0.79 0.70 (0.126) 0.85 (0.619) 0.84 (0.626) yes no yes no no no ICT04CIIS1AT 0.78 0.79 (0.141) 0.83 (0.606) 0.73 (0.545) yes no yes no no no humW04rdpl 0.74 0.91 (0.163) 0.66 (0.484) 0.64 (0.479) no no yes yes yes no SJTUINCMIX3 0.70 0.70 (0.125) 0.74 (0.540) 0.65 (0.489) yes no yes no no yes MeijiHILw1 0.69 0.61 (0.110) 0.84 (0.611) 0.63 (0.473) yes yes yes yes no no csiroatnist 0.67 0.62 (0.111) 0.62 (0.456) 0.76 (0.568) yes yes yes yes yes no MU04web1 0.63 0.64 (0.115) 0.50 (0.362) 0.74 (0.553) yes yes yes yes yes no wdf3oks0arr1 0.59 0.47 (0.085) 0.74 (0.542) 0.54 (0.404) yes no yes yes yes no VTOK5 0.54 0.56 (0.101) 0.70 (0.511) 0.36 (0.270) yes no yes no yes no mpi04web08 0.52 0.46 (0.082) 0.58 (0.423) 0.51 (0.379) yes yes yes yes yes no fdwiedf0 0.46 0.50 (0.090) 0.38 (0.276) 0.51 (0.379) no no no yes yes no LamMcm1 0.38 0.27 (0.049) 0.44 (0.323) 0.44 (0.326) yes yes yes yes yes no irtbow 0.13 0.07 (0.012) 0.22 (0.159) 0.11 (0.086) no no no no no no XLDBTumba01 0.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="es">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year's main experiment involved processing a mixed query stream, with an even mix of each query type studied in TREC-2003: 75 homepage finding queries, 75 named page finding queries and 75 topic distillation queries. The goal was to find ranking approaches which work well over the 225 queries, without access to query type labels.</p><p>We also ran two small experiments. First, participants were invited to submit classification runs, attempting to correctly label the 225 queries by type. Second, we invited participants to download the new W3C test collection, and think about appropriate experiments for the proposed TREC-2005 Enterprise Track. This is the last year for the Web Track in its current form, it will not run in TREC-2005.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Mixed query task</head><p>The mixed query task was conducted using the 18 gigabyte, 1.25 million document crawl of the .GOV domain. Last year's tasks involved queries of three types:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic distillation</head><p>The query describes a general topic, e.g. 'electoral college', the system should return homepages of relevant sites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Homepage finding</head><p>The query is the name of a site that the user wishes to reach, e.g. 'Togo embassy', and the system should return the URL of that site's homepage at (or near) rank one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Named page finding</head><p>The query is the name of a nonhomepage that the user wishes to reach, e.g. 'Ireland consular information sheet', and the system should return the URL of that page at (or near) rank one.</p><p>There are several possible approaches to dealing with the mixed query stream. One is to find a robust ranking method which works well for all three types. Another is to find specialised methods e.g. one for TD, one for NP and one for HP. Specialised methods could be combined, for example by interleaving ranks or combining scores. Combination can either be done uniformly for all queries or based on query classification, preferring the specialist method which seems most appropriate for the current query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Judging and Measures</head><p>Since each NP and HP topic is developed with a URL in mind, the only judging task is to identify URLs of equivalent (near-duplicate) pages. For example identifying that http://xyz.gov/ and http://xyz.gov/ index.html are equivalent answers. TD judging is more time consuming. Finding URLs which are homepages of relevant sites involves a relevance judgment combined with understanding of site structure, which can be gained by navigating between pages and looking at URL(s).</p><p>Judges found 1763 relevant 1 pages: 80 for NP (5 extra), 83 for HP (8 extra) and 1600 for TD. For distillation, the mean number of results per query was 1600/75 = 21.3, with a median of 13. Topic distillation 2003 had mean 10.3 and median 8. Because there were no major changes in query development and judging methods, we believe the 2003 and 2004 sets are matching and reusable test sets for topic distillation.</p><p>We have four measures which we can apply to all query types:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP and MRR Mean average precision (MAP) and</head><p>1 Varying the definition of relevant according to the query type. 1 mean reciprocal rank of the first correct answer (MRR) are standard TREC measures. They are related measures, in that they are exactly equivalent for queries with one correct answer. The problem with applying MAP globally is that some NPHP queries have multiple answers and we only care about the first correct answer. Therefore we apply MAP to TD queries and MRR to NPHP queries. Both measures are calculated on the whole run (1000 ranks), but both put a natural emphasis on the top-ranked documents.</p><p>Success@1 The proportion of queries for which a good answer was at rank 1 (the first result the user sees).</p><p>Success@5 The proportion of queries for which one or more good answers were in the top 5. The top 5 is what might typically appear on the results page of a web search system, without the user needing to scroll ("above the fold"). If a correct answer appears in the top 5 for 90 of 225 queries, then S@5=0.4.</p><p>Success@10 This measure indicates how often a system found something in the top 10, which typically is the first page of web search results. This can also be thought of as a failure measure, because 1 -S@10 is the proportion of queries with nothing in the top 10.</p><p>We also apply Precision@10 and Recall@1000 to the topic distillation queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results per query type</head><p>Table <ref type="table" coords="2,96.48,510.15,4.98,8.97" target="#tab_2">3</ref> presents the results for the 75 distillation queries.</p><p>Considering the MAP and P@10 measures, the top two groups tied, only differing by 0.0011 in MAP and 0.0014 in P@10. Groups 3 and 4 are also very close to each other. Table <ref type="table" coords="2,106.85,558.16,4.98,8.97" target="#tab_0">1</ref> has the results for the 75 named page queries. This year's NP MRR scores are higher than last year's, but a striking difference is that the gap between NP and HP has closed. This is illustrated in Figure <ref type="figure" coords="2,225.59,594.02,4.98,8.97">1</ref> which, compared to a similar plot last year, has a much smaller gap between HP and NP for the top-scoring runs. This could reflect a better balance between 'relevance' and homepage bias (too much homepage bias hurts NP performance).</p><p>Table <ref type="table" coords="2,106.49,653.99,4.98,8.97" target="#tab_1">2</ref> shows results for HP queries. Although the results are high, they are not as high as last year's best HP Run MRR S@1 S@5 S@10 MSRC04B2S 0.731 0.653 0.827 0. performance, of nearly 0.80. Similarly to last year, S@10 performance seems to max out at around 90%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Overall results</head><p>Table <ref type="table" coords="7,96.60,497.15,4.98,8.97" target="#tab_3">4</ref> presents the best run from each group, judged on the average of TD MAP, NP MRR and HP MRR. Although the magnitude for TD is much less than NP and HP, MAP and MRR are related measures so it makes sense to look at the average. Another way to get an overall score out of TD MAP, NP MRR and HP MRR is to normalise each query type according to the maximum score. This gives each run three scores between 0 and 1, and the average of these three scores is an overall score. Such scores are presented in Figure <ref type="figure" coords="7,110.75,617.41,4.98,8.97">2</ref> and Table <ref type="table" coords="7,159.48,617.41,3.74,8.97" target="#tab_4">5</ref>.</p><p>A third way to look at the overall result is by success rate. Success at 10 is an interesting number, because it is different from MAP and MRR which give a lot of weight to rank one, and it indicates how often a user reads a whole page of results without finding a good answer. Figure <ref type="figure" coords="7,326.72,444.70,4.98,8.97">3</ref> presents success rate figures for the best run from each group, according to S@10 across all queries. The best S@10=0.88 measure gives the user no useful documents for 12% of queries, although perhaps this is acceptable if we assume that in those cases the user reformulates their query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">What worked</head><p>Table <ref type="table" coords="7,336.48,557.55,4.98,8.97" target="#tab_4">5</ref> indicates which technologies were used by the best run from each group. It is clear that most groups use document structure and many use anchor text. It also seems useful to use link structure and URL length. Other URL features and query classification were not necessary for good performance, but if groups had their best run using such methods they may well be helpful.</p><p>We also present information on methods used by the best run from several groups. (Full information is in Appendix A.) 1. MSRC04C12 Interleaving of stem and nostem runs, each using structure, URL length and PageRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MSRAx2</head><p>We interpolated relevance scores on the fields of title, body, anchor, url and merged the former four together. The score functions include BM25, proximity and a new proposed URL score function. And the final score combines relevance score and a HostRank that is a PageRank-like value.</p><p>10. uogWebSelAn Content and anchor-text retrieval, Porter Stemming, Divergence From Randomness PL2 weighting scheme, URL-length reranking, Selecting between content and anchor-text retrieval, or content with anchor-text and URL-length reranking 11. UAmsT04MWScb CombMNZ (non-normalized, non-weighted) of stemmed and non-stemmed runs, each using a mixture language model on stemmed full-text, titles, and anchor texts, using both an indegree and URL prior. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">W3C Investigation</head><p>Workshop participants proposed a variety of new experiments, for example relevance ranking in email, or searching for people who are experts in a particular topic area. We plan to pursue such ideas using the W3C dataset in the TREC-2005 Enterprise Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The main experiment showed that, on a mixed query set, effective retrieval is possible without query classification. Topic distillation is still by far the most difficult query type. Query classification runs showed that it is indeed possible to tell the difference. The most common classification mistake was to confuse NP and HP queries.</p><p>The other effect of the mixed query task is to consolidate the findings of previous Web Track years. There are web search information needs which are based on a page's position (a 'homepage') and importance, rather than just the page's text. To answer these information needs, it is not sufficient to search on content alone: use of 'Web evidence' based on structure, links and URLs is necessary. This evidence may be effectively used in an enterprisescale crawl, of a million pages. The Web Track collections are now reusable resources for new experiments with TD, NP, HP and mixed query streams.</p><p>Of course there is also more work to be done in developing evaluation methodologies. Future web experiments could model other user needs, for example transactional search, and refine solutions to tricky issues such as distillation judging and scoring of near-duplicate results. Another direction would be to venture into the wider Web, where adversarial information retrieval is an issue, and many pages are there to manipulate the ranking rather than provide useful information. These can be eliminated or down-weighted via analysis at crawl time or query time. Finally, having so far considered enterprise-scale webs in the Web Track, it is interesting consider ranking with other forms of enterprise information such as mailing list archives and document shares/archives, and a search across a mixture of web and non-web enterprise data. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,72.00,377.01,228.65,8.97;8,91.93,388.97,208.71,8.97;8,91.93,400.92,208.71,8.97;8,91.93,412.88,185.32,8.97;8,72.00,433.30,228.65,8.97;8,91.93,445.25,208.71,8.97;8,91.93,457.21,208.71,8.97;8,91.93,469.16,131.44,8.97;8,72.00,489.59,228.65,8.97;8,91.93,501.54,208.71,8.97;8,91.93,513.50,208.71,8.97;8,91.93,525.45,155.52,8.97;8,72.00,556.76,173.76,12.91;8,72.00,582.26,228.64,8.97;8,72.00,594.21,228.64,8.97;8,72.00,606.17,228.64,8.97;8,72.00,618.12,228.64,8.97;8,72.00,630.08,228.64,8.97;8,72.00,642.03,228.64,8.97;8,72.00,653.99,228.64,8.97;8,72.00,665.94,127.01,8.97"><head>16 .</head><label>16</label><figDesc>THUIRmix045 Word pair weighting based on another run, which used content retrieval in full text and in-link anchor, with a larger weight in fields of Title, head, Bold and first line of page content. 20. ICT04CIIS1AT Anchor text forward propagation, page title text back propagation, combination of anchor text ,key words ,h1 text etc. ,different pivoted weigth function for different part 27. humW04rdpl Plain content search including linguistic expansion from English inflectional stemming, extra weight on properties such as Title and Metadata, lower url depth and root urls 3 Query classification runs Three groups submitted a total of 9 query classification runs. Results are presented in Figure 4. Random classification of 225 queries into three types would tend to lead to about 150 errors, so classification runs were able to do significantly better than random. The best run Mei-jiHILwqc was a manual run. The most common type of error was confusing HP and NP (either by classifying HP as NP or classifying NP as HP).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,320.66,151.43,208.54,490.16"><head>Table 1 :</head><label>1</label><figDesc>Named page results.</figDesc><table coords="2,515.74,151.43,13.45,8.97"><row><cell>880</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,370.24,659.27,109.37,8.97"><head>Table 2 :</head><label>2</label><figDesc>Homepage results.</figDesc><table coords="3,156.15,134.98,298.95,229.16"><row><cell>Run</cell><cell cols="3">MAP P@10 R@1000 S@1 S@5 S@10</cell></row><row><cell>uogWebCAU150</cell><cell>0.179 0.249</cell><cell>0.777</cell><cell>0.507 0.773 0.893</cell></row><row><cell>MSRAmixed1</cell><cell>0.178 0.251</cell><cell>0.815</cell><cell>0.387 0.720 0.880</cell></row><row><cell>MSRC04C12</cell><cell>0.165 0.231</cell><cell>0.744</cell><cell>0.387 0.747 0.800</cell></row><row><cell>humW04rdpl</cell><cell>0.163 0.231</cell><cell>0.808</cell><cell>0.373 0.787 0.907</cell></row><row><cell>THUIRmix042</cell><cell>0.147 0.205</cell><cell>0.761</cell><cell>0.213 0.587 0.747</cell></row><row><cell cols="2">UAmsT04MWScb 0.146 0.209</cell><cell>0.786</cell><cell>0.360 0.667 0.760</cell></row><row><cell>ICT04CIIS1AT</cell><cell>0.141 0.208</cell><cell>0.785</cell><cell>0.333 0.640 0.787</cell></row><row><cell>SJTUINCMIX5</cell><cell>0.129 0.189</cell><cell>0.748</cell><cell>0.293 0.573 0.720</cell></row><row><cell>MU04web1</cell><cell>0.115 0.199</cell><cell>0.647</cell><cell>0.333 0.640 0.760</cell></row><row><cell>MeijiHILw3</cell><cell>0.115 0.153</cell><cell>0.547</cell><cell>0.307 0.547 0.640</cell></row><row><cell>csiroatnist</cell><cell>0.111 0.205</cell><cell>0.261</cell><cell>0.320 0.693 0.853</cell></row><row><cell>mpi04web01</cell><cell>0.106 0.177</cell><cell>0.453</cell><cell>0.240 0.640 0.787</cell></row><row><cell>VTOK5</cell><cell>0.101 0.135</cell><cell>0.721</cell><cell>0.187 0.493 0.533</cell></row><row><cell>fdwiedf0</cell><cell>0.090 0.117</cell><cell>0.536</cell><cell>0.293 0.493 0.587</cell></row><row><cell>wdf3oks0brr1</cell><cell>0.085 0.124</cell><cell>0.720</cell><cell>0.120 0.413 0.573</cell></row><row><cell>LamMcm1</cell><cell>0.049 0.087</cell><cell>0.270</cell><cell>0.173 0.400 0.467</cell></row><row><cell>irttil</cell><cell>0.018 0.029</cell><cell>0.147</cell><cell>0.067 0.147 0.173</cell></row><row><cell>XLDBTumba01</cell><cell>0.003 0.011</cell><cell>0.008</cell><cell>0.040 0.093 0.107</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,122.15,381.81,366.95,259.28"><head>Table 3 :</head><label>3</label><figDesc>Distillation results.</figDesc><table coords="3,122.15,411.93,366.95,229.16"><row><cell>Run</cell><cell cols="4">Average TD MAP NP MRR HP MRR S@1 S@5 S@10</cell></row><row><cell>MSRC04B2S</cell><cell>0.546</cell><cell>0.162</cell><cell>0.731</cell><cell>0.745 0.564 0.809 0.862</cell></row><row><cell>MSRAx4</cell><cell>0.527</cell><cell>0.175</cell><cell>0.685</cell><cell>0.721 0.516 0.796 0.871</cell></row><row><cell>UAmsT04MSind</cell><cell>0.477</cell><cell>0.133</cell><cell>0.640</cell><cell>0.657 0.453 0.733 0.818</cell></row><row><cell>uogWebSelAn</cell><cell>0.466</cell><cell>0.166</cell><cell>0.615</cell><cell>0.617 0.444 0.760 0.818</cell></row><row><cell>THUIRmix045</cell><cell>0.457</cell><cell>0.126</cell><cell>0.619</cell><cell>0.626 0.409 0.702 0.778</cell></row><row><cell>ICT04MNZ3</cell><cell>0.435</cell><cell>0.137</cell><cell>0.603</cell><cell>0.563 0.440 0.689 0.769</cell></row><row><cell>MeijiHILw1</cell><cell>0.398</cell><cell>0.110</cell><cell>0.611</cell><cell>0.473 0.364 0.671 0.738</cell></row><row><cell>SJTUINCMIX2</cell><cell>0.385</cell><cell>0.125</cell><cell>0.543</cell><cell>0.487 0.347 0.618 0.689</cell></row><row><cell>csiroatnist</cell><cell>0.378</cell><cell>0.111</cell><cell>0.456</cell><cell>0.568 0.369 0.662 0.760</cell></row><row><cell>humW04rdpl</cell><cell>0.375</cell><cell>0.163</cell><cell>0.484</cell><cell>0.479 0.369 0.671 0.782</cell></row><row><cell>wdf3oks0arr1</cell><cell>0.344</cell><cell>0.085</cell><cell>0.542</cell><cell>0.404 0.276 0.542 0.653</cell></row><row><cell>MU04web1</cell><cell>0.343</cell><cell>0.115</cell><cell>0.362</cell><cell>0.553 0.356 0.587 0.662</cell></row><row><cell>mpi04web08</cell><cell>0.295</cell><cell>0.082</cell><cell>0.423</cell><cell>0.379 0.298 0.520 0.564</cell></row><row><cell>VTOK5</cell><cell>0.294</cell><cell>0.101</cell><cell>0.511</cell><cell>0.270 0.253 0.502 0.564</cell></row><row><cell>fdwiedf0</cell><cell>0.248</cell><cell>0.090</cell><cell>0.276</cell><cell>0.379 0.258 0.453 0.538</cell></row><row><cell>LamMcm1</cell><cell>0.232</cell><cell>0.049</cell><cell>0.323</cell><cell>0.326 0.218 0.418 0.489</cell></row><row><cell>irtbow</cell><cell>0.086</cell><cell>0.012</cell><cell>0.159</cell><cell>0.086 0.071 0.133 0.231</cell></row><row><cell>XLDBTumba01</cell><cell>0.025</cell><cell>0.003</cell><cell>0.068</cell><cell>0.004 0.036 0.058 0.067</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,132.86,658.76,345.54,46.04"><head>Table 4 :</head><label>4</label><figDesc>Overall results. Average is the mean of the TD MAP, NP MRR and HP MRR. This year the top runs had less of a gap between HP and NP performance (compared to a plot in last year's overview). Performance of all runs, based on ratios with the best run of each type.</figDesc><table coords="3,303.13,695.83,4.98,8.97"><row><cell>3</cell></row></table><note coords="6,171.22,376.23,268.81,8.97"><p>Figure 3: Success rate results. Best run from each group, by S@10.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,72.00,376.79,467.24,32.88"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note coords="7,106.52,376.79,432.72,8.97;7,72.00,388.74,467.24,8.97;7,72.00,400.70,146.38,8.97"><p>Normalised overall results with indication of methods used. Anc: Anchor text used? Lnk: Other link structure used? Strc: Document structure used? ULen: URL length used? UOth: Other URL features used? QCls: Special processing for different query types?</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,310.61,130.00,228.64,515.67"><head>. fdwiedf0* hammingbird algorithm 58. mpi04web07 Automatic</head><label></label><figDesc>This is a baseline run obtained by submitting the query titles to the Panoptic (CSIRO software) search service at ir.nist.gov. Note that an error with topic 179 resulted in no documents retrieved. To pass the submission checking script, the 30th result for topic 178 was arbitrarily inserted as the first for 179. Vector space model. Using anchor text, url-depth and title text. Outdegree reranking. Query Classified based on last year's queries.Query expansion using Conceptual Fuzzy Sets(CFS). 48. wdf3oks0b result merging, okapi, combo stemmer 49. humW04pl same as humW04l except extra weight on properties such as Title and Metadata 50. VTOK5* BASELINE 51. MeijiHILw5 Vector space model. Using anchor text, url-depth and title text. Outdegree reranking. Query Classified based on last year's queries.Query expansion using Conceptual Fuzzy Sets(CFS). Document vector modification by Relevance-based Superimposition Model(RSModel). 52. MU04web3 Vector Space Model + Document-centric impacts + Pagerank 53. mpi04web08* Automatic phrase detection, Anchor text reranking, PageRank, Stemming 54. mpi04web01 our baseline plain keyword queries from title PageRank Stemming 55. mpi04web06 Autmatic query expansion + phrase detection PageRank Stemming 56. mpi04web02 Autmatic query expansion + phrase detection PageRank Stemming 57phrase detection, PageRank, Stemming 59. MU04web5 Vector space model + document-centric impacts 60. MU04web2 Vector Space Model + Document-centric impacts + URL depth 61. MU04web4 Vector space model + document-centric impact + pagerank + URL depth 62. LamMcm1* Multicriteria analysis Lovins Stemming Kleinberg authority scores 63. humW04l plain content search including linguistic expansion from English inflectional stemming 64. irtbow* bag of words but with added weighting for query term order and proximity; Lnu.Ltc weighting. 65. irttil title only; Lnu.Ltc weighting 66. fdwiesl0 improved okpai method 67. irtphr2 phrase search (not useful for single-term queries); Lnu.</figDesc><table coords="9,310.61,130.00,228.64,515.67"><row><cell>31. ICT04basic vector space content model, baseline for all the runs, using com-</cell></row><row><cell>bination of anchor text and some simplest page structure info. not stems,not</cell></row><row><cell>feedback and classification of queries</cell></row><row><cell>32. SJTUINCMIX3* BM25</cell></row><row><cell>33. SJTUINCMIX2 Task classification,BM25</cell></row><row><cell>34. MeijiHILw1* Vector space model. Using anchor text, url-depth and title text.</cell></row><row><cell>Outdegree reranking.</cell></row><row><cell>35. MeijiHILw3 Vector space model. Using anchor text, url-depth and ti-</cell></row><row><cell>tle text. Outdegree reranking. Query Classified based on last year's</cell></row><row><cell>queries. Document vector modification by Relevance-based Superimpo-</cell></row><row><cell>sition Model(RSModel).</cell></row><row><cell>36. SJTUINCMIX1 task classification,BM25,minimal span weighting reRank</cell></row><row><cell>37. MeijiHILw2 Vector space model. Using anchor text, url-depth and title text.</cell></row><row><cell>Outdegree reranking. Query Classified based on last year's queries.</cell></row><row><cell>38. SJTUINCMIX5 Task classification,BM25,Site Unit</cell></row><row><cell>39. SJTUINCMIX4 Task classification,BM25,PageRank reRank</cell></row><row><cell>40. csiroatnist* 41. humW04dpl same as humW04pl except extra weight for lower url depth</cell></row><row><cell>42. MU04web1* Vector Space Model + Document-centric impact + pagerank +</cell></row><row><cell>URL depth</cell></row><row><cell>43. humW04dp same as humW04dpl except linguistic expansion from stem-</cell></row><row><cell>ming disabled</cell></row><row><cell>44. wdf3oks0arr1* result merging, okapi, simple stemmer, homepage rank</cell></row><row><cell>boosting</cell></row><row><cell>45. wdf3oks0brr1 result merging, okapi, combo stemmer, homepage rank boost-</cell></row><row><cell>ing</cell></row><row><cell>46. wdf3oks0a result merging, okapi, simple stemmer</cell></row><row><cell>47. MeijiHILw4 Ltc weight-</cell></row><row><cell>ing.</cell></row><row><cell>68. fdwiellq1 anchro-text ranking</cell></row><row><cell>69. fdwiellq0 okpai model</cell></row><row><cell>70. XLDBTumba01*</cell></row><row><cell>71. VT2 Ranking tuning using linear fusion</cell></row><row><cell>72. VTTD1 TD tuning</cell></row><row><cell>73. VT1 best trial</cell></row><row><cell>74. VT3 Ranking tuning using linear fusion</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A All run descriptions</head><p>The a description of each run as submitted, sorted as in Figure <ref type="figure" coords="9,100.50,162.20,3.74,8.97">2</ref>. Each group's best run is marked with a *.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,74.62,188.52,226.03,6.28;9,91.93,196.49,208.72,6.28;9,91.93,204.46,83.90,6.28" xml:id="b0">
	<monogr>
		<title level="m" coord="9,79.39,188.52,221.25,6.28;9,91.93,196.49,208.72,6.28;9,91.93,204.46,80.52,6.28">MSRC04B2S Weighted Field BM25 (fields title, body &amp; anchor) optimised on the Named Page 2003 task, with linear adition of non-linear PageRank and URL features. Stemming</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.62,210.77,226.03,6.28;9,91.93,218.74,18.77,6.28" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,79.39,210.77,136.40,6.28">MSRAx2* relevance propagation + HostRank</title>
		<imprint/>
	</monogr>
	<note>more details in Section 2.4 above</note>
</biblStruct>

<biblStruct coords="9,74.62,225.05,226.03,6.28;9,91.93,233.02,16.66,6.28" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,79.39,225.05,221.25,6.28;9,91.93,233.02,16.66,6.28">MSRAmixed1 fields weighting + proximity + a new importance named Hos-tRank</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.62,239.33,157.40,6.28" xml:id="b3">
	<monogr>
		<title level="m" coord="9,79.39,239.33,152.62,6.28">MSRAx4 URL match and level + BM25 + HostRank</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.62,245.63,226.03,6.28;9,91.93,253.60,208.72,6.28;9,91.93,261.57,93.00,6.28" xml:id="b4">
	<monogr>
		<title level="m" coord="9,79.39,245.63,221.25,6.28;9,91.93,253.60,208.72,6.28;9,91.93,261.57,89.75,6.28">MSRC04B1S Weighted Field BM25 (fields title, body &amp; anchor) optimised on the Named Page 2003 task, with linear adition of non-linear PageRank and URL features. No stemming</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.62,267.88,112.11,6.28;9,72.00,274.19,136.59,6.28" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,79.39,267.88,107.33,6.28;9,72.00,274.19,136.59,6.28">MSRAmixed3 BM2500 + Proximity 8. MSRAx5 relevance propagation + HostRank</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.62,280.49,226.03,6.28;9,91.93,288.46,208.72,6.28;9,91.93,296.43,119.15,6.28" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,127.38,280.49,173.26,6.28;9,91.93,288.46,95.85,6.28">Weighted Field BM25 (fields title, body &amp; anchor) optimised on the Topic Distillation 2003 task</title>
		<idno>MSRC04B1S2</idno>
		<imprint/>
	</monogr>
	<note>with linear adition of non-linear Click-Distance and URL features. No stemming</note>
</biblStruct>

<biblStruct coords="9,77.81,302.74,222.83,6.28;9,91.93,310.71,208.72,6.28;9,91.93,318.68,208.72,6.28;9,91.93,326.65,86.09,6.28" xml:id="b7">
	<monogr>
		<title level="m" coord="9,82.88,302.74,217.76,6.28;9,91.93,310.71,208.72,6.28;9,91.93,318.68,208.72,6.28;9,91.93,326.65,86.09,6.28">uogWebSelAn* content and anchor-text retrieval, Porter Stemming, Divergence From Randomness PL2 weighting scheme, URL-length reranking, Selecting between content and anchor-text retrieval, or content with anchortext and URL-length reranking</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,332.96,222.83,6.28;9,91.93,340.93,114.04,6.28" xml:id="b8">
	<monogr>
		<title level="m" coord="9,82.88,332.96,217.76,6.28;9,91.93,340.93,110.20,6.28">UAmsT04MWScb* CombMNZ (non-normalized, non-weighted) of runs UAmsT04MWinu and UAmsT04MSinu</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,347.24,222.83,6.28;9,91.93,355.21,208.72,6.28;9,91.93,363.18,208.72,6.28;9,91.93,371.15,86.09,6.28" xml:id="b9">
	<monogr>
		<title level="m" coord="9,82.88,347.24,217.76,6.28;9,91.93,355.21,208.72,6.28;9,91.93,363.18,208.72,6.28;9,91.93,371.15,86.09,6.28">uogWebSelAnL content and anchor-text retrieval, Porter Stemming, Divergence From Randomness PL2 weighting scheme, URL-length reranking, Selecting between content and anchor-text retrieval, or content with anchortext and URL-length reranking</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,377.45,222.83,6.28;9,91.93,385.42,144.68,6.28" xml:id="b10">
	<monogr>
		<title level="m" coord="9,82.88,377.45,217.76,6.28;9,91.93,385.42,142.19,6.28">UAmsT04MSinu Mixture language model on stemmed full-text, titles, and anchor texts, using both an indegree and URL prior</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,391.73,222.83,6.28;9,91.93,399.70,103.03,6.28" xml:id="b11">
	<monogr>
		<title level="m" coord="9,82.88,391.73,217.76,6.28;9,91.93,399.70,100.54,6.28">UAmsT04MSind Mixture language model on stemmed full-text, titles, and anchor texts, using an indegree prior</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,406.01,222.83,6.28;9,91.93,413.98,156.49,6.28" xml:id="b12">
	<monogr>
		<title level="m" coord="9,82.88,406.01,217.76,6.28;9,91.93,413.98,154.00,6.28">UAmsT04MWinu Mixture language model on non-stemmed full-text, titles, and anchor texts, using both an indegree and URL prior</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,420.28,188.09,6.28" xml:id="b13">
	<monogr>
		<title level="m" coord="9,82.88,420.28,179.32,6.28">THUIRmix045* Word pair weighting based on THUIRmix041</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,426.59,222.83,6.28;9,91.93,434.56,208.72,6.28;9,91.93,442.53,65.67,6.28" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="9,82.88,426.59,217.76,6.28;9,91.93,434.56,95.85,6.28">S Weighted Field BM25 (fields title, body &amp; anchor) optimised on the Topic Distillation 2003 task</title>
		<idno>MSRC04B3</idno>
		<imprint/>
	</monogr>
	<note>with linear adition of non-linear Click-Distance No stemming</note>
</biblStruct>

<biblStruct coords="9,77.81,448.84,222.83,6.28;9,91.93,456.81,208.72,6.28;9,91.93,464.78,79.33,6.28" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="9,82.88,448.84,217.76,6.28;9,91.93,456.81,26.32,6.28">THUIRmix044 Query classification with query length and named entity information</title>
		<imprint/>
	</monogr>
	<note>TD topics are assigned to THUIRmix042, while the others are retrieved on THUIRmix041</note>
</biblStruct>

<biblStruct coords="9,77.81,471.09,222.83,6.28;9,91.93,479.06,208.72,6.28;9,91.93,487.03,83.10,6.28" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="9,82.88,471.09,217.76,6.28;9,91.93,479.06,208.72,6.28;9,91.93,487.03,80.26,6.28">THUIRmix042 Content retrieval in full text and in-link anchor of Key resource pages. Key resource pages are selected with non-content features using clustering technologies</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,493.33,222.83,6.28;9,91.93,501.30,208.72,6.28;9,91.93,509.27,105.77,6.28" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="9,82.88,493.33,217.76,6.28;9,91.93,501.30,208.72,6.28;9,91.93,509.27,105.77,6.28">AT* anchor text forward propagation , page title text back propagation, combination of anchor text ,key words ,h1 text etc. ,different pivoted weigth function for different part</title>
		<idno>ICT04CIIS1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,515.58,222.83,6.28;9,91.93,523.55,208.72,6.28;9,91.93,531.52,143.66,6.28" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,126.99,515.58,173.65,6.28;9,91.93,523.55,208.72,6.28;9,91.93,531.52,48.89,6.28">CombMNZ for combination of anchor text retrieval result ,structure info retrieval result and content retrieval result. anchor text forward propagation</title>
		<idno>ICT04MNZ3</idno>
		<imprint/>
	</monogr>
	<note>page title text back propagation</note>
</biblStruct>

<biblStruct coords="9,77.81,537.83,222.83,6.28;9,91.93,545.80,118.17,6.28" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="9,82.88,537.83,217.76,6.28;9,91.93,545.80,118.17,6.28">uogWebCA content and anchor text retrieval, Porter Stemming, Divergence From Randomness PL2 weighting scheme</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,552.10,222.83,6.28;9,91.93,560.07,182.03,6.28" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="9,82.88,552.10,217.76,6.28;9,91.93,560.07,179.24,6.28">THUIRmix041 Content retrieval in full text and in-link anchor, with a larger weight in fields of Title, head, Bold and first line of page content</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,566.38,222.83,6.28;9,91.93,574.35,168.00,6.28" xml:id="b21">
	<monogr>
		<title level="m" coord="9,82.88,566.38,217.76,6.28;9,91.93,574.35,165.58,6.28">ICT04RULE rerank the result by some heuristic strategies make use of the url depth,url works,anchkor text, site compression like trick</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,580.66,222.83,6.28;9,91.93,588.63,208.72,6.28;9,91.93,596.60,208.72,6.28;9,91.93,604.57,73.99,6.28" xml:id="b22">
	<monogr>
		<title level="m" coord="9,82.88,580.66,217.76,6.28;9,91.93,588.63,208.72,6.28;9,91.93,596.60,208.72,6.28;9,91.93,604.57,73.99,6.28">uogWebSelL content and anchor-text retrieval, Porter Stemming, Divergence From Randomness PL2 weighting scheme, URL-length reranking, Selecting between content and anchor-text retrieval, or content with anchor-text and URL-length reranking</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,610.88,222.83,6.28;9,91.93,618.85,206.90,6.28" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="9,82.88,610.88,217.76,6.28;9,91.93,618.85,204.11,6.28">THUIRmix043 THUIRmix041 + primary space model weighting in in-link anchor text and contents of Title, head, Bold and first line of page content</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,631.46,222.83,6.28;9,91.93,639.43,169.57,6.28" xml:id="b24">
	<monogr>
		<title level="m" coord="9,82.88,631.46,217.76,6.28;9,91.93,639.43,169.57,6.28">ICT04CIILC comparable run with ICT04basic, using a different weighted function for Content text, others just the same as ICT04basic</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,77.81,645.74,222.83,6.28;9,91.93,653.71,201.83,6.28;9,72.00,660.01,228.64,6.28;9,91.93,667.98,73.49,6.28" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,231.59,653.71,62.17,6.28;9,72.00,660.01,5.81,6.28">URL-length reranking 30</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,82.88,645.74,217.76,6.28;9,91.93,653.71,134.68,6.28;9,82.88,660.01,217.76,6.28;9,91.93,667.98,71.02,6.28">uogWebCAU150 content and anchor text retrieval, Porter Stemming, Divergence From Randomness PL2 weighting scheme</title>
		<imprint/>
	</monogr>
	<note>UAmsT04LnuNG Lnu.ltc run with word n-gram boosting, using document structure and anchor texts</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
