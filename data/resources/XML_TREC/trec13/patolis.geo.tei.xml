<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,103.08,80.56,405.90,16.72;1,87.00,104.32,438.05,16.72">Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,267.06,126.62,77.94,11.15"><forename type="first">Sumio</forename><surname>Fujita</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">PATOLIS Corporation</orgName>
								<address>
									<addrLine>2-4-29, Koto-ku</addrLine>
									<postCode>135-0043</postCode>
									<settlement>Shiohama, Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,103.08,80.56,405.90,16.72;1,87.00,104.32,438.05,16.72">Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A08E38A2C0395C95900D697A33CF6B38</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Document length</term>
					<term>language modeling for information retrieval</term>
					<term>pseudo-relevance feedback</term>
					<term>reference database feedback</term>
					<term>MeSH</term>
					<term>LocusLink</term>
					<term>MEDLINE</term>
					<term>support vector machines</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC-2004 Genomics track evaluation experiments at Patolis Corporation are described with a focus on the document length issues in different retrieval models such as TF*IDF or probabilistic language modeling approaches. In the genomics ad hoc retrieval task, combination of pseudo-relevance feedback and reference database feedback is applied. For the triage sub-task, we trained a SVM classifier using leave-one-out-cross-validation, and calibrated parameters to be optimal against the training set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The TREC-2004 Genomics track evaluation experiments at the Patolis Corporation group are described. The track consists of the ad hoc retrieval task and the categorization task. The ad hoc retrieval task is designed to simulate the subject topic retrieval against a 10 year subset (4,591,008 records) of the MEDLINE bibliographic database. 50 official (and other 5 sample) search topics are derived from interviews on real biology researchers. Relevance assessments were carried out using the conventional pooling method and each pooled documents are judged as definitely relevant (DR), possibly relevant (PR) or not relevant (NR) against the information needs. Documents rated DR or PR are considered as relevant in official evaluations. Participants are asked to submit up to two sets of top 1000 relevance ranked list of documents retrieved by either automatically or manually constructed queries from given search topics. There are no specific restrictions using data resources. The other task is the categorization task, which actually consists of three subtasks namely triage, annotation hierarchy and annotation hierarchy plus evidence. We participated in the triage subtask where participants are asked to identify papers deemed to have experimental evidences warranting annotation with GO codes from the collection of articles of three journals over two years. The document collection is a subset of these articles filtered through by the "mouse trap" method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Description</head><p>Our evaluation environment: the PLLS system developed based on the Lemur toolkit 2.0.1 for indexing system <ref type="bibr" coords="1,386.41,331.35,15.58,8.74" target="#b14">[15]</ref>; the PostgreSQL RDB system is integrated for treating bibliographic information. The system is operated on a dual CPU PC server(Xeon 3.20GHz, 4GB RAM) running RedHat Linux. The document collections are indexed wholly automatically, and converted to inverted index files of terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing Language</head><p>The words are indexed either stemmed by a porter stemmer or indexed by their appearing forms. Stopword elimination by InQuery stop list is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval Models</head><p>The following two retrieval models are implemented: -TF*IDF with Okapi BM25 TF <ref type="bibr" coords="1,471.11,492.09,16.74,8.74" target="#b16">[17]</ref> <ref type="bibr" coords="1,487.85,492.09,16.74,8.74" target="#b17">[18]</ref> (BM25 TF*IDF hereafter) BM25 TF is incorporated in the dot-product matching function between TF*IDF weighted vectors. Typical parameters like k1, b can be adjusted. Instead of the Okapi IDF: log(N-df(t)+0.5/df(t)+0.5) that gets a negative value when df(t) is very large, we adopted a standard IDF adjusted by the k4 parameter. This is slightly different from the implementation in the Lemur toolkit. The same weighting is applied for the query part but with a different value for k1 and without length normalization i.e. b=0. Such a dot-product matching between BM25 TF*IDF weighted vectors is applied successfully to TREC web ad hoc search task characterized by very short queries and various lengths of documents where subdocument based retrieval is applied [5] [6]. </p><formula xml:id="formula_0" coords="2,101.70,75.93,156.29,31.75">+ + - + + =</formula><p>-KL-divergence of probabilistic language models with Dirichlet prior smoothing (KL-Dir hereafter) <ref type="bibr" coords="2,253.53,216.78,16.75,8.77" target="#b22">[23]</ref> For the KL-divergence model, the detail is described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Reference Database Feedback Strategies</head><p>Besides traditional pseudo relevance feedback, "reference database" feedback methods from the MeSH entry database and the LocusLink summary description database, are applied for expanding query terms. This technique is applied in the TREC-9 Web track by Fujita <ref type="bibr" coords="2,70.92,340.44,11.71,8.77" target="#b4">[5]</ref> where the queries are very short and even noisy. In the Web track, it was effective with very short queries but not with longer queries. In the genomics track, expansions of gene symbol variation and technical term variation are intended using this technique. There is naturally another option to expand a query with such synonymous word groups: extracting exact alias symbol groups from the "ALIAS SYMBOL" field of LocusLink records (from the MH and SY fields of MeSH records as well), gene symbol thesauri are generated. Given an occurrence of a word in the generated thesauri, the query is expanded by the group of synonymous words in the thesauri. We applied more "relaxed" expansions, where indexing each LocusLink or MeSH record as one document and retrieving the best matched documents against the original query and extracting terms from some of the best match documents. Not only synonymous words but also words from summary sentences are added to the query. The system submits the original query generated automatically from topic descriptions against the reference databases, and takes the top n(=1) document(s) from the ranked list for term extraction. The term selection module extracts salient terms from these pseudo-relevant documents and adds them to the query vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Pseudo-Relevance Feedback Strategies</head><p>Pseudo-relevance feedback is applied in both official runs and other unofficial runs.</p><p>Rocchio feedback <ref type="bibr" coords="2,397.84,79.38,16.75,8.77" target="#b18">[19]</ref> for BM25 TF*IDF and the mixture model query update method for KL-divergence retrieval model <ref type="bibr" coords="2,380.85,102.78,16.73,8.77" target="#b23">[24]</ref> (unofficial runs), are adopted. The parameters such as the number of documents for the pseudo relevant set, the number of terms to feedback, some score cutoff threshold values and mixture coefficients of feedback terms against original terms are decided by pre-submission experiments using five sample topic sets and the corresponding relevance judgment file provided by the organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Query Expansion in Summary</head><p>Reference database feedback procedures and the pseudo-relevance feedback are sequentially applied. The system submits the original query generated automatically from each topic description against two reference databases consequently, and makes two groups of documents. In this case, we used only the top one document from each reference database for term extraction. The terms extracted from these documents are added to the query vector. Then the expanded query vector is submitted against the target database and the pseudo-relevance feedback is applied preceding the final search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Language Modeling for IR</head><p>Uses of probabilistic language models in information retrieval intended to adopt a theoretically motivated retrieval model given that recent probabilistic approaches tend to use too many heuristics. Ponte and Croft first applied a document unigram model to compute the probability of the given query to be generated from a document <ref type="bibr" coords="2,440.61,443.04,15.37,8.77" target="#b15">[16]</ref>. In TREC-7, Hiemstra and Kraaij [8] introduced linear interpolation of local and global probabilities while Miller et al. <ref type="bibr" coords="2,366.38,478.14,16.73,8.77" target="#b13">[14]</ref> used hidden Markov model to mixture two distributions. Berger and Lafferty <ref type="bibr" coords="2,479.82,489.84,11.72,8.77" target="#b0">[1]</ref> proposed a statistical translation as a model of user's distillation process from an information need into a succinct query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Model</head><p>The adopted model is simple: estimate a language model for each document and rank documents by the likelihood of generating the submitted query. This is exactly a retrieval version of a Naïve Bayes classifier, which estimates a language model for each class and ranks classes by the likelihood of generating the document to be classified. Applying Bayes' theorem for p(d|q), and eliminating document independent part, we have:</p><formula xml:id="formula_1" coords="2,319.38,654.10,121.60,14.71">) | ( ) ( ) | ( d q p d p q d p ∝</formula><p>Assuming a simple uni-gram model of documents, p(q|d) is:</p><formula xml:id="formula_2" coords="3,74.22,86.07,103.84,28.30">∏ = i i d q p d q p ) | ( ) | (</formula><p>Taking the logarithm, the retrieval function becomes:</p><formula xml:id="formula_3" coords="3,72.54,148.05,223.30,28.30">∑ + = i i d q p d p d q p d p ) | ( log ) ( log )) | ( ) ( log(</formula><p>A document dependent prior probability p(d) can be either a uniform probability or any document dependent factors that may affect the relevance such as document length or hyper link related information. Assuming a uniform prior probability and dropping the first term, transforming the summation over query term positions into a summation over words in the vocabulary, dividing by the query length, we have:</p><formula xml:id="formula_4" coords="3,72.90,292.05,116.47,28.32">∑ ∈V w d w p q w p )) | ( log( ) | (</formula><p>This is exactly the negative cross entropy of a query language model with a document language model, which measures the difference between the two probability distributions and this is equivalent to KLdivergence of a query language model from a document language model in view of ranking documents against the given query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Smoothing Methods</head><p>Zhai and Lafferty presented that a smoothing method plays a crucial role in language modeling IR <ref type="bibr" coords="3,251.55,445.50,15.37,8.77" target="#b22">[23]</ref>. They analyzed the role of smoothing in language modeling IR from two aspects: to avoid zero probabilities for unseen words and "to accommodate generation of common words in a query". In this respect, smoothing plays a role similar to IDF in TF*IDF weighting. They proposed three types of smoothing strategies including the Jelinek-Mercer method i.e. simple linear combination of an estimated document model and a background model p(w|C), the Baysean smoothing using Dirichlet Priors method that computes maximum a posteriori parameter values with a Dirichlet prior ( i.e. a kind of the Laplace smoothing ), and the absolute discount method. The Jelinek-Mercer method is:</p><formula xml:id="formula_5" coords="3,74.22,628.16,187.84,15.54">) | ( ) | ( ) 1 ( ) | ( C w p d w p d w p ml λ λ λ + - =</formula><p>The Dirichlet-Prior method is:</p><formula xml:id="formula_6" coords="3,319.38,75.27,162.94,32.44">µ µ µ + + = | | ) | ( ) , ( ) | ( d C w p d w freq d w p</formula><p>The smoothing factor in the first case is λ while µ/|d|+ µ in the second case. Document length is taken into consideration in the Dirichlet-Prior smoothing: as p(w|C) is divided by the document length, scores of longer documents are more penalized than the Jelinek-Mercer smoothing. We utilized the implementation in the Lemur toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Document Dependent Priors</head><p>On the other hands, any document dependent and typically query independent factors that may affect the relevance can be taken into consideration by the scoring process as document prior probabilities. Some studies suggest that document length is a good choice in TREC experiments since it is predictive of relevance against the TREC test set <ref type="bibr" coords="3,460.89,294.12,15.96,8.77" target="#b13">[14]</ref> <ref type="bibr" coords="3,476.85,294.12,15.96,8.77" target="#b19">[20]</ref>. The following document length dependent probability is applied where µ is smoothing factor. </p><formula xml:id="formula_7" coords="4,74.22,75.27,92.34,42.66">∑ ∈ + + = D d d d d p ' 2 | ' | 2 | | ) ( µ µ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Ad Hoc Retrieval Task 4.1 Official Runs</head><p>We submitted two automatic runs as follows: pllsgen4a1: BM25TF*IDF, long query, pseudo relevance feedback, reference database feedback, stopwords elimination, without stemming. pllsgen4a2: BM25TF*IDF, long query, pseudo relevance feedback, reference database feedback, stopwords elimination, with a porter stemmer.</p><p>Table <ref type="table" coords="4,98.83,270.42,5.03,8.77" target="#tab_1">1</ref> shows the performance of official runs and some comparative runs. By using Porter stemmer in indexing, statistically significant (t-test, p&lt;0.05) improvements of the MAP values are observed. In TREC-9, we explained our approach utilizing the "foreground vs background" metaphor, where foreground terms denote directly the subject concept of the information need and background terms connote the subject topic. When utilizing such expanded longer queries, differentiating weights of query terms according to the "foregroundness" i.e. source of the terms, makes considerable difference in effectiveness. Table <ref type="table" coords="4,99.11,445.93,5.03,8.77" target="#tab_2">2</ref> shows parameters of the official runs and "XXX coeff." indicates the weights for the terms from each source, i.e. &lt;TITLE&gt;, &lt;NEED&gt; and &lt;CONTEXT&gt; fields of topic descriptions, MeSH and LocusLink reference databases, and pseudorelevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Post-Submission Experiments</head><p>We did not afford to submit KL-dir runs because of our experiences in NTCIR-4 <ref type="bibr" coords="4,235.19,555.54,10.66,8.77" target="#b6">[7]</ref>. We had impressions that it tends to retrieve shorter documents than it should do. This causes slightly poorer performance in test collection based evaluation where usually relevance assessments tend to prefer longer documents. Table <ref type="table" coords="4,96.91,637.44,5.03,8.77" target="#tab_4">3</ref> shows the performance comparison combining pseudo-relevance feedback and reference database feedback as well as different retrieval models TF*IDF/KL-Dir on the basis of the pllsgen4a2 setting.</p><p>The pseudo relevance feedback procedure contributes to 4.39% to 2.00 % of consistent improvements in average precision in all cases. The reference database feedback procedure improves MAP consistently but as slightly as 0.97% to 0.44%. The improvement gained by the combination of pseudo-relevance feedback and reference database feedback is 4.57% for TF*IDF runs and 2.53% for KL-Dir runs. The rates of improvements are modest in comparison with our past experiences in the TREC-9 Web track utilizing very short queries (+17%) <ref type="bibr" coords="4,477.10,208.09,11.71,8.77" target="#b4">[5]</ref> and in the TREC 2001 Web track (+21.4%) <ref type="bibr" coords="4,451.83,219.79,10.64,8.77" target="#b5">[6]</ref>. One of the reasons why the gains from feedbacks are small is that full-length queries are utilized where all three topic fields are combined and comparatively rich term sets are generated. Such observation is consistent with our past experiences utilizing various length queries in TREC-9 <ref type="bibr" coords="4,394.45,289.99,11.72,8.77" target="#b4">[5]</ref> and in NTCIR-1 <ref type="bibr" coords="4,477.00,289.99,10.64,8.77" target="#b3">[4]</ref>. The difference is not statistically significant but unofficial KL-Dir runs consistently better than their TF*IDF counterparts (2.40% to 0.05%) even though no parameter tuning was done. By some parameter tuning in post-submission experiments, the best MAP as high as 0.4264 is  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Document Length Issues</head><p>We comparatively studied the behavior of two different retrieval models, namely TF*IDF with BM25 TF and KL-divergence with Dirichlet smoothing in NTCIR-3 and NTCIR-4 Japanese newspaper and patent test collections <ref type="bibr" coords="5,362.04,153.90,10.65,8.77" target="#b6">[7]</ref>.</p><p>Both retrieval models reasonably worked well against the Patent test collections, which is in some sense technico-scientific documents while BM25 TF*IDF outperformed KL-Dir against the newspaper test collections. After some analyses, we found out that this discrepancy is caused by the different behavior of two retrieval models against different lengths of documents.</p><p>In brief, KL-Dir tended to retrieve shorter documents than BM25 TF*IDF.</p><p>The question is why it worked for some test collections but not for other test collections.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Document Length Hypotheses</head><p>The question to be asked here is why longer documents are longer than shorter ones? Though this question may sound as a tautology, it is not. The problem is to know how each document differs in length.</p><p>If longer documents have more information, they may be more likely to be relevant against diverse queries, so that it is fair to get a higher matching score.</p><p>Robertson and Walker [17] postulated two hypotheses to explain different length of documents namely the "Scope hypothesis" and the "Verbosity hypothesis".</p><p>The "Scope hypothesis" considers a long document as a concatenation of a number of unrelated short documents while the "Verbosity hypothesis" assumes that a long document covers the same scope as a short document but it uses more words. These two hypotheses represent the extreme cases and real documents are always the mixture of the two cases.</p><p>The natural consequence of adopting the "Scope hypothesis" is that a long document is more likely to be relevant irrespective of search requests since it covers more subject topics than a shorter one. Robertson and Walker assume that the "Verbosity hypothesis" implies that document properties such as relevance and eliteness are independent of document length. Longer documents are more informative than shorter ones even the subject coverage is the same and also there is the minimum amount of information for a document in order to be relevant against any information needs. Such information amount issues make longer documents more likely to be relevant even under the "Verbosity hypothesis".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Likelihood of Relevance/Retrieved in Diverse Test Collections</head><p>To validate the document length hypotheses, different types of document collections are examined by re-</p><p>applying the analyses against the TREC test collections described by Singhal et al. <ref type="bibr" coords="7,424.92,91.08,31.92,8.77">[20][21]</ref>.</p><p>The MEDLINE document collection(PubMED Abstract 1994-2003: 4,591,008 documents) are put into bins of 5,000 documents in the order of the length of documents counted by the number of indexed terms. We utilized 8268 "topic-relevant document" pairs for 50 topics of the test collection. Possibly relevant (PR) documents are included in these pairs in order to augment the data. From these pairs, p(d in Bin i | d is relevant) for each i-th bin is computed.</p><p>From 50,000 "topic-retrieved document" pairs from retrieval result lists against the test collection, p(d in Bin i | d is retrieved) is computed. Figure <ref type="figure" coords="7,347.00,243.18,5.03,8.77" target="#fig_0">1</ref> shows p(Bin|Relevant) and p(Bin|Retrieved) by BM25TF*IDF and KL-Dir, plotted against the median document length in each bin, in the MEDLINE Collection.</p><p>In Figure <ref type="figure" coords="7,357.52,289.98,3.77,8.77" target="#fig_0">1</ref>, approximation curves of plotted dots by a linear function indicate that the ratio of "KL-Dir retrieved"-"document length" (P(Bin|d is Retrieved by KL-Dir)) is almost overlapped on the ratio of "relevance"-"document length" (P(Bin|Relevant)) while the graph of "BM25TF*IDF retrieved"-"document length" (P(Bin|d is Retrieved by BM25TF*IDF)) is slightly below the graph of P(Bin|Relevant). We have never observed such a situation where KL-dir tends to retrieve longer documents than BM25TF*IDF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Typical Examples of "Scope Hypothesis" and "Verbosity Hypothesis"</head><p>Figure <ref type="figure" coords="7,345.14,437.04,5.03,8.77">2</ref> shows the same analyses against the NTCIR-3 CLIR-J-J (Mainichi newspapers) collection and Figure <ref type="figure" coords="7,316.08,460.44,3.77,8.77" target="#fig_2">3</ref>, Patent test collection <ref type="bibr" coords="7,412.34,460.44,15.47,8.77" target="#b11">[12]</ref>[2] <ref type="bibr" coords="7,439.41,460.44,11.60,8.77" target="#b8">[9]</ref>. Newspaper documents are typically a case of the "scope hypothesis", like TREC collections, where the longer documents necessarily mention more subject topics (see the graph from NTCIR-3 CLIR J-J in Figure <ref type="figure" coords="7,316.08,518.94,3.64,8.77">2</ref>). Patent documents may be seen as a case of the "verbosity hypothesis", where longer documents use more words to describe a specific subject topic. As required by the "Unity of Invention" principle, a patent document is about a single subject so that the document length may not affect relevance or elitness  <ref type="figure" coords="8,270.32,79.38,3.62,8.77" target="#fig_2">3</ref>). The curve of "BM25TF*IDF retrieved"-"document length" (P(Bin|d is Retrieved by BM25TF*IDF)) increases linearly while the curve of KL-Dir is almost flat. In summary, BM25TF*IDF always tends to retrieve longer documents and this may be optimal against newspaper documents while KL-Dir tends to retrieve much shorter documents. KL-Dir seems to be overpenalizing the matching scores of long documents since the approximation curves of P(Bin|d is Retrieved by KL-Dir) is almost flat or even decreasing against document length in Figure <ref type="figure" coords="8,179.64,219.78,3.77,8.77">2</ref>.</p><formula xml:id="formula_8" coords="7,138.66,559.03,216.72,20.47">NTCIR-3 CLIR-J-J NTCIR-4 CLIR-J-J NTCIR-3 Patent NTCIR-</formula><p>In the case of the MEDLINE collection, it seems difficult to say which hypothesis is adequate to assume. Scientific articles tend to concentrate on one specific subject topic irrespective of their length so that they fall into the "Verbosity hypothesis" in view of relevance against a certain subject topic. Some MEDLINE records are extremely short and no abstract is provided, although some of them are assessed as relevant to some topics. Such records are also found in the Mainichi newspaper collection but they are excluded from the NTCIR-3 CLIR-J-J evaluation. Despite such biases, the MEDLINE collection seems to close to the Japanese newspaper collections (see Table <ref type="table" coords="8,70.92,383.59,4.18,8.77" target="#tab_6">5</ref>) rather than the Patent collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Triage Task</head><p>We participated in the triage subtask of the categorization task. Each document in training/test sets is represented as terms weighted by log TF, and we trained a classifier of soft margin linear support vector machines (SVM hereafter) by using SVM_light <ref type="bibr" coords="8,131.76,504.90,15.38,8.77" target="#b9">[10]</ref>. Each document representation is expanded by MeSH terms from the Medline records and Gene expressions identified by a gene name tagger developed and made available by Tanabe et al. <ref type="bibr" coords="8,421.40,79.38,15.38,8.77" target="#b21">[22]</ref>. After examining diverse kind of term weighting such as Log(TF)*IDF, BM25TF*IDF, Log(TF), Boolean, P(t|d), we adopted the normalized Log(TF) weighting. It was not at all clear that the combinations of what feature sets and what weighting methods work well with SVM learning, we were completely groping for optimum utility values by leave-one-out-crossvalidation (LOOCV hereafter, SVM_light options: -x 1 -o 1) against the training set. On top of that, there are some SVM_light parameters to be determined empirically <ref type="bibr" coords="8,423.69,208.09,15.36,8.77" target="#b10">[11]</ref> This approach is contrary to that of Lewis <ref type="bibr" coords="8,500.64,348.49,15.36,8.77" target="#b12">[13]</ref>, who changed and optimized the j parameter and gave default values to the c parameter with normalized vectors, in TREC 2001 filtering. In LOOCV against the training set, the best utility is achieved by C=0.0001505 and J=20 and the result set from this setting is submitted as pllsgen4t1. Other three result sets where the C value is slightly decreased (the threshold is relaxed) and one set where C is increased (threshold is tightened) are submitted. (see   For the feature sets, combining the full text terms, gene entities and MeSH terms is effective but even the combinations of two of them work reasonably well. Anyway, the C parameter tuning is a very time and labor intensive work so that we need some automatic hill-climbing parameter calibration given enough computing power. We shall examine normalized vectors to see if it helps for an easier parameter tuning.</p><p>As our official runs show, the parameters achieving the best utility in LOOCV against the training set are usually over-fitted, the threshold should be relaxed. It is not clear how much it should be relaxed. As each document should be processed separately as the task definition, a delivery ratio basis threshold calibration <ref type="bibr" coords="9,70.92,696.31,11.71,8.77" target="#b2">[3]</ref> is not applicable here.</p><p>For the classifier of pllsgen4t1, which achieved the best utility measure in LOOCV against the training set, the number of support vectors is 4959 against 5837 training examples and the number of misclassified examples amount for 1351. These suggest that the training set with adopted feature sets is not a good example to apply SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>TREC-2004 genomics track evaluation experiments at the Patolis corporation group are described.</p><p>The following observations are drawn from these experiments: For the ad hoc retrieval task, we submitted BM25TF*IDF runs and examined some language modeling runs using KL-divergence with Dirichlet smoothing. KL-Dir runs tend to perform better than BM25TF*IDF runs, which was a rare case in our past experiences. We analyzed the test collection characteristic examining likelihood of relevance/retrieved against different document lengths and find out that the KL-Dir retrieved likelihood overlapped better on the relevance likelihood than that of BM25TF*IDF, which was also the rare case according to our experiences. In future, we will examine more the behavior of two retrieval models against diverse test collections and hopefully induce a better length normalization for language modeling retrieval methods. In the triage subtask, we trained a SVM classifier using LOOCV against the training set. Despite the only one binary classifier to be trained, efforts for parameter calibration are considerable so that we need to consider more automated ways to calibrate parameters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,110.58,661.78,359.50,7.85;5,193.08,672.34,194.46,7.85"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: p(Bin|Relevant) and p(Bin|Retrieved) by BM25TF*IDF and KL-Dir, plotted against the median bin length in the MEDLINE Collection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,108.42,381.10,359.50,7.85;6,174.36,391.66,227.74,7.85"><head>Figure 2 : 3 CLIR</head><label>23</label><figDesc>Figure 2: p(Bin|Relevant) and p(Bin|Retrieved) by BM25TF*IDF and KL-Dir, plotted against the median bin length in the NTCIR-3 CLIR-J-J Collection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,108.42,659.44,359.50,7.85;6,180.54,670.00,215.22,7.85"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: p(Bin|Relevant) and p(Bin|Retrieved) by BM25TF*IDF and KL-Dir, plotted against the median bin length in the NTCIR-3 Patent Collection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,439.04,208.09,3.84,8.77;8,316.08,219.79,225.25,8.77;8,316.08,231.49,225.20,8.77;8,316.08,243.19,225.28,8.77;8,316.08,254.89,225.24,8.77;8,316.08,266.59,40.29,8.77;8,316.08,278.29,225.29,8.77;8,316.08,289.99,225.28,8.77;8,316.08,301.69,225.20,8.77;8,316.08,313.39,225.22,8.77;8,316.08,325.09,225.20,8.77;8,316.08,336.79,40.29,8.77"><head></head><label></label><figDesc>. The parameter j: cost factor, by which training errors on positive examples outweight errors on negative examples, is fixed at 20 since the official utility measure multiplies 20 on the number of true positive examples. The parameter c: trade off between training error and margin, is adjusted empirically by LOOCV on training examples. Because of the fear to over-fitting, this parameter, which works as a threshold is a little bit decreased from the optimum value against training examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,324.42,381.70,233.48,307.06"><head>Table 1 : Performance of official runs and their baseline runs</head><label>1</label><figDesc></figDesc><table coords="3,324.42,381.70,218.93,307.06"><row><cell>Run</cell><cell>Index</cell><cell>RefTerms</cell><cell>Mean</cell><cell>R-Prec.</cell></row><row><cell>description</cell><cell></cell><cell></cell><cell>Avg. Prec.</cell><cell></cell></row><row><cell>TF*IDF</cell><cell>-</cell><cell>Strong</cell><cell>0.3689</cell><cell>0.3932</cell></row><row><cell>(pllsgen4a1)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TF*IDF</cell><cell>Porter</cell><cell>Strong</cell><cell>0.3902</cell><cell>0.429</cell></row><row><cell>TF*IDF</cell><cell>-</cell><cell>Weak</cell><cell>0.3793</cell><cell>0.4018</cell></row><row><cell>TF*IDF</cell><cell>Porter</cell><cell>Weak</cell><cell>0.4075</cell><cell>0.4366</cell></row><row><cell>(pllsgen4a2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>pllsgen4a1</cell><cell cols="2">pllsgen4a2</cell></row><row><cell>K1</cell><cell></cell><cell>0.1</cell><cell>0.4</cell><cell></cell></row><row><cell>B</cell><cell></cell><cell>0.8</cell><cell>0.8</cell><cell></cell></row><row><cell>K4</cell><cell></cell><cell>0.1</cell><cell>0.1</cell><cell></cell></row><row><cell># FB docs</cell><cell></cell><cell>7</cell><cell>7</cell><cell></cell></row><row><cell># FB terms</cell><cell></cell><cell>30</cell><cell>30</cell><cell></cell></row><row><cell cols="3">&lt;TITLE&gt; Coeff. 1.0</cell><cell>1.0</cell><cell></cell></row><row><cell cols="3">&lt;NEED&gt; Coeff. 1.0</cell><cell>0.9</cell><cell></cell></row><row><cell cols="2">&lt;CONTEXT&gt;</cell><cell>0.5</cell><cell>0.5</cell><cell></cell></row><row><cell>Coeff.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MeSH Coeff.</cell><cell></cell><cell>0.04</cell><cell>0.02</cell><cell></cell></row><row><cell>LocusLink</cell><cell></cell><cell>0.04</cell><cell>0.02</cell><cell></cell></row><row><cell>Coeff.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Feedback Coeff. 0.1</cell><cell>0.1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,326.58,698.37,152.48,8.74"><head>Table 2 : Parameters of official runs</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,261.72,521.43,274.94,142.20"><head>Table 3 : Performance comparison in post-submission experiments with long queries</head><label>3</label><figDesc></figDesc><table coords="4,261.72,556.90,270.14,106.73"><row><cell>Run description</cell><cell>Ref</cell><cell cols="3">PFB AvgPrec P@10</cell><cell>ALRD</cell></row><row><cell>TF*IDF+porter</cell><cell>Yes</cell><cell>Yes</cell><cell>0.3476</cell><cell>0.5160</cell><cell>261.7</cell></row><row><cell>(pllsgen4a2)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TF*IDF+porter</cell><cell>Yes</cell><cell>No</cell><cell>0.3165</cell><cell>0.5240</cell><cell>250.4</cell></row><row><cell>TF*IDF+porter</cell><cell>No</cell><cell>Yes</cell><cell>0.3502</cell><cell>0.5140</cell><cell>260.1</cell></row><row><cell>TF*IDF+porter</cell><cell>No</cell><cell>No</cell><cell>0.3090</cell><cell>0.5100</cell><cell>244.0</cell></row><row><cell>KL-Dir+porter</cell><cell>Yes</cell><cell>Yes</cell><cell>0.3239</cell><cell>0.5040</cell><cell>256.5</cell></row><row><cell>KL-Dir+porter</cell><cell>Yes</cell><cell>No</cell><cell>0.3196</cell><cell>0.5080</cell><cell>260.4</cell></row><row><cell>KL-Dir+porter</cell><cell>No</cell><cell>Yes</cell><cell>0.3213</cell><cell>0.5020</cell><cell>256.3</cell></row><row><cell>KL-Dir+porter</cell><cell>No</cell><cell>No</cell><cell>0.3174</cell><cell>0.5060</cell><cell>280.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,263.88,673.35,272.74,20.50"><head>Table 4 : Performance comparison in post-submission experiments with Title only queries</head><label>4</label><figDesc></figDesc><table coords="5,70.92,79.38,227.71,255.79"><row><cell>achieved.</cell></row><row><cell>Using document length priors always harms the</cell></row><row><cell>performance. Giving a large value to µ2(e.g. 100000 i.e.</cell></row><row><cell>making p(d) flat against document length), the</cell></row><row><cell>performance is approaching to the baseline of uniform</cell></row><row><cell>priors but still remains below it.</cell></row><row><cell>The parameter µ2works just like the slope parameter in</cell></row><row><cell>the pivoted normalization. But in this case, no</cell></row><row><cell>document length normalization other than the one</cell></row><row><cell>incorporated in the Dirichlet smoothing was needed.</cell></row><row><cell>Table 4 shows the experiments with the title only</cell></row><row><cell>queries where feedback gains are larger than the long</cell></row><row><cell>query runs. In fact the pseudo feedback contributes to</cell></row><row><cell>maximum 13.3% in a BM25TF*IDF run. On the other</cell></row><row><cell>hands, KL-Dir runs are not so much improved by the</cell></row><row><cell>pseudo feedback, because the mixture model feedback</cell></row><row><cell>is sensitive to the interpolation parameter by which the</cell></row><row><cell>original query model and feedback model are mixtured.</cell></row><row><cell>After readjusting the interpolation parameter, the best</cell></row><row><cell>KL-Dir run achieved 0.3567 of MAP with pseudo</cell></row><row><cell>feedback, which is better than the best BM25TF*IDF</cell></row><row><cell>run.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,78.12,559.03,361.82,146.16"><head>Table 5 : Average document length of relevant</head><label>5</label><figDesc></figDesc><table coords="7,322.44,559.03,110.69,20.47"><row><cell>4</cell><cell>TREC 2004</cell></row><row><cell>Patent</cell><cell>MEDLINE</cell></row></table><note coords="7,278.67,672.93,161.27,8.74;7,78.12,684.69,361.79,8.74;7,78.12,696.45,285.05,8.74;8,70.92,79.38,196.89,8.77"><p>(A)/definitely relevant(DR), partially relevant(AB)/possibly relevant(PR), pooled documents(ABCD/judged) and the whole collection(All docs) counted by the number of indexed terms (see the example from NTCIR-3 Patent in Figure</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,217.20,453.79,306.21,168.25"><head>Table 6 )</head><label>6</label><figDesc></figDesc><table coords="8,217.20,485.08,287.03,136.97"><row><cell>Run Tag</cell><cell>Utility</cell><cell>Official</cell><cell>F-score</cell><cell>#TP</cell><cell>#FP</cell><cell>#FN</cell></row><row><cell>C value</cell><cell>by</cell><cell>utility</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>LOOCV</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>pllsgen4t1</cell><cell>0.5999</cell><cell>0.5302</cell><cell>0.2730</cell><cell>295</cell><cell>1446</cell><cell>125</cell></row><row><cell>0.0001505</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>pllsgen4t2</cell><cell>0.5945</cell><cell>0.5363</cell><cell>0.2645</cell><cell>304</cell><cell>1575</cell><cell>116</cell></row><row><cell>0.00013</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>pllsgen4t3</cell><cell>0.5941</cell><cell>0.5494</cell><cell>0.2496</cell><cell>323</cell><cell>1845</cell><cell>97</cell></row><row><cell>0.0001</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>pllsgen4t4</cell><cell>0.5640</cell><cell>0.5424</cell><cell>0.2186</cell><cell>349</cell><cell>2424</cell><cell>71</cell></row><row><cell>0.00007</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>pllsgen4t5</cell><cell>0.5900</cell><cell>0.5320</cell><cell>0.2785</cell><cell>293</cell><cell>1391</cell><cell>127</cell></row><row><cell>0.00016</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="8,201.18,631.77,186.18,8.74"><head>Table 6 : Performance of triage official runs</head><label>6</label><figDesc></figDesc><table coords="9,75.78,109.30,434.84,278.09"><row><cell>Feature set</cell><cell>Weighting</cell><cell>J</cell><cell>C</cell><cell>Best Utility</cell><cell>Utility against</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>by</cell><cell>Test set</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>LOOCV</cell><cell></cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>Log(TF)/Log(AvgTF)</cell><cell>20</cell><cell>0.0001505</cell><cell>0.5999</cell><cell>0.5305</cell></row><row><cell>MeSH terms (=pllsgen4t1)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms, MeSH terms</cell><cell>Log(TF)/Log(AvgTF)</cell><cell>20</cell><cell>0.0001552</cell><cell>0.5996</cell><cell>0.5305</cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>Log(TF)</cell><cell>20</cell><cell>0.0000175</cell><cell>0.5992</cell><cell>0.5415</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms</cell><cell>Log(TF)/Log(AvgTF)</cell><cell>20</cell><cell>0.00012</cell><cell>0.5805</cell><cell>0.5250</cell></row><row><cell>Gene Entities, MeSH terms</cell><cell>Log(TF)/Log(AvgTF)</cell><cell>20</cell><cell>0.000041</cell><cell>0.5736</cell><cell>0.5067</cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>Log(TF)/Log(AvgTF)</cell><cell>20</cell><cell>0.0000000002</cell><cell>0.5556</cell><cell>0.5037</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell>6</cell><cell></cell><cell></cell></row><row><cell>Polynomial Kernel (d=3)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>Log(TF)*IDF/Norm</cell><cell>20</cell><cell>0.0453</cell><cell>0.5535</cell><cell>0.4862</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>Log(TF)*IDF</cell><cell>20</cell><cell>0.00000107</cell><cell>0.5512</cell><cell>0.4856</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>TF</cell><cell>20</cell><cell>0.0000005</cell><cell>0.5496</cell><cell>0.5130</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>P(t|d)</cell><cell>20</cell><cell>6</cell><cell>0.5417</cell><cell>0.5205</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gene Entities, MeSH terms</cell><cell>Bool</cell><cell>20</cell><cell>0.000083</cell><cell>0.5336</cell><cell>0.4551</cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>BM25TF*IDF</cell><cell>20</cell><cell>0.000003</cell><cell>0.5305</cell><cell>0.4685</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full text terms, Gene Entities,</cell><cell>Bool</cell><cell>20</cell><cell>0.00008</cell><cell>0.5305</cell><cell>0.4711</cell></row><row><cell>MeSH terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="9,70.92,408.81,449.46,109.07"><head>Table 7 : Performance by the decreasing order of the utility value in LOOCV against the training set</head><label>7</label><figDesc>According to the LOOCV against the training set shown in Table7, the following observations are drawn in view of weighting methods.-In summary, IDF weighting does not help while any kinds of TF weighting helps.-Log(TF) is better than raw TF while average normalized Log(TF) is almost same as the simple Log(TF).</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,88.90,235.80,207.24,8.77;10,88.92,247.50,207.18,8.77;10,88.92,259.23,207.14,8.74;10,88.92,270.90,207.23,8.77;10,88.92,282.60,55.07,8.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,248.23,235.80,47.91,8.77;10,88.92,247.50,128.83,8.77">Information retrieval as statistical translation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,235.32,247.53,60.78,8.74;10,88.92,259.23,207.14,8.74;10,88.92,270.93,159.45,8.74">Proceedings of the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.90,300.30,195.24,8.77;10,88.92,312.00,203.82,8.77;10,88.92,323.70,199.71,8.77;10,88.92,335.40,198.73,8.77;10,88.92,347.13,195.83,8.74;10,88.92,358.80,26.03,8.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,166.16,323.70,122.47,8.77;10,88.92,335.40,97.03,8.77">Overview of CLIR Task at the Third NTCIR Workshop</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kishida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kuriyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kanodo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">H</forename><surname>Myaeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,204.30,335.43,83.35,8.74;10,88.92,347.13,191.29,8.74">Working notes of the third NTCIR workshop meeting Part I Overview</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="23" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.90,376.50,194.60,8.77;10,88.92,388.20,205.99,8.77;10,88.92,399.90,176.92,8.77;10,88.92,411.60,196.62,8.77;10,88.92,423.30,192.59,8.77;10,88.92,435.03,178.54,8.74;10,88.92,446.70,184.43,8.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,239.05,399.90,26.79,8.77;10,88.92,411.60,196.62,8.77;10,88.92,423.30,151.61,8.77">Topic-Specific Optimization and Structuring-A report on CLARIT TREC-2001 Experiments</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sheftel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,260.88,423.33,20.63,8.74;10,88.92,435.03,178.54,8.74;10,88.92,446.73,87.15,8.74">NIST Special Publication 500-250:The Tenth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2001">2002. 2001</date>
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.89,464.40,207.27,8.77;10,88.92,476.10,207.24,8.77;10,88.92,487.83,207.22,8.74;10,88.92,499.53,207.18,8.74;10,88.92,511.20,89.63,8.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,154.91,464.40,141.25,8.77;10,88.92,476.10,188.09,8.77">Notes on Phrasal Indexing-JSCB Evaluation Experiments at NTCIR AD HOC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,88.92,487.83,207.22,8.74;10,88.92,499.53,207.18,8.74;10,88.92,511.23,46.75,8.74">Proceedings of the First NTCIR Workshop on Research in Japanese Text Retrieval and Term Recognition</title>
		<meeting>the First NTCIR Workshop on Research in Japanese Text Retrieval and Term Recognition</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.89,522.90,207.29,8.77;10,88.92,534.60,207.22,8.77;10,88.92,546.33,207.22,8.74;10,88.92,558.00,167.63,8.77" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
		<title level="m" coord="10,165.71,522.90,130.47,8.77;10,88.92,534.60,207.22,8.77;10,88.92,546.33,207.22,8.74;10,88.92,558.03,87.27,8.74">Reflections on &quot;Aboutness&quot;-TREC-9 Evaluaton Experiments at Justsystem. In NIST Special Publication 500-249: the Ninth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="281" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.89,569.70,143.49,8.77;10,88.92,581.40,206.74,8.77;10,88.92,593.10,194.41,8.77;10,88.92,604.83,198.60,8.74;10,88.92,616.50,64.55,8.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,153.14,569.70,79.24,8.77;10,88.92,581.40,206.74,8.77;10,88.92,593.10,53.23,8.77">More reflections on &quot;Aboutness&quot;-TREC-2001 Evaluaton Experiments at Justsystem</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,160.38,593.13,122.95,8.74;10,88.92,604.83,168.25,8.74">NIST Special Publication 500-250:The Tenth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="331" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.93,634.20,195.42,8.77;10,88.92,645.90,164.48,8.77;10,88.92,657.60,189.37,8.77;10,88.92,669.30,172.43,8.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,153.11,634.20,131.25,8.77;10,88.92,645.90,164.48,8.77;10,88.92,657.60,88.96,8.77">Revisiting the Document Length Hypotheses --NTCIR-4 CLIR and Patent Experiments at Patolis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,194.94,657.63,83.35,8.74;10,88.92,669.33,129.51,8.74">Working notes of the fourth NTCIR workshop meeting</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="238" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,88.89,687.00,199.14,8.77;10,88.92,698.70,185.24,8.77;10,334.08,79.41,190.30,8.74;10,334.08,91.08,189.05,8.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,229.74,687.00,58.29,8.77;10,88.92,698.70,170.59,8.77">Twenty-one at TREC-7: Ad-hoc and cross-language track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,334.08,79.41,190.30,8.74;10,334.08,91.11,106.85,8.74">NIST Special Publication 500-242:The Seventh Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="227" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.05,108.78,209.71,8.77;10,334.08,120.48,174.25,8.77;10,334.08,132.18,190.69,8.77;10,334.08,143.88,171.47,8.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,359.19,120.48,149.15,8.77;10,334.08,132.18,35.84,8.77">Overview of Patent Retrieval Task at NTCIR-3</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Takano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,388.50,132.21,136.27,8.74;10,334.08,143.91,138.37,8.74">Working notes of the third NTCIR workshop meeting Part I Overview</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="67" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.05,161.58,197.78,8.77;10,334.08,173.28,197.73,8.77;10,334.08,184.98,200.98,8.77;10,334.08,196.68,134.68,8.77" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,389.96,161.58,141.88,8.77;10,334.08,173.28,197.73,8.77;10,334.08,184.98,64.34,8.77">Advances in Kernel Methods -Support Vector Learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<editor>B. Schölkopf and C. Burges and A. Smola</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT-Press</publisher>
		</imprint>
	</monogr>
	<note>Making large-Scale SVM Learning Practical</note>
</biblStruct>

<biblStruct coords="10,334.06,214.38,182.77,8.77;10,334.08,226.08,194.35,8.77;10,334.08,237.78,22.67,8.77" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,387.46,214.38,129.37,8.77;10,334.08,226.08,101.05,8.77">Learning to Classify Text Using Support Vector Machines</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Dissertation</note>
</biblStruct>

<biblStruct coords="10,334.04,255.48,192.16,8.77;10,334.08,267.18,194.23,8.77;10,334.08,278.88,166.43,8.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,403.33,255.48,122.87,8.77;10,334.08,267.18,39.56,8.77">Overview of the Third NTCIR Workshop</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,392.04,267.21,136.27,8.74;10,334.08,278.91,138.37,8.74">Working notes of the third NTCIR workshop meeting Part I Overview</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.04,296.58,181.51,8.77;10,334.08,308.28,195.69,8.77;10,334.08,319.98,197.17,8.77;10,334.08,331.71,198.60,8.74;10,334.08,343.38,64.55,8.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,413.39,296.58,102.16,8.77;10,334.08,308.28,195.69,8.77;10,334.08,319.98,56.51,8.77">Applying Support Vector Machines to the TREC-2001 Batch Filtering and Routing Tasks</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,408.30,320.01,122.95,8.74;10,334.08,331.71,168.25,8.74">NIST Special Publication 500-250:The Tenth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="286" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.08,361.08,202.08,8.77;10,334.08,372.78,209.76,8.77;10,334.08,384.48,160.13,8.77;10,334.08,396.21,182.06,8.74;10,334.08,407.88,190.12,8.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,528.91,361.08,7.26,8.77;10,334.08,372.78,205.44,8.77">A hidden Markov model information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,345.00,384.51,149.21,8.74;10,334.08,396.21,182.06,8.74;10,334.08,407.91,85.78,8.74">Proceedings of the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.03,425.58,204.43,8.77;10,334.08,437.28,191.39,8.77;10,334.08,449.01,189.22,8.74;10,334.08,460.71,92.34,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,461.28,425.58,77.18,8.77;10,334.08,437.28,72.01,8.77">Experiments Using the Lemur Toolkit</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,423.48,437.31,101.99,8.74;10,334.08,449.01,189.22,8.74">NIST Special Publication 500-250: The Tenth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2001">2002. 2001</date>
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.05,478.38,177.68,8.77;10,334.08,490.08,186.71,8.77;10,334.08,501.81,197.93,8.74;10,334.08,513.51,183.87,8.74;10,334.08,525.18,170.38,8.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,465.63,478.38,46.10,8.77;10,334.08,490.08,172.23,8.77">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,334.08,501.81,197.93,8.74;10,334.08,513.51,183.87,8.74;10,334.08,525.21,35.26,8.74">Proceedings of the 1998 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1998 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.05,542.88,204.17,8.77;10,334.08,554.58,200.36,8.77;10,334.08,566.28,159.23,8.77;10,334.08,578.01,197.93,8.74;10,334.08,589.71,183.87,8.74;10,334.08,601.38,144.26,8.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,484.58,542.88,53.64,8.77;10,334.08,554.58,200.36,8.77;10,334.08,566.28,144.43,8.77">Some Simple Effective Approximations to the 2-Poisson Model for Probabilistic Weighted Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,334.08,578.01,197.93,8.74;10,334.08,589.71,183.87,8.74;10,334.08,601.41,35.26,8.74">Proceedings of the 1994 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1994 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,336.58,619.08,204.70,8.77;10,334.08,630.78,207.19,8.77;10,334.08,642.48,207.19,8.77;10,334.08,654.18,207.21,8.77;10,334.08,665.88,200.60,8.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,505.44,630.78,35.83,8.77;10,334.08,642.48,31.33,8.77">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,396.48,642.51,144.79,8.74;10,334.08,654.21,131.50,8.74">Proceedings of the Third Text REtrieval Conference(TREC-3)</title>
		<meeting>the Third Text REtrieval Conference(TREC-3)<address><addrLine>Washington D.C</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,334.03,677.58,169.90,8.77;10,334.08,689.28,190.99,8.77;10,334.08,700.98,184.48,8.77;11,88.92,79.38,159.51,8.77;11,88.92,91.08,128.48,8.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,413.01,677.58,90.92,8.77;10,334.08,689.28,82.04,8.77">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,433.09,689.28,91.98,8.77;10,334.08,700.98,184.48,8.77;11,88.92,79.38,41.83,8.77">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,88.88,108.78,184.13,8.77;11,88.92,120.48,171.85,8.77;11,88.92,132.21,197.93,8.74;11,88.92,143.91,183.87,8.74;11,88.92,155.58,154.19,8.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,88.92,120.48,156.81,8.77">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,88.92,132.21,197.93,8.74;11,88.92,143.91,183.87,8.74;11,88.92,155.61,35.26,8.74">Proceedings of the 1996 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 1996 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,88.87,173.28,201.92,8.77;11,88.92,184.98,171.68,8.77;11,88.92,196.68,195.40,8.77;11,88.92,208.38,76.12,8.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,114.05,184.98,131.34,8.77">Document Length Normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,88.92,196.71,157.72,8.74">Information Processing &amp; Management</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="619" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,334.05,79.38,202.33,8.77;11,334.08,91.08,169.59,8.77;11,334.08,102.78,169.01,8.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,479.11,79.38,57.28,8.77;11,334.08,91.08,154.53,8.77">Tagging Gene and Protein Names in Biomedical Text</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tanabe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,334.08,102.81,57.96,8.74">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1124" to="1132" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,334.05,120.48,166.66,8.77;11,334.08,132.18,205.56,8.77;11,334.08,143.88,203.40,8.77;11,334.08,155.61,190.24,8.74;11,334.08,167.28,176.95,8.77;11,334.08,178.98,90.80,8.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,458.28,120.48,42.42,8.77;11,334.08,132.18,205.56,8.77;11,334.08,143.88,111.24,8.77">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,462.24,143.91,75.24,8.74;11,334.08,155.61,190.24,8.74;11,334.08,167.31,151.53,8.74">Proceedings of the 2001 ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 2001 ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,334.04,196.68,176.65,8.77;11,334.08,208.38,201.44,8.77;11,334.08,220.11,204.85,8.74;11,334.08,231.81,125.87,8.74;11,334.08,243.48,201.92,8.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,458.25,196.68,52.44,8.77;11,334.08,208.38,185.98,8.77">Model-based feedback in the KL-divergence retrieval model</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,334.08,220.11,204.85,8.74;11,334.08,231.81,125.87,8.74;11,334.08,243.51,104.88,8.74">Proceedings of the Tenth International Conference on Information and Knowledge Management(CIKM 2001)</title>
		<meeting>the Tenth International Conference on Information and Knowledge Management(CIKM 2001)<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
