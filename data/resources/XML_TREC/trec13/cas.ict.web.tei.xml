<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.98,88.63,297.35,12.19">TREC 2004 Web Track Experiments at CAS-ICT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,130.50,113.97,56.63,8.74"><forename type="first">Zhaotao</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School</orgName>
								<orgName type="institution">Chinese Academy of Science</orgName>
								<address>
									<postCode>100039)</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,200.29,113.97,36.56,8.74"><forename type="first">Yan</forename><surname>Guo</surname></persName>
							<email>guoy@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.17,113.97,41.00,8.74"><forename type="first">Bin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.47,113.97,53.23,8.74"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.05,113.97,47.23,8.74"><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.60,113.97,49.96,8.74"><forename type="first">Gang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.98,88.63,297.35,12.19">TREC 2004 Web Track Experiments at CAS-ICT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">10277D11BDEAA48B13BA02751EBBF5E1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Web retrieval</term>
					<term>TREC 2004</term>
					<term>the Mixed query task</term>
					<term>information fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report presents CAS-ICT's experiments on the Mixed query task of the TREC2004 Web track. Our work focused on combining different Web page evidences together to improve the overall retrieval performance. Four kinds of evidences, including body content(C), anchor texts (AT), basic structural information (S0) and extended structural information (S1) were considered for retrieval.</p><p>Six combination functions were investigated in our experiments. The experimental results show that most functions can improve the retrieval performance. Some heuristic re-ranking techniques were also introduced and tested in the task. No query classification was made during the experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This year we only participated in the Mixed query task of the Web track. From 2001 to 2003, different Web tasks, including homepage finding, topic distillation, named page finding, and known item finding, have been defined for the Web track. Each of them is a separate task with different type of topics. This year, all these tasks are combined together with only one set of mixed topics. "Mixed" here means topics for the above different tasks are blent together without knowing which one belongs to which task.</p><p>A natural idea is to classify the topics into different types and then to use different model or method for each type. Such kind of work on query classification has been done in <ref type="bibr" coords="1,420.22,500.37,10.66,8.74" target="#b5">[6]</ref>. We also implemented this idea in our work. However, the results are not as good as we expected. And this experiment is not included in this report. Our experiments mainly focused on Web evidences combination and re-ranking techniques.</p><p>As we know, a Web page has much more useful information than a plain text. For instance, besides the body text, the title, Meta data, some tags, anchor texts and links in a Web page can provide rich information to improve the performance of Web retrieval. All these information are called Web evidences. This year, we focused on combining different Web evidences together to improve the overall performance.</p><p>Another work in our experiments is to re-rank the retrieval results according to some heuristic methods.</p><p>Our work was still based on our enhanced version of SMART<ref type="foot" coords="1,376.50,672.79,3.24,5.65" target="#foot_0">1</ref> , which we developed for the previous Web tracks. Lnu-Ltu weighting scheme and pivoted document length normalization (PDLN) technique were used. However, the parameters of PDLN for different Web evidences were set to different values.</p><p>The queries from TREC 2003's home/name page task and topic distillation task were combined together to a mixed query set (called MIXED03) for parameters estimation and training.</p><p>The rest of the report is organized as follows: Section 2 describes the concepts and formulas used in our experiments. Section 3 introduces our experiments and the results in detail. Finally, we give our conclusions in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Concepts and formulas</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Web evidences and their combination</head><p>As we pointed out before, Web pages have more information than plain texts. Besides body content texts, they have some other potentially useful information that can be used for Web retrieval.</p><p>Such information include URL, title, anchor texts, tags, Meta data and structural information such as links. All these information are called Web evidences. In our experiments, a "pseudo-text" was constructed for each page. It consists of not only some information of current page, but also all the anchor texts that link to the current page and all the titles of the pages that the current page links to.</p><p>The in-link information are called backward propagation information while the out-link information called forward propagation information. We guessed such a "pseudo-text" could provide richer information for Web retrieval. And our later experiments confirmed this thought.</p><p>A combination process of different evidences is as follows: given a query, for each page, first a score is computed according to each evidence, and then based on these scores, a combination score is computed as the unique final score. A combination function is the most important in the combination process.</p><p>Formally, a combination score of page p and query q is defined as:</p><formula xml:id="formula_0" coords="2,236.70,443.29,249.28,27.59">1 ( , ) ( ( , )) n i i CS p q com s e q = = (1)</formula><p>Where ei is the ith evidence of total n evidences of page p, s(ei,q) is the score based on ei and q, com is a function that combines the n scores. Some com functions are defined in table <ref type="table" coords="2,436.34,492.39,3.76,8.74" target="#tab_0">1</ref>. Fox&amp; Shaw <ref type="bibr" coords="2,164.48,628.17,11.67,8.74" target="#b1">[2]</ref> have worked on the above methods for combining multiple retrieval runs and obtained improvements over any single retrieval run. Lee [7] analyzed why improvements can be achieved with evidence combination and showed that different runs retrieve similar sets of relevant documents while retrieve different sets of nonrelevant documents. Lee found that in his evaluation CombMNZ got the best retrieval performance. In our submitted run ICT04MNZ3, we used the CombMNZ to combine 3 retrieval results from anchor text, structure info and content. In our system and training set, CombSum performed better than CombMNZ, at the same time CombANZ and CombMIN had worse performance.</p><p>In addition, a linear combination method (LM) is also introduced in our work, which is actually a weighted summation of all individual evidences. The formula is:</p><p>( , ) * ( , )</p><formula xml:id="formula_1" coords="3,235.80,102.87,255.28,31.47">i i i CS p q w s e q = ∑<label>(2)</label></formula><p>Where w i is the weight for evidence e i . Each w i can be learned from training set.</p><p>Table <ref type="table" coords="3,136.36,157.77,5.01,8.74" target="#tab_1">2</ref> defines the evidences that were used in our experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Similarity computation for each evidence</head><p>Given a query q, for each evidence e i , a cosine similarity is computed as the score between q and e i , where both q and e i are represented as weighted term vectors in traditional Vector Space Mode (VSM).</p><p>( , ) cos( , )</p><formula xml:id="formula_2" coords="3,249.24,383.02,97.81,23.21">i i i i</formula><p>e q s e q e q e q</p><formula xml:id="formula_3" coords="3,270.24,367.62,217.84,47.11">• = = r r r r r r<label>(3)</label></formula><p>Where "•" means the inner product of two vectors. In our experiments, the Lnu-Ltu weighting scheme with pivoted normalization technique is used. Concretely, the Lnu weight of a term in a document is defined as</p><formula xml:id="formula_4" coords="3,192.60,477.03,157.36,39.65">1 log( ) 1 log( ) (1.0 - ) #</formula><p>tf average tf slope pivot slope of unique terms</p><formula xml:id="formula_5" coords="3,249.00,473.21,240.22,47.47">+ + × + ×<label>(4)</label></formula><p>Where slope and pivot are two parameters for pivoted normalization, which can also be learned through training. tf is the term frequency in the document. # of unique terms is the number of different terms that occur in the document.</p><p>Pivoted normalization can be used to modify any normalization function thereby reducing the gap between the relevance and the retrieval probabilities <ref type="bibr" coords="3,320.12,597.69,10.61,8.74" target="#b0">[1]</ref>. Its effectiveness was confirmed in our previous results <ref type="bibr" coords="3,153.30,613.29,10.98,8.74" target="#b4">[5]</ref>. In our baseline run ICT04basic, the parameters' value is set as: pivot=196.661 for both text and query, slope=0.04 for content and slope=0.85 for query. Other runs using different parameters for different Web evidence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Re-ranking strategies</head><p>To re-rank the first retrieval results may improve the final performance. Kiduk Yang's PPT <ref type="foot" coords="4,502.08,107.83,3.24,5.65" target="#foot_1">2</ref>proposed a re-ranking strategy that to "keep top 5 static, boost potential homepages and file type page which contains at least 2 query terms".</p><p>Some heuristic strategies based on URL depth, URL words, anchor text and site compression were investigated in our experiments. The strategies are as follows:</p><p>For those results that have same similarities, first sort them according to their URL depth, and then tune their orders according to the following formula. If the page is a PDF file then improve its rank, and on the other side if its URL contains words such as "news", then decrease its rank. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∑</head><p>Where n i is the number of query terms that occur in field i, w i the corresponding weight. In our experiments, the weights for URL, title and anchor texts are respectively set as 0.5, 0.25 and 0.25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training</head><p>The queries from TREC 2003's home/name page task and topic distillation task were combined together to a mixed query set (called MIXED03) for training. .Gov is used as the Web collection.</p><p>Different combination functions were investigated and the parameters were learned through the training experiments. The training results are listed in Table <ref type="table" coords="4,332.84,399.75,3.76,8.74" target="#tab_4">4</ref>. Where C, AT,S0 and S1 are defined in Table <ref type="table" coords="4,309.70,666.15,3.74,8.74" target="#tab_1">2</ref>. Rel_Rt is the number of the queries whose relevant pages are in the return list (1000 pages returned per query)among the total queries. It can be regarded as some kind of recall measure.</p><p>Several observations can be found from Table4:</p><p>The result using S1 (M03_S1) outperforms the result using S0(M03_S0). It may mean that S1 provide more useful information that S0 does.</p><p>Among all individual evidences, the AP result using AT(M03_AT) outperforms the results using any other individual evidence. However, the Rel_RT of M03_AT is not very high.</p><p>This may mean the AT evidence can be used to improve the precision while losing some recall rate. On the contrary, the result using body content texts (M03_C) has the highest Rel_RT, while its AP is very low.</p><p>Except CombMin, any result with other combination function outperforms any individual result in the sense of either AP or Rel_RT. And the linear combination function is the top-performance function in our training.</p><p>After training, some parameters can be learned to get best performances. And then the results and the above observations were applied in this year's task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Official Runs</head><p>In this part we give the description and the results of the 5 official runs submitted, which are listed in Table5. Here both CII and C mean that the runs use the body content text as the evidence for retrieval.</p><p>The difference between them is that different slope and pivot parameters are used (see Table <ref type="table" coords="5,463.50,564.51,3.63,8.74" target="#tab_2">3</ref>).</p><p>ICT04basic is the basic run for all our submitted runs, it can be regarded as the baseline run.</p><p>ICT04basic achieves the Average Precision 0.39, the average S@10 0.7469, and Rel_RT 219 among 225. There are 6 queries missed the relevant documents in the 1000 submitted documents and these 6 queries are all known-item queries.</p><p>The parameters for slope and pivot used for content retrieval in ICT04basic and CT04CIILC are different, but their performance show that different content retrieval results have little effect on merging results. The results of ICT04basic, ICT04CIILC and ICT04CIIS1AT show that richer structure information such as S1 can provide better retrieval results in the mixed query task.</p><p>We used some heuristic strategies (see Section 2.3) to re-rank the retrieval results and intend to improve the retrieval performance. But the comparison of ICT04RULE and ICT04CIIS1AT shows the strategies don't work. But it doesn't mean that re-ranking methods are useless for the mixed query. We believe better re-ranking algorithms should be found.</p><p>ICT04MNZ3 is the run using CombMNZ combination method. It also improves the performance as it did in the training experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>Mixed query task is an interesting task for the Web track. Its queries are those that real search engines face. Our experiments show that richer structure information and a good combination method (such as CombMNZ) can provide better Web retrieval performance. Further work may include query classification or developing more precise re-ranking strategies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,145.56,509.19,239.00,109.66"><head>Table 1 : Some Combination functions</head><label>1</label><figDesc></figDesc><table coords="2,145.56,526.35,239.00,92.50"><row><cell>Name</cell><cell>Meaning</cell></row><row><cell>CombMIN</cell><cell>Minimum of individual similarities</cell></row><row><cell cols="2">CombMAX Maximum of individual similarities</cell></row><row><cell>CombSUM</cell><cell>Summation of individual similarities</cell></row><row><cell>CombANZ</cell><cell>CombSUM/number of nonzero similarities</cell></row><row><cell>CombMNZ</cell><cell>CombSUM* number of nonzero similarities</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,143.88,174.57,288.35,93.82"><head>Table 2 Some evidences' name and their meaning</head><label>2</label><figDesc></figDesc><table coords="3,143.88,192.51,288.35,75.88"><row><cell>Name</cell><cell>Meaning</cell></row><row><cell>CII or C</cell><cell>Body content text of current page</cell></row><row><cell>AT</cell><cell>Anchor texts link-in (backward propagation information)</cell></row><row><cell>S0</cell><cell>Information including title and h1 tag information</cell></row><row><cell>S1</cell><cell>pseudo-text defined in Section 2.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,134.46,667.89,317.56,69.85"><head>Table 3 Parameters for different evidences (Refer to Table 2)</head><label>3</label><figDesc></figDesc><table coords="3,134.46,693.81,317.56,43.93"><row><cell>Evidence's Name</cell><cell>C</cell><cell>CII</cell><cell>AT</cell><cell>S0</cell><cell>S1</cell></row><row><cell>Pivot</cell><cell>196.661</cell><cell>196.661</cell><cell>196.661</cell><cell>192</cell><cell>196.661</cell></row><row><cell>Slope</cell><cell>0.04</cell><cell>0.18</cell><cell>0.04</cell><cell>0.49</cell><cell>0.19</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,90.00,433.17,381.26,206.98"><head>Table 4 Training results</head><label>4</label><figDesc></figDesc><table coords="4,90.00,451.11,381.26,189.04"><row><cell>Run</cell><cell>Average</cell><cell>Rel_Rt/Total</cell><cell>Description</cell></row><row><cell></cell><cell>Precision(AP)</cell><cell>query number</cell><cell></cell></row><row><cell>M03_C</cell><cell>0.2656</cell><cell>321/350</cell><cell>Only using body content texts</cell></row><row><cell>M03_S0</cell><cell>0.2288</cell><cell>280/350</cell><cell>Only using some basic structure</cell></row><row><cell></cell><cell></cell><cell></cell><cell>information such as h1, title</cell></row><row><cell>M03_S1</cell><cell>0.2995</cell><cell>320/350</cell><cell>Using more structure information</cell></row><row><cell></cell><cell></cell><cell></cell><cell>mentioned in Section 2.1</cell></row><row><cell>M03_AT</cell><cell>0.4131</cell><cell>304/350</cell><cell>Using anchor texts</cell></row><row><cell>M03_CombSum</cell><cell>0.4869</cell><cell>341/350</cell><cell>CombSum of C, S0, AT</cell></row><row><cell>M03_CombMNZ</cell><cell>0.4415</cell><cell>342/350</cell><cell>CombMNZ of C, S0, AT</cell></row><row><cell>M03_CombMin</cell><cell>0.1659</cell><cell>309/350</cell><cell>CombMin of C, S0, AT</cell></row><row><cell>M03_LM</cell><cell>0.5082</cell><cell>339/350</cell><cell>Linear combination of C, S0, AT</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,90.00,333.57,414.78,189.40"><head>Table 5 Official runs</head><label>5</label><figDesc></figDesc><table coords="5,90.00,351.51,414.78,171.46"><row><cell>Run</cell><cell>Average</cell><cell>Average</cell><cell>Rel_Rt</cell><cell>Description</cell></row><row><cell></cell><cell>Precision</cell><cell>S@10</cell><cell></cell><cell></cell></row><row><cell>ICT04basic</cell><cell>0.3976</cell><cell>0.7467</cell><cell>219/225</cell><cell>Retrieval using a linear merging of C,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>S0 and AT introduced in 3.2</cell></row><row><cell>ICT04CIILC</cell><cell>0.3958</cell><cell>0.7600</cell><cell>210/225</cell><cell>CII instead of C in ICT04basic, others</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>the same as ICT04basic</cell></row><row><cell>ICT04CIIS1AT</cell><cell>0.4250</cell><cell>0.8044</cell><cell>223/225</cell><cell>Linear merging of CII, S1, AT, the same</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>as ICT04CIILC except S1 instead of S0</cell></row><row><cell>ICT04RULE</cell><cell>0.4219</cell><cell>0.8044</cell><cell>211/225</cell><cell>Re-rank the result of ICT04CIIS1AT</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>using our re-rank algorithm</cell></row><row><cell>ICT04MNZ3</cell><cell>0.4279</cell><cell>0.7689</cell><cell>223/225</cell><cell>CombMNZ of CII, S1, AT</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,95.28,761.86,118.53,7.85"><p>ftp://ftp.cs.cornell.edu/pub/smart</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,95.28,761.86,288.93,7.85"><p>http://elvis.slis.indiana.edu/docs/widit_trec2003_files/frame.htm#slide0006.htm</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,108.24,238.47,397.11,8.74;6,90.00,253.35,192.61,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,252.00,238.47,165.29,8.74">Pivoted Document Length Normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mitra</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/singhal96pivoted.html" />
	</analytic>
	<monogr>
		<title level="m" coord="6,424.85,238.47,49.93,8.74">ACM SIGIR</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,107.52,269.67,397.85,8.74;6,90.00,284.55,417.87,8.74;6,90.00,300.15,258.20,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,199.31,269.67,138.98,8.74">Combination of Multiple Searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/fox94combination.htm" />
	</analytic>
	<monogr>
		<title level="m" coord="6,346.19,269.67,159.19,8.74;6,90.00,284.55,46.13,8.74">Proceedings of the 2nd Text REtrieval Conference</title>
		<meeting>the 2nd Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special</orgName>
		</respStmt>
	</monogr>
	<note>Publication 500-215</note>
</biblStruct>

<biblStruct coords="6,110.04,316.47,395.27,8.74;6,90.00,331.35,398.07,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,174.08,316.47,187.25,8.74">Analyses of Multiple Evidence Combination</title>
		<author>
			<persName coords=""><forename type="first">Joon</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,370.98,316.47,134.33,8.74;6,90.00,331.35,369.32,8.74">Proceedings of the 20th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 20th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,108.06,347.67,397.38,8.74;6,90.00,362.55,80.53,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,308.40,347.67,191.73,8.74">TREC12 Web and Interactive Tracks at CSIRO</title>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trystan</forename><surname>Upstill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,90.00,362.55,54.33,8.74">TREC Report</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,108.54,378.87,396.69,8.74;6,90.00,393.75,351.98,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,132.15,393.75,218.74,8.74">TREC-11 Experiments at CAS-ICT: Filtering and Web</title>
		<author>
			<persName coords=""><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhifeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuo</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,358.81,393.75,53.77,8.74">TREC Report</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.92,410.07,351.74,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,185.54,410.07,223.64,8.74">Query Type Classification for Web Document Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ho</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kim</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
