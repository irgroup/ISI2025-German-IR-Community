<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.33,164.85,312.59,15.11">Expanding Queries using Stems and Symbols</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,200.68,197.33,84.04,10.48;1,288.63,195.72,1.41,6.99"><forename type="first">Michela</forename><surname>Bacchin</surname></persName>
							<email>michela.bacchin@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.65,197.33,87.92,10.48"><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.33,164.85,312.59,15.11">Expanding Queries using Stems and Symbols</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F2E3FDA9C74E727342571D5DC4CF1A59</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the experiments conducted in the ad-hoc retrieval task of the Genomic track at TREC 2004. Different query expansion techniques based on the addition of keyword stems and of genomic product symbols selected by relevance feedback were studied. Stemming was tested using a mutual reinforcement process for building a domain-specific stemmer. Relevance feedback was tested using a technique exploiting associations between symbols and related keywords.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Information Management Systems (IMS) research group of the Department of Information Engineering of the University of Padova participated in the adhoc retrieval task of the Genomic track. The aim of this first participation in the Genomic track was to explore this new domain-specific context using different query expansion techniques. On the one hand, a probabilistic stemming algorithm was used to expand queries by adding morphologically related words; on the other, a relevance feedback technique was designed to expand queries by selecting symbols added to queries together with their semantically related keywords and symbols -symbols are strings which describe genomic or proteic products.</p><p>In general, the employment of stemming is based on the basic idea that words which are similar in morphology are also similar in meaning. Hence the use of stemming algorithm allows to expand the query words with all their variants. Past experiments showed that, firstly, stemming could not improve retrieval performance because of the morphology of the documents language, and, secondly, that stemming is as more effective as the morphology of the language is more complex. In the context of documents about genomics, the dictionary, i.e. the set of keywords extracted from the documents, includes several words which are not present in a generic English dictionary, because they are composed by two or more domain-specific morphemes. Hence the number of variants seems to be greater than in a generic English collection, making the specific language morphology more complex. The hypothesis that the use of stemming in the Genomic track test collection could be more valuable than in a generic English collection has been investigated.</p><p>Symbols are strings of alphabetical, numerical and special characters naming genomic,proteic or biologic products. The language used in the test documents is characterized by the occurrence of several symbols. Symbols precisely and succintly describe document content without using keywords. Despite their precision, symbols can be affected by ambiguity -a genomic product might be identified by more than one symbol -thus making the problem of recall more difficult. It is well known in the IR literature that query expansion is an effective means to improve recall without decreasing precision in contexts where synonymy prevents the retrieval of relevant documents. At TREC our interest was in the investigation as to whether a relevance feedback-driven query expansion technique based on symbol detection can be effective.</p><p>Several experiments were conducted before and also after the release of the official runs. Hence it was decided to report in this paper all the significant experiments conducted even if only two runs was submitted for official TREC evaluation. The paper is organized as follows: In the next section, some issues of stemming in the context of genomic information retrieval are illustrated. In Section 3 the probabilistic model for stemmer generation is surveyed, whereas in Section 4 a relevance feedback technique based on the extraction and processing of symbols is presented. Section 5 describes the experimental setting and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Stemming in a Specific Domain Context</head><p>In the last years our research group proposed and developed a probabilistic model for stemmer generation <ref type="bibr" coords="2,266.73,469.65,9.97,8.74" target="#b3">[4]</ref>. The proposed stemming algorithm infers the word formation rules directly from the words of the corpus of documents and uses no prior linguistic knowledge on the language. Several experiments were carried out to evaluate if this probabilistic approach could be applied for building stemming algorithms for different languages and if the probabilistic stemming algorithm could be as effective as the ones manually built by linguistic experts.</p><p>The results observed were quite successfully with all the tested European languages, such as Italian, Spanish, French, German and English <ref type="bibr" coords="2,409.93,553.34,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,424.12,553.34,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="2,435.53,553.34,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="2,446.94,553.34,7.01,8.74" target="#b5">6]</ref>. For all the test languages the retrieval performances of the probabilistic stemming algorithm were similar to the ones obtained by linguistic stemming algorithms manually built. It was observed that for languages with a complex morphology, such as the Italian language, stemming could be useful for improving the retrieval performance of systems, especially if a researcher is interested in evaluating the precision after a few retrieved documents.</p><p>In TREC 2004 the interest was concentrated in evaluating if stemming could be valuable for improving retrieval performance in the context of documents and queries about Genomics. In this paper, it has been made the hypothesis that the morphology of this domain-specific language could be more complex than the one of the English common language. The dictionary of the MEDLINE collection is different from the one extracted from a collection which uses a common English language, such as the Wall Street Journal articles. There are many word compounds and words composed by two or more domain-specific morphemes. This fact could make the morphology of the MEDLINE language more complex than the common English morphology which is on the contrary quite simple and gives out a few variants for each word. The presence in the document collection of many variants decreases the probability of retrieving all the relevant documents because in every relevant document could be present a different variant which represents the same concept relevant to the one expressed in the query.</p><p>The complexity of the language of the Genomics track test collection would make the implementation of a stemmer difficult and subject to errors, and its effectiveness is not guaranteed even if it is built after an intellectual labor conducted by experts of the domain. Moreover, the language of the domain might evolve rapidly and the stemmer should be kept up-to-date. The research reported in this paper investigated whether an automatic and languageindependent procedure to generate a stemmer for this domain could be a useful and effective exercise. In the next section, the design of such a procedure is illustrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Probabilistic Model for Stemmer Generation</head><p>The probabilistic model proposed in <ref type="bibr" coords="3,298.21,439.76,10.52,8.74" target="#b3">[4]</ref> computes a list of pairs (word, stem) starting from the set of words extracted from a corpus of documents. It is based on a suffix stripping paradigm in which each word is split into a pair of substrings, called prefix and suffix, and considers the prefix as the stem. The model considers that words are the outcome of a generative process performed by a hypothetical machine that takes the set of all the possible prefixes and suffixes as input and produces words as output according to some type of linguistic knowledge and not at random. Because of this, the probability of generating a pair is not uniform -since the machine exploits some kind of linguistic knowledge, the probability that a stem is correctly concatenated with a derivation is higher than the probability that a generic prefix is concatenated with a generic suffix. Stemming can be seen as the inverse of this generative process: given a word, a stemmer has to guess the prefix and the suffix in order to form the most probable pair that the machine has chosen to generate the word. As the machine pools together its knowledge of the language, the most probable pair is formed by the stem and the derivation of the word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Algorithm</head><p>Given a finite collection W of words, let U be the set of N sub-strings generated after splitting each word z ∈ W into all possible positions, except for those which generates empty sub-strings. If x, y are the prefix and the suffix of word z, respectively, then z = xy and there are n -1 possible positions to which z is split, if |z| = n. Let us define the universe of the elementary random events as follows. Let Ω = {(x, y) ∈ U × U : ∃z ∈ W, z = xy} be the set of all pairs (prefix, suffix) which can form any word and let Ω(z) = {(x, y) ∈ Ω : xy = z} be the set of all of the pairs (prefix, suffix) leading to the same word z.</p><p>The stemmer has to infer the most probable pair of prefixes and suffixes (x, y) * = ω * chosen by the machine to generate the given word, computing the expression:</p><formula xml:id="formula_0" coords="4,230.53,285.75,246.95,17.12">ω * = arg max ω∈Ω(z) Pr(ω | z)<label>(1)</label></formula><p>= arg max</p><formula xml:id="formula_1" coords="4,285.01,308.91,192.47,22.31">ω∈Ω(z) Pr(z | ω) Pr(ω) Pr(z)<label>(2)</label></formula><p>= arg max</p><formula xml:id="formula_2" coords="4,285.01,336.73,192.48,15.05">ω∈Ω(z) Pr(ω)<label>(3)</label></formula><p>= arg max i=1,...,n-1</p><formula xml:id="formula_3" coords="4,326.53,357.82,150.95,9.65">Pr(x i , y i )<label>(4)</label></formula><p>where ( <ref type="formula" coords="4,167.32,384.88,4.24,8.74" target="#formula_1">2</ref>) is obtained applying the Bayes' rule, ( <ref type="formula" coords="4,349.77,384.88,4.24,8.74" target="#formula_2">3</ref>) is obtained observing that Pr(z | ω) = 1, since ω ∈ Ω(z) yields to z only, and Pr(z) is the same for all ω and so it does not influence the maximization, and ( <ref type="formula" coords="4,379.24,408.79,4.24,8.74" target="#formula_3">4</ref>) is obtained because Ω(z) = ∪ n-1 i=1 {ω i } and ω i = (x i , y i ). Finally, the relationship which views that probability as the combination of one marginal probability and one conditional probability was exploited to compute P r(x i , y i ), and hence:</p><formula xml:id="formula_4" coords="4,239.70,476.46,131.84,17.12">ω * = arg max ω∈Ω(z) Pr(x) Pr(y | x)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Mutual Reinforcement in Stemming</head><p>To estimate the probability distribution of the pairs (prefix, suffix) Pr(x i , y i ) which is necessary to find the most probable pair, the following notion of probabilistic mutual reinforcement in stemming was introduced:</p><p>Stems are prefixes which have a high probability of being completed by derivations; derivations, in turn, are suffixes which have a high probability of completing stems.</p><p>If a collection of words is observed, a prefix is completed by diverse suffixes, and a suffix completes diverse prefixes. The mutual reinforcement relationship emphasizes that stems are more likely to be completed by derivations; derivations in turn are more likely to complete stems.</p><p>Let us formalize the notion of mutual reinforcement in stemming just introduced. It is a fact that:</p><formula xml:id="formula_5" coords="5,133.77,156.37,236.80,109.00">Pr(x i ) = N j=1 Pr(x i , y j ) Pr(y j ) = N i=1 Pr(x i , y j ) and Pr(x i , y j ) = Pr(y j | x i ) Pr(x i ) Pr(x i , y j ) = Pr(x i | y j ) Pr(y j )</formula><p>Thus the mutual reinforcement relationship between the stems and the derivations can be written as:</p><formula xml:id="formula_6" coords="5,215.82,303.54,261.66,59.66">Pr(xi) = N j=1 Pr(xi | yj) Pr(yj) i = 1, . . . , N Pr(yj) = N i=1 Pr(yj | xi) Pr(xi) j = 1, . . . , N<label>(5)</label></formula><p>Using a more compact notation,</p><formula xml:id="formula_7" coords="5,254.03,386.68,100.41,9.68">p = [Pr(x 1 ) • • • Pr(x N )]</formula><p>as the vector of the prefix probabilities, and and then p is the eigenvector of C = (BA) associated to unity eigenvalue, and s is the eigenvector of D = (AB) associated to unity eigenvalue. Hence, the probability Pr(x i ) can estimated by the component of the eigenvector p associated with the prefix x i , and the probability Pr(y i ) by the component of the eigenvector s associated with the suffix y i . To compute the eigenvectors an iterative algorithm can be applied; the details of our iterative algorithm can be found in <ref type="bibr" coords="5,173.34,665.94,9.97,8.74" target="#b3">[4]</ref>.</p><p>The symbols, i.e. strings of alphabetical, numerical and special characters used to name genomic or proteic products, could be useful to make retrieval results more precise. Actually, symbols encapsulate much information about what the end user aims at searching since these strings are often acronyms or nicknames of longer descriptions of the products about which the documents are relevant or not.</p><p>Despite their potential usefulness in improving retrieval performance, symbols are also ambiguous since a genomic or proteic product can be labelled using more than one symbol in different research papers of the database. As a consequence, a query can label a product using a symbol which mismatches the ones used in relevant documents.</p><p>As it is well known in the IR literature, query expansion helps to address the problem of word ambiguity. Therefore query expansion could be applied to symbols as it was done for keywords. However, it is necessary to add semantics to symbols so that they can be employed in a query expansion technique. If semantics is added to symbols, these can be associated one to each other and these associations can be exploited to expand a query including symbols.</p><p>To add semantics to a symbol, it could be possible to exploit the information given by ontologies or similar databases. However, ontologies or similar databases often cover a small portion of a document collection. Alternatively, it could be possible to exploit the information encoded into the documents content and compute the similarities among all the symbols in the collection. However, such an approach poses significant problems since a vector-based representation of the symbols and a similarity function should be defined.</p><p>In order to search for a source of evidence which adds semantics to symbols, the following hypothesis was drawn: Symbols occur in the document texts closely to keywords which give a semantics to the symbols. This closeness can occur if, for instance, a symbol is introduced just before or after the words giving its definition or function. Another hypothesis was drawn: Symbols occur closely to keywords to which related symbols occur as well. The latter is the association between symbols being searched. The algorithm to discover the associations among symbols has been based on the notion of mutual reinforcement which has been used to design the stemming algorithm presented and tested in this paper. The notion of mutual reinforcement for query expansion can be stated as follows:</p><p>A symbol used to expand the query co-occurs frequently with and closely to keywords used to expand the query, and a keyword used to expand the query co-occurs frequently with and closely to the symbols used to expand the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Symbol Recognition</head><p>To recognize symbols, the following regular expressions were defined:</p><formula xml:id="formula_8" coords="7,133.77,129.29,221.25,29.39">[A-Z][A-Z0-9]*[-/][a-zA-Z0-9]+ [a-zA-Z][A-Z0-9]*'('[a-zA-Z0-9]+')'[a-zA-Z0-9]* [a-zA-Z][A-Z0-9][a-zA-Z0-9]+</formula><p>These expressions defined a symbol as a string containing uppercase letters, digits or some special characters. Some normalization was done to make special characters little influential. The characters -()/ were removed from the strings matching one of the first two regular expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Blind Relevance Feedback Algorithm</head><p>Given a collection of documents D and a full-text query q, a list of documents was retrieved and the m top-ranked ones were selected to start up the query expansion algorithm. Let M be set of these selected documents. The assumption of implicit relevance feedback was made, i.e. the list of document contains many relevant items and the synonyms occur in the retrieved relevant items. From M the algorithm extracted all the tokens labelling symbols or keywords -the distinction between symbols and keywords was made using the regular expressions above introduced.</p><p>Query expansion can be computed choosing to expand the query only with tokens labelled as symbols, or with those labelled as keywords. Once the token type had been chosen, the k top-ranked tokens were extracted from M . The tokens extracted from the top-ranked documents were ranked by a TF•IDF measure, in which TF represents the token frequency in M , while IDF represents the inverse document frequency computed considering all the documents in the collection D. This way, query q was expanded by adding the tokens which were the most specific ones for the top-ranked documents M .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Exploitation of the Mutual Reinforcement</head><p>The algorithm explained above used the TF•IDF measure to select the k topranked tokens to be added to the query. In order to investigate if the notion of mutual reinforcement could be valuable also in the query expansion context, the algorithm was modified to compute also a different token ranking based on the mutual reinforcement relationship between symbols and keywords. The algorithm built a graph whose nodes were symbols and the keywords occurring closely to those symbols. If a symbol occurred within a 10-word text window, then all the window words were extracted and associated to that symbol as co-occurring words. Hence an edge was added from the symbols and the nodes which represented the keywords associated. Then an algorithm exploiting the mutual reinforcement relationship between symbols (hubs) and keywords (authorities) was performed to associate a weight to each symbol and keyword. These weights represented a measure of the degree to which each token (symbol or keyword) is associated to the symbols of the list of top-ranked documents. A symbol (keyword) with the highest score is the "best" one. The hypothesis was that two synonymous symbols tend to be associated to the same keywords, and that the synonyms being found can be effectively used to improve the performance if the keywords come out of relevant documents. The query is then expanded using the top-ranked symbols or keywords. Distinct experiments were carried out both using the best symbols and the best keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setting</head><p>System. To carry out the experiments for the ad-hoc task of the genomic track, a PC equipped with RedHat Linux, a 800 MHz Intel Pentium CPU and 512MB RAM was used. The MySQL AB relational database systems was employed for storing, indexing and searching documents, and a suite of tools were developed in Java and C++ for pre-and post-processing. MySQL is one of the most popular open source database server. It has full-text indexing and searching capabilities, based on a space-vector model <ref type="bibr" coords="8,368.17,289.88,9.97,8.74" target="#b7">[8]</ref>.</p><p>Indexing. Before storing the documents into the document table in MySQL a conversion was necessary. Because of the limit of 4GB for each table in MySQL, all the sections of a generic document could not be stored, and (PMI, TI, AB), i.e., Document-Id, Title and Abstract were only stored. The original 9GB document collection was reduced to a 3GB MySQL document table. All the 599 stop-words have been removed before storing the documents. The MySQL full-text capabilities were exploited to build an index consisting of both Title and Abstract fields.</p><p>Searching. To retrieve the relevant documents a database application was developed to establish a connection to the MySQL database, send the queries and produce a list of relevant documents in a format compatible with trec eval <ref type="bibr" coords="8,464.20,448.38,9.97,8.74" target="#b4">[5]</ref>. The queries have been built using the MySQL full-text extension to standard SQL:</p><p>SELECT pmid, match(TI,AB) AGAINST(Query Text ) AS score FROM To build the query string Query Text, all the words except stop-words appearing in Title and Need sections of the topics provided by NIST were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>Several runs were performed to test, on the one hand, the effectiveness of query expansion by stemming and, on the other hand, the effectiveness of query expansion algorithm presented in Section 4. Each run was characterized by the use of a different algorithm and the run labels and a brief description are reported in Table <ref type="table" coords="8,172.79,665.94,3.88,8.74" target="#tab_1">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Labels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PDnoStem</head><p>No stemming nor query expansion PDTDmp4</p><p>Stemming using the probabilistic algorithm PDporter Stemming using Porter's algorithm for English PDnmXkY fF rZyW Query expansion using m </p><formula xml:id="formula_9" coords="9,236.67,177.97,165.45,20.97">= X, k = Y , f = F , r = Z, y = W</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Results about Stemming</head><p>Since MySQL does not use any stemming algorithm, stemming was a pre-process and a different document table was stored into the database for each different stemming algorithm applied to the original documents. As reported in Table <ref type="table" coords="9,469.73,371.17,3.88,8.74" target="#tab_2">2</ref>, the size of the table which store the original documents was obviously much greater than the size of the stemmed tables. In particular, the table which stored the documents stemmed by the probabilistic stemmer is about 75% of the original one thus confirming that stemming could be useful to decrease the topics, so three set of 50 queries were created -one set for each stemming algorithm applied. Once the topics and the documents were stemmed by the same stemming algorithm, the searches were carried out using the database application described in the previous Section.</p><p>Building the stemming algorithm. Starting from the complete MEDLINE collection, a set of 706,523 words with frequency greater than one were selected out of the 1,200,090 unique words extracted from the collection. The probabilistic stemmer generation was performed from this restricted, yet large set of words thus obtaining a list of pairs (word, stem).</p><p>By default, MySQL does not index words which have a length minor than four, hence the stemming algorithm was modified in order to stem only words whose length was at least five -a rule such that the stem length has to be at least four was added. Moreover, several words which should not have been stemmed because they were already roots were observed in the past experiments. At TREC-13 the stemming algorithm was modified in a way that algorithm does not split the words which have a high probability of being root forms -the complete words is treated as a stem. As result, 113,212, out of 706,523 words has been not stemmed because 89,394 presented a word length minor than five, and 23,818 were already stems with high probability.</p><p>Results. Table <ref type="table" coords="10,211.68,261.45,4.98,8.74" target="#tab_3">3</ref> reports the traditional effectiveness measures: the number of relevant documents which had been retrieved (Rel-Retr), Average Precision (A-P), R-Precision (R-P) and the Precision computed at 5 (P@5) and 10 (P@10) document cut off values. The PDTNmp4 run was one of the two submitted official runs. The results seem confirming the intuition that stemming could be useful in this domain-specific context, even if the improvement is little for A-P and R-P. Yet the precision computed at the 5-document cut off value shows a greater improvement for the runs which stemming was applied in. It is remarkable that PDporter reports the largest improvement of recall, whereas PDTNmp4 is comparable in terms of precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Results about Relevance Feedback using Symbols</head><p>The experiments were designed in a way that it could be possible to isolate each single algorithm feature, which could influence the performances of the query expansion algorithm proposed in this paper. First of all, a set of runs were carried out with different quantities of top-ranked documents used as the source from which relevance information is extractedm is the number of top ranked documents from which the token to be added to the query are extracted -and with different quantities of top-ranked tokens added to the initial query k is the maximum number of tokens to be added to the query. It should be recalled that the extracted tokens are ranked by TF•IDF (see Section 4.2).</p><p>For each value of m,k two runs were performed: one run was performed by adding symbols to queries, one run was performed by adding keywords. In this first set of runs, the mutual reinforcement among symbols and keywords was not used. A run was also done using the query expansion feature of the embedded full-text engine of MySQL with the aim of comparing our algorithm, which distinguishes symbols from keywords, to another blind relevance feedback-based query expansion algorithm which does not distinguish symbols from keywords.</p><p>To implement implicit relevant feedback, it was decided to use only the top 2 and 5 top-ranked document, i.e. m = 2 and m = 5 was used, and to extract the top k = 5 and k = 20 tokens from M . Quite surprisingly, a constant decrease of all the effectiveness figures was observed. In effect, the precision computed at five documents showed a decrease of the baseline performance. The most probable reason is that the baseline could not provide enough relevant documents within the top m. Also the MySQL query expansion run labelled with PDmysqlqe did not obtain an effectiveness improvement.</p><p>An exception was the run labelled with PDnm5k20f2 which reported an increase of the total number of retrieved relevant documents and of the precision at five documents retrieved.</p><p>To test if this average decrease could be imputable to the lack of enough relevant documents among the top m retrieved, a set of runs was performed to test explicit relevant feedback. The top ranked m relevant documents retrieved among the top j retrieved documents were identified. The symbols and the keywords were extracted from this subset of documents to be added to the initial query. a known set of relevant documents seem to perform better than the same runs based on blind relevance feedback. In particular, the improvement of the precision at five documents is statistically significant with a p-value &lt; 0.002 for the Wilcoxon test and for all the runs. Hence, it seems that the explicit knowledge of some relevant documents is a necessary condition to significantly improve the performance of the relevance feedback technique based on the distinction between symbols and keywords.</p><p>In order to test if the mutual reinforcement could be useful to improve the ranking of the top-ranked tokens used to expand the query, a third set of runs was performed. These runs were labelled using r = R as the number of iterations performed by the algorithm implementing the mutual reinforcement between symbols and keywords. As reported in However, j = 1000 is a rather unrealistic assumption in real operational settings and the improvement reported by the runs based on such a high value should be considered carefully. On the contrary, it is worth noting that an appreciable improvement can be observed if j = 25 and mutual reinforcement is performed using r = 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>Our interest has been in the investigation of different query expansion algorithms. First stemming was studied to test if it could be useful in this domainspecific context, and the results were quite positive because all the runs which employ the stemming process obtained performances which were superior to the baseline.</p><p>Then a set of relevance feedback techniques were tested on the basis of the idea that symbols could be crucial for this domain specific context. The results have been rather inconclusive -the query expansion algorithm seems to really improve the performances of the systems only if the start up document set consisted of relevant documents and keywords are the tokens used to expand the query. If the query expansion algorithm were based on blind relevance feedback or symbols are used instead, performance decreases. This might be due to the fact that in the first k documents there are several not relevant documents or symbols do not sufficiently discriminate relevant documents from non-relevant documents.</p><p>However, there are some positive signals which suggest to continue the study of the symbols role in this domain-specific context. An analysis is planned to compare the symbols statistical distribution among relevant and non-relevant documents. Other activities are also planned to improve and adapt the probabilistic stemmer model to this domain -it may be hypothesised that if the model could better infer the word formation rules specific for this context, it could improve the performances of the retrieval system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,255.76,425.91,96.94,9.68;5,133.77,445.52,342.62,9.68;5,133.77,457.48,343.71,9.68;5,133.77,469.46,145.11,9.65;5,287.81,489.05,35.63,8.77;5,133.77,508.69,16.06,8.74;5,288.07,520.62,35.11,8.77;5,133.77,537.20,80.95,8.74;5,281.42,549.12,48.42,8.77;5,133.77,565.71,16.06,8.74;5,283.26,577.63,44.73,8.77"><head>s</head><label></label><figDesc>= [Pr(y 1 ) • • • Pr(y N )] as the vector of the suffix probabilities. Moreover, let A = [a sr ] be the N × N matrix such that a sr = Pr(x r | y s ), and let B = [b rs ] be the N × N matrix such that b rs = Pr(y s | x r ). Therefore, p = A s and s = B p After substituting, p = A B p and s = B A s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,158.68,513.39,202.65,18.43"><head></head><label></label><figDesc>Table name WHERE match(TI,AB) AGAINST(Query Text ) LIMIT 1000</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,139.75,189.93,338.69,117.08"><head>Table 1 :</head><label>1</label><figDesc>Run labels and descriptions.</figDesc><table coords="9,333.81,189.93,86.23,8.74"><row><cell>as parameter values</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,133.77,430.94,343.71,112.92"><head>Table 2 :</head><label>2</label><figDesc>table and index sizes. The same stemming pre-process was also performed for Size of tables in the database.</figDesc><table coords="9,218.29,453.09,174.68,59.23"><row><cell cols="3">Stemming Size in MB Unique terms</cell></row><row><cell>algorithm</cell><cell></cell><cell></cell></row><row><cell>PDnoStem</cell><cell>3,330</cell><cell>706,523</cell></row><row><cell>PDTNmp4</cell><cell>2,527</cell><cell>324,234</cell></row><row><cell>PDporter</cell><cell>2,824</cell><cell>577,553</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,176.23,331.93,258.80,76.83"><head>Table 3 :</head><label>3</label><figDesc>Some effectiveness measures for the experiments done.</figDesc><table coords="10,177.70,331.93,255.84,45.28"><row><cell>RunID</cell><cell>Rel-Retr</cell><cell>A-P</cell><cell>R-P</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell cols="2">PDnoStem 2985</cell><cell cols="4">0.2015 0.2384 0.4880 0.4300</cell></row><row><cell>PDTNmp4</cell><cell>3102</cell><cell cols="4">0.2074 0.2476 0.5120 0.4560</cell></row><row><cell cols="2">PDporter 3248</cell><cell cols="4">0.2024 0.2457 0.5160 0.4320</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,148.71,211.65,302.54,134.91"><head>Table 4 :</head><label>4</label><figDesc>Table 4 reports the usual effectiveness figures for the first set of runs. Effectiveness measures for the query expansions.</figDesc><table coords="11,173.47,233.86,264.32,81.15"><row><cell>RunID</cell><cell>Rel-Retr</cell><cell>A-P</cell><cell>R-P</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell>PDnoStem</cell><cell>2985</cell><cell cols="4">0.2015 0.2384 0.4880 0.4300</cell></row><row><cell>PDnm2k5f1</cell><cell>3014</cell><cell cols="4">0.1967 0.2331 0.4480 0.4000</cell></row><row><cell>PDnm2k5f2</cell><cell>3002</cell><cell cols="4">0.1902 0.2304 0.4600 0.4060</cell></row><row><cell cols="2">PDnm5k20f1 2968</cell><cell cols="4">0.1904 0.2224 0.4600 0.4100</cell></row><row><cell cols="2">PDnm5k20f2 3035</cell><cell cols="4">0.1918 0.2263 0.5040 0.4400</cell></row><row><cell>PDmysqlqe</cell><cell>2745</cell><cell cols="4">0.2086 0.2397 0.4840 0.4300</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,159.85,528.46,317.63,122.95"><head>Table 5 :</head><label>5</label><figDesc>Table 5 reports the figures for the second set of runs. The runs based on Effectiveness measures for explicit relevance feedback.</figDesc><table coords="11,159.85,550.67,291.55,69.19"><row><cell>RunID</cell><cell>Rel-Retr</cell><cell>A-P</cell><cell>R-P</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell>PDnoStem</cell><cell>2985</cell><cell cols="4">0.2015 0.2384 0.4880 0.4300</cell></row><row><cell>PDnm5k20f1j25</cell><cell>2992</cell><cell cols="4">0.2014 0.2277 0.5440 0.4500</cell></row><row><cell>PDnm5k20f2j25</cell><cell>3028</cell><cell cols="4">0.2082 0.2295 0.5640 0.4640</cell></row><row><cell cols="2">PDnm5k100f1j1000 3003</cell><cell cols="4">0.2104 0.2417 0.6000 0.4920</cell></row><row><cell cols="2">PDnm5k100f2j1000 3038</cell><cell cols="4">0.2130 0.2405 0.6520 0.5220</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,133.77,247.51,343.72,170.03"><head>Table 6 :</head><label>6</label><figDesc>Table 6 the mutual reinforcement in this context is not clearly useful since precision does not improve consistently. Yet the total number of retrieved relevant documents increases as reported by PDnm5k100f1j1000r10y10 and PDnm5k20f1j25r10y10 which are two runs that employ symbols. Effectiveness measures for explicit relevance feedback and mutual reinforcement.</figDesc><table coords="12,144.16,317.99,322.93,57.24"><row><cell>RunID</cell><cell>Rel-Retr</cell><cell>A-P</cell><cell>R-P</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell>PDnoStem</cell><cell>2985</cell><cell cols="4">0.2015 0.2384 0.4880 0.4300</cell></row><row><cell cols="2">PDnm5k100f2j1000r10y10 2986</cell><cell cols="4">0.2015 0.2384 0.4880 0.4300</cell></row><row><cell cols="2">PDnm5k100f1j1000r10y10 3134</cell><cell cols="4">0.2125 0.2388 0.5680 0.4720</cell></row><row><cell>PDnm5k20f1j25r10y10</cell><cell>3120</cell><cell cols="4">0.2063 0.2316 0.5160 0.4400</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,154.24,289.86,323.23,8.74;13,154.25,301.81,323.24,8.74;13,154.25,313.77,323.23,8.74;13,154.25,325.72,323.24,8.74;13,154.25,337.68,323.23,8.74;13,154.25,349.63,298.67,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,368.18,289.86,109.29,8.74;13,154.25,301.81,125.27,8.74">Improving the Automatic Retrieval of Text Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agosti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bacchin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,217.73,313.77,259.75,8.74;13,154.25,325.72,286.57,8.74">Advances in Cross-Language Information Retrieval, Third Workshop of the Cross-Language Evaluation Forum, CLEF 2002</title>
		<title level="s" coord="13,417.75,337.68,59.73,8.74;13,154.25,349.63,127.75,8.74">Lecture Notes in Computer Science (LNCS)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Rome, Italy; Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">September 19-20, 2002. 2003</date>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="279" to="290" />
		</imprint>
	</monogr>
	<note>Revised Papers</note>
</biblStruct>

<biblStruct coords="13,154.24,368.48,323.24,8.74;13,154.25,380.43,323.24,8.74;13,154.25,392.39,323.24,8.74;13,154.25,404.34,323.23,8.74;13,154.25,416.30,323.23,8.74;13,154.25,428.26,323.24,8.74;13,154.25,440.21,67.90,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,324.85,368.48,152.63,8.74;13,154.25,380.43,103.74,8.74">The Effectiveness of a Graph-based Algorithm for Stemming</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bacchin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,332.32,392.39,145.17,8.74;13,154.25,404.34,323.23,8.74;13,154.25,416.30,139.35,8.74">Digital Libraries: People, Knowledge, and Technology. Proceedings of 5th International Conference on Asian Digital Libraries (ICADL 2002)</title>
		<title level="s" coord="13,179.14,428.26,158.10,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Lim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Foo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">S G</forename><surname>Khoo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Urs</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Thanos</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">December 11-14. 2002</date>
			<biblScope unit="volume">2555</biblScope>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.24,459.06,323.24,8.74;13,154.25,471.01,320.77,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="13,209.40,459.06,200.77,8.74">A Language-Independent Stemming Algorithm</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bacchin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Padua, Italy</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Information Engineering, University of</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="13,154.24,489.86,323.23,8.74;13,154.25,501.81,323.23,8.74;13,154.25,513.77,84.08,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,338.61,489.86,138.86,8.74;13,154.25,501.81,65.52,8.74">A Probabilistic Model for Stemmer Generation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bacchin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,227.50,501.81,166.24,8.74">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="137" />
			<date type="published" when="2005">2005</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.24,532.61,323.24,9.02;13,154.25,544.57,260.16,9.02" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="13,239.85,532.61,156.50,9.02">The trec eval Evaluation Package</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<ptr target="ftp://ftp.cs.cornell.edu/pub/smart/" />
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
	<note>Visited on October</note>
</biblStruct>

<biblStruct coords="13,154.24,563.41,323.23,8.74;13,154.25,575.37,323.24,8.74;13,154.25,587.32,323.24,8.74;13,154.25,599.28,323.23,8.74;13,154.25,611.23,323.23,8.74;13,154.25,623.19,323.23,8.74;13,154.25,635.14,243.33,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,383.44,563.41,94.03,8.74;13,154.25,575.37,323.24,8.74;13,154.25,587.32,75.58,8.74">Experiments to Evaluate Probabilistic Models for Automatic Stemmer Generation and Query Word Translation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Di Nunzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Orio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,181.41,599.28,296.07,8.74;13,154.25,611.23,323.23,8.74;13,154.25,623.19,19.04,8.74">Evaluation of Cross-Language Information Retrieval Systems, Fourth Workshop of the Cross-Language Evaluation Forum, CLEF 2003. Trondheim</title>
		<title level="s" coord="13,307.36,623.19,170.12,8.74;13,154.25,635.14,58.14,8.74">Revised Papers. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Norway; Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">August 21-22, 2003. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,154.24,653.99,323.25,8.74;13,154.25,665.94,214.62,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,211.46,653.99,112.76,8.74">How Effective is Suffixing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,335.46,653.99,142.03,8.74;13,154.25,665.94,102.06,8.74">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.24,127.96,323.23,9.02;14,154.25,139.92,49.02,8.74" xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Ab</forename><forename type="middle">Mysql</forename><surname>Mysql</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Homepage</surname></persName>
		</author>
		<ptr target="http://www.mysql.com" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,154.24,159.84,323.24,8.74;14,154.25,171.80,323.23,8.74;14,154.25,183.75,156.07,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,214.55,159.84,147.36,8.74">An Algorithm for Suffix Stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sparck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Willet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,372.78,171.80,104.70,8.74;14,154.25,183.75,37.33,8.74">Readings in Information Retrieval</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1980">1980. 1997</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
	<note>Reprinted in</note>
</biblStruct>

<biblStruct coords="14,154.25,203.68,323.22,9.02;14,154.25,215.63,234.14,9.02" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="14,154.25,203.68,184.55,8.74">The English Stoplist of the SMART System</title>
		<ptr target="ftp://ftp.cs.cornell.edu/pub/smart/english.stop" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Visited on October</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
