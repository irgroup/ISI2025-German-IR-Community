<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.52,94.61,364.69,12.62;1,247.07,110.55,151.61,12.62">DalTREC 2004: Question Answering using Regular Expression Rewriting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,229.92,158.06,75.06,10.52"><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,337.29,158.06,78.53,10.52"><forename type="first">Anthony</forename><surname>Cox</surname></persName>
							<email>amcox@cs.dal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.52,94.61,364.69,12.62;1,247.07,110.55,151.61,12.62">DalTREC 2004: Question Answering using Regular Expression Rewriting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4A9EF4F897B8164261BAC45CF2D2E733</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is the first year that the Dalhousie University participated in TREC. We submitted three runs for the QA track. Our evaluation results are generally below the median (with one exception) but seem to be significantly higher than the worst scores, which is within our expectations considering a limited time spent on developing the system. Our approach was based on the regular expression rewriting and the use of external search engines (MultiText and PRISE). One run used Web-reinforced search.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>2004 is the first year that the Dalhousie University participated in TREC. The project DalTREC<ref type="foot" coords="1,151.21,447.13,4.23,6.99" target="#foot_0">1</ref> was initiated in 2003 and serves as an umbrella for TREC-related activities at the Dalhousie university. The topics of interest were Question Answering, HARD, Genomics, and Web. We submitted the runs for the Question Answering (QA) track.</p><p>In our previous work, we explored the application of several approaches to question answering in the overlapping area of unification-based and stochastic NLP (Natural Language Processing) techniques <ref type="bibr" coords="1,216.22,516.83,65.52,9.57" target="#b3">(Kešelj, 2002;</ref><ref type="bibr" coords="1,286.46,516.83,99.38,9.57" target="#b0">Cercone et al., 2002)</ref>. Two novel methods that were explored relied on the notions of modularity and just-in-time sub-grammar extraction.</p><p>One of the learned lessons of the previous experiments was that the regular expression (RegEx) substitutions are a very succinct, efficient, maintainable, and scalable method to model many NL subtasks of the QA task. This was also observed in the context of lexical source-code transformations of arbitrary programming languages <ref type="bibr" coords="1,420.94,584.58,84.28,9.57" target="#b1">(Cox et al., 2004)</ref>, where it is an alternative to manipulations of the abstract syntax tree. In this context, RegEx transformations are more robust in the face of missing header files, errors, usage of macros, templates, and other embedded programming language constructs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Regular Expression Rewriting</head><p>The basic method used at various components of the QA system is RegEx rewriting. The open angle bracket (&lt;) is used as a special escape character, hence we make sure that it does not appear in the source text, which is either a question or a passage. The basic text substrings, such as the target or named entities, are recognized using regular expressions and replaced with an angle-bracket-delimited expression. For example, the target is marked as &lt;TARGET&gt;. More commonly, a named entity e of type t is replaced with &lt;t_e s &gt;, where e s is the named entity e encoded as a string of printable characters that do not include &lt;. The RegEx rewriting can be seen as a bottom-up deterministic parsing technique. For example, the rewriting in which "&lt;NP_x&gt; &lt;VP_y&gt;" is replaced with "&lt;S_z&gt;" corresponds to the contextfree rule S → NP VP. The value z is obtained by decoding x and y, concatenating them, and encoding the result again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Architecture</head><p>An overview of the system architecture is shown in figure <ref type="figure" coords="2,377.63,545.36,5.45,9.57">1</ref> and it is described in more detail in the remaining of this section.</p><p>Question processing component takes the original TREC questions as the input and produces an annotated list of questions. The process includes question parsing, generating complete questions, detecting question category, and producing some additional auxiliary information. The original TREC 2004 questions are grouped by targets. A set of questions around a target may include just a anaphoric reference to the target and not the full target name (e.g., 'it', 'he'). In order to be able to independently use each question in passage extraction, they are rewritten so that they include the target name. We call this form a "complete question" or "full question". Additionally, as the result of parsing the questions, we obtain question category (i.e., the expected answer type), and some other optional information, such as type of the relation between the target and the answer. Question parsing and generating full questions is based on regular expression rewriting rules.</p><p>Generating the full question was done in the following way: We start with the original question. If target appears in the question, it is not changed. For a question of type "other," we generate the question "What is &lt;Target&gt; ?". Otherwise, we attempt the following substitutions: If none of them succeeds, we prepend "&lt;Target&gt;, " to the original question.</p><formula xml:id="formula_0" coords="3,103.18,162.37,315.00,22.64">elsif ($Qtype eq 'OTHER') { $_ = " What is &lt;Target&gt; " } elsif (/ it</formula><p>Passage Retrieval. The passage retrieval from the AQUAINT data set is performed by an external search engine using the full questions generated in the question processing phase. We used the passages retrieved by the MultiText search engine (University of Waterloo), and the documents provided by NIST (produced by the PRISE search engine). In both cases, the MultiText and PRISE, the results are treated in the same way-as passages relevant to the question.</p><p>Target Marking. Using RegEx rewriting rules, the target is identified in the passages and replaced with the &lt;TARGET&gt; tag.</p><p>Question Category (Qcat) Marking. All entities having the identified question category (Qcat) type are marked using RegEx rewriting.</p><p>Answer Matching is based on RegEx matching. For example, the following patternprocessing snippet while (/&lt;${Qcat}_([^&gt;]*)&gt; *&lt;TARGET&gt;/g) { ... } matches the string "Italian Alberto Tomba", because after target marking and Qcat marking, the string becomes "&lt;NATIONALITY_Italian&gt; &lt;TARGET&gt;".</p><p>Pre-run to Run filtering. The result of matching is a list of answers for each questionan unlimited number of answers may appear for any question, or we may have no answers at all. The task of the pre-run-to-run filtering component is to prepare the final run using the following rules:</p><p>• only the first answer is passed for any factoid question (TREC requirement),</p><p>• a NIL answer is introduced for questions with no generated answers,</p><p>• not more than seven answers are allowed per list question (rule of thumb),</p><p>• all answers to a list or 'other' question have to be unique,</p><p>• additionally, answers to an 'other' question may not appear as an answer to any previous question about the same target, and</p><p>• any answer longer than 100 bytes is truncated.</p><p>In the case of web-reinforced question-answering (run Dal04x), this phase is used to locate relevant documents as well (see the next section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We submitted the following three runs:</p><p>Dal04b -the "base" run using MultiText AQUAINT passages;</p><p>Dal04x -the "extended" run using MultiText AQUAINT passages and web passages, and re-finding the answer in the AQUAINT part, and Dal04p -the "PRISE" run using the documents provided by TREC, from the PRISE search engine.</p><p>For the run Dal04x we used web reinforced question-answering: We used relevant passages returned by the MultiText engine from the AQUAINT data set, but also from the Web data collected by the MultiText group. This means that the answers found in the pre-run may not be supported by the AQUAINT documents. For those answers, the system makes attempt to find them in the AQUAINT data set, and only if found there, they are included in the final run with the appropriate document ID. This is adopted as a general method for using external knowledge resources. This year, it is only used in the Dal04x run. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Summary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis</head><p>Our focus was on the factual questions, and in that respect the Dal04x had the best performance. It came as a surprise that Dal04p performed so well regarding the list questions; it is the only score which is larger than the TREC median, and it resulted in Dal04p having the best performance overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We present a relatively simple QA framework based on regular expression rewriting. Three runs were submitted for the QA track. Our evaluation results are generally below the median (with one exception) but seem to be significantly higher than the worst scores. The results fall within our expectations since this is our first TREC participation and we could devote only a minimal number of person-hours to the project.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,257.73,359.55,130.28,9.57"><head></head><label></label><figDesc>Figure 1: System Overview</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,119.77,702.98,204.73,7.86"><p>http://www.cs.dal.ca/˜trecacct -DalTREC URL</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank <rs type="person">Charlie Clarke</rs> for providing MultiText results for the TREC questions from the AQUAINT data set and his Web collection.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="5,103.18,356.68,439.38,8.74;5,114.09,367.64,416.41,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,114.09,367.64,223.44,8.74">From computational intelligence to web intelligence</title>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Cercone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lijun</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aijun</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kanlaya</forename><surname>Naruedomkul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaohua</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,345.88,367.64,68.27,8.74">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="72" to="76" />
			<date type="published" when="2002-11">2002. November</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,103.18,387.57,439.37,8.74;5,114.09,398.52,421.68,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,404.13,387.57,138.42,8.74;5,114.09,398.52,15.94,8.74">Lexical source-code transformation</title>
		<author>
			<persName coords=""><forename type="first">Anthony</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tony</forename><surname>Abou-Assaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,150.89,398.52,246.37,8.74">Proceedings of the STS&apos;04 Workshop at GPCE/OOPSLA</title>
		<meeting>the STS&apos;04 Workshop at GPCE/OOPSLA<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-10">2004. October</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,103.18,418.45,439.38,8.74;5,114.09,429.41,428.46,8.74;5,114.09,440.37,309.40,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,192.30,418.45,227.01,8.74">Question answering using unification-based grammar</title>
		<author>
			<persName coords=""><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,440.99,418.45,101.57,8.74;5,114.09,429.41,30.84,8.74;5,189.28,429.41,146.79,8.74">Advances in Artificial Intelligence</title>
		<title level="s" coord="5,483.06,429.41,59.50,8.74;5,114.09,440.37,89.43,8.74">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>AI; Ottawa, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001-06">2001. 2001. June</date>
			<biblScope unit="volume">LNAI</biblScope>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
	<note>Eleni Stroulia and Stan Matwin</note>
</biblStruct>

<biblStruct coords="5,103.18,460.29,439.37,8.74;5,114.09,471.25,380.58,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,191.60,460.29,213.73,8.74">Modular stochastic HPSGs for question answering</title>
		<author>
			<persName coords=""><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
		<idno>CS-2002-28</idno>
		<imprint>
			<date type="published" when="2002-06">2002. June</date>
			<pubPlace>Waterloo, Ontario, Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science, University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
