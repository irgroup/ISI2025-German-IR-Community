<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.41,110.15,250.95,15.49">Indri at TREC 2004: Terabyte Track</title>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
				<funder ref="#_S9mXgCn">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Advanced Research and De-velopment Activity</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.72,142.63,72.81,10.76"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.48,142.63,78.43,10.76"><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.39,142.63,68.11,10.76"><forename type="first">Howard</forename><surname>Turtle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.02,142.63,72.83,10.76"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.41,110.15,250.95,15.49">Indri at TREC 2004: Terabyte Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">274474C4D0609066B239401AA315075B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides an overview of experiments carried out at the TREC 2004 Terabyte Track using the Indri search engine. Indri is an efficient, effective distributed search engine. Like INQUERY, it is based on the inference network framework and supports structured queries, but unlike INQUERY, it uses language modeling probabilities within the network which allows for added flexibility. We describe our approaches to the Terabyte Track, all of which involved automatically constructing structured queries from the title portions of the TREC topics. Our methods use term proximity information and HTML document structure. In addition, a number of optimization procedures for efficient query processing are explained.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Indri search engine <ref type="foot" coords="1,152.33,465.96,3.48,6.28" target="#foot_0">1</ref> , developed as part of the Lemur Project, is designed to be both efficient and effective over a wide range of collections, especially large, semi-structured text collections, such as the web. This year's TREC Terabyte Track provided a useful platform to test our new system. Indri makes use of INQUERY's underlying inference network retrieval framework, which allows complex structured queries to be constructed and evaluated <ref type="bibr" coords="1,168.29,551.21,10.57,8.97" target="#b0">[1]</ref>. However, Indri makes use of language modeling probabilities instead of INQUERY's tf.idfbased probabilities, which provides increased robustness, as reflected in the Indri query language.</p><p>For this year's track we have two objectives. First, we wish to evaluate the effectiveness of our retrieval model. We devise several methods of automatically constructing complex structured queries from natural language descriptions of information needs. We explore several such methods, including the use of phrases and query expansion. Second, we are interested in evaluating the efficiency of the engine. We use document-at-a-time scoring, and explore several query optimization techniques.</p><p>Therefore, the goal of this paper is to provide a broad overview of Indri and our approaches to the Terabyte Track. In the remainder of this paper we describe Indri's underlying retrieval model, its indexing and query processing infrastructures, details of the runs we submitted, and an evaluation of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task</head><p>The focus of this year's track is content-based search over a large web collection. The collection, named GOV2, consists of a crawl of the entire .gov web domain. Despite it being the Terabyte Track, the collection only weighs in at 426GB uncompressed, which is still significantly larger than most past TREC collections. The collection is made up of 25,205,179 documents, which are mostly HTML documents (91.7%), but also includes plain text versions of crawled PDF, PS, and MS Word documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>The retrieval model implemented in the Indri search engine is an enhanced version of the model described in <ref type="bibr" coords="1,497.64,556.21,10.57,8.97" target="#b8">[9]</ref>, which combines the language modeling <ref type="bibr" coords="1,426.18,568.16,15.75,8.97" target="#b11">[12,</ref><ref type="bibr" coords="1,444.06,568.16,8.30,8.97" target="#b2">3]</ref> and inference network <ref type="bibr" coords="1,544.76,568.16,16.58,8.97" target="#b12">[13]</ref> approaches to information retrieval. The resulting model allows structured queries similar to those used in INQUERY to be evaluated using language modeling estimates within the network, rather than tf.idf estimates. Figure <ref type="figure" coords="1,480.77,615.98,4.97,8.97">3</ref> shows a graphical model representation of the network. As in the original inference network framework, documents are ranked according to P (I|D, α, β), the belief the information need I is met given document D and hyperparameters α and β as evidence.</p><p>Due to space limitations, a general understanding of the inference network framework is assumed. See <ref type="bibr" coords="1,489.81,689.35,11.61,8.97" target="#b8">[9]</ref> and <ref type="bibr" coords="1,520.87,689.35,16.59,8.97" target="#b12">[13]</ref> to fill in any missing details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Representation</head><p>Typically, in the language modeling framework, a document is represented as a sequence of tokens (terms). Based on this sequence, a multinomial language model over the vocabulary is estimated. However, it is often the case that we wish to model more interesting text phenomenon, such as phrases, the absence of a term, etc. Here, we represent documents as multisets of binary feature vectors. The features can be nearly any interesting binary observation of the underlying text. The features used to represent documents in our model are discussed later.</p><p>We assume that there is a single feature vector for each position within a document, although in general this need not be the case. Such a model moves away from modeling text towards modeling features of text. Throughout the remainder of this paper we refer to such models as language models, although they really are better described as language feature models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Language Models</head><p>Since our event space is now binary we can no longer estimate a single multinomial language model for each document. Instead, we estimate a multiple-Bernoulli model for each document, as in Model B of <ref type="bibr" coords="2,112.85,353.83,15.26,8.97" target="#b9">[10]</ref>. This overcomes the theoretical issues encountered in <ref type="bibr" coords="2,104.28,365.79,10.57,8.97" target="#b8">[9]</ref>. Note that the multiple-Bernoulli model imposes the assumption that the features (r i 's) are independent, which of course may be a poor assumption depending on the feature set.</p><p>We take a Bayesian approach and impose a multiple-Beta prior over the model (θ). The Beta is chosen for simplicity, as it is the conjugate prior to the Bernoulli distribution. Thus, P (D|θ) ∼ M ultiBernoulli(θ) and P (θ|α, β) ∼ M ultiBeta(α, β). Our belief at node θ is then: for each i where #(r i , D) is the number of times feature r i is set to 1 in document D's multiset of feature vectors.</p><formula xml:id="formula_0" coords="2,50.40,481.90,260.50,40.27">P (θ i |D, α, β) = P (D|θ i )P (θ i |α i , β i ) θi P (D|θ i )P (θ i |α i , β i ) = Beta(#(r i , D) + α i , |D| -#(r i , D) + β i )</formula><p>We estimate such a model for the entire text of a document. Additionally, we estimate specific models for a number of HTML fields. To do so, we treat all of the text in a document that appears within a given field as a pseudo-document. For example, a model can be estimated for all of the text that appears within the h1 tags of a document. More details of the specific fields we explored are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Representation Nodes</head><p>The r i nodes correspond to document features that can be represented in an Indri structured query. Indri implements all of the term and proximity operators available in INQUERY, including single terms, #N (ordered window N ), and #uwN (unordered window N ). See <ref type="bibr" coords="2,385.84,282.66,11.61,8.97" target="#b8">[9]</ref> for more details. The belief at a given representation node is computed as:</p><formula xml:id="formula_1" coords="2,338.90,322.50,194.78,59.66">P (r i |D, α, β) = θi P (r i |θ i )P (θ i |D, α i , β i ) = E[θ i ] = #(r i , D) + α i |D| + α i + β i</formula><p>Furthermore, selecting α i = µP (r i |C) and β i = µ(1 -P (r i |C)) we get the multiple-Bernoulli model equivalent of the multinomial model's Dirichlet smoothing <ref type="bibr" coords="2,478.53,419.36,16.58,8.97" target="#b14">[15]</ref> estimate:</p><formula xml:id="formula_2" coords="2,348.76,441.16,173.84,23.75">P (r i |D, α, β) = #(r i , D) + µP (r i |C) |D| + µ</formula><p>where µ acts as a tunable smoothing parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Query Nodes</head><p>The query node operators are soft probabilistic operators. All of the query operators available in INQUERY are also available in Indri, with the addition of a weighted version of the #and operator named #wand. The operators are #combine (same as #and), #weight (same as #wand), #or, #not, #sum, #wsum, and #max. See <ref type="bibr" coords="2,355.19,592.67,11.62,8.97" target="#b8">[9]</ref> for the details of how beliefs are computed at the query nodes. Since we are using language modeling probabilities within the network, the #wsum operator no longer makes sense and the the #combine (#and) and #weight (#wand) operators are more appropriate <ref type="bibr" coords="2,359.83,653.49,10.57,8.97" target="#b8">[9]</ref>. In fact, it can be shown that the Indri query #combine( q 1 . . . q N ) using the estimates just described returns exactly the same ranked list as the query q 1 . . . q N using the traditional (multinomial with Dirichlet smoothing) query likelihood model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Test Platform</head><p>We ran our index builds and our queries in parallel on a cluster of 6 identically configured machines (the machine configuration is shown in Figure <ref type="figure" coords="3,144.44,340.06,3.59,8.97">2</ref>). For the run involving anchor text, we ran an application on a single machine that extracted all anchor text from the collection. We discarded all in-site links, that is, all machines that pointed to pages on the same machine as they originated from. The remaining link text was associated with the destination page of each link. This process took more time than indexing did, and it generated approximately 7GB of anchor text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Indri Retrieval Engine</head><p>The Indri engine was written to handle question answering and web retrieval tasks against large corpora. The engine is written in C++ and runs on Linux, Windows, Solaris and Mac OS X. We used the Terabyte Track as a proving ground for this engine.</p><p>The indexing algorithm is quite similar to the one described in <ref type="bibr" coords="3,60.39,558.71,10.57,8.97" target="#b5">[6]</ref>, although it was developed before we had seen this paper. In the early phases of development we had attempted to store the vocabulary of the collection in a B-Tree data structure. With caching, this method seemed to do well on collections of up to 10GB, but after that point performance degraded dramatically. We eventually changed the system to flush the vocabulary during posting flushes, as in <ref type="bibr" coords="3,153.44,630.44,10.57,8.97" target="#b5">[6]</ref>. This technique dramatically improved our indexing times.</p><p>The Indri indexing process creates a variety of data structures:</p><p>• A compressed inverted file for the corpus, including term position information</p><p>• Compressed inverted extent lists for each field indexed in the corpus</p><p>• A vector representation of each document, including term position information and field position information</p><p>• A compressed version of the corpus text, including byte offsets of indexed terms</p><p>We found that flushing the vocabulary during posting flushes complicated the creation of document vectors. These vectors are compressed arrays of numbers, where each number corresponds to some term in the collection. In initial development, each term was assigned a fixed number when it was first seen in the corpus. With vocabulary flushing, we were no longer able to keep fixed term numbers throughout the indexing process. We therefore write the document vectors out using temporary term numbers. Once each term is assigned a final term number during the final inverted list merge, we rewrite the document vectors, exchanging the temporary term numbers for the final numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Anchor Text</head><p>For the anchor text run, we followed the model presented by Ogilvie and Callan in <ref type="bibr" coords="3,399.84,367.40,15.26,8.97" target="#b10">[11]</ref>. In this model, different portions of the document are considered to be different representations of the same document. We used the heading fields (h1, h2, h3 and h4), the title, the whole text, and the anchor text of each web page as these different representations. The Indri query language enabled us to weight these different representations during retrieval.</p><p>Let the set of pages in the corpus be C. For each document d ∈ C, there is a (possibly empty) set of documents in C that have links to d. Let this set of documents be L. We can partition L into two sets, L I and L E , where L I consists of those documents on the same server as d (where server identity is defined by DNS name), and L E consists of those documents on other servers. Let A(d) represent the anchor text in links from L E to d. We use A(d) as the anchor text model for d.</p><p>In order to be able to use the anchor text model of a document during retrieval, we created an anchor text harvesting program. This anchor text harvester wrote out all the links in the collection into a separate anchor text only corpus. The program then associated the anchor text for each link to the destination document. Approximately 70% of the time for this process was taken in parsing the corpus to find the text; the remaining 30% was taken in associating the link text with the destination documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Retrieval</head><p>Indri uses a document-distributed retrieval model when operating on a cluster. Each machine in the cluster runs a process called a query server, which can perform queries against its local collection. A process called the query director sends queries out to the query servers for processing, and then merges the results.</p><p>In order to generate scores on a cluster that are identical to those in a single collection, it is necessary for each cluster node to use the same corpus statistics for term frequency and corpus size. To do this, Indri starts every query by collecting statistics from the query servers. The query director combines these statistics to create a collection model for the query. These statistics are then sent back to the query servers with the query itself for final processing. This two-phase process allows Indri to handle statistics collection for phrases in the same way that it handles collection statistics for terms.</p><p>In the results we reported for the conference, our system used 1MB buffers on all term inverted lists in order to keep disk seek overhead to an acceptable minimum. We processed all queries into directed acyclic graphs before evaluation, which dramatically cut down on the time necessary to evaluate the more complicated adaptive window runs. We also incorporated a fast path for frequency-only terms; that is, terms that can be scored based on their frequency within the document, and without position information. For these frequency terms, we read postings from the inverted list in batches, and did not decompress the position information.</p><p>Since the deadline, we have added two more optimizations. The first is max score, described in <ref type="bibr" coords="4,202.24,394.92,15.25,8.97" target="#b13">[14]</ref>. This optimization was in place before the deadline, but because of bugs in the implementation was not actually working. The max score optimization allows Indri to skip inverted list postings that we know cannot be associated with a document in the top n positions of the ranked list. Note that this optimization is rank and score safe.</p><p>We have also implemented #weight operator folding. This optimization removes unnecessary #weight and #combine operators. For instance, a query such as </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Runs</head><p>Five official runs were submitted for evaluation. We created runs that vary from very simple (indri04QL) to very complex (indri04FAW) with the aim of evaluating the efficiency and effectiveness of our system across a wide range of query types. In order to emulate reality as close as possible, all queries were automatically constructed using only the title field from the topic. The runs submitted were: indri04QL -Query likelihood. For each topic we create an Indri query of the form #combine( q 1 . . . q N ), where Q = q 1 , . . . , q N is the title portion of the topic.</p><p>indri04QLRM -Query likelihood + pseudo relevance feedback. For each topic, we construct a relevance model <ref type="bibr" coords="4,527.63,225.20,11.61,8.97" target="#b7">[8]</ref> from the top 10 documents retrieved using the indri04QL query. The original query is then augmented with the 15 terms with the highest likelihood from the relevance model. The final form of the Indri query is:</p><formula xml:id="formula_3" coords="4,361.59,294.21,149.40,19.22">#weight( 0.5 #combine( q1 . . . qN ) 0.5 #combine( e1 . . . e15 ) )</formula><p>where e 1 . . . e 15 are the expansion terms.</p><p>indri04AW -Phrase expansion. This run explores how we can exploit Indri's proximity operators to improve effectiveness. We base our technique on the following assumption described in <ref type="bibr" coords="4,353.64,390.17,10.78,8.97" target="#b1">[2]</ref>: query terms are likely to appear in close proximity to each other within relevant documents. For example, given the query "Green party political views" (topic 704), relevant documents will likely contain the phrases Green party and political views within relatively close proximity to one another. Most retrieval models ignore proximity constraints and allow query terms to appear anywhere within a document, even if the words are clearly unrelated. Let us treat a query as a set of terms Q and define S Q = P(Q) \ {∅} (i.e. the set of all non-empty subsets of Q). Then, our queries attempt to capture certain innate dependencies between query terms via the following assumptions on S Q : 1. Every s ∈ S Q that consists of contiguous query terms is likely to appear as an exact phrase in a relevant document (i.e. #1) 2. Every s ∈ S Q such that |s| &gt; 1 is likely to appear (ordered or unordered) within a reasonably sized window of text in a relevant document (i.e. #uw4|s|).</p><p>These assumptions state that (1) exact phrases that appear in a query are likely to appear as exact phrases within relevant documents and that (2) all query terms are likely to appear within close (ordered or unordered) proximity to each other in a relevant document. As a concrete example, given the query "Prostate cancer treatments" (topic 710) our system generates the following query: Queries constructed in this way boost the score of documents that adhere to our assumptions. Experiments on the WT10g collection with queries of this form performed significantly better than traditional query likelihood queries.</p><p>indri04AWRM -Phrase expansion + pseudo relevance feedback. This run uses the query constructed from the indri04AW run for pseudo relevance feedback. Here, 5 documents were used to construct the relevance model and 10 expansion terms were added to the query. For this run, we weighted the original query 0.7 and the expansion terms 0.3 to yield a query of the form:</p><formula xml:id="formula_4" coords="5,82.36,349.67,186.69,8.27">#weight( 0.7 Qorig 0.3 #combine( e1 . . . e10 ) )</formula><p>where Q orig is the original query and e 1 . . . e 10 are the expansion terms.</p><p>indri04FAW -Phrase expansion + document structure. Our final run is a largely untested and purely experimental attempt to make use of anchor text and document structure. As discussed earlier, the Indri search engine can index fields and can evaluated complex queries containing certain field constructs.</p><p>Several past studies have found that anchor text and document structure yields inconsistent improvements in effectiveness for ad hoc web retrieval <ref type="bibr" coords="5,137.41,495.21,10.78,8.97" target="#b3">[4,</ref><ref type="bibr" coords="5,151.69,495.21,7.46,8.97" target="#b4">5,</ref><ref type="bibr" coords="5,162.65,495.21,7.19,8.97" target="#b6">7]</ref>. The results were obtained using the WT10g collection, which is roughly 2.5% the size of the GOV2 corpus. Therefore, we wish to explore whether these results hold for this larger collection. The queries constructed for this run make use of main body text, anchor text, the title field, and header fields (h1, h2, h3, h4). The queries constructed are of the form:</p><formula xml:id="formula_5" coords="5,122.50,588.36,106.42,41.48">#weight( 0.15 Q inlink 0.25 Q title 0.10 Q heading 0.50 Q mainbody )</formula><p>where each Q f ield is a phrase expansion query evaluated using the respective field language model. For example, Q inlink is the phrase expansion query evaluated using a language model built from all of the anchor text associated with a page. All smoothing parameters, weights, and window sizes were tuned using the WT10g collection and which were used for ad hoc web retrieval at TREC-9 and 10 <ref type="bibr" coords="5,550.57,196.78,10.78,8.97" target="#b3">[4,</ref><ref type="bibr" coords="5,310.98,208.73,7.19,8.97" target="#b4">5]</ref>. Table <ref type="table" coords="5,345.34,221.29,4.97,8.97" target="#tab_3">1</ref> gives a detailed summary of the runs. Each run used an index built from the entire collection of 25,205,179 documents. Documents are stemmed with the Porter stemmer and stopped using a standard list of 421 common terms. In the table, indexing time is the number of minutes required to build the index in parallel across the cluster. Therefore, this number is the maximum time required by any single machine to index its subcollection. Index size is the total size of the index on disk including both the inverted file and compressed collection. Average query time is the average number of seconds required to run a query (distributed across the cluster) and retrieve 20 documents. The last column denotes whether or not the run made any use of any document structure, such as titles, headers, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>The results from our official runs are given in Table <ref type="table" coords="5,525.20,425.12,3.73,8.97" target="#tab_2">2</ref>. In the table, AvgP denotes mean average precision and P10 is the precision at 10 retrieved documents. The results seem to indicate that both phrase expansion and query expansion improve performance, where our best run, indri04AWRM, uses both. In fact, the indri04AWRM run was the best automatic, title-only run at the track.</p><p>After our official runs were submitted we discovered a number of serious bugs in Indri. Since the code was relatively young at the time and largely untested, this was not unexpected. After the bugs were fixed, we decided to carry out our runs again and see what impact the fixes had on effectiveness. Note that we did not change anything else in the system such as parsing, weights, smoothing parameters, query formulation methodologies, etc. Only core bug fixes were applied to the system. Also, since many other groups used other fields from the TREC topics, such as the description and narrative fields, we decided to run experiments using these fields.</p><p>Table <ref type="table" coords="5,346.49,641.53,4.97,8.97" target="#tab_4">3</ref> summarizes the results using the corrected system and various combinations of fields from the TREC topics. For the QL and QLRM runs, all of the text from all the fields under consideration is concatenated and included in the query with equal weighting. For example, for the title+desc run, the query formulation is: where Q QL,title is the QL (bag of words) formulation of the text in the title field and Q QL,desc is the QL formulation of the text in the description field.</p><p>For the AW and AWRM runs, a phrase expansion query is constructed using only the title portion of the topic. The text from any additional fields is included in the query and given equal weight. Here is an example of the title+desc+narr query formulation:</p><p>#weight( 1.0 Q AW,title 1.0 Q QL,desc 1.0 QQL,narr ) where Q AW,title is the AW (phrase expansion) formulation of the text in the title field and Q QL,desc and Q QL,narr are the QL formulations of the text in the description and narrative fields, respectively.</p><p>Based on the corrected results, we see that the phrase expansion technique still yields improvements, but the query expansion runs lead to degraded performance. One explanation for the poor performance of the query expansion runs is the fact that our query expansion parameters were trained using the "broken" code. Another possible explanation is that the noise inherent in a collection the size of GOV2 produces poor expansion terms. We plan to further investigate this matter in the future.</p><p>Furthermore, the results show that naively using the description and narrative portions of the TREC topics can lead to further improvements. In fact, the corrected AW run using the title, description, and narrative fields outperforms the overall best official Terabyte Track run by approximately 7% (the run, uogTBQEL, submitted by the University of Glasgow, had an average precision of 0.3075 and made use of the same topic fields). Although web users have been trained by commercial search engines to formulate short keyword queries, they do so at the expense of precision. Considering more complex queries can lead to significant improvements in both average precision and precision at 10 documents. We wish to explore the issue of complex queries, including how to best express and represent them, in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>This year's Terabyte Track provided a forum to evaluate how well existing retrieval architectures and models scale to (almost) terabyte sized collections. Based on the outcome of the track, we are confidant the Indri search engine is both efficient and effective on such large scale collections. Distributed across six machines, Indri indexed the 25 million document, 426GB GOV2 collection in 6 hours (approximately 12 GB/hr/machine) and processed approximately one query every second. In terms of effectiveness, phrase expansion via Indri's structured query operators proved to be a powerful asset. In the official runs, Indri had the best title only run using this technique. Despite all of this, we hope to improve our system for next year. There are a number of things we aim to explore, including faster indexing, improved query processing times, more use of HTML document structure, looking into further use of complex queries, more effective query expansion techniques for noisy data, document priors, and link analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,73.20,699.15,204.80,8.97;2,73.47,545.39,204.40,116.73"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Indri's inference network retrieval model.</figDesc><graphic coords="2,73.47,545.39,204.40,116.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,96.14,523.43,152.31,8.07;4,139.03,534.38,116.15,8.07;4,50.40,553.61,63.09,8.97;4,71.34,575.07,208.51,8.07;4,50.40,595.48,250.37,8.97;4,50.40,607.43,250.34,8.97;4,50.40,619.38,250.35,8.97;4,50.40,631.34,62.32,8.97"><head>#</head><label></label><figDesc>weight( 0.5 #combine( Bruce Croft ) 0.5 #combine( James Allan ) ) is equivalent to: #weight( 0.25 Bruce 0.25 Croft 0.25 James 0.25 Allan ) However, our implementation of max score operates only on the top level #weight operator. As such, #weight folding, in concert with max score, gave us a large speedup in the query expansion runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,211.37,82.03,296.66,628.25"><head>Table 2 :</head><label>2</label><figDesc>Official submission results.</figDesc><table coords="5,211.37,701.31,89.39,8.97"><row><cell>TREC topics 451-550</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,170.59,82.03,270.67,189.57"><head>Table 1 :</head><label>1</label><figDesc>Summary of runs.</figDesc><table coords="6,170.59,82.03,270.67,189.57"><row><cell cols="2">run id</cell><cell>index time (mins)</cell><cell cols="2">index size (GB)</cell><cell>avg. query time (s)</cell><cell>struct?</cell></row><row><cell cols="2">indri04QL</cell><cell>355</cell><cell>224</cell><cell></cell><cell>1.36</cell><cell>no</cell></row><row><cell cols="2">indri04QLRM</cell><cell>355</cell><cell>224</cell><cell></cell><cell>26.0</cell><cell>no</cell></row><row><cell cols="2">indri04AW</cell><cell>355</cell><cell>224</cell><cell></cell><cell>6.5</cell><cell>no</cell></row><row><cell cols="2">indri04AWRM</cell><cell>355</cell><cell>224</cell><cell></cell><cell>39.4</cell><cell>no</cell></row><row><cell cols="2">indri04FAW</cell><cell>1300</cell><cell>226</cell><cell></cell><cell>52.2</cell><cell>yes</cell></row><row><cell></cell><cell cols="2">Title</cell><cell cols="2">Title+Desc</cell><cell cols="2">Title+Desc+Narr</cell></row><row><cell></cell><cell>AvgP</cell><cell>P10</cell><cell>AvgP</cell><cell>P10</cell><cell>AvgP</cell><cell>P10</cell></row><row><cell>QL</cell><cell cols="6">0.2565 0.4980 0.2730 0.5510 0.3088 0.5918</cell></row><row><cell cols="7">QLRM 0.2529 0.4878 0.2675 0.5673 0.2928 0.5796</cell></row><row><cell>AW</cell><cell cols="6">0.2839 0.5857 0.2988 0.6184 0.3293 0.6306</cell></row><row><cell cols="7">AWRM 0.2874 0.5653 0.2974 0.6102 0.3237 0.6367</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,87.08,284.37,437.41,40.83"><head>Table 3 :</head><label>3</label><figDesc>Summary of corrected results using different combinations of TREC topic fields to construct queries.#weight( 1.0 Q QL,title 1.0 Q QL,desc )</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,64.75,702.67,175.21,7.17"><p>Available for download at http://www.lemurproject.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="9">Acknowledgments</head><p>This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs> and in part by <rs type="funder">Advanced Research and De-velopment Activity</rs> and <rs type="funder">NSF</rs> grant #<rs type="grantNumber">CCF-0205575</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_S9mXgCn">
					<idno type="grant-number">CCF-0205575</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,70.30,172.06,230.45,8.07;7,70.32,183.02,149.59,8.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,244.04,172.06,56.71,8.07;7,70.32,183.02,54.88,8.07">The INQUERY retrieval system</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,141.99,183.02,32.43,8.07">DEXA-92</title>
		<imprint>
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.31,197.96,230.43,8.07;7,70.32,208.92,217.87,8.07" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,235.30,197.96,65.44,8.07;7,70.32,208.92,148.44,8.07">Shortest substring ranking (multitext experiments for trec-4)</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Burkowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note>In TREC 4</note>
</biblStruct>

<biblStruct coords="7,70.31,223.86,230.43,8.07;7,70.32,234.82,89.27,8.07" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,170.91,223.86,129.82,8.07;7,70.32,234.82,31.44,8.07">Language Modeling for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Kluwer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.31,249.77,230.41,8.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,118.11,249.77,115.11,8.07">Overview of the trec-9 web track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,248.22,249.77,27.10,8.07">TREC 9</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.31,264.71,230.43,8.07;7,70.32,275.68,90.78,8.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,185.77,264.71,114.97,8.07;7,70.32,275.68,16.77,8.07">Overview of the trec-2001 web track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,103.38,275.68,31.61,8.07">TREC 10</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.31,290.62,232.26,8.07;7,70.32,301.58,176.89,8.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,157.59,290.62,144.97,8.07;7,70.32,301.58,61.11,8.07">Efficient single-pass index construction for text databases</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Heinz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,138.32,301.58,24.21,8.07">JASIST</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="713" to="729" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.31,316.52,230.42,8.07;7,70.32,327.48,230.41,8.07;7,70.32,338.43,78.40,8.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,178.86,316.52,121.86,8.07;7,70.32,327.48,140.68,8.07">Integration of multiple evidences based on a query type for web search</title>
		<author>
			<persName coords=""><forename type="first">I.-H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,221.93,327.48,75.03,8.07">Info. Proc. and Mgt</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="459" to="478" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.31,353.38,230.44,8.07;7,70.32,364.34,49.99,8.07" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,123.59,353.38,125.23,8.07">A Generative Theory of Relevance</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>UMass</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="7,70.31,379.28,230.42,8.07;7,70.32,390.25,230.40,8.07;7,70.32,401.20,78.40,8.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,173.09,379.28,127.63,8.07;7,70.32,390.25,147.95,8.07">Combining the language model and inference network approaches to retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,225.23,390.25,71.71,8.07">Info. Proc. and Mgt</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="735" to="750" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.30,416.15,230.45,8.07;7,70.32,427.10,230.41,8.07;7,70.32,438.06,34.13,8.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,241.26,416.15,59.49,8.07;7,70.32,427.10,147.08,8.07">Formal multiple bernoulli models for language modeling</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,239.69,427.10,42.00,8.07">SIGIR 2004</title>
		<imprint>
			<biblScope unit="page" from="540" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.30,453.01,230.42,8.07;7,70.32,463.96,140.03,8.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,164.98,453.01,135.74,8.07;7,70.32,463.96,78.75,8.07">Combining document representations for known item search</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.59,463.96,22.39,8.07">SIGIR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.30,478.91,230.42,8.07;7,70.32,489.87,183.66,8.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,178.17,478.91,122.55,8.07;7,70.32,489.87,73.00,8.07">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,159.41,489.87,40.73,8.07">SIGIR 1998</title>
		<imprint>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.30,504.82,230.44,8.07;7,70.32,515.77,179.26,8.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,170.21,504.82,130.53,8.07;7,70.32,515.77,74.78,8.07">Evaluation of an inference networkbased retrieval model</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,152.43,515.77,16.78,8.07">TOIS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="222" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.30,530.72,230.45,8.07;7,70.32,541.67,195.89,8.07" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,161.26,530.72,139.49,8.07;7,70.32,541.67,33.35,8.07">Query evaluation: strategies and optimizations</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Flood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,110.61,541.67,71.17,8.07">Info. Proc. and Mgt</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="831" to="850" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.30,556.62,230.43,8.07;7,70.32,567.58,230.44,8.07;7,70.32,578.53,99.53,8.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,159.21,556.62,141.52,8.07;7,70.32,567.58,164.40,8.07">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,242.31,567.58,58.45,8.07;7,70.32,578.53,15.74,8.07">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
