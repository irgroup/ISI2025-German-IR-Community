<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.04,78.19,325.30,17.22;1,120.00,100.15,371.49,17.22;1,145.20,122.11,321.28,17.22">Domain-Specific Synonym Expansion and Validation for Biomedical Information Retrieval (MultiText Experiments for TREC 2004)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.16,167.04,81.05,8.79"><forename type="first">Stefan</forename><surname>Büttcher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.61,167.04,105.63,8.79"><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.88,167.04,103.46,8.79"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.04,78.19,325.30,17.22;1,120.00,100.15,371.49,17.22;1,145.20,122.11,321.28,17.22">Domain-Specific Synonym Expansion and Validation for Biomedical Information Retrieval (MultiText Experiments for TREC 2004)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E96347D84FDE77AEC1AB5DCABCFB036D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the domain of biomedical publications, synonyms and homonyms are omnipresent and pose a great challenge for document retrieval systems. For this year's TREC Genomics Ad hoc Retrieval Task, we mainly addressed the problem of dealing with synonyms. We examined the impact of domain-specific knowledge on the effectiveness of query expansion and analyzed the quality of Google as a source of query expansion terms based on pseudo-relevance feedback.</p><p>Our results show that automatic acronym expansion, realized by querying the AcroMed database of biomedical acronyms, almost always improves the performance of our document retrieval system. Google, on the other hand, produced results that were worse than the other, corpus-based feedback techniques we used as well in our experiments. We believe that the primary reason for Google's bad performance in this task is its highly restricted query language.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the work done by members of the MultiText project at the University of Waterloo for the TREC 2004 Genomics track. The MultiText group only participated in the Ad hoc retrieval task of the Genomics track, which consisted of finding documents that are relevant with respect to certain topics in a subset of the Medline/PubMed database of medical publications <ref type="bibr" coords="1,181.61,574.31,29.29,9.96">[PM04]</ref>. The subset included articles published between 1963 and 2004. It consisted of 4,591,008 different documents with a total size of 14 GB (XML text), where the term document refers to incomplete articles, annotated with certain keywords, such as MeSH terms <ref type="bibr" coords="1,235.89,634.07,32.73,9.96">[MeS04]</ref>. Out of these 4,591,008 documents, 3,479,798 contained the abstract of the article, the remaining 1,111,210 only the article title and the annotations. In total, 50 topics were given to the track participants. An example topic is shown in Figure <ref type="figure" coords="1,217.93,693.83,3.90,9.96" target="#fig_0">1</ref>.</p><p>Information retrieval in the context of biomedical databases traditionally has to contend with three major problems: the frequent use of (possibly nonstandardized) acronyms, the presence of homonyms (the same word referring to two or more different entitities) and synonyms (two or more words referring to the same entity). For the two runs we submitted for the Genomics track, we addressed the problems caused by acronyms and synonyms. We chose to follow a strategy that was a mixture of known heuristics for approximate string matching for genomics-related data and a knowledge-based approach that used domain-specific knowledge from various sources, such as the AcroMed database of biomedical acronyms <ref type="bibr" coords="1,413.08,613.31,29.79,9.96" target="#b0">[Acr04]</ref>. Since acronyms can be viewed as special forms of synonyms, it was possible to develop a system that can deal with both problems (synonyms and acronyms) in a uniform way.</p><p>Furthermore, we implemented an automatic query expansion technique using pseudo-relevance feed- We evaluated the quality of feedback terms produced by a simple Google query and compared the results with known query expansion techniques. We also studied possibilities to combine both strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The MultiText system</head><p>Our work is based on the MultiText text retrieval system, which was initially implemented at the University of Waterloo in 1994 <ref type="bibr" coords="2,216.81,356.15,36.92,9.96" target="#b1">[CCB94]</ref> and has experienced a variety of extensions and modification over the last decade. MultiText supports several different document scoring mechanisms. We employed the MultiText implementation of Okapi BM25 [RWJ + 94] [RWB98] and MultiText's QAP passage scoring algorithm <ref type="bibr" coords="2,186.49,427.91,37.04,9.96" target="#b3">[CCT00]</ref> [CCL01], which had initially been developed for question answering tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Okapi BM25 document scoring</head><p>MultiText's implementation of BM25 is the same as the original function proposed by <ref type="bibr" coords="2,237.23,520.67,57.18,9.96;2,70.92,532.67,10.55,9.96">Robertson et al.</ref> [RWJ + 94] in the absence of document relevance information. Every query term T is assigned a term weight</p><formula xml:id="formula_0" coords="2,123.72,566.99,166.62,23.90">w T = ln( |D| -|D T | + 0.5 |D T | + 0.5 ), (<label>1</label></formula><formula xml:id="formula_1" coords="2,290.34,573.71,4.23,9.96">)</formula><p>where D is the set of all documents in the corpus, and D T is the set of documents containing the term T . For a given query Q = {T 1 , ..., T n }, the score of a document D is computed using the formula</p><formula xml:id="formula_2" coords="2,81.60,647.27,212.98,27.61">T ∈Q w T • q T • d T • (1 + k 1 ) d T + k 1 • ((1 -b) + b • lenD lenavg ) ,<label>(2)</label></formula><p>where d T is the number of occurrences of the term T in the document D, len D is the length of D, len avg is the average document length in the corpus, and q T is the query-specific relative weight of the term T . Usually, q T equals the number of occurrences of T in the original query. We discuss this parameter in more detail in section 8. The remaining parameters in formula 2 were chosen to be k 1 = 1.2 and b = 0.75.</p><p>In addition to mere term queries, MultiText supports structured queries, and in particular disjunctions of terms. We call a disjunction of query terms</p><formula xml:id="formula_3" coords="2,377.40,340.07,103.32,10.33">T ∨ = T 1 ∨ T 2 ∨ • • • ∨ T m</formula><p>a disjunctive query element. The BM25 weight of a disjunctive query element is</p><formula xml:id="formula_4" coords="2,333.72,390.11,207.34,23.89">w T∨ = ln( |D| -|D T1 ∪ • • • ∪ D Tm | + 0.5 |D T1 ∪ • • • ∪ D Tm | + 0.5 ).<label>(3)</label></formula><p>For convenience, we let the "+" symbol denote the disjunction operator ("∨") whenever we present example queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MultiText QAP passage scoring</head><p>MultiText's QAP passage scoring algorithm computes text passage scores based on the concept of self-information. It may be extended to a document scoring algorithm by finding the passage with the highest score within a document and assigning the passage's score to the entire document, although this is not the original purpose of QAP. Our pseudorelevance feedback mechanisms are derived from the QAP scoring function.</p><p>Given a query Q, every passage P of length l, containing the terms T ⊆ Q, is assigned the score</p><formula xml:id="formula_5" coords="2,356.76,646.40,180.05,27.05">H(P ) = T ∈T (log 2 ( N f T ) -log 2 (l)), (<label>4</label></formula><formula xml:id="formula_6" coords="2,536.81,652.67,4.23,9.96">)</formula><p>where N is the total number of tokens in the corpus (corpus size), and f T is the number of occurrences </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System overview</head><p>An overview of the document retrieval system developed for the Genomics track is given by Figure <ref type="figure" coords="3,70.92,461.03,3.90,9.96">2</ref>. The system consists of a preprocessing stage and three document retrieval stages. Most parts of the system can be changed by varying the respective parameters. Because there were no training data available, many of these parameters are arbitrarily chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query preprocessing &amp; Synonym expansion (Stage 1)</head><p>In the preprocessing stage, the input data (XML text) is parsed and all stop words are removed. The list of stop words contains the usual terms, like "the" and "and", but also a number of additional terms inferred from the sample topics, e.g. "find", "information", and "literature". After the stop words have been removed, several synonym generation techniques are applied to the query. A detailed explanation of these techniques can be found in section 4. The result of this process is an expanded query containing possible synonyms of the terms in the original query. The unexpanded query is taken by MultiText to score documents using both BM25 and QAP, while the expanded query is used to produce a third, BM25-scored document set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expansion validation (Stage 2)</head><p>In the second stage (see section 5 for details), the documents returned by the first stage are analyzed and systematically scanned for any occurrences of terms added to the query in the expansion phase of stage 1 or permutations of query terms. Terms that have been added to the query in stage 1, but occur very infrequently in the documents returned, are removed from the query, whereas frequent permutations of query terms which have not been part of the old query might be added. The resulting query is sent to MultiText, and documents are scored by BM25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudo-relevance feedback (Stage 3)</head><p>The third stage, which is described in sections 6 and 7, performs a set of standard pseudo-relevance feedback operations in order to create new expansion terms. The terms produced by the feedback are added to the query, and BM25 is used again to compute the document scores. Finally, if our retrieval system has found species names in the original query, it tries to match the documents in the ID: 14 TITLE: Expression or Regulation of TGFB in HNSCC cancers NEED: Documents regarding TGFB expression or regulation in HNSCC cancers. QUERY_TITLE: "expression" "regulation" "tgfb" "hnscc" "cancers" EXPANDED_TITLE: "expression" "regulation" ("tgfb"+"blk"+"ced"+"dlhc"+ "tgfbeta"+"tgfb1"+"tgfb2"+"tgf r"+"transforming growth factor beta"+ "latent transforming growth factor beta"+"ltbp 1"+"ltbp1"+"mav"+ "maverick"+.....) ("hnscc"+"head and neck squamous cell") "cancers" QUERY_NEED: "regarding" "tgfb" "expression" "regulation" "hnscc" "cancers" EXPANDED_NEED: "regarding" ("tgfb"+"blk"+"ced"+"dlhc"+"tgfbeta"+"tgfb1"+ .....) "expression" "regulation" ("hnscc"+"head and neck squamous cell") "cancers" result list against these species names and promotes documents that contain the species names or synonyms of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Domain-specific query expansion</head><p>For domain-specific query expansion, we used two different techniques in stage 1 of our system:</p><p>• a general variant generation approach that creates lexical variants of a list of given terms;</p><p>• a database of biomedical synonyms, extracted from various sources available on the web.</p><p>In addition to these methods, we examine permutations of query terms to find further expansions. The result of the query expansion in stage 1 is an expanded query that combines each original query terms and all its expansions (synonyms etc.) into one disjunctive query element (defined in section 2), as shown in Figure <ref type="figure" coords="4,156.30,499.07,3.90,9.96" target="#fig_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lexical variants</head><p>In the context of biomedical articles, we have to deal with an abundant number of lexical variants of the same term. These are mainly caused by the authors' different preferences of hyphenation, spacing and Greek letters. In the Medline corpus used for this year's Genomics track, for instance, the NF-kappa B protein is referred to in 6 different ways: "NF-kappa B" (33902 times), "NF-kappaB" (28551), "NFkap-paB" (3211), "NF-kB" (688), "NFkB" (259), and "NFkappa B" (45).</p><p>Our system addresses this problem by scanning the original query for interesting terms (i.e., terms that are likely to have lexical variants). We consider a term interesting if it contains at least one hyphen, digit, or Greek letter. For each such term, a list of possible variants is created according to the following rules:</p><p>1. Greek letters are contracted to their Latin equivalents: "alpha" becomes "a", "beta" becomes "b", and so on.</p><p>2. Hyphens are removed from the term.</p><p>3. Before and after every Greek letter, a hyphen is inserted.</p><p>4. At every transition from alphabetic to numerical characters and back, a hyphen is inserted.</p><p>For each term, every possible combination of the above rules is applied to the term. For example, the set of variants generated for the term "Lsp1alpha" (Larval serum protein 1 alpha) is: "lsp-1-alpha", "lsp-1-a", "lsp-1alpha", "lsp-1a", "lsp1alpha", "lsp1-a", "lsp1alpha", "lsp1a".</p><p>The problem of replacing spaces by hyphens and vice versa can be ignored because the MultiText engine already considers them equivalent. Case folding is automatically applied to all terms as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Synonym expansion</head><p>In biomedical publications, we have mainly three types of synonyms that can appear in a query:</p><p>• acronyms;</p><p>• gene names or symbols;</p><p>• protein names or symbols.</p><p>Acronyms can be dealt with in a straightforward fashion by adding the respective long form to the query whenever a known acronym is encountered.</p><p>Genes and proteins have additional structure that can be used when looking for appropriate expansions: the symbol "ACP" (acid phosphatase) describes a family of proteins, including ACP1 and ACP2. This allows us to not only add synonyms of "ACP" to the query, but also "ACP1" and "ACP2". Following the Gene Ontology terminology, we call these narrow synonyms (as opposed to exact synonyms, such as acronyms).</p><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AcroMed</head><p>The AcroMed database contains a list of mappings from acronyms to their long forms, automatically created from Medline abstracts. For our experiments, we used only a subset of the AcroMed data. We ignored all acronym/long-form pairs with less than 5 occurrences. The rationale behind this was to avoid low-quality expansion terms caused by wrong AcroMed data. The resulting database contained 25,589 acronyms and 49,822 long forms.</p><p>For every input topic, our system searches the topic text for occurrences of acronyms stored in the AcroMed database. In order to allow for lexical variants, an approximate string matching algorithm is used that allows exactly the types of variants that are described in section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>euGenes</head><p>The Genomic Information for Eukaryotic Organisms database (euGenes.org) consists of genetic information for 9 different species. The version used for our experiments contains 184,460 different genes. Our system does not use the information offered by eu-Genes to its full extent. Instead, it only builds a mapping from gene symbols to full names.</p><p>Again, the special needs discussed in section 4.1 are taken into account when the euGenes database is searched for a gene symbol. Furthermore, when looking for expansions, we also allow for narrow synonyms by cutting off the tail of the gene symbol after the last transition from alphabetical to numerical characters or vice versa. The gene symbol "TGFB2" (Human gene Transforming Growth Factor Beta 2), for example, is given the database entries "TGFB2" and "TGFB". The same holds for hyphens, so the gene "ATPsyn-beta" (Drosophila gene ATP Synthase Beta) can even be found when the query is asking for "ATPsyn".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LocusLink</head><p>LocusLink is most prominent source of publicly available information on genes. It provides detailed information about the function and position of genes. We used a version of the LocusLink database containing 128,580 entries. Our system does not utilize the full LocusLink information but only the following fields of a LocusLink record:</p><p>• OFFICIAL SYMBOL: the officially approved symbol for this gene;</p><p>• PREFERRED SYMBOL: a symbol that might become the official symbol in the future, but has not been validated by the nomenclature committee yet;</p><p>• OFFICIAL GENE NAME: the official name of the gene;</p><p>• PREFERRED GENE NAME: similar to the PREFERRED SYMBOL field;</p><p>• ALIAS SYMBOL: an alias that is sometimes used to refer to the gene;</p><p>• PRODUCT: the protein product of the transcript.</p><p>A gene can be found in the database by searching for its official symbol, its preferred symbol, one of its aliases, or its protein product. The product is included in this list because genes and their products are often treated as synonyms. Narrow synonyms do not get a special treatment in the LocusLink data because that information in many cases is already included in the ALIAS SYMBOL fields of a gene record.</p><p>Some LocusLink records also provide a PMID field that contains a list of PubMed articles related to the gene. This information could have been very beneficial if used in an appropriate way. However, it was not clear to us if these fields are of sufficiently high quality and how exactly we could make good use of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Expansion validation</head><p>In stage 2, the results of the first stage are combined using an interleaving fusion technique described by Yeung et al. [YCC + 03]. From each of the three documents lists generated in stage 1, one document is picked in turn and added to the new document list. Duplicates are removed from the result.</p><p>The new document list is used to validate the expansion terms in the following way: The system takes ID: 14 TITLE: Expression or Regulation of TGFB in HNSCC cancers NEED: Documents regarding TGFB expression or regulation in HNSCC cancers. QUERY_TITLE: "expression" "regulation" "tgfb" "hnscc" "cancers" EXPANDED_TITLE: #1.00 "expression" #1.00 "regulation" #0.45 "tgfb" #0.95 ("tgfb"+"tgf beta"+"beta tgf"+"tgfbeta"+"tgfb1"+"tgfb2"+"tgfb3") #0.45 "hnscc" #0.95 ("hnscc"+"head and neck squamous cell") #1.00 "cancers" QUERY_NEED: "regarding" "tgfb" "expression" "regulation" "hnscc" "cancers" EXPANDED_NEED: #1.00 "regarding" #0.45 "tgfb" #0.95 ("tgfb"+"tgf beta"+ "beta tgf"+"tgfbeta"+"tgfb1"+"tgfb2"+"tgfb3") #0.45 "hnscc" #0.95 ("hnscc"+"head and neck squamous cell") #1.00 "cancers"</p><p>Figure <ref type="figure" coords="6,178.29,175.79,3.90,9.96">4</ref>: Example topic in stage 2 (with query-specific term weights q T ) the first 150 documents from the result list produced by stage 1 and tries to match them against the expansion terms generated by the expansion techniques described in section 4. Furthermore, it looks for permutations of expansion terms in the documents returned. This is done because the name of the protein that belongs to a certain gene is often a permutation of the gene name. The Homo sapiens gene "glucosidase, alpha; acid", for instance, encodes the "acid alpha-glucosidase" preprotein.</p><p>The documents are scanned for the expansion terms or term sequences, and the number of occurrences is counted for every expansion. For every original query term, the best 10 expansions are kept. This set of remaining expansion candidates is then further restricted by removing all expansions that have less than 1% of the occurrences of the top candidate. The remaining expansions are combined into a new disjunctive query element that is added to the original query.</p><p>Terms for which an expansion has been found, are given a reduced term weight q T = 0.45. However, the set of validated expansions gets a weight q T = 0.95, so the total weight of the term increases to q T,total = 1.4. The idea behind this weight increase is the assumption that terms for which we have an expansion are likely to be key elements of the original query. Having the original term appear twice in the resulting query (once by itself, once in the disjunction) is intended to keep query drift low. Query terms for which no expansion could be found get the default term weight q T = 1.0.</p><p>The result of the validation process is shown in figure 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Pseudo-relevance feedback</head><p>In stage 3 of our retrieval system, we expand the query produced in stage 2 by using the results of three difference pseudo-relevance feedback (PRF) algorithms. The output of each PRF process is a vector of term-score pairs. All terms that are already part of the old query (either exactly or in a stem-equivalent form) are removed from the vectors. The results are merged using the normalized Comb-SUM fusion algorithm [Lee97] <ref type="bibr" coords="6,451.10,342.59,26.00,9.96" target="#b10">[SF94]</ref>.</p><p>From the merged term vector, the best 10 candidates are taken and added to the old query with query-specific term weights</p><formula xml:id="formula_7" coords="6,391.08,403.19,149.98,10.34">q T = 0.3 • score T ,<label>(5)</label></formula><p>where score T is the feedback score of the term T . Because feedback scores are normalized, the topscoring feedback term will have weight 0.3 in the resulting expanded query.</p><p>In the following sections we explain the computation of the feedback scores for each of the three feedback techniques employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Passage feedback</head><p>The passage feedback algorithm used by our system creates a vector of expansion candidate terms from a list of scored passages (nodes "MultiText QAP" and "Passage Feedback" in Figure <ref type="figure" coords="6,449.74,592.55,3.88,9.96">2</ref>). It is based on the QAP passage scoring algorithm described in section 2 and has successfully been used by the MultiText group in TREC 2003 [YCC + 03].</p><p>The algorithm takes the top 100 documents, as returned by MultiText's QAP, and examines the neighborhood of the best passage within each document. Every time the algorithm encounters a certain term T within that neighborhood, the score of that term is increased:</p><formula xml:id="formula_8" coords="7,98.28,67.52,192.06,23.45">score T := score T + log 2 ( N f T ) -log 2 (l), (<label>6</label></formula><formula xml:id="formula_9" coords="7,290.34,73.79,4.23,9.96">)</formula><p>where N is the corpus size, f T the number of occurrences of T in the corpus, and l is the size of the minimum window that contains both the relevant passage and the term T . If, for example, the relevant passage in the document were "Bart Simpson" and the neighborhood "This is Bart Simpson with his sister Lisa", the size of the minimum window for the term "sister" would be 5. Obviously, this passage feedback algorithm was inspired by the original QAP scoring function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Document feedback</head><p>The document feedback is similar to the passage feedback. However, it examines entire documents instead of passage neighborhoods. In addition, the document feedback algorithm does not assume that all documents returned by the previous stage are equally relevant. Instead, it gives different weights to the input documents according to their rank and score in the previous stage.</p><p>The algorithm examines the top 100 documents, as returned by BM25 in stage 2. For every term T that appears within a document D, the feedback score of that term is increased:</p><formula xml:id="formula_10" coords="7,87.24,415.64,207.34,23.45">score T := score T + w D • log 2 ( N f T • len D ),<label>(7)</label></formula><p>where w D is the feedback weight of the document D.</p><p>After trying several document weighting schemes, we decided to use the following formula:</p><formula xml:id="formula_11" coords="7,134.52,487.84,155.83,11.97">w D = score D • c rankD . (<label>8</label></formula><formula xml:id="formula_12" coords="7,290.35,489.47,4.23,9.96">)</formula><p>score D is the document BM25 document score, rank D is the document rank in the result list produced by stage 2, and c &lt; 1 is chosen in such a way that</p><formula xml:id="formula_13" coords="7,150.60,553.99,143.98,30.29">10 i=1 c i = 100 i=11 c i ,<label>(9)</label></formula><p>i.e., the first 10 documents have the same cumulated weight as the following 90 documents. This weighting function assumes that the results produced in stage 2 are already of high quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Google feedback</head><p>While the two feedback techniques described so far rely on the quality of the previous query and the text found in the Medline corpus, our feedback system includes a third technique that uses Google as a source of expansion terms.</p><p>The NEED part of the original query, stop words removed, is sent to Google. The document snippets returned are considered ordinary documents, and for every term T appearing in a Google snippet S, the term score is updated in the same way as above:</p><formula xml:id="formula_14" coords="7,342.72,170.24,146.76,23.45">score T := score T + log 2 ( N f T • len S</formula><p>).</p><p>(10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Species names</head><p>After the feedback process has finished, a final filtering is performed on the list of documents returned. The filter does not cause any changes to the document ranks unless our system has found one or more species names in the original query.</p><p>For example, if the original query contains the terms "human" and "mice", then the filter will try to match the documents against the strings "human", "humans", "homo sapiens", "mouse", "mice", and "mus musculus". The filter is based on a manually created list of 11 species names (and synonyms) that frequently appear in biomedical publications. The idea behind this process is that a species name that appears in a topic is most probably a key word.</p><p>The actual filtering is based on the interleave fusion technique. From the list of documents D returned by BM25, two lists are created:</p><p>• D pos consists of all documents that contain at least one of the search strings;</p><p>• D neg contains all the remaining documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation</head><p>We submitted two runs for the Genomics track. The first run only made use of the NEED field of the given topics. The second run considered TITLE and NEED.</p><p>If a query term appeared in both TITLE and NEED, it was simply given twice the normal term weight (q T = 2.0). The results of our runs are shown in Table <ref type="table" coords="7,344.73,693.83,3.90,9.96" target="#tab_1">1</ref>. After the runs had been submitted, we found a bug in the validation part of our retrieval system that gave a validation score to the first term in a document n times as high as to the last term, where n is the length of the document. All experiments discussed in this section have been conducted with the corrected version of the validation algorithm. For comparison, we have included both versions (with and without the bug) in Table <ref type="table" coords="8,201.63,424.19,3.90,9.96" target="#tab_1">1</ref>. It can be seen from the table that using the TITLE as well improves the quality of the results dramatically over the NEEDonly run. For the further discussion, we will only consider TITLE+NEED runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">System components</head><p>This section deals with the retrieval effectiveness of the individual stages of our system. Table <ref type="table" coords="8,260.61,550.31,5.03,9.96">2</ref> shows the major trec eval values for the intermediate results produced by each stage of our document retrieval system. The first row (1/BM25,plain) contains the BM25 baseline, i.e., the results produced by an unexpanded query (stop words removed), where documents have been scored by BM25. The last row contains the results for the final document list obtained after species names filtering. We can see that both the number of relevant documents retrived and the mean average precision (MAP) increase significantly, from 4,811 to 5,534 (15.0% improvement) and from 0.3353 to 0.3895 (16.2% im-provement), respectively.</p><p>From the intermediate values, we can also conclude that the domain-specific query expansion techniques applied in stage 1 and stage 2 constitute a little more than half of this improvement (5,315 relevant documents retrieved, 0.3639 MAP), while the pseudorelevance feedback performed in stage 3 is responsible for the other half.</p><p>Additional experiments have shown that the effectiveness of the second stage is primarily caused by the generation of permutations of query terms/expansions, not by throwing away infrequent expansions.</p><p>Perhaps more interesting than the mean average precision, from the point of view of an actual person who has to look at the documents retrieved by our system, is the precision after 20 documents. This value increases from 0.530 (plain BM25 query) to 0.585 (final result), which is a 10.4% improvement.</p><p>From Table <ref type="table" coords="8,371.36,301.67,5.03,9.96">2</ref> we can also see that the final species names filtering process could not improve the results in the expected way. We will investigate this phenomenon in section 8.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Domain-specific knowledge</head><p>It is clear by now that domain-specific query expansion is beneficial for the effectiveness of our document retrieval system. However, we do not know yet which part of our domain-specific query expansion method is the major factor for the improvement seen. Therefore, we have conducted some additional experiments in which we have selectively disabled certain parts of the query expansion subsystem.</p><p>From the results shown in Table <ref type="table" coords="8,474.62,502.55,5.03,9.96" target="#tab_2">3</ref> (in comparison with Table <ref type="table" coords="8,388.63,514.43,4.43,9.96">2</ref>) we see that the general heuristics we employed when generating lexical variants are responsible for the biggest improvement. The second best contributor is the AcroMed acronym database, which causes an improvement of 4.8% over the Heuristics only run. It is surprising that adding gene information from euGenes and LocusLink deteriorates the mean average precision (comparing rows Heuristics&amp;AcroMed and All of the above in Table <ref type="table" coords="8,317.28,622.07,3.88,9.96" target="#tab_2">3</ref>), although the additional data increases the recall from 5,284 to 5,315 relevant documents. We believe that this is mainly because the number of alias symbols provided by the LocusLink database is overwhelming. For the term "TGFB" in topic 14, for instance, the expansion techniques in stage 1 produce 185 candidates (including lexical variants). For </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Pseudo-relevance feedback</head><p>Pseudo-relevance feedback could increase the MAP by 8.1% and the recall by 4.1% over the results produced in stage 2 in our experiments (cf. Table <ref type="table" coords="9,282.92,436.19,3.88,9.96">2</ref>). Since we have utilized three different PRF methods, it is interesting to see which method had the greatest impact.</p><p>Table <ref type="table" coords="9,100.78,495.35,5.03,9.96">4</ref> shows that passage feedback and document feedback were very effective. We can also see that the combination of both methods (row Pas-sage&amp;Doc.) produced even better results than each technique taken alone. On the other hand, Google feedback performed really poorly. It is not clear what caused Google to deliver much worse results than the other feedback methods.</p><p>We can, however, identify at least two potential problems related with the use of Google:</p><p>• Google only supports exact boolean searches. While this is acceptable for short queries (3-5 terms), it can be problematic when dealing with longer queries.</p><p>• Queries are cut off after the 10th term. This does not only mean that we cannot send ex-panded queries to Google, but even unexpanded queries might be too long. In fact, this was the case for 10 of the 50 topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Species names</head><p>The results shown in Table <ref type="table" coords="9,444.99,131.87,5.03,9.96">2</ref> suggest that the final filtering process performed after the pseudorelevance feedback could not improve the performance of our system and did even decrease its precision. To understand what happened during the filtering process, it is necessary to look at individual topics: Our system could identify species names in 15 out of 50 topics. For 9 of these 15 topics a slight improvement was caused by the filtering, for 4 topics nothing changed, and for the remaining 2 topics the average precision dropped radically (0.8870 to 0.7971 and 0.9478 to 0.7870). Because of the unusually high precision before the filtering, these two topics cannot be considered representative.</p><p>Hence, the filtering seems to have a slightly positive impact on the precision for topics with low or medium precision. We did not expect precision values above 70% when designing the filtering algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Expansion term weights</head><p>In stage 2 and 3, as shown in Figure <ref type="figure" coords="9,492.59,409.67,3.90,9.96">4</ref>, our system gives a term weight q T = 0.45 to a term T for which we have an expansion. The disjunctive query element (the expansion) that is derived from the original term is given the weight q T = 0.95. Due to the lack of training data, we could not validate the choice of these parameters. Additional experiments conducted after the qrels for the topics had been released showed that by setting q T := 0.9 and q T := 0.5 the MAP could have been increased:</p><p>• from 0.3639 to 0.3740 in stage 2;</p><p>• from 0.3935 to 0.4042 in stage 3.</p><p>This increase, however, carries the cost of a slightly decreased recall (5,253 down from 5,315 documents and 5,519 from 5,534 documents, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions &amp; Future work</head><p>For the TREC 2004 Genomics track, we have implemented a number of different query expansion techniques, based on simple heuristics generating lexical variants of query terms, domain-specific knowledge used to find synonyms and acronym expansions, and pseudo-relevance feedback. We have shown that most of the techniques utilized by our system improved recall and precision.</p><p>From the sources we employed for knowledge-based query expansion, the AcroMed database of biomedical acronyms produced expansions of highest quality, outperforming both the euGenes and LocusLink genetic databases.</p><p>Since the domain-specific knowledge in the genomics domain can be used to produce a very large number of possible synonyms for initial query terms, techniques to validate these expansions have to be found. We presented a simple way that can be used to verify that an expansion term appears in the context we are interested in by looking at the results of an early retrieval stage. Better techniques for expansion validation, probably based on language model approaches, are desirable.</p><p>Our experiments with Google as a source of pseudorelevance feedback were a little disappointing, since Google performed worse than either of the two other feedback methods. Nonetheless, we will keep using Google for this purpose and try to find a way to circumvent the problems created by Google's restricted query interface. We will also study how our own web corpus, which is about 1 terabyte of publicly available text data, can be used to produce high-quality expansion terms in the special context of biomedical publications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,204.00,175.79,203.85,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example topic in original XML form</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,140.64,185.75,330.54,9.96"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example topic after preprocessing and query expansion in stage 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,89.86,165.11,204.57,9.96;5,70.92,176.99,223.72,9.96;5,70.92,188.99,130.09,9.96;5,201.12,188.23,6.12,5.45;5,207.60,188.99,87.04,9.96;5,70.92,200.99,223.57,9.96;5,70.92,212.87,223.49,9.96"><head></head><label></label><figDesc>used three different sources to deal with the above kinds of synonyms: The AcroMed database of biomedical acronyms [PCC + 01] [Acr04], the Eukaryotic Genes database at the University of Indiana [Gil02] [euG04], and the LocusLink database [LL04].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,317.28,508.67,7.67,9.96;7,324.96,512.68,11.75,6.33;7,340.32,508.67,26.74,9.96;7,367.08,512.68,12.47,6.33;7,383.40,508.67,157.55,9.96;7,317.28,520.67,154.08,9.96;7,471.48,524.68,11.75,6.33;7,486.36,520.67,54.79,9.96;7,317.28,532.55,60.44,9.96;7,377.76,536.56,12.47,6.33;7,393.72,532.55,147.49,9.96;7,317.28,544.55,39.92,9.96;7,357.24,548.56,11.75,6.33;7,373.92,544.55,28.06,9.96;7,402.00,548.56,12.47,6.33;7,415.32,544.55,125.66,9.96;7,317.28,556.55,214.62,9.96"><head>D</head><label></label><figDesc>pos and D neg are merged into a new document list D by taking two documents from D pos and one document from D neg in turn. Depending on the relative size of D pos and D neg , the filtering may leave the document order untouched or change it radically.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,70.92,53.31,393.01,317.60"><head>Google Feedback Passage Feedback Document Feedback Term Fusion (CombSUM) Query Expansion MultiText BM25 Species Names Filtering Final Result Stage 1 Stage 2 Stage 3</head><label></label><figDesc></figDesc><table coords="3,70.92,53.31,393.01,317.60"><row><cell></cell><cell></cell><cell></cell><cell cols="2">Query Expansion</cell></row><row><cell>Topic (XML text)</cell><cell>Parsing, Stop Word Removal</cell><cell cols="2">Acronym/Synonym Finder (AcroMed, EuGenes, LocusLink)</cell><cell>Species Names Finder</cell><cell>Variant Generator</cell></row><row><cell>Unexpanded</cell><cell></cell><cell>MultiText</cell><cell>Expanded</cell><cell></cell></row><row><cell>Query</cell><cell></cell><cell>BM25</cell><cell>Query</cell><cell></cell><cell>Legend</cell></row><row><cell></cell><cell>MultiText</cell><cell></cell><cell>MultiText</cell><cell></cell><cell>Query</cell></row><row><cell></cell><cell>QAP</cell><cell></cell><cell>BM25</cell><cell></cell><cell>Process</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Expansion</cell></row><row><cell></cell><cell></cell><cell>Doc. Fusion</cell><cell>Expansion Validator,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>(Interleave)</cell><cell>Permutation Finder</cell><cell></cell></row><row><cell></cell><cell></cell><cell>MultiText</cell><cell>Expanded</cell><cell></cell></row><row><cell></cell><cell></cell><cell>BM25</cell><cell>Query</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">(Pseudo-Relevance Feedback)</cell><cell></cell></row><row><cell></cell><cell cols="4">Figure 2: The document retrieval system</cell></row><row><cell cols="3">of the term T in the corpus. H(P ) is called the</cell><cell></cell><cell></cell></row><row><cell cols="2">self-information of the passage P .</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,70.92,58.67,224.03,234.83"><head>Table 1 :</head><label>1</label><figDesc>Results for NEED-only and TITLE+NEED runs (50 topics, 8,268 relevant documents; "*": bugfixed versions)</figDesc><table coords="8,70.92,99.70,223.57,193.80"><row><cell>Run</cell><cell cols="3">Recall Avg.prec. R-Prec.</cell></row><row><cell>NEED</cell><cell>5,082</cell><cell>0.3318</cell><cell>0.3630</cell></row><row><cell>TITLE+NEED</cell><cell>5,544</cell><cell>0.3867</cell><cell>0.4037</cell></row><row><cell>NEED*</cell><cell>5,094</cell><cell>0.3394</cell><cell>0.3716</cell></row><row><cell>TITLE+NEED*</cell><cell>5,534</cell><cell>0.3895</cell><cell>0.4046</cell></row><row><cell cols="4">Table 2: Intermediate results for TITLE+NEED run</cell></row><row><cell cols="2">(default parameters)</cell><cell></cell><cell></cell></row><row><cell cols="4">Stage/Process Recall Avg.prec. R-Prec.</cell></row><row><cell>1/BM25,plain</cell><cell>4,811</cell><cell>0.3353</cell><cell>0.3707</cell></row><row><cell>1/BM25,exp.</cell><cell>4,772</cell><cell>0.2775</cell><cell>0.3138</cell></row><row><cell>1/QAP,plain</cell><cell>3,892</cell><cell>0.2782</cell><cell>0.3215</cell></row><row><cell>2/BM25</cell><cell>5,315</cell><cell>0.3639</cell><cell>0.3845</cell></row><row><cell>3/BM25,PRF</cell><cell>5,534</cell><cell>0.3935</cell><cell>0.4108</cell></row><row><cell>3/Filtering</cell><cell>5,534</cell><cell>0.3895</cell><cell>0.4046</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,70.92,58.67,223.73,304.08"><head>Table 3 :</head><label>3</label><figDesc>Comparison of domain-specific knowledge (results after stage 2)</figDesc><table coords="9,70.92,87.70,223.72,275.05"><row><cell>Technique</cell><cell cols="3">Recall Avg.prec. R-Prec.</cell></row><row><cell>Heuristics only</cell><cell>5,230</cell><cell>0.3550</cell><cell>0.3832</cell></row><row><cell>Heu.&amp;AcroMed</cell><cell>5,284</cell><cell>0.3722</cell><cell>0.4059</cell></row><row><cell>Heu.&amp;euGenes</cell><cell>5,253</cell><cell>0.3554</cell><cell>0.3827</cell></row><row><cell>Heu.&amp;Loc.Link</cell><cell>5,288</cell><cell>0.3631</cell><cell>0.3843</cell></row><row><cell>All of the above</cell><cell>5,315</cell><cell>0.3639</cell><cell>0.3845</cell></row><row><cell cols="4">Table 4: Comparison of pseudo-relevance feedback</cell></row><row><cell>methods</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="3">Recall Avg.prec. R-Prec.</cell></row><row><cell>Passage PRF</cell><cell>5,470</cell><cell>0.3889</cell><cell>0.4092</cell></row><row><cell>Document PRF</cell><cell>5,528</cell><cell>0.3924</cell><cell>0.4065</cell></row><row><cell>Google PRF</cell><cell>5,370</cell><cell>0.3708</cell><cell>0.3942</cell></row><row><cell>Passage&amp;Doc.</cell><cell>5,559</cell><cell>0.3957</cell><cell>0.4128</cell></row><row><cell>All of the above</cell><cell>5,534</cell><cell>0.3935</cell><cell>0.4108</cell></row><row><cell cols="4">"P53" in topic 22, they come up with a set of 176</cell></row><row><cell cols="4">candidates. This high number of expansion terms</cell></row><row><cell cols="4">entails two possible risks: reduction of the weight of</cell></row><row><cell cols="3">the original query term and query drift.</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,116.26,575.06,178.09,8.97;10,116.28,585.98,166.42,8.97;10,116.28,596.90,20.74,8.97" xml:id="b0">
	<analytic>
		<title/>
		<ptr target="http://medstract.med.tufts.edu/acro1.1/" />
	</analytic>
	<monogr>
		<title level="j" coord="10,116.26,575.06,156.62,8.97">The Medstract Project -AcroMed</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,116.26,612.86,178.09,8.97;10,116.28,623.78,178.19,8.97;10,116.28,634.82,178.19,8.97;10,116.28,645.74,178.32,8.97;10,116.28,656.66,135.13,8.97" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,231.04,623.78,63.43,8.97;10,116.28,634.82,178.19,8.97;10,116.28,645.74,75.34,8.97">An Algebra for Structured Text Search and a Framework for its Implementation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Forbes</forename><forename type="middle">J</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Burkowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-08">August 1994</date>
			<publisher>University of Waterloo</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="10,116.26,672.62,178.09,8.97;10,116.28,683.66,178.42,8.97;10,116.28,694.58,177.94,8.97;10,362.76,52.58,178.25,8.96;10,362.76,63.50,178.16,8.96;10,362.76,74.42,178.03,8.97;10,362.76,85.46,83.70,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,219.77,683.66,74.93,8.97;10,116.28,694.58,120.15,8.97">Exploiting Redundancy in Question Answering</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,261.39,694.58,32.84,8.96;10,362.76,52.58,178.25,8.96;10,362.76,63.50,178.16,8.96;10,362.76,74.42,128.42,8.96">Proceed-ings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>eed-ings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2001-11">November 2001</date>
			<biblScope unit="page" from="358" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,362.75,98.54,178.09,8.97;10,362.76,109.46,178.43,8.97;10,362.76,120.38,178.19,8.97;10,362.76,131.42,177.89,8.97;10,362.76,142.34,40.16,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,474.17,109.46,67.02,8.97;10,362.76,120.38,135.61,8.97">Relevance Ranking for One to Three Term Queries</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elizabeth</forename><forename type="middle">A</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tudhope</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,505.35,120.38,35.61,8.96;10,362.76,131.42,128.67,8.96">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="311" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,362.74,155.42,178.27,8.97;10,362.76,166.34,129.02,8.97" xml:id="b4">
	<monogr>
		<ptr target="http://eugenes.org/" />
		<title level="m" coord="10,362.74,155.42,178.27,8.97;10,362.76,166.34,15.92,8.97">Genomic Information for Eukaryotic Organisms</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,362.74,179.42,178.31,8.97;10,362.76,190.34,178.16,8.97;10,362.76,201.26,122.76,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,447.52,179.42,93.53,8.97;10,362.76,190.34,113.95,8.97">euGenes: A Eukaryote Genome Information System</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><forename type="middle">G</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,486.02,190.34,54.90,8.96;10,362.76,201.26,33.13,8.96">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="148" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,362.75,214.34,178.32,8.97;10,362.76,225.38,178.14,8.97;10,362.76,236.30,178.04,8.96;10,362.76,247.22,178.15,8.96;10,362.76,258.26,178.05,8.97;10,362.76,269.18,20.74,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,418.52,214.34,122.55,8.97;10,362.76,225.38,49.79,8.97">Analyses of Multiple Evidence Combination</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,431.71,225.38,109.19,8.96;10,362.76,236.30,178.04,8.96;10,362.76,247.22,178.15,8.96;10,362.76,258.26,54.45,8.96">Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,322.77,352.22,16.46,8.97;10,339.24,351.28,5.64,4.65;10,345.60,352.22,195.32,8.97;10,362.76,363.14,177.97,8.97;10,362.76,374.06,178.19,8.97;10,362.76,385.10,178.19,8.97;10,362.76,396.02,178.17,8.97;10,362.76,406.94,178.12,8.96;10,362.76,417.86,178.12,8.96;10,362.76,428.90,66.31,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,454.85,374.06,86.10,8.97;10,362.76,385.10,178.19,8.97;10,362.76,396.02,137.55,8.97">Linguistic Knowledge Extraction from Medline: Automatic Construction of an Acronym Database</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jose</forename><surname>Castano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brent</forename><surname>Cochran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maciej</forename><surname>Kotecki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Morrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,413.35,406.94,127.53,8.96;10,362.76,417.86,174.06,8.96">Proceedings of the 10th World Congress on Health and Medical Informatics</title>
		<meeting>the 10th World Congress on Health and Medical Informatics</meeting>
		<imprint>
			<date type="published" when="2001-09">2001. September 2001</date>
		</imprint>
	</monogr>
	<note>PCC + 01</note>
</biblStruct>

<biblStruct coords="10,362.74,487.82,178.09,8.97;10,362.76,498.86,178.04,8.97;10,362.76,509.78,178.17,8.96;10,362.76,520.70,92.43,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,362.76,498.86,73.45,8.97">Okapi at TREC-7</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,465.29,498.86,75.52,8.96;10,362.76,509.78,178.17,8.96;10,362.76,520.70,20.76,8.96">Proceedings of the Seventh Text REtrieval Conference (TREC 1998)</title>
		<meeting>the Seventh Text REtrieval Conference (TREC 1998)</meeting>
		<imprint>
			<date type="published" when="1998-11">November 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,322.89,533.78,16.82,8.97;10,339.72,532.84,5.64,4.65;10,345.96,533.78,194.89,8.97;10,362.76,544.70,178.08,8.97;10,362.76,555.74,178.04,8.97;10,362.76,566.66,178.18,8.96;10,362.76,577.58,92.43,8.97" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,362.76,555.74,73.45,8.97">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">S</forename><surname>Rwj + 94</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,465.29,555.74,75.52,8.96;10,362.76,566.66,178.18,8.96;10,362.76,577.58,20.76,8.96">Proceedings of the Third Text REtrieval Conference (TREC 1994)</title>
		<meeting>the Third Text REtrieval Conference (TREC 1994)</meeting>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,362.75,590.66,178.20,8.97;10,362.76,601.70,177.94,8.97;10,362.76,612.62,178.04,8.96;10,362.76,623.54,125.53,8.97" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,519.00,590.66,21.94,8.97;10,362.76,601.70,120.17,8.97">Combination of Multiple Searches</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,507.86,601.70,32.84,8.96;10,362.76,612.62,178.04,8.96;10,362.76,623.54,53.86,8.96">Proceedings of the Third Text REtrieval Conference (TREC 1994)</title>
		<meeting>the Third Text REtrieval Conference (TREC 1994)</meeting>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,322.95,636.62,17.01,8.97;10,339.96,635.68,5.64,4.65;10,346.20,636.62,194.76,8.97;10,362.76,647.54,178.32,8.97;10,362.76,658.58,178.31,8.97;10,362.76,669.50,178.14,8.97;10,362.76,680.42,178.28,8.97;10,362.76,691.46,20.74,8.97" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,439.40,658.58,101.67,8.97;10,362.76,669.50,29.06,8.97">Task-Specific Query Expansion</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Egidio</forename><forename type="middle">L</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Terra</surname></persName>
		</author>
		<idno>YCC + 03</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,410.48,669.50,130.42,8.96;10,362.76,680.42,130.23,8.96">Proceedings of the 12th Text REtrieval Conference (TREC 2003)</title>
		<meeting>the 12th Text REtrieval Conference (TREC 2003)</meeting>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
