<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,105.18,76.51,384.99,16.20;1,101.71,97.51,391.93,16.20">Sheffield University and the TREC 2004 Genomics Track: Query Expansion Using Synonymous Terms</title>
				<funder ref="#_qjjqtha">
					<orgName type="full">Medical Research Council</orgName>
				</funder>
				<funder ref="#_Tu3XPyb">
					<orgName type="full">UK Engineering and Physical Sciences Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.84,136.20,45.91,9.88"><forename type="first">Yikun</forename><surname>Guo</surname></persName>
							<email>guo@dcs.shef.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.83,136.20,64.28,9.88"><forename type="first">Henk</forename><surname>Harkema</surname></persName>
							<email>harkema@dcs.shef.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.26,136.20,71.21,9.88"><forename type="first">Rob</forename><surname>Gaizauskas</surname></persName>
							<email>gaizauskas@dcs.shef.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,105.18,76.51,384.99,16.20;1,101.71,97.51,391.93,16.20">Sheffield University and the TREC 2004 Genomics Track: Query Expansion Using Synonymous Terms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E77158B21284FCF779662B77087B3DBA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this paper we describe our approach to the Ad Hoc Retrieval task of the TREC 2004 Genomics Track. This is a conventional searching task based on a 10-year subset of MEDLINE (about 4.5 million documents and 9 gigabytes in size) and 50 topics derived from information needs obtained via interviews of real biomedical researchers. We will also discuss the results of our submitted runs. The hypothesis we want to test is whether the performance on this particular retrieval task can be improved by expanding queries with synonyms of the original query terms. We use the UMLS Metathesaurus, a comprehensive collection of controlled vocabularies in the biomedical domain, to identify query terms in topics and to determine their synonyms. Our approach is simple in the sense that we only consider synonyms of query terms and do not exploit hierarchical relations between terms such as hyponomy and hyperonymy. Synonymy-based query expansion generally increases recall, but decreases precision due to ambiguous terms. Word senses of ambiguous terms which are inappropriate with regard to the topic under consideration give rise to "polluting" synonyms. We hope that the use of a specifically biomedical term resource such as UMLS will limit the negative effects synonymy-based query expansion may have on precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head><p>In this section we describe how we derive a set of query terms from a given topic and how this set is used by the Information Retrieval engine to find a set of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Generating Query Terms General Approach</head><p>Our general approach is to identify terms in a topic, where is term is understood to be a (multi-word) expression that is relevant in the domain under consideration. Given a set of terms for a topic, we expand this set by finding synonyms for these terms. The terms together with their synonyms will serve as the query terms that are submitted to the Information Retrieval engine. To identify terms in topics and to find their synonyms we rely on the UMLS Metathesaurus (Humphreys et al., 1998). The UMLS Metathesaurus provides a semantic classification of terms from a wide range of vocabularies in the clinical and biomedical domain. It currently contains well over 2 million distinct English terms. Since the Ad Hoc Retrieval task involves searching over MEDLINE abstracts using topics derived from information needs of biomedical researchers, we assume that the UMLS Metathesaurus is a useful source of domain-relevant terms (see McCray et   al. (2001) for more discussion of this issue). To map a given topic to the Metathesaurus, we use the MetaMap program (Aronson, 2001). Using linguistic knowledge of various kinds, MetaMap identifies UMLS terms and variant forms of these terms in free text. For each term it finds, MetaMap will return one or more unique concept identifiers (CUIs) for that term.<ref type="foot" coords="2,224.82,136.15,3.51,6.32" target="#foot_0">1</ref> Given the CUIs of a term, we look in the UMLS Metathesaurus for all other terms that are assigned at least one of these CUIs: these terms form the set of synonyms for the original term. A quick inspection of the performance of MetaMap on the five sample topics provided with the data for the Ad Hoc retrieval task revealed that it did not identify all relevant terms in these topics. In particular, it did not pick up protein and gene names such as p63 and MTP1. It also missed other potentially relevant terms, e.g., tumorogenesis and inflammatory perturbation. In order to remedy this problem, we employed a chunker (LT CHUNK<ref type="foot" coords="2,340.50,245.34,3.51,6.32" target="#foot_1">2</ref> ) to find NP chunks and symbols to be used as additional query terms. Symbols in LT CHUNK include single, non-numerical characters and certain punctuation marks that cannot be classified otherwise, as well as sequences of characters containing at least one alphabetic character and at least one numeric character. We only retained symbols of length greater than 1; these are assumed to be protein and gene names. Using the procedure outlined above, we find, on average, 9.4 UMLS Metathesaurus terms per topic, and 9.2 LT chunks per topic. <ref type="bibr" coords="2,241.38,338.95,3.51,6.32">3</ref> Each UMLS term generates approximately 5.4 synonymous terms from UMLS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filtering</head><p>The UMLS Metathesaurus is a comprehensive resource, containing all sorts of terms. Not all of these terms are useful for text processing in general or for a given application in particular. For this reason we apply two sets of filters to potential search terms. First, terms identified by MetaMap are ignored if they occur in a short, manually assembled list of stop words. This list contains words matched by MetaMap which are too general to be useful, e.g., information, researcher, retrieve, literature. We have also identified a set of semantic types (TUIs) in the UMLS Semantic Network which we a priori judged to be irrelevant to the domain. This list contains semantic types such as "Daily or Recreational Activity", "Professional or Occupational Group", and "Manufactured Object". Any term such that all of its CUIs are assigned to irrelevant semantic types is ignored for further processing. Terms making it through the stop word filter and the irrelevant semantic type filter will be considered for synonym expansion. The second set of filters applies to the set of synonyms generated for a given term. This set of filters is based on Aronson (2003). A synonym is removed in the following cases:</p><p>1. The synonym is a "bad" string, i.e., because of its form it is very unlikely to appear in a MEDLINE abstract. Strings that contain punctuation marks such as "=" and "!" are considered bad strings. Additionally, strings that contain classificatory elements such as "not elsewhere classified", "not otherwise specified" are removed.</p><p>2. The synonym belongs to a "bad" UMLS term type. Bad term types indicate strings that are inappropriate for text processing (see Aronson (2003) for further details). 3. The synonym is marked as a "suppressible synonym" in UMLS. Suppressible synonyms are usually short forms of terms that give rise to problematic cases of ambiguity, e.g., Abdomen is a suppressible synonym of Malignant neoplasm of abdomen. 4. The synonym consists of more than five words, e.g., solute carrier family 11 (proton-coupled divalent metal ion transporters).<ref type="foot" coords="3,333.48,167.35,3.51,6.32" target="#foot_3">4</ref> 5. The synonym is string-identical to the term it is a synonym of.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Information from UMLS</head><p>Besides supplying CUIs for identifying synonyms of terms, the UMLS Metathesaurus provides other information that can be used when preparing sets of query terms. The previous section already illustrated the use of semantic types from the UMLS Semantic Network to discard irrelevant terms. Semantic types can also be used in a positive way to mark up terms that are especially important to the domain under consideration. The Information Retrieval engine can use this mark-up to assign extra weight to the query terms concerned or to filter the document collection. We did not exploit this possibility in our current system. One of the sources included in UMLS is the Medical Subject Headings controlled vocabulary of biomedical terms (MeSH). This enables us to recognize MeSH terms in topics and identify which of a term's synonyms are MeSH terms. <ref type="bibr" coords="3,271.92,375.13,3.51,6.32">5</ref> This information can be used by the Information Retrieval engine for matching against the MeSH fields of MEDLINE citations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Document Retrieval Corpus Indexing</head><p>The document collection for the Ad Hoc retrieval task is a 10-year subset of the MEDLINE bibliographic database, amounting to roughly 9 gigabytes of textual data. In order to search efficiently in this document collection we use the Lucene text search engine. <ref type="bibr" coords="3,412.74,496.33,3.51,6.32">6</ref> Lucene consists of a set of APIs providing high-performance, full-featured ranked searching functionality, implemented in Java. Because of its high efficiency and cross-platform usability, it has been widely used in many applications to provide full text search functionality. <ref type="bibr" coords="3,335.88,543.12,3.51,6.32">7</ref> One advantage of using Lucene is that one can specify different ways of indexing the various fields associated with a document. For example, adjunctive fields such as "PUBLISHING DATE", "AUTHORS", and "JOURNAL" etc., which are not relevant to the task, will be stored but not indexed and can be retrieved after a search. The contents of fields such as "TITLE", "ABSTRACT" and "MESH", however, will first go through a set of filters for stemming, removal of stop words, and tokenization, and will then be indexed. The whole index procedure requires just a few megabytes of memory. It runs with reasonable speed, about 350MB text per hour on an average Unix machine, for indexing the whole collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Construction</head><p>After the query terms have been identified and expanded as described in section 2.1, these terms are used to construct a query to be matched against the documents in the collection. Lucene supports field search, where one can specify which fields a query will be matched against. For example, the query "title:mouse" will restrict Lucene to search for the keyword mouse in title fields only, ignoring other fields. Terms consisting of multiple tokens, e.g., histoplasma capsulatum, are searched using the phrase operator, ensuring that the string is matched exactly. Query terms can be combined with Boolean operators, such as "AND", "OR" and "NOT" to form complex queries. In our experiment, multiple terms from the same topic are combined into one query using the "OR" operator. One of the factors determining the relative ranking of a document is the number of disjuncts in a complex query matching the document, where more matching disjuncts implies a higher rank. In addition, each query term can also be given a boosting factor to reflect its relative importance. Lucene will bias its search to those queries with high boosting factors. The relevant documents are returned in a descending order. In query construction, all three parts of a topic, i.e., title, information need and context, are treated equally and used to provide search terms. After merging repeated instances of terms, the terms are searched against both the title and abstract field of each MEDLINE abstract, except for the MeSH terms -these are searched against the MeSH field. Since we found that some noun phrases such as "protein", "genes" etc., are too general in the sense that searching for these terms retrieves too many documents, queries that return more than 10K documents are filtered out in the last step of the query construction process. This will prevent relevant matching documents from being overwhelmed by non-relevant matching documents. The queries used in the first run consist of terms identified by MetaMap and LT CHUNKER. For the second run, synonyms are added to the queries, using the "OR" operator. The queries containing the original keywords are given a boosting factor of 5, while the queries for the synonyms are given a boosting factor of 1. These factors were determined from experimentation with the five sample topics. Searching the document collection with Lucene is very fast. Given a query, Lucene will first pass it through the same filters that are used in the indexing step to do stemming, stop word removal, and tokenization. Next, it will retrieve a set of documents and compute their relevance scores. Typically, the whole process takes no more than 20 seconds per query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results and Discussion</head><p>We submitted two runs for the Ad Hoc Retrieval task. The first run is our baseline, where no synonyms were added to the query. The second run is with synonyms. Our hypothesis is that performance will improve by expanding queries using synonyms from UMLS. However, the various evaluation statistics indicate that performance does not differ very much between the two runs. As tables 1 and 2 show, the results of the second run are just slightly better than those of the first run. The non-interpolated average precision over all relevant documents for run 1 is 0.1294 vs. 0.1304 for run 2. Run 1 achieved an exact R-precision of 0.1632; the R-precision of run 2 is 0.1619. The total number of relevant documents retrieved over all topics is 2228 for run 1 and 2402 for run 2 (out of a total number of 8268 relevant documents). We also compared our results against the per-topic best, worst, and median scores of the participants; the performances of the two runs are not very good in terms of the average precision: only 10 and 9 topics out of the 50 topics making up the task are above the median respectively. However, with regard to the precision at 10 documents, our system does relatively well: there are 23 topics above the median and 5 of these are the best (they all achieved a precision of 1.0) for the second run. This suggests that our system performs relatively well at high precision side in the recall-precision graph. Graph 1 shows the interpolated recall-precision of our runs. Note that high precision at 10 documents is an important factor for information retrieval systems, where users will typically only inspect the top 10 documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall</head><p>Precision To analyze our results further, we grouped the query terms into three classes: 1) chunk terms obtained from the output of LT CHUNKER, 2) UMLS terms recognized by MetaMap and, 3) synonyms of the UMLS terms. We used each of these three classes of keywords to search directly against the sets of true relevant abstracts in order to count how many abstracts are retrieved. The resulting numbers can be viewed as the upper bound for our approach and can be used to evaluate the relative importance of each class of query terms. The results of this exercise are summarized in table 3. For each class of terms this table shows the total number of true abstracts retrieved using this class of terms only (# abstr. matched), the number of terms of this class identified in a topic (# terms), and the number of abstracts matched per term (ratio, i.e., (# abstr. matched) / (# terms)). All numbers are averaged over the 50 topics. For example, on average, the set of UMLS terms found in a topic matches 145.0 true relevant abstracts. Graph 1: Interpolated Recall-Precision Averages of our two runs Furthermore, we established that, averaged over all 50 topics, the set of UMLS terms and chunk terms for a topic matches 152.4 true relevant documents, whereas the set of synonyms for a topic only matches 5.0 additional documents, i.e., documents which are not already matched by the UMLS terms and the chunk terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall-Precision</head><p># We also studied the contribution of each of the three classes of terms in the context of the full retrieval task rather than their matching power against the set of true relevant documents. The results are shown in table 4: for each class of terms it provides the interpolated recall-precision averages over all queries, where these queries consist of terms from the class specified by the column only. <ref type="bibr" coords="6,149.04,638.47,3.51,6.32">8</ref> It is interesting to note that while the UMLS terms retrieve more relevant documents (2270) than the chunk terms (1838), using the latter class of terms produces higher precision scores at the first few recall levels. Using synonyms only returns 1057 relevant documents and precision levels are poor in this case. Comparing tables 1 and 4 we see that none of the three classes of terms used on their own outperforms run 1 (chunk terms + UMLS terms) or run 2 (chunk terms + UMLS terms + synonyms). This preliminary analysis reveals that both UMLS terms and chunk terms play an important role in retrieving relevant abstracts. Synonymous terms seem to be less important: many synonyms are found, but only a few new relevant abstracts are retrieved by these terms. Maybe the synonyms in UMLS are not very relevant to this particular task. A better query expansion method might be to add the highly weighted terms found in the top ranked retrieved abstracts to a query and search again. Some further experiments are needed to verify this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this paper we have described our approach to the Ad Hoc Retrieval task of the TREC 2004 Genomics Track. We submitted two runs: one baseline run and one run in which the query terms from the baseline run were expanded with synonymous terms. To find query terms in topics and to determine synonymous terms, we made use of the UMLS Metathesaurus. It turns out that recall computed over the fixed return sets of 1000 documents for each query goes up when synonyms are included, but only slightly: 2186 relevant documents retrieved in the first run vs. 2346 relevant documents retrieved in the second run (out of a total of 8268 relevant documents). Precision computed over the fixed return sets increases very slightly, too. The various evaluation measures indicate that the rankings produced by the two runs are virtually the same: the use of synonyms promotes neither relevant documents nor irrelevant ones in the ranking. Further analysis of the results shows that even though each UMLS search term generates about 5.4 synonyms, these synonyms are less "powerful" than the original search terms. On average, each synonym matches only 2.6 relevant documents, whereas the original search terms match 11.9 documents (for UMLS terms) and 15.8 documents (for chunks). Also, the expanded queries retrieve only very few fresh documents, i.e., relevant documents that were not retrieved by the original, unexpanded queries. This suggests that the document collection and the topic set in this particular experiment exhibit a shared vocabulary: generally, a document relevant to a given topic contains the same terms as the topic rather than terms synonymous to terms in the topic.<ref type="foot" coords="7,501.36,728.65,3.51,6.32" target="#foot_8">9</ref> </p><p>Apparently, the increase in the relevance scores of relevant documents that do contain synonyms is neutralized by a similar increase in the relevance scores of irrelevant documents containing synonyms, leaving the overall ranking of the retrieved documents unchanged. Alternatively, the boosting factor assigned to synonyms, which was derived from a very small and incomplete training set, might be too low for these terms to have a noticeable effect. The poor performance of queries consisting exclusively of synonyms indicates that the use of synonyms draws many irrelevant documents into the result set. In this light, it is rather surprising that run 2 (with synonyms) does not perform worse than run 1 (without synonyms). Again, this may have to do with the boosting factor assigned to synonyms. The poor performance of synonyms can also be taken to show that the use of synonymous terms within documents is limited. In the theoretical case in which a document contains all synonyms of the terms occurring in it, replacing the terms in a topic with their synonyms would not affect retrieval performance negatively. Of course, this theoretical situation does not obtain. However, since the documents used in the task are MEDLINE abstracts, which tend to be relatively short and non-repetitive, thus limiting the opportunity for authors to use synonyms, this argument is worth considering. Future work will focus on increasing the baseline performance, which will allow us to draw firmer conclusions regarding the observed minimal effect of the use of synonyms. We will also investigate to what extent the use of synonyms contributes to falsely retrieved documents. Furthermore, we will connect our results to earlier, similar work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,179.28,201.84,236.67,413.18"><head>Table 1 :</head><label>1</label><figDesc>Recall level precision averages for run 1 and run 2</figDesc><table coords="5,205.02,201.84,190.47,413.18"><row><cell></cell><cell cols="2">run 1 Precision run 2</cell></row><row><cell>0.00</cell><cell>0.5898</cell><cell>0.5545</cell></row><row><cell>0.10</cell><cell>0.2799</cell><cell>0.2806</cell></row><row><cell>0.20</cell><cell>0.1959</cell><cell>0.2032</cell></row><row><cell>0.30</cell><cell>0.1717</cell><cell>0.1676</cell></row><row><cell>0.40</cell><cell>0.1297</cell><cell>0.1209</cell></row><row><cell>0.50</cell><cell>0.0932</cell><cell>0.1064</cell></row><row><cell>0.60</cell><cell>0.0788</cell><cell>0.0811</cell></row><row><cell>0.70</cell><cell>0.0605</cell><cell>0.0630</cell></row><row><cell>0.80</cell><cell>0.0454</cell><cell>0.0496</cell></row><row><cell>0.90</cell><cell>0.0365</cell><cell>0.0392</cell></row><row><cell>1.00</cell><cell>0.0021</cell><cell>0.0000</cell></row><row><cell>At x docs</cell><cell cols="2">Precision run 1 Precision run 2</cell></row><row><cell>5</cell><cell>0.4160</cell><cell>0.3840</cell></row><row><cell>10</cell><cell>0.3540</cell><cell>0.3660</cell></row><row><cell>15</cell><cell>0.3400</cell><cell>0.3480</cell></row><row><cell>20</cell><cell>0.3250</cell><cell>0.3270</cell></row><row><cell>30</cell><cell>0.2940</cell><cell>0.2913</cell></row><row><cell>100</cell><cell>0.1892</cell><cell>0.1850</cell></row><row><cell>200</cell><cell>0.1300</cell><cell>0.1329</cell></row><row><cell>500</cell><cell>0.0712</cell><cell>0.0735</cell></row><row><cell>1000</cell><cell>0.0446</cell><cell>0.0480</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,190.80,637.80,213.77,9.02"><head>Table 2 :</head><label>2</label><figDesc>Document level averages for run 1 and run 2</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,185.40,466.98,219.26,89.66"><head>Table 3 :</head><label>3</label><figDesc>Matching against true abstracts</figDesc><table coords="6,185.40,466.98,219.26,57.74"><row><cell></cell><cell>abstr. matched</cell><cell># terms</cell><cell>ratio</cell></row><row><cell>Chunk terms</cell><cell>111.8</cell><cell>9.4</cell><cell>11.9</cell></row><row><cell>UMLS terms</cell><cell>145.0</cell><cell>9.2</cell><cell>15.8</cell></row><row><cell>Synonyms</cell><cell>131.9</cell><cell>49.8</cell><cell>2.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,135.84,92.64,323.67,219.56"><head>Table 4 :</head><label>4</label><figDesc>Recall-precision averages for chunk terms, UMLS terms, and synonyms</figDesc><table coords="7,140.28,92.64,308.18,187.70"><row><cell>Recall</cell><cell>Prec. chunk terms</cell><cell>Prec. UMLS terms</cell><cell>Prec. synonyms</cell></row><row><cell>0.00</cell><cell>0.5545</cell><cell>0.4673</cell><cell>0.1076</cell></row><row><cell>0.10</cell><cell>0.2435</cell><cell>0.1993</cell><cell>0.0301</cell></row><row><cell>0.20</cell><cell>0.1700</cell><cell>0.1445</cell><cell>0.0233</cell></row><row><cell>0.30</cell><cell>0.1171</cell><cell>0.1133</cell><cell>0.0078</cell></row><row><cell>0.40</cell><cell>0.0685</cell><cell>0.0933</cell><cell>0.0056</cell></row><row><cell>0.50</cell><cell>0.0489</cell><cell>0.0752</cell><cell>0.0043</cell></row><row><cell>0.60</cell><cell>0.0355</cell><cell>0.0550</cell><cell>0.0040</cell></row><row><cell>0.70</cell><cell>0.0194</cell><cell>0.0399</cell><cell>0.0036</cell></row><row><cell>0.80</cell><cell>0.0107</cell><cell>0.0173</cell><cell>0.0001</cell></row><row><cell>0.90</cell><cell>0.0017</cell><cell>0.0033</cell><cell>0.0001</cell></row><row><cell>1.00</cell><cell>0.0002</cell><cell>0.0000</cell><cell>0.0001</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,96.84,712.02,408.53,9.02;2,90.00,727.62,249.28,9.02"><p>We ran MetaMap using the default values for the Filtering Options and under the strict processing model (see http://mmtx.nlm.nih.gov/mmtx.shtml#Processing).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,95.76,743.22,223.37,9.02"><p>See http://www.ltg.ed.ac.uk/software/chunk/index.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,95.52,758.82,384.05,9.02"><p>We currently do not have any numbers regarding the overlap between UMLS terms and chunks.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,95.58,712.02,364.98,9.02"><p>This string is also considered a "bad" string because it contains a parenthesized expression.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,95.76,727.62,344.27,9.02"><p>Synonyms that are MeSH terms are subject only to filter 5 mentioned in section 2.1.2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="3,95.76,743.22,212.32,9.02"><p>See http://jakarta.apache.org/lucene/docs/index.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="3,95.76,758.82,208.87,9.02"><p>Cf. http://wiki.apcha.org/jakarta-lucene/PoweredBy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="6,95.76,758.82,311.25,9.02"><p>Note that the set of synonyms of a given term does not include the term itself.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="7,97.92,758.82,407.40,9.02"><p>Our experimental set-up does not allow us to make any claims about the incidence of relevant</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Angus Roberts</rs> for his help with setting up and running MetaMap and LT CHUNKER for us. We would also like to acknowledge the support of the <rs type="funder">UK Engineering and Physical Sciences Research Council</rs> (grant number: <rs type="grantNumber">GR/R67743</rs>) and <rs type="funder">Medical Research Council</rs> (grant number: <rs type="grantNumber">60086</rs>) which has made possible the work reported here.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Tu3XPyb">
					<idno type="grant-number">GR/R67743</idno>
				</org>
				<org type="funding" xml:id="_qjjqtha">
					<idno type="grant-number">60086</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,90.00,504.72,415.43,9.02;8,90.00,520.38,395.65,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,175.79,504.72,329.64,9.02;8,90.00,520.38,32.29,9.02">Effective Mapping of Biomedical Text to the UMLS Metathesaurus: the MetaMap Program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,143.10,520.38,294.40,9.02">Proceedings of the American Medical Informatics Association Symposium</title>
		<meeting>the American Medical Informatics Association Symposium</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,537.90,415.44,9.02;8,90.00,553.56,49.38,9.02" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<ptr target="http://skr.nlm.nih.gov/papers/index.shtml" />
		<title level="m" coord="8,179.22,537.90,199.24,9.02">Filtering the UMLS Metathesaurus for MetaMap</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,571.08,415.36,9.02;8,90.00,586.68,415.37,9.02;8,90.00,602.34,94.48,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,417.22,571.08,88.14,9.02;8,90.00,586.68,200.86,9.02">The Unified Medical Language System: An Informatics Collaboration</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A B</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M</forename><surname>Schoolman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">O</forename><surname>Barnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,314.76,586.68,190.62,9.02;8,90.00,602.34,45.09,9.02">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,619.92,415.18,9.02;8,90.00,635.52,415.40,9.02;8,89.99,651.18,101.45,9.02" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Malley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Browne</surname></persName>
		</author>
		<title level="m" coord="8,382.86,619.92,122.32,9.02;8,90.00,635.52,117.05,9.02;8,253.68,635.52,251.72,9.02;8,89.99,651.18,43.30,9.02">Proceedings of the American Medical Informatics Association Symposium</title>
		<meeting>the American Medical Informatics Association Symposium</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="448" to="452" />
		</imprint>
	</monogr>
	<note>Evaluating UMLS strings for Natural Language Processing</note>
</biblStruct>

<biblStruct coords="8,90.00,712.02,415.21,9.02;8,90.00,727.62,415.28,9.02;8,90.00,743.22,415.15,9.02;8,90.00,758.82,276.94,9.02" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,90.00,712.02,415.21,9.02;8,90.00,727.62,415.28,9.02;8,90.00,743.22,415.15,9.02;8,90.00,758.82,70.59,9.02">documents that contain terms whose synonyms (that do not occur in the document as terms themselves) match synonyms of terms occurring in topics. (Note that the existence of a situation in which a synonym of a term in a document matches a term in a topic implies the existence of a situation in which a synonym</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
