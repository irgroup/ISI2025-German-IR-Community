<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.41,132.56,443.82,18.14">A Hidden Markov Model for the TREC Novelty Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-10-27">October 27, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,260.09,172.37,100.46,12.58;1,360.55,170.15,1.66,8.74"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
							<email>conroy@super.org</email>
							<affiliation key="aff0">
								<orgName type="department">IDA/Center for Computing Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.41,132.56,443.82,18.14">A Hidden Markov Model for the TREC Novelty Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-10-27">October 27, 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">5A26064E0BCC62F063C85D24F3F39D3B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The algorithms for choosing relevant sentences were tuned versions of those presented in the past DUC evaluations and TREC 2003 (see <ref type="bibr" coords="1,263.10,315.24,67.78,10.48">[4, 5, 10] [11]</ref> for more details). The enhancements to the previous system are detailed in Section 3.</p><p>Two methods were explored to find a subset of the relevant sentences that had good coverage but low redundancy. In the multi-document summarization system, the QR algorithm is used on termsentence matrices. For this work, the method of maximum marginal relevance was also employed. The evaluation of these methods is discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preprocessing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tokenization</head><p>The tokenization was quite simple. First the text was converted to lower case. All contiguous strings of characters taken from the set {a,b,...,z} were terms except for those matched on a short list of stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Parsing Files using DTDs</head><p>Using the SGML document type definition (DTD) for a document allowed us to determine the set of all possible SGML tags that exist in documents of that type. Using these tag sets, we distinguished which sentences 1) were candidates for relevant sentences, 2) were not candidates for relevant sentences but which contained key terms or phrases that would aid in identifying relevant sentences, and 3) contained no useful information for the task of extracting relevant sentences. We created a new attribute, stype, for the SGML tag denoting a sentence boundary, &lt;s&gt;, in order to denote each of these three types of sentences. The possible values for this new attribute are 1, 0, and -1, respectively. Table <ref type="table" coords="1,207.94,659.95,5.86,10.48" target="#tab_0">1</ref> presents the values of stype used for sentences embedded into the SGML tags encountered in the several types of documents used in the evaluation. Choosing to embed information into the document itself instead of creating a processing module in our algorithm allowed us flexibility in using the information throughout the various stages of our system. Furthermore, it will allow us to expand the types of sentence classification without changing the code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Finding Relevant Sentences</head><p>An HMM, in contrast to a naive Bayesian approach ([1], <ref type="bibr" coords="2,375.58,535.49,12.09,10.48" target="#b5">[7]</ref>), has fewer assumptions of independence. In particular, it does not assume that the probability that sentence i is relevant is independent of whether sentence i -1 is relevant. In the HMM developed for this evaluation, we used a joint distribution for the features set which varied based upon the position in the document.</p><p>All of the features used by the HMM were based upon the terms (as defined in Section 2.1) found in a sentence. The features for the HMM were as follows:</p><p>• the entropy of the terms in the sentence-value is o 0 (i) =j p j log(p j ) where j ranges over all the terms in sentence i and p j is the probability of term j for the given document.</p><p>• number of signature terms, n sig , in a sentence-value is o 1 (i) = log(n sig + 1).</p><p>• number of tokens, n tok , in a sentence-value is o 2 (i) = log(n tok + 1). 34 34 34 34 The signature terms are the terms that are more likely to occur in the document (or document set) than in the corpus at large. To identify these terms, we used the log-likelihood statistic suggested by Dunning <ref type="bibr" coords="3,122.45,332.09,12.36,10.48" target="#b4">[6]</ref> and used first in summarization by Lin and Hovy <ref type="bibr" coords="3,395.50,332.09,11.71,10.48" target="#b6">[8]</ref>. The statistic is equivalent to a mutual information statistic and is based on a 2-by-2 contingency table of counts for each term.</p><p>The features were normalized component-wise to have mean zero and variance one. In addition, the features for sentences with stype 0 and -1 were coerced to be -1, which forced these sentences to have an extremely low probability of being selected as relevant sentences.</p><p>An HMM handles the positional dependence, dependence of features, and Markovity. (For more details about HMMs, see <ref type="bibr" coords="3,191.28,418.76,12.36,10.48" target="#b1">[2]</ref> and <ref type="bibr" coords="3,230.97,418.76,12.09,10.48" target="#b7">[9]</ref>.) The model we proposed has 2s + 1 states, with s relevance states and s + 1 non-relevance states. A picture of the Markov chain is given in Figure <ref type="figure" coords="3,521.34,433.21,4.55,10.48" target="#fig_0">1</ref>. Note that we allowed hesitation only in non-relevance states and skipping of states only from relevance states. This chain was designed to model the extraction of up to s -1 lead relevant sentences and an arbitrary number of supporting relevant sentences. Using training data, we obtained a maximum-likelihood estimate for each transition probability and this formed an estimate, M , for the transition matrix for our Markov chain, where element (i, j) of M is the estimated probability of transitioning from state i to state j.</p><p>Associated with each state i is an output function, b i (O) = P r(O|state i), where O is an observed vector of features. We made the simplifying assumption that the features were multivariate normal. The output function for each state was estimated by using the training data to compute the maximum-likelihood estimate of its mean and covariance matrix. We estimated 2s + 1 means, but assumed that all of the output functions shared a common covariance matrix.</p><p>Training for the HMM was straightforward given marked data. Since the states of the HMM were known in the training data, creating the model simply amounted to computing the maximum likelihood statistics given the counts.</p><p>In particular, the training data helped determine the number of states for the HMM. The upshot was that a state space consisting of nine states (five relevance states and four non-relevance states) was optimal given TREC 2003 data. With this model we computed γ j (i), the probability that sentence j corresponded to state i. We computed the probability that a sentence was a relevant sentence by summing γ j (i) over all even values of i, values corresponding to relevance states. This posterior probability, which we define as g j , was used to select the most likely relevant sentences. We refer the reader to <ref type="bibr" coords="4,175.71,104.64,12.35,10.48" target="#b2">[3]</ref> for details.</p><p>This posterior probability was used to select which sentences were likely to be relevant. The selection algorithm attempted to choose the number of sentences so that the expected F 1 score was maximized. The approximate F 1 score was computed based on the expected precision, E(P ), and expected recall, E(R), as follows:</p><formula xml:id="formula_0" coords="4,58.32,175.37,300.80,44.32">F 1 = 2E(P )E(R) E(P ) + E(R)<label>where</label></formula><formula xml:id="formula_1" coords="4,269.26,219.17,80.44,26.83">E(P ) = t S g t |S|</formula><p>where |S| is the cardinality of the set S of sentences selected, and</p><formula xml:id="formula_2" coords="4,266.72,275.82,87.21,29.55">E(R) = t S g t t g t .</formula><p>The set S was chosen by selectively choosing the sentences in decreasing order of their probability of being a relevant sentence. The score F 1 was then computed and the set S increased as long as F 1 increased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Finding New Sentences</head><p>To choose a subset of the candidate relevant sentences to produce new sentences we experimented with two algorithms: a pivoted QR decomposition and MMR. These methods work on the termsentence matrix, A, where A ij is 1 if term i occurs in relevant sentence j. Before applying the sentence selection algorithms, the columns of A were normalized; the Euclidean length of a column was set equal to the probability that the corresponding sentence was indeed relevant. For Tasks 2 and 4 these probabilities were 1 since the relevant sentences were given, while for Task 3, the probability was equal to the score produced by the HMM for that sentence, g j .</p><p>A QR decomposition with partial pivoting, can be applied to the weighted term-sentence matrix A w = A. The QR decomposition was used to determine whether a sentence should be considered new or redundant. In the QR factorization a sentence was considered redundant if the vector corresponding to it had a low value for F 1 . This is in contrast to the method we used in 2003 where a small weight, say less than τ, a predefined threshold. [I believe this change in part accounted for the lower performance on Task 2.] Likewise this method was used by the MMR to determine when a redundant sentence was found.</p><p>The standard implementation of the pivoted QR decomposition is a "Gram-Schmidt" process and was used to select new sentences as follows.</p><p>Algorithm 4.1 (Pivoted QR Decomposition) Suppose A w has m rows and n columns: i.e., the document has m unique terms and n sentences. The following iteration constructs a matrix Q with columns q i , a matrix R with nonzero elements r ji , and an ordering for the columns in an array Index.</p><p>For i = 1, 2, . . . , min(m, n),</p><p>Among the remaining columns of A w , choose the column with maximal norm. Denote this column by a , where is its index in the original matrix.</p><p>Set Index i = .</p><p>Set q i = a / a .</p><p>Update the other columns of A w to make them orthogonal to the chosen column: for each unchosen column a j , set r ji = a T j q i and set a j = a j -r ji q i . The set of "new" sentences of size k contains sentences Index 1 , . . . , Index k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>For Task 1 the HMM used for TREC was trained using the marked relevant and new sentences in the Novelty data from TREC 2003. Specifically, for Task 1 two models were built. The first model used only one output for the HMM, (o 1 , the number log of the number of signature terms+1). These runs have the prefix ccs1f. A second model used all three features and these entries have the prefix ccs3f.</p><p>Note that for Task 1 the suffixes "mmrt1" and "qrt1" denote the results using an MMR and those using just a pivoted QR, respectively. The suffix 0t1 simply passes all tagged relevant sentences as novel.</p><p>The median F 1 scores are given in the tables for the entries and as well as the median rank of the entry based on the other Novelty submission, which there were 60 for Task 1. In addition, we computed the median F 1 score for the document sets that contained only relevant documents, i.e., those with exactly 25 documents (SZ=25) versus those with some non-relevant documents in the set (SZ&gt;25). Finally, we see the F 1 scores for document sets which were Event topics versus Opinion topics. In Task 2 we were given the relevant sentences and had to determine the new sentences. We submitted 5 approaches: a pivoted QR (ccsumqrt2 ), and four variations of MMR entries, which varied the weighting parameter between the HMM score and the redundancy penalty. For the task of selecting the new sentences given a list of putative relevant sentences (Task 2), our entries did much poorer this year than last year, where the pivoted QR did comparably with the best entries submitted. (We are still investigating; however, as mentioned above we believe this may have been due to the new stopping selection scheme.) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,105.49,228.64,409.66,10.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Markov Chain to Extract 2 Lead Sentences and Supporting Sentences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,58.32,88.74,503.99,311.44"><head>Table 1 :</head><label>1</label><figDesc>Mapping SGML tags to stype values. All tags not shown but allowed by each DTD are assigned stype = -1.</figDesc><table coords="2,133.97,88.74,352.70,260.05"><row><cell>File</cell><cell>DTD</cell><cell>Filename</cell><cell>SGML Tag</cell><cell>stype</cell></row><row><cell cols="2">APW* ACQUAINT</cell><cell cols="2">acquaint.dtd &lt;TEXT&gt;</cell><cell>1</cell></row><row><cell>NYT*</cell><cell></cell><cell></cell><cell>&lt;HEADLINE&gt;</cell><cell>0</cell></row><row><cell>XIE*</cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell cols="2">FBIS* FBIS</cell><cell>fbis.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;TI&gt;</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;H1&gt;, . . . , &lt;H8&gt;</cell><cell>0</cell></row><row><cell>FR*</cell><cell cols="2">Federal Register fr.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;SUMMARY&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;SUPPLEM&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;FOOTNOTE&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;DOCTITLE&gt;</cell><cell>0</cell></row><row><cell>FT*</cell><cell cols="2">Financial Times ft.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;HEADLINE&gt;</cell><cell>0</cell></row><row><cell>LA*</cell><cell>LA Times</cell><cell>latimes.dtd</cell><cell>&lt;TEXT&gt;</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;HEADLINE&gt;</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;SUBJECT&gt;</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>&lt;GRAPHIC&gt;</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,82.95,483.75,454.74,120.10"><head>Table 2 :</head><label>2</label><figDesc>Performance of CCSUM on Task 1: Relevant Sentences; 60 Total Entries</figDesc><table coords="5,82.95,483.75,454.74,97.56"><row><cell></cell><cell cols="8">Median Median Median Median SZ=25 SZ&gt;25 Event Opinion</cell></row><row><cell></cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell>Rank</cell><cell></cell><cell></cell><cell>F1</cell><cell>F1</cell></row><row><cell>ccs1f0t1</cell><cell>20</cell><cell>82</cell><cell>32</cell><cell>41</cell><cell>48</cell><cell>30</cell><cell>44</cell><cell>24</cell></row><row><cell>ccs1ftop0t1</cell><cell>20</cell><cell>75</cell><cell>31</cell><cell>48</cell><cell>48</cell><cell>29</cell><cell>42</cell><cell>24</cell></row><row><cell>ccs3fmmrt1</cell><cell>22</cell><cell>86</cell><cell>34</cell><cell>36</cell><cell>49</cell><cell>28</cell><cell>43</cell><cell>25</cell></row><row><cell>ccs3fqrt1</cell><cell>21</cell><cell>94</cell><cell>34</cell><cell>34</cell><cell>49</cell><cell>31</cell><cell>47</cell><cell>25</cell></row><row><cell>ccs3ftop0t1</cell><cell>22</cell><cell>86</cell><cell>34</cell><cell>36</cell><cell>49</cell><cell>28</cell><cell>43</cell><cell>25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,82.95,88.74,454.74,120.10"><head>Table 3 :</head><label>3</label><figDesc>Performance of CCSUM on Task 1: New Sentences; 60 Total Entries</figDesc><table coords="6,82.95,88.74,454.74,97.56"><row><cell>Run</cell><cell cols="8">Median Median Median Median SZ=25 SZ&gt;25 Event Opinion</cell></row><row><cell></cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell>Rank</cell><cell></cell><cell></cell><cell>F1</cell><cell>F1</cell></row><row><cell>ccs1f0t1</cell><cell>7</cell><cell>82</cell><cell>13</cell><cell>44</cell><cell>11</cell><cell>14</cell><cell>18</cell><cell>11</cell></row><row><cell>ccs1ftop01t</cell><cell>7</cell><cell>74</cell><cell>13</cell><cell>42</cell><cell>11</cell><cell>13</cell><cell>18</cell><cell>10</cell></row><row><cell>ccs3fmmrt1</cell><cell>7</cell><cell>84</cell><cell>13</cell><cell>40</cell><cell>13</cell><cell>13</cell><cell>18</cell><cell>11</cell></row><row><cell>ccs3fqrt1</cell><cell>8</cell><cell>88</cell><cell>14</cell><cell>39</cell><cell>13</cell><cell>14</cell><cell>20</cell><cell>11</cell></row><row><cell>ccs3ftop0t1</cell><cell>7</cell><cell>86</cell><cell>13</cell><cell>41</cell><cell>12</cell><cell>13</cell><cell>18</cell><cell>11</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Median Median Median Median SZ=25 SZ&gt;25 In Task 3 we were given the relevant and new sentences for the first 5 documents of each of the document sets. We realized after submitting our results two of our entries (not shown in the table here) were bogus. They were processed as if they were Task 2 entries and are invalid entries. As such these entries scored 0 for relevant sentences and the best for the novel sentences!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Median </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,82.38,575.21,479.94,10.48;6,82.38,589.66,479.94,10.48;6,82.38,604.10,205.73,10.48" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,383.47,575.21,178.85,10.48;6,82.38,589.66,92.06,10.48">A Scalable Summarization System Using Robust NLP</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Aone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gorlinsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,205.85,589.66,356.47,10.48;6,82.38,604.10,101.06,10.48">Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on Intelligent Scalable Text Summarization</title>
		<meeting>the ACL&apos;97/EACL&apos;97 Workshop on Intelligent Scalable Text Summarization</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.38,627.28,479.93,10.48;6,82.38,641.72,479.94,10.48;6,82.38,656.17,51.37,10.48" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,333.64,627.28,228.68,10.48;6,82.38,641.72,328.97,10.48">A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Petrie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Soules</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,428.53,641.72,86.61,10.48">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="164" to="171" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,82.38,679.34,479.94,10.48;6,82.38,693.79,479.93,10.48;6,82.38,708.23,66.33,10.48" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,228.99,679.34,333.33,10.48;6,82.38,693.79,113.25,10.48">Text Summarization via Hidden Markov Models and Pivoted QR Matrix Decomposition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-03">March, 2001</date>
			<pubPlace>College Park, Maryland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="7,82.38,228.09,479.95,10.48;7,82.38,242.53,479.93,10.48;7,82.38,256.98,198.85,10.48" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,144.11,242.53,387.18,10.48">Performance of a Three-Stage System for Multi-Document Summarization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dunlavy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Van Halteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,82.38,256.98,163.15,10.48">DUC 03 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,82.38,281.39,479.94,10.48;7,82.38,295.83,140.35,10.48" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,158.28,281.39,311.50,10.48">Accurate Methods for Statistics of Surprise and Coincidence</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,487.30,281.39,75.02,10.48;7,82.38,295.83,53.54,10.48">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,82.38,320.24,479.94,10.48;7,82.38,334.69,479.93,10.48;7,82.38,349.13,147.61,10.48" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,282.12,320.24,177.66,10.48">A Trainable Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kupiec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,490.54,320.24,71.78,10.48;7,82.38,334.69,479.93,10.48;7,82.38,349.13,43.82,10.48">Proceedings of the 18th Annual International SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 18th Annual International SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,82.38,373.54,479.94,10.48;7,82.38,387.99,124.60,10.48;7,206.98,386.37,7.94,6.99;7,220.17,387.99,342.15,10.48;7,82.38,402.43,62.51,10.48" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,192.06,373.54,358.74,10.48">The Automatic Acquisition of Topic Signatures for Text Summarization</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,97.64,387.99,109.34,10.48;7,206.98,386.37,7.94,6.99;7,220.17,387.99,342.15,10.48;7,82.38,402.43,26.62,10.48">Proceedings of the 18 th International Conference on Computational Liguistics (COLLING 2000)</title>
		<meeting>the 18 th International Conference on Computational Liguistics (COLLING 2000)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,82.38,426.84,479.94,10.48;7,82.38,441.29,158.37,10.48" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,155.20,426.84,331.59,10.48">A Tutorial on Hidden Markov Models and Selected Applications</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,504.03,426.84,58.29,10.48;7,82.38,441.29,58.42,10.48">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="257" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,82.39,465.69,479.93,10.48;7,82.38,480.14,479.93,10.48;7,82.38,494.59,359.14,10.48" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,88.17,480.14,474.14,10.48;7,82.38,494.59,128.94,10.48">Understanding Machine Performance in the Context of Human Performance for Multidocument Summarization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Okurowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,242.67,494.59,163.15,10.48">DUC 02 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,82.39,518.99,479.94,10.48;7,82.38,533.44,312.10,10.48" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,225.08,518.99,217.13,10.48">Overview of the TREC 2003 Novelty Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,471.69,518.99,90.63,10.48;7,82.38,533.44,250.53,10.48">Proceedings of the Twelfth Text REtrieval Conference (TREC 2003)</title>
		<meeting>the Twelfth Text REtrieval Conference (TREC 2003)</meeting>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
