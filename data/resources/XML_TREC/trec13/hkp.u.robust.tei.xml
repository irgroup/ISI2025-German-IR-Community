<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.32,120.87,418.54,14.47;1,248.28,138.75,98.67,14.47">The Hong Kong Polytechnic University at the TREC 2004 Robust Track</title>
				<funder ref="#_ZEJTh6h">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,203.64,172.04,52.96,10.84"><forename type="first">D</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName coords="1,266.60,172.04,56.80,10.84"><forename type="first">R</forename><forename type="middle">W P</forename><surname>Luk</surname></persName>
						</author>
						<author>
							<persName coords="1,332.19,172.04,55.06,10.84"><forename type="first">K</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.32,120.87,418.54,14.47;1,248.28,138.75,98.67,14.47">The Hong Kong Polytechnic University at the TREC 2004 Robust Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EDAC9707C491F24F3821D8F683482786</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the robust track, we mainly tested our passage-based retrieval model with different passage sizes and weighting schemes. In our approach, we used two retrieval models, namely the 2-Poisson model using BM25 term weights and the vector space model (VSM) using adaptive pivoted unique document length normalization. Also, we utilize WordNet to re-weight some PRF terms and extract some context words as expanded query terms. We show that our passage-based model achieves the comparable performance on the whole query set. Moreover, our new methods of using WordNet information for query expansion can improve the retrieval performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Generally speaking, there are two major categories of information retrieval technology and research: semantic and statistical.</p><p>Semantic approaches mainly depend on syntactic and semantic information and they try to understand the natural language text that a user would provide. In statistical approaches, the retrieval is based on some statistical measure of query, documents and relation between them. By far most work to date has been devoted to statistical approaches. It is well acknowledged that statistical approaches combined with some semantic methods will yield better performance.</p><p>In the past, lots of people use WordNet for information retrieval. [Voorhees 93] used synsets in WordNet to disambiguate nouns in documents and then used a combination of synonyms, hypernyms and hyponyms for query expansion <ref type="bibr" coords="1,459.17,651.39,48.57,10.18;1,105.06,664.83,9.19,10.18">[Voorhees 94</ref>]. <ref type="bibr" coords="1,131.44,664.83,70.23,10.18">[Stairmand 97</ref>] used WordNet to compute the lexical cohesion for IR.</p><p>[Richardson 95] used WordNet to calculate the semantic distance between concepts or words in order to get the similarity between a documents and a query. [Mandala 98] investigate the problem of low performance improvement by using WordNet and tried to use automatically constructed thesaurus to compensate the insufficiency of information of WordNet. [Flank 98] proposed a layered approach for IR and used WordNet for semantic expansion. <ref type="bibr" coords="2,122.52,149.12,23.12,10.18">[Liu,</ref><ref type="bibr" coords="2,149.30,149.12,39.61,10.18">et al 04]</ref> utilized WordNet to disambiguate word senses of query terms and after the sense is determined, they use WordNet to expand the query. They use definition words as well as related words that others have often used, such as synonyms.</p><p>In addition to our passage-based model, we also make use of WordNet. In detail, we use the definition as well as all relationships defined for each of the senses: noun, verb, adjective and adverb in WordNet. Section 3 and 4 will explain these implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">FORMAL RUNS AND OTHER RUNS</head><p>Our formal runs were based on passage retrieval. Each passage has fixed length of 300 terms, unless we encountered the end of file before. The document similarity score sim(.) is computed by combining passage scores using a weighted Boolean disjunction operation [Fox 92] or generalized mean function:</p><formula xml:id="formula_0" coords="2,220.86,386.43,166.61,37.36">α α ∑ = = i k j j i i q p rel q d sim 1 , ) , ( ) , (</formula><p>where q is the query, d i is the i-th document, p i,j is the j-th passage of the i-th document, k i is the number of passages in the i-th document, rel(.) is the relevance score assigned by the retrieval model, and α (= 20) is a soft-hard decision parameter.</p><p>We used two retrieval models to return rel(.), namely the 2-Poisson model using BM25 term weights <ref type="bibr" coords="2,201.68,485.06,110.96,10.18" target="#b1">[Robertson et al., 1996]</ref> and the vector space model (VSM) using adaptive pivoted unique document length normalization [Singhal 96]. In addition, the retrieval was carried out with pseudo-relevance feedback (PRF) as in our Chinese retrieval [Luk 04] where the top 20 passages were analyzed, selecting 40 terms and using a term weight mixture parameter of 0.3. The formal runs were obtained when we had some problems with the stop word lists and the passage size was adjusted to 250 terms per passage. We re-ran the same queries for some of the runs and Table <ref type="table" coords="3,299.60,108.86,5.84,10.18">2</ref> showed that better results were obtained. More significant improvement was found to be in the description queries. The performance of our basic retrieval system was performing similar to the median performance in this robust track compared with the formal runs only (see Table <ref type="table" coords="3,478.60,149.12,4.23,10.18">3</ref>). Table <ref type="table" coords="3,117.15,292.52,5.84,10.18">3</ref> compares the retrieval effectiveness performances between our search engine and the search engine by other participants. Our search engine was approximately in the middle (close to the median) for the MAP and for the P@10 performances. The differences between the best formal runs by other participants were statistically better than ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submitted</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Informal runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP (%)</head><p>P@10 (%) It is possible that our search engine performed particularly poorly for a specific set of queries. Therefore, we compared the performance of our search engine with the performance of other participants' for the three subset of queries, namely the new topics (Table <ref type="table" coords="3,121.15,592.64,4.21,10.18">4</ref>), the old topics (Table <ref type="table" coords="3,237.09,592.64,4.88,10.18" target="#tab_3">5</ref>) and the hard topics (Table <ref type="table" coords="3,375.92,592.64,4.23,10.18" target="#tab_4">6</ref>). For each of the subset of queries, the performance of our search engine was close to the median. Therefore, our search engine did not perform poorly in any of the three subsets of queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PRF TERMS RE-RANKING</head><p>Pseudo-relevance feedback improves the performance of retrieval. However, not all PRF terms are so helpful since they are blindly extracted from top ranked documents in returned list. Some PRF terms can even bring down the performance. So we propose some methods to filter out the bad PRF term and add weight of good ones. These methods are based on that such an assumption: title query terms can reflect the user need and together with the word related, they can indicate user need much better.</p><p>[Mandala 98] found that polysemous words degrade the precision of information retrieval since all senses of the original query term are considered for expansion. Hence they consider to add the terms that are most similar to the entirety of query terms rather than a single query term. We also do the similar work: assign a higher score for a candidate PRF term if it can match more sets of related terms of query terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1Re-rank PRF terms with WordNet Definition of query terms</head><p>We use dictionary definition of title query terms as a baseline to evaluate PRF terms. The definition of a term usually contains a hypernym of it and some limiting components. For example, in WordNet, "telescope" has a definition of "a magnifier of images of distant objects" and "Hubble" has "United States astronomer who discovered that (as the universe expands) the speed with which nebulae recede increases with their distance (1889-1953)".</p><p>Then, we know "telescope" is a kind of image magnifier and relates with distant objects and "Hubble" is an astronomer and related with "discover", "nebulae". The advantage of obtaining related words from definition is the additional words are quite direct and accurate, although the number of them is usually limited. And when some term has some completely distinct sense, such as "bank", the methods will bring in lots of noise if no word sense disambiguation techniques are taken.</p><p>Let def 1 , def 2 ,…, def Q be the definition of the title query q 1 , q 2 ,…, q Q . For a PRF term weighted prf i , if it can match n definitions ("match" means it appears in the definition), we re-weight prf i a new value of</p><formula xml:id="formula_1" coords="5,245.22,386.97,121.59,35.32">i i prf Q n idf ⋅ + + + ⋅ ) 1 . 0 1 . 0 1 (</formula><p>where idf i is idf of this PRF term.</p><p>In practice, we re-weight 60 PRF terms (i.e. Q=60). For each title query term, we get the definitions of all senses it has from WordNet. Then, we remain the nouns and stem them with Porter's Stemmer. After matching PRF terms, we rank them by new PRF weights.</p><p>We only rely on the nouns in definition because some researchers indicated that nouns are enough to represent a topic. [Brezeale 1999] believed that using nouns only will be sufficient to represent a web page. <ref type="bibr" coords="5,309.35,548.49,37.55,10.18" target="#b0">[Fell90]</ref> found that meanings of verbs are more flexible than the meanings of nouns, so the meaning of a verb is much more dependent on the kinds of nouns in the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Re-rank PRF terms with related words of query terms</head><p>The number of definition words mentioned above is small and we can only match few PRF terms to them and the effectiveness of re-weighting is not significant. In consideration of this, we use WordNet defined relationships to get more related words of query terms. Take "telescope" for an example again, we get eight related terms. One hyponym of it is "astronomical telescope". Since we get "astronomer" from definition of "Hubble", we can know one of the common concept for "telescope" and "Hubble" might be "astronomy", which could be obtained by stemming both and matching.</p><p>Let s 1 , s 2 ,…, s Q be the sets of related words of the title query definitions def 1 , def 2 ,…, def Q . For a PRF term weighted prfi, if it is the element of n sets among s 1 , s 2 ,…, s Q , we re-weight prfi a new value of</p><formula xml:id="formula_2" coords="6,245.22,145.41,121.59,35.32">i i prf Q n idf ⋅ + + + ⋅ ) 1 . 0 1 . 0 1 (</formula><p>where idfi is idf of this PRF term.</p><p>Let wi is a word with POS i in Wordnet and n relationships R 1 , R 2 ,…, R n are defined for w i . We use R j (w i ) to represent the word(s) that have relationship R j with w i . So for a set of word S, we get its directly related words:</p><formula xml:id="formula_3" coords="6,213.66,238.22,186.18,42.76">U U S w j i j i w R S REL ∈ = ) ( ) ( 1</formula><p>For REL k , we can get its directly related words set REL k+1 by U U</p><formula xml:id="formula_4" coords="6,200.52,298.01,212.19,38.59">) ( 1 ) ( ) ( S REL w j i j k k i w R S REL ∈ + =</formula><p>The above set s i can be equal to REL k (def i ) given the iteration times k.</p><p>In practice, we use the 60 definitions generated in last section and perform POS tagging on them by MontyLingua. We get the related words of all nouns, verbs, adjectives and adverbs in definition by WordNet. These related words are generated by all relationships defined as REL k above. Actually, our first experiments use REL 1 (def) as related words. Similarly, then, we select the nouns among them and stem them for matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">QUERY EXPANSION WITH NOUN PHRASES IN CONTEXT</head><p>No matter how many topics a document covers, in a small passage of it, we assume it covers only one topic. And around the position of query terms appears, the topic is more likely to be relevant with the information need. That's the reason that we extract context words around each query terms in documents. We use such context word as a supplementary for query terms just as PRF terms do. And we select some candidates from them and give them weights based on some syntactic and semantic information.</p><p>We extract context from top ranked documents in retrieved list for they are more likely to be relevant and contain more query terms. First, these documents are POS tagged and then labeled with phrases by MontyLingua. As for each query term, we sequentially extract ten non-stopword terms in both the left and right side of it. Then, we remain the terms that appears in noun phrases as the candidate terms for later matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Matching context terms with WordNet Definition of query terms</head><p>For context terms, we use the similar weighting methods just as we process the PRF terms. Let def 1 , def 2 ,…, def Q be the definition of the title query q 1 , q 2 ,…, q Q . For a context term, if it can be found in n definitions, we give it a weight of ) 1 . 0</p><formula xml:id="formula_5" coords="7,259.26,105.15,87.55,35.32">1 . 0 1 ( + + + ⋅ Q n idf i</formula><p>where idfi is idf of this context term.</p><p>For easy comparsion, we assign weights for 60 context terms. After that, we rank them by new weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Matching context terms with related words of query terms</head><p>For the same reason, we weight context terms based on the results of matching them with the related words of query terms.</p><p>And we generate the related words of definitions of query terms def 1 , def 2 ,…, def Q : REL 1 (def 1 ), REL 1 (def 2 ), …, REL 1 (def Q ) and give context words weights based on the number of matching n:</p><formula xml:id="formula_6" coords="7,259.26,276.33,93.46,35.32">) 1 . 0 1 . 0 1 ( + + + ⋅ Q n idf i</formula><p>where idf i is idf of this context term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTAL RESULTS</head><p>We produce 60 PRF terms from query terms by the methods used in [Luk 04]:</p><formula xml:id="formula_7" coords="7,216.36,401.91,161.32,57.42">     = &lt; &lt; ≥ = 1 0 1 ) ( 2 ) ( ) ( 1 1 1 1 3 j j j n for k n for j S k n for j S j S</formula><p>where S 1 (j)= tf j in top N doc * df j in the topN doc* idf j and n j is the j-th document frequency and k 1 is a parameter of term specificity.</p><p>Then we match these PRF terms with the definition and related terms mentioned above and re-rank them. We choose the top 30 ranked PRF terms and all 60 terms to do retrieval on 10 queries (query No 311-320). The original PRF terms and their weights are set to be the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-weighted by definition</head><p>Re-weighted by related terms Baseline Top30 Top 60 Top 30 Top60 MAP 0.2068 0.1617 0.2189 0.1559 0.2161 P@10 0.3600 0.3300 0.4300 0.3100 0.4300 Table <ref type="table" coords="7,216.93,640.34,4.56,10.18">9</ref>: Performance with different sizes of terms.</p><p>We found that our re-weighting methods improve the retrieval performance a little. And we notice that retrieval with 60 terms performs much better than 30 terms. This shows that the matching methods are effective to add weights for good term but insufficient to penalize and eliminate the bad terms. Later, we found the same and even more significant phenomenon on matching context terms. It results from the very low matching percentage.</p><p>We extend the 10 queries to 50 queries (No 301-350) of TREC-6 to show the performance of our re-weighting methods.</p><p>Baseline Re-weighted by definition</p><p>Re-weighted by related terms MAP 0.1301 0.1405 0.1400 P@10 0.3020 0.3200 0.3200 Table <ref type="table" coords="8,245.51,245.00,11.71,10.18">10</ref> : Peformance on TREC-6</p><p>In order to investigate the matching of context words, we extracted 10349 terms from noun phrases in the context of query terms <ref type="bibr" coords="8,344.79,285.26,38.57,10.18">(317)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(318)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(319)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(320)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(321)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(322)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(323)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(324)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(325)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(326)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(327)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(328)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(329)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(330)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(331)</ref><ref type="bibr" coords="8,383.36,285.26,5.36,10.18">(332)</ref><ref type="bibr" coords="8,388.72,285.26,21.42,10.18">(333)</ref> and each query has 608 distinct context terms in average. In total, only 160 of the 10349 context terms can match the definition terms so the matching percentage is 1.5%. And 650 of the 10349 context terms can match related terms (REL 1 ) of the query terms so the matching percentage is 6.28%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>From above test and evaluation of our formal runs, other runs, we find the our formal runs perform badly because of the stopword list failure. The performance of our other runs is comparable with the median of all participants on T and TDN queries and ours is a little worse than median with D queries.</p><p>Our WordNet-based experiments show that using WordNet to re-weight original PRF term can improve the results but it still needs more work if we expect significant progress. The low percentage of matching context words requires other term expansion methods to make it reasonable and feasible.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,158.63,713.91,298.74,10.18"><head>Table 5 :</head><label>5</label><figDesc>Comparison of our other runs on old topics with other participants</figDesc><table coords="3,158.63,713.91,298.74,10.18"><row><cell>Query Measure</cell><cell>New</cell><cell>Best</cell><cell>Median</cell><cell>Worst</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,128.04,482.84,356.56,10.18"><head>Table 6 :</head><label>6</label><figDesc>Comparison of our other runs on hard topics with other participants</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENT</head><p>We thank <rs type="person">Prof. Kwok</rs> for his participation in the project <rs type="grantNumber">PolyU 5199/04E</rs> which supported this work. And we thank <rs type="person">Ms WONG Wing-sze</rs> for her kind help in setting up the system.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZEJTh6h">
					<idno type="grant-number">PolyU 5199/04E</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,148.05,617.54,359.59,10.18;8,105.06,630.98,220.16,10.18;8,105.06,657.80,402.61,10.18;8,105.06,671.24,402.65,10.18;8,105.06,684.68,200.52,10.18;9,105.06,108.86,402.67,10.18;9,105.06,122.30,402.59,10.18;9,105.06,135.68,129.32,10.18" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,261.75,617.54,157.56,10.18;8,110.13,657.80,393.37,10.18;9,340.12,108.86,124.14,10.18">Flank 98] Sharon Flank. A layered approach to NLP-based information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Betrabet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,105.06,671.24,392.38,10.18">Proceedings of the 17th international conference on Computational linguistics</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Frakes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<meeting>the 17th international conference on Computational linguistics<address><addrLine>Montreal, Quebec, Canada; NJ</addrLine></address></meeting>
		<imprint>
			<publisher>PHI</publisher>
			<date type="published" when="1990">1990. 1998. 1992</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="393" to="418" />
		</imprint>
	</monogr>
	<note>International Journal of Lexicography</note>
</biblStruct>

<biblStruct coords="9,107.94,162.56,399.78,10.18;9,105.06,175.94,402.77,10.18;9,105.06,189.38,402.67,10.18;9,105.06,202.82,226.60,10.18;9,105.06,229.64,402.69,10.18;9,105.06,243.08,402.70,10.18;9,105.06,256.46,69.01,10.18;9,105.06,283.34,402.66,10.18;9,105.06,296.72,402.65,10.18;9,105.06,310.16,402.57,10.18;9,105.06,323.60,339.93,10.18;9,105.06,350.42,402.61,10.18;9,105.06,363.86,402.56,10.18;9,105.06,377.24,273.66,10.18;9,105.06,404.12,386.02,10.18;9,105.06,417.50,397.65,10.18;9,105.06,430.94,362.33,10.18;9,105.06,444.38,208.78,10.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,446.68,162.56,61.05,10.18;9,105.06,175.94,398.02,10.18;9,325.01,229.64,182.74,10.18;9,105.06,243.08,359.13,10.18;9,455.52,283.34,52.20,10.18;9,105.06,296.72,159.70,10.18;9,405.96,350.42,101.71,10.18;9,105.06,363.86,253.65,10.18">An effective approach to document retrieval via utilizing WordNet and recognizing phrases</title>
		<author>
			<persName coords=""><forename type="first">Shuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clement</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiyi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">F</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Takenobu</forename><surname>Wong ; Rila Mandala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hozumi</forename><surname>Tokunaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">R</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Smeaton ; Robertson</surname></persName>
		</author>
		<idno>CA-0395</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,105.06,189.38,402.67,10.18;9,105.06,202.82,170.80,10.18;9,412.93,296.72,94.78,10.18;9,105.06,310.16,329.97,10.18;9,196.49,417.50,271.95,10.18">Proceedings of the 27th annual international conference on Research and development in information retrieval</title>
		<editor>
			<persName><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</editor>
		<meeting>the 27th annual international conference on Research and development in information retrieval<address><addrLine>Somerset, New Jersey; Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1995">July 2004. Tokyo, 2-4 June 2004. 1998. 1995. 1996. October 1996</date>
			<biblScope unit="page" from="73" to="86" />
		</imprint>
		<respStmt>
			<orgName>School of Computer Applications, Dublin City University ; National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>TREC-4, The Fourth Text REtrieval Conference (TREC-4)</note>
</biblStruct>

<biblStruct coords="9,157.04,471.14,350.70,10.18;9,105.06,484.58,402.49,10.18;9,105.06,498.02,259.98,10.18;9,105.06,524.84,402.67,10.18;9,105.06,538.28,402.67,10.18;9,105.06,551.66,338.99,10.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,330.17,471.14,177.57,10.18;9,105.06,484.58,49.10,10.18;9,366.06,524.84,141.67,10.18;9,105.06,538.28,65.37,10.18">Text classification using WordNet hypernyms</title>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stan</forename><surname>Matwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mandar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,169.45,484.58,338.10,10.18;9,105.06,498.02,176.87,10.18;9,178.38,538.28,329.34,10.18;9,105.06,551.66,257.60,10.18">Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Montreal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1998. 1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
	<note>Proceedings of the COLING/ACL Workshop on Usage ofWordNet in Natural Language Processing Systems</note>
</biblStruct>

<biblStruct coords="9,165.64,578.54,342.16,10.18;9,105.06,591.92,344.21,10.18;9,105.06,618.80,402.59,10.18;9,105.06,632.18,397.64,10.18;9,105.06,659.07,402.65,10.18;9,105.06,672.44,322.79,10.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,250.96,578.54,238.13,10.18;9,255.31,618.80,252.34,10.18;9,105.06,632.18,37.63,10.18;9,256.38,659.07,233.28,10.18">Using wordnet to disarmbiguate word senses for text retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Stairmand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,105.06,591.92,231.72,10.18;9,162.33,632.18,231.80,10.18;9,105.06,672.44,228.87,10.18">Proceedings of the 20th A CM-SIGIR Conference</title>
		<meeting>the 20th A CM-SIGIR Conference</meeting>
		<imprint>
			<date type="published" when="1993">1997. 1993. 1994</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
	<note>Proceedings of the 17th ACM-SIGIR Conference</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
