<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,92.64,106.22,410.72,15.13;1,281.28,121.94,33.28,15.13">Identifying relevant full-text articles for GO annotation without MeSH terms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,199.92,150.47,37.62,11.89"><forename type="first">Chih</forename><surname>Lee</surname></persName>
							<email>clee@nlg.csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<addrLine>1, Section 4, Roosevelt Road</addrLine>
									<postCode>106</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.68,150.47,61.11,11.89"><forename type="first">Wen-Juan</forename><surname>Hou</surname></persName>
							<email>wjhou@nlg.csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<addrLine>1, Section 4, Roosevelt Road</addrLine>
									<postCode>106</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,331.80,150.47,64.05,11.89"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
							<email>hh_chen@csie.ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<addrLine>1, Section 4, Roosevelt Road</addrLine>
									<postCode>106</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,92.64,106.22,410.72,15.13;1,281.28,121.94,33.28,15.13">Identifying relevant full-text articles for GO annotation without MeSH terms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2D3E4A66C9218FEEF9275F79E08EB863</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Gene Ontology (GO) is a controlled vocabulary. Given a gene product, GO enables scientists to clearly and unambiguously describe specific molecular functions of the gene product, specific biological processes in which it is involved, and specific cellular components to which it is localized. In this paper, we present our approach to identifying which papers have experimental evidence warranting annotation with GO codes. The training data set contains 375 relevant full-text articles and 5,462 irrelevant ones, and the test data set contains 420 positive full-text articles and 5,623 negative ones. We regarded this problem as a binary classification problem, and employed Support Vector Machines (SVMs) to distinguish positive articles from negative ones. Title, abstract, figure/table captions, and three standard sections -Results, Discussion, and Conclusion were the targets of feature extraction. Without incorporating MeSH (Medical Subject Headings) terms as part of the features, our system achieved 0.381 in Normalized Utility measure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Gene Ontology (GO) <ref type="bibr" coords="1,184.20,471.71,12.58,11.89" target="#b0">[1]</ref> is a system of keywords hierarchically organized as a directed acyclic graph with three main categories -biological process, cellular component, and molecular function. It provides a unified set of terms for the annotation of gene products in different organisms. The assignment of a GO term requires supporting evidence. The main source of evidence comes from published biomedical articles which contain accurate and reliable experimental results. Usually, curators have to read newly published papers to update their databases, and obviously they can hardly keep up with the rapidly growing number of new biomedical papers.</p><p>Efforts have been made to automatically annotate proteins with GO terms based on analysis of biomedical literature <ref type="bibr" coords="1,196.32,582.59,11.57,11.89" target="#b5">[6,</ref><ref type="bibr" coords="1,212.52,582.59,7.96,11.89" target="#b6">7,</ref><ref type="bibr" coords="1,225.11,582.59,12.64,11.89" target="#b9">10]</ref>. None of these works, however, exploited full-text articles, which have been shown to contain more information than abstracts <ref type="bibr" coords="1,412.56,594.95,11.28,11.89" target="#b7">[8]</ref>. The BioCreative workshop 2004 [16] initiated a GO annotation task, and provided 636 full-text documents from the Journal of Biological Chemistry. The evaluation was manually done by curators, and the overall results showed low performances which indicated a long way from practical application. Therefore, the categorization task in TREC 2004 genomics track <ref type="bibr" coords="1,371.88,644.15,17.86,11.89">[13]</ref> was simplified and limited to assignment of the three main categories. Also, full-text documents from three journals over two years were provided in this task.</p><p>The categorization task tried to mimic two of the classification activities carried out by human annotators in the mouse genome informatics (MGI) [15] system: a triage task and two variants of MGI's annotation task. Curators at MGI employ a three-step process to identify the papers most likely to describe gene function. First, articles from several hundred journals are searched for keywords mouse, mice, or murine. Second, confronted with articles from the first step, curators determine which articles should be sent for curation. The goal for this triage process is to limit the number of articles for more exhaustive analysis. Finally, curators identify genes for which there are experimental evidence supporting assignment of GO terms.</p><p>Because of limited resources and time constraints, we did only the triage subtask. The goal of this task is to correctly identify which papers have been deemed to have experimental evidence warranting annotation of certain GO codes. Since this task can readily be regarded as a binary classification problem, we employed Support Vector Machines (SVMs) <ref type="bibr" coords="2,401.28,191.99,11.37,11.89" target="#b8">[9]</ref>, which are especially suitable for binary classification problems.</p><p>Feature extraction is the key to successful classification in the machine learning approach, and is even more important than the underlying classification algorithm. When it comes to text categorization, the simple bag-of-words representation is often the first choice. However, the performance of cross validation on this simple approach was only about 0.1 in normalized utility (NU) measure <ref type="bibr" coords="2,153.24,265.79,16.36,11.89">[13]</ref>. Therefore, we tried some other representations and settled down to the one adopted in this paper. First, we obtained a list of GO terms <ref type="bibr" coords="2,343.80,278.15,17.39,11.89">[11]</ref> annotated to MGI markers. Then, a document was represented by the similarities to those GO terms. The details of this approach are discussed in the Section 3.</p><p>The rest of this paper is organized as follows. Section 2 presents the overview of our architecture. The basic idea and the experimental methods in this study are introduced in Section 3. Section 4 shows the results and makes some discussions. Finally, Section 5 concludes the remarks and suggests some future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architecture Overview</head><p>Figure <ref type="figure" coords="2,118.68,649.91,5.37,11.89" target="#fig_0">1</ref> shows the overall architecture of our method for the triage task. First, we obtained a list of N GO terms from the MGI website <ref type="bibr" coords="2,255.72,662.15,15.97,11.89">[11]</ref>. With M training documents available, we extracted a list of keywords for each document. Each document was then represented by the vector sum of similarity between each keyword and the list of N GO terms, forming an N-element vector. Detail of the conversion process is explained in Section 3. A SVM classifier was trained with the resulting M N-element vectors. Given a test document, it was converted to an N-element vector through the same process performed on those training documents. Afterwards, this test instance was sent to the trained SVM classifier to decide whether it is relevant or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Preprocessing</head><p>Before performing classification, two document preprocessing operations were performed to extract more information from the full-text documents. The two operations were (1) acronym expansion and ( <ref type="formula" coords="3,155.87,208.31,4.19,11.89">2</ref>) keyword extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acronym expansion</head><p>Once the combination of sections was decided, which is explained in Section 3.3, an operation was performed to substitute the long forms for the tagged acronyms, each of which referred to a glossary entry in the document. The reason for this operation is that acronyms are sometimes ambiguous, and their long forms obviously carry more information. An example of this operation is shown in Figure <ref type="figure" coords="3,181.80,299.87,3.98,11.89" target="#fig_1">2</ref>. In Figure <ref type="figure" coords="3,249.72,299.87,3.98,11.89" target="#fig_1">2</ref>, an abbreviation "IP 3 " will be replaced with "inositol trisphosphase (IP 3 )".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keyword extraction</head><p>After the acronym operation, the remaining SGML tags were removed from the documents for later keyword extraction. With the 554K-entry inflection table found in UMLS Knowledge Sources <ref type="bibr" coords="3,125.88,535.43,11.28,11.89" target="#b4">[5]</ref>, the keywords were normalized and extracted from each document. In this step, only words that occur in both the inflection table and the document were extracted and normalized. The normalization here refers to the transformation of words to their root forms. For example, a verb in the past tense like "demonstrated" is normalized to its base form "demonstrate". Moreover, a plural noun like "receptors" is normalized to its singular form "receptor". Then, stop words were removed in the next stage. An example of keyword extraction is shown in Figure <ref type="figure" coords="3,173.52,609.23,3.99,11.89" target="#fig_2">3</ref>. The upper left part of Figure <ref type="figure" coords="3,316.08,609.23,5.37,11.89" target="#fig_2">3</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Extraction</head><p>Under the bag-of-words representation, the feature vector of an article was 23K long and the resulting dataset severely suffered from the data sparseness problem. Therefore, we attempted to solve this problem by reducing the dimension of feature vector via a list of N GO terms. Given a keyword, the similarity vector V k for this keyword is the similarity between this keyword and the N GO terms. The feature vector V D for a document is therefore the vector sum of the similarity vectors of all keywords it contains. In our study, Classic Dice (CD) coefficient was adopted as the similarity measure, and stop words were ignored at this stage. The formulas of computing the CD coefficient and similarity values are listed below.</p><formula xml:id="formula_0" coords="4,99.24,535.70,128.10,15.25">( , ) (2 )/( ) CD A B Z X Y = ×</formula><p>+ , where A, B are two strings, X is the number of tokens in A, Y is the number of tokens in B, and Z is the number of tokens occurring in both A and B.</p><formula xml:id="formula_1" coords="4,99.60,565.49,273.29,16.25">1 2 ( , ) ( , ) ( , ) ... ( , ) t k k k k k N w CD w t CD w t CD w t = = V Sim T [ ] ,</formula><p>where w k is a keyword and T is the vector of N GO terms, t 1 , t 2 and t N is the first, second and Nth GO term, respectively.</p><formula xml:id="formula_2" coords="4,99.60,596.32,51.48,24.41">D k k D = V</formula><p>V , where D is a document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Exploitation of Full Text Documents</head><p>Which sections of an article should be the targets of feature extraction is also an important issue.</p><p>In other words, we have to find out where the experimental evidence warranting annotation with GO codes resides in a document. The triage subtask is very much similar to the task 1 in KDD  combination of the title, abstract, figure captions and table captions as the base combination, and gradually included some other sections of the article to the base combination. Two other combinations were therefore constructed. Unfortunately, none of them outperformed the base combination under the aforementioned feature extraction method. These two combinations are briefly described below. Some types of documents do not have the abstract part, and hence in this case, the body of the article is added to the simple combination, forming the second combination. In other words, if the abstract is absent, the body of the article is added to form the second combination. For third one, if the abstract is present, the result, discussion, and conclusion sections are included. While these sections are intuitively evidence-rich sections, the third combination did not stand out as expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">SVM Classification</head><p>The software package LIBSVM <ref type="bibr" coords="5,228.73,281.15,12.57,11.89" target="#b3">[4]</ref> was employed to deal with SVM-related operations. Radial basis function was adopted as the kernel function, and 4-fold cross validation was performed to select the model attaining the highest normalized utility, i.e., the best-performing parameters -C and gamma, which are the penalty constant in optimization and the parameter for radial basis kernel, respectively. Under our feature extraction method, the selected values for C and gamma are around 64 and 3.81 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Normalization versus Stemming</head><p>Due to time constrains, some of the methods simply followed our intuition without further verification or experience backup. The one in which we were interested the most is using normalization instead of stemming, which is a usual preprocessing operation in text categorization. Unlike stemming, normalization is more precise because it converts words to their base forms without losing too much information. As expected, further experiment displayed a 0.03 NU drop in the stemmed version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussions</head><p>Table <ref type="table" coords="5,114.72,567.59,5.37,11.89" target="#tab_2">1</ref> lists the results of our three official runs, the results of two other top-performing teams, and the results of the median-performing run and the worst-performing run. As mentioned in Section 3.3, NTU2v3N1 used the base combination, NTU3v3N1 used the second combination, and NTU4v3N1416 used the third combination. It seems that adding other sections besides the title, abstract, and captions introduced more noise and less useful information. The results may be explained by Schuemie et al.'s finding <ref type="bibr" coords="5,261.72,629.15,12.57,11.89" target="#b7">[8]</ref> that the information density is higher in the abstract than in all the other four standard sections -Introduction, Methods, Results and Discussion. Therefore, some filtering techniques should be applied to these four sections to remove non-informative and noisy contents. The official run dimacsTfl9d was produced by Dayanik et al.'s system <ref type="bibr" coords="5,413.64,678.47,12.58,11.89" target="#b1">[2]</ref> which attained the best performance. Besides the title and abstract of an article, they used the MeSH terms attached to the article as the target of feature extraction. Bayesian logistic regression was adopted to perform classification. They also performed an interesting experiment which depended only on the MeSH term "Mice" to make the decision, and found that using this term alone can outperform all the other systems. Fujita's system <ref type="bibr" coords="6,260.40,118.07,12.57,11.89" target="#b2">[3]</ref> achieved slightly lower performance of 0.5494 NU (pllsgen4t3). They used terms from full text, gene entities and MeSH terms as the targets of feature extraction, and used SVM as the classifier. It is obvious that MeSH terms played an important role in distinguishing positive documents from negative ones, especially the term "Mice". Since this task aimed to assist curators at MGI, it is reasonable that articles attached with the MeSH term "Mice" are very likely to be positive. Therefore, we can ascribe the high performance of these two systems to the use of MeSH terms.</p><p>As there are 375/420 positive examples and 5462/5623 negative examples in the training/test dataset, the curators at MGI will have to read about 15 papers to find a positive one if they do not get any hints in advance. For the best official run (dimacsTfl9d), curators will have to read roughly 6 papers to find one useful, and around 88 percent of the positive papers can be retrieved. Using our approach, curators will have to read roughly 10 papers to find one useful and only 69 percent of the positive papers can be retrieved. To put it in another way, the best run reduced from 15 to 6 the number of papers that the curators have to read to get a positive one, losing 12 percent of the useful papers. In our opinion, the best official run greatly alleviated the burden of curators, and our approach didn't seem to help a lot. However, it is possible to combine our approach with others, making the filtering job even more effective. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We demonstrate our approach based on a list of GO terms in this paper. We tried three combinations of sections in an article as the target of feature extraction, and found the simplest one most useful. We hypothesize that filtering should be applied to sections other than Abstract before they can be used for feature extraction. Also, we found that normalization is a better preprocessing operation than stemming under our feature extraction approach. Without the use of MeSH terms, our system performed slightly better than the median-performing system. With our approach, 69 percent of positive papers were retained at the precision rate of 10 percent. Although we didn't achieve the best performance, it is possible to incorporate other ideas into our method, and combine other types of features with the existing ones.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,229.32,588.23,117.53,11.89"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System overview.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,198.48,437.15,190.49,11.89"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of acronym operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,156.36,350.03,273.41,11.89"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example of keyword extraction and normalization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,188.52,341.32,5.55,7.50;5,194.04,342.71,314.49,11.89;5,87.48,355.07,421.05,11.89;5,87.48,367.31,420.93,11.89;5,87.48,379.55,420.89,11.89;5,87.48,392.03,38.49,11.89;5,126.00,397.00,21.13,7.50;5,149.76,392.03,28.89,11.89;5,178.68,397.00,23.05,7.50;5,204.24,392.03,231.28,11.89"><head>- 6 .</head><label>6</label><figDesc>Another issue worth addressing is the imbalance among the number of training and test examples. For the training data, there are 375 positive examples and 5462 negative examples, the ratio of which is about 1 to 20. Therefore, we tried to put more weights on the positive examples, i.e., the positive examples received larger C in SVM training. As expected, setting C positive to 20C negative achieved the best performance in our cross validation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,87.48,348.67,420.94,297.05"><head></head><label></label><figDesc>contains the target document for keyword extraction. The lower left part illustrates the inflection table found in UMLS. The right part shows the extracted and normalized list of keywords.</figDesc><table coords="3,93.96,348.67,382.02,56.26"><row><cell cols="3">It is presently unclear how these receptors</cell><cell>It is presently unclear how these receptors could</cell></row><row><cell cols="3">could selectively mediate cAMP responses to</cell><cell>selectively mediate cAMP responses to sugars and</cell></row><row><cell>sugars</cell><cell>and</cell><cell>&lt;GLOSREF</cell><cell>inositol trisphosphate (IP&lt;INF&gt;3&lt;/INF&gt;) responses</cell></row><row><cell cols="3">RID="G3"&gt;IP&lt;INF&gt;3&lt;/INF&gt;&lt;/GLOSREF&gt;</cell><cell>to artificial sweeteners.</cell></row><row><cell cols="2">responses to artificial sweeteners.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,149.88,338.63,296.13,177.25"><head>Table 1 :</head><label>1</label><figDesc>Results of official runs in the triage task.</figDesc><table coords="6,149.88,359.63,296.13,156.25"><row><cell></cell><cell cols="2">Normalized Utility F-score Recall Precision</cell></row><row><cell>dimacsTfl9d</cell><cell>0.6512</cell><cell>0.2681 0.8881 0.1579</cell></row><row><cell>"Mice" run</cell><cell>0.6404</cell><cell>0.2572 0.8929 0.1502</cell></row><row><cell>pllsgen4t3</cell><cell>0.5494</cell><cell>0.2496 0.769 0.149</cell></row><row><cell>NTU2v3N1</cell><cell>0.3810</cell><cell>0.1752 0.6905 0.1003</cell></row><row><cell>NTU3v3N1</cell><cell>0.3601</cell><cell>0.1673 0.6857 0.0953</cell></row><row><cell>Median</cell><cell>0.3425</cell><cell>0.2345 0.469 0.1563</cell></row><row><cell cols="2">NTU4v3N1416 0.3323</cell><cell>0.1650 0.6357 0.0948</cell></row><row><cell>Worst</cell><cell>0.0114</cell><cell>0.0267 0.0143 0.2</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,104.40,134.03,404.01,11.89;7,105.00,146.39,344.08,11.89" xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,485.76,134.03,22.65,11.89;7,105.00,146.39,268.83,11.89">Gene Ontology: Tool for the Unification of Biology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Nature Genetics</note>
</biblStruct>

<biblStruct coords="7,103.20,170.99,405.29,11.89;7,105.00,183.23,403.49,11.89;7,105.00,195.59,24.05,11.89" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dayanik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fradkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Madigan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Menkov</surname></persName>
		</author>
		<title level="m" coord="7,105.00,183.23,355.68,11.89">DIMACS at the TREC 2004 Genomics Track (DRAFT)</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="162" to="171" />
		</imprint>
	</monogr>
	<note>TREC 2004 Notebook</note>
</biblStruct>

<biblStruct coords="7,105.48,220.31,402.93,11.89;7,105.00,232.55,266.20,11.89" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,155.16,220.31,353.25,11.89;7,105.00,232.55,193.55,11.89">Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis, TREC 2004 Notebook</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="152" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.01,257.15,403.36,11.89;7,105.00,269.39,253.73,11.89" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html" />
		<title level="m" coord="7,281.04,257.15,223.22,11.89">A Practical Guide to Support Vector Classification</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,103.20,294.11,405.23,11.89;7,105.00,306.35,403.55,11.89;7,105.00,318.71,178.48,11.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,417.36,294.11,91.08,11.89;7,105.00,306.35,259.40,11.89">The Unified Medical Language System: an Informatics Research Collaboration</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M</forename><surname>Schoolman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">O</forename><surname>Barnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,374.28,306.35,134.27,11.89;7,105.00,318.71,101.86,11.89">Journal of American Medical Information Association</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,103.32,343.43,405.09,11.89;7,105.00,355.67,285.05,11.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,345.60,343.43,162.81,11.89;7,105.00,355.67,106.14,11.89">DIAN: a novel algorithm for genome ontological classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Pouliot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">B</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,217.68,355.67,75.88,11.89">Genome Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1766" to="1776" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,103.20,380.27,405.44,11.89;7,105.00,392.51,403.49,11.89;7,105.00,404.99,107.32,11.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,413.64,380.27,95.00,11.89;7,105.00,392.51,276.52,11.89">Gene annotation from scientific literature using mappings between keyword systems</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Prérez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Perez-Iratxeta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Thode</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Andrade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,391.08,392.51,112.98,11.89">Journal of Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2084" to="2091" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,104.04,429.47,404.45,11.89;7,105.00,441.83,403.42,11.89;7,105.00,454.07,318.16,11.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,266.88,441.83,241.54,11.89;7,105.00,454.07,87.98,11.89">Distribution of information in biomedical abstracts and full-text publications</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Weeber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J A</forename><surname>Schijvenaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Van Der Eijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jelier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mons</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,199.92,454.07,108.79,11.89">Journal of Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2597" to="2604" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,102.48,478.79,331.73,11.89" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,152.40,478.79,176.80,11.89">The Nature of Statistical Learning Theory</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,108.72,503.39,399.76,11.89;7,105.00,515.63,396.88,11.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,105.00,515.63,227.59,11.89">Large-scale protein annotation through gene ontology</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wasserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Novik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Grebinskiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shoshan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,339.84,515.63,75.88,11.89">Genome Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="785" to="794" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
