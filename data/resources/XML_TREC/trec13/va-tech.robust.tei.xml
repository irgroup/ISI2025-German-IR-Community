<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,109.56,75.94,392.87,14.42">Can We Get A Better Retrieval Function From Machine?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,87.01,125.42,42.24,10.80"><forename type="first">Li</forename><surname>Wang</surname></persName>
							<email>wang@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Ross School of Business Pamplin College of Business Department of Computer Science</orgName>
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,215.96,125.42,58.92,10.80"><forename type="first">Weiguo</forename><surname>Fan</surname></persName>
							<email>wfan@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Ross School of Business Pamplin College of Business Department of Computer Science</orgName>
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,350.92,125.42,45.68,10.80"><forename type="first">Wensi</forename><surname>Xi</surname></persName>
							<email>xwensi@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Ross School of Business Pamplin College of Business Department of Computer Science</orgName>
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,449.95,125.42,73.68,10.80"><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
							<email>fox@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Ross School of Business Pamplin College of Business Department of Computer Science</orgName>
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.26,150.24,55.79,9.02"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
							<affiliation key="aff1">
								<address>
									<settlement>Virginia Tech Ann Arbor, Blacksburg, Blacksburg</settlement>
									<region>MI, VA, VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,109.56,75.94,392.87,14.42">Can We Get A Better Retrieval Function From Machine?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C8CA1CA6E53EFB567249B1DCB4B64035</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine Learning</term>
					<term>Retrieval Function</term>
					<term>Query Expansion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The quality of an information retrieval system heavily depends on its retrieval function, which returns a similarity measurement between the query and each document in the collection. Documents are sorted according to their similarity values with the query and those with high rank are assumed to be relevant. Okapi BM25 and their variations are very popular retrieval functions and they seem to be the default retrieval function for the IR research community; and there are many other widely used and well studied functions, for example, Pivoted TFIDF and INQUERY. Most of these retrieval functions being used today are made based on probabilistic theories and they are adjusted in real world according to different contexts and information needs. In this paper, we propose the idea that a good retrieval function can be discovered by a pure machine learning approach, without using probabilistic theories and knowledge-based techniques. Two machine learning algorithms, Support Vector Machine (SVM) and Genetic Programming (GP) are used for retrieval function discovery, and GP is found to be a more effective approach. The retrieval functions discovered by GP might be hard for human interpretation, but their performance is superior to Okapi BM25, one of the most popular functions. The new retrieval function is combined with query expansion techniques and the retrieval performance is improved significantly. Based on our observations in the empirical study, the GP function is more reliable and effective than Okapi BM25 when query expansion techniques are used.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Retrieval function is one of the most important components in an information retrieval system. For a query submitted by the user, retrieval function is used to measure the similarity between query and each document in the collection. Then documents are sorted according to their similarity measurements and the documents ranked to the top are assumed to be relevant to this specific query.</p><p>Although there are many other criteria for evaluating an information retrieval system, such as response time of the search engine and volume of its collection, the accuracy of returned documents is a critical index for the performance of an IR system. The accuracy can be measured by recall, precision, or mean average precision (MAP) which is a compromise between recall and precision.</p><p>Under the same conditions, such as the same document collection, preprocessing procedure for documents, indexing method and etc., the accuracy of an IR system completely depends on how effective its retrieval function is.</p><p>There are many popular and well established retrieval functions, such as Pivoted TFIDF <ref type="bibr" coords="2,513.72,326.66,14.01,10.80" target="#b1">[1]</ref> and Okapi BM25 <ref type="bibr" coords="2,130.95,347.36,12.75,10.80" target="#b2">[2]</ref>. They have been thoroughly studied, widely used in real world and proved to be effective. These functions are invented by information retrieval experts, guided by probabilistic theories and their prior experience. They share the same property that the function has simple format and can be easily interpreted. According to different contexts and information needs, many variations of these functions have been created in practice, by either adjusting parameter values or modifying some fragments in the function. The first approach can not alter the framework of a retrieval function. The later one is conducted either based on theories or by trial-and-error approach.</p><p>The methodology of discovering new functions is not changed. The machine/statistical learning algorithms have been used; however their success is limited on parameter tuning and estimation. A new function or model still has to be proposed by human experts, and then its effectiveness is finetuned by a machine learning approach for different tasks.</p><p>Can we completely rely on machines to construct retrieval functions for us? Can the functions discovered by machine beat those made by human experts? This is the basic incentive of our research. We use two popular machine learning algorithms, kernel based Support Vector Machine (SVM) <ref type="bibr" coords="2,101.07,637.16,13.99,10.80" target="#b3">[3]</ref> and genetic programming (GP) <ref type="bibr" coords="2,276.02,637.16,12.75,10.80" target="#b4">[4]</ref>, in our experiments for retrieval function discovery.</p><p>The new retrieval functions found by each approach are compared with Okapi BM25, which has the best performance among traditional functions in our experiment. Kernel based SVM is found not an effective tool for retrieval function discovery task in our experiment; but genetic programming gives inspiring results. Many retrieval functions constructed by GP are able to outperform Okapi BM25.</p><p>Based on the best GP function, several automatic query expansion algorithms are used to further improve the retrieval performance. An empirical study is conducted to explore how GP-discovered function works with query expansion algorithms. Large scale experiments are done for this purpose.</p><p>When combined with query expansion, the GP function can get a significantly better performance, measured as MAP, than the baseline system using Okapi BM25. From the observation of MAP surface, the GP function is more robust to the parameter settings than Okapi BM25; and with GP function people have more chance to reach the optimal settings of query expansion using design of experiment (DOE) approach in practice.</p><p>The reminder of the paper is organized as follows: Section 2 gives a brief description of our automatic retrieval function discovery mechanism and the retrieval function performance comparison; Section 3 introduces the empirical study on query expansion algorithms; Section 4 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Automatic Retrieval Function Discovery</head><p>The problem we are studying is the traditional 2-class classification problem. Given a user query and a document, we need to predict whether this document belongs to class 0 (irrelevant document) or class 1 (relevant document), according to predictors extracted from the query and document. The training data can be obtained from previous TREC results. For the predictors, we take those used in traditional retrieval functions, such as term frequency within the document (tf), term frequency within the query (qtf), document frequency for a term (df) and etc.</p><p>The 2-class classification problem has been well studied and there are quite a few existing algorithms suitable for this task, such as linear regression, logistics regression, Linear Discrimimnant Analysis (LDA) and Quadratic Discriminant Analysis (QDA) <ref type="bibr" coords="3,362.29,575.06,12.75,10.80" target="#b5">[5]</ref>. All of these methods need a given model; then they minimize the misclassification rate or other object function by adjusting parameter values within that framework. A trial-and-error approach has to be used to explore the infinite model space, which consists of all possible combinations of predictors. Therefore these algorithms largely depend on human input and it is hard to arrive at a potentially useful model which might has extremely complex format. Support Vector Machine is another effective tool for 2-class classification problem and it also requires a given model. However when using the kernel method, SVM essentially transforms the given linear predictor space into a nonlinear higher-dimensional or even infinite-dimensional predictor space, reproducing kernel Hillbert space (RKHR). Therefore it has potential to provide a good retrieval function which is flexible and complex.</p><p>Genetic programming is another algorithm that can be used. Different from the approaches above, there is no sound mathematical explanation for its success in practice. GP algorithm often shows its edge where the solution has high complexity and when the usual analytical methods fail. The details of experiment setting can be found in <ref type="bibr" coords="4,245.25,199.04,12.74,10.80">[6]</ref>.</p><p>We used kernel-based SVM and GP in our experiments for retrieval function discovery. Some mechanisms are needed to prevent over-fitting and reduce predicting error. K-fold cross-validation is a popular method for this purpose. However, the training process for retrieval function discovery is already computational intense, we can not afford with the K-fold cross-validation here. Instead, we use the setup with independent training, validation and testing data to control over-fitting and choose models. These three independent data are randomly picked from previous TREC queries and data sets.</p><p>After choosing different kernels for SVM and manually expanding the predictor space, the SVM algorithm still can not provide a retrieval function with satisfactory performance on the testing data.</p><p>But the GP method gives us pretty inspiring results. It generates a group of models that have better MAP than Okapi BM25 on validation and testing data sets. These GP functions are further tested using the 150 queries from TREC 6 -8 and 50 new queries from Robust Track of TREC 2003.</p><p>Figure <ref type="figure" coords="4,97.90,468.08,6.00,10.80">1</ref> shows the performance comparison between Okapi BM25 and the GP function used in our retrieval system on different fields of queries. Based on 200 queries in previous TRECs, the GP function improves the MAP performance by 10.6%, 4.5% and 7.7%, on description field, title field and all fields, respectively. The performance improvement is significant using an ANOVA test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Empirical Study on Query Expansion</head><p>Query expansion, or blind feedback, is a useful technique for boosting retrieval performance. It uses a two stage retrieval strategy. In the first stage, a preliminary rank list for the query is returned using the retrieval function; then without actual user feedback, it assumes the top D documents in that rank list are relevant to the query and uses an algorithm to pick T words from the words contained in original query as well as in those D documents. There are many popular query expansion techniques, such as Rocchio, Ide Dec-Hi, KLD, RSV and CHI <ref type="bibr" coords="5,368.07,305.96,12.75,10.80" target="#b7">[7]</ref>, which use different algorithms to pick the new query with T words in it. Figure <ref type="figure" coords="5,287.88,326.66,6.00,10.80">2</ref> shows the performances of our baseline system with</p><p>Okapi BM25 and our submissions, where GP function and query expansion technique are combined. </p><note type="other">Figure 2</note><p>Evaluated by 200 queries from TREC 6-8 and TREC 2003, combining GP function and query expansion technique provides 29.3%, 30.2% and 22.5% improvements over our baseline system using Okapi BM25 on description field, title field and all fields, respectively.</p><p>Figure <ref type="figure" coords="5,112.87,681.38,6.00,10.80">3</ref> shows the comparison between the performance of our submissions and the best performance achieved for Okapi BM25 in our extensive experiments where query expansion techniques are applied. GP function has 8.4%, 8.6% and 6.8% performance improvements over Okapi BM25 on different fields of queries. However the performances shown for Okapi BM25</p><p>might not be achieved in practice. It will be explained in the next section. </p><note type="other">Figure 3</note><p>All of the blind feedback algorithms need two common parameters, D and T. According to our experience, the performance of these query expansion techniques is rather sensitive to the chosen values for D and T. Theoretically it is better to use an adaptive approach for choosing D and T values for each query, where a machine/statistical learning algorithm can be used to determine the best D and T combination from predictors, but we suspect the effectiveness and robustness of such a strategy in our experiments. Instead, we simply use a constant (D, T) pair within each query expansion algorithm. Since every point (D, T) corresponds to a performance measurement that the system achieves with that setup, we need to search the optimal point in this 2-dimensional space.</p><p>However we can not find any theories to describe and predict the shape of such surface. It can only be learned via experiments. Since the computational cost for getting the performance measurement at a single (D, T) point is not cheap, in practice the design of experiment (DOE) approach should be used in order to avoid extensive searching and to achieve a relatively optimal solution.</p><p>Large scale experiments are conducted in our research to learn the big picture of performance This observation suggests the property of robustness for GP function. (2) Although the surfaces of GP function are not strictly concave, it is not too far from it; however the Okapi BM25 surfaces are pretty irregular, with many local maximums. This implies that in practice it is more likely and easier to achieve the optimal setting for GP function, while using Okapi BM25 people can be trapped into local maximums. In Figure <ref type="figure" coords="8,199.33,199.04,4.51,10.80">3</ref>, it shows the performance comparison between GP function and Okapi BM25 when query expansions are applied to both functions. We take the best performance of Okapi BM25 based on our extensive experiments. However these performances can be hardly achieved in practice when large scale experiments are not affordable.</p><p>The contour plots confirm our conclusions in 3-D plots. We can find that the area of the highest performance regions for GP function is more regular and larger than area of the corresponding Okapi BM25 in contour plots. That is the indicator for robustness. In the contour plots of GP function, a global maximum is surrounded by nearly parallel contour lines; but in those of Okapi BM25, multiple local maximums exist and the contour lines are jerky. Therefore starting from an arbitrary setting, it is easier for GP function to reach the global maximum if we follow the direction suggested by maximal gradient at each step.</p><p>From our empirical study, we can conclude that when combined with blind feedback techniques:</p><p>(1) GP function is more robust to parameter settings than Okapi BM25; <ref type="bibr" coords="8,412.20,447.38,14.00,10.80" target="#b2">(2)</ref> We have more chance to find the optimal parameter setting with GP function than Okapi BM25 in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this paper, we used a non-knowledge based technique to construct the retrieval function and compare its performance with the popular retrieval functions made by experts. Our retrieval function itself is proved to be more effective than any of these existing functions. The blind feedback techniques were further combined and large scale experiments were conducted to test performances of our function and Okapi BM25 under various settings. The new retrieval function discovered by GP has superior performance to Okapi BM25 when blind feedback is applied. From the empirical study of performance surfaces, we find many pleasing properties of the GP-learned function.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,290.97,715.70,40.34,10.80"><head></head><label></label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,135.00,412.70,336.72,10.80"><head>(Figure 4 3 -Figure 5</head><label>435</label><figDesc>Figure 4 3-D Performance Surface for GP function and Okapi BM25</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Acknowledgement</head><p>We are grateful to <rs type="person">Ming Luo</rs> and <rs type="person">Ye Zhou</rs> for their programming support.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,68.24,161.75,74.00,12.58" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.01,185.24,403.84,10.80;9,99.00,199.04,336.67,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,343.49,185.24,149.42,10.80">Document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,99.00,199.04,197.37,10.80">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="619" to="633" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.02,212.84,435.54,10.80;9,99.00,226.64,436.15,10.80;9,99.00,240.44,79.01,10.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,494.37,212.84,40.19,10.80;9,99.00,226.64,36.42,10.80">Okapi at TREC-4</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,162.90,226.64,270.64,10.80">the Proceedings of the Fourth Text Retrieval Conference</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="73" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.00,254.24,271.38,10.80" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m" coord="9,169.68,254.24,130.06,10.80">Statistical Learning Theory</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.01,268.04,443.43,10.80;9,99.00,281.84,248.27,10.80" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,154.98,268.04,387.46,10.80;9,99.00,281.84,42.34,10.80">Genetic Programming: On the Programming of Computers by Means of Natural Selection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Koza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.01,295.64,424.96,10.80;9,99.00,309.44,100.98,10.80" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<title level="m" coord="9,294.72,295.64,103.96,10.80">Pattern Classification</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.03,323.24,419.60,10.80;9,99.00,337.04,425.77,10.80;9,99.00,350.90,443.24,10.80;9,99.00,364.64,110.64,10.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,344.35,323.24,174.27,10.80;9,99.00,337.04,272.79,10.80">Tuning before feedback: Combining ranking discovery and blind feedback for robust retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,395.76,337.04,129.01,10.80;9,99.00,350.90,443.24,10.80;9,99.00,364.64,42.64,10.80">the Proceedings of the27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,99.01,378.44,446.07,10.80;9,99.00,392.24,428.11,10.80;9,99.00,406.04,57.66,10.80" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,290.89,378.44,254.18,10.80;9,99.00,392.24,256.50,10.80">Effective profiling of consumer information retrieval needs: a unified framework and empirical comparison</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pathak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Decision Support Systems, pp. in press</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
