<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.63,72.44,406.45,16.59">DIMACS AT THE TREC 2004 GENOMICS TRACK</title>
				<funder>
					<orgName type="full">KD-D group</orgName>
				</funder>
				<funder ref="#_c3XaUdU">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,143.78,118.01,73.95,11.06"><forename type="first">Aynur</forename><surname>Dayanik</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Aqsaqal Enterprises</orgName>
								<address>
									<settlement>Penticton</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.06,118.01,77.98,11.06"><forename type="first">Dmitriy</forename><surname>Fradkin</surname></persName>
							<email>dfradkin@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Aqsaqal Enterprises</orgName>
								<address>
									<settlement>Penticton</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.69,118.01,61.45,11.06"><forename type="first">Alex</forename><surname>Genkin</surname></persName>
							<email>agenkin@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Aqsaqal Enterprises</orgName>
								<address>
									<settlement>Penticton</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.52,118.01,59.93,11.06"><forename type="first">Paul</forename><surname>Kantor</surname></persName>
							<email>paul.kantor@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Aqsaqal Enterprises</orgName>
								<address>
									<settlement>Penticton</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,168.88,129.67,76.39,11.06"><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
						</author>
						<author>
							<persName coords="1,258.02,129.67,76.26,11.06"><forename type="first">David</forename><surname>Madigan</surname></persName>
							<email>dmadigan@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Aqsaqal Enterprises</orgName>
								<address>
									<settlement>Penticton</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.26,129.67,86.00,11.06"><forename type="first">Vladimir</forename><surname>Menkov</surname></persName>
							<email>vmenkov@cs.indiana.edu</email>
						</author>
						<author>
							<persName coords="1,251.48,174.65,104.88,6.99"><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis Consulting</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">DIMACS</orgName>
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.63,72.44,406.45,16.59">DIMACS AT THE TREC 2004 GENOMICS TRACK</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F583F3A1B930A5B19FDAC957E6565FF6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>DIMACS participated in the text categorization and ad hoc retrieval tasks of the TREC 2004 Genomics track. For the categorization task, we tackled the triage and annotation hierarchy subtasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">TEXT CATEGORIZATION TASK</head><p>The Mouse Genome Informatics (MGI) project of the Jackson Laboratory<ref type="foot" coords="1,132.48,314.03,3.65,5.24" target="#foot_0">1</ref> provides data on the genetics, genomics, and biology of the laboratory mouse. In particular, the Mouse Genome Database (MGD) contains information on the characteristics and functions of genes in the mouse, and on where this information appeared in the scientific literature. Human curators encode this information using controlled vocabulary terms from the Gene Ontology<ref type="foot" coords="1,260.47,376.79,3.65,5.24" target="#foot_1">2</ref> (GO), and provide citations to documents that report each piece of information. GO consists of three structured networks: Biological Process (BP), Molecular Function (MF), and Cellular Component (CC)) of terms describing attributes of genes and gene products.</p><p>The TREC 2004 Genomics track defined a categorization task with three subtasks based on simplified versions of this curation process. DIMACS participated in two of those subtasks, triage and annotation hierarchy, but not in the annotation hierarchy plus evidence subtask. We discuss our two subtasks below, and full details are available in the track overview paper <ref type="bibr" coords="1,117.59,504.09,9.22,7.86" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Triage Subtask</head><p>To find information on mouse genes, MGI first automatically scans new scientific literature for records containing one or more of the words "mouse", "mice", and "murine". In a triage step, MGI personnel then check each article to see if it contains information appropriate for inclusion in MGD. (The triage step also identifies articles for other purposes, but we can ignore that here.)</p><p>The TREC 2004 triage subtask is intended to simulate the problem faced by triage personnel. Full text articles published in 2002 and 2003 by three major journals were obtained. Those articles containing "mouse", "mice", or "murine" were identified and separated into a training set (5837 documents from 2002) and a test set (6043 documents from 2003).</p><p>The goal for subtask participants was to identify which of the articles from the test set had, during MGI's operational manual triage process, been chosen for sending to GO curators. (Whether curators had or hadn't actually linked to this document from any MGD entry was not an issue.) We can view this as a binary text classification problem, with articles chosen for curation during the triage process being positive examples, and those rejected during triage being negative examples. Logs from MGI were used to produce relevance judgments for the subtask data. Subtask participants were given the relevance judgments for the training set, which showed that 375 of the training set articles were positive examples (had been selected for curation) and 5462 training articles were negative examples. The test set relevance judgments, revealed after official runs were submitted, showed 420 positive and 5623 negative test examples. The official effectiveness measure for the triage subtask was this normalized linear utility:</p><formula xml:id="formula_0" coords="1,394.61,403.92,81.81,19.74">T 13N U = T 13U T 13Umax</formula><p>where T 13U = 20 * T P -F P T 13Umax = 20 * (T P + F N ). TP, FP, and FN are defined in the confusion matrix in Table <ref type="table" coords="1,316.81,490.33,3.59,7.86" target="#tab_0">1</ref>. Table <ref type="table" coords="1,352.16,490.33,4.61,7.86" target="#tab_1">2</ref> shows the values of T13NU for the boundary cases on the test data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Annotation Hierarchy Subtask</head><p>Articles that pass MGI's triage process are examined by GO curators. They identify mouse genes and gene products mentioned in the article, claims that they have certain characteristics, and the type of evidence for those characteristics. These characteristics are recorded using the appropriate GO terms, type of evidence is recorded using other codes, and the document is recorded as the source of the evidence.</p><p>The annotation hierarchy subtask is a very simplified version of this curation process. A system is given a pair (D, G), where G is a gene discussed in document D. The system must decide whether D's discussion of G contains information appropriate for coding with GO terms and, if so, in which of the three GO hierarchies those GO terms would fall. Systems are not required to identify the particular GO terms.</p><p>The distinct genes). These sets of pairs were formed by roughly this process:</p><p>1. A set of GO records were found that had links to documents from the track data set. One can think of the records as tuples of the form (G, GO term, evidence, D). These tuples were mapped to the form (D, G, XY ) by replacing the GO term with the label for the hierarchy it falls in (BP , CC, or M F ). Redundant tuples were discarded. This resulted in the records in the files pgd+train.txt and pgd+test.txt. The presence of a tuple (D, G, XY ) in, say, pgd+train.txt means that pair (D, G) is a positive example for class XY . If some (D, G, XY ) is present in one of these files, but (D, G, W Z) is not present for some W Z = XY , then (D, G) is a negative example for class W Z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>A set of documents from the track data set were found that were selected during triage for purposes other than GO curation. For each such document, and one or more genes identified in that document, a record of the form (D, G) was included in pg-train.txt or pgtest.txt. Each pair (D, G) in pg-train.txt and pg-test.txt is viewed as a negative example for all three of BP , CC, and M F .</p><p>Note that there are two sources of negative examples, but only one of positive examples. All examples, both positive and negative, are listed in pgtrain.txt and pgtest.txt. Thus, the goal of a system was to identify for each pair (D, G) in pgtest.txt, whether or not it should be assigned each of BP, CC, and MF.</p><p>We treated this decision as three separate binary classification problems. This meant we created three copies of the training and test vectors, one for each of GO hierarchy labels. A document/gene pair (D,G) became a positive example for label XY (where XY is BP, CC or MF) if a record of the form (D G XY) is present in pgd+train.txt or pgd+test.txt, and a negative example for XY otherwise. Table <ref type="table" coords="2,68.83,679.80,4.61,7.86" target="#tab_9">8</ref> shows the number of positive instances for each topic in training and test data.</p><p>The official effectiveness measure for the annotation hierarchy subtask is F1 (F-measure with equal weight on recall and precision) <ref type="bibr" coords="2,376.79,249.97,14.34,7.86" target="#b9">[10,</ref><ref type="bibr" coords="2,394.20,249.97,7.17,7.86" target="#b8">9,</ref><ref type="bibr" coords="2,404.44,249.97,7.17,7.86" target="#b4">5]</ref> where Precision (p) = T P/(T P + F P ) Recall (r) = T P/(T P + F N )</p><formula xml:id="formula_1" coords="2,374.19,294.25,162.32,19.74">F 1 = 2 * r * p r + p = 2 * T P 2 * T P + F P + F N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BAYESIAN LOGISTIC REGRESSION FOR THE TEXT CATEGORIZATION TASK</head><p>Logistic regression models estimate the probability that an example belongs to a class using this formula:</p><formula xml:id="formula_2" coords="2,321.32,385.75,228.89,23.68">p(yi = +1|β, xi) = exp(β T xi) 1 + exp(β T xi) = exp( j βjxi,j) 1 + exp( j βjxi,j)</formula><p>where yi encodes the class of example i (positive/relevant = +1, negative/nonrelevant = -1) and xi,j is the value of feature j for example i. The model parameters β are chosen by supervised learning, i.e. by optimizing some function defined on a set of examples for which manually judged values of yi are known.</p><p>In our work, we adopt a Bayesian framework and choose the β that maximizes the posterior loglikelihood of the data,</p><formula xml:id="formula_3" coords="2,343.48,508.64,185.78,26.84">l(β) = (- n i=1 ln(1 + exp(-β T xiyi)) + ln p(β),</formula><p>where p(β) is, for each β, the prior probability that β is the correct parameter vector. The prior p(β) encodes what we believe are likely values of β before seeing the training data.</p><p>Our experiments use the BBR (Bayesian Binary Regression) software. <ref type="foot" coords="2,375.10,585.00,3.65,5.24" target="#foot_2">3</ref> BBR supports two forms of priors: a separate Gaussian prior for each βj or a separate Laplace prior for each βj. (The overall prior is the product of the individual priors for feature parameters.) The key difference between the two is that Gaussian priors produce dense parameter vectors with many small but nonzero coefficients, while Laplace priors produce sparse feature vectors with most coefficients identically equal to 0.</p><p>We describe BBR and Bayesian logistic regression in detail elsewhere <ref type="bibr" coords="2,358.39,680.92,9.22,7.86" target="#b2">[3]</ref>. Here we review only a few details necessary to interpreting our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Choice of Hyperparameter</head><p>The Gaussian and Laplace priors have two hyperparameters for each model parameter βj: a modal value µj (the most likely prior value of βj), and a regularization hyperparameter (σ 2 j for Gaussian and λj for Laplace) that indicates how close to µj we expect βj to be. For simplicity, our TREC work assumes all µj's are 0, and that the regularization hyperparameter is the same for all features. This leaves a single regularization hyperparameter to be chosen for the whole model.</p><p>Rather than specifying this regularization hyperparameter manually based on our prior beliefs, we use an empirical Bayes approach <ref type="bibr" coords="3,119.24,185.66,9.22,7.86" target="#b1">[2]</ref>, and choose it by cross-validation on the training set. We consider a fixed set of hyperparameter values, and choose the one that maximizes the 10-fold crossvalidation estimate of mean posterior log-likelihood on the training data. The values considered were </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Threshold Selection</head><p>Logistic regression models estimate the probability that the example is a positive/relevant example. We then must convert this probability to a binary class label. The simplest approach is to define a threshold value that the estimated probability must exceed for the test example to be predicted to be relevant.</p><p>We tested two approaches to choosing a threshold for a categorization problem:</p><p>• MEE (Maximum Expected Effectiveness): Choose the threshold that maximizes the expected value of the subtask effectiveness measure on the test set, under the assumption that the estimated class membership probabilities are correct and independent <ref type="bibr" coords="3,245.31,536.64,9.22,7.86" target="#b4">[5]</ref>.</p><p>• TROT (Training set Optimization of Threshold): Choose the threshold that maximizes the subtask's effectiveness measure on the training set.</p><p>Both TROT and MEE were tested by cross-validation on the triage subtask training data. MEE was found consistently better and so was used for all our triage runs. The MEE threshold for the T13NU effectiveness measure is p(yi = +1) &gt;= 1/21 = 0.0476 on a probability scale.</p><p>TROT was used for all annotation runs. Computing the MEE threshold for F1 requires processing test examples as a batch <ref type="bibr" coords="3,86.82,669.06,9.22,7.86" target="#b4">[5]</ref>, something not allowed by the track guidelines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Two-Stage Classifiers</head><p>The importance of the MeSH term "Mice" in the triage subtask (see Section 4.2) was apparent in our experiments on the training set. Therefore, in addition to one-stage thresholded logistic regression models, we also tested the following two-stage classifier on the triage task:</p><p>1. IF a document does NOT contain the MeSH term "Mice" classify it as negative.</p><p>2. ELSE classify it using a thresholded logistic regression model.</p><p>The logistic regression models used in the two-stage classifier were trained only on training examples containing the MeSH term "Mice". The hope was that this would train the model to focus less on whether the document was about mice, and more on distinguishing whether evidence about gene characteristics was present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Upweighting of Positive Examples</head><p>The proportion of positive examples in the annotation hierarchy subtask was low, and for that subtask we experimented with upweighting positive training examples relative to negative ones. This was done by making w-1 extra copies of each positive training example. The weights tried were: w = 1 (no upweighting), w = 5, and w = 6. The replicated examples were used both when fitting model parameters and when tuning the threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TEXT REPRESENTATION FOR TEXT CATEGORIZATION SUBTASKS</head><p>The track provided the full text of the journal articles in both SGML and XML form. We used the XML versions from train.xml.zip and test.xml.zip. We also made use of additional descriptions of each article. The track files train.crosswalk.txt and test.crosswalk.txt specified the PubMed ID for each article. We used these IDs to obtain the MEDLINE record for each article either from the ad hoc track data, or by downloading from PubMed. 4  The MEDLINE records for 536 of the training articles and 408 of the test articles contain GenBank accession numbers for genes discussed in the article. While this is done for only a subset of genes mentioned, it is a useful clue when present, because the GenBank entry specifies the organism a gene was studied in. Using the accession number, we downloaded the corresponding GenBank 5 record, and extracted the organism name field.</p><p>These materials gave several alternative sources of representations for the training and test articles:</p><p>• Full Text: The union of text from the title (&lt;atl&gt;), subject (&lt;docsubj&gt;), abstract (&lt;abs&gt;), and body (&lt;bdy&gt;) XML elements of the article.</p><p>• Abstract: The union of text from the subject, title, and abstract of the article.</p><p>• MEDLINE: The MeSH terms, Medical Subject Headings, from the MEDLINE record (lines starting with "MH -" in ASCII text format), plus the union of text from the title (&lt;ArticleTitle&gt;) and abstract (&lt;Abstract&gt;) elements of that record. MeSH terms were converted to single tokens (Section 3.1) and so were kept distinct from the two text fields. 4 http://eutils.ncbi.nlm.nih.gov/entrez/query.fcgi 5 http://www.ncbi.nlm.nih.gov/entrez/batchentrez.cgi?db= Nucleotide</p><p>• MeSH: Only the MeSH terms from the MEDLINE record.</p><p>• GenBank: The organism name from the GenBank record, converted to a single token (Section 3.1).</p><p>Various combinations of these representations were tried on the training data and a subset were selected for the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text processing</head><p>For the full text articles, we extracted the contents of the specified XML elements for the particular representation (see above), concatenated those contents, and deleted all the internal XML tags. Text processing was done using the Lemur<ref type="foot" coords="4,79.80,209.17,3.65,5.24" target="#foot_3">6</ref> utility ParseToFile, in combination with the Porter stemmer <ref type="bibr" coords="4,92.68,221.40,9.73,7.86" target="#b5">[6]</ref> supplied by Lemur and the SMART <ref type="bibr" coords="4,263.77,221.40,9.74,7.86" target="#b6">[7]</ref> stoplist. <ref type="foot" coords="4,73.82,230.09,3.65,5.24" target="#foot_4">7</ref> This parser performed case-folding, replaced punctuation with whitespace, and tokenized text at whitespace boundaries. The Lemur utility BuildBasicIndex was used to construct Lemur index files, which we then converted to document vectors in BBR's format.</p><p>MEDLINE records were handled the same way, except that MeSH terms were converted to single tokens (e.g. replacing "Mice, Knockout" with "MHxxxMicexxxKnockout") before Lemur processing to force them to have a separate term ID than words. GenBank organism names were similarly converted to single terms (e.g. "Mus musculus" to "GenBankxxxMusxxxmusculus").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Term Weighting</head><p>BBR requires text to be represented as vectors of numeric feature values. For both annotation and triage subtasks we used TFxIDF (term frequency times inverse document frequency) weighting <ref type="bibr" coords="4,131.57,409.91,9.21,7.86" target="#b7">[8]</ref>, with IDF weights computed on the training instances only.</p><p>We describe our weighting methods using Cornell triple notation <ref type="bibr" coords="4,90.66,441.29,9.22,7.86" target="#b7">[8]</ref>, i.e. TCN, where</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• T = Term Frequency Component:</head><p>b : binary, 1.0 if term is present, 0.0 if not l : "log tf", i.e. 1 + log e (tf ) if term is present, 0.0 if not</p><p>• C = Collection Frequency Component:</p><p>x : 1 for all terms -L = "lookahead IDF": log e (N +1)</p><p>(n j +1) .</p><p>• N = Normalization Component:</p><p>x : no normalization c : Cosine normalization, i.e. the feature vector is normalized to have a Euclidean norm of 1.0.</p><p>Here N is the number of documents from which IDF weights are computed (the categorization training set, so N = 5837 for the triage subtask and N = 1418 for the annotation hierarchy subtask), and nj is the number of documents containing term j. Lookahead IDF (which we indicate by nonstandard symbol "L") is a version of IDF weighting that defines a value even for terms that do not occur in the training corpus. It can be viewed as including a future document being weighted in the set of documents used to define term weights for it, thus the name "lookahead". Note that different representations of documents or document/gene pairs will produce different IDF weights, and thus different final term weights.</p><p>Test set terms that do not occur in the training set introduce a question about how to do cosine normalization. Terms that are unique to the test set can never contribute to a document's score. These test set terms can, however, depress the within-document weights of other terms in test set documents, through their impact on cosine normalization. We therefore tested two variants of cosine normalization:</p><p>• Normalize &amp; Project (N&amp;P) : Terms that occur only on the test set are included in the test set vectors during cosine normalization, and then removed (for efficiency).</p><p>• Project &amp; Normalize (P&amp;N) : Terms that occur only on the test set are removed from test set vectors before cosine normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Document Representation for the Annotation Hierarchy Subtask</head><p>We have so far discussed representations that capture the entire contents of a document at some level of granularity. Such approaches were used to represent documents in all our triage runs, and to represent document/gene pairs for three of our submitted annotation runs (dimacsAabsw1, di-macsAl3w, and dimacsAg3mh).</p><p>For the annotation subtask, we also tested representations of document/gene pairs that take the gene into account. In particular, we attempted to identify portions of the document that discussed the particular gene. Two gene-specific representations were tried:</p><p>• Paragraphs: We separated the body text (&lt;bdy&gt; element) of the article into paragraphs (&lt;P&gt; elements).</p><p>We then retained in the representation of the pair only those paragraphs that contained at least one term from the "gene description" (see below).</p><p>• Windows: For each term in the gene description, we extract from the document all windows of half-size k (i.e. 2k + 1 terms per window, except at the beginning and end of the document) centered at an occurrence of that term. The document/gene pair is represented by the union of these windows. Note that windows sometimes overlap if multiple terms from a gene description occur near each other. This increases the frequency of words that occur close to many gene terms. In some cases a term can even have a higher frequency in the document/gene description than it has in the full document.</p><p>We computed term weights from the resulting representations of document/gene pairs as if each document/gene pair was a document.</p><p>Biomedical articles, unfortunately, may refer to a gene using any of several, possibly nonstandard, symbols and/or names for the gene and/or its products <ref type="bibr" coords="5,218.36,57.64,13.52,7.86" target="#b11">[12]</ref>. We therefore tested several approaches to producing gene descriptions:</p><p>• Symbol: The description consisted solely of the MGI gene symbol which pgtrain.txt or pgtest.txt lists for the document/gene pair.</p><p>• Name: The description included the MGI gene name which gtrain.txt or gtest.txt lists for the gene. The Name description is produced by replacing the characters []().,+ in those names with whitespace, downcasing the text, and separating the result into terms at whitespace boundaries. No stemming was used.</p><p>• Locuslink: We downloaded a copy of LocusLink 8 , a database linking disparate information on genes, on 20 July 2004. For each gene symbol, we found the corresponding LocusLink record, extracted the contents of the OFFICIAL GENE NAME and ALIAS SYMBOL fields, and separated the contents into terms.</p><p>Combinations (e.g. Symbol + Name, Symbol + Name + LocusLink) of these representations were also tested, with duplications of terms across representations removed.</p><p>For example, pgd+train.txt contains the record 12213961 Map2k6 BP.</p><p>This reflects an MGD record stating document 12213961 presents evidence of one or more biological processes (BP) that gene Map2k6 is relevant to. In our Symbol representation, the gene description was thus simply Map2k6.</p><p>In the Symbol + Name representation, the gene description was:</p><p>Map2k6 mitogen activated protein kinase kinase 6, and in the Symbol + Name + LocusLink representation it was: Map2k6 mitogen activated protein kinase kinase 6 MEK6 MKK6 Prkmk6 SAPKK3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">TRIAGE SUBTASK EXPERIMENTS</head><p>After submitting our official triage subtask runs we discovered a few software bugs, and so re-ran each run with the corrected code. The corrected runs also allowed us to to clarify our techniques by omitting CPU-saving shortcuts used in our official runs (e.g. fractional cross-validation and reduced sets of hyperparameter values). We present effectiveness data on both the official and corrected runs. Results were similar, so we give detailed descriptions only of the corrected runs.</p><p>Our triage runs used the following techniques:</p><p>• dimacsTfl9d : Representation: MEDLINE. Weighting: lLc (N&amp;P). Classifier form: two-stage. Prior: Laplace. Hyperparameter: 0.404. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>Our official triage subtask results are summarized in Table <ref type="table" coords="5,316.81,344.46,3.59,7.86" target="#tab_4">3</ref>. Run dimacsTfl9d was our best scoring run, and indeed was the best among all submitted runs (Table <ref type="table" coords="5,515.23,354.92,3.58,7.86" target="#tab_6">5</ref>). Table <ref type="table" coords="5,316.81,365.38,4.61,7.86" target="#tab_5">4</ref> shows the corrected runs that correspond to each official triage run.</p><p>Looking at the above runs, and others we do not have space to include, shows that Laplace priors were consistently more effective than Gaussian priors. This is not surprising, given that a very small feature set was able to give high effectiveness (see next Section). MEE thresholding was considerably more effective than TROT thresholding, which suggests a benefit to this approach when the desired tradeoff between false positives and false negatives is extreme. In contrast to the annotation subtask, P&amp;N and N&amp;P cosine normalization gave almost identical effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Set Issues</head><p>Run dimacsTfl9d, the subtask's best run, uses only the MEDLINE record, not the full text document. This is disturbing, since it suggests participating systems were not successfully making judgments about the presence of experimental evidence in the document text.</p><p>The news gets worse. We show in Table <ref type="table" coords="5,490.55,564.74,4.61,7.86" target="#tab_4">3</ref> a hypothetical run where a test document is classified positive if its MED-LINE record contains the MeSH term "Mice", and negative otherwise. This run would have beaten all runs submitted by other groups! As far as we can tell from the results, no system successfully distinguished documents that discuss mice in general, from documents that contain GO-codable information appropriate for MGD.</p><p>On the other hand, the problem might be in the track data. MGD is a database of facts about genes, not facts about documents. Pointers to documents are included to provide citations for these facts, but providing comprehensive access to the scientific literature is not the goal of the database. It seems plausible that, in making the triage decision, MGI personnel may be less likely to designate for annotation documents that appear to report already wellknown facts about mouse genes. This would have little relevance to GO users, but could play havoc with classification experiments. More discussions with MGI personnel, and interindexing consistency studies, would be desirable.</p><p>An additional minor problem with the track data, which we and other groups detected only after official submissions, was that 4 of 420 positive test documents were omitted in 6043 test set documents (i.e. in test.crosswalk.txt file) and some documents given as negative documents were found to be positive after the submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ANNOTATION HIERARCHY SUBTASK EXPERIMENTS</head><p>For each of our annotation hierarchy subtask runs we trained three thresholded logistic regression classifiers, one for each of the BP, CC, and MF hierarchies. As with our triage runs, we found some bugs after submission and so re-ran each run with the corrected code. Our runs were: All submitted, and corrected, annotation runs chose a threshold based on optimizing the training set F1 (TROT approach). All corrected runs used full 10-fold cross-validation on the training set to choose hyperparameter values from those listed in Section 2.1.</p><p>The results of our 5 official runs are given in Table <ref type="table" coords="6,285.73,553.44,3.59,7.86" target="#tab_7">6</ref>. NIST statistics on all official runs are given in Table <ref type="table" coords="6,268.31,563.90,3.59,7.86" target="#tab_8">7</ref>.</p><p>All submitted runs (except the binary representation di-macsAg3mh) used the P&amp;N variant of cosine normalization. Tables <ref type="table" coords="6,82.70,595.28,4.61,7.86" target="#tab_10">9</ref> and<ref type="table" coords="6,108.12,595.28,9.22,7.86" target="#tab_11">10</ref> compare corrected runs with the P&amp;N versus the N&amp;P variants. Run dimacsAg3mh is not normalized, and so appears identical in the two tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Discussion</head><p>The effectiveness of our annotation submissions varied considerably, with the best (dimacsAl3w) a respectable F 1 = 0.49. Disappointingly, our runs using gene-specific representations of pairs (dimacsAp5w5 and diamcsAw20w5) scored substantially worse than runs using document-based representations. Gene-specific representations had higher precision than document-based methods, but much lower recall.</p><p>One problem with gene-specific representations was that some documents discussing a gene contain few or no terms from the gene description, even with gene descriptions expanded using LocusLink. (The use of LocusLink to expand the gene descriptions did improve effectiveness slightly, as shown in Table <ref type="table" coords="6,384.61,109.94,7.68,7.86" target="#tab_13">11</ref>.) Even with the richest gene descriptions (Symbol + Name + LocusLink), there were 54 training document/gene pairs and 80 test document/gene pairs with empty vectors for the paragraph-based representation. Similarly, there were 38 training pairs and 67 test pairs with empty vectors for all window-based representations. (The paragraph and window representations differ because the paragraph representation did not use the title or abstract of the document, while the window representation did.) A weighted combination of the full document and the gene-specific passages might improve the situation.</p><p>For weighted representations, the P&amp;N variant of cosine normalization was substantially more effective than the N&amp;P variant. This is somewhat surprising. Cosine normalization is meant to compensate for unequal document lengths, and there seems little reason that it should matter how many terms in a test document also occurred in the training set. We suspect that the rich vocabulary of technical documents, and the relatively small training set, is causing test document vectors to have many novel terms. Our lookahead IDF weighting gives these terms large weights, thus reducing (via cosine normalization) the weights of all other terms under N&amp;P normalization, but not P&amp;N normalization. The benefit for the counterintuitive P&amp;N normalization is likely to disappear if we remove IDF weights from the document representation (where they arguably do not really belong) and instead take them into account in our Bayesian prior.</p><p>As for variations on the learning approach, Gaussian priors were almost always more effective than Laplace priors for this task. This is not surprising given the very large vocabulary implied by a full GO hierarchy. Gaussian priors usually gave better precision than Laplace priors, but worse recall, though this may simply be a problem with choosing thresholds for F1. Upweighting positive examples improved effectiveness on document-based representations, but not with gene specific ones. Again, we hope to eliminate the need for this with better thresholding and choice of regularization parameters.</p><p>Training data results suggested that the 3 annotation hierarchy classification problems (BP, CC, MF) would have benefited from different machine learning and representation approaches. Due to time and resource constraints we did not take advantage of this in our runs, but doing so would be important in the operational setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Data Set Issues</head><p>The test set had a substantially higher proportion of relevant pairs than the training set (Table <ref type="table" coords="6,485.05,606.58,3.58,7.86" target="#tab_9">8</ref>). This increase would not have affected the best threshold for a linear utility effectiveness measure (like T13NU), but does change the best threshold for a nonlinear effectiveness measure such as F1. Our test set results were substantially lower than we expected from cross-validation runs on the training data, and this change may be one reason.</p><p>While the annotation subtask does not have a smoking gun analogous to the triage subtask's MeSH "Mice" classifier (Section 4.2), we have similar concerns about the consistency of relevance judgments for the annotation task as well. easy to imagine that GO curators are less likely to include a link to the 10th document mentioning a particular fact about a gene than they are to the first document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">AD HOC RETRIEVAL TASK</head><p>The ad hoc retrieval task assessed text retrieval systems on information needs of real biomedical researchers. The detailed description of the task is given in the track overview paper <ref type="bibr" coords="7,79.67,679.80,9.22,7.86" target="#b3">[4]</ref>. Here we give a brief summary.</p><p>Document Collection. The document collection consisted of 10-year subset (from 1994 to 2003) of the MED-LINE database of the biomedical literature. The DCOM field of the MEDLINE records was used to define "date" for selecting this 10-year subset. The collection included 4, 591, 008 MEDLINE records (about 10 gigabytes in size).</p><p>Topics. The track supplied 5 sample topics with incomplete relevance judgments so participants would know what to expect. The test data consisted of 50 topics. All 55 topics (sample and test) were constructed from information needs of the real biomedical researchers. Each topic was represented with a title, need and context field. A sample topic is shown in Table <ref type="table" coords="7,380.87,678.01,7.85,7.86" target="#tab_12">12</ref>.</p><p>Relevance Judgements. All relevance judgments were done by two people with backgrounds in biology, but not the creators of the original information needs. A pool of doc-  uments to judge for each topic was built by combining the top 75 documents from one run of each of the 27 groups participating in the track. Duplicates were eliminated leaving an average pool size of 976 documents. Judges did not know which systems submitted each document. Each document in the pool was judged as definitely relevant (DR), possibly relevant (PR), or not relevant (NR) to the topic it belongs. Since the task requires binary relevance judgments, DR and PR labeled documents were considered relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">TEXT RETRIEVAL FOR AD HOC TASK</head><p>We used the ASCII text version of the MEDLINE records, provided to the track participants in five separate files. <ref type="foot" coords="8,272.00,634.67,3.65,5.24" target="#foot_5">9</ref> We uncompressed and concatenated these five files to create a single file for the document collection.</p><p>For the ad hoc retrieval task, we employed both the MG text retrieval system<ref type="foot" coords="8,136.83,676.51,7.31,5.24" target="#foot_6">10</ref> , version 1.2.1, <ref type="bibr" coords="8,206.48,678.28,13.52,7.86" target="#b10">[11]</ref>, and the full text capability of MySQL database system<ref type="foot" coords="8,468.87,392.81,7.31,5.24" target="#foot_7">11</ref> , version 4.0.16. We were able to create a single MG full text index for the entire collection of MEDLINE records. We used MySQL to create an index from each document ID to the position of the document record in the approximately 10GB concatenated file of records. However, an attempt to build a full text index using MySQL failed due to the large size of the collection.</p><p>Our retrieval methods therefore first employed MG to retrieve the top-ranked 5000 documents for each topic, and then did MySQL specific processing on this subset. For the initial MG retrieval, we prepared queries by concatenating title words and nouns from need statements. Nouns from need statements were obtained by running a rule-based partof-speech tagger <ref type="bibr" coords="8,384.94,530.56,9.22,7.86" target="#b0">[1]</ref>. Any word tagged with "NN", "NNP", "NNS" and "CD" were included in the query. Then we issued this query to MG as a ranked query to retrieve the top 5000 documents. MG retrieved at least 5000 documents for all topics except test topic 37, for which only 825 documents were retrieved.</p><p>We now describe our two variants on post-processing the top 5000 documents:</p><p>Method is specified, the word is optional, but the rows that contain it will be scored higher. A phrase that is enclosed within double quote characters matches only rows that contain the phrase. Our MySQL queries were of this form: topic title as a phrase preceeded by "&gt;" to increase the score if topic title appears as a phrase, topic title as a subexperession preceeded by "&gt;"and all words preceeded by "+", all title words each preceeded by "&gt;" and all noun words from the need statement. For instance, for the sample topic 52 given in Table <ref type="table" coords="9,89.90,344.66,7.85,7.86" target="#tab_12">12</ref>, the MySQL query became:</p><p>&gt;"wnt signaling pathway" &gt;(+wnt +signaling +pathway) &gt;wnt &gt;signalling &gt;pathway information model organ system wnt pathway.</p><p>The boolean query was executed using MySQL and top 1000 results were obtained. MySQL scores the retrieved documents for a boolean query for relevance ranking, and we used its scores for ranking. MySQL returned 1000 documents for all topics except topic 37. Only 822 documents were returned for topic 37.</p><p>Method 2: The second method was based on MG ranking and the use of phrases for topic titles. Our goal was to favor documents that contained the topic title as a phrase. For example, for the sample topic 52, a document having a phrase "wnt signalling pathway" should get a better ranking than a document with only "signalling pathway". We retrieved the MEDLINE abstracts corresponding to the retrieved set of articles (top 5000 results) from the initial retrieval step, using our external index. Then we postprocess these MEDLINE abstracts to find the ones which include the topic title as a phrase by matching (ignoring case). We order the results starting from the documents which contain the topic title as a phrase and then the ones which do not include it. In each case, we ranked the results by MG scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">TEXT REPRESENTATION FOR AD HOC TASK</head><p>We extracted the title, abstract, chemical names and MeSH terms from the MEDLINE records. (Note that 1,209,243 (26.3%) of the records had no abstract.) Text from chemical names and MeSH terms were processed the same way text from titles and abstracts were processed. We used MG to parse and build indices. All of the stopwords are indexed by MG, however, we eliminated stop words from the queries. We used the stoplist from SMART system as for the text categorization tasks. We did not use stemming. Document parsing performed case-folding and replaced punctuation with whitespace. Tokenization was done by defining a term as a maximal-length contiguous sequence of up to 15 alphanumeric characters. Query parsing was done identically to document parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">AD HOC TASK RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Approach</head><p>We constructed queries using the words in title fields, eliminating stop words, and the "noun" words in need sections of the topics. Brill's rule-based part of speech tagger, version 1.14 obtained as part of KeX protein name tagger tool 12 , was used <ref type="bibr" coords="9,388.67,362.27,9.22,7.86" target="#b0">[1]</ref>. We eliminated duplicate words and stopwords from the queries. The MG system includes support for ranked queries, where similarity is evaluated using the cosine measure. We used the MG system's default TFx-IDF term weighting and cosine similarity measure. First we issued ranked queries to MG. Then, using the top 5000 results, we applied Method 1 and Method 2 for reranking them to obtain top 1000 results as discussed in Section 7. We submitted one run obtained using Method 1 ranking method: rutgersGAH1, and another run using Method 2: rutgersGAH2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Results</head><p>The effectiveness measure for the ad hoc task was mean average precision (MAP). Table <ref type="table" coords="9,449.23,512.76,9.22,7.86" target="#tab_4">13</ref> shows the MAP results for our official runs computed over 50 test topics. Our rut-gersGAH1 run performed better. Partipicants were provided the best, median, and worst average precision results for each topic. On the 50 test topics, compared to 37 automatic runs, our rutgersGAH1 run's average precision score was greater than the median 24 times, was less than the median 26 times, and never achieved the best result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Mean Average Precision rutgersGAH1 0.1702 rutgersGAH2 0.1303 Table <ref type="table" coords="9,356.13,652.47,9.04,7.89" target="#tab_4">13</ref>: Summary results of our ad hoc runs.</p><p>12 http://www.hgc.ims.u-tokyo.ac.jp/service/tooldoc/KeX/ intro.html</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,67.12,277.46,225.78,7.86;6,76.21,287.92,216.68,7.86;6,76.21,298.38,89.60,7.86;6,67.12,317.70,231.55,7.86;6,76.21,328.16,216.69,7.86;6,76.21,338.62,46.27,7.86;6,67.12,357.93,225.78,7.86;6,76.21,368.39,216.68,7.86;6,76.21,378.85,89.60,7.86;6,67.12,398.17,225.78,7.86;6,76.21,408.63,216.69,7.86;6,76.21,419.09,216.69,7.86;6,76.21,429.55,48.89,7.86;6,67.12,448.86,225.78,7.86;6,76.21,459.32,216.69,7.86;6,76.21,469.78,216.69,7.86;6,76.21,480.25,136.81,7.86"><head>•</head><label></label><figDesc>dimacsAabsw1: Representation: Abstract. Weighting: lLc (P&amp;N). Prior: Gaussian. Upweighting of positive examples: no (w = 1). • dimacsAg3mh: Representation: MeSH. Weighting: bxx. Prior: Gaussian. Upweighting of positive examples: no (w = 1). • dimacsAl3w: Representation: Full text. Weighting: lLc (P&amp;N). Prior: Laplace. Upweighting of positive examples: no (w = 1). • dimacsAp5w5: Representation: Paragraphs, selected using Locuslink information. Weighting: lLc (P&amp;N). Prior: Gaussian. Upweighting of positive examples: yes (w = 5). • dimacsAw20w5: Representation: Windows with halfwindow size 20, selected using LocusLink information. Weighting: lLc (P&amp;N). Prior: Gaussian. Upweighting of positive examples: yes (w = 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,316.81,690.27,242.74,28.78"><head>Table 1 :</head><label>1</label><figDesc>Confusion table.</figDesc><table coords="1,316.81,690.27,242.74,28.78"><row><cell>subtask provides a set of 1418 document/gene pairs</cell></row><row><cell>(representing 504 distinct documents and 1291 distinct genes)</cell></row><row><cell>for training and 877 pairs for testing (378 documents and 773</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,158.49,211.13,292.74,7.89"><head>Table 2 :</head><label>2</label><figDesc>Boundary cases for T13NU on triage subtask test set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,539.93,711.19,15.98,7.86"><head>Table 3 :</head><label>3</label><figDesc>Our official triage subtask results, plus a hypothetical test set run using only MeSH term "Mice".</figDesc><table coords="6,539.93,711.19,15.98,7.86"><row><cell>It is</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,97.56,244.46,409.87,79.72"><head>Table 4 :</head><label>4</label><figDesc>Test set results from rerunning our triage submissions with corrected software.</figDesc><table coords="7,229.87,274.08,149.98,50.11"><row><cell></cell><cell>Best</cell><cell cols="2">Median Worst</cell></row><row><cell cols="3">Precision 0.2309 0.1360</cell><cell>0.0713</cell></row><row><cell>Recall</cell><cell cols="2">0.9881 0.5571</cell><cell>0.0143</cell></row><row><cell>F-score</cell><cell cols="2">0.2841 0.1830</cell><cell>0.0267</cell></row><row><cell>T13NU</cell><cell cols="2">0.6512 0.3425</cell><cell>0.0114</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,53.80,337.51,502.11,101.14"><head>Table 5 :</head><label>5</label><figDesc>NIST-supplied statistics on effectiveness of official triage submissions (59 triage runs, 20 participants).</figDesc><table coords="7,163.04,378.09,283.63,60.57"><row><cell>Run</cell><cell cols="4">TP FP FN TN Precision Recall F-score</cell></row><row><cell cols="3">dimacsAabsw1 113 76</cell><cell>382 501 0.5979</cell><cell>0.2283 0.3304</cell></row><row><cell>dimacsAg3mh</cell><cell cols="3">225 196 270 381 0.5344</cell><cell>0.4545 0.4913</cell></row><row><cell>dimacsAl3w</cell><cell cols="3">162 161 333 416 0.5015</cell><cell>0.3273 0.3961</cell></row><row><cell>dimacsAp5w5</cell><cell>96</cell><cell>81</cell><cell>399 496 0.5424</cell><cell>0.1939 0.2857</cell></row><row><cell cols="2">dimacsAw20w5 83</cell><cell>55</cell><cell>412 522 0.6014</cell><cell>0.1677 0.2622</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,167.83,451.48,269.33,79.72"><head>Table 6 :</head><label>6</label><figDesc>Our official annotation hierarchy subtask results.</figDesc><table coords="7,229.87,481.10,149.98,50.10"><row><cell></cell><cell>Best</cell><cell cols="2">Median Worst</cell></row><row><cell cols="3">Precision 0.6014 0.4174</cell><cell>0.1692</cell></row><row><cell>Recall</cell><cell cols="2">1.0000 0.6000</cell><cell>0.1333</cell></row><row><cell>F-score</cell><cell cols="2">0.5611 0.3584</cell><cell>0.1492</cell></row><row><cell>T13NU</cell><cell cols="2">0.7842 0.5365</cell><cell>0.1006</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,103.77,544.53,402.19,7.89"><head>Table 7 :</head><label>7</label><figDesc>NIST-supplied official annotation hierarchy results (36 runs, 20 participants).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="8,70.63,55.40,468.46,163.58"><head>Table 8 :</head><label>8</label><figDesc>Number of relevant pairs in the training and test sets for the annotation hierarchy subtask.</figDesc><table coords="8,133.82,55.40,342.08,163.58"><row><cell></cell><cell cols="2">Training</cell><cell></cell><cell></cell><cell>Test</cell></row><row><cell cols="6">Topic # Relevant Pairs % Relevant Pairs # Relevant Pairs % Relevant Pairs</cell></row><row><cell>BP</cell><cell>228</cell><cell></cell><cell>0.161</cell><cell>170</cell><cell>0.194</cell></row><row><cell>CC</cell><cell>163</cell><cell></cell><cell>0.115</cell><cell>131</cell><cell>0.149</cell></row><row><cell>MF</cell><cell>198</cell><cell></cell><cell>0.140</cell><cell>194</cell><cell>0.221</cell></row><row><cell>Total</cell><cell>589</cell><cell></cell><cell>0.138</cell><cell>495</cell><cell>0.188</cell></row><row><cell>Run</cell><cell></cell><cell cols="4">TP FP FN Precision Recall F-score</cell></row><row><cell cols="4">dimacsAabsw1 113 93</cell><cell>382 0.5485</cell><cell>0.2283 0.3224</cell></row><row><cell cols="2">dimacsAg3mh</cell><cell cols="3">201 186 294 0.5194</cell><cell>0.4061 0.4558</cell></row><row><cell cols="2">dimacsAl3w</cell><cell cols="3">242 248 253 0.4939</cell><cell>0.4889 0.4914</cell></row><row><cell cols="2">dimacsAp5w5</cell><cell>92</cell><cell>61</cell><cell>403 0.6013</cell><cell>0.1859 0.2840</cell></row><row><cell cols="3">dimacsAw20w5 90</cell><cell>58</cell><cell>405 0.6081</cell><cell>0.1818 0.2799</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="8,53.80,231.81,502.11,100.64"><head>Table 9 :</head><label>9</label><figDesc>Test set results from rerunning our annotation submissions with corrected software. Weighted representations use P&amp;N normalization, as in our submitted runs.</figDesc><table coords="8,175.33,271.88,259.05,60.57"><row><cell>Run</cell><cell cols="4">TP FP FN Precision Recall F-score</cell></row><row><cell cols="2">dimacsAabsw1 41</cell><cell>21</cell><cell>454 0.6613</cell><cell>0.0828 0.1472</cell></row><row><cell>dimacsAg3mh</cell><cell cols="3">201 186 294 0.5194</cell><cell>0.4061 0.4558</cell></row><row><cell>dimacsAl3w</cell><cell cols="3">157 149 338 0.5131</cell><cell>0.3172 0.3920</cell></row><row><cell>dimacsAp5w5</cell><cell>33</cell><cell>31</cell><cell>462 0.5156</cell><cell>0.0667 0.1181</cell></row><row><cell cols="2">dimacsAw20w5 55</cell><cell>42</cell><cell>440 0.5670</cell><cell>0.1111 0.1858</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="8,53.80,345.28,502.11,98.51"><head>Table 10 :</head><label>10</label><figDesc>Test set results from rerunning our annotation submissions with corrected software. Weighted representations use N&amp;P normalization, unlike the submitted runs.</figDesc><table coords="8,60.37,391.94,225.95,51.85"><row><cell>TOPIC ID: 52</cell></row><row><cell>TITLE: Wnt signaling pathway</cell></row><row><cell>NEED: Find information on model organ system where Wnt</cell></row><row><cell>signaling pathway has been studied.</cell></row><row><cell>CONTEXT: Need to retrieve literature for any computer</cell></row><row><cell>modeled organ system that has studied Wnt.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="8,113.31,465.53,120.09,7.89"><head>Table 12 :</head><label>12</label><figDesc>A sample topic.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="8,316.81,614.22,239.11,81.12"><head>Table 11 :</head><label>11</label><figDesc>1:The MEDLINE abstracts corresponding to the retrieved set of MEDLINE articles (5000 articles) were stored in a table in MySQL (title, abstract, chemical names and MeSH terms fields) by creating a full index on all four fields. This process is quite fast; it took less than a second to insert the results into a table and create a full text index. Next a boolean type query, specifically designed for MySQL boolean search, was constructed from the topic statement Gene-specific representation results (F1 Measure), P&amp;N normalization, on the test set.</figDesc><table coords="9,53.80,55.03,399.16,192.89"><row><cell cols="2">Prior Weight</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Gene-Specific</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">No Domain Knowledge</cell><cell></cell><cell cols="2">Locus Link</cell></row><row><cell></cell><cell></cell><cell>Par</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>Par</cell><cell>5</cell><cell>10</cell><cell>20</cell></row><row><cell>G</cell><cell>1</cell><cell cols="7">0.280 0.224 0.178 0.220 0.307 0.204 0.174 0.189</cell></row><row><cell>G</cell><cell>5</cell><cell cols="7">0.288 0.315 0.290 0.321 0.284 0.326 0.259 0.280</cell></row><row><cell>G</cell><cell>6</cell><cell cols="7">0.281 0.313 0.305 0.253 0.279 0.331 0.191 0.187</cell></row><row><cell>L</cell><cell>1</cell><cell cols="7">0.441 0.393 0.410 0.390 0.442 0.434 0.439 0.451</cell></row><row><cell>L</cell><cell>5</cell><cell cols="7">0.372 0.298 0.298 0.342 0.367 0.335 0.343 0.371</cell></row><row><cell>L</cell><cell>6</cell><cell cols="7">0.369 0.298 0.305 0.346 0.368 0.336 0.346 0.365</cell></row><row><cell cols="5">and the need statement. Note that MySQL can perform</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">boolean full text searches using the IN BOOLEAN MODE</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">modifier. A '+' sign preceeding a word in a query indicates</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">that this word must be present in every result returned. The</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">&gt; operator increases a word's contribution to the relevance</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">score that is assigned to a result. By default, when no '+'</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,58.41,700.84,126.55,7.86"><p>http://www.informatics.jax.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,58.41,711.19,118.29,7.86"><p>http://www.geneontology.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,321.42,711.19,189.70,7.86"><p>http://www.stat.rutgers.edu/∼madigan/BBR/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,58.41,682.90,137.54,7.86"><p>http://www-2.cs.cmu.edu/∼lemur</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,58.41,693.25,190.71,7.86;4,284.69,693.25,8.21,7.86;4,53.80,702.22,210.37,7.86;4,53.80,711.19,125.71,7.86"><p>ftp://ftp.cs.cornell.edu/pub/smart/english.stop or http://jmlr.csail.mit.edu/papers/volume5/lewis04a/ lyrl2004 rcv1v2 README.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="8,58.41,700.84,164.41,7.86"><p>2004 TREC ASCII MEDLINE {A-E}.gz</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="8,58.41,711.19,119.34,7.86"><p>http://www.cs.mu.oz.au/mg/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7" coords="8,321.42,711.19,93.75,7.86"><p>http://www.mysql.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The work was partially supported under funds provided by the <rs type="funder">KD-D group</rs> for a project at DIMACS on Monitoring Message Streams, funded through <rs type="funder">National Science Foundation</rs> grant <rs type="grantNumber">EIA-0087022</rs> to <rs type="institution">Rutgers University</rs>. The views expressed in this article are those of the authors, and do not necessarily represent the views of the sponsoring agency.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_c3XaUdU">
					<idno type="grant-number">EIA-0087022</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,72.62,161.45,210.14,7.86;10,72.62,171.91,189.65,7.86;10,72.62,182.37,195.57,7.86;10,72.62,192.83,75.27,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,107.96,161.45,174.79,7.86;10,72.62,171.91,28.23,7.86">Some advances in rule-based part of speech tagging</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,119.46,171.91,142.81,7.86;10,72.62,182.37,190.88,7.86">Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94)</title>
		<meeting>the Twelfth National Conference on Artificial Intelligence (AAAI-94)<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.62,204.29,208.45,7.86;10,72.62,214.75,220.28,7.86;10,72.62,225.21,89.47,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,239.53,204.29,41.53,7.86;10,72.62,214.75,174.40,7.86">Bayes and Empirical Bayes Methods for Data Analysis</title>
		<author>
			<persName coords=""><forename type="first">Bradley</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Louis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.62,236.67,188.55,7.86;10,72.62,247.13,210.65,7.86;10,72.62,257.59,216.51,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,113.31,247.13,169.95,7.86;10,72.62,257.59,74.18,7.86">Large-scale bayesian logistic regression for text categorization</title>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Madigan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>DIMACS</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="10,72.62,269.04,218.29,7.86;10,72.62,279.51,197.82,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,136.69,269.04,138.55,7.86">Trec 2004 genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,72.62,279.51,122.88,7.86">13th Text Retrieval Conference</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="10,72.62,290.96,174.89,7.86;10,72.62,301.42,216.77,7.86;10,72.62,311.88,216.49,7.86;10,72.62,322.34,199.88,7.86;10,72.62,332.81,167.88,7.86;10,72.62,343.27,218.77,7.86;10,72.62,353.73,178.06,7.86;10,72.62,364.19,44.06,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,140.63,290.96,106.87,7.86;10,72.62,301.42,154.31,7.86">Evaluating and optimizing autonomous text classification systems</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,262.99,311.88,26.11,7.86;10,72.62,322.34,199.88,7.86;10,72.62,332.81,167.88,7.86;10,72.62,343.27,151.91,7.86">SIGIR &apos;95: Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Ingwersen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Raya</forename><surname>Fidel</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="246" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.62,375.65,190.91,7.86;10,72.62,386.11,142.17,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,129.49,375.65,130.19,7.86">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,72.62,386.11,31.79,7.86">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980-07">July 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.62,397.56,198.38,7.86;10,72.62,408.02,196.81,7.86;10,72.62,418.48,79.51,7.86" xml:id="b6">
	<monogr>
		<title level="m" coord="10,145.92,397.56,125.08,7.86;10,72.62,408.02,192.79,7.86">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</editor>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.62,429.94,162.37,7.86;10,72.62,440.40,183.65,7.86;10,72.62,450.86,206.80,7.86;10,72.62,461.32,82.43,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,72.62,440.40,183.65,7.86;10,72.62,450.86,32.07,7.86">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,111.32,450.86,163.20,7.86">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.62,472.78,177.88,7.86;10,72.62,483.24,179.09,7.86" xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,160.75,472.78,89.75,7.86;10,72.62,483.24,51.72,7.86">Information Retrieval. Butterworths</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct coords="10,72.62,494.70,218.96,7.86;10,72.62,505.16,218.20,7.86;10,72.62,515.62,90.77,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,198.51,494.70,93.07,7.86;10,72.62,505.16,101.07,7.86">Automatic Information Structuring and Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Cornelis</forename><surname>Joost Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,230.35,505.16,56.50,7.86">King&apos;s College</title>
		<imprint>
			<date type="published" when="1972-07">July 1972</date>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,72.62,527.08,203.51,7.86;10,72.62,537.54,217.23,7.86;10,72.62,548.00,200.51,7.86;10,72.62,558.46,54.28,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,236.83,527.08,39.30,7.86;10,72.62,537.54,217.23,7.86;10,72.62,548.00,26.21,7.86">Managing Gigabytes: Compressing and Indexing Documents and Images</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct coords="10,72.62,569.92,216.43,7.86;10,72.62,580.38,178.08,7.86;10,72.62,590.84,135.81,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,173.09,569.92,115.96,7.86;10,72.62,580.38,174.45,7.86">Extracting synonymous gene and protein terms from biological literature</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,72.62,590.84,57.95,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="340" to="349" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
