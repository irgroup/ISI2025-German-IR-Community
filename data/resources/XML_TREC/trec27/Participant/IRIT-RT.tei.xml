<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.83,88.00,288.65,12.90">IRIT at TREC Real-Time Summarization 2018</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,211.10,126.50,80.53,8.64"><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
							<email>abdelhamid.chellal@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Institut de Recherche en Informatique de Toulouse</orgName>
								<orgName type="laboratory">UMR 5505</orgName>
								<orgName type="institution">University of Toulouse II</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.99,126.50,83.85,8.64"><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
							<email>mohand.boughanem@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Institut de Recherche en Informatique de Toulouse</orgName>
								<orgName type="laboratory">UMR 5505</orgName>
								<orgName type="institution">University of Toulouse II</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>F-31062</postCode>
									<settlement>Toulouse cedex 9</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.83,88.00,288.65,12.90">IRIT at TREC Real-Time Summarization 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F02C8549D31D9189691A60E10E1B7AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the participation of the IRIT laboratory (University of Toulouse) to the Real-Time Summarization track of TREC RTS 2018. This track is consisting of two scenarios ( A: push notification and B: Email digest) which tackle the challenge of fulfilling the prospective and the retrospection information needs repressively. We submitted three runs for both scenarios A and B. For scenario A, we propose to use a supervised learning approach to build a binary classifier that predicts the relevance of an incoming tweet with respect to the topic of interest. The proposed approach leverages social signals as well as query dependent features to enhance the detection of relevant tweets. Additionally, we investigate the impact of the use of live relevance feedback to re-train the classier each time new relevance assessments are made available. For scenario B, the daily digest is generated by iteratively selecting the top tweets that pass the relevance filter with discarding the redundant ones.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>User-generated content on social media, such as Twitter, provides in many cases, the latest news before traditional media, which allows having a retrospective summary of events and being updated in a timely fashion whenever a new development occurs. However, social media, while being a valuable source of information, can be also overwhelming given the volume and the velocity of published information. To shield users from being overwhelmed by irrelevant and redundant posts, retrospective summarization and prospective notification (real-time summarization) were introduced as two complementary tasks of information seeking on document streams.</p><p>TREC Real-Time Summarization (RTS) track focus on the aforementioned types of information needs. In this track, participant systems are required to monitor the live stream provided by Twitter streaming API over a period of twelve days (from Monday July 23, 2018 00:00:00 UTC to Friday August 3, 2018 23:59:59 UTC) and to identify relevant tweets per day with respect to predefined user interest. This track is composed of two scenarios namely scenario A (push notification) and scenario B (Email digest). In the former, systems monitor the live posts stream and push relevant and novel notifications as soon as possible in order to update the user whenever a novel information occurs. The latter aims to generate a daily summary after the day ends that consists of a batch of up to 100 ranked tweets that capture "what happened" regarding each topic As previous edition (TREC RTS 2017 track), participant systems can fetch mobile assessor relevance judgments in real time for its pushed tweets. The availability of relevance feedback provides opportunities for techniques based on adaptive learning and relevance feedback.</p><p>To tackle scenario A, the core task is to determine whether a tweet is relevant or not. The majority of existing approaches rely on the threshold-based filter in which the decision to select or discard an incoming tweet depends on whether its relevance score falls above a predefined threshold. However, it was shown that the accuracy of the tweet filtering relies on identifying an appropriate threshold for pushing updates <ref type="bibr" coords="1,167.56,661.32,10.57,8.64" target="#b0">[1,</ref><ref type="bibr" coords="1,179.79,661.32,7.05,8.64" target="#b1">2]</ref>. The relevance threshold value has a serious impact on the filtering effectiveness. To overcome the issue of setting the relevance threshold value, we propose to use a supervised learning approach to build a binary classifier that predicts the relevance of an incoming tweet with respect to the topic of interest. To identify relevant tweet to push to the user, we consider the relevance filtering as binary classification problem in which the incoming tweet is classified as relevant or not relevant.</p><p>For scenario B, the daily digest is generated by selecting the top weighted tweets iteratively and with discarding those having their similarity with respect to the current summary above a certain threshold.</p><p>2 Learn to filter strategy for prospective notification 2.1 System overview Knowing that to be effective a system needs to optimize three constraints: the relevance with respect to the topic of interest, the novelty/redundancy (avoid pushing multiple tweets that convey the same information) and the latency between the publication time and the notification time of selected tweets (provide updates as soon as the event occurs). To fulfill these requirements, our approach consists of three filters adjusted sequentially namely:</p><p>-Pre-processing and low-quality tweet filtering; -Relevance filter based on a binary classifier that takes advantage of the ongoing user relevance feedback; -Novelty filter.</p><p>In these filters, the decision to select/ignore the incoming tweet is made as soon as the tweet is collected. In order to reduce the latency between notification time and publication time, the tweet that passes these filters is pushed immediately without delay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Pre-processing and low-quality tweet filtering</head><p>The pre-processing step consists of stop-words removal, stemming and tokenize the tweet using Twokenize tool <ref type="foot" coords="2,167.26,408.24,3.69,6.39" target="#foot_0">1</ref> . Then, we apply a simple quality and topical filters to discard potential trash and irrelevant tweets and yields to boost the efficiency of our approach to handle the velocity of the tweet stream. The quality filter excludes any tweet that does meet at least one of the following rules:</p><p>-Non-English Filtering: We rely on Twitter's language detector to discard the non-English tweets.</p><p>In addition, tweets that contain more than 35% of non-English characters are also filtered out. -BadWrods Filtering: Tweets including swear or bad words are filtered out since we assume that it would be inappropriate to push notification containing such kind of vocabulary. -Retweet de-duplication: Since the practice of "retweeting" the same content is very common on Twitter, we de-duplicated tweets using retweet mechanism and tweet identifier (tweet id). If the incoming tweet is a re-tweet of an already seen tweet in the stream then this new tweet is eliminated. -Trash filtering: Any tweet that meets one of the following conditions is considered as trash and hence it is filtered out:</p><p>• It contains less than five unique tokens;</p><p>• It includes more than one URL ;</p><p>• It mentions more than two usernames ;</p><p>• It contains more than three hashtags ;</p><p>The topical filter step is a word overlap filter that drops all incoming tweets that do not contain a predefined number of query words. The incoming tweet T is considered as a candidate tweet if its number of overlapping words with the query title is higher than the minimum of either a predefined constant (K) or the number of words in the query title min(K, |Q t |). In our runs, the value of (K) was set to 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Relevance filtering</head><p>The main task in the prospective notification is the identification of relevant posts, in a timely fashion, in the social media stream. To shield users from unwanted notifications, systems attempt to find a trade-off between pushing too many or too few tweets. To achieve this purpose, it is common to rely on a threshold-based filter. In the case of a high threshold value, a system may miss pushing interesting content to the user. Conversely, in the case of a low threshold value, a system may overwhelm the user with irrelevant tweets. However, it is difficult to properly and effectively set the relevance threshold value <ref type="bibr" coords="3,125.46,180.43,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="3,137.91,180.43,7.19,8.64" target="#b1">2]</ref>.</p><p>To overcome the issue of relevance threshold setting, we propose a learn to filter approach based on machine learning. Instead to rely on a threshold-based filter, we use a binary classifier that predicts the relevance of an incoming tweet with respect to the topic of interest. The proposed approach leverages social signals as well as query dependent features to enhance the detection of relevant tweets. We propose a set of social and other non-content features suitable for real-time tweet filtering. Furthermore, we explore and evaluate an adaptive learning strategy in which the live user relevance feedback is used to update periodically the relevance classifier. This allows investigating the gain that can be achieved by taking advantage of an ongoing relevance feedback which is generated by users as tweets are pushed.</p><p>We use TREC real-time tweet filtering and summarization dataset <ref type="bibr" coords="3,385.36,288.03,15.39,8.64" target="#b2">[3]</ref>(TREC RTF 2015) to train the binary classifier as follows: we extract for each topic tweets from the judgment pool of TREC 2015 RTF dataset. We obtain 94,068 tweets among them 8,164 tweets were labeled as relevant. We notice that the classes of these sets are unbalanced. To get a balanced training dataset, we filter out all tweets that do not contain at least two query's words. Thus, we obtain a training dataset that contains 6,663 tweets in which the distribution of relevant and irrelevant tweet is 50.18% and 49.81% respectively.</p><p>In the context of real-time tweet filtering, we are limited to use features that are already available in the meta-data of a tweet. This allows us to predict the relevance of the incoming tweet as soon as it is published. Hence, we are not able to use Twitter's REST APIs to collect further features such as the profiles of followers or to crawl external URL webpage text. This is due to restrictions imposes by Twitter (e.g., limiting the number of calls to a time slot) on using REST APIs, which makes these features inapplicable in real-time filtering scenario. Among the set of available features extracted from the tweet's meta-data, we used feature selection algorithms to determine the best relevance-dependent signals that can be effectively used in the tweet filtering task. We use an information gain algorithm implemented in Weka tool <ref type="bibr" coords="3,210.62,455.40,10.70,8.64" target="#b3">[4]</ref>, which allows us to identify 22 features categorized into three classes: query dependent, tweet specific and user account features. The query dependent features measure the relevance with respect to the query and social signals features (tweet specific and user account features) are query independent.</p><p>Query dependent features: To capture the relevance of a tweet's content, we used six query dependent features that measure the relevance of the given tweet text with respect to a topic. These features are as follows:</p><formula xml:id="formula_0" coords="3,108.86,541.69,101.50,10.63">-|(Q t ∪ Q d ) ∩ Hashtag|:</formula><p>The number of words overlaps between the query terms and hashtags in the tweet. The rationale behind this feature is that the presence of a query term as a hashtag is a valuable signal of relevance since hashtags are used to draw attention and to label the content of a given tweet; -The cosine similarity between the query title and the tweet's text vectors using a word embedding model (word2vec <ref type="bibr" coords="3,194.32,602.87,10.66,8.64" target="#b4">[5]</ref>). The vectors of the title of the query and the tweet's text are obtained by summing up all vectors of their words. This feature can be considered as a semantic-based relevance score which aims to leverage the probable semantic relationship between terms of the query and the tweet by taking advantage of a word embedding model;</p><formula xml:id="formula_1" coords="3,108.86,647.97,112.60,10.70">-|(Q t ∩ T |) and |(Q d ∩ T |):</formula><p>The number of words that overlap between the text of the tweet and the query's title |Q t | and the query's description |Q d | respectively; -RSV (T, Q t ) and RSV (T, Q d ): The relevance score of the incoming tweet with respect to the title Q t and the description Q d respectively.</p><p>The relevance scores RSV (T, Q t ) and RSV (T, Q d ) are evaluated using an adaptation of Extended Boolean Model proposed by <ref type="bibr" coords="4,216.29,103.37,10.45,8.64" target="#b5">[6]</ref>, in which the word embedding is used to estimate the weight of query terms in order to cope with the shortness of tweets and word mismatch issues.</p><p>Tweet specific features: These features describe elements that are mentioned in a tweet text and the nature of the tweet itself which can be a retweet of another tweet or a reply to an old tweet of another user. We leverage seven <ref type="bibr" coords="4,236.40,151.46,11.85,8.64" target="#b6">(7)</ref> tweet-specific features that are defined as follows: We exploit five tweet-specific features: (1) URL&amp; Hashtag: Whether the tweet contains a URL or a hashtag; (2) Retweet count per day: The ratio of times this tweet has been retweeted and its age (in days); (3) the number of words that a tweet text contains; (4) the hour at which the tweet was published; (5) whether an entity (PERSON, ORGANIZATION, LOCATION) is mentioned in the tweet. For this, we use Stanford Named Entity Recognizer <ref type="foot" coords="4,244.66,209.30,3.69,6.39" target="#foot_1">2</ref> .</p><p>User account features: We argue that the importance of tweet content is related to the authority of the user who posts the tweet. The authority of a user can be captured through social features that are available in the meta-data of tweets. Notice here that in the case that the given tweet is a retweet, we consider the features of the user that published the original tweet, and not the one who retweeted it. These features are time-sensitive, the importance of a signal depends on the account age. An old account may have much more followers than a recent one. Therefore, in user account features, we implicitly consider the age of the account (in days) at the time of the tweet publication. The user account features are as follows:</p><p>-Follower: Number of followers of the author of the tweet; -Friend: Number of followees of the author of the tweet; -Verified: Whether the user account is verified; -Tweet/day: Ratio of the number of posted tweets and the age of the account; -List/day: Ratio of the number of lists a user appears in and the age of the account; -Fol/day: Ratio of the number of user followers and the age of the account; -Fr/day: Ratio of user friends and the age of the account; -Fol/Fr: Ratio of the numbers of followers and followees of the user; -(List + Fol/Fr)/day: A combination of Fol/Fr and the number of lists the user appears in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Novelty filtering</head><p>The novelty detection is based upon an adaptation of word overlap similarity in which the incoming tweet is compared to all tweets previously pushed to the user. To do so, the tweets of the summary are aggregated into a summary set of terms SW and the incoming tweet is compared to this summary set. The novelty score of the incoming tweet T = {t 1 , ...,t n } is computed using word overlap as follows:</p><formula xml:id="formula_2" coords="4,248.19,535.32,256.22,22.32">NS(T, SW ) = 1 - |SW ∩ T | |T |<label>(1)</label></formula><p>With :</p><formula xml:id="formula_3" coords="4,258.17,575.51,242.37,29.29">SW = M j=1 {t j 1 ,t j 2 , ...,t j n } (<label>2</label></formula><formula xml:id="formula_4" coords="4,500.54,585.61,3.87,8.64">)</formula><p>Where M is the number of tweets already selected in the summary and t j i is the i-th term in tweet j in the summary.</p><p>In our runs, the incoming tweet is pushed only if its novelty score is greater than a predefined threshold. We set the novelty threshold value to 0.5 for all topics and overall the evaluation period based on pilot experiments carried out on TREC RTS 2017 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Adaptive learning strategy</head><p>To further improve the effectiveness of the binary classifier, we use relevance information feedback to update the binary classifier. The system takes advantage of relevance feedback to re-train the classifier. To do so, the classifier is initialized with a training dataset and it is retrained periodically each times new relevance judgments have been made available. The system fetches the relevance judgment of users periodically (every 10 minutes: rate fixed by track organizer) and uses it to label the new instances that correspond to the features of the pushed tweets. These new labeled instances are added to the current training instances set and the model is retrained. We set this strategy in order to fit a real-world scenario in which the user may choose to judge the pushed tweet immediately or later (if it arrives at an inopportune time) or may choose to not do it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Runs</head><p>We submitted three runs based upon a binary classifier (IRIT-Run1, IRIT-Run2 and IRIT-Run3) in which the same novelty threshold value and a minimum word overlap between the interest profile and the tweet text were used. The main difference between these runs is the classification algorithm and whether the classifier is adaptive (the live assessment feedback were used to re-train the classifier) or not. Table <ref type="table" coords="5,143.98,299.19,4.98,8.64">1</ref> describes the configuration of our three runs.</p><formula xml:id="formula_5" coords="5,227.95,331.49,150.39,41.40">Run Classifier Adaptive IRIT-Run1 XGboost[7] Yes IRIT-Run2 XGboost[7] No IRIT-Run3 Random Forest [8]</formula><p>Yes Table <ref type="table" coords="5,247.07,375.63,3.36,8.06">1</ref>. Configuration of our different runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results for scenario A in terms of mobile live assessment</head><p>In scenario A, tweets submitted by participating systems were immediately routed to the mobile phone of an assessor with the corresponding interest profile. Judgments happened online as systems submitted tweets. The assessor may choose to judge the tweet immediately or later (if it arrives at an inopportune time) or may choose to not do it. Note that in this evaluation, a tweet might be judged by more than one mobile assessor. In this year, among 298 topics, assessors judged 135 topics.</p><p>Table <ref type="table" coords="5,141.26,512.82,4.99,8.64" target="#tab_0">2</ref> reports the performance of our runs based upon learning to filter approach in terms of the number of tweets that were judged relevant (Rel), redundant (Red), and not relevant (Not Rel); the number of unjudged posts; the total length of each run (|R|), the coverage of judged tweets the mean latency and median latency. The four last columns report the strict and lenient precision (P S, P L) and the strict and lenient utility (U S, U L). were achieved by run IRIT-Run3 in which the binary classifier is based on Random Forest algorithm. The comparison between the performance of IRIT-Run1 that use the ongoing relevance feedback to retrain the binary classifier and the performance of IRIT-Run2 which is not adaptive reveals that the adaptive learning strategy outperforms the passive learning strategy overall metrics. These results show that taking advantage of the ongoing relevance feedback allows improving the ability to identify relevant tweets.</p><p>Interestingly, we note that the best performing run is the one that pushed the smallest numbers of tweets. The number of tweets pushed by run IRIT-Run3 is 40.46% less than the number of tweets pushed by run-IRIT2. This result reveals that the adaptive learning strategy based on Random Forest algorithm managed to achieve a good balance between pushing too many or too few tweets. This result may suggest that the learn to filter model that takes advantage of an ongoing assessment feedback is able to detect silent days and to keep silence in such days.</p><p>For the timeliness, we notice that the mean latency of our approach is less than 1 minutes (32-34 seconds). This result can partially be explained by the fact that the decision to select/ignore an incoming tweet is made in real-time as soon as a tweet is available. However, notice that latency is computed with respect to the first tweet in each cluster, and thus a system may have a high latency even if it submits a tweet immediately after it is identified. This allows to concludes that our approaches trade off summary quality with latency and hence produces good quality output at the cost of low latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Runs for Scenario B</head><p>To generate runs for scenario B, the tweets stream is filtered using the low-quality tweet and relevance filters with ignoring the limit of ten tweets per day. At the end of each day, we obtained a set of candidates tweets for each topic. From this set of tweets, the top ten tweets are iteratively selected with the exclusion of those having word overlap above a static redundancy threshold set to 0.6. Candidate tweets are ordered according to their the relevance score computed using an adaptation of Extended Boolean Model proposed by <ref type="bibr" coords="6,217.55,494.66,10.58,8.64" target="#b5">[6]</ref>.</p><p>We submit three runs which were generated as follows:</p><p>1. The first run (IRIT-RunB1) takes as input tweets that passe the relevance filter based on adaptive learning strategy used in run IRIT-Run1 of scenario A. Notice here that the binary classifier used in IRIT-Run1 is based on XGboost <ref type="bibr" coords="6,262.11,552.18,11.79,8.64" target="#b6">[7]</ref> algorithm and the relevance feedback of mobile assessor was used to retrain the binary classifier periodically. 2. The second run (IRIT-RunB2) is almost the same as the first run except that we use as input a set of tweets that were filtered without updating the binary relevance; 3. The third run (IRIT-RunB3) takes as input tweets that passe the relevance filter based on adaptive learning strategy used in run IRIT-Run3 in which the binary classifier is based on Random Forest <ref type="bibr" coords="6,118.82,623.82,10.58,8.64" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results for scenario B</head><p>Table <ref type="table" coords="6,125.64,673.28,4.91,8.64" target="#tab_1">3</ref> reports our results for Scenario B, in terms of in terms of two variants of nDCG metric namely nDCGp and nDCG1. We recall here that the difference between these variants lies in the way in which systems are penalized for pushing tweets on a silent day. On such day, nDCG1 variant is binary whereas nDCGp is based on a linear penalty. In the nDCG1 metric, a system receives a perfect score (1) if it does not push any tweet on a silent day, or zero otherwise, whereas in the nDCGp metric the penalty is gradually increased from 0 to 1 according to the number of pushed tweets. First, we observe that the best performance is achieved by run IRIT-RunB3 that takes as input tweets filtered by the adaptive binary classifier based on Random Forest. This result confirms those obtained in scenario A.</p><p>As shown in Table <ref type="table" coords="7,191.83,175.10,3.66,8.64" target="#tab_1">3</ref>, our best performing run (IRIT-RunB3) overpass the baseline for nDCGp with an improvement of 1.95% but it failed to beat the baseline in terms of nDCGp metrics. This result underlines the fact that our run pushed more tweets in silent days than the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and future work</head><p>We presented in this paper an adaptive learning to filter strategy to tackle the challenge of for realtime tweet summerization. In the proposed approach, we consider the tweet filtering task as a binary classification problem. We use supervised learning approach to build a binary classifier that predicts the relevance of an incoming tweet with respect to the topic of interest. The proposed method allows countering the threshold setting issue and taking advantage of an ongoing assessment feedback. The binary classifier leverages social signals as well as query dependent features to enhance the detection of relevant tweets. For this purpose, we suggest a set of social and other non-content features suitable for real-time tweet filtering.</p><p>We believe that results are quite promising and could give interesting insights in the future regarding the challenge of real-time tweet filtering and summarization, which are important components in the information access within data-streams. The learning based filter achieves a good performance overall metrics with low cost of latency. Results also revealed that more improvements are achieved by taking advantage of ongoing relevance feedback.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,101.89,592.22,402.52,101.65"><head>Table 2 .</head><label>2</label><figDesc>Performances of our submitted runs for scenario A evaluated by the mobile assessors.From Table2, first, we observe that the performance of runs IRIT-Run1 and IRIT-Run3 based on adaptive learning strategy outperform the baseline overall evaluation metric. The best performances</figDesc><table coords="5,134.37,592.22,335.82,38.60"><row><cell></cell><cell cols="9">Rel Red Not Rel unjudged |R| coverage Mean latency Median latency S P</cell><cell>L P S U L U</cell></row><row><cell cols="4">IRIT-Run3 3115 84 2385</cell><cell>62</cell><cell cols="2">1836 0.966</cell><cell>328.8</cell><cell>34.0</cell><cell cols="2">0.5578 0.5729 646 814</cell></row><row><cell cols="4">IRIT-Run1 3226 93 3112</cell><cell>90</cell><cell cols="2">2182 0.959</cell><cell>316.6</cell><cell>33.0</cell><cell cols="2">0.5016 0.5161 21 207</cell></row><row><cell cols="4">IRIT-Run2 3507 71 4337</cell><cell>61</cell><cell cols="2">2579 0.976</cell><cell>270.0</cell><cell>32.0</cell><cell cols="2">0.4431 0.4521 -901 -759</cell></row><row><cell>Baseline</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.4791</cell><cell cols="2">0.4829 -27.5 -12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,195.11,144.92,216.08,8.12"><head>Table 3 .</head><label>3</label><figDesc>Performances of our submitted runs for scenario B.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,111.85,685.88,140.15,7.77"><p>http://www.ark.cs.cmu.edu/TweetNLP/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,111.85,685.88,175.51,7.77"><p>http://nlp.stanford.edu/software/CRF-NER.shtml</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.25,453.71,399.31,7.77;7,113.59,464.51,390.81,7.93;7,113.27,475.47,203.19,7.93" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,356.32,453.71,148.24,7.77;7,113.59,464.67,69.02,7.77">Simple dynamic emission strategies for microblog filtering</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Lin Luchen Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Roegiest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,203.22,464.51,301.19,7.73;7,113.27,475.47,177.23,7.93">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;16</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,486.59,399.16,7.77;7,113.59,497.38,392.38,7.93;7,113.27,508.34,246.41,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,344.33,486.59,160.07,7.77;7,113.59,497.55,105.22,7.77">Multi-criterion real time tweet summarization based upon adaptive threshold</title>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><surname>Dousset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,235.08,497.38,266.86,7.73">2016 IEEE/WIC/ACM International Conferences on Web Intelligence (WI16</title>
		<meeting><address><addrLine>Omaha, Nebraska USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">October 13-16, 2016. 2016</date>
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,519.46,399.16,7.77;7,113.59,530.26,391.93,7.93;7,113.59,541.38,20.17,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,459.82,519.46,44.59,7.77;7,113.59,530.42,107.79,7.77">Overview of the trec 2015 microblog track</title>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yulu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Garrick</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,238.85,530.26,94.62,7.73">Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">November 17-20, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,552.34,399.16,7.77;7,113.59,563.14,323.25,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,470.09,552.34,34.31,7.77;7,113.59,563.30,115.96,7.77">The weka data mining software: An update</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,236.51,563.14,85.52,7.73">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009-11">November 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,574.26,399.15,7.77;7,113.37,585.06,153.01,7.93" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,335.84,574.26,168.57,7.77;7,113.37,585.22,42.98,7.77">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR, abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,596.18,399.16,7.77;7,113.59,606.97,392.38,7.93;7,113.32,617.93,291.64,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,344.76,596.18,159.65,7.77;7,113.59,607.13,84.44,7.77">Word similarity based model for tweet stream prospective notification</title>
		<author>
			<persName coords=""><forename type="first">Abdelhamid</forename><surname>Chellal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><surname>Dousset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,214.47,606.97,287.53,7.73">Advances in Information Retrieval -39th European Conference on IR Research</title>
		<meeting><address><addrLine>Aberdeen, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-08">2017. April 8-13, 2017. 2017</date>
			<biblScope unit="page" from="655" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,628.89,399.16,7.93;7,113.37,639.85,391.36,7.93;7,113.07,650.97,105.34,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,235.39,629.05,144.72,7.77">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName coords=""><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,396.73,628.89,107.68,7.73;7,113.37,639.85,312.05,7.93">Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16</title>
		<meeting>the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.25,661.77,258.23,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,166.12,661.93,55.51,7.77">Random forests</title>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,228.13,661.77,64.70,7.73">Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
