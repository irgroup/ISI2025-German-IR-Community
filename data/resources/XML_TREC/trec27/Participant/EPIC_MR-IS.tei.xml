<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,87.28,85.14,437.00,17.58;1,249.10,106.91,113.73,17.58">EPIC_MR Participation in the TREC 2018 Incidence Stream Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,224.60,159.93,106.90,11.10"><forename type="first">Simon</forename><forename type="middle">W Y</forename><surname>Chung</surname></persName>
						</author>
						<author>
							<persName coords="1,341.55,159.93,45.54,11.10"><forename type="first">K</forename><forename type="middle">K</forename><surname>Lo</surname></persName>
						</author>
						<title level="a" type="main" coord="1,87.28,85.14,437.00,17.58;1,249.10,106.91,113.73,17.58">EPIC_MR Participation in the TREC 2018 Incidence Stream Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D0198B4373A2EDB9084F56D63EF6BB50</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation of the EPIC_MR group to the TREC 2018 Incident Streams Track. The target of the track is to monitor the social media and classify different type of information to help different response agencies. This paper describes our approach to use the words with Wikipedia articles to build the training vector, and also the result and comments of our runs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In this short paper, we describe the methods we used to build our training set, how do we evaluate the different type of classification algorithm, the result of our runs and the comments based on our current work.</p><p>The goal of TREC 2018 Incident Streams Track is to analyze social media emergencies information like requests and report, so the responding units can quickly get useful information and help in planning. In this track, tweets are used for the testing set. The track will analyze numbers of tweets which is fall under different event such as earthquakes, flood and classify each tweet into 25 high-level event type. Some examples of the event types are Request for goods, request for information, calling to action, report, and etc.</p><p>For starter, we proposed a simple way to filter words with meaning, train the classification algorithm by tagging the event type and then use them to categorize the tweets into high-level event type in a fast manner.</p><p>The paper mainly focuses on the system overview and result. System overview will talk about the data and how our system is constructed. Result will talk about our test result and discussion about them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Overview Data Collection</head><p>All topic, information type and tweets data are provided by task coordinators. There are 6 topics with around 1.3k tweets for training and 15 topics with around 22k tweets for testing. The system classifies the tweets into 25 high level types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training</head><p>To make the dataset (the tweets) more meaningful for training, we do a couple of adjustment to the words. First, we remove punctuation and non-alphanumeric characters to create an English only training set in order to reduce complexity and improve accuracy. Second, we make all characters to normalize the word forms. Third, we filtered out the common English stop words which is provided by nltk library and some self-defined stop word such as "RT, meaning retweet" as these words are less meaningful to our system. Fourth, strings like URL are also filtered out as they are also relatively less meaningful to the message.</p><p>The remaining are the words we are interested in and relatively meaningful. However, some words are meaningless with phrases. We decided to combine those words into 2-gram and 3gram combinations to find possible combinations. For the 2-gram and 3-gram combinations, we search those possible phrases with Wikipedia knowledge base to see if there are any matches. For those phrases with Wikipedia matches, we regard them as meaningful phrase and mark them as new words. Combining the original words and possible phrases, we use them to train as our training vector.</p><p>For the training, we used different models to test for accuracy. They include CART (Classification and Regression Trees), Gaussian Naive Bayes, Neural network Multi-layer Perceptron, Nearest Centroid, Random Forest Classifier, Gradient Boosting Classifier. All the training and fitting are run using sklearn python library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Selection</head><p>With different model, we use the training dataset to evaluate its accuracy. We pick 80% of data to train and another 20% to fit. The result shows that CART (Classification and Regression Trees) and Random Forest Classifier have relatively higher and similar accuracy comparing to the others. Therefore, for the real data set, we decided to use CART and Random Forest Classifier with different number of trees to our final learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result</head><p>Below is our submitted run performance. We mainly focus the F1 score and Accuracy, the score is close to the Median score comparing to the others. As you can see, the score is not ideal.</p><p>One of the reasons is the training set is not good and meaningful enough. It should be better if we linking the text with more knowledge base. Also, social media text are usually not standard English, there it should be better if we can unify the text with same word such as text correction and unify to single verb tense or even part of speech. Also taking user profile into account may be also useful to improve the model. With more experiments to discover more combinations, the result should be improved.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
