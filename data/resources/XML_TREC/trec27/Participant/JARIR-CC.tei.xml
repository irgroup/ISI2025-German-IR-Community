<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.38,152.67,336.38,12.64">Query Expansion Based on NLP and Word Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,169.70,191.70,63.43,8.96"><forename type="first">Billel</forename><surname>Aklouche</surname></persName>
							<email>billel.aklouche@ensi-uma.tn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">JARIR: Joint group for Artificial Reasoning and Information Retrieval</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratory of Computer Science for Industrial System (LISI)</orgName>
								<orgName type="institution">Carthage University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">National School of Computer Science (ENSI)</orgName>
								<orgName type="institution">La Manouba University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.31,191.70,68.93,8.96"><forename type="first">Ibrahim</forename><surname>Bounhas</surname></persName>
							<email>bounhas.ibrahim@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">JARIR: Joint group for Artificial Reasoning and Information Retrieval</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratory of Computer Science for Industrial System (LISI)</orgName>
								<orgName type="institution">Carthage University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Higher Institute of Documentation (ISD)</orgName>
								<orgName type="institution" key="instit2">La Manouba University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.87,191.70,59.61,8.96"><forename type="first">Yahya</forename><surname>Slimani</surname></persName>
							<email>yahya.slimani@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">JARIR: Joint group for Artificial Reasoning and Information Retrieval</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratory of Computer Science for Industrial System (LISI)</orgName>
								<orgName type="institution">Carthage University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Higher Institute of Multimedia Arts of Manouba (ISAMM)</orgName>
								<orgName type="institution" key="instit2">La Manouba University</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.38,152.67,336.38,12.64">Query Expansion Based on NLP and Word Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DFE54025BCAD78B2539309B0367FF698</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ad Hoc Information Retrieval</term>
					<term>Query Expansion</term>
					<term>NLP Tools</term>
					<term>Word2Vec</term>
					<term>BM25</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Query Expansion is an important process in information retrieval, which consists in adding new related terms to the original query in order to better identify relevant documents. In this paper, we discuss the participation of the JARIR research group to the TREC 2018 Common Core Track. We present different Query Expansion methods, which are based on Natural Language Pre-processing (NLP) tools and Word2Vec embedding models. Using the title of TREC topics, we select semantically related terms to the query. Our approach is composed of four steps: (1) Data Pre-processing, (2) Model Training, (3) Query Expansion and (4) Documents Ranking. For our best runs, results show that most of our topics scores are above the published median scores with some topics having the best scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2018 Common Core Track 1 is a traditional ad hoc retrieval task with the aim of exploring new collection construction methodologies and providing the IR community with a solid test collection. The track provides participants with a new dataset composed of the Washington Post Corpus and 50 topics. The TREC Washington Post Corpus contains news articles and blog posts written and published by Washington Post 2 from January 2012 through August 2017. Two sets of topics are provided: (a) 25 topics from the 2017 Common Core Track and (b) 25 new topics developed by the NIST assessors for this track. Each team could submit up to 10 runs total, a run contains a ranked list of top n documents retrieved for each topic. The track received a total of 72 runs submitted by 12 participating teams. Across all 72 runs, 7 were manual runs, 31 used existing relevance judgments if available and 34 were automatic runs. The track 50 topics are judged by the NIST assessors. Our participation consists in using Query Expansion in Information Retrieval. Query Expansion refers to the techniques that expand search terms to include other related terms that enhance original queries, in order to provide richer and more relevant results. For several years, great effort has been devoted to the development of new Query Expansion approaches <ref type="bibr" coords="2,206.57,222.18,10.69,8.96" target="#b0">[1]</ref>. In this paper, we present different Query Expansion methods that are based on NLP tools and Word2Vec embedding models <ref type="bibr" coords="2,385.39,234.18,10.69,8.96" target="#b4">[5]</ref>. Indeed, there are two models in Word2Vec for producing word vectors: Skip-Gram and Continuous Bag Of Words (CBOW). We compare and investigate the use of both models in obtaining new semantically related terms to the original queries. The two models were trained on the TREC Washington Post Corpus. In all proposed methods, a common pre-processing step is applied before getting in the training step. In addition, we investigate the impact of query reweighting and terms selection strategy on retrieval effectiveness.</p><p>The remainder of the paper is organized as follows. Section 2 outlines our approach and experiments. We evaluate and discuss our results in Section 3. Finally, Section 4 concludes the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach And Experiments</head><p>Our submission to the TREC 2018 Common Core Track consists of six automatic runs.</p><p>Using only the title of TREC topics, which contains few keywords, our goal is to investigate a real IR scenario where no prior judgment is available and no manual intervention is performed. Also, in accordance with our goal, we aimed to present a Query Expansion approach that combines the advantages of NLP techniques and Word2Vec embedding models, in order to get an efficient retrieval system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. General architecture of the proposed approach</head><p>Figure <ref type="figure" coords="3,165.02,150.18,4.98,8.96">1</ref> illustrates the general architecture of the proposed approach. First, we exploit NLP techniques to extract a clean textual content from the TREC Washington Post Corpus. The filtered corpus is then used to train Word2Vec Skip-Gram or CBOW models; the training step consists in learning word vector representations that are good at capturing semantic relations between terms <ref type="bibr" coords="3,307.39,198.18,10.69,8.96" target="#b4">[5]</ref>. Afterward, the word vectors of the trained model are used to select top n similar terms to the original TREC topic titles; the new terms are selected based on their similarity to the entire query or their similarity to its individual terms. Furthermore, a term reweighting might be performed in order to update the new query. Finally, the new expanded queries are used to retrieve a set of top ranked 10,000 documents for each topic according to the state-of-the-art weighting scheme Okapi BM25 <ref type="bibr" coords="3,212.33,270.21,10.69,8.96" target="#b7">[8]</ref>. Each step of our approach is described in more details in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Pre-processing</head><p>Data pre-processing is an important and necessary phase before dealing with text corpora. We need to convert the corpus into a clean and consistent format, which is easier to process. To this end, we used the Python library NLTK<ref type="foot" coords="3,362.35,355.14,3.24,5.83" target="#foot_2">3</ref> for all the pre-processing steps:</p><p>• Text segmentation: we used NLTK's Tokenizers to split text into sentences and then split sentences into individual tokens.</p><p>• Stop words removal: in this step, all non-informative words are filtered out. We used a stop word list composed from Terrier and NLTK.</p><p>• Stemming: we used Porter Stemmer <ref type="bibr" coords="3,299.35,440.27,10.69,8.96" target="#b6">[7]</ref>, which is implemented in NLTK to reduce all terms to their stems. In addition, all terms are lowercased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model Training</head><p>Word embeddings refers to techniques that are used to produce vector representations of words <ref type="bibr" coords="3,166.22,514.31,10.69,8.96" target="#b3">[4]</ref>. In this work, we used Word2Vec for computing word embeddings. Word2Vec can use either Skip-Gram or CBOW model to construct word vectors. Within a surrounding window, the Skip-Gram model predicts the context words of a given target word, while the CBOW model predicts a target word based on context words <ref type="bibr" coords="3,151.46,562.31,10.69,8.96" target="#b4">[5]</ref>. We used the filtered TREC Washington Post Corpus resulting from the previous step to train the models. The training parameters were set as follows. We used a window size equal to 5 and we set the vectors dimension to 300. We also removed any words that appear less than 5 times in the whole corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query Expansion</head><p>In this step, word vectors are used to find semantically related terms to the query. To this end, we used Euclidean Distance to calculate the similarity score between two vectors. Thus, an exhaustive search is performed to find all possible candidate vectors. As mentioned before in this section, expansion terms are either similar to the entire query or to its individual terms. Consequently, the target vector is the result of addition of vectors associated with original query terms in the first case, while in the second case, the target vector is the vector associated with an individual term. Afterward, the candidate terms are sorted in a decreasing order according to their similarity scores. The top n terms are chosen as the final expansion terms where n is the number of the original query terms. Moreover, a reweighting step might be applied to assign weights to the new query terms. To this end, we chose to attribute a weight of w=1 to the original query terms and a weight of w=0.5 to the new expansion terms. The new expanded queries are then used in documents retrieval and ranking step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Documents Ranking</head><p>We used Terrier<ref type="foot" coords="4,192.17,363.18,3.24,5.83" target="#foot_3">4</ref> , a flexible and a high performance scalable Information Retrieval platform <ref type="bibr" coords="4,161.42,376.29,10.69,8.96" target="#b5">[6]</ref>, to index the collection and form our runs. We opted to use the well-established Okapi BM25 probabilistic weighting scheme with default parameters in order to perform the documents ranking. For each run, the top ranked 10,000 documents retrieved for each topic were submitted, in descending order by score.</p><p>In Table <ref type="table" coords="4,160.82,436.31,3.77,8.96" target="#tab_0">1</ref>, we summarize the method adopted for each submission. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>As mentioned before, the TREC 2018 Common Core Track received a total of 72 runs from 12 participating teams. Across all 72 runs, 7 were manual runs, 31 used existing relevance judgments if available and 34 were automatic runs. The judgment sets for the 50 topics were created by NIST assessors. We submitted 6 automatic runs for this year's track. Table <ref type="table" coords="5,161.18,174.18,4.98,8.96" target="#tab_1">2</ref> demonstrates the mean performance of each run over the 50 NIST topics for the evaluation metrics MAP, NDCG and P@10 [3]. To position our results with results of other teams, we included the average of the "Median" scores calculated across all the submitted automatic runs. Half of our runs reached a score above the TREC median according to all measures. Figure <ref type="figure" coords="5,152.66,430.79,4.98,8.96" target="#fig_0">2</ref> illustrates the mean performance of our best run jarir_sg_re measured by MAP compared with TREC_Median. We can observe that most of our results are above the median scores. More precisely, 40 out of 50 topics have a result above the median including 2 topics having the best score. Besides, we also achieved the best P@10 value on 3 topics and the best NDCG value on 2 topics. It is important to note that the TREC_Median scores were computed from runs that used existing relevance judgments. As stated before, our runs were produced without using any prior judgment. Furthermore, it is worth mentioning that 27 out of 50 topics achieved a score above the median over all TREC submitted runs, i.e., over the four categories of runs.</p><p>Among our runs, jarir_sg_re achieved the best retrieval effectiveness according to all measures. As described in Section 2, jarir_sg_re used Word2Vec Skip-Gram model for training, expansion terms that are similar to the entire query and query reweighting. Figure <ref type="figure" coords="6,152.78,210.18,4.98,8.96" target="#fig_1">3</ref> shows a performance comparison between all submitted runs in terms of MAP, NDCG and P@10. As it can be observed, Word2Vec Skip-Gram model outperformed the CBOW model in all scenarios. Interestingly enough, using query reweighting yielded the best results and brought a significant improvement compared to other approaches. That is, retrieval effectiveness decreases when all terms of the expanded query have been assigned the same weight. Furthermore, using similarity to the whole query to get expansion terms yielded better results than using similarity to individual query terms, which is consistent with our expectation. However, what we did not expect was that the run jarir_cbow was ranked last after the run jarir_cbow_ind, which means that in the case of CBOW model, selecting expansion terms that are similar to individual query terms gave slightly better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed a Query Expansion approach based on Natural Language Pre-processing techniques and Word2Vec embedding models. Overall results are consistent with our expectations. The obtained scores show that for our best run, 80% of our topics are above the TREC median scores. In our experiments, we trained Word2Vec models over the entire TREC Washington Post Corpus. As a future work, we plan to investigate local training of Word2Vec models in a query-specific manner as previous studies demonstrated promising results <ref type="bibr" coords="7,330.79,162.18,10.69,8.96" target="#b1">[2]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,135.86,598.99,323.57,8.10;5,124.70,463.89,345.79,126.25"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Performance of jarir_sg_re run measured by MAP compared with TREC_Median.</figDesc><graphic coords="5,124.70,463.89,345.79,126.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,141.50,438.76,311.94,8.10;6,124.70,243.40,345.90,186.55"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Comparison of performance by MAP, NDCG and P@10 for all submitted runs.</figDesc><graphic coords="6,124.70,243.40,345.90,186.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,146.35,474.70,299.10,187.05"><head></head><label></label><figDesc></figDesc><graphic coords="2,146.35,474.70,299.10,187.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,130.34,460.24,328.64,109.71"><head>Table 1 .</head><label>1</label><figDesc>Summary of the six submitted runs to TREC</figDesc><table coords="4,130.34,477.47,328.64,92.48"><row><cell>Run Tag</cell><cell>Data Pre-</cell><cell>Word2Vec</cell><cell>Expansion</cell><cell>Query Re-</cell></row><row><cell></cell><cell>Processing</cell><cell>Model</cell><cell>Terms Similarity</cell><cell>weighting</cell></row><row><cell>jarir_skipgram</cell><cell></cell><cell>Skip-Gram</cell><cell>Whole query</cell><cell>No</cell></row><row><cell>jarir_cbow</cell><cell></cell><cell>CBOW</cell><cell>Whole query</cell><cell>No</cell></row><row><cell>jarir_sg_re</cell><cell></cell><cell>Skip-Gram</cell><cell>Whole query</cell><cell>Yes</cell></row><row><cell>jarir_cb_re</cell><cell></cell><cell>CBOW</cell><cell>Whole query</cell><cell>Yes</cell></row><row><cell>jarir_sg_ind</cell><cell></cell><cell>Skip-Gram</cell><cell>Individual terms</cell><cell>No</cell></row><row><cell>jarir_cb_ind</cell><cell></cell><cell>CBOW</cell><cell>Individual terms</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,124.70,234.11,332.31,163.38"><head>Table 2 .</head><label>2</label><figDesc>Overall Performance of submitted runs, compared to the median results of all automatic runs</figDesc><table coords="5,169.34,262.53,255.43,134.96"><row><cell>Run Tag</cell><cell>MAP</cell><cell>NDCG</cell><cell>P@10</cell></row><row><cell>jarir_skipgram</cell><cell>0.1769</cell><cell>0.4576</cell><cell>0.2980</cell></row><row><cell>jarir_cbow</cell><cell>0.1289</cell><cell>0.3841</cell><cell>0.2460</cell></row><row><cell>jarir_sg_re</cell><cell>0.2040</cell><cell>0.4861</cell><cell>0.3700</cell></row><row><cell>jarir_cb_re</cell><cell>0.1896</cell><cell>0.4595</cell><cell>0.3200</cell></row><row><cell>jarir_sg_ind</cell><cell>0.1471</cell><cell>0.4130</cell><cell>0.2720</cell></row><row><cell>jarir_cb_ind</cell><cell>0.1317</cell><cell>0.3868</cell><cell>0.2600</cell></row><row><cell>TREC_Median</cell><cell>0.1744</cell><cell>0.4482</cell><cell>0,3340</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,129.98,675.31,114.50,8.10"><p>https://trec-core.github.io/2018/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,129.98,686.35,123.28,8.10"><p>https://www.washingtonpost.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,129.98,686.35,181.12,8.10"><p>Natural Language ToolKit (https://www.nltk.org/)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,129.98,686.35,60.19,8.10"><p>http://terrier.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,128.11,220.07,342.20,8.10;7,138.86,232.07,229.18,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,243.96,220.07,226.35,8.10;7,138.86,232.07,21.99,8.10">A Survey of Automatic Query Expansion in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,166.30,232.07,123.98,8.10">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="50" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,244.07,342.53,8.10;7,138.86,256.10,90.48,8.10" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07891</idno>
		<title level="m" coord="7,257.80,244.07,208.54,8.10">Query Expansion with Locally-Trained Word Embeddings</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,268.10,160.62,8.10;7,306.96,268.10,163.32,8.10;7,138.86,280.10,126.68,8.10" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,306.96,268.10,136.39,8.10">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,292.10,342.24,8.10;7,138.86,304.10,167.69,8.10" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="7,318.03,292.10,152.32,8.10;7,138.86,304.10,75.52,8.10">Efficient Estimation of Word Representations in Vector Space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,316.10,342.39,8.10;7,138.86,328.10,331.50,8.10;7,138.86,340.10,331.49,8.10;7,138.86,352.10,330.85,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,361.09,316.10,109.40,8.10;7,138.86,328.10,171.83,8.10">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,331.41,328.10,138.95,8.10;7,138.86,340.10,331.49,8.10;7,138.86,352.10,69.35,8.10">Advances in Neural Information Processing Systems, Proceedings of the 26th International Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">December 05 -10, 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,364.10,342.17,8.10;7,138.86,376.10,331.93,8.10;7,138.86,388.10,310.73,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,400.54,364.10,69.74,8.10;7,138.86,376.10,64.60,8.10">Terrier Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,220.89,376.10,249.91,8.10;7,138.86,388.10,116.81,8.10">Advances in Information Retrieval, Proceedings of the European Conference on Information Retrieval</title>
		<meeting><address><addrLine>Grenoble, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">March 26-29, 2005</date>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,400.10,332.47,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,189.91,400.10,117.13,8.10">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,312.66,400.10,57.61,8.10">Program journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.11,412.10,342.57,8.10;7,138.86,424.12,331.45,8.10;7,138.86,436.12,331.84,8.10;7,138.86,448.12,190.20,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,243.16,412.10,227.51,8.10;7,138.86,424.12,129.09,8.10">Some Simple Effective Approximations to the 2-Poisson Model for Probabilistic Weighted Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,285.88,424.12,184.43,8.10;7,138.86,436.12,276.41,8.10">Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1994">July 03 -06, 1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
