<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.66,112.05,432.69,15.12">UMass at TREC 2018: CAR, Common Core and News Tracks</title>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,160.03,144.53,83.63,10.48"><forename type="first">Shahrzad</forename><surname>Naseri</surname></persName>
							<email>shnaseri@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.00,144.53,55.93,10.48"><forename type="first">John</forename><surname>Foley</surname></persName>
							<email>jjfoley@smith.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst Smith College</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.26,144.53,62.97,10.48"><forename type="first">James</forename><surname>Allan</surname></persName>
							<email>allan@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.66,112.05,432.69,15.12">UMass at TREC 2018: CAR, Common Core and News Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">974874D6691857CECBE8B1325BB235AA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>UMass participated in three TREC tasks in 2018: the TREC CAR, TREC Core tasks and TREC News (Background Linking). In this paper we detail the contents of our submissions and our lessons learned from this year's participation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is an overview of University of Massachusetts efforts in providing document retrieval run submissions for the TREC CAR passage retrieval, TREC Core and TREC News background linking tracks. In TREC CAR, our run investigates the impact of similarity between query and documents embedding vector representation on retrieval accuracy with the goal of alleviating vocabulary mismatch problem. For our TREC core submission, we explored more efficient variations on a traditional term dependency model to see if there are detectable differences in new document pools. We also explored some of our efficiency gains in a document feedback context within the TREC News background linking task.</p><p>We demonstrate our approaches in retrieval for TREC CAR, TREC Core and TREC News in Section 2, Section 3 and Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TREC CAR</head><p>In this year's TREC CAR track, we aim to investigate the long standing vocabulary mismatch problem for the hierarchical complex topics of CAR collection. We address the task of passage retrieval and retrieval from a passage collection exacerbates the vocabulary mismatch problem. This is because of the extensive use of language variety and abbreviations in related series of passages. Neural ranking models <ref type="bibr" coords="1,128.24,512.15,9.79,7.86" target="#b7">[8,</ref><ref type="bibr" coords="1,141.10,512.15,11.80,7.86" target="#b10">11,</ref><ref type="bibr" coords="1,155.98,512.15,11.80,7.86" target="#b11">12]</ref> tackle this problem by learning a global dense word embedding representation based on the adjacent terms in the context. Using the learned embedding vector, we then can find the similar terms in the multi-dimensional embedding space to a given term. In this work, since CAR is an entity centric collection, we learn a joint word-entity embedding representation on the Wikipedia corpus and represent query and the paragraphs based on their corresponding embedding vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing TREC CAR Passages</head><p>We index the paragraphs in TREC CAR corpus using Galago search engine with the link and the paragraph's text fields. Queries' stop words are removed using the 418 INQUERY stopwords list. Stemming is performed using the built-in Krovetz stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning Joint Word-Entity Embeddings</head><p>Motivated from the concept of vocabulary mismatch problem, we learn a joint entity-word embedding following the approach presented by Ni et al. <ref type="bibr" coords="1,281.47,675.35,13.51,7.86" target="#b12">[13]</ref>. We learn a low dimensional vector representation for entities and words based on Mikolov Skip-gram model <ref type="bibr" coords="1,314.37,686.31,14.23,7.86" target="#b9">[10]</ref> using term co-occurrence information within a text. Each entity mention specified by its link is considered as a single "term". The Skip-gram model aims to maximize the probability of current term based on its surrounding terms using a neural network.</p><p>The following excerpt shows the transformation of text with entity mentions using special placeholders for each mention:</p><p>A hybrid electric vehicle (HEV) is a type of hybrid vehicle that combines a conventional internal combustion engine (ICE) system with an electric propulsion system (hybrid vehicle drivetrain). The presence of the electric powertrain is intended to achieve either better fuel economy than a conventional vehicle or better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Embedding-based Passage Ranking</head><p>Each topic, i.e. query, in CAR collection is consist of three subtopics. As an example, the query [Antibiotic use in livestock/Use in different livestock/In swine production] has "Antibiotic use in livestock" as root (R), "Use in different livestock" as intermediate (I) and "In swine production" as leaf (L) subtopics. To formulate a query, we use the concatenation of R, I and L. We retrieve a set of documents with three baseline methods: SDM (Sequential Dependence Model), RM3 and query likelihood with the subtopic combinations of R-L, R-I-L and R-I-L, respectively.</p><p>Furthermore, we represent each document and query based on their entity embeddings. Each document is represented by average of entities' embedding vector in the document. Each query has a fine-grained subtopic representations as well as a complete topic representation. To be more specific, we represent a query by the average embedding vectors of entities only in Root (R), entities only in Leaf (L) as well as all of the entities in the topic.</p><p>We use cosine similarity between the document vector representation and each query representation as features for a LambdaMart learning-to-rank model. Moreover, the retrieval scores from the base retrieval model are also added as features to the learning-to-rank model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Run Submitted</head><p>We tune the retrieval hyper-parameters on the benchmarkY1-train.v2.0 training data using grid search. For the Query Likelihood model the smoothing parameter Âµ = 400 gives the optimal result. For the Sequential Dependence Model (SDM) baseline mu = 1200, uww = 0.02, odw = 0.10, and uniw = 0.82 are the best parameters.</p><p>For pseudo relevance feedback baseline, we use SDM model as the baseline retrieval method. The expansion parameters are tuned similarly using grid search and we find that 10 expansion documents with 20 feedback terms and an interpolation weight of 0.8 is most effective. For document entity annotations we use the existing links provided in Wikipedia. Furthermore, for query annotation, we use the open-source state-of-the-art SMAPH entity linker<ref type="foot" coords="2,249.45,471.39,3.65,5.24" target="#foot_0">1</ref> for each query's subtopic.</p><p>In our experiment all parameter tuning as well as learning the learning-to-rank model was performed on benchmarkY1-train.v2.0. benchmarkY1-test-public.v2.0 data was used as a validation set during training the learning-to-rank model. We use LambdaMart as our learning-to-rank model.</p><p>The result for our submitted run is showed in Table <ref type="table" coords="2,321.52,517.00,3.54,7.86" target="#tab_0">1</ref>. As results suggest, the best run is the rl-sdm run, and our global embedding vector similarity features were unable to beat the strong rl-sdm baseline. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TREC Core</head><p>For the TREC Core task, we chose to explore some approximations to traditional term dependency models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing WAPO Articles</head><p>We indexed the Wapo corpus provided for both news and core tasks with the following fields (when available): published.date, url, kind, title, author, kicker, and we constructed a body from the text of (HTML tags were removed with JSoup<ref type="foot" coords="3,264.93,112.74,3.65,5.24" target="#foot_1">2</ref> ) the JSON paragraph "blobs".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Background: Dependency Models</head><p>Many models try to incorporate textual information beyond simple unigrams. One of the most commonly used models is the sequential dependence model (SDM) described by Metzler and Croft <ref type="bibr" coords="3,448.26,168.71,9.10,7.86" target="#b8">[9]</ref>. Variations of this model are still relevant to many applications today, such as entity retrieval <ref type="bibr" coords="3,420.32,179.67,13.52,7.86" target="#b16">[17]</ref>. Although this model is described as a markov random field, Dietz and Foley showed that this is equivalent to a handful of other formulations, particularly generative models <ref type="bibr" coords="3,408.67,201.59,9.22,7.86" target="#b2">[3]</ref>.</p><p>Huston and Croft surveyed a wide variety of models that integrate dependency into query-document scoring <ref type="bibr" coords="3,129.68,223.50,9.33,7.86" target="#b4">[5]</ref>. In a later, unpublished technical report, they compare the many different formulations of so-called UnorderedWindow dependencies (broken down by what kinds of overlap are allowed) and determined that there was no observable statistical difference between common formulations <ref type="bibr" coords="3,473.10,245.42,9.22,7.86" target="#b5">[6]</ref>.</p><p>Surprisingly, there is little research focusing on the efficiency and effectiveness tradeoffs between feature functions chosen in dependency models. Huston's thesis is a rather complete discussion of the tradeoffs between indexing and computing dependencies on the fly, and includes discussion of a sketching technique for more cheaply estimating these statistics and counts <ref type="bibr" coords="3,362.99,289.26,9.22,7.86" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cheap Sequential Dependency Modeling</head><p>In this subsection, we describe a "bag of tricks" for cutting down the execution time of traditional SDM <ref type="bibr" coords="3,505.47,332.50,9.63,7.86" target="#b8">[9]</ref> queries. Our evaluation will show that these tricks have limited impact on overall accuracy, making our CSDM formulation a practical alternative version to this classical model.</p><p>In the sequential dependence model, term dependencies are assumed between adjacent terms in a query. Unigrams are also kept as the primary ranking of documents, and dependencies are given lower weights in comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Min-Estimate Statistics</head><p>Most modern retrieval models have some kind of probabilistic interpretation and specify either the collection frequency of a phrase or the document frequency of a phrase as a necessary component for normalizing values. In most systems, like Galago this means that a dependency query becomes two evaluations for the underlying engine: once to compute the collection-wide frequencies and once to compute the actual document values.</p><p>We propose a simple alternative to this normalizer that eliminates one pass of batch processing. Instead of calculating the exact value (which involves visiting every document): F (wi, wj, C) = dâC F (wi, wj, d), we leverage the pre-stored unigram statistics of F (wi, C) and F (wj, C) to estimate F . Since traditional dependencies -both ordered and unordered -involve the intersection of posting lists, we can estimate their statistics as upper-bounded by the minimum: F (wi, wj, C) = min(F (wi, C), F (wj, C)). This minimum as upper-bound is intuitive: the phrase "garden vegetables" can occur no more than "garden" or "vegetables" occur independently.</p><p>Since it is an upper-bound, it works fine as a normalizer (no estimated probabilities above 1.0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Stopwords only in Dependencies</head><p>One common efficiency trick in any query processing is to elide stopwords. However, famous TREC queries such as "to be or not to be" encourage system designers to leave stopwords in their indexes and and their batch query submission systems.</p><p>If we elide stopwords from the unigram representation, we handle queries like "to be or not to be" as a sequence of dependencies where intersection of posting lists can be used to limit candidate scoring, e.g., "[D(to be) D(be or) D(or not) D(not to) D(to be)]". While still dramatically cutting down the number of candidates (instead of processing and fully-scoring nearly all documents, we can eliminate some that do not have rarer bigrams like "be or". Once you toss in some query intelligence and feature folding, you can often execute this stopped query much faster <ref type="bibr" coords="3,298.33,690.77,9.22,7.86" target="#b1">[2]</ref>. would indicate true differences. We used the pairwise randomization test derived from Galago in order to compute run differences</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Document Query Generation</head><p>We began by computing a traditional relevance model <ref type="bibr" coords="5,325.90,228.35,9.33,7.86" target="#b6">[7]</ref>, which provides a mapping of unigrams to probabilities, P (w|RD), where the set of relevant documents is just the input query document: P (w|DQ), excluding the inquery stopwords provided with Galago<ref type="foot" coords="5,320.27,248.50,3.65,5.24" target="#foot_2">3</ref> . For all pairs of terms wi, wj we then compute the minimum distance between them as they occur in the original source document: mindist(wi, wj). We extracted a set of dependencies for which mindist(wi, wj) â¤ M , where the minimum distance was left as a parameter. We weighted these dependency parameters by their importance: the geometric mean of their probabilities P (wi|DQ) â¢ P (wj|DQ). We used the full set of detected dependencies and combined it linearly with the traditional relevance model expression (capped to a parameter k terms). We used Dirichlet smoothing for all probability computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Result Filtering</head><p>Duplicate detection was a challenge this year, so we de-duplicated documents by title (choosing the most recent publication date for any conflicts) and rejected all documents without a title from ranking -feeling that documents are not useful for background research if they cannot be summarized concisely.</p><p>We also enforced that documents retrieved were published before the query document, using a streaming model for our evaluation. Following the track guidelines, we also excluded documents whose kickers were: "Opinion(s)", "Letters to the Editor", or "The Post's View".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Runs Submitted</head><p>We briefly tuned our Âµ, N , M and Î» parameters on a simulated task over Robust04, because it is also a News corpus. Because we did not learn different parameters for different queries, we did not consider this run to be using prior knowledge. The parameters selected were quite close to default parameters used in the Galago search engine. We had N = 50 feedback terms, a window detection threshold of M = 8, and a lambda between dependencies of Î» = 0.8.</p><p>Our TREC submissions here had no significant differences, for a variety of parameter selection reasons. We hope to explore window dependencies extraction in further Background linking submissions.</p><p>umass rm This run is a standard relevance model. umass rdm This run was an attempt to mix extracted unordered window dependencies into a standard umass rm model, but in practice these dependencies barely changed the ranking, and did not affect measures, despite searching for a bug.</p><p>umass cbrdm This run was actually just an RM model with BM25 scoring functions, due to a processing bug. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Name</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results Discussion</head><p>While we intended for term dependency extraction from relevance documents to have a bigger impact (due to weighting and relative lack of importance they did not) our results here do suggest that our cheaper dependencies do not have a significant impact and that using BM25 rather than query likelihood does not result in a loss of performance on an additional task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Time Filtering</head><p>We submitted runs that pruned all documents published after the query document. Documents missing a publication time were considered to be older than any others and were therefore included. Although this was not part of the final ruleset, it actually significantly improved results, at least in terms of precision! (umass rm achieves lower performance without time filtering: NDCG@5=3.556 vs. NCDG@5=0.4157).</p><p>In future submissions to TREC News, we hope to explore this relationship between time and relevance more deeply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We present our approach in TREC CAR, TREC Core and TREC News background-linking tasks. SDM is a powerful baseline: our TREC CAR submission was unable to beat it (with more features) and we have preliminary evidence to suggest that simpler features lead to equivalent retrieval power. In TREC Core, we found that our approximations to standard SDM functions caused no significant drops in performance, and in TREC News we found that background articles being before a query article was a highly useful feature. We plan to study our models in more detail in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,169.18,557.85,273.63,64.77"><head>Table 1 :</head><label>1</label><figDesc>Paragraph retrieval on benchmarkY2test Manual</figDesc><table coords="2,169.18,572.71,273.63,49.91"><row><cell>Model</cell><cell cols="3">MAP R-Prec NDCG</cell></row><row><cell cols="2">umass entityEmbedLambdaMart 0.2792</cell><cell>0.2803</cell><cell>0.5223</cell></row><row><cell>rl-sdm</cell><cell>0.3542</cell><cell>0.3488</cell><cell>0.5769</cell></row><row><cell>ril-rm3</cell><cell>0.2482</cell><cell>0.2580</cell><cell>0.4878</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,71.64,73.56,469.52,90.93"><head>Table 2 :</head><label>2</label><figDesc>One-sided p-value computation for whether runs are different: low p-values (typically p &lt; 0.05)</figDesc><table coords="5,195.58,73.56,220.84,69.19"><row><cell></cell><cell></cell><cell>baseline</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">umass ql umass sdm</cell></row><row><cell>treatment</cell><cell>umass ql</cell><cell>1.000</cell><cell>0.384</cell></row><row><cell></cell><cell>umass sdm</cell><cell>0.616</cell><cell>1.000</cell></row><row><cell></cell><cell>umass bsdm</cell><cell>0.479</cell><cell>0.381</cell></row><row><cell></cell><cell>umass cbsdm</cell><cell>0.380</cell><cell>0.294</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,191.87,628.46,228.26,66.47"><head>Table 3 :</head><label>3</label><figDesc>Runs submitted to TREC.</figDesc><table coords="5,191.87,628.46,228.26,45.28"><row><cell></cell><cell>Scorer</cell><cell cols="2">NDCG@5 NDCG@1000</cell></row><row><cell>umass rm</cell><cell>dirichlet</cell><cell>0.4157</cell><cell>0.4658</cell></row><row><cell>umass rdm</cell><cell>dirichlet</cell><cell>0.4157</cell><cell>0.4658</cell></row><row><cell cols="2">umass cbrdm bm25</cell><cell>0.4173</cell><cell>0.4688</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,87.24,709.73,139.73,6.64"><p>https://github.com/marcocor/smaph</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,87.24,709.90,76.21,6.64"><p>https://jsoup.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,87.24,715.13,143.96,6.64"><p>http://lemurproject.org/galago.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">MinCount instead of UnorderedWindow</head><p>The core purpose behind window dependencies is to up-weight documents in which terms appear close together. Unfortunately, calculating the count of times two terms occur within a fixed window of each other requires a lot of storage or posting lists.</p><p>Instead, we propose looking at the MinCount of terms within a document. This provides an upperbound (once-again) on the true value of any UnorderedWindow. Motivated by Huston and Croft's technical report findings <ref type="bibr" coords="4,159.44,147.38,9.75,7.86" target="#b5">[6]</ref> that variations of UnorderedWindow functions are not that impactful on retrieval, we decided to investigate just how much the actual term proximity mattered, or if what were achieving was mostly just a softer boolean AND of the terms in question.</p><p>In the SDM formulation of a query, there are often phrase nodes (e.g., OrderedWindows) and span nodes (the UnorderedWindows). Especially in the presence of the OrderedWindows (there are many good tricks to compute phrases, such as next-word indices <ref type="bibr" coords="4,306.99,202.18,13.50,7.86" target="#b15">[16]</ref>), it is unlikely that a first-pass retrieval model is distinguishing many documents based on term occurrence distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">BM25 instead of Query Likelihood</head><p>The final "trick" we consider is that of a BM25-based SDM. While both models are state-of-the-art unigram retrieval models, BM25 has some nice properties: it is purely additive, no expensive logarithm computation is done, and its minimum score is bounded to zero. This means that BM25 often has better performance when used with early termination algorithms such as MaxScore <ref type="bibr" coords="4,409.05,287.26,14.34,7.86" target="#b14">[15]</ref> and WAND <ref type="bibr" coords="4,476.74,287.26,9.73,7.86" target="#b0">[1,</ref><ref type="bibr" coords="4,489.55,287.26,10.75,7.86" target="#b13">14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">TREC Core Runs Submitted</head><p>For these runs our BM25 parameters were the Galago default, our Dirichlet Âµ was set to be the average document length, and our SDM parameters were set to the commonly-chosen defaults of (Î»u = 0.8, Î» odw = 0.15, Î»uww = 0.05).</p><p>Since we verified offline that our minimum-based statistics estimation ( Â§3.3.1) makes no discernible impact on other collections, we used it for all of our dependency models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">TREC Core Results Discussion</head><p>We proposed to explore features where we did not expect much change in effectiveness for a large change in efficiency. Because there were no queries available on this dataset, we were unable to tune our query likelihood and BM25 parameters. This means that our best hypothesis between differences between runs is still that our BM25 default parameters are not as good as our QL parameters. We look forward to the release of the track-collected judgments in order to investigate this direction further under a cross-fold validation setup. We performed significance testing to determine whether the differences observed in mean average precision (mAP) were different within queries. We find that no distinction can be claimed even though there are differences at (Â±0.005). This suggests that on this dataset, with this power, with default parameters on each model, our "bag of tricks" for making SDM faster observes some differences, but with fairly high odds, (30%-40%) it is actually due just to random chance. We plan to investigate parameter tuning differences and multiple datasets in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TREC News BG Linking</head><p>For the TREC News Background Linking task, we re-used our indices built for our TREC Core submission. The procedure for creating the indexes is described in Section 3.1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,116.22,450.26,398.87,7.86;6,116.22,461.22,398.87,7.86;6,116.22,472.18,223.23,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,376.20,450.26,138.90,7.86;6,116.22,461.22,103.88,7.86">Efficient query evaluation using a two-level retrieval process</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Herscovici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soffer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,242.51,461.22,272.58,7.86;6,116.22,472.18,111.11,7.86">Proceedings of the twelfth international conference on Information and knowledge management</title>
		<meeting>the twelfth international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,116.22,485.95,398.87,7.86;6,116.22,496.91,371.50,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,226.59,485.95,207.99,7.86">Efficiency optimizations for interpolating subqueries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Cartright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,456.74,485.95,58.35,7.86;6,116.22,496.91,286.69,7.86">Proceedings of the 20th ACM Conference on Information and Knowledge Management</title>
		<meeting>the 20th ACM Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,116.22,510.68,398.87,7.86;6,116.22,521.64,238.42,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,194.56,510.68,320.53,7.86;6,116.22,521.64,71.82,7.86">On the equivalence of generative and discriminative formulations of the sequential dependence model</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Foley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00152</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,116.22,535.42,398.87,7.86;6,116.22,546.37,169.26,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,168.15,535.42,272.25,7.86">Indexing Proximity-based Dependencies for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts Amherst</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,116.22,560.15,398.87,7.86;6,116.22,571.11,400.66,7.86;6,116.22,582.07,104.18,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,216.95,560.15,228.95,7.86">A comparison of retrieval models using term dependencies</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,467.97,560.15,47.12,7.86;6,116.22,571.11,395.82,7.86">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,116.22,595.84,398.87,7.86;6,116.22,606.80,85.96,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,224.25,595.84,182.08,7.86">Window extraction for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note>IR IR-976</note>
</biblStruct>

<biblStruct coords="6,116.22,620.57,398.87,7.86;6,116.22,631.53,400.66,7.86;6,115.76,642.49,88.31,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,230.19,620.57,135.00,7.86">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,387.97,620.57,127.12,7.86;6,116.22,631.53,380.43,7.86">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,116.22,656.27,398.87,7.86;6,116.22,667.22,398.87,7.86;6,116.22,678.18,321.26,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,457.35,656.27,57.74,7.86;6,116.22,667.22,174.12,7.86">Characterizing question facets for complex answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,311.98,667.22,203.11,7.86;6,116.22,678.18,200.91,7.86">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1205" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,116.22,691.96,398.87,7.86;6,116.22,702.92,398.87,7.86;6,116.22,713.88,142.88,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,222.49,691.96,211.44,7.86">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,456.37,691.96,58.72,7.86;6,116.22,702.92,398.87,7.86;6,116.22,713.88,32.07,7.86">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,75.84,398.87,7.86;7,116.22,86.80,400.65,7.86;7,115.99,97.76,70.14,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,368.26,75.84,146.83,7.86;7,116.22,86.80,154.78,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,293.20,86.80,203.61,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,112.70,398.87,7.86;7,116.22,123.66,400.66,7.86;7,115.76,134.62,399.33,7.86;7,116.22,145.58,171.86,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,253.96,112.70,261.13,7.86;7,116.22,123.66,75.66,7.86">Learning to match using local and distributed representations of text for web search</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,214.01,123.66,281.85,7.86">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web<address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,160.52,400.15,7.86;7,116.22,171.48,400.66,7.86;7,115.99,182.44,225.15,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,328.31,160.52,168.97,7.86">Benchmark for complex answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,116.22,171.48,380.62,7.86">Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval</title>
		<meeting>the ACM SIGIR International Conference on Theory of Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,197.38,398.87,7.86;7,116.22,208.34,398.87,7.86;7,116.22,219.30,289.69,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,430.17,197.38,84.93,7.86;7,116.22,208.34,191.16,7.86">Semantic documents relatedness using concept graph representation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Mass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sheinwald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,330.31,208.34,184.78,7.86;7,116.22,219.30,178.02,7.86">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Ninth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,234.24,398.87,7.86;7,115.88,245.20,293.40,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,277.96,234.24,116.58,7.86">Exploring the magic of wand</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Petri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,417.87,234.24,97.22,7.86;7,115.88,245.20,190.44,7.86">Proceedings of the 18th Australasian Document Computing Symposium</title>
		<meeting>the 18th Australasian Document Computing Symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,260.15,398.87,7.86;7,116.22,271.08,143.73,7.89" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,208.44,260.15,192.96,7.86">Query evaluation: strategies and optimizations</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Flood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,408.98,260.15,106.11,7.86;7,116.22,271.11,51.71,7.86">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="831" to="850" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,286.05,400.66,7.86;7,116.22,297.01,273.81,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,278.86,286.05,233.92,7.86">What&apos;s next? index structures for efficient phrase querying</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,131.33,297.01,136.61,7.86">Australasian Database Conference</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,116.22,311.95,398.87,7.86;7,116.22,322.91,398.87,7.86;7,116.22,333.87,280.86,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,266.07,311.95,249.02,7.86;7,116.22,322.91,72.34,7.86">Fielded sequential dependence model for ad-hoc entity retrieval in the web of data</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhiltsov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kotov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Nikolaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,210.86,322.91,304.23,7.86;7,116.22,333.87,169.73,7.86">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
