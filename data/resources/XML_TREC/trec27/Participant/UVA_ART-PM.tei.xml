<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,54.82,77.96,502.35,14.33;1,83.13,97.89,445.75,14.33">Team UVA_ART at TREC 2018 Precision Medicine Track: Graph-based Concept Expansion and NLP for Document Relevance Boosting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.74,133.13,59.50,9.50"><forename type="first">Sean</forename><surname>Mullane</surname></persName>
						</author>
						<author>
							<persName coords="1,264.98,133.13,63.00,9.50"><forename type="first">Kasi</forename><surname>Vegesana</surname></persName>
						</author>
						<author>
							<persName coords="1,336.69,133.13,73.84,9.50"><forename type="first">Valentina</forename><surname>Baljak</surname></persName>
						</author>
						<title level="a" type="main" coord="1,54.82,77.96,502.35,14.33;1,83.13,97.89,445.75,14.33">Team UVA_ART at TREC 2018 Precision Medicine Track: Graph-based Concept Expansion and NLP for Document Relevance Boosting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">124D74873D474F56A423C56799365168</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the UVA_ART* team entries in the TREC 2018 workshop series Precision Medicine Track. We submitted 5 runs for the Scientific Abstracts task. Our approach used an exclusivity-based relatedness measure defined on the UMLS Metathesaurus ontologies to add context to our queries. We combined this with natural language processing using cTAKES for concept annotation to effect a graph-based query expansion on an enriched document corpus. We used Elasticsearch as our ranking and query engine with different query templates for each run. Our efforts demonstrate that the existing medical ontologies can be leveraged to achieve moderate results with little to no other clinical input.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Successfully treating cancer is made particularly difficult because of its high mutation rate and the many forms it can take. A treatment that is effective against one cancer variant may fail against another, even among cancers within the same patient. Thus it is paramount for a physician to choose the correct treatment for each patient <ref type="bibr" coords="1,193.71,370.45,10.58,8.64" target="#b0">[1]</ref>.</p><p>At the same time, since there are a multitude of research papers and clinical trials that each may be relevant to the treatment of a given cancer, it is difficult for a physician to be aware of newer and potentially more effective treatments in each case. The TREC 2018 Precision Medicine track aims to encourage research into precision medicine, oncology in particular, to provide better solutions to physicians and researchers.</p><p>The TREC 2018 PM track is a continuation of the 2017 PM track with some modifications. This track is split into two components: the Scientific Abstracts task and the Clinical Trials task.</p><p>• Scientific Abstracts: Participants ranked and submitted articles from a corpus of bio-medical article abstracts, largely from MEDLINE/PubMed. The documents were ranked by relevance for the treatment, prevention, and prognosis of the disease given specific genetic and demographic information about the patient. • Clinical Trials: Participants ranked and submitted clinical trials from a set of clinical trials listed on Clini-calTrials.gov. The trials were ranked by relevance and eligibility for the patient given their specific genetic and demographic information. We chose to focus on the Scientific Abstracts task, for which we submitted 5 runs. This task is the most directly *This work was supported by the University of Virginia Health System 1 All authors are with the Data Science group of the Analytics and Reporting Team at the UVA Health System, University of Virginia, Stacey Hall, Charlottesville, VA SPM9R@virginia.edu, KBV7C@virginia.edu, VB8N@virginia.edu relevant to potential clinical care at our institution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SYSTEM OVERVIEW</head><p>We worked under the usual time constraints, and wanted to utilize readily available tools for this task, so we chose to use several tools already in use at the UVA Health System: Apache cTAKES 4.0.0 and Elasticsearch 6.2.1. Apache cTAKES <ref type="bibr" coords="1,384.76,250.38,11.62,8.64" target="#b1">[2]</ref> is a natural language processing system designed for extraction of information from electronic medical record clinical free-text. Elasticsearch is an open-source document search and analytics engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Natural Language Parsing</head><p>We used a basic cTAKES dictionary look-up annotation pipeline to annotate the article abstracts and titles with identified concepts from the Unified Medical Language System (UMLS) Metathesaurus, a set of medical ontologies comprised of medically-relevant terms and relationships among them. The UMLS was provided by the National Library of Medicine <ref type="bibr" coords="1,354.32,393.18,10.58,8.64" target="#b2">[3]</ref>. This processing served two purposes:</p><p>1) Reduce noise and variation within terms by mapping multiple variations of a single concept to the single concept unique identifier (CUI). 2) Enable direct use of CUIs from query expansion tool to search no need to map CUIs back to natural language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Query Expansion</head><p>The small amount of information available for each topic and the large number of articles that can be returned by a query make it difficult to distinguish among the highestranked articles. To better distinguish between more and less relevant articles, it can be useful to use query expansion to add terms to the query. Adding appropriate terms to the query can help surface more relevant papers over less relevant papers.</p><p>We used a largely hands-off approach to expand our queries. Our primary approach used a concept graph-based relatedness metric to find the most closely-related concepts to those associated with each topic. We also included a handful of terms that proved useful to distinguish queries in a similar approach to ours in the TREC 2017 PM task <ref type="bibr" coords="1,501.76,645.94,10.58,8.64" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Elasticsearch Query Boosting</head><p>We used the Elasticsearch relevance ranking engine to score the articles in our corpus. All 5 runs used the default relevance scoring algorithm. Inspired by the approach in <ref type="bibr" coords="1,543.89,705.05,10.58,8.64" target="#b3">[4]</ref>, we chose to create a set of templates for our 5 submissions, which included a variety of required terms and optional </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Raw Data Preprocessing</head><p>For our first step we wrote a Python script using the base Python xml package to parse the XML dataset. We extracted the most common elements of each document and wrote the resulting data into a database table in MS SQL Server 2016. We chose to use fields that were most frequently available for our analysis: PMID, Title, Abstract, and Journal. While other data e.g. MeSH tags were available, we chose to use only textual data for simplicity and because we already have a text-processing infrastructure available to us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Article Pre-Filtering</head><p>Since PubMed includes many documents which are not relevant at all to cancer treatment, and to reduce the time required to annotate the documents, we filtered the corpus down to 2.7 million abstracts out of 15 million in our original data set. This count of articles was prohibitively large for any sort of meaningful processing.</p><p>To filter down the articles we used the tree-like nature of the ISA relation in the SNOMEDCT-US ontology to expand the concept for cancer (C0006826) to all of its descendants. We extracted the preferred natural text label of each concept, keeping 200 concepts that described types of cancer. Using an exact text search we kept in the data set all articles whose abstracts included at least 1 of these phrases or which was published in a journal composed of at least 10% of such articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Natural Language Processing</head><p>In order to include in our scope the search terms most relevant to the task, we created a custom dictionary using the cTAKES dictionary creator tool. We chose to use the NCI, RxNorm and SNOMED-CT US ontologies from the 2016 AB UMLS Metathesaurus as the basis of this dictionary and of the concept graph, selecting identified types (TUI) relevant to diseases and symptoms, cancer types, genes, demographics, medications and several other categories.</p><p>For the cTAKES dictionary look-up annotation, we used the fast dictionary look-up annotation pipeline. For this pipeline, cTAKES creates a set of phrase variants for each concept in the dictionary. Then for each word token and the tokens forming its surrounding context, phrases matching the set of tokens are returned. We chose the "overlap" look-up annotator which allows for a limited number of tokens to be skipped to capture more phrase variants as matches. The fast look-up annotator was found to perform similarly to more complex methods of dictionary look-up <ref type="bibr" coords="2,478.25,369.57,10.58,8.64" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Query Expansion</head><p>There have been several approaches to query expansion in the TREC 2017 precision medicine track which performed well <ref type="bibr" coords="2,333.73,428.50,11.62,8.64" target="#b7">[8]</ref>  <ref type="bibr" coords="2,348.73,428.50,10.58,8.64" target="#b8">[9]</ref>. We therefore chose to use query expansion but chose a different method to achieve this.</p><p>By using cTAKES to annotate the likely subset of articles and the topics themselves with identified concepts from the UMLS, we were able to directly make use of the concepts and their defined relationships in the UMLS ontologies to create a query expansion engine using graph analysis.</p><p>Our goal here was to add concepts that are not only related to the query concepts but nearly exclusively so. By using an exclusivity-based relatedness metric <ref type="bibr" coords="2,495.39,536.31,11.62,8.64" target="#b6">[7]</ref> we aimed to minimize the generality of the resulting expanded query. For example, expanding the Melanoma concept to the Cancer concept (C0006826) would return many results for other types of cancer. Expanding Melanoma to specific closelyrelated concepts, e.g. particular genes or cancer variants, instead expands the query to find articles that are still highly relevant to Melanoma in particular, so other more general articles that are not specific to Melanoma should be ranked lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. UMLS Ontologies</head><p>We used the two default ontologies used by cTAKES (SNOMED-CT US and RxNorm) as well as NCI. These are part of the Metathesaurus:</p><p>The UMLS includes the Metathesaurus, the Semantic Network, and the SPECIALIST Lexicon and Lexical Tools. The Metathesaurus is the biggest component of the UMLS. It is a large biomedical thesaurus that is organized by concept, or meaning, and it links similar names for the same concept from nearly 200 different vocabularies. The Metathesaurus also identifies useful relationships between concepts and preserves the meanings, concept names, and relationships from each vocabulary. [6] SNOMED-CT US and RxNorm are comprehensive repositories of general medical information and pharmaceuticals, respectively. The NCI ontology represents information from the National Cancer Institute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Relatedness Metric</head><p>We adapted the relatedness metric defined in <ref type="bibr" coords="3,263.92,239.59,10.58,8.64" target="#b6">[7]</ref>. The UMLS by default has the necessary requirements for this: a set of concepts with relationships defined between them with types defined on the relationships. A further requirement, symmetry in the relationships, is not present by default. To make use of this it was necessary to alter pairs of relationships where a natural inverse exists (e.g. is_part_of and has_part) to a single relationship type. In other cases where a relationship is not paired with a natural inverse we pruned the relationships. We used MS SQL Server 2016 to preprocess the data and the NetworkX v1.11 library in Python 3.6.6 to create and traverse the graph. Our graph had 451,021 nodes with 3,134,917 edges and 162 relationship types. There were 632,634 nodes, 8,804,418 relationships and 397 relationship types in the 3 ontologies we used from the 2016AB UMLS Metathesaurus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Relatedness Algorithm</head><p>Steps 1, 2, and 3 are quoted from the definition in <ref type="bibr" coords="3,274.99,453.46,10.79,8.64" target="#b6">[7]</ref>: Definition Given an edge e of type t between two adjacent nodes x and y, directed from x to y, we define the exclusivity of edge e as the probability that, if we randomly select an edge e out of the set of all edges of type t that exit node x and all edges of type t entering node y, that edge e is edge e. Formally,</p><formula xml:id="formula_0" coords="3,78.02,550.38,220.78,25.01">exclusivity(x τ → y) = 1 | τ x → * | + | * τ → y| -1<label>(1)</label></formula><p>where |x τ → * | denotes the number of relations of type τ ∈ T that exit node x, and | * τ → y| denotes the number of relations of type τ ∈ T that enter node y.</p><p>Given a path through G,</p><formula xml:id="formula_1" coords="3,170.63,619.60,73.06,13.26">P = n 1 τ 1 → n 2 τ 2</formula><p>→, ..., n K , with τ i ∈ T ∓ its weight can be computed by Formula 2.</p><formula xml:id="formula_2" coords="3,82.61,660.61,216.19,26.44">weight(P ) = 1 i 1/exclusivity(n i τ → n i+1 )<label>(2)</label></formula><p>Then, given a node x and the set y i ∈ N of nodes connected to x by paths of length k or less, we compute their relatedness as the sum of the path weights of all paths of length k or less between x and y. In order to give preference to shorter paths, we factor in a constant length decay factor, a.</p><formula xml:id="formula_3" coords="3,341.87,98.83,216.13,26.52">rel (k) Excl (x, y) = Pi∈P (k) x,y α length(Pi) weight(P i )<label>(3)</label></formula><p>Finally we keep the top m nodes y i ∈ N defined for a constant c by:</p><formula xml:id="formula_4" coords="3,385.66,166.28,172.34,14.30">{y i | rel (k) Excl (x, y i ) &gt; c}<label>(4)</label></formula><p>We chose α = 0.5 and c ∈ [0.1, 0.2], with c chosen separately for each data type (Diagnosis, Gene) to return 5-10 CUIs on average. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview of Runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSION</head><p>Overall all 5 runs had decidedly mixed results. All were below the mean of TREC participant median topic performance in infNDCG and R-Prec, but above mean median in the P10 measure. We saw a sharp drop-off in article count during 2014-2015 which could possibly explain some of the issues we faced with prediction accuracy. However we discovered this too late to correct it. We also observed that the journals with the highest number of articles pre-and-post filtering were significantly different. This was to be expected given that we selected specifically for cancer-related articles. The UVAEXPBSTEXT run performed best of the 5 runs. The boosting of results including CUIs that refer to treatment and clinical trial concepts and that refer to treatment and clinical trial concepts caused an improvement in infNDCG and particularly P10 precision over the more basic UVAEXP-BOOST. We note that the requirement that the Gene CUI match caused an improvement over the UVAEXPBSTSHD run, which was similar except for Gene being optional.</p><p>Interestingly the addition of extra negation terms in the UVAEXPBSTNEG run did not improve precision. Based on results from other teams in TREC 2017 PM, we believe that tuning the boosting terms with clinical judgment of article relevance would provide a significant improvement.</p><p>The moderate overall performance of this method demonstrates that even an untuned method that makes no direct use of clinical judgment can perform adequately on this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. FOLLOW-UP ANALYSIS</head><p>After the results had been published, we looked further into the reasons for the performance of our model. We were interested to determine the effect of several factors to the performance across the three main TREC metrics. New runs included the full set of 1000 documents per topic, instead of top 20 we submitted for the conference. Further, we decided not to add missing abstracts for 2014 and 2015 in order to isolate effects of changes to the model, and to compare results to the original runs.</p><p>We wanted to evaluate key aspects of our approach to compare the relative gain in performance from each: concept embedding of query terms, relatedness graph-based expansion of query terms, Elasticsearch custom query boosting, and extended general text terms and CUIs. To do this we ran a series of additional queries using different combinations of query elements with the best-performing query from the original submission for comparison.</p><p>1) must diseasegene should extracuis (UVAEXPB-STEXT): This run was our best performing run originally submitted to TREC and it included full abstract text, exact CUIs, and extended general CUIs as "should" field in Elasticsearch query.  In this run, text is not included at all, and instead uses exact CUIs, extended general CUIs as "should", and expanded CUIs for diagnosis and gene in a "should" clause.</p><p>Fig. <ref type="figure" coords="5,351.06,487.33,2.99,6.91">5</ref>. Updated UVAHS ART vs TREC median: infNDCG</p><p>Overall, new runs show improved results compared to the original submission in the metrics where additional documents are beneficial. P10 remains our strongest metric category, with 6 out 0f 10 runs beating the TREC median performance, as shown in Figure <ref type="figure" coords="5,451.82,571.99,3.74,8.64" target="#fig_4">4</ref>. We have seen the most significant improvement, with inclusion of all 1000 articles per topic, in infNDCG metric, with 2 runs beating the median, Figure <ref type="figure" coords="5,380.69,607.86,3.74,8.64">5</ref>. In R-prec metrics, we have seen some significant increase, Figure <ref type="figure" coords="5,423.96,619.81,3.74,8.64">6</ref>, with several runs coming close to the median, but none surpassing it. We believe that missing articles had the most significant impact on the performance under this metric, given the high probability that a number of relevant articles have been published in the time frame where we missed documents.</p><p>Using "must" vs "should" section in Elasticsearch query did not significantly affect results. cTakes CUI embbeding provided the highest precision gain, while relatedness helps long tail cumulative gain, but doesn't improve precision. Fig. <ref type="figure" coords="6,96.74,484.14,2.99,6.91">6</ref>. Updated UVAHS ART vs TREC median: R-prec Similarly, Elasticsearch boosting helps total cumulative gain, without significant increase of precision. However, pure embedding doesn't perform as well as a combined approach with inclusion of full abstract text. Also, at some point, additional expanded CUIs show a decline in gain, most likely due to widening the search scope to include less relevant articles.</p><p>Overall best performance across the metrics was achieved in a run named new should exactCUIs expCUIs extCUIs boost. This run uses the most complete query with inclusion of full text, extended general CUIs as "should", exact CUIs, expanded CUIs for diagnoses and gene in "extrashould" field, and Elasticsearch boosting. While some components of the approach affected performance in certain metrics more than others, the most complete combination of concept embedding of query terms, relatedness graph-based expansion of query terms, Elasticsearch custom query boosting, and expanded general text terms and CUIs, has proven to be the best performing overall.</p><p>We believe that with further refinement of CUIs and additional expert knowledge we can improve the performance of this approach. The relative simplicity of the system lends itself well to practical use in health care institutions, and for the wide variety of topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,132.84,411.89,87.13,6.91;2,57.67,54.00,237.45,345.14"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System Overview</figDesc><graphic coords="2,57.67,54.00,237.45,345.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,120.64,584.81,111.52,6.91;4,54.00,410.36,244.81,155.27"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. UVA_ART overall results</figDesc><graphic coords="4,54.00,410.36,244.81,155.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,385.77,188.71,99.66,6.91;4,313.20,54.00,244.79,121.97"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Article count by year</figDesc><graphic coords="4,313.20,54.00,244.79,121.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,323.16,585.11,234.84,9.03;4,337.44,597.45,49.13,8.64;4,323.16,609.02,234.84,9.03;4,337.44,621.36,220.56,8.64;4,337.44,633.32,46.11,8.64;4,323.16,644.88,234.84,9.03;4,337.44,657.23,146.64,8.64;4,323.16,668.79,234.84,9.03;4,337.44,681.14,220.56,8.64;4,337.44,693.09,195.67,8.64;4,323.16,704.66,234.84,9.03;4,337.44,717.00,220.56,8.64;4,337.44,728.96,80.30,8.64"><head>2 )</head><label>2</label><figDesc>new basic noCUIs: As an input, uses only natural text of abstracts. 3) new basic exactCUIs: Includes the text and exact CUIs, but does not utilize any type of query expansion or boosting 4) new basic extCUI: Includes text, and extended general CUIs in "should" query clause. 5) new must exactCUIs expCUIs extCUIs: This run includes previous terms and adds exact CUIs and expanded CUIs for diagnosis and gene as "must". 6) new must exactCUIs expCUIs extCUIs boost: In addition to previous run, this boosted exact CUIs for diagnosis and gene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,84.86,487.51,183.09,6.91;5,54.00,54.00,244.80,420.76"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. Updated UVAHS ART vs TREC median:: P10</figDesc><graphic coords="5,54.00,54.00,244.80,420.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,54.00,54.00,244.80,417.40"><head></head><label></label><figDesc></figDesc><graphic coords="6,54.00,54.00,244.80,417.40" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,327.47,165.97,230.53,6.91;6,327.47,174.94,41.82,6.91" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,391.08,165.97,166.92,6.91;6,327.47,174.94,16.92,6.91">Overview of the TREC 2017 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,183.90,230.53,6.91;6,327.47,192.87,230.53,6.91;6,327.47,201.84,230.53,6.91;6,327.47,210.80,230.53,6.91;6,327.47,219.77,186.42,6.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,327.47,201.84,230.53,6.91;6,327.47,210.80,227.41,6.91">Mayo Clinic Clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</title>
		<author>
			<persName coords=""><forename type="first">Guergana</forename><forename type="middle">;</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">;</forename><surname>Masanz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><forename type="middle">;</forename><surname>Ogren</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Jiaping; Sohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Sunghwan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karin</forename><surname>Kipper-Schuler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Chute</surname></persName>
		</author>
		<idno type="DOI">10.1136/jamia.2009.001560</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,327.47,219.77,23.87,6.91">JAMIA</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="507" to="513" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,228.74,230.53,6.91;6,327.47,237.70,248.10,6.91;6,327.47,246.67,83.13,6.91" xml:id="b2">
	<monogr>
		<ptr target="https://www.nlm.nih.gov/research/umls/licensedcontent/umlsarchives04.html" />
		<title level="m" coord="6,327.47,228.74,154.64,6.91">UMLS Release File Archives: 2004-2017AB</title>
		<imprint>
			<date type="published" when="2018-10">Oct-2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,255.64,230.53,6.91;6,327.47,264.60,184.24,6.91" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lpez-Garca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oleynik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Kas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schulz</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">12</biblScope>
		</imprint>
		<respStmt>
			<orgName>TREC 2017 Precision Medicine -Medical University of Graz</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,273.57,230.53,6.91;6,327.47,282.53,2.65,6.91;6,345.18,282.53,24.34,6.91;6,384.56,282.53,28.69,6.91;6,428.31,282.53,38.18,6.91;6,481.54,282.53,29.00,6.91;6,525.59,282.53,32.41,6.91;6,327.47,291.50,223.20,6.91;6,327.47,300.47,173.44,6.91" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,381.38,273.57,176.62,6.91;6,327.47,282.53,2.65,6.91;6,345.18,282.53,24.34,6.91;6,384.56,282.53,28.69,6.91;6,428.31,282.53,34.71,6.91">-Fast Dictionary Lookup -Apache cTAKES -Apache Software Foundation</title>
		<idno>cTAKES 4.0</idno>
		<ptr target="https://cwiki.apache.org/confluence/display/CTAKES/cTAKES+4.0+-+Fast+Dictionary+Lookup" />
		<imprint>
			<date type="published" when="2018-10">Oct-2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,309.43,230.53,6.91;6,327.47,319.15,221.97,5.61;6,327.47,327.37,83.13,6.91" xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Metathesaurus</surname></persName>
		</author>
		<ptr target="https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/" />
		<imprint>
			<date type="published" when="2018-10">Oct-2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,336.33,230.53,6.91;6,327.47,345.30,230.53,6.91;6,327.47,354.27,230.53,6.91;6,327.47,363.23,230.53,6.91;6,327.47,372.20,230.53,6.91;6,327.47,381.17,212.80,6.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,467.21,336.33,90.79,6.91;6,327.47,345.30,227.00,6.91">Path-Based Semantic Relatedness on Linked Data and Its Use to Word and Entity Disambiguation</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Hulpu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Prangnawarat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,336.22,354.27,106.12,6.91">The Semantic Web -ISWC 2015</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Corcho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Simperl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Strohmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Daquin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Srinivas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Groth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Dumontier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Heflin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Thirunarayan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Thirunarayan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Staab</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9366</biblScope>
			<biblScope unit="page">442457</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,390.13,230.53,6.91;6,327.47,399.10,147.29,6.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,507.31,390.13,50.69,6.91;6,327.47,399.10,126.37,6.91">UTD HLTRI at TREC 2017: Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Skinner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.47,408.06,230.53,6.91;6,327.47,417.03,171.73,6.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,327.47,408.06,230.53,6.91;6,327.47,417.03,168.31,6.91">Team UKNLP at TREC 2017 Precision Medicine Track: A Knowledge-Based IR System with Tuned Query-Time Boosting</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
