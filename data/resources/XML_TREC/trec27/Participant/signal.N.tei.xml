<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.13,83.74,252.24,15.10">Signal at TREC 2018 News Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,87.31,115.73,100.61,5.61;1,190.91,112.87,1.00,4.11"><forename type="first">Dwane</forename><surname>Van Der Sluis</surname></persName>
							<email>dwane.vandersluis@signal-ai.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University College London and Signal</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.44,115.73,74.34,5.61"><forename type="first">Dyaa</forename><surname>Albakour</surname></persName>
							<email>dyaa.albakour@signal-ai.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University College London and Signal</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,430.18,115.73,80.94,5.61"><forename type="first">Miguel</forename><surname>Martinez</surname></persName>
							<email>miguel.martinez@signal-ai.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University College London and Signal</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.13,83.74,252.24,15.10">Signal at TREC 2018 News Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EC57BAD6F2C833144C3B60E2AB9F75F2</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>is paper provides an overview of the experiments we carried out for the entity ranking task at the TREC 2018 News Track. In particular, we experimented with adapting the supervised salience component of Salient Entity Linking (SEL), a state-of-the-art uni ed framework for entity linking and salience ranking. In our adaptation, we assume perfect entity linking performance and rank the entities using the salience components of SEL. Furthermore, in this adaptation, we aim to enhance the e ciency of the supervised salience ranking, and also to introduce sentiment-based features for entity salience.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>is paper presents our participation in the entity ranking task of the TREC 2018 News Track. e task involves ranking the list of mentioned entities given a news article according to how 'useful' they are to the reader to understand the article. In other words, the task aims at separating important entities from non-important ones within an article.</p><p>Indeed, the entity ranking task relates closely to 'entity salience', how related the entity is to the central discourse topic. Detecting and measuring entity salience is important for semantic search <ref type="bibr" coords="1,282.64,406.81,9.29,4.21" target="#b2">[3]</ref>, knowledge extraction <ref type="bibr" coords="1,136.96,417.76,10.68,4.21" target="#b5">[6]</ref> and automatic summarisation <ref type="bibr" coords="1,263.16,417.76,9.52,4.21" target="#b0">[1]</ref>. Past approaches for measuring entity salience have included mining web query logs <ref type="bibr" coords="1,113.13,439.68,9.52,4.21" target="#b1">[2]</ref>, utilising grammatical features <ref type="bibr" coords="1,242.87,439.68,10.68,4.21" target="#b3">[4]</ref> and graph based analysis, such as an adaptation of PageRank <ref type="bibr" coords="1,243.87,450.64,9.52,4.21" target="#b4">[5]</ref>. Recently Trani et al. <ref type="bibr" coords="1,97.89,461.60,10.68,4.21" target="#b6">[7]</ref> introduced Salient Entity Liking (SEL), a uni ed algorithm for entity linking (automatic annotation of text with entities in a Knowledge Base -KB) and salience ranking. e paper describing SEL <ref type="bibr" coords="1,109.04,494.48,10.43,4.21" target="#b6">[7]</ref> is one of the few publications in this area with a public dataset, and as far as we are aware, is the state-of-the-art for entity salience ranking.</p><p>In our participation at the news track, we make the assumption that entity salience ranking would re ect directly the entity ranking that should be achieved in the entity ranking task. erefore, our participation evaluates entity salience ranking approaches that we develop by adapting the aforementioned SEL. SEL performs both entity linking and salience ranking using a uni ed supervised ranking algorithm. We adapt SEL to perform salience ranking while assuming a perfect entity linking performance. In other words, the linked entities are known in advance, and we use and adapt the * is work has been done in the scope of a Master thesis in collaboration with Signal. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). TREC'18, November 14-16, 2018, Gaithersburg, Md. USA. © 2018 Copyright held by the owner/author(s). 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 DOI: 10.1145/nnnnnnn.nnnnnnn salience component of SEL to rank these entities. In our adaptation, we focuses on two enhancements:</p><p>• develop a computationally e cient variant of SEL by reducing the number of expensive features required for the supervised ranking algorithm within SEL • explore whether sentiment can be used to determine salience.</p><p>In particular, we hypothesise that strong positive or negative sentiment expressed towards entities in a news article may indicate that it is salient or central to the main topic of the article. erefore, we devise a set of features based on analysis of sentiment expressed towards speci c entities in the article. We then use these features within the supervised salient ranking component of SEL Following this, we submi ed three di erent runs: one that reproduces SEL as closely as possible and two that re ect the enhancements explained above. e structure of this paper is as follows. We present the adaptation of SEL and our enhancements in Section 2. Our experimental setup is described in Section 3 before introducing our runs in Section 4. Section 5 discusses our results. Finally we summarise our conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ADAPTATION OF SEL</head><p>In this section, we give an overview of the SEL uni ed algorithm of entity linking and salience ranking and explain how we adapt it for the entity ranking task at the News Track.</p><p>In a nutshell, SEL works as follows. When performing entity linking, it generates a list of candidate entities from the reference KB (i.e. Wikipedia) and instead of making a binary decision on whether the entity is mentioned in the text, it assigns a salience score. A threshold on the salience score can be applied to perform entity linking. Also, the linked entities can be ranked by their salience score. Figure <ref type="figure" coords="1,400.98,523.82,4.25,4.21" target="#fig_1">1</ref> depicts the pipeline of SEL. e pipeline consists of the following components: e light feature extractor (Component B in Figure <ref type="figure" coords="1,536.28,615.47,2.97,4.21" target="#fig_1">1</ref>): for each candidate entity in C D , computationally cheap to calculate, 'light' features, are computed. ese include features representing position, frequency and topographical characteristics of the entity. <ref type="bibr" coords="1,334.08,670.26,9.51,4.21" target="#b2">(3)</ref> e binary classi er (Component C in Figure <ref type="figure" coords="1,519.55,670.26,3.05,4.21" target="#fig_1">1</ref>): trained on annotated documents, it receives the 'light' features as input and makes a decision to prune 'incorrect' candidate entities (not mentioned in the documents). It therefore e 'heavy' features aim to model the relatedness of each candidate entity to other candidate entities within that graph. In particular, the 'heavy' features, are calculated for each pruned candidate entity in C D , conceptually by computing the centrality of the candidate entity to multiple sub-graphs of the KB graph created from W D . <ref type="bibr" coords="2,69.92,474.27,9.51,4.21" target="#b4">(5)</ref> e regression model (Component E in Figure <ref type="figure" coords="2,256.12,474.27,3.00,4.21" target="#fig_1">1</ref>): trained on documents annotated with the salience levels of the mentioned, i.e. linked, entities. It receives the full set of 'light' and 'heavy' features for each pruned candidate entity ce in C D , and produces a salience score sal(ce ) for that entity. A threshold on the produced scores for pruned candidate entities can then be applied to produce the list of linked entities L D = {e 1 , e 2 , ..} (entity linking). Each entity in L D can then be ranked by its salience score sal(e) (saliency ranking)</p><p>In our adaptation of SEL, we focus on its salience-related components. We assume a perfect entity linking performance, i.e. the set of linked entities L D are known in advance and the task is to assign a salience score for each entity in L D . erefore, the spotting, candidate generator, and candidate pruning are not needed, leaving extraction (components B and D) and the regression model (component E).</p><p>In the following subsection, we introduce two enhancements of SEL that we experimented with in our submissions:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">E cient Salient Features</head><p>One of the limitations of SEL is the complexity of computing the heavy features. Computing some of these features, involves traversing huge sub-graphs of the Wikipedia graph which may consist of hundreds of thousands of nodes. As a result, it is not feasible to use SEL for salient entity ranking in a practical real-time se ing.</p><p>erefore, we developed an e cient variant of SEL. In particular, we conducted a feature analysis study, where we estimated the information gain of each light and heavy feature and its average running time. We then ranked the features by a function of their information gain and running time, favouring features with high information gain low running time. Following this, we selected top features from this ranking and use only those to train the regression model and predict salience scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Using Sentiment Analysis for Salience</head><p>News articles o en express opinions or views about the central topic of the article. erefore, we hypothesise that understanding the sentiment polarity around the entities mentioned in the document may indicate how salient they are to the topic of the article. To do that, we perform a dictionary-based sentiment analysis approach to devise additional features for each entity that aim to measure the sentiment polarity around it. In particular, applying a sliding window around the entity mention, we use a sentiment dictionary (in this case the AFINN 111 database) to assign a sentiment score for each word in the window. From this, we construct six di erent features to measure sentiment polarity as detailed in Table <ref type="table" coords="2,537.33,617.47,3.12,4.21" target="#tab_0">1</ref>. We use these features in addition to the original SEL features (light and heavy) to train the regression model and predict salience scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL SETUP</head><p>In this section, we detail the experimental setup for our submi ed runs. In particular, we rst focus on describing the datasets and resources required to train and to extract features for the adapted </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>To train the supervised ranking component of SEL (the regression model), we used the Dexter Entity Salience dataset 1 used originally to train the SEL model <ref type="bibr" coords="3,154.63,483.13,9.27,4.21" target="#b6">[7]</ref>. It consists of 365 Wikinews articles published between November 2004 and June 2014. Each article contains the linked entities to the Wikipedia KB, as it is authored by Wikinews users, who can specify the Wikipedia entities in the article. e number of linked entities in these articles vary between 10 and 25 entities. Multiple Annotators assigned the salience of each linked entity within each article. Ground truth salience levels are detailed in Table <ref type="table" coords="3,116.16,559.84,3.05,4.21" target="#tab_3">4</ref>. We also summarise the statistics of the dataset in Table <ref type="table" coords="3,85.38,570.80,3.07,4.21" target="#tab_1">2</ref>.</p><p>In the News Track, the Washington Post dataset is used to source the topics for the entity ranking task (the articles for which the entities need to be ranked. To give the reader an idea of the similarities and di erences between this dataset and the one we used for training our salience regression model, we summarise similar statistics in Table <ref type="table" coords="3,147.34,636.56,3.09,4.21" target="#tab_2">3</ref>. Both datasets consist of news articles, in English, with a similar mean number of entities per article (14.9 vs. 16.5). However there were di erences. Articles in the Dexter Entity Salience dataset (the training dataset) are far shorter in length than those in the Washington Post dataset (1,599 vs. 7,327 characters) 1 h ps://github.com/dexter/dexter-datasets/tree/master/entity-saliency </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Wikipedia Resources</head><p>Wikipedia is used as the KB reference of entities in the News Track. It is also the KB for entities in the Dexter training dataset. As in the original implementation of SEL, for the KB graph needed to calculate the light and heavy features, we use the Wikipedia link graph.</p><p>e Wikipedia link graph is a graph where vertices are Wikipedia entities, and edges are the hyperlinks between Wikipedia pages representing these entities. To create this graph and the data structures necessary to calculate the features, we used a Wikipedia dump from June 2018<ref type="foot" coords="3,375.05,495.38,3.38,3.41" target="#foot_0">2</ref> , and processed it using the packages provided by the Dexter developers. 3 4   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation Details</head><p>Each topic in the Entity Ranking task consists of a news article D from the Washington post and a list of mentioned entities in the article, where their Wikipedia identi ers (their names) are given. In other words, the set of linked entities L D in each article (see Section 2) is given. However, the features used to train the supervised salience ranking also require knowledge of the spots S D of these entities, i.e. where they are mentioned in the text (see Section 2). For this reason, we developed a 'so -match mapper' to map the entities to their spots. e so -match mapper takes the name of each entity and tries to nd an exact match in the text (the title and the content of the article). If no matches are found, Table <ref type="table" coords="4,142.28,84.49,3.45,7.94">5</ref>: Results of our runs Run nDCG@5 P@5 signal-ucl-sel 0.6071 0.6480 signal-ucl-e 0.6084 0.6440 signal-ucl-slst 0.5772 0.6200 median 0.6153 0.6680 the exact match is relaxed by removing the last word of the entity name. is covers most of the entities, but for those not matched we assign a single random spot from the text of the document. Finally, to implement the regressor component of SEL, we use the sklearn implementation of the Gradient Boosting Regression Tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RUNS</head><p>We submi ed three runs to the Entity Ranking task of the TREC news track. Each run is based on our described adaptation of SEL, but each has di erent sets of features:</p><p>• signal-ucl-sel: we use the majority of the light and heavy features implemented by the original SEL algorithm <ref type="bibr" coords="4,282.73,321.69,9.52,4.21" target="#b6">[7]</ref>. e full set of features used are the 'light' features listed in Table <ref type="table" coords="4,116.00,343.60,4.17,4.21">6</ref> and the 'heavy' features listed in Table <ref type="table" coords="4,266.28,343.60,3.07,4.21">7</ref>.</p><p>• signal-ucl-e : this run uses the enhancement of SEL for e ciency described in Section 2.1, where we selected a subset of the light and heavy features (26 from total 59) to improve e ciency while trying to maintain e ectiveness. • signal-ucl-slst: this run uses the enhancement of SEL described in Section 2.2, where we use sentiment-based features for salience, in addition to all the light and heavy features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We report results of our runs in the entity ranking task in Table <ref type="table" coords="4,289.27,468.58,3.08,4.21">5</ref>.</p><p>We observe that the signal-ucl-e run is of similar e ectiveness to signal-ucl-sel. ey both obtain very similar P@5 and nDCG@5, even though signal-ucl-e uses far less features (26 vs 59). is validates our approach for e cient salience ranking -removing the features with low information gain and high complexity did not a ect the e ectiveness. e sentiment-based signal-ucl-slst run has lower P@5 and nDCG@5 than the two other runs. Adding the sentiment features was not e ective as we originally hypothesised.</p><p>Overall, all our runs are on par with the median performance of all submi ed runs to the track in terms of P@5 and nDCG@5. Indeed, document by document performance of the run signal-ucl-sel can be seen in Figure <ref type="figure" coords="4,132.66,600.08,3.04,4.21" target="#fig_2">2</ref>, in comparison to the median performance. It shows that this run is either on par or outperforms the median performance for about 80% of the topics (news articles), yet performs poorly for some topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>For the entity ranking task at the TREC News track, we experimented with a supervised approach that measures entity salience to rank entities. To this end, we adapted the state-of-the-art SEL algorithm. Overall our adaptation is promising, as all our runs perform on par with the median of all submi ed runs. Most notably, our enhancement for e ciency shows that the computational complexity of the SEL approach can be reduced with li le or no performance loss. However, adding extra features capturing sentiment expressed towards entities degraded performance. We aim to investigate further by looking at more e ective ways to measure sentiment as well as training the salience regressor model on di erent datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,334.08,549.71,225.64,4.21;1,348.57,559.04,209.63,7.91;1,348.57,570.00,211.14,9.08;1,348.57,580.96,209.63,9.08;1,348.57,593.55,211.01,4.21;1,357.97,602.88,195.10,9.08;1,334.08,615.47,9.51,4.21"><head></head><label></label><figDesc>and candidate generator (Component A in Figure 1): Given a document D, this component identi es small portions of text, known as spots S D in the document D. For each spot in S D , the component generates a set of candidate entities that may be referred to by the spot. e union of all candidate entities are denoted with C D . (2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,186.38,290.96,239.25,7.94;2,53.80,82.69,504.44,194.52"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Flow diagram of SEL as implemented by Trani [7]</figDesc><graphic coords="2,53.80,82.69,504.44,194.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,317.96,285.60,240.24,7.94;4,317.96,296.56,209.54,7.94;4,317.96,82.69,252.21,189.15"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Distribution of the di erences between nDCG@5 for the signal-ucl-sel run and the median nDCG@5.</figDesc><graphic coords="4,317.96,82.69,252.21,189.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,58.78,84.49,247.44,84.01"><head>Table 1 :</head><label>1</label><figDesc>Sentiment-based Features for SalienceTitle normalised summed sentiment of the 20 surrounding words Title proportion of words that have negative sentiment in the title Title proportion of words that have positive sentiment in the title Body normalised summed sentiment of the 20 surrounding words Body proportion of words that have negative sentiment in the body Body proportion of words that have positive sentiment in the body</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,53.50,190.07,240.79,239.09"><head>Table 2 :</head><label>2</label><figDesc>Dexter dataset statistics. * HS Entities (Highly Salient) refer to entities with a salience score ≥ 2.0</figDesc><table coords="3,53.80,226.03,240.25,203.13"><row><cell>Number of Articles</cell><cell>365</cell></row><row><cell>Number of Entities</cell><cell>5,460</cell></row><row><cell>Min Entities per Article</cell><cell>10</cell></row><row><cell>Max Entities per Article</cell><cell>32</cell></row><row><cell>Mean Entities per Article</cell><cell>14.9</cell></row><row><cell>Min Article Length</cell><cell>594</cell></row><row><cell>Max Article Length</cell><cell>2472</cell></row><row><cell>Mean Article Length</cell><cell>1599</cell></row><row><cell>Min HS Entities per Article *</cell><cell>0</cell></row><row><cell>Max HS Entities per Article *</cell><cell>10</cell></row><row><cell cols="2">Mean HS Entities per Article * 4.1</cell></row><row><cell>Min Salience</cell><cell>0.25</cell></row><row><cell>Max Salience</cell><cell>3.0</cell></row><row><cell>Mean Salience</cell><cell>1.56</cell></row><row><cell>Salience StdDev</cell><cell>0.56</cell></row><row><cell cols="2">SEL. en, we describe some of the important implementation</cell></row><row><cell>details.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,350.22,84.49,175.42,94.97"><head>Table 3 :</head><label>3</label><figDesc>Washington Post Dataset statistics.</figDesc><table coords="3,375.59,109.50,124.98,69.96"><row><cell>Number of Articles</cell><cell>50</cell></row><row><cell>Min Entities per Article</cell><cell>3</cell></row><row><cell>Max Entities per Article</cell><cell>52</cell></row><row><cell cols="2">Mean Entities per Article 16.5</cell></row><row><cell>Min Article Length</cell><cell>1,855</cell></row><row><cell>Max Article Length</cell><cell>56,925</cell></row><row><cell>Mean Article Length</cell><cell>7,329</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,317.66,197.70,246.73,173.27"><head>Table 4 :</head><label>4</label><figDesc>Salience levels and descriptions in the Dexter Entity Salience Dataset<ref type="bibr" coords="3,385.97,208.66,11.73,7.94" target="#b6">[7]</ref> </figDesc><table coords="3,322.94,233.67,241.45,137.31"><row><cell>Name</cell><cell>Description</cell></row><row><cell></cell><cell>e entity describes the main topics</cell></row><row><cell>3 Top Relevant</cell><cell></cell></row><row><cell></cell><cell>or the leading characters of a document</cell></row><row><cell></cell><cell>Satellite entities that are not necessary</cell></row><row><cell>2 Highly Relevant</cell><cell>for understanding the document, but</cell></row><row><cell></cell><cell>provide important facets</cell></row><row><cell></cell><cell>Entities that provide background</cell></row><row><cell></cell><cell>information about the content</cell></row><row><cell>1 Partially Relevant</cell><cell>of the document, but disregarding</cell></row><row><cell></cell><cell>them would not a ect negatively the</cell></row><row><cell></cell><cell>comprehension of the document</cell></row><row><cell></cell><cell>Any other entity that is not relevant</cell></row><row><cell>0 Not Relevant</cell><cell></cell></row><row><cell></cell><cell>or not mentioned in the article</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,321.00,670.79,199.54,3.27;3,317.96,679.03,114.11,3.27"><p>h p:// p.acc.umu.se/mirror/wikimedia.org/dumps/enwiki/20180601/ enwiki-20180601-pages-articles.xml.bz2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,321.00,687.43,238.33,3.27;3,317.96,695.66,9.04,3.27"><p>h ps://github.com/dexter/elianto/blob/master/how-to-generate-a-wikinews-dataset. md</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,320.88,704.07,141.79,3.27"><p>h ps://github.com/diegoceccarelli/json-wikipedia</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="4,334.39,425.01,224.99,3.27;4,334.39,432.96,173.36,3.28" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,453.82,425.01,105.56,3.27;4,334.39,432.98,42.62,3.27">Modeling local coherence: An entitybased approach</title>
		<author>
			<persName coords=""><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,382.62,432.96,72.97,3.28">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,334.39,440.95,223.81,3.27;4,334.39,448.90,223.82,3.28;4,334.39,456.87,223.81,3.28;4,334.39,464.84,224.89,3.28;4,334.39,472.83,104.91,3.27" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,374.28,448.92,132.81,3.27">Ranking Entities Using Web Search ery Logs</title>
		<author>
			<persName coords=""><forename type="first">Bodo</forename><surname>Billerbeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gianluca</forename><surname>Demartini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudiu</forename><forename type="middle">S</forename><surname>Firan</surname></persName>
		</author>
		<ptr target="//dl.acm.org/citation.cfm?id=1887759.1887797" />
	</analytic>
	<monogr>
		<title level="m" coord="4,493.63,440.95,64.57,3.27;4,334.39,448.92,18.64,3.27;4,519.31,448.90,38.89,3.28;4,334.39,456.87,223.81,3.28;4,334.39,464.84,52.69,3.28">Proceedings of the 14th European Conference on Research and Advanced Technology for Digital Libraries (ECDL&apos;10)</title>
		<meeting>the 14th European Conference on Research and Advanced Technology for Digital Libraries (ECDL&apos;10)<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="273" to="281" />
		</imprint>
	</monogr>
	<note>Tereza Iofciu, and Ralf Krestel</note>
</biblStruct>

<biblStruct coords="4,334.39,480.80,224.89,3.27;4,334.39,488.75,223.81,3.28;4,334.39,496.72,224.58,3.28;4,334.39,504.71,14.51,3.27" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,351.54,488.77,112.99,3.27">Identifying salient entities in web pages</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tae</forename><surname>Yano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinying</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johnson</forename><surname>Apacible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,476.89,488.75,81.31,3.28;4,334.39,496.72,184.36,3.28">Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</title>
		<meeting>the 22nd ACM international conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2375" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,334.39,512.68,223.81,3.27;4,334.39,520.63,223.81,3.28;4,334.39,528.60,61.15,3.28" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,406.35,512.68,151.85,3.27;4,334.39,520.65,57.10,3.27">A rethink of the relationship between salience and anaphora resolution</title>
		<author>
			<persName coords=""><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,403.75,520.63,154.45,3.28;4,334.39,528.60,58.21,3.28">Proceedings of the 6th discourse anaphora and anaphor resolution colloquium</title>
		<meeting>the 6th discourse anaphora and anaphor resolution colloquium</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,334.39,536.57,223.81,3.28;4,334.39,544.54,223.82,3.28;4,334.39,552.53,23.23,3.27" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<title level="m" coord="4,334.39,544.54,143.20,3.28">PageRank citation ranking: Bringing order to the web</title>
		<meeting><address><addrLine>Stanford InfoLab</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="4,334.39,560.50,224.99,3.27;4,334.39,568.45,223.81,3.28;4,334.39,576.42,167.25,3.28" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,510.09,560.50,49.28,3.27;4,334.39,568.47,85.07,3.27">Knowledge questions from knowledge graphs</title>
		<author>
			<persName coords=""><forename type="first">Dominic</forename><surname>Seyler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,432.90,568.45,125.30,3.28;4,334.39,576.42,126.33,3.28">Proceedings of the ACM SIGIR International Conference on eory of Information Retrieval</title>
		<meeting>the ACM SIGIR International Conference on eory of Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,334.39,584.41,224.99,3.27;4,334.39,592.38,224.99,3.27;4,334.39,599.23,224.27,5.58;4,334.39,608.32,216.54,3.27" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,429.27,592.38,130.11,3.27;4,334.39,600.35,7.86,3.27">SEL: A uni ed algorithm for salient entity linking</title>
		<author>
			<persName coords=""><forename type="first">Salvatore</forename><surname>Trani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudio</forename><surname>Lucchese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Ra Aele Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diego</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Salvatore</forename><surname>Ceccarelli</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Orlando</surname></persName>
		</author>
		<idno type="DOI">10.1111/coin.12147</idno>
		<ptr target="p://dx.doi.org/10.1111/coin.12147arXiv:hps://onlinelibrary.wiley.com/doi/pdf/10.1111/coin.12147" />
	</analytic>
	<monogr>
		<title level="j" coord="4,347.38,600.33,73.15,3.28">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2" to="29" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
