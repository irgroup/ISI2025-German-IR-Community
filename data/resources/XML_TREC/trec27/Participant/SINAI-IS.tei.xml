<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,97.47,84.23,417.06,15.44">SINAI at TREC 2018: Experiments in Incident Streams</title>
				<funder ref="#_gKeAjkx">
					<orgName type="full">Ministerio de Educación Cultura y Deporte</orgName>
				</funder>
				<funder ref="#_K73aQEH">
					<orgName type="full">Fondo Europeo de Desarrollo Regional (FEDER)</orgName>
				</funder>
				<funder>
					<orgName type="full">Spanish Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,103.94,114.29,158.88,10.59"><forename type="first">Miguel</forename><surname>Ángel García-Cumbreras</surname></persName>
						</author>
						<author>
							<persName coords="1,360.37,114.29,138.49,10.59"><forename type="first">Manuel</forename><surname>Carlos Díaz-Galiano</surname></persName>
						</author>
						<author>
							<persName coords="1,133.53,172.67,98.71,10.59"><forename type="first">Manuel</forename><surname>García-Vega</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CEATIC</orgName>
								<orgName type="institution" key="instit2">Universidad de Jaén Jaén</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">CEATIC</orgName>
								<orgName type="institution" key="instit2">Universidad de Jaén Jaén</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">CEATIC</orgName>
								<orgName type="institution" key="instit2">Universidad de Jaén Jaén</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Salud María Jiménez-Zafra CEATIC</orgName>
								<orgName type="institution" key="instit2">Universidad de Jaén Jaén</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,97.47,84.23,417.06,15.44">SINAI at TREC 2018: Experiments in Incident Streams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">86A07C1C5DA77CD8FB4C2E62279CA6E7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Social Media streams</term>
					<term>Incidents</term>
					<term>NLP</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the system architecture of the University of Jaén -SINAI team's for the TREC 2018 Incident Streams Track. The goal of the challenge is to automatically process social media streams during emergency situations with the aim of categorizing information and aid requests made on social media for emergency service operators. We explored four alternatives: baseline experimentation, WordNet synonyms, spelling correction and word embeddings. All of them use Support Vector Machine (SVM) as machine learning method. Our experiments reveal that the last approach leads to improve the baseline result.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Social media sites (e.g., Twitter, Facebook, Instagram) have emerged as powerful means of communication for people who want to share information on a wide variety of real-world events. In a crisis situation such as floodings, fires, storms or shootings, people nowadays report and discuss about their observations and opinions in Social Media <ref type="bibr" coords="1,79.15,487.46,22.59,7.94">[4] [3]</ref>. Some studies show that these amount of data help to detect the incidents <ref type="bibr" coords="1,138.27,498.42,10.70,7.94">[5]</ref> or to analyze the information reported by the people <ref type="bibr" coords="1,108.44,509.38,9.58,7.94" target="#b0">[1]</ref>. Tweets reflect useful event information for a variety of events. These event messages can provide a set of unique perspectives, regardless of the event type, and users sometimes report news prior to the traditional news media.</p><p>The first step of this process is the classification of tweets at high-level (by information type). It is usual to work with an specific ontology, called MOAC 1 . MOAC, the Management of a Crisis vocabulary, is a lightweight vocabulary aiming to provide terms to enable practitioners to relate different "things" in crisis management activities together as Linked Data.</p><p>We have applied different approaches, testing WordNet synonyms, spelling correction and Word embeddings <ref type="bibr" coords="1,237.67,629.93,9.39,7.94">[2]</ref>.</p><p>Chapter 2 present the data definition and analysis. Chapter 3 describes our system and the approaches, and the last chapter shows the results obtained and the conclusions. 1 available at http://observedchange.com/moac/ns/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DATA ANALYSIS</head><p>The data provided by the organization is based on a selection of incidents or events of different types. For each incident, a stream of tweets related to it has been collected using hashtags and keywords.</p><p>In 2018, TREC-IS is focused in the following 25 high-level classes: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SYSTEM OVERVIEW</head><p>Supervised learning algorithms demand for a valid application certain requirements that sometimes are difficult to meet. One of the most difficult to overcame in some cases is the need for a large and varied learning data set. When there is lack of data, two main strategies can be followed: transfer learning and data augmentation.</p><p>We have applied different strategies to increase data, using a traditional classification architecture, with the following components.</p><p>(1) Getting the tweets. Given the list of ids of the training and test tweets, the system used twarc 2 to download the data of each tweet id. (2) Preprocessing. Each tweet was preprocessed as usual (filtering, repeated characters, punctuation marks, stopwords removal, stemming, etc). The preprocessing was made using TextBlob 3 . We tested spelling correction, based on Peter Norvig's module. (3) Topic expansion with synonyms. Considering the low number of words in a tweet, we wanted to test the expansion of the context of the tweet using WordNet synonyms. (4) Topic expansion with word embeddings. It is the collective name for a set of language modeling and feature learning 2 available at https://github.com/DocNow/twarc 3 available at https://textblob.readthedocs.io/en/dev/ techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers. It aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of language data. Based on the Wikipedia English files, we expanded each term of the preprocessed tweet with three related words. We used three new terms based on previous experiments. The experiments carried out have the following features:</p><p>(1) Run1: baseline run. Preprocessing without spelling correction, not topic expansion (2) Run2: Preprocessing without spelling correction, topic expansion with WordNet synonyms (3) Run3: Preprocessing with spelling correction, not topic expansion (4) Run4: Preprocessing without spelling correction, topic expansion with Word Embeddings</p><p>After the first runs with the training dataset, and the analysis of the results our first decision was to delete some of the high-level classes. Specifically those that didn't have a number of tweets so that the automatic classifier could learn (Discussion, FirstPartyObservation, PastNews, ThirdPartyObservation, Unknown, Information-Wanted, ServiceAvailable, Volunteer, Hashtags).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION AND CONCLUSIONS</head><p>The metrics used for the evaluation are the usual ones: precision, recall, F1 and accuracy. Since a tweet can be categorized into one or more classes, to evaluate the quality of the runs the organization used a multi-type evaluation (categorization performance per information type in a 1 vs All manner) and a any-type evaluation (if the system assigned any of the categories that the human assessor selected for that tweet). The organization reported together with the evaluation of each run the median performance across participants.</p><p>Tables <ref type="table" coords="2,354.52,520.19,4.25,7.94" target="#tab_1">2</ref> and<ref type="table" coords="2,378.19,520.19,4.25,7.94" target="#tab_2">3</ref> show the overall performance and the overall performance (micro average) for each run.</p><p>Under the multi-type evaluation, the categorization performance is calculated per information type in a 1 vs All manner. A system is considered to have categorized a tweet for a category correctly if both the system and human assessor selected that category. The metrics used are:</p><p>• Under the any-type evaluation, a system receives a full score for a tweet if it assigned any of the categories that the human assessor selected for that tweet. This is useful for providing a view on the overall performance of a TREC-IS system.The metrics used are:</p><p>• Analyzing in a general way the results obtained we can conclude, as we had already foreseen in the analysis of the training data, that this is a complex task, which in many cases is complicated to solve</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Precision</head><p>Recall F1 Acc 1 0,1729 0,0726 0,0786 0,9029 2 0,1307 0,0696 0,0768 0,8987 3 0,1825 0,0712 0,0767 0,9023 4 0,1782 0,0753 0,0824 0,9025 MP 0,1827 0,0784 0,0824 0,0899 by humans, which means that an automatic system will not achieve good results.</p><p>Our system, by discarding those categories under-represented in the training data, has been affected in the recall value, but this has allowed the average values of the rest of participants to be reached and even increased.</p><p>In particular, the best precision value obtained with our system (0,5297) with the run4, significantly improves the median performance (0,3977). This is also the case for F1 and accuracy, although not with such a difference.</p><p>In a depth analysis, at topic level, Table <ref type="table" coords="3,220.08,432.48,4.25,7.94" target="#tab_3">4</ref> shows the results obtained for the best five topics.</p><p>Although the variation of results between the baseline case and the rest of the experiments is not significant, it can be verified that the topics that have achieved the best values are those that have been trained the most. We could place a threshold of 100 examples for a topic in training, as a measure for the classification system to work correctly.</p><p>Likewise, we can verify that in most of the analyzed cases, the best results have been obtained by applying spelling correction and word embeddings, and that the use of WordNet synonyms has introduced more noise, obtaining worse results.</p><p>As future work we will analyze the use of deep learning with a more adapted neural network system, introducing more training data for some of the topics and analyzing the behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic Run Precision</head><p>CallToAction-Donations </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,328.87,175.44,229.57,7.95;2,342.36,186.40,216.83,7.94;2,342.36,197.36,61.67,7.94;2,328.87,208.32,229.34,7.95;2,342.36,219.27,187.40,7.94"><head>( 5 )</head><label>5</label><figDesc>Training. The core framework functionality is triggered by an incident detection module based on a machine learning, SVM in our case. (6) Test. When the test dataset was processed, we run it against each training model, obtaining the prediction class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,317.73,295.50,240.47,410.80"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table coords="1,317.73,295.50,240.47,410.80"><row><cell>• Request</cell></row><row><cell>-Goods Services</cell></row><row><cell>-Search And Rescue</cell></row><row><cell>-Information Wanted</cell></row><row><cell>• Call To Action</cell></row><row><cell>-Volunteer</cell></row><row><cell>-Donations</cell></row><row><cell>-Move People</cell></row><row><cell>• Report</cell></row><row><cell>-First Party Observation</cell></row><row><cell>-Third Party Observation</cell></row><row><cell>-Weather</cell></row><row><cell>-Emerging Threats</cell></row><row><cell>-Significant Event Change</cell></row><row><cell>-Multimedia Share</cell></row><row><cell>-Service Available</cell></row><row><cell>-Factoid</cell></row><row><cell>-Official</cell></row><row><cell>-CleanUp</cell></row><row><cell>-Hashtags</cell></row><row><cell>• Other</cell></row><row><cell>-Past News</cell></row><row><cell>-Continuing News</cell></row><row><cell>-Advice</cell></row><row><cell>-Sentiment</cell></row><row><cell>-Discussion</cell></row><row><cell>-Irrelevant</cell></row><row><cell>-Unknown</cell></row><row><cell>-Known Already</cell></row><row><cell>We have analyzed the training data from a statistical point of</cell></row><row><cell>view. Table 1 shows the training classes distribution.</cell></row><row><cell>As we can see the training collection is not well balanced, since</cell></row><row><cell>there are classes with more than 120 tweets while others have only a</cell></row><row><cell>few examples, insufficient to describe those classes or for a machine</cell></row><row><cell>learning (ML) system to learn.</cell></row><row><cell>The goal of this task is for systems to categorize the tweets in</cell></row><row><cell>each event/incident's stream into different information feeds that</cell></row></table><note coords="2,99.22,375.14,182.59,7.70;2,53.80,417.36,240.41,7.94;2,53.80,428.32,72.31,7.94"><p>TREC-IS training dataset: tweets distribution might be consumed by different public safety personnel or used for post-event analysis.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,53.80,166.92,240.25,109.55"><head>Table 2 :</head><label>2</label><figDesc>Overall performance (multi-type)</figDesc><table coords="3,53.80,205.01,240.25,71.46"><row><cell>Run</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>Acc</cell></row><row><cell>1</cell><cell>0,5064</cell><cell>0,5302</cell><cell>0,5181</cell><cell>0,3843</cell></row><row><cell>2</cell><cell>0,4189</cell><cell>0,4979</cell><cell>0,4550</cell><cell>0,3317</cell></row><row><cell>3</cell><cell>0,5019</cell><cell>0,5129</cell><cell>0,5074</cell><cell>0,3762</cell></row><row><cell>4</cell><cell>0,5297</cell><cell>0,4849</cell><cell>0,5063</cell><cell>0,3785</cell></row><row><cell>MP</cell><cell>0,3977</cell><cell>0,6164</cell><cell>0,4774</cell><cell>0,3384</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,62.03,282.99,223.49,7.70"><head>Table 3 :</head><label>3</label><figDesc>Overall performance (micro average, any-type)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,317.96,104.14,241.07,359.77"><head>Table 4 :</head><label>4</label><figDesc>Precision values per run and topic (best five topics) [2] Yoav Goldberg and Omer Levy. 2014. Word2vec explained: deriving mikolov et al.'s negative-sampling word-embedding method. CoRR, abs/1402.3722. arXiv: 1402.3722. http://arxiv.org/abs/1402.3722. [3] Akshay Java and Tim Finin. Why we twitter: understanding microblogging usage and communities. (). [4] Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. What is twitter, a social network or a news media? (). [5] Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes twitter users: real-time event detection by social sensors. In In Proceedings of the Nineteenth International WWW Conference (WWW2010). ACM.</figDesc><table coords="3,462.10,104.14,71.56,7.94"><row><cell>1</cell><cell>0,74</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work has been partially supported by a grant from the <rs type="funder">Ministerio de Educación Cultura y Deporte</rs> (<rs type="grantNumber">MECD -scholarship FPU014/00983</rs>), <rs type="funder">Fondo Europeo de Desarrollo Regional (FEDER)</rs> and <rs type="projectName">REDES</rs> project (<rs type="grantNumber">TIN2015-65136-C2-1-R</rs>) from the <rs type="funder">Spanish Government</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gKeAjkx">
					<idno type="grant-number">MECD -scholarship FPU014/00983</idno>
				</org>
				<org type="funded-project" xml:id="_K73aQEH">
					<idno type="grant-number">TIN2015-65136-C2-1-R</idno>
					<orgName type="project" subtype="full">REDES</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,71.97,686.81,222.07,6.23;3,71.97,694.78,114.29,6.23" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,131.39,686.84,112.20,6.18">Iranelection: quantifying online activism</title>
		<author>
			<persName coords=""><forename type="first">Devin</forename><surname>Gaffney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,262.47,686.81,31.57,6.23;3,71.97,694.78,82.90,6.23">Proceedings of the Web Science Conference</title>
		<meeting>the Web Science Conference</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>WebSci10</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
