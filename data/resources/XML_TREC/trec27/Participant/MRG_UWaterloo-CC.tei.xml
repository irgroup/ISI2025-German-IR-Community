<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,56.69,107.73,420.11,19.92;1,56.69,129.65,172.71,19.92">MRG_UWaterloo Participation in the TREC 2018 Common Core Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,56.69,171.77,114.11,7.59"><forename type="first">Maura</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,200.59,171.77,113.23,7.59"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,56.69,107.73,420.11,19.92;1,56.69,129.65,172.71,19.92">MRG_UWaterloo Participation in the TREC 2018 Common Core Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A783F76088EB4F4A8639318AC984DD8F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The MRG_UWaterloo team from the University of Waterloo participated in the TREC 2018 Common Core Track. We used logistic regression to score and rank all documents from the Washington Post dataset, using pseudo-relevant and pseudo-nonrelevant training documents fetched from the Web using Google search.</p><p>For run uwmrg, the training set for each topic consisted of of the top ten links returned by a Google search for the words in the topic title and description. Each link was fetched and rendered as plain text using the command lyx -dump. Documents containing the the literal text title: and description: were excluded, as were documents containing 404 Not Found. The former indicates a legacy copy of the topic statement from prior TREC eorts, while the latter indicates a defunct page.</p><p>In total, the training set contained 496 documents. For each topic we labeled relevant all the documents fetched using its title and description, and we labeled not relevant all the rest.</p><p>For run uwmrgx, we extracted the anchor text and query-based summary for each of the ten links provided in the Google-generated search engine result page. For each topic, these ten extracts were combined to form a single training document. Thus, the training set for each topic consisted of 50 documents, with one positive example and 49 negative examples.</p><p>We extracted each article in the Washington Post dataset and stripped the XML tags using lyx -dump to form a plain text rendering of each document. Normalized tf-idf feature vectors were created using code extracted from the TREC Total Recall Track Baseline Model Implementation (BMI). 1  The logistic regression implementation was Soa-ML 2 with parameters --learner_type logreg-pegasos --loop_type roc --lambda 0.0001 --iterations 200000, also taken from BMI. For each topic, documents were sorted by score, and the top 10,000 were submitted to NIST.</p><p>Ocial TREC results are shown below. MAP P@10 NDCG</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body/>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
