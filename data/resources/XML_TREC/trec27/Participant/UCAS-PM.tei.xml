<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.88,115.96,337.60,12.62">UCAS at TREC-2018 Precision Medicine Track</title>
				<funder ref="#_gDu2hWf">
					<orgName type="full">Beijing Natural Science Foundation</orgName>
				</funder>
				<funder ref="#_avBAehp">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,203.69,154.44,42.15,8.74"><forename type="first">Zhi</forename><surname>Zheng</surname></persName>
							<email>zhengzhi18@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,254.06,154.44,39.66,8.74"><forename type="first">Canjia</forename><surname>Li</surname></persName>
							<email>licanjia17@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.97,154.44,30.12,8.74"><forename type="first">Ben</forename><surname>He</surname></persName>
							<email>benhe@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.67,154.44,52.99,8.74"><forename type="first">Jungang</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.88,115.96,337.60,12.62">UCAS at TREC-2018 Precision Medicine Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C82A8B8EBD52E3030305397990A14819</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the system developed for the TREC 2018 Precision Medicine track. We adopt BM25F model with query expansion to retrieve clinical trials. For scientific abstract task, we use BM25 model to generate an initial ranking list and then adopt two methods to re-rank. Experimental results show that a new model that penalizes the articles unrelated to treatment, prevention, and prognosis improves the performance for scientific abstracts task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>TREC Precision Medical track 2018 (PM2018) focuses on matching patients with existing articles from PubMed Central (PMC) and experimental treatments in clinical trials from ClinicalTrials.gov website. Specifically, there are two tasks in PM track: clinical trials and scientific abstracts. The goal of retrieving clinical trials is to identify trials for which the given patient is eligible to enroll. The goal of retrieving scientific abstracts is to identify relevant articles for the treatment, prevention, and prognosis of the disease under the specific conditions for the given patient. There are 50 topics concerning patients' condition: disease, genetic variants, demographic. For each collection, participants are allowed to submit a maximum of five runs.</p><p>In this paper, we describe the system developed for the TREC 2018 Precision Medicine track. We adopt BM25F model with query expansion to retrieve clinical trials. For scientific abstract task, we use BM25 model to generate an initial ranking and then adopt two methods for the re-ranking.</p><p>The rest of the paper is organized as follows. Section 2 gives a detailed introduction to our retrieval system for the two tasks, respectively. Section 3 presents the experimental results and analysis. Finally, Section 4 concludes our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we give a detailed introduction to our approach for each task, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Topic Expansion and Preprocessing</head><p>For a given topic, a document can be judged as relevant if it contains synonyms or abbreviations of the disease. For example, "head and neck squamous cell carcinoma" has an abbreviation "HNSCC" and "gastric cancer" has a synonym "stomach cancer". We add these abbreviations and synonyms into the original topic. Moreover, a document might also be relevant to the topic if it doesn't contain the exact disease but more general concepts about diseases. For example, in clinical trials task, a document which doesn't contain the given disease "melanoma" but contains "tumor" can be relevant to the topic if it matches other conditions, i.e., genetic variants and demographic. We also add these terms into topic.</p><p>The topics consist of three parts, namely the disease, genetic variants and demographic. We ignore the demographic part by filtering out clinical trials that don't match the demographic requirements during post-processing. We assume that disease is a better indicator of patients' conditions, and the more general the term is, the lower weight it should be assigned. Thus, the disease (including its synonyms and abbreviations), the name of the gene, the type of mutation (e.g., "amplification"), the general disease term (e.g., "tumor") are assigned with term weights of 4.0, 3.0, 2.0, 2.0. For example, topic 7 is reformulated as follows: melanoma 4.0 braf 3.0 amplif ication 2.0 tumor 2.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Index</head><p>We use Terrier <ref type="bibr" coords="2,195.35,417.77,12.06,8.74" target="#b0">[1]</ref> to index clinical trials and scientific abstracts after Porter stemming and stopword removal. For clinical trials, the indexed fields are NCT ID, official title, brief summary, detailed description, eligibility criteria, arm group and keyword. The PMID, title, abstract fields are indexed for all abstracts from PubMed and AACR/AASCO proceedings. For PubMed abstracts, we additionally index MeSH terms, journal title, publication type and chemical compounds fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Retrieval and Ranking</head><p>In this section, we introduce our methods for document retrieval and ranking for two tasks, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Scientific Abstracts</head><p>BM25 model. An initial ranking list is generated by the well-established BM25 model <ref type="bibr" coords="2,156.75,610.15,13.19,8.74" target="#b1">[2]</ref>. Given a document d and a query q, the ranking function is</p><formula xml:id="formula_0" coords="2,211.07,640.55,269.52,26.35">score 1 (q, d) = t∈q w t (k 1 + 1)tf K + tf (k 3 + 1)qtf k 3 + qtf<label>(1)</label></formula><p>where t denotes one term in the query, and qtf is the term frequency of t in query q. tf is the term frequency of query term t in document d. K is calculated as follows:</p><formula xml:id="formula_1" coords="3,250.21,160.52,230.38,24.17">K = k 1 ((1 -b) + b • l avg l<label>(2)</label></formula><p>where l and avg l denote the length of document d and the average length of documents in the whole collection. k 1 , k 3 and b are free parameters whose default setting is k 1 = 1.2, k 3 = 1000 and b = 0.75, respectively. w t is the weight of query term t, which is given by:</p><formula xml:id="formula_2" coords="3,253.19,249.56,223.16,23.22">w t = log 2 N -df t + 0.5 df t + 0.5 (<label>3</label></formula><formula xml:id="formula_3" coords="3,476.35,256.30,4.24,8.74">)</formula><p>where N is the number of documents in the collection, and df t is the document frequency of query term t, which denotes the number of documents that contains t. K-NRM. In this work, we employ a modified version of K-NRM <ref type="bibr" coords="3,419.09,318.55,16.10,8.74" target="#b2">[3]</ref>, which is adopted for the PM tasks as proposed in <ref type="bibr" coords="3,318.99,330.50,9.96,8.74" target="#b3">[4]</ref>, to re-rank the initial ranking. K-NRM which is a state-of-the-art neural retrieval model using Gaussian kernels for the relevance matching of term pairs. Given a query q and document d, K-NRM first maps each term t to an L-dimension embedding v t . Then the cosine similarity of each query-document term pair is computed, results in a translation matrix M :</p><formula xml:id="formula_4" coords="3,264.74,411.93,215.86,12.47">M ij = cos( v t q i , v t d j )<label>(4)</label></formula><p>After that, K-NRM uses f Gaussian kernels to obtain the soft match between each query term and terms in a document, which is given by</p><formula xml:id="formula_5" coords="3,233.59,466.34,246.99,28.23">K k (M i ) = j exp(- (M -µ k ) 2 2σ 2 k )<label>(5)</label></formula><p>where µ k and σ k are the mean and variance of kernel k. Subsequently, the kernel vector for query term t i is composed by the f kernels, as shown in Equation <ref type="formula" coords="3,470.86,518.33,3.87,8.74" target="#formula_6">6</ref>.</p><formula xml:id="formula_6" coords="3,235.73,539.98,244.87,9.65">K(M i ) = {K 1 (M i ), ..., K f (M i )}<label>(6)</label></formula><p>Then the query-document ranking features φ(M ) can be calculated as follows:</p><formula xml:id="formula_7" coords="3,240.62,580.86,239.98,30.32">φ(M ) = m i=1 log K(M i ) • w(t q i )<label>(7)</label></formula><p>where w(t q i ) is the query term weights. Next, φ(M ) is fed into a learning to rank layer to produce the relevance score as follows:</p><formula xml:id="formula_8" coords="3,232.20,654.05,248.39,11.72">score 2 (q, d) = tanh(w T φ(M ) + b)<label>(8)</label></formula><p>Ultimately, we interpolate the ranked list generated by K-NRM with the initial one after normalizing scores by Min-Max normalization, as shown in Equation 9.</p><formula xml:id="formula_9" coords="4,194.15,161.99,286.45,9.65">score(q, d) = λ • score 1 (q, d) + (1 -λ) • score 2 (q, d)<label>(9)</label></formula><p>Treatment information. The goal of retrieving scientific abstracts is to identify relevant articles for the treatment, prevention, and prognosis of the disease under the specific conditions for the given patient. Abstracts discussing information not useful for these goals will not be considered relevant.</p><p>In our experiments, we find that the MeSH terms like "therapy" and "diagnosis" are indicative to the treatment. Thus, we use MeSH terms to judge whether a document in the initial ranking list contains treatment information, and promote its ranking in during re-ranking if it is indeed related to the treatment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Clinical Trials</head><p>BM25F model. For clinical trials task, we obtain document ranking using BM25F model <ref type="bibr" coords="4,201.45,332.67,9.96,8.74" target="#b4">[5]</ref>. Given a query q and a document d, for each field f in d, a normalized term frequency is computed as follows:</p><formula xml:id="formula_10" coords="4,241.75,361.61,238.84,37.40">tf f = tf f ((1 -b f ) + b f • l f avg l f ) (10)</formula><p>where tf f is the term frequency in field f , b f is a field-dependent parameter, l f is the length of field f and avg l f is the average length of field f in the whole document collection.</p><p>Then, these term frequencies can be combined in a linearly weighted sum to obtain the term pseudo-frequency:</p><formula xml:id="formula_11" coords="4,267.21,475.61,213.38,20.14">tf = f W f • tf f (11)</formula><p>where W f is the weight for each field. Finally, the ranking function is given by:</p><formula xml:id="formula_12" coords="4,241.72,524.88,238.87,26.35">score(q, d) = t∈q tf k 1 + tf • w t<label>(12)</label></formula><p>where w t is defined by Equation 3 and k 1 is a free parameter. Query Expansion. The query expansion mechanism extracts the most informative terms from the top-returned documents as the expanded query terms.</p><p>In our experiments, we use Terrier's DFR-based term weighting models, namely Bo1 and KL <ref type="bibr" coords="4,191.77,608.30,9.96,8.74" target="#b5">[6]</ref>.</p><p>Post-processing. In order to filter out the clinical trials for which the patient is not eligible to enroll, we extract gender, minimum age and maximum age fields from the documents returned to check whether they match the patient demographics. Documents that do not meet the criteria will be discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Run Description</head><p>For scientific abstracts task, we submitted five runs, all of which use BM25 model with no query expansion and perform Porter stemming and stopword removal, so we omit these parts in the table. Differences between fives runs are shown in Table <ref type="table" coords="5,162.16,201.18,3.87,8.74" target="#tab_0">1</ref>. For clinical trials task, we submitted five runs which are summarized in Table <ref type="table" coords="5,134.77,355.57,3.87,8.74" target="#tab_1">2</ref>. We employ topic expansion for all five runs, so this part is omitted in the table. The column Preprocessing denotes stopword removal and stemming.  The evaluation results of our runs for scientific abstracts and clinical trials are shown in Table <ref type="table" coords="6,219.74,236.93,4.98,8.74" target="#tab_2">3</ref> and<ref type="table" coords="6,246.96,236.93,3.87,8.74" target="#tab_3">4</ref>, respectively. Top scores are highlighted in boldface. For scientific abstracts task, the run UCASSA5 outperforms other runs, according to infNDCG and P@10 metrics, suggesting that the treatment information plays an important role in this task. For clinical trials task, the run UCASCT4 outperforms other runs, according to infNDCG and R-prec metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we describe the system developed for the TREC 2018 Precision Medicine track. We adopt BM25F model with query expansion to retrieve clinical trials. For scientific abstract task, we use BM25 model to generate an initial ranking list. Two different methods are employed to re-rank the initial results. Experimental results show that the effectiveness of the abstract retrieval can be improved by penalizing articles that are not related to treatment, prevention, and prognosis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,184.56,231.23,271.47,82.11"><head>Table 1 .</head><label>1</label><figDesc>Runs submitted to the SA task</figDesc><table coords="5,184.56,250.29,271.47,63.06"><row><cell>RunID</cell><cell>Topic Expansion</cell><cell>Re-rank Method</cell></row><row><cell>UCASSA1</cell><cell>Yes</cell><cell>-</cell></row><row><cell>UCASSA2</cell><cell>No</cell><cell>-</cell></row><row><cell>UCASSA3</cell><cell>Yes</cell><cell>K-NRM</cell></row><row><cell>UCASSA4</cell><cell>No</cell><cell>K-NRM</cell></row><row><cell>UCASSA5</cell><cell>No</cell><cell>Treatment Information</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,166.96,399.52,287.34,93.07"><head>Table 2 .</head><label>2</label><figDesc>Runs submitted to the CT task</figDesc><table coords="5,166.96,418.57,287.34,74.02"><row><cell>RunID</cell><cell>Baseline Model</cell><cell>Field Weights</cell><cell>Query Expansion</cell><cell>Preprocessing</cell></row><row><cell>UCASCT1</cell><cell>BM25F</cell><cell>Group 1</cell><cell>Bo1</cell><cell>No</cell></row><row><cell>UCASCT2</cell><cell>BM25F</cell><cell>Group 2</cell><cell>Bo1</cell><cell>No</cell></row><row><cell>UCASCT3</cell><cell>BM25F</cell><cell>Group 2</cell><cell>Bo1</cell><cell>Yes</cell></row><row><cell>UCASCT4</cell><cell>BM25F</cell><cell>Group 1</cell><cell>Bo1</cell><cell>Yes</cell></row><row><cell>UCASCT5</cell><cell>BM25</cell><cell>-</cell><cell>KL</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,205.84,578.86,197.29,82.11"><head>Table 3 .</head><label>3</label><figDesc>Evaluation results for SA task</figDesc><table coords="5,205.84,597.92,197.29,63.06"><row><cell>RunID</cell><cell>infNDCG</cell><cell>P@10</cell><cell>R-prec</cell></row><row><cell>UCASSA1</cell><cell>0.5352</cell><cell>0.5700</cell><cell>0.3492</cell></row><row><cell>UCASSA2</cell><cell>0.5450</cell><cell>0.5640</cell><cell>0.3654</cell></row><row><cell>UCASSA3</cell><cell>0.5452</cell><cell>0.5720</cell><cell>0.3480</cell></row><row><cell>UCASSA4</cell><cell>0.5346</cell><cell>0.5720</cell><cell>0.3560</cell></row><row><cell>UCASSA5</cell><cell>0.5580</cell><cell>0.5980</cell><cell>0.3646</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,205.20,115.91,197.94,82.11"><head>Table 4 .</head><label>4</label><figDesc>Evaluation results for CT task</figDesc><table coords="6,205.20,134.97,197.94,63.06"><row><cell>RunID</cell><cell>infNDCG</cell><cell>P@10</cell><cell>R-prec</cell></row><row><cell>UCASCT1</cell><cell>0.5303</cell><cell>0.5500</cell><cell>0.3931</cell></row><row><cell>UCASCT2</cell><cell>0.5313</cell><cell>0.5480</cell><cell>0.4009</cell></row><row><cell>UCASCT3</cell><cell>0.5226</cell><cell>0.5240</cell><cell>0.4004</cell></row><row><cell>UCASCT4</cell><cell>0.5347</cell><cell>0.5440</cell><cell>0.4019</cell></row><row><cell>UCASCT5</cell><cell>0.5221</cell><cell>0.5240</cell><cell>0.3746</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported in part by the <rs type="funder">Beijing Natural Science Foundation</rs> under Grant No. <rs type="grantNumber">4162067</rs>, and the <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">61472391</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gDu2hWf">
					<idno type="grant-number">4162067</idno>
				</org>
				<org type="funding" xml:id="_avBAehp">
					<idno type="grant-number">61472391</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,536.87,342.24,7.86;6,146.91,547.83,333.67,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,381.44,536.87,99.15,7.86;6,146.91,547.83,129.74,7.86">From puppy to maturity: Experiences in developing terrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,286.04,547.83,137.02,7.86">Open Source Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,558.58,342.25,7.86;6,146.91,569.54,333.68,7.86;6,146.91,580.50,74.75,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,295.15,558.58,185.44,7.86;6,146.91,569.54,46.16,7.86">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,206.34,569.54,212.49,7.86">Foundations and Trends R in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,591.25,342.25,7.86;6,146.91,602.21,333.68,7.86;6,146.91,613.17,333.68,7.86;6,146.91,624.13,174.11,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,353.77,591.25,126.82,7.86;6,146.91,602.21,90.59,7.86">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,258.46,602.21,222.12,7.86;6,146.91,613.17,257.43,7.86">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">August 7-11, 2017. 2017</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,634.88,342.24,7.86;6,146.91,645.84,333.68,7.86;6,146.91,656.80,194.02,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,217.74,634.88,254.55,7.86">Neural precision medicine by mining implicit treatment concepts</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,157.39,645.84,323.20,7.86;6,146.91,656.80,17.31,7.86">2018 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2018</title>
		<meeting><address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">December 3-6, 2018, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,119.67,342.24,7.86;7,146.91,130.63,333.67,7.86;7,146.91,141.59,333.68,7.86;7,146.91,152.55,73.67,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,442.29,119.67,38.30,7.86;7,146.91,130.63,190.31,7.86">Microsoft cambridge at TREC 13: Web and hard tracks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,360.74,130.63,119.85,7.86;7,146.91,141.59,105.29,7.86">Proceedings of the Thirteenth Text REtrieval Conference</title>
		<meeting>the Thirteenth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-11-16">2004. November 16-19, 2004, 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,163.51,342.24,7.86;7,146.91,174.47,238.41,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,193.37,163.51,287.22,7.86;7,146.91,174.47,45.20,7.86">Probability models for information retrieval based on divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow, UK</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
