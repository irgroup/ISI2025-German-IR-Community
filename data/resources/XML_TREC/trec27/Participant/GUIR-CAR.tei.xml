<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.83,124.98,339.62,15.20">PACRR Gated Expansion for TREC CAR 2018</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,113.13,157.49,86.46,10.56"><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">Georgetown University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,211.48,157.49,71.90,10.56"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
							<email>ayates@mpi-inf.mpg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.26,157.49,77.78,10.56"><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">Georgetown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,407.68,157.49,69.73,10.56"><forename type="first">Ophir</forename><surname>Frieder</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">Georgetown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.83,124.98,339.62,15.20">PACRR Gated Expansion for TREC CAR 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">66AADE590EDE201049B250844ABCD92C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we present our approach to the 2018 TREC Complex Answer Retrieval (CAR) task. We submitted two passage retrieval runs. The first uses the state-of-the-art technique from TREC CAR 2017: a modified neural ranker modified to incorporate query heading frequency information while performing term matching on each heading independently. The second run incorporates a novel gated technique for incorporating query expansion terms in a neural ranker. Our TREC runs indicate significant performance improvements can be achieved when using the expansion approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Complex Answer Retrieval (CAR) is the task of finding answers to questions that have complex, multi-paragraph answers. The TREC CAR 2018 track is a continuation of the TREC CAR 2017 track, which first introduced CAR <ref type="bibr" coords="1,236.85,416.53,9.96,8.80" target="#b0">[1]</ref>. TREC CAR 2018 uses a similar task formulation, with the addition of questions from AI2's Text book question answering dataset (TQA) for task evaluation.</p><p>In this work, we describe our passage retrieval submissions to TREC CAR 2018. Our main contribution is the addition of a query expansion technique, which we find significantly improves CAR performance from a baseline neural method.</p><p>2 Background and Related Work TREC CAR 2017 first introduced the complex answer retrieval task. It makes use of a dump of Wikipedia as both a source of answers (paragraphs), complex queries (article heading hierarchies), and an automatic source of relevance judgments (paragraphs under a given heading are assumed relevant to the query associated with that heading). Various baseline approaches were proposed on this dataset. Early baseline approaches for CAR passage retrieval include BM25, cosine similarity (both with TF-IDF vectors and word embeddings), a baseline learning-to-rank approach, query expansion, and the Duet deep neural model <ref type="bibr" coords="1,308.71,590.85,15.49,8.80" target="#b9">[10,</ref><ref type="bibr" coords="1,327.81,590.85,11.62,8.80" target="#b10">11]</ref>. Submissions to TREC CAR 2017 included various approaches, including neural ranking architectures <ref type="bibr" coords="1,375.33,602.80,10.51,8.80" target="#b6">[7,</ref><ref type="bibr" coords="1,389.39,602.80,7.75,8.80" target="#b7">8,</ref><ref type="bibr" coords="1,400.68,602.80,11.62,8.80" target="#b11">12]</ref>, and query expansion approaches using established unsupervised rankers <ref type="bibr" coords="1,308.26,614.76,9.96,8.80" target="#b4">[5]</ref>.</p><p>The leading approaches for CAR incorporate two concepts into existing neural ranking methods: heading frequency and heading independence <ref type="bibr" coords="1,293.26,638.67,10.51,8.80" target="#b6">[7,</ref><ref type="bibr" coords="1,308.68,638.67,7.01,8.80" target="#b5">6]</ref>. Heading frequencies are incorporated by calculating the frequency that CAR headings appear in the training set, and using this as a signal when learning to rank. The intuition is that headings that occur frequently in training data (e.g., "History") are less likely to match in the text than headings that occur less frequently (e.g., "Green Sea Turtle"). Heading independence is achieved by limiting the scope of soft n-gram matching in in target documents by only matching n-grams within a given heading. This approach is similar to modifications to the Sequential Dependence Model (SDM <ref type="bibr" coords="1,340.57,710.40,10.29,8.80" target="#b8">[9]</ref>), and also performed well at TREC CAR 2017 <ref type="bibr" coords="1,133.60,722.35,9.96,8.80" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline CAR-PACRR</head><p>In this section we describe the details of our first run (guir), the CAR-PACRR model. This was an implementation of the prior state-of-the-art CAR approach <ref type="bibr" coords="2,360.83,142.29,9.96,8.80" target="#b5">[6]</ref>, and was based on the PACRR information retrieval architecture <ref type="bibr" coords="2,236.60,154.25,9.96,8.80" target="#b2">[3]</ref>. Let the general-domain neural ranking model R(q, d) = C(M (q, d)). M (q, d) represents a matching function, yielding a relevance scores for each query term in query q = {q 1 , q 2 , ..., q |q| } from document d = {d 1 , d 2 , ..., d |d| }. In PACRR, this function represents convolutions over the query-document similarity matrix. C(•) represents a combination function, which aggregates individual query term scores into a final relevance score. In PACRR, this is accomplished using a simple dense feedforward network. One naïve solution for CAR simply concatenates all heading terms in a CAR query, and uses the PACRR as-is.</p><p>CAR-PACRR aims to tailor the PACRR architecture for CAR in two ways. First, it breaks the headings into three categories: title, intermediate, and target headings, a technique referred to as heading independence. This differs from prior work which simply concatenates all headings, treating them as a single, long query. The title (q title ) represents terms in the root of the query tree, and corresponds to the title of an article. The target heading q target represents the bottom-most heading in a path in the query tree, and is the main topic of the query. Intermediate headings q int are a concatenation of headings along the path between q title and q target , which provide context for q target . CAR-PACRR performs matching separately on each of these categories, and concatenates the results prior to combination:</p><formula xml:id="formula_0" coords="2,184.30,353.45,226.67,10.81">R(q, d) = C(M (q title , d) M (q int , d) M (q target , d))</formula><p>By performing matching separately for each heading position, the model is able to isolate and prioritize the information need of each position separately. For instance, precise matching on q title may be more important than matching on q int . The second change that CAR-PACRR makes to the model is incorporating heading frequency statistics. The intuition is that frequent headings (e.g., "History") are less important to match precisely than infrequent headings (e.g., "After the Acts of Union of 1707"). This is similar to the intuition that terms with a high IDF value are more important to match in a query. However, these frequencies are calculated among query headings found in the training corpus, not the document collection itself. Heading frequency values are incorporated into the CAR-PACRR model by simply concatenating an additional vector hf = {hf title , hf int , hf target } for score combination, i.e., R(q, d) = C(M (q title , d) M (q int , d) M (q target , d) hf ) Note that these network modifications are generally applicable to interaction-focused neural architectures that follow the R(q, d) = C(M (q, d)) paradigm (e.g., K-NRM <ref type="bibr" coords="2,403.41,540.69,14.61,8.80" target="#b13">[14]</ref>, MatchPyramid <ref type="bibr" coords="2,491.98,540.69,14.61,8.80" target="#b12">[13]</ref>, and DRMM <ref type="bibr" coords="2,140.93,552.64,10.29,8.80" target="#b1">[2]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CAR-PACRR with Expansion</head><p>Prior work has shown that expanding queries using pseudo-relevance feedback can be an effective technique for boosting ad-hoc ranking performance <ref type="bibr" coords="2,313.27,610.86,9.96,8.80" target="#b3">[4]</ref>. Thus, we test the following approach for incorporating query expansion terms into the CAR-PACRR model to improve CAR performance.</p><p>Let e h = {e h 1 , e h 2 , ..., e h |e| } be the sequence of expansion terms from some query expansion technique (e.g., RM3) for heading h. We augment the function M (•) to accept the sequence of expansion terms, such that:</p><formula xml:id="formula_1" coords="2,212.29,680.03,170.70,10.81">M (q h , d, e h ) = match(q h , d) E(e h , d)</formula><p>We define a simple gating technique to perform E(e h , d). First, an expansion relevance matrix R ∈ R |e h |×2 is defined, such that R i,0 = idf (e h i ) and R i,1 = expscore(e h i ), where idf (•) and expscore(•) are the inverse document frequency and expansion score of of term e h i , respectively. Then, to calculate the gate weights, a 1 × 2 convolution is applied to R with relu activation yielding G ∈ R |e h | . Meanwhile, an expansion-document similarity score S ∈ R |e h | is calculated via the maximum cosine similarity between the word embedding of each expansion term and each document term S i = max j cosine(embed(e h i ), embed(d j )). S i . In the end, query-document relevance is defined as: R (q, d, e) = C(M (q title , d, e title ) M (q int , d, q int ) M (q target , d, q target ) hf )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We trained two variants of the CAR-PACRR model: one with the expansion technique (guir-exp), and one without (guir). Training was conducted on fold 0 of the TREC CAR 2018 training corpus using automatic relevance judgments. We used the performance on the TREC CAR 2017 test set using manual relevance judgments as our validation dataset. That is, we tuned hyper-parameter performance this dataset, such as the optimal training epoch. For our guir-exp run, we use the top 100 expansion terms from Relevance Model 3 <ref type="bibr" coords="3,303.64,367.35,9.96,8.80" target="#b3">[4]</ref>, and set k exp = 10.</p><p>Our results for TREC CAR 2018 are given in Table <ref type="table" coords="3,328.25,379.31,3.87,8.80" target="#tab_0">1</ref>. The results show a significant improvement in Rprec, MAP, and nDCG when using the expansion approach (guir-exp), as compared to the unmodified neural baseline (guir). However, the baseline approach itself significantly underperforms compared to the baseline QL method (which it re-ranks). This may be due to one of several reasons. Perhaps validating on hierarchical relevance judgments while training on tree hierarchical relevance judgments might have resulted in this performance mismatch. Or, perhaps the techniques may be over-tuned for the Wikiepdia setting, and are under-performing on the TQA queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we presented a query expansion approach for CAR. When evaluating with manual relevance judgments, the expansion approach significantly outperforms the unmodified baseline. However, the expansion approach was not able to outperform query likelihood. Further work is necessary to diagnose the issue.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,340.10,778.33,170.13,8.80"><head>Table 1 :</head><label>1</label><figDesc>The final score for each expansion term TREC CAR 2018 performance results of our official runs (guir and guir-exp), and an unofficial query likelihood (QL) baseline run. In all three metrics, the guir-exp run outperforms the guir run (marked with *, paired Student's t-test, p &lt; 0.01).is calculated via element-wise multiplication: S i = S i G i . Finally, the maximum k exp scores are selected E(e h , d) = max</figDesc><table coords="3,190.88,90.13,205.83,151.76"><row><cell>Run</cell><cell>Rprec</cell><cell>MAP</cell><cell>nDCG</cell></row><row><cell>guir</cell><cell>0.2479</cell><cell>0.2475</cell><cell>0.4644</cell></row><row><cell>guir-exp</cell><cell cols="3">*0.2849 *0.2918 *0.5098</cell></row><row><cell>QL (unofficial)</cell><cell>0.3154</cell><cell>0.3080</cell><cell>0.5253</cell></row><row><cell>kexp</cell><cell></cell><cell></cell><cell></cell></row><row><cell>i</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,105.51,608.38,404.72,8.80;3,105.51,620.34,69.50,8.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,335.48,608.38,170.27,8.80">Trec complex answer retrieval overview</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,117.97,620.34,24.83,8.80">TREC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.51,640.26,404.72,8.80;3,105.51,652.22,68.78,8.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,279.06,640.26,227.32,8.80">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,117.97,652.22,24.26,8.80">CIKM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.51,672.14,404.72,8.80;3,105.51,684.10,229.28,8.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,324.45,672.14,185.79,8.80;3,105.51,684.10,143.70,8.80">A position-aware deep model for relevance matching in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,269.93,684.10,32.38,8.80">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.51,704.02,404.73,8.80;3,105.51,715.98,63.63,8.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,238.99,704.02,143.11,8.80">Relevance-based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,402.72,704.02,25.85,8.80">SIGIR</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="260" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.51,735.90,340.26,8.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,199.30,735.90,168.40,8.80">CUIS team for TREC 2017 CAR track</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,388.72,735.90,24.83,8.80">TREC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.51,755.83,404.73,8.80;3,105.51,767.78,312.68,8.80" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,485.31,755.83,24.93,8.80;3,105.51,767.78,234.95,8.80">Characterizing question facets for complex answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,361.18,767.78,25.85,8.80">SIGIR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,88.14,404.72,8.80;4,105.51,100.09,57.05,8.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,274.23,88.14,217.85,8.80">Contextualized pacrr for complex answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,105.51,100.09,24.83,8.80">TREC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,120.02,404.72,8.80;4,105.51,131.97,137.91,8.80" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,311.72,120.02,198.51,8.80;4,105.51,131.97,59.84,8.80">UTD HLTRI at TREC 2017: Complex answer retrieval track</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Maldonado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,186.38,131.97,24.83,8.80">TREC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,151.90,404.72,8.80;4,105.51,163.85,90.80,8.80" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,232.57,151.90,225.97,8.80">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,479.22,151.90,25.85,8.80">SIGIR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,183.78,404.72,8.80;4,105.51,195.73,284.05,8.80" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,266.02,183.78,244.22,8.80;4,105.51,195.73,126.24,8.80">Learning to match using local and distributed representations of text for web search</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,252.86,195.73,24.46,8.80">WWW</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,215.66,404.72,8.80;4,105.51,227.61,138.54,8.80" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,330.45,215.66,175.94,8.80">Benchmark for complex answer retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,117.96,227.61,26.64,8.80">ICTIR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,247.54,404.72,8.80;4,105.51,259.50,57.05,8.80" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="4,263.84,247.54,228.42,8.80">New york university submission to TREC-CAR 2017</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,105.51,259.50,24.83,8.80">TREC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,279.42,404.72,8.80;4,105.51,291.38,67.27,8.80" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="4,352.10,279.42,153.89,8.80">Text matching as image recognition</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,117.96,291.38,23.05,8.80">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.51,311.30,404.72,8.80;4,105.51,323.26,138.10,8.80" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="4,339.96,311.30,170.28,8.80;4,105.51,323.26,59.86,8.80">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,186.60,323.26,25.85,8.80">SIGIR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
