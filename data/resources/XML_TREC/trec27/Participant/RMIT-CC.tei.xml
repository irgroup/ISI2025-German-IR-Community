<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,165.24,83.75,282.02,15.12">RMIT at the 2018 TREC CORE Track</title>
				<funder>
					<orgName type="full">Mozilla Foundation</orgName>
				</funder>
				<funder ref="#_QcjuBD4">
					<orgName type="full">Australian Research Council&apos;s Discovery Projects Scheme</orgName>
				</funder>
				<funder ref="#_3dqPb67">
					<orgName type="full">Australian</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,103.29,111.86,78.13,5.59"><forename type="first">Rodger</forename><surname>Benham</surname></persName>
						</author>
						<author>
							<persName coords="1,269.24,111.86,74.74,5.59"><forename type="first">Luke</forename><surname>Gallagher</surname></persName>
						</author>
						<author>
							<persName coords="1,433.72,111.86,73.66,5.59"><forename type="first">Joel</forename><surname>Mackenzie</surname></persName>
						</author>
						<author>
							<persName coords="1,109.58,157.44,64.53,5.59"><forename type="first">Binsheng</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName coords="1,281.92,157.44,47.77,5.59"><forename type="first">Xiaolu</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName coords="1,440.34,157.44,59.85,5.59"><forename type="first">Falk</forename><surname>Scholer</surname></persName>
						</author>
						<author>
							<persName coords="1,187.95,203.01,55.34,5.59"><forename type="first">Alistair</forename><surname>Mo</surname></persName>
						</author>
						<author>
							<persName coords="1,341.53,203.01,93.12,5.59"><forename type="first">J</forename><forename type="middle">Shane</forename><surname>Culpepper</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">University of Melbourne Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">RMIT University Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,165.24,83.75,282.02,15.12">RMIT at the 2018 TREC CORE Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A4843463ED5E3260346EEA94A5FA2AF2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ad-hoc retrieval is an important problem with many practical applications. It forms the basis of web search, question-answering, and a new generation of virtual assistants being developed by several of the largest so ware companies in the world. In this report, we continue our exploration of the importance of multiple expressions of information needs. Our thesis is that over-reliance on a single query can lead to suboptimal performance, and that by creating multiple query representations for an information need and combining the relevance signals through fusion and relevance modeling, highly e ective systems can be produced. is approach may form the basis for more complex multi-stage retrieval systems in a variety of applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>e second TREC CORE Track<ref type="foot" coords="1,168.39,452.08,3.38,3.40" target="#foot_0">1</ref> continues the ad-hoc evaluation campaign from 2017, where the aim is to bring the community together to solicit a diverse set of runs and to establish new methodologies for creating test collections. is year, we focused on exploring similar ideas to those we used in the previous CORE track <ref type="bibr" coords="1,74.72,509.34,9.39,4.20" target="#b4">[5]</ref>, including manual query variations and rank fusion, with other ideas such as relevance modeling and external resources. In addition, we again focus on recall-oriented search to build robust runs on the new collection through combining multiple representations of an information need <ref type="bibr" coords="1,199.18,553.18,9.39,4.20" target="#b7">[8]</ref>.</p><p>Inspired by the strong participation of Zhang et al. <ref type="bibr" coords="1,245.30,564.14,14.72,4.20" target="#b16">[17]</ref> and their use of relevance feedback, we solicit a shallow pool of document judgments to lter out poorly performing queries prior to rank fusion. We felt that this was a tractable and useful exercise to ensure that relevant documents are at the head of the run, while also improving the likelihood of introducing unjudged relevant documents not found by other participants. In addition, we use the resulting judgment set to select the best query per-topic, and to check if the poorly performing run RMITUQVBestM2 last year was an aberrant result due to using an external collection to decide the "best" query. Another point of inquiry is whether external query expansion combined with multiple systems on the target corpora can further improve retrieval e ectiveness.</p><p>Bailey et al. <ref type="bibr" coords="1,377.18,269.19,10.55,4.20" target="#b2">[3]</ref> observed the retrieval consistency of query variations using the UQV100 collection <ref type="bibr" coords="1,458.87,280.15,9.27,4.20" target="#b1">[2]</ref>. e query variations on this collection were included in the judgment pooling process with shallow judgments, as Mo at et al. <ref type="bibr" coords="1,442.90,302.07,14.72,4.20" target="#b14">[15]</ref> showed that test collections formed without user query variability do not generalize well outside of the supplied title query. Based on these observations, we also investigate whether the CORE 2018 test collection construction methodology exhibits similar behaviour.</p><p>Research Goals. We focus on three research questions: • RQ1: Can shallow judgments from bronze-assessors be used to further improve double fusion e ectiveness by ltering out nonperforming queries prior to fusion? • RQ2: Can external corpora be combined with multiple information needs in order to produce be er results than the original corpora alone? • RQ3: How robust is the new collection to multiple query variations representing the same information need?</p><p>In the next section, we discuss how our submi ed runs were formed, and in Section 3 we provide the results of our submi ed runs using the y topics assessed by NIST, and conduct further analysis on these runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">APPROACH</head><p>We now describe the various resources used to create the ve submi ed runs, and how these runs are generated.</p><p>Collections. e new W P v2 corpus for the CORE track was parsed using the jq tool<ref type="foot" coords="1,446.78,568.45,3.38,3.40" target="#foot_2">2</ref> . Note that Twi er was also embedded into the original unprocessed collection (json within json). All double embeddings were stripped out of the nal trectext SGML forma ed text produced by our scripts. Indri 5.11 and Terrier 4.2 were then used to index the resulting collection. For external query expansion, we used the Gigaword and Tipster corpora as originally described by Diaz and Metzler <ref type="bibr" coords="1,476.11,636.66,13.39,4.20" target="#b10">[11]</ref>, which were also reforma ed into trectext SGML format before indexing. External expansion was conducted using a patched version of Indri 5.12. <ref type="foot" coords="1,554.32,656.12,3.38,3.40" target="#foot_3">3</ref>Details on how this collection was parsed are available in Benham et al. <ref type="bibr" coords="2,73.56,99.43,9.39,4.20" target="#b4">[5]</ref>.</p><p>A peculiarity of this W P corpus is that there are many duplicate documents. To improve recall, we include all duplicate documents in-place at the rank position they are retrieved (that is, duplicates are not suppressed). To determine if a document is a duplicate, we compute the MD5 hash of all document titles in the collection, and if any documents collide with a hash, those documents are considered duplicates. ere are cases where this simple approach for identifying duplicates is not e ective, such as when the title of the document is "Tra c Report", and the document body is not the same. By selecting a threshold of only allowing in-place insertion of duplicate documents for MD5 collisions of less than 100 matches, and manually verifying that the result of this decision did not include incorrect duplicates into runs, we were satis ed with our approach.</p><p>Runs. e runs we generated for the CORE 2018 track are a logical extension of the previous ideas employed in Benham et al. <ref type="bibr" coords="2,53.80,291.21,9.42,4.20" target="#b4">[5]</ref>. We have since improved the e ectiveness of our automatic runs by leveraging external relevance modeling proposed by Diaz and Metzler <ref type="bibr" coords="2,101.31,313.13,13.39,4.20" target="#b10">[11]</ref>, which was recently explored by Benham et al. <ref type="bibr" coords="2,53.80,324.09,9.42,4.20" target="#b5">[6]</ref>. In their work, the R 04 collection was treated as the target collection and the G +T corpus was used as a source for relevance modeling. is time around we followed a similar methodology, but replaced the target collection with the W P corpus. Empirically, we found that using Terrier's query expansion models DFree and DLH13 produced more e ective runs than relevance modeling with Indri -a line of experimentation we did not explore previously. We hypothesize that combining these two approaches will be more e ective, which helps to address RQ2. Fortunately, the second round of the CORE track o ered the bene t of tuning query expansion parameters using 5-fold cross-validation on the CORE 2017 N Y T collection. is collection is more similar in composition (temporally) to the new W P collection than R 04 used in the previous year. Indri was employed to perform a parameter sweep over the N Y T collection. ese parameters were also used for a number of query expansion runs with the Terrier platform.</p><p>Bailey et al. <ref type="bibr" coords="2,108.65,510.39,10.55,4.20" target="#b2">[3]</ref> proposed double fusion, where multiple queries for the same information need are issued to multiple systems and merged into a single, high quality SERP. Benham and Culpepper <ref type="bibr" coords="2,53.80,543.27,10.55,4.20" target="#b3">[4]</ref> showed that double fusion had the best e ectiveness and risksensitivity trade-o space using the T Risk measure <ref type="bibr" coords="2,250.17,554.23,14.85,4.20" target="#b11">[12]</ref> on the R 04 and C W 12 B corpora. Incidentally, the authors found that reciprocal rank fusion (RRF), with k xed to 60 as proposed and recommended by Cormack et al. <ref type="bibr" coords="2,193.42,587.10,9.42,4.20" target="#b6">[7]</ref>, was a marginally more e ective way to perform unsupervised fusion than the rank-biased centroid (RBC) approach proposed by Bailey et al. <ref type="bibr" coords="2,247.71,609.02,9.42,4.20" target="#b2">[3]</ref>, and this was used for the RMIT CORE runs in 2017. In addition, we did not perform a true double fusion in the last CORE e ort -rather, we selected on a per-topic basis whether a sequential dependency model combined with query expansion should be used for the top-5 performing query variations on R 04, or BM25 instead. Although di erent systems were used, they were not used in conjunction with each other as a source of evidence to form the topic centroid. We use a true double fusion this year to avoid tuning on a per-topic basis.</p><p>Rather than using an external collection to select the best query variation from a pool of candidates wri en by the authors (as we did in CORE 2017), we instead opted to form our own judgments (explained below). is is due to the unexpected nding that the best query variation from the constrained set evaluated on both collections was only the same for 12 out of 50 topics, suggesting that the best formulation of an information need is indeed collection dependent. We also used this judgment set to lter out queries with a zero average precision (AP) score prior to fusion to form what we hypothesize to be our most e ective run; forming the run that allows us to address RQ1. Table <ref type="table" coords="2,435.53,436.03,4.09,4.20" target="#tab_1">1</ref> provides a description of each of the runs submi ed, while Figure <ref type="figure" coords="2,438.16,446.99,4.13,4.20" target="#fig_0">1</ref> shows a UML representation of how each of the submi ed runs was formed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generating</head><p>ery Variations. e approach to generating query variations was a similar process to our 2017 submission Benham et al. <ref type="bibr" coords="2,339.70,496.30,9.42,4.20" target="#b4">[5]</ref>.</p><p>e authors of that paper were invited to contribute up to ten query variations per-topic. As the NIST assessed topics include 25 of the old topics which we had previously collected query variations for, we needed to gather query variations for the 25 new topics only. And since the CORE track has had a ve-fold reduction in the number of topics, we were able to collect more data per-topic than in previous experiments.</p><p>Users were given spell-check suggestions for the queries they submit, using the Bing Spell Check API. All queries were casefolded and Krovetz stemmed, consistent with our participation in 2017 <ref type="bibr" coords="2,348.32,605.89,9.52,4.20" target="#b4">[5]</ref>. By the end of the collection stage, 1,455 variations were collected for the 50 topics. Table <ref type="table" coords="2,461.51,616.85,4.25,4.20" target="#tab_0">2</ref> shows the contributions made by each participant. e query variants are slightly shorter compared to 2017 in terms of the average number of terms (5.48 to 5.02) and the average number of characters (33.9 to 32.0). We avoid comparing the ratio of unique variations as we are only using bag of words models, rather than proximity models like last year. is data curation exercise helps to answer RQ1 and RQ3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Type Description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMITUQVDBFNZDM1 Manual</head><p>Authors formed a judgment pool to the top-5 of RMITUQVDBFDM3 and a title query language model run. ese judgments were used to remove any query variations with a zero score prior to rank fusion. e reduced set of queries using RMITUQVDBFDM3, where documents found to have duplicates were included in-place in the ranked list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMITUQVDBFDM3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Manual</head><p>ery variations for the original TREC topics were generated by the authors. All query variations were run on systems with parameters shown to be e ective on NYT using Indri and Terrier with query expansion, as well as external corpus query expansion using G and ]G +T . is was fused to make a single run using RRF k=60. Documents found with duplicates were included in-place in the ranked list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMITUQVBestDM2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Manual</head><p>Authors formed a judgment pool to the top-5 of RMITUQVDBFDM3 and a title query language model run. ese judgments were used to select the best title-only query without fusion using the same systems as in RMITUQVDBFDM3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMITFDA4</head><p>Automatic Title query runs on Indri and Terrier with query expansion, and external expansion runs from G and T fused into a single run using RRF. ery expansion parameters taken from NYT judgments (collection-wide, not per-topic). A baseline for how query variations compare to titles. Duplicate documents were included in-place in the ranked list. Judgments. In Benham et al. <ref type="bibr" coords="3,166.33,597.82,9.42,4.20" target="#b4">[5]</ref>, we found that fusion of many queries yielded a more e ective and robust SERP. is is in contrast to selecting the best query from a constrained set of high-quality candidates by using an external collection with relevance judgments. A preliminary investigation into the "best" query from this set shows that the ordering is highly-speci c to the collection; even on corpora of similar content. is year instead of using the judgments from an external collection, we form a shallow judgment pool to a minimum depth of 5 documents per-topic, and a maximum of 15.</p><p>e judgment pool was formed using the title queries supplied by NIST over BM25 and Language Modeling (LM) using Indri, as well as our submi ed run RMITUQVDBFDM3 described in Table <ref type="table" coords="3,537.94,608.78,3.13,4.20" target="#tab_1">1</ref>. On average each topic had a pool-depth of 10.40, compared to the NIST assessment average pool depth per-topic of 524.66. Figure <ref type="figure" coords="3,529.20,630.70,4.11,4.20" target="#fig_1">2</ref> shows a screenshot of the judgment solicitation interface authors used for the assessment exercise. Table <ref type="table" coords="3,351.14,663.58,4.25,4.20" target="#tab_2">3</ref> shows statistics on the judgments collected with the average document length per-assessor, and a post-hoc analysis of intra-assessor agreement with the NIST QREL set. We compute Krippendor 's α coe cient introduced by Hayes and Krippendor  [13] to quantify this agreement with respect to the nominal dichotomous categories we de ne as: Not Relevant, Somewhat Relevant and Fully Relevant. Where multiple assessors judged the same document, the median score was taken as the true assessment, where the median could correspond to one of the three categories mentioned above. Overall we nd that our relevance assessments are di erent to NIST with a Krippendor 's α of 0.507. If we binarize both sets of judgments to collapse the categories Somewhat Relevant and Fully Relevant to become Relevant, Krippendor 's alpha remains relatively unchanged with a value of 0.504, with a percentage agreement of 76.08%. As document assessment is a subjective exercise, disagreement is likely to occur. For example, on the TREC topic 336 titled Black Bear A acks, two assessors for the document identi er d6ed7028c686e5756ceb0aa0c9b62e0d found the document to be Not relevant as it is about a personal account of a black bear a ack, and does not discuss the frequency or possible causes for a black bear a ack -however it is marked as Fully Relevant in the NIST QREL set. In any case, our goal for forming a judgment set is to form a general guide for inclusion of queries into a fusion pool and is not to replicate the decisions made by NIST assessors. We later show that despite the high disagreement, our use of the judgment set in the generation of RMITUQVDBFNZDM1 and RMITUQVBestDM2 runs was justi ed as retrieval e ectiveness improved. Given that the assessors are "bronze" judges while the NIST assessors are presumed to be "gold" assessors <ref type="bibr" coords="4,462.92,254.04,9.27,4.20" target="#b0">[1]</ref>, further explorations in presentation ordering <ref type="bibr" coords="4,396.85,265.00,14.59,4.20" target="#b9">[10]</ref> or gathering multiple judgments through crowdsourcing <ref type="bibr" coords="4,373.59,275.95,10.44,4.20" target="#b8">[9]</ref> might result in higher agreement with the NIST assessors, and improve performance further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>Once again, all of our runs met the e ectiveness requirements of the track organizers, meaning that all ve runs from RMIT contributed to the judgment pool. We now outline a basic analysis of these systems for completeness.</p><p>Baseline Con guration. As a point of reference, we report three additional runs in the main results reported in Table <ref type="table" coords="4,518.03,382.06,3.21,4.20" target="#tab_3">4</ref>: Title is a BM25 run on the query title, RRF is the RRF fusion of all unique variations for among each topic, and BestUQV is the top-performing single UQV from each topic. We use RRF as our basis for signi cance testing, as it represents a strong yet simple baseline given a set of UQVs.</p><p>Comparing Submitted Runs. Figure <ref type="figure" coords="4,463.11,453.29,4.25,4.20" target="#fig_2">3</ref> shows the e ectiveness of our submi ed runs across a number of commonly used metrics including AP, NDCG@k, and RBP with persistence ϕ. In Figure <ref type="figure" coords="4,553.99,475.21,4.21,4.20" target="#fig_2">3</ref> it is interesting to observe that of the manual runs, the best system depends on the metric and evaluation depth. While focusing on Table <ref type="table" coords="4,339.81,508.08,3.08,4.20" target="#tab_3">4</ref>, the two automatic runs, RMITEXTGIGADA5 and RMITFDA4 were unsurprisingly outperformed by the manual runs across all metrics. In particular, the RRF baseline was statistically signi cantly be er than RMITEXTGIGADA5 across a number of the tested metrics. On the other hand, no signi cance was found between RRF and any other submi ed run. Interestingly, the oracle run BestUQV signi cantly outperformed the RRF baseline for all metrics, demonstrating the importance of how information needs are formulated. As RMITFDA4 is more e ective than RMITEXTGIGADA5, and includes RMITEXTGIGADA5 in its fused run (see Figure <ref type="figure" coords="4,535.36,606.71,3.47,4.20" target="#fig_0">1</ref>) and passes a pairwise t-test over AP, we answer RQ2 in the a rmative.</p><p>Table <ref type="table" coords="4,350.51,628.63,4.25,4.20">5</ref> shows the tournament matrix of wins, ties, and losses when comparing the runs head-to-head.</p><p>ese outcomes are consistent with the e ectiveness comparison, showing at the topic level how the manual runs consistently outperform the automatic runs. RMITUQVDBFNZDM1 is the best of the ve runs but it is only slightly superior to RMITUQVDBFDM3, with 32 out of the 50 topic scores within 10% of each other (the de nition of "tie" used  here). e other pairwise comparisons show larger gaps in the win and loss numbers, which is an indication of their performance di erence.</p><p>All three manual runs show similar performance, but RMI-TUQVDBFNZDM1 is more e ective than the other two. In both Table 5 and Table <ref type="table" coords="5,110.40,641.98,3.03,4.20" target="#tab_3">4</ref>, run RMITUQVDBFNZDM1 and RMITUQVDBFDM3 are particularly of interest. e RMITUQVDBFDM3 run is a double fusion run over all query variants and several retrieval systems. As described in Table <ref type="table" coords="5,121.03,674.86,3.01,4.20" target="#tab_1">1</ref>, RMITUQVDBFNZDM1 is also a fusion run built from RMITUQVDBFDM3, with the worst performance query variants removed, based on judgments pooled using RMITUQVDBFDM3 and an LM run at depth d = 5. From Figure <ref type="figure" coords="5,462.56,88.47,3.08,4.20" target="#fig_2">3</ref>, we can observe that the two runs show similar performance when evaluated using deep metrics such as AP or RBP 0.95, but a larger performance gap can be observed when evaluated with shallow metrics such as NDCG@20 and RBP 0.5. e only exception is exhibited when considering NDCG@10, where the median RMITUQVDBFDM3 score is worse than RMITUQVDBFNZDM1. Despite the greater e ectiveness of RMITUQVDBFNZDM1 compared to RMITUQVDBFDM3, a pairwise ttest of their AP scores found no statistical signi cance, and therefore we cannot answer RQ1 in the a rmative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Consistency of ery Variations</head><p>Figure <ref type="figure" coords="5,345.69,221.97,4.25,4.20">4</ref> shows, on a per-topic basis, the variance of the AP score for each submi ed query variation using a simple bag-ofwords ranking model (BM25). It also shows the performance of the provided title query as a diamond, using the same BM25 con guration. e le -most topics are consistently di cult, with no submi ed variations (nor the title query) performing well. On the other hand, there appears to be less consistency among easy topics, as the IQR generally seems to increase with the mean AP of the topic.</p><p>Inconsistency Analysis. Looking closer, we can observe inconsistencies in the UQVs. For example, consider the three topics with the highest IQR from Figure <ref type="figure" coords="5,422.89,348.00,3.14,4.20">4</ref>:</p><p>• 804: "women on 20s"</p><p>• 806: "computers and paralyzed people"</p><p>• 811: "car hacking"</p><p>Topic 804 had a poor-performing title query, with an AP of 0.021 for a simple BM25 ranking. Furthermore, the highest scoring 18 query variations all contained the name Harriet Tubman, with 10 of these variations also including the name Andrew Jackson. e AP scores of these top 18 variations ranged from 0.578 to 0.834, a stark contrast to the AP score of the title query. Topic 806 had a title query with an AP of 0.400, corresponding to the median-performing topic out of the 33 variations. For this topic, the query terms that perform well are less clear-cut, with no real trends observed in the top performing variations. Interestingly, the fourth best variation, with an AP of 0.562, did not mention computers at all (the query was exoskeleton paralyzed paralysis movement). is serves to demonstrate the high variance in query formulation, and the unpredictable behaviour that can occur for isolated query variations.</p><p>e title query for topic 811 outperformed all submi ed query variations that we solicited, with an AP of 0.625. Even queries that seemingly add a slight perturbation such as car computer hacking or car hacking tools greatly reduced the performance, resulting in AP scores of 0.360 and 0.118, respectively.</p><p>While the oracle run BestUQV shows the potential upside to selecting a single yet high performing query variant on a per-topic basis, further analysis shows that UQVs exhibit high variance in their individual performance. is demonstrates why rank fusion is preferred for robustness and consistency <ref type="bibr" coords="5,477.33,658.69,9.33,4.20" target="#b2">[3,</ref><ref type="bibr" coords="5,488.91,658.69,6.22,4.20" target="#b7">8]</ref>.</p><p>Table <ref type="table" coords="6,77.85,84.49,3.45,7.94">5</ref>: Comparing wins, ties and losses terms of AP score in the column header, against the run listed in each row, with a 10% di erence taken to be the upper threshold for a "tie". Topic AP Figure <ref type="figure" coords="6,81.94,351.18,3.45,7.94">4</ref>: e per-topic BM25 based on a bag-of-words BM25 run for every query variation for each topic, sorted by mean AP. Clearly, some topics were consistently di cult, and others exhibit high variance depending on the query variation that is processed. Diamonds represent the TREC title query for each topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Do ery Variations Generalize?</head><p>e metric RBP <ref type="bibr" coords="6,114.57,416.68,14.85,4.20" target="#b13">[14]</ref> is by design a lower bound estimate on the retrieval e ectiveness of a system. It provides a residual score that indicates the amount of unjudged documents present in an evaluation. A high residual indicates uncertainty -we simply do not know whether the unjudged documents are relevant or not. Figure <ref type="figure" coords="6,80.09,471.48,4.25,4.20">5</ref> depicts the residuals from BM25 for RBP with ϕ = 0.95 across all UQVs for each of the 50 topics. In contrast to Figure <ref type="figure" coords="6,288.77,482.43,3.13,4.20">4</ref>, topics that have more e ective scores and less variance should overall have a lower residual score.</p><p>Consider topic 825, overall the residual and variance is low for the submi ed UQVs. However, there are a number of outliers for topic 825 that can be seen in Figure <ref type="figure" coords="6,184.22,537.23,3.04,4.20">5</ref>. e background description for topic 825 is "Does diversion of U.S. corn crops into ethanol for fuel increase food prices?", and looking at Table <ref type="table" coords="6,233.00,559.15,3.13,4.20">6</ref>, even the poor performing queries mention "food", "corn", "price" or "ethanol" with one exception. ese appear to be important terms for the BM25 retrieval model, however, looking at the actual query variations in Table <ref type="table" coords="6,88.30,602.98,3.13,4.20">6</ref>, there appears to be a sense of participant initiated query dri . e human element within an IR task is the strongest and weakest link -a lack of knowledge, fatigue or a momentary distraction are all viable cases for outliers. Among the outliers listed in Table <ref type="table" coords="6,105.84,646.82,4.09,4.20">6</ref> we see that as the RBP score improves, the residual becomes lower indicating greater con dence because there are more judged documents examined. Within the table, the MED-RBP scores (see Tan and Clarke <ref type="bibr" coords="6,129.82,679.69,13.96,4.20" target="#b15">[16]</ref>) indicate how di erent two ranked lists are when compared under RBP ϕ = 0.95. is can give insight as to why things may be di erent for certain variants. Take, for example, variant 825-4-3 and 825-3-6.</p><p>e RBP scores are essentially the same, however, the residuals di er, and 825-3-5 has more relevant information than 825-4-3. is results in an improved MED-RBP score and indicates that perhaps being more certain about what is not relevant is equally important for capturing a user's information need.</p><p>It is di cult to ascertain whether the same information need expressed in di erent ways is able to generalize across a collection. It certainly does work in some cases, as shown in Figure <ref type="figure" coords="6,532.29,490.65,3.13,4.20">4</ref>, with supporting evidence in Figure <ref type="figure" coords="6,432.81,501.61,3.13,4.20">5</ref>. However, there are other cases where variants that should retrieve a sensible SERP for a topic are falsely evaluated as performing poorly due to high residuals. One take on this is that query variants for the same information need may have di erent objectives. e variant 825-4-3 is suggestive of an open-domain style question-answer type of query, and while the information need may be similar, the level of interpretation required by the system is di erent. Despite this, Figure <ref type="figure" coords="6,536.89,578.32,4.25,4.20">4</ref> and Figure <ref type="figure" coords="6,342.98,589.28,4.09,4.20">5</ref> clearly show that there is contrasting levels of uncertainty over query variations per-topic with a xed BM25 retrieval model. e diamond in Figure <ref type="figure" coords="6,401.54,611.20,4.09,4.20">5</ref> shows the residual uncertainty of the title queries that contributed to the pool, where most of these residuals are below the rst quartile compared query variant residuals. We nd that the collection forms robust answer set to the supplied TREC title queries, however, this does not hold true for query variations, answering RQ3. It would be interesting in future work to explore the e ect of query variants across di erent retrieval models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,199.71,567.93,212.59,7.94"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Flowchart representation of the runs submi ed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,53.80,420.17,240.25,7.94;4,53.80,432.82,76.97,4.20;4,60.76,215.38,226.32,191.04"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Screenshot of the document relevance assessment solicitation interface.</figDesc><graphic coords="4,60.76,215.38,226.32,191.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,53.80,535.38,240.24,7.94;5,53.80,548.03,240.25,4.20;5,53.57,558.99,81.32,4.20"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparing the submi ed runs across a range of e ectiveness metrics. Diamonds denote the mean e ectiveness value for each system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,317.66,84.49,240.55,193.78"><head>Table 2 :</head><label>2</label><figDesc>ery variation statistics per user. Uniqueness is calculated with respect to a bag of words, as all retrieval models used are BoW. Participants marked with † were co-authors of the CORE 2017 activity that did not contribute in 2018.</figDesc><table coords="2,325.25,145.19,225.67,133.08"><row><cell>Participant</cell><cell cols="4">eries Avg. Terms Avg. Chars % Unique</cell></row><row><cell>1</cell><cell>152</cell><cell>3.84</cell><cell>25.72</cell><cell>80.92%</cell></row><row><cell>2</cell><cell>120</cell><cell>5.09</cell><cell>32.68</cell><cell>87.50%</cell></row><row><cell>3 †</cell><cell>30</cell><cell>3.47</cell><cell>24.60</cell><cell>73.33%</cell></row><row><cell>4 †</cell><cell>59</cell><cell>4.90</cell><cell>30.56</cell><cell>94.92%</cell></row><row><cell>5</cell><cell>337</cell><cell>5.85</cell><cell>37.39</cell><cell>97.92%</cell></row><row><cell>6</cell><cell>161</cell><cell>5.22</cell><cell>33.70</cell><cell>94.41%</cell></row><row><cell>7</cell><cell>97</cell><cell>5.69</cell><cell>36.86</cell><cell>89.69%</cell></row><row><cell>8</cell><cell>322</cell><cell>4.90</cell><cell>30.32</cell><cell>94.72%</cell></row><row><cell>9</cell><cell>95</cell><cell>4.83</cell><cell>30.02</cell><cell>89.47%</cell></row><row><cell>10</cell><cell>82</cell><cell>6.45</cell><cell>37.88</cell><cell>92.68%</cell></row><row><cell>Overall</cell><cell>1455</cell><cell>5.02</cell><cell>31.97</cell><cell>89.56%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,170.45,84.49,270.80,7.94"><head>Table 1 :</head><label>1</label><figDesc>Description of the submi ed runs to the 2018 TREC CORE track.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,61.14,83.64,489.71,111.27"><head>Table 3 :</head><label>3</label><figDesc>Document judgment statistics per user, with Krippendor α computed with respect to the NIST QREL set. Ratings Participant Judgments Avg. Terms / Doc Irrelevant Somewhat Relevant Fully Relevant Unique Judgments α Agreement</figDesc><table coords="4,67.80,143.03,471.35,51.88"><row><cell>5</cell><cell>507</cell><cell>348.83</cell><cell>189</cell><cell>73</cell><cell>245</cell><cell>391</cell><cell>0.529</cell></row><row><cell>9</cell><cell>60</cell><cell>474.30</cell><cell>31</cell><cell>18</cell><cell>11</cell><cell>28</cell><cell>0.431</cell></row><row><cell>8</cell><cell>30</cell><cell>369.70</cell><cell>19</cell><cell>9</cell><cell>2</cell><cell>17</cell><cell>0.253</cell></row><row><cell>10</cell><cell>19</cell><cell>454.74</cell><cell>14</cell><cell>2</cell><cell>3</cell><cell>11</cell><cell>-0.126</cell></row><row><cell>Overall</cell><cell>616</cell><cell>365.34</cell><cell>253</cell><cell>102</cell><cell>261</cell><cell>447</cell><cell>0.507</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,53.50,84.49,240.54,433.76"><head>Table 4 :</head><label>4</label><figDesc>Comparing the submi ed runs with additional runs as reference. Pairwise t-tests were conducted using a Bonferroni correction against the RRF run, with † and ‡ representing signi cance at p &lt; 0.05 and p &lt; 0.01, respectively.</figDesc><table coords="5,56.59,142.64,232.67,375.61"><row><cell cols="2">System</cell><cell></cell><cell>AP</cell><cell cols="2">NDCG@k</cell><cell>RBP ϕ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell>20</cell><cell>0.80</cell><cell>0.95</cell></row><row><cell cols="2">Title</cell><cell></cell><cell cols="3">0.227  ‡ 0.394  ‡ 0.379  ‡ 0.442  ‡ 0.320  ‡</cell></row><row><cell cols="2">RRF</cell><cell></cell><cell cols="3">0.355 0.548 0.527 0.611 0.452</cell></row><row><cell cols="2">BestUQV</cell><cell></cell><cell cols="3">0.417  ‡ 0.685  ‡ 0.632  ‡ 0.733  ‡ 0.526  ‡</cell></row><row><cell cols="3">RMITEXTGIGADA5</cell><cell cols="3">0.258  ‡ 0.424  † 0.388  ‡ 0.464  ‡ 0.351  †</cell></row><row><cell cols="2">RMITFDA4</cell><cell></cell><cell cols="3">0.311 0.473 0.454 0.520 0.404</cell></row><row><cell cols="3">RMITUQVBestDM2</cell><cell cols="3">0.318 0.541 0.505 0.597 0.423</cell></row><row><cell cols="3">RMITUQVDBFDM3</cell><cell cols="3">0.375 0.533 0.522 0.584 0.464</cell></row><row><cell cols="6">RMITUQVDBFNZDM1 0.385 0.557 0.538 0.614 0.481</cell></row><row><cell></cell><cell></cell><cell>AP</cell><cell cols="2">NDCG@10</cell><cell>NDCG@20</cell></row><row><cell></cell><cell>1.00</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.75</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.50</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.25</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Metric Score</cell><cell>0.00 1.00</cell><cell>RBP 0.50</cell><cell cols="2">RBP 0.80</cell><cell>RBP 0.95</cell></row><row><cell></cell><cell>0.75</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.50</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.25</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.00</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">RMITEXTGIGADA5 RMITFDA4 RMITUQVBestDM2</cell><cell cols="2">RMITUQVDBFDM3 RMITUQVDBFNZDM1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,56.72,689.74,16.65,3.26"><p>TREC  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2018" xml:id="foot_1" coords="1,89.82,689.74,124.83,3.26"><p>CORE Track: h p://trec-core.github.io/2018</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="1,321.00,674.63,86.25,3.26"><p>h ps://github.com/stedolan/jq</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="1,321.00,683.04,84.31,3.26"><p>h ps://github.com/diazf/indri</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. is work was supported by the <rs type="funder">Australian Research Council's Discovery Projects Scheme</rs> (<rs type="grantNumber">DP170102231</rs>), by an <rs type="funder">Australian</rs> <rs type="programName">Government Research Training Program Scholarship</rs>, and by a grant from the <rs type="funder">Mozilla Foundation</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QcjuBD4">
					<idno type="grant-number">DP170102231</idno>
				</org>
				<org type="funding" xml:id="_3dqPb67">
					<orgName type="program" subtype="full">Government Research Training Program Scholarship</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>e per-topic residual based on a bag-of-words BM25 run across every query variation for each topic, by the mean residual of RBP 0.95. High residuals imply that many retrieved documents were not judged. A high variance in residuals implies that some UQVs surface many unjudged documents, whereas others surface mostly judged documents. Diamonds represent the TREC title query for each topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>RMIT (with assistance from one local friend) submi ed ve unique runs to the 2018 TREC CORE track of which two were automatic, and three manual. All of the submi ed runs met the organizers' quality criteria for inclusion into the judgment pool. Similar to last year, we focused on user query variations and rank fusion to generate highly robust runs, with our best system RMITUQVDBFNZDM1 achieving an AP score of 0.385. RMIT placed fourth in the overall standings with respect to the number of unique, relevant documents found, with a total of 35. Outcomes pertaining to our research goals were mixed. Providing shallow judgments to improve double fusion e ectiveness (RQ1) did result in an improved aggregate score, however, it did not yield statistically signi cant results. For RQ2, our ndings show that improvements can be obtained by "hedging your bets" across an information need with external corpora for improved robustness. Our hypothesis for RQ3 mirrors the conclusion drawn by Mo at et al. <ref type="bibr" coords="7,484.03,483.54,13.33,4.20" target="#b14">[15]</ref>, suggesting that collections built without query variations are less robust than those that employ UQVs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,70.23,100.11,71.79,3.26;8,188.30,100.11,16.79,3.26;8,233.58,100.11,16.45,3.26;8,88.10,116.05,41.06,3.26" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Omas</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vries</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="667" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,124.02,5.18,3.26;8,119.52,124.02,174.53,3.26;8,70.23,130.70,151.62,6.16" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,204.66,124.02,89.38,3.26;8,70.23,131.99,46.14,3.26">UQV100: A test collection with query variability</title>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Omas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,129.00,130.70,29.32,6.16">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="725" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,139.96,223.81,3.26;8,70.23,146.64,185.44,6.16" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,212.36,139.96,81.68,3.26;8,70.23,147.93,79.76,3.26">Retrieval consistency in the presence of query variations</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mo At</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Omas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,162.82,146.64,29.32,6.16">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="395" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,154.61,224.57,6.16;8,70.23,162.58,125.23,6.16" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,162.14,155.90,106.08,3.26">Risk-reward trade-o s in rank fusion</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Benham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,281.25,154.61,13.56,6.16;8,70.23,162.58,64.65,6.16">Proc. Aust. Doc. Comp. Symp</title>
		<meeting>Aust. Doc. Comp. Symp</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,171.84,224.58,3.26;8,69.99,178.52,224.82,6.16;8,70.23,186.49,33.41,6.16" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,161.94,179.81,105.13,3.26">RMIT at the 2017 TREC CORE track</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Benham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T</forename><surname>Damessie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,281.22,178.52,13.59,6.16;8,70.23,186.49,13.73,6.16">Proc. TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,195.75,223.81,3.26;8,70.23,202.43,224.58,6.16;8,70.23,211.69,14.51,3.26" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,269.18,195.75,24.87,3.26;8,70.23,203.72,132.61,3.26">Towards e cient and e ective query variant generation</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Benham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mackenzie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,215.90,202.43,37.64,6.16">Proc. DESIRES</title>
		<meeting>DESIRES</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="62" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,219.66,223.81,3.26;8,70.23,226.34,224.58,6.16;8,70.23,235.60,58.94,3.26" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,225.98,219.66,68.06,3.26;8,70.23,227.63,177.11,3.26">Reciprocal rank fusion outperforms condorcet and individual rank learning methods</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bü Cher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,261.83,226.34,30.08,6.16">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.23,242.28,224.58,6.16;8,70.23,251.55,42.67,3.26" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,114.67,243.57,128.28,3.26">Single query optimisation is the root of all evil</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,254.96,242.28,36.71,6.16">Proc. DESIRES</title>
		<meeting>DESIRES</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">100</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,89.40,223.99,3.26;8,334.39,96.08,223.81,6.16;8,334.23,105.34,47.55,3.26" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,502.83,89.40,55.55,3.26;8,334.39,97.37,155.47,3.26">Gauging the quality of relevance assessments using inter-rater agreement</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T</forename><surname>Damessie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">P</forename><surname>Nghiem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,506.05,96.08,30.46,6.16">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1089" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,113.31,223.81,3.26;8,334.39,119.99,189.39,6.16" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,494.84,113.31,63.37,3.26;8,334.39,121.28,82.54,3.26">Presentation ordering e ects on assessor agreement</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T</forename><surname>Damessie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,430.20,119.99,29.33,6.16">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="723" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,129.25,223.81,3.26;8,334.39,135.93,151.50,6.16" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,398.70,129.25,159.50,3.26;8,334.39,137.22,45.60,3.26">Improving the estimation of relevance models using large external corpora</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,393.04,135.93,29.32,6.16">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,145.19,223.81,3.26;8,334.39,151.87,185.24,6.16" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,447.53,145.19,110.68,3.26;8,334.39,153.16,85.75,3.26">Hypothesis testing for the risk-sensitive evaluation of retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Dinc ¸er</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,433.26,151.87,29.32,6.16">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,161.13,224.00,3.26;8,334.39,167.81,224.58,6.16;8,334.39,177.07,14.51,3.26" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,431.42,161.13,126.96,3.26;8,334.39,169.10,70.18,3.26">Answering the call for a standard reliability measure for coding data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Krippendor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,411.56,167.81,110.78,6.16">Communication Methods and Measures</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="89" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,185.04,223.81,3.26;8,334.39,191.72,191.93,6.16" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,406.53,185.04,151.67,3.26;8,334.39,193.01,35.03,3.26">Rank-biased precision for measurement of retrieval e ectiveness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,374.72,191.72,90.28,6.16">ACM Trans. Information Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,200.98,224.00,3.26;8,334.21,207.66,224.76,6.16;8,334.39,216.92,14.51,3.26" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,472.61,200.98,85.78,3.26;8,334.21,208.95,123.37,3.26">Pooled evaluation over query variations: Users are as diverse as systems</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mo At</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,472.52,207.66,30.24,6.16">Proc. CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1759" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,224.89,223.81,3.26;8,334.39,231.57,224.64,6.16;8,334.39,240.84,47.55,3.26" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,419.70,224.89,138.50,3.26;8,334.39,232.87,100.99,3.26">A family of rank similarity measures based on maximized e ectiveness di erence</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,443.66,231.57,90.71,6.16">IEEE Trans. Know. &amp; Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2865" to="2877" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,334.39,248.81,224.58,3.26;8,334.39,255.48,224.57,6.16;8,334.39,263.45,33.41,6.16" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,394.37,256.78,139.21,3.26">Uwaterloomds at the trec 2017 common core track</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abualsaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ghelani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,545.91,255.48,13.05,6.16;8,334.39,263.45,13.73,6.16">Proc. TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
