<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.09,72.00,309.38,12.64">NHK STRL at TREC 2018 Incident Streams track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,83.57,116.65,74.73,10.53;1,158.31,114.95,1.41,7.44"><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
							<email>miyazaki.t-jw@nhk.or.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">NHK STRL (Science and Technology Research Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,175.47,116.65,94.42,10.53;1,269.90,114.95,1.41,7.44"><forename type="first">Kiminobu</forename><surname>Makino</surname></persName>
							<email>makino.k-gg@nhk.or.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">NHK STRL (Science and Technology Research Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,287.06,116.65,57.80,10.53"><forename type="first">Yuka</forename><surname>Takei</surname></persName>
							<email>takei.y-ek@nhk.or.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">NHK STRL (Science and Technology Research Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.01,116.65,84.48,10.53"><forename type="first">Hiroki</forename><surname>Okamoto</surname></persName>
							<email>okamoto.h-iw@nhk.or.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">NHK STRL (Science and Technology Research Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,469.64,116.65,47.32,10.53"><forename type="first">Jun</forename><surname>Goto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NHK STRL (Science and Technology Research Laboratories</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.09,72.00,309.38,12.64">NHK STRL at TREC 2018 Incident Streams track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B9C5D704438D2CEDE99F07F22787E42</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe NHK STRL's models for the TREC 2018 Incident Streams track. The goal of this track is classifying incident related Tweets into information types such as Infor-mationWanted and EmergingThreats. The number of provided pieces of training data is about 2,000, which is not enough for current machine learning methods. We propose two models to overcome this small amount of data scenario: a knowledge base-based model and a model that considers meta-information. In addition, we used two bag-of-words baseline models, a multi-layer perceptron-based one and a support vector machine-based one, for comparison. Evaluation results show that our models can classify Tweets with a rather high F1 score.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter has been playing an important role in getting to know what is occurring in the real world. There are many applications that use Twitter information, such as disaster monitoring <ref type="bibr" coords="1,90.36,535.12,105.02,9.59" target="#b0">(Ashktorab et al., 2014;</ref><ref type="bibr" coords="1,199.80,535.12,90.47,9.59" target="#b11">Mizuno et al., 2016)</ref> and news material gathering <ref type="bibr" coords="1,196.18,548.67,94.09,9.59" target="#b18">(Vosecky et al., 2013;</ref><ref type="bibr" coords="1,72.00,562.22,89.50,9.59" target="#b4">Hayashi et al., 2015)</ref>. NHK has also been studying news material gathering targeted at disasters and societal accidents/incidents <ref type="bibr" coords="1,236.12,589.31,54.15,9.59;1,72.00,602.86,24.85,9.59" target="#b15">(Takei et al., 2017;</ref><ref type="bibr" coords="1,99.59,602.86,88.18,9.59" target="#b8">Makino et al., 2018;</ref><ref type="bibr" coords="1,190.51,602.86,74.70,9.59" target="#b3">Goto et al., 2018)</ref>. Our models judge Tweets on the basis of whether they are able to be used as news material or not and classifies the Tweets into news genres, such as fires, floods, and car accidents. The basis of the models can be adopted for various applications. Therefore, we can adopt our models with little customization for the Incident Streams (IS) track of the Text REtrieval Conference (TREC) 2018.</p><p>The task of the IS track for TREC 2018 is classifying incident related Tweets along with  <ref type="table" coords="1,463.12,572.21,4.09,9.59">1</ref>. The Tweets are classified along with the information type, as listed with the number of Tweets belonging to each respective class in Table <ref type="table" coords="1,415.63,612.86,4.09,9.59" target="#tab_0">2</ref>.</p><p>As shown in Table <ref type="table" coords="1,402.72,626.41,4.09,9.59" target="#tab_0">2</ref>, a training set does not include much data, and it is unbalanced for classes, so we developed models by taking the following strategies into account.</p><p>• We put a high priority both on micro and macro F1 scores when choosing a finegrained model, even though the IS track measures models by using only the micro F1 score. This is because data sets are unbalanced, so the micro F1 score may not show the actual accuracy.</p><p>• To overcome the small size of the training data, we use a knowledge base (KB) or meta-information such as timestamp to expand data.</p><p>• We use only Tweets provided as training/development data: we do not aggregate Tweets for training. This is because we have only a few pieces of data, so we cannot evaluate the effects of the aggregated data precisely.</p><p>We developed two models for this task: a KBbased model and a model that considers metainformation. We also use multi-layer perceptron (MLP)-and support vector machine (SVM)-based bag-of-words (BoW) baseline models for comparison. We describe our models in detail in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are many studies on classifying Tweets by information type. <ref type="bibr" coords="2,152.77,428.00,110.73,9.59" target="#b17">Toriumi and Baba (2016)</ref> focus on retweets -one important user behavior -to classify Tweets that are related to disasters into information types. <ref type="bibr" coords="2,165.30,468.65,85.22,9.59" target="#b14">Stowe et al. (2016)</ref> propose methods that use meta-information -timestamps, whether a tweet is a retweet or not, and so onto classify disaster-related Tweets into information types. <ref type="bibr" coords="2,103.50,522.84,98.95,9.59" target="#b5">Kanouchi et al. (2015)</ref> classify Tweets according to the people who are mentioned in the Tweet by using meta-information in addition to bag-of-words as input features.</p><p>Also, many methods for extracting and identifying Tweets for certain tasks are reported. <ref type="bibr" coords="2,72.00,606.70,97.35,9.59" target="#b18">Vosecky et al. (2013)</ref> propose a novel multifaceted topic model for discovering topics on Twitter. <ref type="bibr" coords="2,122.25,633.80,95.99,9.59" target="#b4">Hayashi et al. (2015)</ref> use streaming NMF (non-negative matrix factorization) with filter for "hijacking topics," which are pseudo-topics caused by advertisements and automatic messages, to detect topics. <ref type="bibr" coords="2,173.75,688.00,65.52,9.59" target="#b7">Li et al. (2018)</ref> use a naive Bayes classifier with an iterative self-training strategy to learn from unlabelled data and extracts disaster-related Tweets. <ref type="bibr" coords="2,194.61,728.65,95.66,9.59" target="#b2">Caragea et al. (2016)</ref> adopt a convolutional neural network (CNN) to identify informative tweets during disaster events. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">KB-based model (run1)</head><p>The KB-based model is based on the model proposed in <ref type="bibr" coords="2,346.39,549.22,97.58,9.59" target="#b10">(Miyazaki et al., 2018)</ref>, which is inspired by relational graph convolutional networks (R-GCN) <ref type="bibr" coords="2,336.67,576.32,112.89,9.59" target="#b13">(Schlichtkrull et al., 2018)</ref>. An overview of the model is given in Figure <ref type="figure" coords="2,429.71,589.87,4.09,9.59">1</ref>. The model expands each word in a Tweet using WordNet <ref type="bibr" coords="2,491.91,603.42,33.63,9.59;2,307.28,616.97,25.45,9.59" target="#b9">(Miller, 1995)</ref> as a KB to encode texts (Figure <ref type="figure" coords="2,482.58,616.97,3.94,9.59">2</ref>). Then, the encoded vector is fed into a feed-forward neural network to classify the information type and give a necessity score. We give details on the methods used to do this below.</p><p>We use the following notation to describe the methods in this section; E is a set of entry words for a KB, R is a set of relation in the KB, T is a set of terms in the data set, and d KB and d BoW are the size of the dimensions for KB-and BoWbased embedding respectively.</p><p>Text encoding Consider a Tweet containing n entry words that mentions e 1 , e 2 , ..., e n , each of which is contained in a KB, e i ∈ E. The vector m e i r ∈ 1 |d KB | represents the entry word e i based on the set of other entities connected through directed relation r:</p><formula xml:id="formula_0" coords="3,129.84,146.21,160.43,34.72">m e i r = ∑ e ′ ∈Nr(e i ) W (1) e ′ ,<label>(1)</label></formula><p>where, W</p><p>(1) e ′ ∈ 1 d KB is an embedding of entry word e ′ from embedding matrix W (1) ∈ R |E|×d KB , and N r (e) is the neighborhood function, which returns all nodes e ′ connected to e by directed relation r.</p><p>Then, m e i r for all r are transformed by using a weighted sum:</p><formula xml:id="formula_1" coords="3,121.74,292.80,168.52,51.05">v e i = ∑ r∈R a ir ReLU(m e i r ) a i = σ(W (2) • ⃗ e i ) , (2)</formula><p>where, a i ∈ 1 |R| is the attention that entry word e i represented by one-hot vector ⃗ e i pays to all relations using weight matrix W (2) ∈ R |E|×|R| , and σ and ReLU are sigmoid and the rectified linear unit activation functions, respectively. Here, we obtain embedded vector v e i for entry word e i .</p><p>Since the number of entry words in Tweets is sparse, we also encode, and use all the terms in Tweets regardless of if they are entry words or not. We represent each term by:</p><formula xml:id="formula_2" coords="3,141.95,496.74,148.32,13.96">v w j = W (3) • ⃗ w j ,<label>(3)</label></formula><p>where ⃗ w j is a one-hot vector of size |T | where the value j represents the frequency of w j in a Tweet, and</p><formula xml:id="formula_3" coords="3,90.48,547.62,167.46,12.13">W (3) ∈ R |T |×d BoW is a weight matrix.</formula><p>Overall, a Tweet representing vector v is obtained by concatenating mean vectors of KB-and BoW-based encoding:</p><formula xml:id="formula_4" coords="3,112.00,602.98,174.02,44.74">v =   1 n n ∑ i=1 v e i , 1 m m ∑ j=1 v w j   , (<label>4</label></formula><formula xml:id="formula_5" coords="3,286.03,625.86,4.24,9.59">)</formula><p>where m is the number of words that a Tweet includes.</p><p>The model is almost the same as that of <ref type="bibr" coords="3,72.00,701.55,94.65,9.59" target="#b10">(Miyazaki et al., 2018</ref>), but we do not share the weight matrix for KB-and BoW-based encoding because |T | is too small, so if the weight matrix is shared, the effect of BoW embedding may be too small. Also, we concatenate KB-and BoW-based encoding vectors instead of adding them together. This is because the dimensions of input for KBand BoW-based encoding is far different, so the embedding dimensions (d KB and d BoW ) should be different. Therefore, we cannot add these vectors.</p><p>Classifying To estimate the information type of a given Tweet, we use 1-layer feed-forward neural network with classification output layers:</p><formula xml:id="formula_6" coords="3,369.93,204.20,151.37,12.32">o = softmax W (4) v , (<label>5</label></formula><formula xml:id="formula_7" coords="3,521.30,206.92,4.24,9.59">)</formula><p>where</p><formula xml:id="formula_8" coords="3,307.28,229.30,218.27,25.32">W (4) ∈ R class×d KB +d BoW is a weight ma- trix.</formula><p>Then, an importance score is also obtained as:</p><formula xml:id="formula_9" coords="3,339.65,280.72,181.65,46.21">h = softmax W (5) [o , v] score = h 0 × 1.0 + h 1 × 0.75 + h 2 × 0.5 + h 3 × 0.25 , (<label>6</label></formula><formula xml:id="formula_10" coords="3,521.30,299.51,4.24,9.59">)</formula><p>where W (5) ∈ R 4×d KB +d BoW +class is a weight matrix. The importance is classified into one of four classes in the training data, "Critical," "High," "Medium," and "Low." Therefore, we use a weighted sum by using the classification score h as the weight, and obtain an importance score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Meta-information considering model (run3)</head><p>The model that considers meta-information is based on a simple MLP model. An overview of the model is given in Figure <ref type="figure" coords="3,413.26,490.89,4.09,9.59">3</ref>. In addition to texts, this model uses date/time categories and event type information as the input of MLP. It encodes each input to each vector. Then, encoded vectors are concatenated and fed into a feed-forward neural network to classify the information type, and give a necessity score. We give details of the method below. d BoW and d M eta are the size of the dimensions for text BoW-and meta-information-based embedding.</p><p>Each input encoding Tweets are arranged in chronological order on the basis of the time at which they were created. The frequency and cumulative distribution function (CDF) of Tweets regarding elapsed time from the first Tweet of each event is shown in Figure <ref type="figure" coords="3,416.73,701.55,4.09,9.59" target="#fig_1">4</ref>. We divide Tweets into three classes along with their time difference from an event that has occurred so that each class has the same number of Tweets for each event. Then, those classes are date/time categories. The number of event types is six, as shown in Figure <ref type="figure" coords="4,248.88,267.72,4.09,9.59">1</ref>. ⃗ d ∈ 1 3 and ⃗ t ∈ 1 6 are one-hot vectors for date/time categories and event types respectively. We represent each term by:</p><formula xml:id="formula_11" coords="4,112.50,327.16,173.53,33.71">v w = W (6) • m ∑ j=1 ⃗ w j + b (6) , (<label>7</label></formula><formula xml:id="formula_12" coords="4,286.03,339.02,4.24,9.59">)</formula><formula xml:id="formula_13" coords="4,114.43,366.30,175.84,30.05">v d = W (7) • ⃗ d , (8) v t = W (8) • ⃗ t ,<label>(9)</label></formula><p>where W (6) ∈ R |T |×d BoW , W (7) ∈ R 3×d M eta , and W (8) ∈ R 6×d M eta are weight matrices and b (7) ∈ 1 d BoW is a bias. Overall, a Tweet representing vector ⃗ v all is obtained by concatenating vectors of text, date/time, and event type encoding:</p><formula xml:id="formula_14" coords="4,122.08,498.84,163.64,10.77">v all = ReLU([v w , v d , v t ]) . (<label>10</label></formula><formula xml:id="formula_15" coords="4,285.72,499.07,4.54,9.59">)</formula><p>Classifying To estimate the information type and importance score of a given Tweet, we use each 1-layer feed-forward neural network with a classification output layer:</p><formula xml:id="formula_16" coords="4,117.71,582.37,168.01,13.27">o = softmax W * • v all + b * , (<label>11</label></formula><formula xml:id="formula_17" coords="4,285.72,585.10,4.54,9.59">)</formula><p>where</p><formula xml:id="formula_18" coords="4,102.05,605.61,111.55,12.13">W * ∈ R k×(d BoW +2•d M eta</formula><p>) is a weight matrix, and b * ∈ 1 k is a bias, for which k is a class for information types and 4 is for the importance score. Then, the importance score is calculated the same as eq. ( <ref type="formula" coords="4,129.22,661.98,3.86,9.59" target="#formula_9">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">MLP-and SVM-based baseline models (run2 and run4)</head><p>The MLP-based baseline model is a simple MLP model. The model uses eq. ( <ref type="formula" coords="4,200.84,728.65,9.09,9.59" target="#formula_16">11</ref>) by inputting text BoW vector v w as v all , where W * ∈ R k×d BoW is a weight matrix. The SVM baseline model is inputted with concatenated vector [v w , v d , v t ], and it uses a linear kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data set and settings</head><p>Our experiments were based on the data set provided for the TREC 2018 IS track, which was a Twitter data set with original json data of Tweet (including text, user information, timestamp, and so on) related to incidents. The data set contained approximately 2,000 Tweets for training/development and more than 20,000 Tweets for testing. Each Tweet in the training/development  <ref type="table" coords="5,147.25,139.96,3.94,9.59">1</ref>), information type (as shown in Table <ref type="table" coords="5,114.39,153.51,3.94,9.59" target="#tab_0">2</ref>), information importance ("Critical," "High," "Medium," and "Low"), and indicator terms that human annotators selected when choosing an information type. The models were trained with 10-fold cross validation to find the best setting and all models were used as ensemble models for test data. We excluded words appeared fewer than five times in training sets.</p><p>All neural network-based models were learned with the Adam optimizer (Kingma and Ba, 2014), based on categorical cross-entropy loss, and models were implemented in Chainer <ref type="bibr" coords="5,234.79,303.22,55.48,9.59;5,72.00,316.77,23.48,9.59" target="#b16">(Tokui et al., 2015)</ref>.</p><p>The SVM-based model was implemented by using scikit-learn <ref type="bibr" coords="5,140.47,344.53,101.19,9.59" target="#b12">(Pedregosa et al., 2011)</ref>.</p><p>The hyperparameters used were as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KB-based model</head><p>The minibatch size was 10; the hidden layer size for KB-based encoding was 1,500, for BoW-based encoding is 500, classifier for information type is 500, and classifier for importance score is 250; There were 100 training iterations, with early stopping based on development performance; WordNet 3.1 <ref type="bibr" coords="5,226.23,463.25,64.04,9.59" target="#b9">(Miller, 1995)</ref> with the nltk toolkit <ref type="bibr" coords="5,166.69,476.80,102.60,9.59" target="#b1">(Bird and Loper, 2004)</ref> was used as the KB; The relations shown in Table <ref type="table" coords="5,284.81,490.34,5.45,9.59" target="#tab_2">3</ref> were used. We used channel weights W c = |cmax| |c| , where |c| is the number of information types c appearing in the training data, and |c max | is that of the most-frequent class, for calculating losses in model training.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-inforation considering model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Table <ref type="table" coords="5,334.52,189.69,5.45,9.59" target="#tab_3">4</ref> presents the results for our models. Each scores in the table is the mean average of each of the 10-fold cross validations using trainig data.</p><p>We can see that Meta-information considering model is the bast result in the micro F1 score, and MLP-based baseline is the best in the macro F1 score.</p><p>Table <ref type="table" coords="5,345.64,285.46,5.45,9.59" target="#tab_4">5</ref> shows the results using test data. This is the official results of TREC 2018 IS track. Values in the brackets shows the rank in the all methods submitted to the track<ref type="foot" coords="5,421.99,324.09,3.99,7.01" target="#foot_0">1</ref> . The target metric of the main task of the track is the macro F1 score, and that of the sub task is the information priority. Information priority is measured with the mean squared error between the output and the gold data that obtained by human annotators, so the lower is the better.</p><p>In the table, MLP-based baseline model is better in both micro and macro F1 scores in our methods. Our KB-based method achieved the best result in the sub task of the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Our Meta-information considering model and MLP-based baseline model achieve rather better scores in both Micro and Macro F1 scores. This is because we have only a small training data, so it is better to have parameters need to be learned. Meta-information considering model and MLPbased baseline model have rather smaller number of parameters, so these methods fit for the task.</p><p>On the other hand, KB-based model has rather smaller differences between the two results -using training data and test data. As we mentioned, we can use only a small data for training, so test data includes many OOVs (see Table <ref type="table" coords="5,477.01,670.90,3.94,9.59">6</ref>). This is one of the big reasons of that all our models drop the F1 scores when using test data for evaluation.</p><p>Our KB-based model can consider OOVs, so the effect of OOVs is rather small. Meta-information considering model is the best in Micro F1 score in the experiment using training data, but the third place in that using test data. We used timestamp information as Meta-information, which is affected by the physical distance between the incident occurred and the Tweet posted. This is because if the distance is far, the Twitter user only can know about the incident from TV, Web news and some other sources. Therefore, the post may be made very after the incident occurred. Incidents included in test set are occurred in various places including non-English countries/regions. Tweets included in data set are written in English, so most of Tweet for these incidents may delay. This may make our Metainformation considering model work with limited improvement for test set.</p><p>Our models achieved the best results in TREC 2018 IS track in information priority estimation sub task. We regard estimating information priority as one of the tasks of multi-task learning, which may work well in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we described models for classifing incident-related Tweets along with information type. We used four models, a KB-based model, model considers meta-information, and MLP-and SVM-based baseline models. We showed that our models -the KB-based model and model considers Meta-information -outperformed baseline methods.</p><p>Using our models in combination is left as our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,307.73,262.82,217.36,8.76"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Overall architecture of our KB-based model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,307.28,526.07,218.27,8.76;4,307.28,538.03,119.15,8.76"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Frequency of Tweets regarding elapsed time from first Tweet of each event</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,250.35,597.04,39.90,9.59;5,72.00,610.36,218.26,10.68;5,72.00,623.91,218.26,10.68;5,72.00,637.69,218.27,9.59;5,72.00,651.24,218.27,9.59;5,72.00,664.79,179.51,9.59;5,72.00,687.85,218.26,9.74;5,72.00,701.55,218.27,9.59;5,72.00,715.10,218.27,9.59;5,72.00,728.65,218.28,9.59;5,72.00,742.19,218.28,9.59;5,72.00,755.74,177.53,9.59"><head></head><label></label><figDesc>The hidden layer size for text encoding d BoW was 200, and the other's encoding d M eta was 10. The hidden layer size of the classifier was 200. One hundred training iterations, with early stopping based on development performance, were used. MLP-and SVM-based baseline model All of the hidden layer sizes for the MLP-based baseline model were 200; One hundred training iterations, with early stopping based on development performance, were used. The LinearSVC module was used for the SVM-based baseline model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,307.28,375.87,218.28,205.93"><head>Table 2 :</head><label>2</label><figDesc>List of classes and number of pieces of data in training/development set.</figDesc><table coords="1,314.60,398.50,203.62,96.32"><row><cell>Class</cell><cell>#</cell><cell>Class</cell><cell>#</cell></row><row><cell>Request-SearchAndRescue</cell><cell>0</cell><cell>Request-GoodsServices</cell><cell>0</cell></row><row><cell>Request-InformationWanted</cell><cell>10</cell><cell>CallToAction-Volunteer</cell><cell>2</cell></row><row><cell>CallToAction-MovePeople</cell><cell>26</cell><cell>CallToAction-Donations</cell><cell>15</cell></row><row><cell>Report-FirstPartyObservation</cell><cell>28</cell><cell>Report-Weather</cell><cell>41</cell></row><row><cell>Report-ThirdPartyObservation</cell><cell>15</cell><cell>Report-EmergingThreats</cell><cell>36</cell></row><row><cell>Report-SignificantEventChange</cell><cell>34</cell><cell>Report-MultimediaShare</cell><cell>127</cell></row><row><cell>Report-ServiceAvailable</cell><cell>15</cell><cell>Report-Factoid</cell><cell>140</cell></row><row><cell>Report-Official</cell><cell>52</cell><cell>Report-CleanUp</cell><cell>2</cell></row><row><cell>Report-Hashtags</cell><cell>4</cell><cell>Other-PastNews</cell><cell>12</cell></row><row><cell>Other-ContinuingNews</cell><cell>250</cell><cell>Other-Advice</cell><cell>39</cell></row><row><cell>Other-Sentiment</cell><cell>132</cell><cell>Other-Discussion</cell><cell>51</cell></row><row><cell>Other-Irrelevant</cell><cell>163</cell><cell>Other-Unknown</cell><cell>26</cell></row><row><cell>Other-KnownAlready</cell><cell>112</cell><cell></cell><cell></cell></row></table><note coords="1,307.28,518.01,218.27,9.59;1,307.28,531.56,218.28,9.59;1,307.28,545.11,218.27,9.59;1,307.28,558.66,218.28,9.59;1,307.28,572.21,152.99,9.59"><p>their information type. In this shared task, we have around 2,000 Tweets as training/development data, and more than 20,000 Tweets as test data. Each data set includes Tweets related to several kinds of incident, as listed in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,72.00,72.97,218.27,76.58"><head>Table 3 :</head><label>3</label><figDesc>Relations that we used for KB-based model.</figDesc><table coords="5,72.00,82.14,218.27,67.41"><row><cell>Lemmas, Hypernyms, Hyponyms, PartMeronyms,</cell></row><row><cell>SubstanceMeronyms, MemberHolonyms, Entailments</cell></row><row><cell>set had labels that indicate the incident name (as</cell></row><row><cell>shown in Table</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,307.28,72.97,218.26,70.87"><head>Table 4 :</head><label>4</label><figDesc>Results of the classifying by information type using training data as 10-fold cross validation.</figDesc><table coords="5,316.17,95.71,200.47,48.13"><row><cell>Model</cell><cell cols="2">Micro F1 Macro F1</cell></row><row><cell>KB-based</cell><cell>0.557</cell><cell>0.328</cell></row><row><cell>Meta-information considering</cell><cell>0.598</cell><cell>0.369</cell></row><row><cell>MLP-based baseline</cell><cell>0.597</cell><cell>0.375</cell></row><row><cell>SVM-based baseline</cell><cell>0.546</cell><cell>0.304</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,72.00,72.97,370.35,195.59"><head>Table 5 :</head><label>5</label><figDesc>Results of the classifying by information type using test data.</figDesc><table coords="6,72.00,83.76,370.35,184.80"><row><cell>Model</cell><cell></cell><cell cols="2">Micro F1 Macro F1</cell><cell>Information Priority</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Lower is better)</cell></row><row><cell cols="2">KB-based</cell><cell>0.120</cell><cell>0.497 (13)</cell><cell>0.060 (1)</cell></row><row><cell cols="3">Meta-information considering 0.114</cell><cell>0.542 (7)</cell><cell>0.061 (2)</cell></row><row><cell cols="2">MLP-based baseline</cell><cell>0.119</cell><cell>0.551 (5)</cell><cell>0.062 (3)</cell></row><row><cell cols="2">SVM-based baseline</cell><cell>0.088</cell><cell>0.465 (21)</cell><cell>0.066 (4)</cell></row><row><cell cols="2">TREC Median</cell><cell>0.083</cell><cell>0.478</cell><cell>0.093</cell></row><row><cell cols="3">Table 6: Comparing vocabulary size of data sets. Train-</cell><cell></cell></row><row><cell cols="3">ing (all) means all vocabulary, and training (5+) means</cell><cell></cell></row><row><cell cols="3">vocabuary of words that appeared more than 5 times in</cell><cell></cell></row><row><cell>training data.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Vocabulary size # of OOVs</cell><cell></cell></row><row><cell>Test</cell><cell>43,117</cell><cell>-</cell><cell></cell></row><row><cell>Training (all)</cell><cell>4,476</cell><cell>40,413</cell><cell></cell></row><row><cell>Training (5+)</cell><cell>619</cell><cell>42,540</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,326.75,747.07,22.92,7.88"><p>TREC</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2018" xml:id="foot_1" coords="5,374.25,747.07,151.29,7.88;5,307.28,757.03,182.02,7.88"><p>IS track accepts 39 methods from 12 research groups, so the rank has the range of 1 to 39,</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The KB-based method is based on the method that the first author studied when visiting the <rs type="institution">University of Melbourne</rs>. The authors greatly appreciate <rs type="person">Professor Timothy Baldwin</rs>, Associate <rs type="person">Professor Trevor Cohn</rs>, and <rs type="person">Dr. Afshin Rahimi</rs> for their useful advices.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,307.28,301.07,218.26,8.76;6,318.19,312.02,207.35,8.76;6,318.19,322.98,152.17,8.76" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,420.55,312.02,104.99,8.76;6,318.19,322.98,95.72,8.76">Tweedr: Mining twitter to inform disaster response</title>
		<author>
			<persName coords=""><forename type="first">Zahra</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manojit</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ISCRAM</note>
</biblStruct>

<biblStruct coords="6,307.28,344.07,218.26,8.76;6,318.19,355.03,207.36,8.76;6,318.19,366.08,207.35,8.55;6,318.19,376.95,207.35,8.76;6,318.19,387.91,32.94,8.76" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,468.96,344.07,56.58,8.76;6,318.19,355.03,84.28,8.76">Nltk: the natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,426.48,355.12,99.07,8.55;6,318.19,366.08,207.35,8.55;6,318.19,377.04,19.14,8.55">Proceedings of the ACL 2004 on Interactive poster and demonstration sessions</title>
		<meeting>the ACL 2004 on Interactive poster and demonstration sessions</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="6,307.28,409.00,218.26,8.76;6,318.19,419.96,207.35,8.76;6,318.19,430.92,207.36,8.76;6,318.19,441.87,207.35,8.76;6,318.19,452.83,207.35,8.76;6,318.19,463.79,17.43,8.76" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,377.63,419.96,147.90,8.76;6,318.19,430.92,203.04,8.76">Identifying informative messages in disaster events using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Silvescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrea</forename><forename type="middle">H</forename><surname>Tapia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,328.85,441.96,196.69,8.55;6,318.19,452.92,152.13,8.55">International Conference on Information Systems for Crisis Response and Management</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="137" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,484.88,218.27,8.76;6,318.19,495.84,207.35,8.76;6,318.19,506.80,207.37,8.76;6,318.19,517.85,207.35,8.55;6,318.19,528.81,207.36,8.55;6,318.19,539.68,139.77,8.76" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,381.50,495.84,144.04,8.76;6,318.19,506.80,162.65,8.76">Automatic tweet detection based on data specified through news production</title>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuka</forename><surname>Takei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kiminobu</forename><surname>Makino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,507.73,506.89,17.82,8.55;6,318.19,517.85,207.35,8.55;6,318.19,528.81,144.32,8.55">Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion</title>
		<meeting>the 23rd International Conference on Intelligent User Interfaces Companion<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-03-07">2018. March 07-11, 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,560.77,218.27,8.76;6,318.19,571.73,207.35,8.76;6,318.19,582.68,207.36,8.76;6,318.19,593.64,207.36,8.76;6,318.19,604.69,207.35,8.55;6,318.19,615.56,146.00,8.76" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,467.24,571.73,58.30,8.76;6,318.19,582.68,207.36,8.76;6,318.19,593.64,11.42,8.76">Real-time topr topic detection on twitter with topic hijack filtering</title>
		<author>
			<persName coords=""><forename type="first">Kohei</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Takanori</forename><surname>Maehara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Masashi</forename><surname>Toyoda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,347.31,593.73,178.24,8.55;6,318.19,604.69,207.35,8.55;6,318.19,615.65,49.22,8.55">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,636.65,218.26,8.76;6,318.19,647.61,207.35,8.76;6,318.19,658.57,207.35,8.76;6,318.19,669.53,207.36,8.76;6,318.19,680.58,207.35,8.55;6,318.19,691.53,207.36,8.55;6,318.19,702.40,207.36,8.76;6,318.19,713.36,102.10,8.76" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,506.17,647.61,19.37,8.76;6,318.19,658.57,207.35,8.76;6,318.19,669.53,13.49,8.76">Who caught a cold?-identifying the subject of a symptom</title>
		<author>
			<persName coords=""><forename type="first">Shin</forename><surname>Kanouchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eiji</forename><surname>Aramaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hiroshi</forename><surname>Ishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,351.85,669.62,173.70,8.55;6,318.19,680.58,207.35,8.55;6,318.19,691.53,207.36,8.55;6,318.19,702.49,85.58,8.55">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1660" to="1670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,307.28,734.45,218.26,8.76;6,318.19,745.41,207.36,8.76;6,318.19,756.46,70.29,8.55" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m" coord="6,485.94,734.45,39.60,8.76;6,318.19,745.41,139.44,8.76">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,72.00,67.17,218.26,8.76;7,82.91,78.13,207.35,8.76;7,82.91,89.09,207.35,8.76;7,82.91,100.05,207.36,8.76;7,82.91,111.01,90.28,8.76" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,177.12,78.13,113.15,8.76;7,82.91,89.09,207.35,8.76;7,82.91,100.05,25.37,8.76">Disaster response aided by tweet classification with a domain adaptation approach</title>
		<author>
			<persName coords=""><forename type="first">Hongmin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Doina</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nic</forename><surname>Herndon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,118.43,100.14,171.83,8.55;7,82.91,111.10,31.54,8.55">Journal of Contingencies and Crisis Management</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="27" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,131.57,218.26,8.76;7,82.91,142.53,207.35,8.76;7,82.91,153.49,207.37,8.76;7,82.91,164.54,207.36,8.55;7,82.91,175.41,123.31,8.76" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,155.21,142.53,135.05,8.76;7,82.91,153.49,146.94,8.76">Classification of tweets about reported events using neural networks</title>
		<author>
			<persName coords=""><forename type="first">Kiminobu</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuka</forename><surname>Takei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,254.20,153.58,36.07,8.55;7,82.91,164.54,207.36,8.55;7,82.91,175.50,53.31,8.55">Proceedings of the 4th Workshop on Noisy User-generated Text (W-NUT)</title>
		<meeting>the 4th Workshop on Noisy User-generated Text (W-NUT)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,195.97,218.26,8.76;7,82.91,206.93,207.35,8.76;7,82.91,217.89,12.45,8.76" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,167.52,195.97,122.74,8.76;7,82.91,206.93,27.36,8.76">Wordnet: a lexical database for english</title>
		<author>
			<persName coords=""><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,121.14,207.02,115.50,8.55">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,238.46,218.27,8.76;7,82.91,249.42,207.35,8.76;7,82.91,260.37,207.35,8.76;7,82.91,271.42,207.36,8.55;7,82.91,282.29,75.26,8.76" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,182.87,249.42,107.39,8.76;7,82.91,260.37,105.14,8.76">Twitter geolocation using knowledge-based methods</title>
		<author>
			<persName coords=""><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Afshin</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,213.09,260.46,77.17,8.55;7,82.91,271.42,207.36,8.55;7,82.91,282.38,20.15,8.55">Proceedings of the 4th Workshop on Noisy User-generated Text (W-NUT)</title>
		<meeting>the 4th Workshop on Noisy User-generated Text (W-NUT)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,302.86,218.27,8.76;7,82.91,313.82,207.35,8.76;7,82.91,324.78,207.35,8.76;7,82.91,335.73,207.35,8.76;7,82.91,346.69,207.35,8.76;7,82.91,357.74,207.35,8.55;7,82.91,368.61,207.36,8.76;7,82.91,379.57,37.36,8.76" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,210.99,324.78,79.27,8.76;7,82.91,335.73,207.35,8.76;7,82.91,346.69,80.19,8.76">Wisdom x, disaana and d-summ: Large-scale nlp systems for analyzing textual big data</title>
		<author>
			<persName coords=""><forename type="first">Junta</forename><surname>Mizuno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Masahiro</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kiyonori</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong-Hoon</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Kloetzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chikara</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kentaro</forename><surname>Torisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,188.31,346.78,101.96,8.55;7,82.91,357.74,207.35,8.55;7,82.91,368.70,177.21,8.55">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="263" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,400.14,218.26,8.76;7,82.91,411.09,207.36,8.76;7,82.91,422.05,207.35,8.76;7,82.91,433.01,207.35,8.76;7,82.91,443.97,207.37,8.76;7,82.91,454.93,156.28,8.76" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,241.01,433.01,49.26,8.76;7,82.91,443.97,113.59,8.76">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,209.80,444.06,80.48,8.55;7,82.91,455.02,68.66,8.55">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">2011. Oct</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,475.50,218.26,8.76;7,82.91,486.45,207.36,8.76;7,82.91,497.41,207.36,8.76;7,82.91,508.37,207.37,8.76;7,82.91,519.33,124.51,8.76" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,109.19,497.41,181.08,8.76;7,82.91,508.37,59.47,8.76">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,160.80,508.46,129.47,8.55;7,82.91,519.42,16.59,8.55">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,539.90,218.27,8.76;7,82.91,550.86,207.35,8.76;7,82.91,561.81,207.36,8.76;7,82.91,572.86,207.35,8.55;7,82.91,583.82,207.36,8.55;7,82.91,594.69,42.61,8.76" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,245.99,550.86,44.27,8.76;7,82.91,561.81,162.06,8.76">Identifying and categorizing disaster-related tweets</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Stowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leysia</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Palen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,272.46,561.90,17.81,8.55;7,82.91,572.86,207.35,8.55;7,82.91,583.82,202.70,8.55">Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>The Fourth International Workshop on Natural Language Processing for Social Media</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,615.26,218.26,8.76;7,82.91,626.22,207.35,8.76;7,82.91,637.17,207.36,8.76;7,82.91,648.22,207.35,8.55;7,82.91,659.09,207.36,8.76;7,82.91,670.05,73.62,8.76" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,137.75,626.22,152.51,8.76;7,82.91,637.17,82.05,8.76">Tweet extraction for news production considering unreality</title>
		<author>
			<persName coords=""><forename type="first">Yuka</forename><surname>Takei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ichiro</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,182.68,637.26,107.60,8.55;7,82.91,648.22,207.35,8.55;7,82.91,659.18,49.98,8.55">Proceedings of the 31st Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 31st Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="370" to="375" />
		</imprint>
		<respStmt>
			<orgName>The National University (Phillippines)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.00,690.62,218.26,8.76;7,82.91,701.58,207.35,8.76;7,82.91,712.53,207.37,8.76;7,82.91,723.58,207.35,8.55;7,82.91,734.54,207.35,8.55;7,82.91,745.41,207.36,8.76;7,82.91,756.37,72.22,8.76" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,153.77,701.58,136.49,8.76;7,82.91,712.53,139.93,8.76">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName coords=""><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenta</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shohei</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,240.91,712.62,49.36,8.55;7,82.91,723.58,207.35,8.55;7,82.91,734.54,207.35,8.55;7,82.91,745.50,184.14,8.55">Proceedings of workshop on machine learning systems (Learn-ingSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)</title>
		<meeting>workshop on machine learning systems (Learn-ingSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,67.17,218.26,8.76;7,318.19,78.13,207.37,8.76;7,318.19,89.18,207.35,8.55;7,318.19,100.05,207.35,8.76;7,318.19,111.01,206.08,8.76" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,461.80,67.17,63.74,8.76;7,318.19,78.13,134.62,8.76">Real-time tweet classification in disaster situation</title>
		<author>
			<persName coords=""><forename type="first">Fujio</forename><surname>Toriumi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Seigo</forename><surname>Baba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,476.19,78.22,49.36,8.55;7,318.19,89.18,207.35,8.55;7,318.19,100.14,79.79,8.55">Proceedings of the 25th International Conference Companion on World Wide Web</title>
		<meeting>the 25th International Conference Companion on World Wide Web</meeting>
		<imprint>
			<publisher>International World Wide Web Conferences Steering Committee</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="117" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,130.93,218.26,8.76;7,318.19,141.89,207.35,8.76;7,318.19,152.85,207.36,8.76;7,318.19,163.90,207.36,8.55;7,318.19,174.77,207.36,8.76;7,318.19,185.73,24.79,8.76" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="7,394.13,141.89,131.41,8.76;7,318.19,152.85,65.10,8.76">Dynamic multi-faceted topic discovery in twitter</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Vosecky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Wai-Ting</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wilfred</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,403.45,152.94,122.09,8.55;7,318.19,163.90,207.36,8.55;7,318.19,174.86,135.90,8.55">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="879" to="884" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
