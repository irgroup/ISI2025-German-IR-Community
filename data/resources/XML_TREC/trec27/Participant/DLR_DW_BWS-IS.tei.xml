<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,60.09,55.67,491.83,20.73;1,54.87,83.56,502.26,20.73;1,121.41,111.46,369.17,20.73">Classification of Incident-related Tweets: Tackling Imbalanced Training Data using Hybrid CNNs and Translation-based Data Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,119.28,151.27,59.22,9.50;1,178.50,149.00,1.41,6.99"><forename type="first">Anna</forename><surname>Kruspe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
								<orgName type="institution">Bauhaus University Institute of Data Science</orgName>
								<address>
									<settlement>Jena, Weimar</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,189.81,151.27,56.52,9.50;1,246.32,149.00,1.41,6.99"><forename type="first">Jens</forename><surname>Kersten</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
								<orgName type="institution">Bauhaus University Institute of Data Science</orgName>
								<address>
									<settlement>Jena, Weimar</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.63,151.27,75.07,9.50;1,332.70,149.00,1.70,6.99"><forename type="first">Matti</forename><surname>Wiegmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
								<orgName type="institution">Bauhaus University Institute of Data Science</orgName>
								<address>
									<settlement>Jena, Weimar</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.27,151.27,54.98,9.50;1,403.25,149.00,1.88,6.99"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
								<orgName type="institution">Bauhaus University Institute of Data Science</orgName>
								<address>
									<settlement>Jena, Weimar</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,414.08,151.27,70.07,9.50;1,484.15,149.00,1.41,6.99"><forename type="first">Friederike</forename><surname>Klan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Aerospace Center (DLR)</orgName>
								<orgName type="institution">Bauhaus University Institute of Data Science</orgName>
								<address>
									<settlement>Jena, Weimar</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,60.09,55.67,491.83,20.73;1,54.87,83.56,502.26,20.73;1,121.41,111.46,369.17,20.73">Classification of Incident-related Tweets: Tackling Imbalanced Training Data using Hybrid CNNs and Translation-based Data Augmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">428ADD74378FE40AA81E93ABBFEDC5C7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present our four approaches submitted to the 2018 Text REtrieval Conference (TREC) Incident Streams (IS) track. One of the main challenges in this track is the lack of training data for certain classes defined in the ontology. We therefore take measures to expand the provided data; in a first step, additional tweets are manually selected from CrisisLexT26 and EMTerms for all underrepresented classes, ensuring a minimum number of 50 tweets per class. Using this expanded data, we train four models. The first is a baseline model that uses a logistic regression classifier on word statistics. The second is a state-of-the-art CNN which considers different frame widths on pre-trained word embeddings. This model is then extended with two identical CNN branches trained on the CrisisLexT26 and CrisisNLP data sets, and a posterior fusion network (third approach). Since all of these models still suffer from a lack of training data, more training examples are generated through a data augmentation technique using automatic round-trip translation. The fourth presented approach is identical to the third one, but is trained on this augmented data set. Finally, we describe our importance ranking procedure for tweets. Our method is implemented by weighting the average importance of the detected class and the tweet's relevance obtained with a classifier trained on the CrisisLexT26 data set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The 2018 Text REtrieval Conference (TREC) Incident Streams (IS) track serves as an evaluation for the classification of tweets into incident-related classes. A class ontology, an annotated training data set, and a test data set without annotations were provided. The ontology comprises 25 classes describing a variety of topics during an incident, such as "Report-ServiceAvailable", "Other-Sentiment", "Request-SearchAndRescue", or "CallToAction-Donations". The training set contains around 1300 tweets related to 6 incidents, while the test data set is composed of around 22,000 tweets from 13 events. Submissions were expected to assign a class to each of these tweets as well as an importance score and a ranking within each event. We focused on training fully automatic models in order to contribute to these tasks. This paper describes our four submissions to the challenge. We start by describing our data extension and augmentation procedures, then present our four classification approaches and a method for calculating the tweets' importance. Following this, we present an analysis of the results and finish with a small conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DATA EXTENSION AND AUGMENTATION</head><p>The main issue we came across while developing classification models was the selection of the training data. Both a class ontology and matching data were supplied for the challenge; however, some of the classes are underrepresented in the training data with just a handful of examples or, in extreme cases, none at all. Even the well-represented classes do not have the amount of training examples usually necessary for training classification models. For this reason, we first supplement the training data with manually selected tweets. These tweets are taken from the CrisisLexT26 <ref type="bibr" coords="1,475.14,397.86,10.58,8.64" target="#b4">[5]</ref>, <ref type="bibr" coords="1,492.39,397.86,11.62,8.64" target="#b5">[6]</ref> and EMTerms <ref type="bibr" coords="1,311.98,409.81,11.62,8.64" target="#b6">[7]</ref> data sets. We aimed at obtaining at least 50 examples per class. The ontology only provides rough descriptions of each class, and in many cases, there were not enough examples to obtain a clear idea what characteristics defined each class. In addition, many of the class definitions allow for overlapping annotations (e.g. a tweet could be both a "MultimediaShare" and a "FirstPartyObservation") or assume some sort of apriori information (e.g. "KnownAlready") which leads to highly subjective judgement. These factors make the process of selecting additional training data challenging. Manual selection is employed to obtain a base set of tweets for each class. Since this approach is tedious and costly, an automatic method was also developed for expanding the training data even further. This is done by running the existing tweets through an automatic translation engine to translate them into another language, then translating them back into English in the same way, introducing some lexical and semantic variety while keeping the meaning intact. This style of round-trip translation was first described by Lau et al. <ref type="bibr" coords="1,311.98,636.96,10.58,8.64" target="#b0">[1]</ref>. Ostyakov<ref type="foot" coords="1,369.35,635.29,3.49,6.05" target="#foot_0">1</ref> then proposed employing it for the "Toxic Comments" Kaggle challenge <ref type="foot" coords="1,431.29,647.25,3.49,6.05" target="#foot_1">2</ref> , where Lee et al. won first prize with this approach <ref type="foot" coords="1,391.19,659.20,3.49,6.05" target="#foot_2">3</ref> . Ostyakov implemented the translation using the "TextBlob" Python library <ref type="foot" coords="2,202.38,50.76,3.49,6.05" target="#foot_3">4</ref> . In contrast with this method, we do not perform the translation in a scripted manner; instead, we manually run chunks of the training data through Google Translate. This allows for a larger variety of translation languages, which are selected randomly from all available. In this way, we expand the amount of training examples per class to around 500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED MODELS</head><p>In this section, we will describe the four models designed for classifying tweets into the classes provided in the ontology. The first of these models (A) is a baseline model primarily using logistic regression on frequency vectors; it is trained only on the original data. The other three (B to D) employ Convolutional Neural Networks (CNNs). The first two of these models are trained on the provided training data set plus the manually selected additional data. The last model (D) also uses the examples obtained with the augmentation procedure described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Logistic regression</head><p>In our first approach, several basic features are extracted from the tweets:</p><p>• The word 1-, 2-, and 3-gram frequencies, including stop words and only using terms that occur at least three times in total • The character 1-, 2-, and 3-gram frequencies, including stop words and only using terms that occur at least three times in total • The sentiment of the teaser message, as determined by</p><p>Vader <ref type="bibr" coords="2,95.61,405.91,11.62,8.64" target="#b7">[8]</ref> • The number of likes and the number of retweets • Whether there is media attached and whether the user is verified These features are fed into a logistic regression model, which is then trained on the 25 annotated classes. Only the original training data is used as some of the tweet metadata is not available for the additional data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. CNN</head><p>The first deep model that we tested is a Convolutional Neural Network (CNN) as proposed by Kim <ref type="bibr" coords="2,233.54,534.80,10.58,8.64" target="#b2">[3]</ref>. A visualization is provided in figure <ref type="figure" coords="2,159.70,546.76,3.74,8.64" target="#fig_0">1</ref>. This approach was specifically developed for classifying sentences into diverse categories, e.g. question types or sentiments. In contrast to the logistic regression model, the CNN only processes the tweet text data. At the input, the text data is transformed into an embedding using pre-trained weights. In the original model, this is done in two parallel channels: One with fixed embedding weights (static) and one which allows them to be adapted (non-static). Then, several convolutional layers with different kernel widths are applied in parallel. Global max-pooling is performed for each of these layers, and the results are concatenated. This new embedding is then fed into a fully connected layer with dropout to determine the final class. This type of model has successfully been used for crisis-related data <ref type="bibr" coords="2,498.34,52.43,10.58,8.64" target="#b1">[2]</ref>. Instead of generating an embedding from text data as in the original approach, we use a pre-trained embedding specific to crisis-related tweets <ref type="bibr" coords="2,407.06,88.29,11.62,8.64" target="#b3">[4]</ref> (only as a non-static channel). For the convolutional layers, kernel sizes of 3, 4, and 5 with 100 filters each are used, as suggested by Kim. Neither fixing the embedding nor adding filters or convolutional layers improve the results significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Fusion CNN</head><p>According to preliminary manual inspection, the previously described CNN performs fairly well for the classification task, but suffers from the lack of training data for some classes, in addition to the unbalanced distribution between classes. This is expressed in a tendency to ignore, under-/overvalue, or overtrain on certain classes. Two approaches for overcoming this issue were implemented: A fusion CNN trained on the expanded data set, and a fusion CNN with data augmentation. In a first idea, the model is supplemented with sub-models trained on the existing crisis-related tweet data sets CrisisNLP <ref type="bibr" coords="2,311.98,302.49,11.62,8.64" target="#b3">[4]</ref> and CrisisLexT26. These data sets both contain manual annotations. While the class ontologies used for annotating these data sets are not identical to that provided in the Incident Streams track, there is some overlap, as they refer to a similar problem statement. CNNs identical to the one described above (see section III-B) are trained for each of these data sets. Then, the outputs of these models are combined with that of the CNN trained directly on the TREC-IS data, and a fusion network is added to transform these results into a final class decision. For this step, not only the individual models' outputs (i.e. class probabilities) are taken into account, but also the outputs from the previous layer (i.e. a CNN embedding). The underlying idea here is that the two additional models will produce embeddings and intermediate classifications useful for solving the TREC-IS problem. Two versions of the CNN that is directly trained on the TREC-IS data are also integrated: One with the previously described crisis-specific work embeddings, and one with general-purpose GloVe embeddings <ref type="foot" coords="2,500.67,516.02,3.49,6.05" target="#foot_4">5</ref> . The weights of the pre-trained networks are fixed, while the weights of the networks directly trained on TREC-IS and those of the fusion network are adapted during training. A schematic of this architecture is presented in figure <ref type="figure" coords="2,470.13,565.51,3.74,8.64" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Fusion CNN with augmented data</head><p>The second approach to overcome the lack of training data consists in the use of the augmented data described above (see section II). The described fusion network iss trained on a combination of the original training data, the manually selected additional tweets, and the examples automatically generated via round-trip translation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMPORTANCE SCORING PROCEDURE</head><p>Submissions to the incident streams track also required an importance score for each test tweet, and a ranking according to these scores. No definition or criteria for such an importance scoring were provided. The training data annotations contain a "priority" field, although we are not sure if this corresponds to importance. We decided on a two-fold metric: One contributing factor is the a-priori importance v c of each class, while the other is an invididual importance value v i for each tweet. The individual importances v i are obtained from another Yoon Kim CNN trained on the CrisisLexT26 data set. In addition to class annotations, this data set also contains annotations regarding the individual "informativeness" of each tweet. This might be somewhat conceptually different from "importance", but we assume that there is a correlation. The weighted softmax likelihoods of the highest (inf 1 ) and second-highest (inf 2 ) importance class are taken into account. Their maximum is retained as an importance value specific to each individual tweet:</p><formula xml:id="formula_0" coords="4,122.71,289.04,177.31,9.65">v i = max(inf 1 , 0.5inf 2 )<label>(1)</label></formula><p>On the other hand, class-wise importance v c is calculated in two ways: First, by running the training data set through the described informativeness classifier and calculating the percentage of tweets per class that received the most "informative" label; second, by calculating the same percentage based on the "priority" information provided in the training data itself. Both results look relatively similar for most classes. Disparities occur for classes with a lack of training data; in these cases, values are chosen based on those of similar classes.</p><p>Finally, the harmonic mean of the importance attributed to the detected class and the informativeness obtained with the CrisisLexT26 model is used as the final tweet score:</p><formula xml:id="formula_1" coords="4,146.98,474.94,153.04,23.23">I = 2 v i * v c v i + v c<label>(2)</label></formula><p>V. RESULTS AND DISCUSSION During evaluation, annotators were allowed to assign multiple classes to a tweet. For this reason, evaluation was performed in two modes: "Any-type", where a result was considered correct if the recognized class was part of the ground truth; and "Multi-type", where results were calculated on a 1-vs.-all basis. This means that for the second mode, systems only receive a score of 1/N for a correctly classified tweet where the annotator chose N classes, and can therefore not obtain perfect over-all scores. The "any-type" and "multi-type" results are shown in figures 3a and 3b respectively. They allow for a number of interesting observations. Considering the "any-type" mode, the basic Yoon Kim CNN obtains the best recall and F1 values at 0.77 and 0.55, while the baseline logistic regression model has the best precision at 0.48. The more complex fusion CNN performs slightly worse, both when trained on the expanded and on the augmented data set. For the "multi-type" evaluation, the trend is different: The baseline model performs worst of all, while the three CNN models all have identical recall and F1 values. For precision, each addition to the CNN increases the result slightly. At first sight, this discrepancy is surprising. It becomes clearer, however, when considering that the "any-type" evaluation was essentially performed on a tweet-wise basis while the "multi-type" evaluation weights all classes equally. As described before, the classes are not equally distributed. This effect can be further analyzed using the class-wise scores as shown in figure <ref type="figure" coords="4,392.22,171.98,3.74,8.64" target="#fig_5">4</ref> Since these classes also appear with high prevalence in the evaluation data, the model achieves high precision. A similar effect, although much weaker, can be observed for the basic CNN. In contrast, the fusion CNNs trained on both the expanded and the augmented training data perform somewhat worse for the overrepresented classes, leading to the lower results in the "any-type" evaluation. However, they often achieve better results on underrepresented classes, explaining the higher or equal "multi-type" results. Despite the over-all decrease, it is interesting to see that those models fulfil their purpose, making classes with little original training data more approachable. This could be an interesting direction for future research. The choice of model here is dependent on the goal of the final system -i.e., whether a high "any-type" F1 is desired or whether the model is expected to be able to detect underrepresented classes better. Still, the over-all results leave a lot of room for improvement. Figure <ref type="figure" coords="4,344.30,446.95,4.98,8.64" target="#fig_5">4</ref> also demonstrates that it is very hard to train the model for low-resource classes. In a production system, this problem would probably be solved by obtaining more training data, or possibly by accepting varying priors for the classes. As mentioned above, the ontology's chosen classes are not mutually exclusive, which is reflected in the evaluation strategy. A future model could be trained to perform multilabeling as well. Results for the importance scoring task are nearly identical for all four approaches at a mean squared error of 0.16. This is higher than the reported median error of all participants. Since our scoring procedures takes the recognized class into account, errors from this other task are propagated. In addition, ground-truth annotations were performed on a discrete scale instead of continuous values; in contrast, our scores represent a relative instead of an absolute measure of importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>For the 2018 TREC Incident Streams track, we submitted the results of four automatic text classification approaches. Our main contribution is the study of strategies to cope with the irregularities of the data: Some classes defined in the ontology have no or just very few corresponding examples in the   training data. In addition, the class definitions are somewhat vague and overlapping. As a first remedy, we manually collect more training data from existing Twitter data sets. We then institute a personal baseline for the Incident Streams task by training a logistic regression classifier on hand-crafted features based on word and character frequencies as well as tweet metadata, only using the original training data. Building on the state of the art in text classification, we also train a CNN as proposed by Kim on the expanded data. This CNN has been shown to perform well on other crisis-related data sets, but struggles here due to the limited training data. For this reason, we expand the architecture with two identical networks trained on existing crisis-related data sets. The three individual networks are consolidated with a subsequent fusion network. Finally, a data augmentation method employing round-trip translation is introduced. The same network as before is trained on this augmented data set. We also propose a method for rating the importance of tweets with regard to incidents. This is done by taking into account both the a-priori importance of the detected semantic class and the informativeness of the individual tweet obtained with a model trained on a different data set. Results show that the basic CNN performs best over-all at an F1 measure of 0.55. The fusion CNN approach, trained on the expanded and augmented data sets, demonstrates improvements for classes underrepresented in the original training set, which was the motivation for their development. Evaluation was performed in a different mode than training by allowing multiple annotations per tweet. A future system could, for example, improve on these results by also allowing this or by re-defining the classes, by using more training data, or by further developing these approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,183.76,321.89,244.47,8.64;3,48.96,83.59,514.07,230.44"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: CNN for text classification as proposed by Kim [3].</figDesc><graphic coords="3,48.96,83.59,514.07,230.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,48.96,661.20,514.07,8.82;3,48.96,673.15,353.73,8.82;3,151.78,410.60,308.45,242.91"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2:A visualization of the fusion networks, consisting of sub-networks trained on CrisisLexT26, CrisisNLP, and TREC-IS data. The CNNs are identical to the one proposed in experiment B (also see figure1).</figDesc><graphic coords="3,151.78,410.60,308.45,242.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,395.95,171.98,167.08,8.64;4,311.98,183.93,251.06,8.64;4,311.98,195.89,251.06,8.64;4,311.98,207.84,251.06,8.64;4,311.98,219.80,251.06,8.64;4,311.98,231.75,251.06,8.64"><head></head><label></label><figDesc>. In addition to the individual F1 values for each class, this plot also includes the number of original training examples available per class. The distribution of the evaluation examples is roughly similar. It becomes clear that the baseline model is strongly biased towards the frequent classes while ignoring the ones with few training examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,125.54,184.56,151.81,7.77;5,331.34,184.56,158.44,7.77"><head></head><label></label><figDesc>(a) Results for the "any-type" evaluation.(b) Results for the "multi-type" evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,208.76,201.24,194.49,8.64;5,98.63,61.88,205.63,115.56"><head>Fig. 3 :</head><label>3</label><figDesc>Fig.3: Over-all results for the four approaches.</figDesc><graphic coords="5,98.63,61.88,205.63,115.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,48.96,683.08,514.07,8.64;5,48.96,695.03,43.60,8.64;5,100.37,246.55,411.25,428.66"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Class-wise F1 measures for the four approaches (colored bars) and numbers of training examples per class (transparent gray bars).</figDesc><graphic coords="5,100.37,246.55,411.25,428.66" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,323.44,682.56,125.95,6.91"><p>https://github.com/PavelOstyakov/toxic</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,323.44,692.43,236.89,6.91"><p>https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,323.44,702.29,239.10,6.91;1,311.98,711.26,55.35,6.91"><p>https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/ discussion/52557</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,60.42,711.26,106.07,6.91"><p>https://github.com/sloria/textblob</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,323.44,711.26,123.30,6.91"><p>https://nlp.stanford.edu/projects/glove/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,67.22,466.76,232.80,6.91;6,67.22,475.73,232.80,6.91;6,67.22,484.69,176.47,6.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,184.16,466.76,115.86,6.91;6,67.22,475.73,59.56,6.91">Unsupervised Prediction of Acceptability Judgements</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lappin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,145.57,475.73,154.45,6.91;6,67.22,484.69,84.47,6.91">53rd Annual Conference of the Association of Computational Linguistics</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07">July 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,494.00,232.80,6.91;6,67.22,502.97,232.80,6.91;6,67.22,511.94,232.80,6.91;6,67.22,520.90,232.80,6.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,152.36,494.00,147.66,6.91;6,67.22,502.97,232.80,6.91;6,67.22,511.94,40.73,6.91">Crisis Event Extraction Service (CREES) -Automatic Detection and Classification of Crisis-related Content on Social Media</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Burel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,124.89,511.94,175.14,6.91;6,67.22,520.90,119.70,6.91">15th International Conference on Information Systems for Crisis Response and Management</title>
		<meeting><address><addrLine>Rochester, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,530.21,232.80,6.91;6,67.22,539.18,232.80,6.91;6,67.22,548.15,90.48,6.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,96.74,530.21,188.21,6.91">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,67.22,539.18,229.48,6.91">2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10">October 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,557.46,232.80,6.91;6,67.22,566.42,232.80,6.91;6,67.22,575.39,232.80,6.91;6,67.22,584.35,82.60,6.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,198.67,557.46,101.35,6.91;6,67.22,566.42,196.67,6.91">Twitter as a lifeline: Humanannotated twitter corpora for NLP of crisis-related messages</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,281.99,566.42,18.04,6.91;6,67.22,575.39,211.92,6.91">Tenth International Conference on Language Resources and Evaluation</title>
		<meeting><address><addrLine>Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,593.66,232.80,6.91;6,67.22,602.63,232.80,6.91;6,67.22,611.60,232.80,6.91;6,67.22,620.56,55.95,6.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,229.34,593.66,70.69,6.91;6,67.22,602.63,229.67,6.91">CrisisLex: A Lexicon for Collecting and Filtering Microblogged Communications in Crises</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vieweg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,79.23,611.60,161.33,6.91">AAAI Conference on Weblogs and Social Media</title>
		<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">June 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,629.87,232.80,6.91;6,67.22,638.84,232.80,6.91;6,67.22,647.81,232.80,6.91;6,67.22,656.77,187.42,6.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,209.13,629.87,90.89,6.91;6,67.22,638.84,218.37,6.91">What to Expect When the Unexpected Happens: Social Media Communications Across Crises</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vieweg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,67.22,647.81,232.80,6.91;6,67.22,656.77,56.79,6.91">ACM 2015 Conference on Computer Supported Cooperative Work and Social Computing</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-03">March 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,666.08,232.80,6.91;6,67.22,675.05,232.80,6.91;6,67.22,684.01,232.80,6.91;6,67.22,692.98,72.14,6.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,216.30,666.08,83.73,6.91;6,67.22,675.05,121.57,6.91">EMTerms 1.0: A Terminological Resource for Crisis Tweets</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Temnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vieweg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,207.86,675.05,92.16,6.91;6,67.22,684.01,190.78,6.91">International Conference on Information Systems for Crisis Response and Management</title>
		<meeting><address><addrLine>Kristiansand, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,67.22,702.29,232.80,6.91;6,67.22,711.26,232.80,6.91;6,330.24,53.72,232.80,6.91;6,330.24,62.69,76.72,6.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,143.16,702.29,156.86,6.91;6,67.22,711.26,132.03,6.91">VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,216.14,711.26,83.88,6.91;6,330.24,53.72,176.27,6.91">Proceedings of the Eighth International Conference on Weblogs and Social Media</title>
		<meeting>the Eighth International Conference on Weblogs and Social Media<address><addrLine>Ann Arbor, Michigan, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">June 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
