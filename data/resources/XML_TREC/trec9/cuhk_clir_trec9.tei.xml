<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,225.68,61.77,147.06,12.88;1,120.56,77.06,354.13,11.10">TREC-9 CLIR at CUHK Disambiguation by Similarity Values Between Adjacent Words</title>
				<funder ref="#_VCBXkx3">
					<orgName type="full">DARPA, USA</orgName>
				</funder>
				<funder ref="#_cZ4mmNJ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,225.44,106.76,58.16,10.80"><forename type="first">Honglan</forename><surname>Jin</surname></persName>
							<email>hljin@se.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Systems Engineering and Engineering Management Department</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.44,106.76,74.64,10.80"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
							<email>kfwong@se.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Systems Engineering and Engineering Management Department</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,225.68,61.77,147.06,12.88;1,120.56,77.06,354.13,11.10">TREC-9 CLIR at CUHK Disambiguation by Similarity Values Between Adjacent Words</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2AC530C9E4D1BB7320DBED1D5014097D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We investigated the dictionary-based query translation method combining the translation disambiguation process using statistic cooccurrence information trained from the provided corpus.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We believe that neighboring words tend to be related in contextual meaning and have higher chance of co-occurrence particularly if adjacent words (two or more) compose a phrase. The correct translation equivalents of co-occurrence pattern in a source language are more likely to co-occur in a target language documents than in conjunction with any incorrect translation equivalents within a certain range of contextual window size.</p><p>In this work, we tested several methods to calculate the degree of co-occurrence and used them as the basis of disambiguation. Different from most disambiguation methods which usually select one best translation equivalent for a word, we select the best translation equivalent pairs for two adjacent words. The final translated queries are the concatenation of all overlapped adjacent word translation pairs after disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Description</head><p>The well-known vector space modeled SMART information retrieval system, Version 11, is used as our platform. We adopted the weighting strategy for documents and queries as Lnu.Ltu <ref type="bibr" coords="1,81.44,615.68,10.86,9.07" target="#b0">[1,</ref><ref type="bibr" coords="1,92.30,615.68,7.24,9.07" target="#b2">2]</ref>, which has been proved more successful than cosine normalization.</p><p>The queries were produced after query translation and ambiguity resolution. We fed them to the SMART system to get the retrieval result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Translation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bilingual Dictionaries</head><p>A bilingual English to Chinese machine readable dictionary (MRD ) produced by Earth Village (http://www.samlight.com/ev/eng/) is used as our translation resource. This MRD has many entries exactly the same with those in the bilingual dictionary edited by LDC (http://morph.ldc.upenn.edu/Projects/Chinese). The reason we chose Earth Village was that Earth Village provided POS (parts of speech) information. We thought it was useful at the early stage of our experiments but ended up not using it. For phrase translation purpose, we combined three sources: a Chinese to English MRD (http://www.mindspring.com/~paul_denisowski/ cedict.html), Earth Village, and the one from LDC. The Chinese to English MRD was converted to English -&gt;Chinese and we extracted all the phrase translations from the above resources and complied a single phrase level English Chinese MRD. From our previous experiments, we found the more the number of translations for a word, the higher the chance of introducing extraneous translations for this word. For this reason , we used only Earth Village MRD as our word level translation resource . There are 61729 entries, 2.3 translations in average for each word. However, for the 25 queries in TREC-9, each word in the source language (English) has 5 translations in Chinese after the translation by Earth Village MRD.</p><p>Phrase level translation was performed before word level translation. All English words were morphologically transformed to its original word root by using WordNet (http://www.wordnet.com). The root was used as the key to search for its corresponding translations in the dictionary. To perform phrase level translation, we created from bigrams to five-grams composed by adjacent words first in the queries. If a higher gram translation failed, a lower one would be tried until bigram was reached. If it still failed, word level translation was adopted. Otherwise, phrase level translation was performed a nd the same procedure starting from the next word position was repeated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese Segmentation</head><p>The corpus and the translated queries were segmented by using the perl coded software developed by Erik Peterson (http://www.mandarintools.com). But we replaced the original word list dictionary with our own, a word list of Hong Kong style words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post processing after translation</head><p>After the initial translation, we did some pruning based on our previous experience and some ad hoc rules. Earth Village is basically a mainland Chinese language style dictionary while the corpus used is in Hong Kong style Chinese. For the same concept, two styles may have totally different representations in the bilingual dictionary. For the translated segmented queries (mainland style), we did the following pruning:</p><p>1. Delete the translations having longer than five Chinese characters unless there 's only one translation: If a translation is too long (exceed five characters for example ), this translation is highly likely the description of the word meaning instead of direct translation of the word. 2. Delete the translated entries being segmented unless there 's only one translation. If a translated word is segmented, very probably it is because (1) there's no entry in the dictionary for the word segmentation, ( <ref type="formula" coords="2,185.39,538.64,3.92,9.07">2</ref>) it has different translations in China and Hong Kong.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Keep only the first three translations with</head><p>the highest term frequency ( TF) in the corpus. From our previous experiments, translations with high term frequency in the target language tend to have higher chance of being the correct translations than rare appearing ones.</p><p>After the above processing, each word has no more than three translation candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disambiguation</head><p>There are several scenarios of resolving translation ambiguity by using co-occurrence (CO) information.</p><p>First, a NLP parser can be used to recognize all the grammatical sub-components such as a phrase. Then the CO information is used to calculate the coherent values in the target language among the composite words within a phrase. The translation for this phrase is the one that has the highest coherent values among all the translation combinations for the phrase. However, a parser is not always reliable. Further, individual words which are not associated to any phrases are isolated in meaning ; we can do nothing to resolve their translation ambiguity.</p><p>Second, ambiguity is resolved in sentence level rather than phrase level like method one. We create all the translation combinations in the target language for a sentence and choose the one that has the highest coherent values as the final translation. Obviously, as a sentence is usually much longer than a phrase, the number of translation combinations in this method is much larger and thus the computation cost can be too high. Another problem with this method is that when the corpus is not large enough, the coherent values trained from it may be misleading. The longer a sentence is , the more costly is the computation and the larger the corpus is required . The rate of increase of both computation cost and size of the corpus required is exponential.</p><p>Third, the disambiguation is done between two adjacent words. Among all the translation combinations between two words, we choose the pair with the highest coherent values as the final translation. The cost is low and the corpus size requirement is much less restricted. We adopted this method for its easy computation and the corpus condition.</p><p>Co-occurrence information such as mutual information (MI) <ref type="bibr" coords="2,387.11,564.08,15.21,9.07" target="#b4">[ 3]</ref> was used to calculate the degree of cohesion between two words. MI measure however strongly favors rarely appearing words. We apply the methods to calculate the similarity values between all adjacent word pairs in queries to reduce the translation errors.</p><p>If two words always co-occur within a particular contextual range such as adjacent positions, a sentence or even a whole document, they should have similar distribution pattern within that contextual range throughout the document collection. Higher similar distribution means higher degree of co-occurrence pattern or coherent values.</p><p>The correct translation equivalents of co-occurrence pattern in source language is more likely to co-occur in the target language documents than in conjunction with any incorrect translation equivalents within a certain range of contextual window size.</p><p>We calculate this degree of similarity as the inner product of two vectors each representing a word distribution in the collection. For disambiguation purpose, a fine-grained context for a cooccurrence scope is essential. We chose the window size to be a sentence in target language. The dimension of the vectors are the number of windows (or the number of sentences in the collection). The value of each dimension is 1 if a word appears in that sentence and 0 otherwise. We made two assumptions here : a word always appears no more than once in a sentence and the variation of sentence length can be ignored. By considering only the distribution throughout the corpus as the normalization factor, we assigns idf value to each dimension of a vector of a word as the weight, i.e., where N is the total number of documents in the corpus and Nc is the number of documents where the word appears. The similarity of two words by their inner product is the sum of in each dimension where tf(ab) is the cooccurrence indicator (1 or 0) in sentence scope and idf(a), idf(b) are the idf values for word s a and b respectively.</p><p>We calculate similarity value s for all possible pairs of translation between two adjacent nonstopword words in queries and select the translated pairs with the highest similarity value in the target language as the final translations.</p><p>The final translated queries are the concatenation of all overlapped adjacent word translation pairs after disambiguation.</p><p>Our method is different from others in that we did not select the best translation candidate for a word. We select the best translation pairs instead. By considering all overlapping pairs, each word in fact has two translations (except the first and the last words in a sentence). But if a translation has strong similarity value with the translation of the word adjacently before and after it, two translations should be the same.</p><p>There are several features for this arrangement: First, no grammatical boundary such as phrase boundary recognition is needed during disambiguation. Second, even if two adjacent words are not a phrase, many of them are related in contextual meaning and have a higher chance of co -occurrence. Overlapped concatenation makes each word's translation be selected twice. If two translations are the same, such a word appearing in queries in the target language would have higher weighting than a word having two different translations when the TF value is considered in query weighting. We believe the former case would produce more correct translations. If this is the case, more correct translations would enforce higher weighting values, which would help the retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>We submitted two official runs. One was monolingual and the other cross-lingual. However, we will describe more runs here to support our analysis.</p><p>We used all three parts of a query: title, description and narratives. All our queries are long queries. We used SMART Lnu.Ltu weighting and SMART Rocchio query expansion (mono run) before and after query translation (xlingual run). Three parameters of expansion were set to alpha=8, beta=16, gamma=8. For monolingual query expansion, we added 35 terms extracted from the top 10 documents. From our previous experiment, we trained the optimal number of terms to be 10 terms. But as there was a copyright statement at the end of each document, we increased the number to 35 terms. For the same reason, the number to be added for cross-lingual run is increased from 20 terms to 50 terms from the top 20 documents. We also did query expansion before query translation using the corpus from TREC data vol. 5 , the Foreign Broadcast Information Service (FBIS) files. FBIS is more than 400 MB in size and contains many international related documents. The number of expanded terms were 10 terms from the top 10 documents. The translation for the added terms in the source language were done by selecting the first two translations in the dictionary. All the parameters mentioned above</p><formula xml:id="formula_0" coords="3,133.52,363.72,107.94,97.78">) / log( c N N idf = ) ( * ) ( * ) ( b idf a idf ab tf</formula><p>were trained from our pre vious experiments if not otherwise stated.  There are some interesting phenomena from the results. Our final cross-lingual run exceeds its corresponding monolingual run, the performance ratio is 0.2583/0.2419=106.8%. However, if we compare the performance before any query expansions, that ratio is 0.1862/0.2288=81%.</p><p>For the cross-lingual run, the improvement of query expansion (from 0.1862 to 0.2642) before query translation is as high as 42%. We contribute the drastic improvement to the following reasons: First, the corpus "Foreign Broadcast Information Service" seems to contain many relevant documents to the queries in the source language and thus it is ideal for the source of blind relevance feedback. Second, selecting the first two translations for the expanded terms seems to be very successful in this context. Due to the time limitation, we could not investigate carefully on how to select the best translation candidates for isolated terms.</p><p>By looking at the results produced from the final query expansion, the improvement for monolingual is 6% (from 0.2288 to 0.2419), which is reasonable. However, the query expansion after translation led to performance degradation, from 0.2642 to 0.2583 even though the retrieved relevant documents increased from 495 to 514. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>In this section, we present the results from more runs to support our analysis. We aim to compare our proposed method with other related ones such as MI (mutual information) and highest term frequency methods. To do this, we did the following experiments.</p><p>1. The disambiguation is done by selecting the translation pairs with the highest MI value (denoted as sim_mi). MI is calculated as 2. The disambiguation is done by selecting the translation candidate with the highest term frequency appeared in the target corpus (denoted as htf). The similarity measure used in our official runs was used here except idf normalization, i.e., the disambiguation is done by selecting the translation pairs with the highest value of co-occurrence numbers (denoted as sim_tf).</p><p>Table <ref type="table" coords="4,340.91,633.68,5.04,9.07" target="#tab_5">5</ref> shows the retrieval results for the above runs in average precision ( 11-point). These runs were all done by query expansion before and after query translation with the same parameters used in our official cross-lingual runs.  We performed a final experiment trying to support our hypothesis that our overlapped concatenation of best selected translation pairs would enforce more correct translations to have higher weighting if the term frequency factor in the query is properly considered. If this is the case, it would be helpful for retrieval performance. To test this, we did Lnu.ntu weighting retrieval where term frequency factor is "augmented" comparing with Lnu.Ltu weighting.</p><p>The average 11-point recall precision is 0.2649 before the query expansion and 0.2596 after the query expansion. Although the increase is not obvious (0.2642 and 0.2583 in our official crosslingual run), this result gives the highest figure comparing with all Lnu.Ltu runs.</p><p>We also observed consistent retrieval degradation after the final query expansion in all cross-lingual runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion:</head><p>We presented our disambiguation method by using similarity values between all adjacent words in the target language. It is based on the co-occurrence numbers within a sentence scope in the whole collection. On top of that, idf values of a word pair are used to normalize the cooccurrence numbers. We have shown that both co-occurrence number with or without normalization worked better than MI method. In particular, idf normalization is 4.5% (0.2583/0.2473) better than MI method in our experiments. More tests will be performed to further verify the improvement reported here. This is our first participation in TREC. We reckon that this is a good start for our future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,81.44,84.32,200.63,155.71"><head>Table 1 :Official run results</head><label>1</label><figDesc></figDesc><table coords="4,81.44,96.59,200.63,143.44"><row><cell>Run</cell><cell cols="3">11-point Relevant R precision</cell></row><row><cell>CHUHK00CH1</cell><cell>0.2419</cell><cell>552</cell><cell>0.2524</cell></row><row><cell>CHUHK00XEC1</cell><cell>0.2583</cell><cell>514</cell><cell>0.2618</cell></row><row><cell cols="3">Table 1 is our official run results.</cell><cell></cell></row><row><cell cols="4">CHUHK00CH1 is the monolingual run and</cell></row><row><cell cols="2">CHUHK00XEC1 is the</cell><cell cols="2">cross-lingual run .</cell></row><row><cell cols="4">There are 663 relevant documents altogether in</cell></row><row><cell cols="4">TREC-9. Table 2 is the component result for</cell></row><row><cell cols="4">monolingual CHUHK00CH1 run and Table 3 is</cell></row><row><cell cols="3">the component result for cross-lingual</cell><cell></cell></row><row><cell cols="2">CHUHK00XEC1 run.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,81.44,254.72,174.17,66.79"><head>Table 2 : Monolingual component results</head><label>2</label><figDesc></figDesc><table coords="4,87.20,273.17,126.71,48.33"><row><cell>Run</cell><cell>11-point</cell></row><row><cell>Lnu.Ltu</cell><cell>0.2288</cell></row><row><cell>above+expansion (top</cell><cell>0.2419</cell></row><row><cell>10 docs, 35 terms)</cell><cell>(+6%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,81.44,338.96,176.92,104.07"><head>Table 3 : Cross-lingual component results</head><label>3</label><figDesc></figDesc><table coords="4,84.56,357.41,150.95,85.62"><row><cell>Run</cell><cell>11-point</cell></row><row><cell>Lnu.Ltu</cell><cell>0.1862</cell></row><row><cell>above+expansion before query</cell><cell></cell></row><row><cell>translation (top 10 docs, 10</cell><cell>0.2642</cell></row><row><cell>terms)</cell><cell></cell></row><row><cell>above+expansion after query</cell><cell></cell></row><row><cell>translation (top 20 docs, 50</cell><cell>0.2583</cell></row><row><cell>terms)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,315.44,151.04,188.39,20.59"><head>Table 4</head><label>4</label><figDesc></figDesc><table coords="4,315.44,151.04,188.39,20.59"><row><cell>concludes our performance comparing</cell></row><row><cell>with other groups.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,315.44,190.16,210.11,56.23"><head>Table 4 : Result comparison</head><label>4</label><figDesc></figDesc><table coords="4,317.84,212.19,207.71,34.20"><row><cell>Run</cell><cell cols="3">best median worst</cell></row><row><cell>CHUHK00CH1(mono)</cell><cell>3</cell><cell>12</cell><cell>10</cell></row><row><cell cols="2">CHUHK00XEC1(xlingual) 2</cell><cell>16</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,81.44,121.28,198.28,230.35"><head>Table 5 : Comparative results</head><label>5</label><figDesc></figDesc><table coords="5,81.44,164.94,198.28,186.69"><row><cell>Run</cell><cell>11-point (b)</cell><cell>11-point (a)</cell></row><row><cell>mi</cell><cell>0.2552</cell><cell>0.2473</cell></row><row><cell>htf</cell><cell>0.2613</cell><cell>0.2544</cell></row><row><cell>sim_tf</cell><cell>0.2638</cell><cell>0.2564</cell></row><row><cell cols="3">MI method was worse than the others while htf,</cell></row><row><cell cols="3">sim_tf and our sim_idf performed better. It is</cell></row><row><cell cols="3">surprising that htf, the simplest method produced</cell></row><row><cell cols="3">such a good result considering the efforts it</cell></row><row><cell cols="2">takes. The result of</cell><cell>sim_tf reveals similar</cell></row><row><cell cols="3">message: high term frequency translations in the</cell></row><row><cell cols="3">target are good indication of good translations.</cell></row><row><cell cols="3">MI has the disadvantage of strongly favoring</cell></row><row><cell cols="2">rarely appearing words.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This project is partially supported by <rs type="funder">DARPA, USA</rs>, under the <rs type="programName">TIDES program</rs> (grant No.: <rs type="grantNumber">N6601-00-1-8912</rs>) and <rs type="grantName">Research Grant Committee</rs>, <rs type="person">Hong Kong</rs>, under the <rs type="grantName">direct grant initiative</rs> (project No.: <rs type="grantNumber">2050253</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VCBXkx3">
					<idno type="grant-number">N6601-00-1-8912</idno>
					<orgName type="grant-name">Research Grant Committee</orgName>
					<orgName type="program" subtype="full">TIDES program</orgName>
				</org>
				<org type="funding" xml:id="_cZ4mmNJ">
					<idno type="grant-number">2050253</idno>
					<orgName type="grant-name">direct grant initiative</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,339.92,381.68,123.20,9.07;5,482.96,381.68,31.35,9.07" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,315.44,393.20,197.10,9.07;5,315.44,404.72,98.54,9.07;5,420.08,402.61,5.04,5.83;5,427.64,404.72,83.70,9.07;5,315.44,416.00,169.92,9.07;5,315.44,427.52,198.77,9.07;5,315.44,439.04,37.80,9.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,342.88,393.20,165.33,9.07">Pivoted Document Length Normalization</title>
		<author>
			<persName coords=""><forename type="first">Mitra</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,326.36,404.72,87.62,9.07;5,420.08,402.61,5.04,5.83;5,427.64,404.72,83.70,9.07;5,315.44,416.00,169.92,9.07;5,315.44,427.52,153.39,9.07">Proceedings of the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,334.76,473.60,60.48,9.07;5,416.24,473.60,98.07,9.07" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,315.44,485.12,198.29,9.07;5,315.44,496.64,102.49,9.07;5,437.36,496.64,68.02,9.07;5,315.44,508.16,198.96,9.07;5,315.44,519.68,197.84,9.07;5,315.44,531.20,61.32,9.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,404.56,485.12,109.17,9.07;5,315.44,496.64,98.71,9.07">New Retrieval Approaches Using SMART: TREC 4</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Salton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,344.72,508.16,169.68,9.07;5,315.44,519.68,86.57,9.07">Proceedings of the Fourth Text REtrieval Conference (TREC-4)</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Fourth Text REtrieval Conference (TREC-4)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="500" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,332.00,559.52,169.09,9.07;5,315.44,571.04,175.27,9.07;5,315.44,582.56,196.00,9.07;5,315.44,594.08,10.08,9.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,480.04,559.52,21.05,9.07;5,315.44,571.04,175.27,9.07;5,315.44,582.56,51.68,9.07">Word collocation norms, mutual information, and lexicography</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,374.96,582.56,104.46,9.07">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
