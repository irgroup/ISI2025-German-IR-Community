<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,198.50,73.44,216.94,12.60;1,155.50,91.44,302.85,12.60">Report on the TREC-9 Experiment: Link-Based Retrieval and Distributed Collections</title>
				<funder ref="#_59QzB6f">
					<orgName type="full">SNSF (Swiss National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,241.50,111.17,56.52,9.00"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Institut interfacultaire d&apos;informatique</orgName>
								<orgName type="institution">Université de Neuchâtel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.60,111.17,59.16,9.00"><forename type="first">Yves</forename><surname>Rasolofo</surname></persName>
							<email>yves.rasolofo@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Institut interfacultaire d&apos;informatique</orgName>
								<orgName type="institution">Université de Neuchâtel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,198.50,73.44,216.94,12.60;1,155.50,91.44,302.85,12.60">Report on the TREC-9 Experiment: Link-Based Retrieval and Distributed Collections</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9B4853BFE243E6EB10C128B831B53024</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The web and its search engines have resulted in a new paradigm, generating new challenges for the IR community which are in turn attracting a growing interest from around the world. The decision by NIST to build a new and larger test collection based on web pages represents a very attractive initiative. This motivated us at TREC-9 to support and participate in the creation of this new corpus, to address the underlying problems of managing large text collections and to evaluate the retrieval effectiveness of hyperlinks.</p><p>In this paper, we will describe the results of our investigations, which demonstrate that simple raw score merging may show interesting retrieval performances while the hyperlinks used in different search strategies were not able to improve retrieval effectiveness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Due to the huge number of pages and links, browsing cannot be viewed as an adequate searching process, even with the introduction of tables of contents or other classifying lists (e.g., Yahoo!). As a result, effective query-based mechanisms for accessing information will always be needed. Search engines currently available on the web are not able to adequately access all available information <ref type="bibr" coords="1,250.50,546.17,40.31,9.00;1,72.50,558.17,7.92,9.00">[Lawrence 99</ref>], as they are inhibited by many drawbacks <ref type="bibr" coords="1,72.50,570.17,50.41,9.00">[Hawking 99</ref>].</p><p>In the first chapter, we will describe our experiments on the web track in which a large web text collection is divided into four sub-collections in order to keep inverted file size below the 2 GB limit. The second chapter will verify whether or not hyperlinks improved retrieval effectiveness based on four different link-based search models.</p><p>To evaluate our hypothesis, we used the SMART system as a test bed for implementing the OKAPI probabilistic model <ref type="bibr" coords="1,159.28,698.17,59.09,9.00">[Robertson 95</ref>]. This year our experiments were conducted on an Intel Pentium III/600 (memory: 1 GB, swap: 2 GB, disk: 6 x 35 GB) and all experiments were fully automated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Distributed collections</head><p>To evaluate the retrieval effectiveness of various merging strategies, we formed four separate subcollections (see Appendix 1). In this study, we assumed that each sub-collection used the same indexing schemes and retrieval procedures. A distributed context such as this more closely reflects local area networks or search engines available on the Internet than the meta search engines, where different search engines may collaborate to respond to a given user request [Le Calvé 00], <ref type="bibr" coords="1,436.58,373.17,44.30,9.00">[Selberg 99</ref>].</p><p>The following characteristics would more precisely identify our approach. A query was sent to all four text databases (no selection procedure were applied) and according to the four ranked lists of items produced, our search system merged them into a single result list presented to the user (Section 1.2). Before we describe the collection merging approaches, Section 1.1 will identify retrieval effectiveness measures achieved by various search models with the whole collection and with each of our four sub-collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Performance of sub-collections</head><p>From the original web pages, we retained only the following logical sections: &lt;TITLE&gt;, &lt;H1&gt;, &lt;CENTER&gt;, &lt;BIG&gt;, with the most common tags &lt;P&gt; (or &lt;p&gt;, together with &lt;/P&gt;, &lt;/p&gt;) being removed. Text delimited by the tags &lt;DOCHDR&gt;, &lt;/DOCHDR&gt; were also removed.</p><p>For long requests, various insignificant keywords were also removed (such as "Pertinent documents should include …"). Moreover, search keywords appearing in the Title part of the topics were considered to have a term frequency of 3 (this feature has no impact on short requests).</p><p>For the web track, we conducted different experiments using the OKAPI probabilistic model in which the weight w ij assigned to a given term t j in a document D i was computed according to the following formula:</p><formula xml:id="formula_0" coords="2,95.50,125.17,139.61,59.35">w ij = (k 1 + 1) . tf ij K + tf ij with K = k 1 .     (1 -b) + b . l i avdl</formula><p>where tf ij indicates the within-document term frequency, and b, k 1 are parameters. K represents the ratio between the length of D i measured by l i (sum of tf ij ) and the collection mean denoted by advl.</p><p>To index a request, the following formula was used:</p><formula xml:id="formula_1" coords="2,95.50,271.17,143.33,26.35">w qj = tf qj k 3 + tf qj . ln[(N -df j ) / df j ]</formula><p>where tf qj indicates the search term frequency, df j the collection-wide term frequency, N the number of documents in the collection, and k 3 is a parameter.</p><p>To adjust the underlying parameters of the OKAPI search model, we used advl = 900, b = 0.7625, k 1 = 1.5, and k 3 = 1000. These parameter values were set according to the best performance achieved on the WT2g (TREC-8). A slightly different parameter setting was suggested by <ref type="bibr" coords="2,206.50,409.17,84.66,9.00">Walker et al. [98]</ref> whereby advl = 900, b = 0.75, k 1 = 1.2, and k 3 = 1000. When using our parameter values, the corresponding label will be "OKAPI" while the second setting will be identified by adding an "R".</p><p>Two different query formulations were considered: (1) using only the Title section (T), or (2) all three logical sections (Title, Descriptive and Narrative, noted T-D-N). The data in Table <ref type="table" coords="2,220.76,511.17,5.00,9.00" target="#tab_0">1</ref> shows that retrieval effectiveness is significantly enhanced when topics include more search terms.</p><p>In order to build a single collection, we selected the first 500 retrieved items of 13 search strategies (corresponding to OKAPI and different vector-space approaches) and we added all relevant documents not retrieved by our various search models.</p><p>Table <ref type="table" coords="2,112.06,615.17,5.00,9.00" target="#tab_0">1</ref> provides a summary of the results of our various experiments. In this case, we reported the non-interpolated average precision at eleven recall values, based on 1,000 retrieved items per request. From this data we can see that the parameter setting used by Walker's et al. results in better performance (e.g., in the WEB9.1 sub-collection, the average precision increases from 19.47 to 20.30 (+4.3%)).</p><p>It is recognized that pseudo-relevance feedback (blind expansion) is a useful technique for enhancing retrieval effectiveness. In this study, we evaluated the OKAPI search model with and without query expansion in order to verify whether or not this technique might improve retrieval performance when faced with different query formulations.</p><p>In this study, we adopted Rocchio's approach <ref type="bibr" coords="2,325.50,164.17,48.05,9.00">[Buckley 96</ref>] where the parameter settings were chosen according to experiments done with the WT2g from the TREC data (TREC-8).</p><p>For a short request the values α=0.75, β=0.25 were assigned and the system was allowed to add to the original query those 50 search terms extracted from the 12-best ranked documents. For long queries, the parameters were set as follows: α=0.7, β=0.3 and the search engine was allowed to add to the original query those 40 search terms extracted from the 15 best-ranked documents. The resulting retrieval effectiveness is depicted in Table <ref type="table" coords="2,505.90,300.17,5.00,9.00" target="#tab_0">1</ref> under the label "XQ".</p><p>After examining sub-collections WEB9.1 and WEB9.3, there was some improvement in results, as depicted in Table <ref type="table" coords="2,399.54,352.17,3.81,9.00" target="#tab_0">1</ref>. For example, based on our parameter setting and examining the WEB9.1 sub-collection, the average precision increased from 19.47 (label "OKAPI") to 21.44 (label "OKAPIXQ") (+10.1%). However, for the other two sub-collections, the average precision decreased (e.g. in WEB9.4, the average precision decreases from 19.26 to 18.24 (-5.3%)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Merging procedure</head><p>Recent works have suggested solutions in which answer lists were merged in order to produce a unique ranked list of retrieved records. As a first approach, we might assume that each sub-collection contains approximately the same number of pertinent items and that the distribution of the relevant documents is the same across the answer lists. Based only on a ranking of the retrieved records, we might interleave the results in a roundrobin fashion. According to previous studies [Voorhees 95], [Callan 95], the retrieval effectiveness of such interleaving schemes is around 40% below the performance achieved by a single retrieval scheme technique, with a single huge collection representing the entire set of documents. The third column of In order to account for the score achieved by the retrieved document, we might formulate the hypothesis that each sub-collection is managed by the same search strategy and that the similarity values are therefore directly comparable <ref type="bibr" coords="3,263.50,340.17,27.77,9.00;3,86.50,352.17,8.32,9.00">[Kwok 95</ref>]. Such a strategy, called raw-score merging, produces a final list, sorted by the retrieval status value computed by each separate search engine.</p><p>However, as demonstrated by <ref type="bibr" coords="3,233.50,392.17,53.33,9.00">Dumais [94]</ref>, collection-dependent statistics in document or query weights may vary widely among sub-collections; and therefore, this phenomenon may invalidate the raw-score merging hypothesis.</p><p>The fourth column of Table <ref type="table" coords="3,216.65,456.17,5.00,9.00" target="#tab_1">2</ref> indicates the retrieval effectiveness of such merging approaches, depicting a relatively interesting performances in our case (degradation of around -5.3% for long requests or -14.9% for short queries). Thus, the raw-score merging seems to be a simple and valid approach when a huge collection is distributed across a local-area network and operating within the same retrieval scheme.</p><p>As a third merging strategy, we may normalize each sub-collection's similarity value (SIM(Di, Q)) by dividing it by the maximum value in each result list. The fifth column in Table <ref type="table" coords="3,242.22,604.17,5.00,9.00" target="#tab_1">2</ref> shows its average precision, depicting surprisingly poor retrieval effectiveness (average reduction of -19.6% for short queries and -16.2% for long requests).</p><p>As a fourth merging strategy, Callan et al. <ref type="bibr" coords="3,273.00,656.17,16.66,9.00">[95]</ref> suggest using the CORI approach, which will first compute a score s i for each sub-collection as follows:</p><formula xml:id="formula_2" coords="3,338.50,311.17,192.86,71.76">score (t j | db i ) = defB + (1-defB) . df i df i + K . log db + 0.5 cf j         log(db + 1) with K = k . (1 -b) + b . ldb i avldb      </formula><p>where t j indicates a search keyword, db i the ith collection, df i the number of documents in the ith collection containing term t j , cf j the number of collections containing term t j , db the total (number of collections equals to four in our case), ldb i the number of indexing terms included in the ith corpus, avldb the mean value of ldb i , where defB, b and k are three parameters. <ref type="bibr" coords="3,461.75,481.17,74.50,9.00">Xu &amp; Callan [98]</ref> suggest assigning values to these constants (defB=0.4, k=200, and b=0.75, values used in this study). The previous equation is defined for one search term, and the score for a given collection is simply the sum over all keywords included in the current request.</p><p>The sub-collection score (noted s i ) is the first component used to merge the retrieved items. To obtain the score of a given retrieved item of the ith collection, the similarity between the request and the document is multiplied by a coefficient w i computed as follows: where dbs indicates the number of the selected collections (all in our case), s i the score achieved by the ith collection and Sm the mean score over all collections. According to our evaluation, the mean average precision results in a degradation of around 20.2% for short queries and 5.1% for long requests. It is interesting to note that both the raw-score merging and the CORI approach result in good performances when dealing with long requests yet a decrease in performance when using short requests.</p><formula xml:id="formula_3" coords="3,355.50,642.17,133.33,13.78">w i = 1 + dbs . [(s i -Sm) / Sm]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Link-based retrieval</head><p>Various retrieval strategies have been suggested in order to take account of hyperlinks, based on the assumption that links between documents indicate useful semantic relationships between related web pages [Kleinberg 98], [Brin 98], <ref type="bibr" coords="4,332.50,378.17,61.87,9.00">[Chakrabarti 99</ref>]. For example, Chakrabarti et al.</p><p>[99] stated: "Citations signify deliberate judgment by the page author. Although some fractions of citations are noisy, most citations are to semantically related material. Thus the relevance of a page is a reasonable indicator of the relevance of its neighbors, although the reliability of this rule falls off rapidly with increasing radius on average." [Chakrabarti 99, p. 550-551] With small variations, similar hypotheses are also cited by other authors [Kleinberg 98]. In order to verify the retrieval effectiveness of such assumptions, we have evaluated four different search strategies, namely our spreading activation approach in Section 2.1, our PAS search model in Section 2.2, Kleinberg's algorithm in Section 2.3 and the PageRank approach in Section 2.4. These search strategies will be described briefly using a small example.</p><p>As a first step, the search strategy computes the similarity between the given query and the documents, with values noted as SIM(D i , Q). These values are depicted inside a rectangle in Figure <ref type="figure" coords="4,528.91,679.17,3.78,9.00" target="#fig_0">1</ref>. In this case, we can see that the first five retrieved documents are D 8 , D 4 , D 9 , D 1 and D 2 . At this point various retrieval schemes will take note of the hyperlinks so that the retrieval effectiveness might hopefully be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Spreading activation</head><p>In a first link-based strategy, we chose the spreading activation (SA) approach [Crestani 00]. In that method, the degree of match between a web page D i and a query, as initially computed by the IR system (denoted SIM(D i , Q)), is propagated to the linked documents through a certain number of cycles using a propagation factor. We used a simplified version with only one cycle and a fixed propagation factor λ for all links. In that case, the final retrieval status value of a document D i linked to m documents is computed according to the following equation:</p><formula xml:id="formula_4" coords="5,93.50,289.22,181.35,29.30">RSV(D i ) = SIM(D i , Q) + λ • SIM(D j ,Q) j=1 k ∑</formula><p>Using all the incoming and outgoing links, and for different values of the parameter λ, in most cases did not result in retrieval improvement within the WT2g corpus [Savoy 01]. In order to be more selective in the spreading phase, we only consider in this study the best outgoing and the best incoming link for each of the k best-ranked documents (the constant k was fixed to 15 in this paper and the parameter λ to 0.05). But, what do we mean by the best link? Instead of considering the m web pages linked to a given document, we only consider the incoming link coming from the best ranked document. For the outgoing links, we adopt a similar point of view, taking into account only the link starting from the given document to the best rank web page.</p><p>For example, based on Figure <ref type="figure" coords="5,223.04,539.17,3.78,9.00" target="#fig_0">1</ref>, we do not follow all outgoing from D 4 but we activate only the hyperlink to D 2 (the rank of this document is better than for the others). Similarly, the best incoming link is the link between D 8 to D 4 . Fixing the parameter λ to 0.1 and k to 5, the final retrieval status value of D 4 , noted RSV(D 4 ), will be :</p><formula xml:id="formula_5" coords="5,92.50,634.90,190.74,39.27">RSV(D 4 ) = SIM(D 4 , Q) + λ • SIM(D 2 , Q) + λ • SIM(D 8 , Q) = 90 + 0.1 • 60 + 0.1 • 100 = 106</formula><p>The similarity value of non-retrieved documents (e.g., D 20 in our example) will be set ac-cording the similarity achieved by the last retrieved item (10 in our example, 1,000 in the evaluation). The evaluation of other web pages included in our example is given in Table <ref type="table" coords="5,504.86,110.17,3.79,9.00" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Probabilistic argumentation system</head><p>In a second set of experiments, we used our probabilistic argumentation systems (PAS) [Picard 98], in which we used a simplified version of our approach, whereby the final retrieval status value of a document (or its degree of support, denoted DSP(D i )) might only be affected by its direct neighbors. In this case we do not need to keep track of inferences, and can derive a simple formula which might be considered to be a more refined spreading activation method. Instead of propagating a document's similarity value, we propagated its probability of being relevant.</p><p>In this approach, we must therefore first compute the relevance probability of a document D i .</p><p>To achieve this, we suggest using logistic regression methodology <ref type="bibr" coords="5,409.82,333.17,57.36,9.00">[Bookstein 92</ref>] and the natural logarithm of its rank as an explanatory variable. Such a computation will be noted p(D i | rank) [Le Calvé 00] and in accordance with the following formula:</p><formula xml:id="formula_6" coords="5,347.50,395.93,120.15,24.47">P D i rank [ ] = e α+β⋅ln(rank)</formula><p>1 + e α +β⋅ln(rank) in which α et β are parameters set to 0.7 and -0.8 respectively.</p><p>In a second step, this probability of relevance will be modified according to the neighbors of a given document. The individual contribution of a linked document D j to D i is given by [p(D j | rank) • p(link)], instead of the [SIM(D j , Q) • λ] used with the spreading activation technique.</p><p>Just as with the spreading activation experiments, using all incoming or outgoing links did not demonstrate any improvement, except in some cases when using the WT2g test collection [Savoy 01]. We then decided to include only the most important sources of evidence, the same way as for spreading activation. For example, we considered the initial rank of document D i , the best incoming document D in and the best outgoing document D out . This link-based retrieval approach will thus multiply the probability of linked document relevance by the probability of the link, denoted p(link in ) for incoming hyperlinks or p(link out ) for outgoing links. The final degree of support corresponding to document D i is computed as follow:</p><p>DSP</p><formula xml:id="formula_7" coords="6,109.50,123.17,125.66,36.78">(D i ) = 1 -(1 -p(D i | rank)) • [1 -p(D in | rank) • p(link in )] • [1 -p(D out | rank) • p(link out )]</formula><p>Fixing p(link in )=0.1 and p(link out )=0.2, and based on the situation depicted in Figure <ref type="figure" coords="6,258.73,180.17,3.84,9.00" target="#fig_0">1</ref>, computation of degree of support for Document 1 as follows:</p><p>DSP</p><formula xml:id="formula_8" coords="6,109.50,215.17,160.91,85.00">(D 1 ) = 1 -(1 -p(D 1 | rank)) • [1 -p(D 9 | rank) • p(link in )] • [1 -p(D 10 | rank) • p(link out )] = 1 -(1 -0.3991) • [1 -0.4554 • 0.1] • [1 - 0.2762 • 0.2] = 1 -(0.6009) • [0.95446] • [0.94476] = 1 -0.5418 = 0.4582</formula><p>Table <ref type="table" coords="6,127.61,307.17,5.00,9.00" target="#tab_3">4</ref> lists other results pertaining to the best ten retrieved items of Figure <ref type="figure" coords="6,231.53,319.17,3.89,9.00" target="#fig_0">1</ref>. For the results based on the web test collection, link probabilities are fixed as p(link in ) = 0.062, p(link out ) = 0.051, probability estimates are defined in [Savoy 01]. Finally, documents not belonging to the top 1000 have a similarity value equal to the similarity value obtained for the 1000th retrieved item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Kleinberg's algorithm</head><p>As a third link-based approach, we have applied Kleinberg's algorithm [Kleinberg 98]. In this scheme, a web page pointing to many other information sources must be viewed as a "good" hub while a document with many web pages pointing to it is a "good" authority. Likewise, a document that points to many "good" authorities is an even better hub while a web page pointed to by many "good" hubs is an even better authority.</p><p>For document D i after c+1 iterations, the updated formulas for the hub and authority scores H c+1 (D i ) and A c+1 (D i ) are: which is computed for the k best-ranked documents (defined as the root set) retrieved by a classical search model, together with their children and parents (which defined the base set). The hub and authority scores were updated for five iterations (while the ranking did not change after this point), and a normalization procedure (dividing each score by the sum of all square values) was applied after each step.</p><formula xml:id="formula_9" coords="6,187.50,277.82,274.33,133.13">A c+1 (D i ) = ∑ D j =parent(D i ) H c (D j ) H c+1 (D i ) = ∑ D j =child(D i ) A c (D j ) Rank D i SIM(D i , Q) D i RSV(D</formula><p>As an example, we will refer to the initial situation shown in Figure <ref type="figure" coords="7,196.38,202.17,3.85,9.00" target="#fig_0">1</ref> Initially, the hub and authority score for each document is set to 1. In the first iteration, the hub score for D 4 corresponds to the sum of the authority values for its children (D 40 , D 41 , D 42 , D 2 ) while its authority score is the sum of the hub scores of its parents (D 8 , D 49 ). For other items belonging to the basic set, computation of these scores is depicted in Table <ref type="table" coords="7,196.88,341.17,3.78,9.00" target="#tab_4">5</ref>.</p><p>After five iterations and using the normalization procedure, we obtained the ranked list depicted in Table <ref type="table" coords="7,156.73,381.17,3.99,9.00" target="#tab_5">6</ref>. Taking the five best-ranked documents obtained by the traditional search engine into account and the top five documents retrieved according to the authority scores, we note that the intersection included only one item, namely D 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">PageRank algorithm</head><p>Brin &amp; Page [98] suggest a link-based search model called PageRank that first evaluated the importance of each web page based on its citation pattern. As for the spreading activation approach, the PageRank algorithm reranked the retrieved pages of a traditional search schemes according to the PageRank values assigned to the retrieved items.</p><p>In this approach, a web page will have a higher score if many web pages point to it. This value increases if there are highly scoring documents pointing to it The computation of the PageRank value can be done using an iterative procedure (five iterations were computed in our case). After each iteration, each PageRank value was divided by the sum of all PageRank values. Finally, as initial values, PR(D i ) were set to 1/N where N indicates the number of documents in the collection.</p><p>Based on our example, the result list achieved by using the PageRank algorithm is depicted in Table <ref type="table" coords="7,358.70,233.17,3.83,9.00" target="#tab_6">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Evaluation</head><p>The retrieval effectiveness of the four link-based search model are shown in Table <ref type="table" coords="7,480.06,282.17,3.96,9.00" target="#tab_8">9</ref>. From this table, it seems clear that links do not seem an appropriate source of information about document contents, and they seem to provide less information than do the bibliographic references or co-citation schemes used in our previous studies [Savoy 96]. The poor results depicted by Kleinberg's approach or PageRank algorithm raise some questions: Is our implementation without bugs? Can other teams confirm these findings? Have the underlying parameters the good values? Our official runs were produced using the rawscore merging, where three were based only on the Title portion of the requests (NEtm, NENRtm, NENRtmLpas) and three were based on all logical sections of the queries (NEnm, NEnmLpas, NEnmLsa). Three of them were link-based retrievals (ending by Lpas or Lsa indicating the PAS or spreading activation approach).</p><p>For the two types of requests, our official runs included a spelling check performed automatically by the Smalltalk-80 system. This feature has a positive effect for short queries (e.g., 15.96 vs. 17.54 (+9.9%)) but not for long ones (25.99 vs. 24.99 (-3.8%)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The various experiments carried out within the web track demonstrated that:</p><p>-Hyperlinks do not result in any significant improvement (at least as implemented in this study). Link information seems to be marginally useful when the retrieval system produces relatively high retrieval effectiveness;</p><p>-Pseudo-relevant feedback techniques (blind query expansion) usually result in significant improvement but setting the underlying parameters based on another test collection may lead to a decrease in retrieval effectiveness; -Longer topic descriptions (Title, Description and Narrative) improve the retrieval performance significantly over short queries built only from the Title section;</p><p>-It seems that the raw-score approach might be a valid first attempt for merging result lists provided by the same retrieval model. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,95.57,643.13,178.51,6.41"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Starting situation for our link-based approaches</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,200.24,202.17,90.04,9.00;7,86.50,213.17,203.83,10.78;7,86.50,226.17,203.50,10.78;7,86.50,239.17,203.30,10.78"><head></head><label></label><figDesc>. We fixed k = 5 and our root set was {D 8 , D 4 , D 9 , D 1 , D 2 }, leading to the following base set {D 8 , D 4 , D 9 , D 1 , D 2 , D 80 , D 40 , D 41 , D 42 , D 20 , D 25 , D 49 , D 10 }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,143.67,615.17,146.43,9.00;7,86.50,626.17,203.50,10.78;7,86.50,639.17,203.79,10.78;7,86.50,653.17,133.88,9.00;7,93.50,664.17,89.07,10.78;7,185.50,661.90,1.50,5.40;7,190.00,664.17,75.16,10.78;7,109.50,677.17,110.99,10.78;7,332.50,78.17,203.72,9.00;7,332.50,89.17,203.83,10.78;7,332.50,102.17,104.50,10.78"><head></head><label></label><figDesc>. The PageRank value of a given web page D i , value noted as PR(D i ), having D 1 , D 2 , … D m pages pointing to D i , is computed according to the following formula: PR(D i ) = (1 -d) + d . [(PR(D 1 ) / C(D 1 )) + … + (PR(D m ) / C(D m ))]where d is a parameter (set to 0.85 as suggested by [Brin 98] and C(D j ) are the number of outgoing links for web page D j .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,325.50,653.17,212.44,45.00"><head>Table 1 :</head><label>1</label><figDesc>Table 2 confirms this finding but to a lesser extent (around -26.1% when dealing with short queries or -17.0% when examining Title, Descriptive and Narrative fields in the topics). Average precision of isolated sub-collections and the whole test collection</figDesc><table coords="3,111.50,81.17,412.38,170.00"><row><cell></cell><cell></cell><cell></cell><cell>Average Precision</cell><cell></cell><cell></cell></row><row><cell></cell><cell>WEB9.1</cell><cell>WEB9.2</cell><cell>WEB9.3</cell><cell>WEB9.4</cell><cell>WEB9</cell></row><row><cell>Query Title only</cell><cell>46 queries</cell><cell>44 queries</cell><cell>43 queries</cell><cell>46 queries</cell><cell>50 queries</cell></row><row><cell>Model</cell><cell>749 rel</cell><cell>600 rel</cell><cell>608 rel</cell><cell>660 rel</cell><cell>2,617 rel.</cell></row><row><cell>Okapi</cell><cell>19.47</cell><cell>20.85</cell><cell>16.09</cell><cell>19.26</cell><cell>19.55</cell></row><row><cell>OkapiR</cell><cell>20.30</cell><cell>21.32</cell><cell>16.52</cell><cell>19.51</cell><cell>19.86</cell></row><row><cell>OkapiXQ</cell><cell>21.44</cell><cell>20.89</cell><cell>17.73</cell><cell>18.24</cell><cell>19.43</cell></row><row><cell>OkapiNRXQ</cell><cell>21.70</cell><cell>20.67</cell><cell>18.98</cell><cell>18.33</cell><cell>19.31</cell></row><row><cell>Query T-D-N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Okapi</cell><cell>32.61</cell><cell>30.26</cell><cell>28.09</cell><cell>28.44</cell><cell>27.25</cell></row><row><cell>OkapiNR</cell><cell>33.25</cell><cell>30.19</cell><cell>29.01</cell><cell>28.49</cell><cell>27.52</cell></row><row><cell>OkapiXQ</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>28.10</cell></row><row><cell>OkapiNRXQ</cell><cell>34.41</cell><cell>28.25</cell><cell>31.18</cell><cell>26.69</cell><cell>28.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,93.50,79.82,448.78,219.35"><head>Table 2 :</head><label>2</label><figDesc>Average precision of different merging procedures</figDesc><table coords="4,278.50,79.82,136.92,10.18"><row><cell>Average Precision (% change)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,159.50,400.17,312.33,280.00"><head>Table 3 :</head><label>3</label><figDesc>Retrieval status value obtained by the spreading activation</figDesc><table coords="6,435.50,400.17,6.33,10.78"><row><cell>i )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,162.50,693.17,296.97,9.00"><head>Table 4 :</head><label>4</label><figDesc>Computation of the degree of support of our PAS search model</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,131.50,358.17,365.33,138.00"><head>Table 5 :</head><label>5</label><figDesc>Computation of the hub and authority scores for our example</figDesc><table coords="8,131.50,376.85,365.33,119.32"><row><cell>Rank</cell><cell>D i</cell><cell>SIM(D i , Q)</cell><cell>D i</cell><cell>A 5 (D i )</cell><cell>D i</cell><cell>H 5 (D i )</cell></row><row><cell>1</cell><cell>8</cell><cell>100</cell><cell>2</cell><cell>0.1239</cell><cell>4</cell><cell>0.1501</cell></row><row><cell>2</cell><cell>4</cell><cell>90</cell><cell>42</cell><cell>0.0762</cell><cell>25</cell><cell>0.0723</cell></row><row><cell>3</cell><cell>9</cell><cell>80</cell><cell>41</cell><cell>0.0762</cell><cell>9</cell><cell>0.0241</cell></row><row><cell>4</cell><cell>1</cell><cell>70</cell><cell>40</cell><cell>0.0762</cell><cell>8</cell><cell>0.0241</cell></row><row><cell>5</cell><cell>2</cell><cell>60</cell><cell>20</cell><cell>0.0667</cell><cell>2</cell><cell>0.0222</cell></row><row><cell>6</cell><cell>42</cell><cell>50</cell><cell>4</cell><cell>0.0413</cell><cell>49</cell><cell>0.0148</cell></row><row><cell>7</cell><cell>93</cell><cell>40</cell><cell>10</cell><cell>0.0413</cell><cell>1</cell><cell>0.0148</cell></row><row><cell>8</cell><cell>10</cell><cell>30</cell><cell>80</cell><cell>0.0254</cell><cell>80</cell><cell>0</cell></row><row><cell>9</cell><cell>49</cell><cell>20</cell><cell>1</cell><cell>0.0254</cell><cell>42</cell><cell>0</cell></row><row><cell>10</cell><cell>6</cell><cell>10</cell><cell>9</cell><cell>0</cell><cell>41</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,159.50,509.17,309.33,133.00"><head>Table 6 :</head><label>6</label><figDesc>Computation of the hub and authority scores after five iterations</figDesc><table coords="8,159.50,528.17,309.33,114.00"><row><cell>Rank</cell><cell>D i</cell><cell>SIM(D i , Q)</cell><cell>Rank</cell><cell>D i</cell><cell>PR(D i )</cell></row><row><cell>1</cell><cell>8</cell><cell>100</cell><cell>1</cell><cell>10</cell><cell>0.2710</cell></row><row><cell>2</cell><cell>4</cell><cell>90</cell><cell>2</cell><cell>4</cell><cell>0.2548</cell></row><row><cell>3</cell><cell>9</cell><cell>80</cell><cell>3</cell><cell>2</cell><cell>0.2146</cell></row><row><cell>4</cell><cell>1</cell><cell>70</cell><cell>4</cell><cell>1</cell><cell>0.1849</cell></row><row><cell>5</cell><cell>2</cell><cell>60</cell><cell>5</cell><cell>42</cell><cell>0.1797</cell></row><row><cell>6</cell><cell>42</cell><cell>50</cell><cell>6</cell><cell>93</cell><cell>0.15</cell></row><row><cell>7</cell><cell>93</cell><cell>40</cell><cell>7</cell><cell>49</cell><cell>0.15</cell></row><row><cell>8</cell><cell>10</cell><cell>30</cell><cell>8</cell><cell>9</cell><cell>0.15</cell></row><row><cell>9</cell><cell>49</cell><cell>20</cell><cell>9</cell><cell>8</cell><cell>0.15</cell></row><row><cell>10</cell><cell>6</cell><cell>10</cell><cell>10</cell><cell>6</cell><cell>0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,122.50,655.17,376.99,9.00"><head>Table 8 :</head><label>8</label><figDesc>Ranked list obtained in our example by the traditional and the PageRank approach</figDesc><table coords="9,190.50,75.17,251.33,207.00"><row><cell></cell><cell cols="4">without normalizat.</cell><cell cols="4">with normalization</cell></row><row><cell>D i</cell><cell>PR</cell><cell>1 (D i )</cell><cell>PR</cell><cell>5 (D i )</cell><cell>PR</cell><cell>1 (D i )</cell><cell>PR</cell><cell>5 (D i )</cell></row><row><cell>1</cell><cell cols="2">0.1736</cell><cell cols="2">0.2138</cell><cell cols="2">0.1925</cell><cell cols="2">0.1849</cell></row><row><cell>2</cell><cell cols="2">0.1854</cell><cell cols="2">0.2863</cell><cell cols="2">0.2138</cell><cell cols="2">0.2146</cell></row><row><cell>4</cell><cell cols="2">0.2208</cell><cell cols="2">0.3413</cell><cell cols="2">0.2775</cell><cell cols="2">0.2548</cell></row><row><cell>6</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>8</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>9</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>10</cell><cell cols="2">0.2208</cell><cell cols="2">0.3954</cell><cell cols="2">0.2775</cell><cell cols="2">0.2710</cell></row><row><cell>20</cell><cell cols="2">0.2681</cell><cell cols="2">0.5846</cell><cell cols="2">0.3625</cell><cell cols="2">0.3547</cell></row><row><cell>22</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>25</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>40</cell><cell cols="2">0.1618</cell><cell cols="2">0.2225</cell><cell cols="2">0.1713</cell><cell cols="2">0.1797</cell></row><row><cell>41</cell><cell cols="2">0.1618</cell><cell cols="2">0.2225</cell><cell cols="2">0.1713</cell><cell cols="2">0.1797</cell></row><row><cell>42</cell><cell cols="2">0.1618</cell><cell cols="2">0.2225</cell><cell cols="2">0.1713</cell><cell cols="2">0.1797</cell></row><row><cell>49</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>60</cell><cell cols="2">0.1972</cell><cell cols="2">0.2775</cell><cell cols="2">0.235</cell><cell cols="2">0.2198</cell></row><row><cell>80</cell><cell cols="2">0.1736</cell><cell cols="2">0.2138</cell><cell cols="2">0.1925</cell><cell cols="2">0.1849</cell></row><row><cell>93</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell><cell cols="2">0.15</cell></row><row><cell>100</cell><cell cols="2">0.1972</cell><cell cols="2">0.4861</cell><cell cols="2">0.235</cell><cell cols="2">0.2762</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,93.50,295.17,439.80,165.83"><head>Table 7 :</head><label>7</label><figDesc>Computation of the PageRank values with and without normalization</figDesc><table coords="9,306.50,312.82,81.92,10.18"><row><cell>Average Precision</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,99.50,473.17,430.28,107.00"><head>Table 9 :</head><label>9</label><figDesc>Average precision of different link-based approaches</figDesc><table coords="9,99.50,489.90,430.28,90.27"><row><cell>Official run name</cell><cell>Corresponding run name</cell><cell>Average Pre.</cell><cell># ≥ Median</cell><cell># Best</cell></row><row><cell>NEtm</cell><cell>OKAPIXQ</cell><cell>17.54</cell><cell>41</cell><cell>3</cell></row><row><cell>NENRtm</cell><cell>OKAPIRXQ</cell><cell>17.43</cell><cell>41</cell><cell>2</cell></row><row><cell>NENRtmLpas</cell><cell>OKAPIRXQ + PAS</cell><cell>17.36</cell><cell>40</cell><cell>1</cell></row><row><cell>NEnm</cell><cell>OKAPIXQ</cell><cell>24.99</cell><cell>45</cell><cell>4</cell></row><row><cell>NEnmLpas</cell><cell>OKAPIRXQ + PAS</cell><cell>24.88</cell><cell>43</cell><cell>0</cell></row><row><cell>NEnmLsa</cell><cell>OKAPIRXQ + SA</cell><cell>21.85</cell><cell>41</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="9,193.50,593.17,234.93,9.00"><head>Table 10 :</head><label>10</label><figDesc>Summary of our official runs for the web track</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank <rs type="person">C. Buckley</rs> from <rs type="affiliation">SabIR</rs> for allowing us the opportunity to use the SMART system. This research was supported by the <rs type="funder">SNSF (Swiss National Science Foundation</rs>) under grant <rs type="grantNumber">21-58'813.99</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_59QzB6f">
					<idno type="grant-number">21-58&apos;813.99</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(#q:495) (#q:495) (#q:495) (#q:495) (#q:495) minimum 1 1 1 1 1 for # query (#q:461) (#q:461) (#q:464) (#q:456) (#q:473) size invert. file doc.nnn 674. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,161.50,644.17,128.39,9.00;9,100.50,656.17,189.93,9.00;9,100.50,668.17,153.60,9.00;9,269.50,668.17,21.38,9.00;9,100.50,680.17,190.16,9.00;9,100.50,692.17,51.90,9.00;9,332.50,629.17,203.58,9.00;9,346.50,641.17,190.16,9.00;9,346.50,653.17,102.82,9.00" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,188.73,656.17,101.69,9.00;9,100.50,668.17,148.74,9.00">Applications of loglinear models for informetric phenomena</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bookstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stephens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,459.25,629.17,76.83,9.00;9,346.50,641.17,185.99,9.00">The anatomy of a large-scale hypertextual web search engine</title>
		<imprint>
			<date type="published" when="1992">1992. 1998</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
	<note>WWW</note>
</biblStruct>

<biblStruct coords="9,393.01,665.17,143.30,9.00;9,346.50,677.17,189.67,9.00;9,346.50,689.17,132.80,9.00" xml:id="b1">
	<analytic>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,403.50,677.17,132.67,9.00;9,346.50,689.85,27.92,8.10">New retrieval approaches using SMART</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.50,74.17,203.47,9.00;10,100.50,86.17,190.05,9.00;10,100.50,98.17,140.93,9.00" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,100.50,86.17,190.05,9.00;10,100.50,98.17,35.26,9.00">Searching distributed collections with inference networks</title>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">J P</forename><surname>Callan 95</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,145.36,98.17,62.11,9.00">ACM-SIGIR&apos;95</title>
		<imprint>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.50,110.17,124.44,9.00;10,100.50,122.17,189.53,9.00;10,100.50,134.17,190.00,9.00;10,100.50,146.17,137.86,9.00" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,171.67,122.17,118.36,9.00;10,100.50,134.17,190.00,9.00;10,100.50,146.17,26.20,9.00">Focused Crawling: A new approach to topic-specific web resource discovery</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,136.50,146.17,29.11,9.00">WWW</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="545" to="562" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,148.04,158.17,142.23,9.00;10,100.50,170.17,189.94,9.00;10,100.50,182.17,189.98,9.00;10,100.50,194.17,61.92,9.00" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,248.12,158.17,42.15,9.00;10,100.50,170.17,186.13,9.00">Searching the web by constrained spreading activation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,100.50,182.17,157.92,9.00">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="585" to="605" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,144.81,206.17,145.49,9.00;10,100.50,218.17,189.55,9.00;10,100.50,230.17,35.83,9.00" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,208.88,206.17,81.42,9.00;10,100.50,218.17,184.68,9.00">Latent semantic indexing (LSI) and TREC-2. TREC&apos;2, 1994</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,156.50,242.17,133.06,9.00;10,100.50,254.17,189.68,9.00;10,100.50,266.17,189.57,9.00;10,100.50,278.17,61.92,9.00" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,215.91,254.17,74.27,9.00;10,100.50,266.17,136.15,9.00">Results and challenges in web search evaluation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thistlewaite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,252.50,266.17,30.05,9.00">WWW</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="243" to="252" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.50,290.17,62.33,9.00;10,164.50,290.17,57.77,9.00;10,237.50,290.17,53.33,9.00;10,100.50,302.17,190.22,9.00;10,100.50,314.17,190.00,9.00;10,100.50,326.17,148.94,9.00" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,237.50,290.17,53.33,9.00;10,100.50,302.17,156.43,9.00">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">J</forename><surname>Kleinberg 98</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,273.50,302.17,17.22,9.00;10,100.50,314.17,190.00,9.00;10,100.50,326.17,80.43,9.00">Proceedings of 9th ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>9th ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="668" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.50,338.17,147.72,9.00;10,100.50,350.17,189.87,9.00;10,100.50,362.17,189.72,9.00;10,100.50,374.17,102.85,9.00" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="10,134.10,350.17,156.27,9.00;10,100.50,362.17,184.43,9.00">TREC-3 ad-hoc, routing retrieval and thresholding experiments using PIRCS</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="247" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.13,386.17,136.12,9.00;10,100.50,398.17,189.85,9.00;10,100.50,410.17,111.91,9.00" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,274.72,386.17,15.53,9.00;10,100.50,398.17,151.36,9.00">Accessibility of information on the web</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,262.29,398.17,28.06,9.00">Nature</title>
		<imprint>
			<biblScope unit="volume">400</biblScope>
			<biblScope unit="issue">6740</biblScope>
			<biblScope unit="page" from="107" to="110" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,86.50,422.17,203.78,9.00;10,100.50,434.17,189.88,9.00;10,100.50,446.17,189.98,9.00;10,100.50,458.17,61.92,9.00" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,251.90,422.17,38.37,9.00;10,100.50,434.17,185.78,9.00">Database merging strategy based on logistic regression</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Le Calvé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,100.50,446.17,157.92,9.00">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Le Calvé 00</note>
</biblStruct>

<biblStruct coords="10,332.50,74.17,203.80,9.00;10,346.50,86.17,190.11,9.00;10,346.50,98.17,190.33,9.00;10,346.50,110.17,17.50,9.00" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,430.28,74.17,106.02,9.00;10,346.50,86.17,190.11,9.00;10,346.50,98.17,80.13,9.00">Modeling and combining evidence provided by document relationships using PAS systems</title>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">J</forename><surname>Picard 98</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,443.50,98.17,63.96,9.00">ACM-SIGIR&apos;98</title>
		<imprint>
			<biblScope unit="page" from="182" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,402.84,122.17,133.35,9.00;10,346.50,134.17,190.44,9.00;10,346.50,146.17,189.94,9.00;10,346.50,158.17,189.79,9.00;10,346.50,170.17,172.96,9.00" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,449.50,134.17,87.44,9.00;10,346.50,146.17,189.94,9.00;10,346.50,158.17,90.19,9.00">Large test collection experiments on an operational, interactive system: OKAPI at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,448.11,158.17,88.18,9.00;10,346.50,170.17,76.37,9.00">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="360" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,332.50,182.17,203.89,9.00;10,346.50,194.17,189.81,9.00;10,346.50,206.17,189.78,9.00;10,346.50,218.17,118.94,9.00" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,426.00,182.17,110.39,9.00;10,346.50,194.17,104.68,9.00">Citation schemes in hypertext information retrieval</title>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">J</forename><surname>Savoy 96</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,472.03,194.17,64.28,9.00;10,346.50,206.17,85.55,9.00">Information retrieval and hypertext</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Agosti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Smeaton</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="99" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,332.50,230.17,203.81,9.00;10,346.50,242.17,189.76,9.00;10,346.50,254.17,132.99,9.00" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">J</forename><surname>Savoy 01</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Picard</surname></persName>
		</author>
		<title level="m" coord="10,470.45,230.17,65.86,9.00;10,346.50,242.17,189.76,9.00;10,346.50,254.17,60.43,9.00">Retrieval effectiveness on the web. Information Processing &amp; Management</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="10,391.76,266.17,144.44,9.00;10,346.50,278.17,189.83,9.00;10,346.50,290.17,87.93,9.00" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Selberg</surname></persName>
		</author>
		<title level="m" coord="10,460.84,266.17,75.36,9.00;10,346.50,278.17,79.62,9.00">Towards comprehensive web search</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>University of Washington</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="10,332.50,302.17,203.80,9.00;10,346.50,314.17,60.55,9.00;10,422.50,314.17,115.00,9.00;10,346.50,326.17,148.97,9.00" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,422.50,314.17,115.00,9.00;10,346.50,326.17,36.98,9.00">Learning collection fusion strategies</title>
		<author>
			<persName coords=""><forename type="first">]</forename><forename type="middle">E M</forename><surname>Voorhees 95</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">K</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Johnson-Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,389.76,326.17,61.86,9.00">ACM-SIGIR&apos;95</title>
		<imprint>
			<biblScope unit="page" from="172" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,391.75,338.17,144.15,9.00;10,346.50,350.17,189.75,9.00;10,346.50,362.17,189.68,9.00;10,346.50,374.17,189.80,9.00;10,346.50,386.17,35.83,9.00" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughamen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<title level="m" coord="10,346.50,362.17,189.68,9.00;10,346.50,374.17,114.31,9.00">Okapi at TREC-6: Automatic ad hoc, VLC, routing, filtering and QSDR</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="125" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,371.71,398.17,164.48,9.00;10,346.50,410.17,189.83,9.00;10,346.50,422.17,35.83,9.00" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,458.06,398.17,78.12,9.00;10,346.50,410.17,111.93,9.00">Effective retrieval with distributed collections</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,467.88,410.17,63.19,9.00">ACM-SIGIR&apos;98</title>
		<imprint>
			<biblScope unit="page" from="112" to="120" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
