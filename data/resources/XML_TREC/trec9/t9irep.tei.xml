<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,188.28,159.00,234.72,10.32">TREC-9 Interactive Track Report</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2001-05-14">May 14, 2001</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,268.56,183.24,74.04,16.40"><forename type="first">William</forename><surname>Hersh</surname></persName>
							<email>hersh@ohsu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Division of Medical Informatics &amp; Outcomes Research</orgName>
								<orgName type="institution">Oregon Health Sciences University Portland</orgName>
								<address>
									<postCode>97201</postCode>
									<region>OR</region>
									<country>USA Paul Over</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Retrieval Group Information Access Division</orgName>
								<orgName type="institution">National Institute of Standards and Technology Gaithersburg</orgName>
								<address>
									<postCode>20899</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,188.28,159.00,234.72,10.32">TREC-9 Interactive Track Report</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2001-05-14">May 14, 2001</date>
						</imprint>
					</monogr>
					<idno type="MD5">18CDCD35AF8EC7EAF451C072E110A9B3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC Interactive Track has the goal of investigating interactive information retrieval by examining the process as well as the results. In TREC-9 six research groups ran a total of 12 interactive information retrieval IR system variants on a shared problem: a fact-nding task, eight questions, and newspaper newswire documents from the TREC collections. This report summarizes the shared experimental framework, which for TREC-9 was designed to support analysis and comparison of system performance only within sites. The report refers the reader to separate discussions of the experiments performed by each participating group | their hypotheses, experimental systems, and results. The papers from each of the participating groups and the raw and evaluated results are available via the TREC home page trec.nist.gov.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For TREC-9 the high-level goal of the Interactive Track remained the investigation of searching as an interactive task by examining the process as well as the outcome. In particular, the track examined the use of IR systems in a fact-nding task | searchers had to nd the answers to questions designed to require reference to multiple documents. There was a strong desire to reduce the time per search previously: 20 minutes, to reduce the overall search session time per searcher more than three hours, to use di erent data from that used for the last several years by the track the Financial Times of London, and to explore di erent t ypes of questions from the sort studied in the last several TREC interactive tracks, ones which w ould require some simple organization of the found information. In response to these goals a common experimental framework was designed with the following features: The framework allowed groups to estimate the effect of their experimental manipulation free of the main additive e ects of searcher and topic. It was also designed to reduce the e ect of interactions, e.g., searcher with topic, topic with system, etc.</p><p>In TREC-9 the emphasis was on each group's exploration of di erent approaches to supporting the common searcher task and understanding the reasons for the results they obtained. No formal coordination of hypotheses or comparison of systems across sites was planned, but groups were encouraged to seek out and exploit synergies. Some groups designed tailored their systems to optimize performance on the task; others simply used the task to exercise their systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Participants</head><p>Each research group selected its own experimental participants, known here as searchers." There was only one restriction: no searcher could have previously used either the control system or the experimental system. Additional restrictions were judged impractical given the di culty of nding searchers. A minimum of sixteen searchers was required, but the experimental design allowed for the addition of more in groups of eight and additions were encouraged. Standard demographic data about each searcher were collected by each site and some sites administered additional tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Apparatus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IR systems</head><p>In addition to running its experimental systems, each participating site chose a control system appropriate to the local research goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computing resources</head><p>Each participating group was responsible for its own computing resources adequate to run both the control and experimental systems and collect the data required for its own experiments and for submission to NIST. The control and the experimental systems were to be provided with equal computing resources within a site but not necessarily the same as those provided at other sites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questions</head><p>Questions from the non-interactive TREC-8 Question and Answer Track w ere considered for use, but proved too easy for an interactive task. A n umber of candidate questions were developed by the participating research groups inspired more by the data at hand than any systematic considerations. Four sorts were considered and tested to gauge their suitability:</p><p>Find any n Xs, e.g., Name three US Senators on committees regulating the nuclear industry. Find the rst or last X, e.g., Who was the last Republican to pull out of the nomination race to be the candidate of his her party for US president in 1992? In the end, eight questions were chosen, four of each of the rst two t ypes. Questions of the last two sorts were di cult to nd create and, given their superlative" nature, seemed less likely to be doable in the ve minutes alloted to each search. All the questions called for very short answers.The rst four required the searcher to respond with an answer that has from one to four parts. This was a bounded version of the instance retrieval type of question used in TREC-5 through TREC-8 interactive tracks. The second four required the searcher to decide which of two given answers is the correct one. Here are the questions:</p><p>1. What are the names of three US national parks where one can nd redwoods? 2. Identify a site with Roman ruins in present d a y</p><p>France. 3. Name four lms in which Orson Welles appeared. 4. Name three countries that imported Cuban sugar during the period of time covered by the document collection. 5. Which children's TV program was on the air longer: the original Mickey Mouse Club or the original Howdy Doody Show? 6. Which painting did Edvard Munch complete rst: "Vampire" or "Puberty"? 7. Which was the last dynasty of China: Qing or Ming? 8. Is Denmark larger or smaller in population than Norway?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Searcher task</head><p>The task of the interactive searcher was to nd and record the answer to the question and identify one or more documents that supported the answer | all within the ve minutes allotted for each question.</p><p>The question creation process guaranteed that each question could be answered based on documents in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document collection</head><p>The collection of documents to be searched included the following TREC collections: 1. Associated Press disks 1-3  <ref type="table" coords="3,381.65,181.55,25.50,4.52;3,455.58,181.55,35.17,4.52;3,339.20,189.62,4.40,4.52;3,371.97,189.62,35.17,4.52;3,455.58,189.62,35.17,4.52;3,339.20,197.70,4.40,4.52;3,371.97,197.70,35.17,4.52;3,455.58,197.70,35.17,4.52;3,339.20,205.77,4.40,4.52" target="#tab_2">4-7-5-8  A: 1-3-2-6   2  A: 3-5-7-1  B: 8-4-6-2   3  A: 1-3-4-6  B: 2-8-7-5   4</ref> </p><formula xml:id="formula_0" coords="3,317.76,205.77,172.99,146.70">A: 5-2-6-3 B: 4-7-1-8 5 B: 7-6-2-4 A: 3-5-8-1 6 B: 8-4-3-2 A: 6-1-5-7 7 A: 6-1-8-7 B: 5-2-4-3 8 B: 2-8-1-5 A: 7-6-3-4 9 A: 4-7-5-8 B: 1-3-2-6 10 B: 3-5-7-1 A: 8-4-6-2 11 B: 1-3-4-6 A: 2-8-7-5 12 B: 5-2-6-3 A: 4-7-1-8 13 A: 7-6-2-4 B: 3-5-8-1 14 A: 8-4-3-2 B: 6-1-5-7 15 B: 6-1-8-7 A: 5-2-4-3 16 A: 2-8-1-5 B: 7-6-3-4 2. Wall Street Journal disks 1-2</formula><p>3. San Jose Mercury News disk 3 4. Financial Times from disk 4 5. Los Angeles Times disk 5 6. Foreign Broadcast Information Service disk 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Procedure</head><p>Each searcher performed eight searches on the document collection using the eight i n teractive track topics in a pseudo-random order. Each searcher performed 4 searches on one of the site's systems and then 4 on the other to avoid the extra cognitive load of switching systems with each search. Table <ref type="table" coords="3,506.16,530.91,5.04,13.80" target="#tab_1">1</ref> shows an example ordering of searches for two systems, eight questions, and sixteen searchers. Instructions on the task preceded all searching and a system tutorial preceded the rst use of each system. In addition, each searcher was asked to complete a questionnaire, prior to all searching, after each search, after the last search on a given system, and after all searching was complete. The detailed experimental design determined the pseudo-random order in which each searcher used the systems experimental and control and topics. The minimal 16-searcher-by-8-topic matrix can be rearranged and seen as 32 2-searcher-by-2-topic Latin squares. Each 2-by-2 square has the form shown in Table <ref type="table" coords="4,99.12,314.91,5.04,13.80" target="#tab_2">2</ref> and has the property that the treatment effect," here E , C, the control-adjusted response, can be estimated free and clear of the main additive effects of searcher and topic. Participant and topic are treated statistically as blocking factors. This means that even in the presence of the anticipated di erences between searchers and topics, the design provided estimates of E ,C that were not contaminated by these di erences.</p><p>However, the estimate of E ,C would be contaminated by the presence of an interaction between topic and searcher. Therefore, we replicated the 2-by-2 Latin square 8x4 times to get the minimal 16-by-8 design for each site. The contaminating e ect of the topic by searcher interaction was reduced by a veraging the thirty-two estimates of E , C that are available, one for each 2-by-2 Latin square. This is analogous to averaging replicate measurements of a single quantity in order to reduce the measurement uncertainty. Each 2-by-2 square yields one withinsearcher estimate of the E , C di erence for a total of thirty-two such estimates for each 16-searcher-by-8-topic matrix.</p><p>In resolving experimental design questions not covered here e.g., scheduling of tutorials and searches, etc., participating sites were asked to minimize the di erences between the conditions under which a given searcher used the control and those under which he or she used the experimental system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Data submitted to NIST</head><p>Five sorts of data were collected for evaluation analysis for all searches unless otherwise specied and are available from the TREC-9 Interactive Track w eb page www-nlpir.nist.gov projects t9i.</p><p>sparse-format data | list of documents saved and the elapsed clock time for each search rich-format data | searcher input and signicant e v ents in the course of the interaction and their timing searcher questionnaires on background, user satisfaction, etc. a full narrative description of one interactive session for a question to be chosen by each site any further guidance or re nement of the task speci cation given to the searchers Only the sparse-format data were evaluated at NIST. Each each response, i.e., each attempt to answer a question, was assessed using two questions:</p><p>Does the response contains all, some or none of the items asked for by the question? Do the documents cited fully support all, some or none of the correct items in the response? Note that in the case of the Is it A or B" questions 5 -8, the response can contain at most one item, so the answer to the rst assessment question can only be all" items i.e., one, or none", and similarly for the second question. Counts for partial responses and partial support are thus not present in the next section's assessment outcome gures for this sort of question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>This section presents the raw results aggregated across all sites and systems by question. The total number of responses per question varies since not all sites submitted complete results. Each table presents the number of responses in each assessment category. All the questions of type Is it A or B?" are presented rst with their reduced set of possible outcomes; otherwise the tables are presented in order of decreasing success. Discussion of the supporting documents is limited to those submitted with the responses; no exhaustive search of the document collection was undertaken to nd all possible supporting documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Questions</head><p>Question 7 had 23 di erent documents submitted in support of answers to it see Figure <ref type="figure" coords="5,233.76,267.39,5.82,13.80" target="#fig_1">1</ref>. and the assessors found all to be supportive. Twelve of the documents provide the dates for the Qing dynasty only, seven for the Ming only, and four the combined dates without allowing one to say which came rst.</p><p>Question 5 had only seven documents saved in support of it see Figure <ref type="figure" coords="5,168.24,339.27,5.82,13.80">2</ref>. and all were supportive t o some extent. Four provided the dates for the Howdy Doody Show and three for the Mickey Mouse Club. So, one document of each sort was needed for a fully supported answer.</p><p>Question 6 had only two supportive documents see Figure <ref type="figure" coords="5,104.40,411.15,5.82,13.80">3</ref>. | one for Vampire" and one for Puberty". Seven documents were submitted as supportive.</p><p>Question 8 see Figure <ref type="figure" coords="5,187.32,447.15,5.82,13.80" target="#fig_2">4</ref>. was answered in part by ten documents that provided the population of Denmark and ve that included the number for Norway. There were no documents that included both numbers.</p><p>Question 4 see Figure <ref type="figure" coords="5,183.72,507.03,5.82,13.80">5</ref>. had 54 documents submitted as supportive but the assessors found only 39 to be so. Possible answers with the number of documents providing them in parentheses were Indonesia 23, Khazakhstan 19, South Korea 19, former Soviet Union 3, Soviet Union 16, Russia 10, China 5, Canada 3, Japan 3, Latvia 2, Britain UK 1, Caricom 1, Eastern Europe E. Germany 1, Iran 1, Italy 1, Mexico 1, Portugal 1, and Socialist Bloc 1. Seven percent of all responses contained no answer. Twenty percent of all responses contained an incorrect answer 15 contained 1 wrong answer, 4 contained 2, 1 contained 3.  For question 3 see Figure <ref type="figure" coords="7,199.80,124.47,4.80,13.80">6</ref>., 40 documents were saved as supportive but only 17 were judged to be so. Possible answers were Citizen Kane 4, Third Man 4, Catch-22 2, Othello 2, Some to Love 2, Chimes at Midnight 1, Lady from Shanghai 1, and MacBeth 1. The collection contained a number of references to lms which Welles directed but did not appear in. In the haste of the moment, some searchers may h a ve overlooked this important distinction. Five percent of all responses contained no answer. Forty-nine percent of all responses contained an incorrect answer 33 contained 1 wrong answer, 9 contained 2, 7 contained 3. The Magni cent Ambersons" accounts for 80 of the responses with a single wrong answer. This lm was directed by W elles and his was the voice of the narrator. The assessor did not consider this an appearance.</p><p>For question 1 see Figure <ref type="figure" coords="7,199.80,339.63,4.80,13.80">7</ref>., 24 documents were submitted, of which only 13 were supportive. Possible answers were Redwood National Park 5, Sequoia National Park 5, Yosemite National Park 5, Kings Canyon National Park 4, California Six Rivers National Park 1, and Lassen National Park 4. The collection contained many references to state parks with redwoods and some of these were submitted as answers but were not counted as valid. There may also have been some question about whether a sequoia is redwood and whether a national monument or national forest should count as a national park. The assessors answered yes" to all those questions. Fifteen percent of all responses contained no answer. Forty-two percent of all responses contained an incorrect answer 9 contained 1 wrong answer, 8 contained 2, 24 contained 3.</p><p>Finally, for question 2 see Figure <ref type="figure" coords="7,242.04,554.91,4.80,13.80">8</ref>., 27 documents were submitted as supportive but only 7 were found to be so. Possible answers found were amphitheater in southern France 2, arena at Nimes 2, ruins in Arles 2, arena of Lutec 1, ruins in Orange 1, ruins near Frethun 1, and ruins near Perigord, North Dordogue 1. Forty-eight percent o f all responses contained no answer. Thirty-four percent of all responses contained an incorrect answer. The question required only one item per answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approaches</head><p>The approaches taken by each group are summarized in the following paragraphs. For more details on the approaches and information on the results, the reader is directed to the site reports in these proceedings or on the TREC web site trec.nist.gov.</p><p>Chapman University V ogt, in pressinvestigated the use of a rich transcript of user actions to predict relevance of documents viewed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Glasgow</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Future work</head><p>Results from the TREC Interactive T rack h a ve shown over the last few years that interactive evaluation, while complicated, is possible and can generate informative results. There is agreement among most of the track participants, however, that there is room for methodological improvements within the basic TREC setting. A workshop was held at SIGIR 2000 to explore such possible improvements Hersh &amp; Over, 2000. The recommendations are listed below. They will be the basis for the design of the TREC-2001 Interactive T rack, which will comprise focused observational studies of Web searching. It is hoped that from the observations will come the germs of hypotheses which can be implemented and tested in a more controlled experimental setting for TREC-2002.</p><p>The SIGIR workshop's recommendations are as follows:</p><p>Relieve some of the pressure on participants by running the track on a 2-yr cycle with interim results reported after the rst year Move the search task closer to everyday searching, where for example duplication of information, recency, authority, etc. matter, by using live W eb data and deal with the implications of its heterogeneous and dynamic nature for evaluation, etc.</p><p>De ne Web search tasks in four domains chosen based on surveys of popular web usage -tasks experimental searchers should be able to identify with based on a simple cover story: nding consumer medical information on a given subject, buying a given item, planning travel to a given place, collecting material for a project on a given subject.</p><p>At least for the rst 2-yr cycle TREC-2001 2 allow participants to undertake mainly observational studies during the rst year, but designed to support metrics-based comparison of systems during the second year. This might i n volve collecting web documents during year 1 for use as a static collection in year 2.</p><p>Alter the experimental design probably only for use in year 2 to allow for more statements of information need e.g., questions circa 25. A given searcher would only search a small subset. It might still be based on the 2-topic-by-2-search Latin square to retain blocking by searcher and topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Authors' note</head><p>The design of the TREC-9 Interactive T rack matrix experiment grew out of the e orts many people, who contributed to the discussion the track discussion list, suggested questions, and helped test them.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,330.48,640.71,209.04,13.80;1,330.48,662.43,124.56,13.80;2,91.92,124.47,110.28,13.80;2,91.92,153.39,208.68,13.80;2,91.92,165.27,37.08,13.80;2,91.92,194.19,174.84,13.80;2,91.92,223.11,208.80,13.80;2,91.92,235.11,83.04,13.80"><head></head><label></label><figDesc>an interactive search task | question answering 8 questions | short answers 16 searchers | minimum a newswire newspaper article collection to be searched a required set of searcher questionnaires 5 classes of data to be collected at each site and submitted to NIST</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,310.56,132.15,228.72,13.80;5,310.56,144.15,24.96,13.80"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Responses to question 7 by assessment outcome.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,72.00,132.15,228.72,13.80;6,72.00,144.15,24.96,13.80"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Responses to question 8 by assessment outcome.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,370.80,259.95,168.60,13.80;7,330.48,271.83,208.92,13.80;7,352.44,293.19,186.84,13.80;7,352.44,305.19,28.44,13.80;7,352.44,321.87,96.12,13.80;7,330.48,343.11,208.80,13.80;7,330.48,355.11,208.80,13.80;7,330.48,367.11,208.80,13.80;7,330.48,378.99,208.80,13.80;7,330.48,390.99,136.32,13.80;7,330.48,412.35,209.04,13.80;7,330.48,424.23,208.92,13.80;7,330.48,436.23,208.80,13.80;7,330.48,448.23,93.48,13.80;7,352.44,469.47,186.96,13.80;7,352.44,481.47,83.28,13.80;7,352.44,498.15,186.84,13.80;7,352.44,510.03,26.64,13.80;7,330.48,531.39,208.80,13.80;7,330.48,543.39,208.80,13.80;7,330.48,555.27,208.92,13.80;7,330.48,567.27,88.44,13.80;7,330.48,588.63,208.80,13.80;7,330.48,600.51,198.96,13.80;7,352.44,621.87,186.84,13.80;7,352.44,633.87,90.48,13.80;7,352.44,650.55,186.84,13.80;7,352.44,662.43,38.04,13.80;8,91.92,124.47,208.80,13.80;8,91.92,136.47,186.00,13.80;8,91.92,159.39,208.80,13.80;8,91.92,171.27,208.80,13.80;8,91.92,183.27,115.32,13.80"><head></head><label></label><figDesc>University Alexander, Brown, &amp; J o emon, in press looked at the value of summaries: indicative, query-biased document summaries full text of documents Oregon Health Sciences University Hersh et al., in press asked whether techniques which are effective in batch IR are also e ective in an interactive setting. Their work compared Okapi weighting with tf.idf weighting. Royal Melbourne Institute of Technology-CSIRO D'Souza, Fuller, Thom, Vines, &amp; Zobel, in presscompared the use of two di erent document surrogates: document title plus the rst twenty w ords from the document document title plus the three best" sentences They used two measures of system e ectiveness: number of responses complete and fully supported and number of requested items correct and fully supported. Rutgers University Belkin et al., in press examined two i n terfaces for question answering: 10 titles plus the text of the top document plus suggested terms 6 scrollable documents showing the best passage" They evaluated the systems in terms of number of responses complete and fully supported. She eld University Beaulieu, Fowkes, &amp; Joho, in press studied a known system's Okapi performance on the new task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,310.56,131.43,228.72,54.64"><head>Table 1 :</head><label>1</label><figDesc>Minimal 16-searcher-by-8-question matrix as run.</figDesc><table coords="3,324.14,167.45,197.83,18.62"><row><cell></cell><cell>Block 1</cell><cell>Block 2</cell></row><row><cell>Searcher</cell><cell>System: Questions</cell><cell>System: Questions</cell></row><row><cell>1</cell><cell>B:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,72.00,131.43,228.72,100.34"><head>Table 2 :</head><label>2</label><figDesc>Basic 2-by-2 Latin square on which e v aluation is based.</figDesc><table coords="4,123.71,170.80,123.60,60.97"><row><cell>Searchers</cell><cell cols="2">System,Topic combinations</cell></row><row><cell>S1</cell><cell>E,Tx</cell><cell>C,Ty</cell></row><row><cell>S2</cell><cell>C,Ty</cell><cell>E,Tx</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,310.56,440.19,228.72,13.80;8,335.52,452.19,203.76,13.80;8,335.52,464.19,203.88,13.80;8,335.52,476.07,203.88,13.80;8,335.52,488.07,203.64,13.80;8,335.52,500.07,161.76,13.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,335.52,452.19,203.76,13.80;8,335.52,464.19,203.88,13.80;8,335.52,476.07,17.09,13.80">Question answering, relevance feedback and summarisation: TREC-9 interactive track report</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Joemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,369.96,488.22,169.20,13.60;8,335.52,500.22,41.14,13.60">The Ninth Text REtrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman Eds</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="8,310.56,521.43,228.72,13.80;8,335.52,533.43,203.88,13.80" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fowkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in press. She eld Interactive Experiment at TREC-9</note>
</biblStruct>

<biblStruct coords="8,335.52,545.31,203.76,13.80;8,335.52,557.46,203.64,13.60;8,335.52,569.46,12.12,13.60" xml:id="b2">
	<monogr>
		<title level="m" coord="8,335.52,557.46,203.64,13.60;8,335.52,569.46,6.06,13.60">The Ninth Text REtrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman Eds</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,310.56,590.67,228.72,13.80;8,335.52,602.67,203.76,13.80;8,335.52,614.67,203.88,13.80;8,335.52,626.55,203.88,13.80;8,335.52,638.55,203.88,13.80;8,335.52,650.55,203.64,13.80;8,335.52,662.43,184.20,13.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,488.28,602.67,51.00,13.80;8,335.52,614.67,203.88,13.80;8,335.52,626.55,203.88,13.80;8,335.52,638.55,52.80,13.80">Support for Question-Answering in Interactive Information Retrieval: Rutgers&apos; TREC-9 Interactive Track Experiments</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Perez-Carballo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sikora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,390.12,650.70,149.04,13.60;8,335.52,662.58,63.58,13.60">The Ninth Text REtrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman Eds</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="9,72.00,124.47,228.72,13.80;9,96.96,136.47,203.88,13.80;9,96.96,148.35,203.76,13.80;9,96.96,160.35,203.52,13.80;9,96.96,172.35,161.76,13.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,180.24,136.47,120.60,13.80;9,96.96,148.35,26.85,13.80">Melbourne TREC-9 Experiments</title>
		<author>
			<persName coords=""><forename type="first">D'</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vines</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,131.40,160.50,169.08,13.60;9,96.96,172.50,41.14,13.60">The Ninth Text REtrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman Eds</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="9,72.00,192.27,228.84,13.80;9,96.96,204.15,203.76,13.80;9,96.96,216.15,125.40,13.80" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Over</surname></persName>
		</author>
		<title level="m" coord="9,223.68,192.27,77.16,13.80;9,96.96,204.15,203.76,13.80;9,96.96,216.30,58.50,13.60">SIGIR Workshop on Interactive Retrieval at TREC and Beyond. SIGIR Forum</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.00,236.07,228.72,13.80;9,96.96,248.07,203.76,13.80;9,96.96,259.95,203.88,13.80;9,96.96,271.95,203.76,13.80;9,96.96,283.83,203.76,13.80;9,96.96,295.83,203.64,13.80;9,96.96,307.83,195.48,13.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,267.84,248.07,32.88,13.80;9,96.96,259.95,203.88,13.80;9,96.96,271.95,203.76,13.80;9,96.96,283.83,68.95,13.80">Further Analysis of Whether Batch and User Evaluations Give the Same Results With a Question-Answering Task</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Turpin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sacherek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kraemer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,166.44,295.98,134.16,13.60;9,96.96,307.98,74.86,13.60">The Ninth Text REtrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman Eds</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="9,72.00,327.75,228.72,13.80;9,106.20,339.63,194.52,13.80;9,96.96,351.63,41.16,13.80" xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Vogt</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in press. Passive F eedback Collection An Attempt to Debunk the Myth of Clickthroughs</note>
</biblStruct>

<biblStruct coords="9,142.80,351.63,157.92,13.80;9,96.96,363.63,203.52,13.80;9,96.96,375.66,48.00,13.60" xml:id="b8">
	<monogr>
		<title level="m" coord="9,131.40,363.78,169.08,13.60;9,96.96,375.66,41.14,13.60">The Ninth Text REtrieval Conference TREC-9</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman Eds</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
