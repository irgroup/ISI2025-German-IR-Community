<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,167.20,75.53,278.00,12.53">CINDOR TREC-9 English-Chinese Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,233.44,105.06,74.71,10.80"><forename type="first">Miguel</forename><forename type="middle">E</forename><surname>Ruiz</surname></persName>
							<email>mruiz@textwise.com</email>
							<affiliation key="aff0">
								<orgName type="institution">MNIS-TextWise</orgName>
								<address>
									<addrLine>Labs 401 South Salina Street Syracuse</addrLine>
									<postCode>13202</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.74,105.06,55.69,10.80"><forename type="first">Steve</forename><surname>Rowe</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MNIS-TextWise</orgName>
								<address>
									<addrLine>Labs 401 South Salina Street Syracuse</addrLine>
									<postCode>13202</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.72,118.74,91.79,10.80"><forename type="first">Maurice</forename><surname>Forrester</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MNIS-TextWise</orgName>
								<address>
									<addrLine>Labs 401 South Salina Street Syracuse</addrLine>
									<postCode>13202</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.80,118.74,82.54,10.80"><forename type="first">PÃ¡raic</forename><surname>Sheridan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MNIS-TextWise</orgName>
								<address>
									<addrLine>Labs 401 South Salina Street Syracuse</addrLine>
									<postCode>13202</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,167.20,75.53,278.00,12.53">CINDOR TREC-9 English-Chinese Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E4C7F2BB9FB3FBAA399C72AD8BAC57E7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MNIS-</head><p>TextWise Labs participated in the TREC-9 Chinese Cross-Language Information Retrieval track. The focus of our research for this participation has been on rapidly adding Chinese capabilities to CINDOR using tools for automatically generating a Chinese Conceptual Interlingua from existing lexical resources. For the TREC-9 evaluation we also built a version of our system which loosely integrates the CINDOR Conceptual Language Analysis process with the SMART retrieval system. This was motivated by the conclusions of our TREC-8 experiments which pointed to sub-standard retrieval based on the underlying retrieval algorithm. This integrated system has further allowed us to experiment with a range of approaches for crosslanguage retrieval, some specific to Chinese, which we have used in combination for our official TREC submissions. For evaluation, we submitted a monolingual Chinese run and a crosslanguage English-Chinese run. Analysis of results to date allow us to conclude that the automatically generated Conceptual Interlingua helps to improve performance in both crosslanguage and monolingual retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The CINDOR (Conceptual Interlingua Document Retrieval) project at MNIS-TextWise Labs is pursuing a 'Conceptual Interlingua' approach to cross-language information retrieval, based on a conceptual lexical resource modeled around WordNet <ref type="bibr" coords="1,454.72,531.16,56.96,10.80" target="#b1">[Miller 1990</ref>]. The current version of CINDOR supports cross-language retrieval in any combinations of English, Spanish, French, Italian, German, and Japanese (and now Chinese). For our TREC-9 participation we concentrated our efforts in rapidly adding Chinese capabilities to CINDOR and building tools that allow automatic generation of a (Chinese) Conceptual Interlingua. Our approach is based on automatically mapping Chinese terminology into English WordNet concepts using existing bilingual dictionaries and corpora. This paper presents an overview of each stage of our research leading up to the submission of TREC-9 runs. It includes a brief introduction to the CINDOR approach to cross-language retrieval in Section 2, followed by a description of our techniques for mapping existing lexical resources into the Conceptual Interlingua in Section 3. Section 4 gives an overview of the CINDOR system used in our experiments, incorporating the SMART retrieval engine for weighting and retrieval, and the various cross-language retrieval techniques that we combined in our final experiments. We conclude in Section 5 with an overview of the results obtained in our TREC-9 submission based on the brief analysis we have conducted so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The CINDOR System.</head><p>The CINDOR system is a cross-language text retrieval system capable of accepting a user's query stated in their native language and then seamlessly searching, relevance ranking, retrieving and displaying documents written in a variety of foreign languages. A general overview of the CINDOR system and approach to cross-language retrieval can be found in <ref type="bibr" coords="2,132.62,242.68,79.44,10.80" target="#b2">[Ruiz et al 2000]</ref>.</p><p>At the core of the CINDOR approach to cross-language retrieval is the idea of a 'Conceptual Interlingua'; a hierarchically organized knowledge base of essentially language-independent concepts. This concept hierarchy is then linked to multiple terminological resources for different languages which realize the lexicalization of concepts in each of the languages of the system. Cross-language retrieval is enabled by mapping the terms of documents and user queries from different languages into the interlingual concept representation, which provides the vocabulary for indexing and matching of document and query content.</p><p>Our Conceptual Interlingua has been built around the Princeton WordNet <ref type="bibr" coords="2,454.24,394.36,57.44,10.80" target="#b1">[Miller 1990</ref>], which contains approximately 165,000 different word forms organized into some 92,000 concepts denoted by a group of synonyms, or 'synsets'. We consider the synset hierarchy as the core of the Conceptual Interlingua, with the 165,000 English terms to be the starting terminology for English. This has been extended with terminology in French, Spanish, and Japanese mapping to about 20,000 synsets in each case. More recently, we have integrated the German and Italian versions of EuroWordNet in order to provide a basis of terminology coverage in those languages. A primary focus of our research for TREC-9 has been the automated extension of the Conceptual Interlingua to terminology in Chinese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Chinese Conceptual Interlingua</head><p>A stated goal of our research agenda in conjunction with TREC-9 participation was to link Chinese terminology into the Conceptual Interlingua in a fully automated process in as little time as possible. Our resulting efforts spanned a two-month period with essentially one person concentrating on this effort. Our goal was to identify existing lexical or terminology resources in Chinese and one of the existing Conceptual Interlingua languages (English) and use a range of approaches to link concepts to Chinese terms. While we were aware of a Chinese resource similar to WordNet (HowNet), it was not clear that there was a simple mapping from HowNet to WordNet (plus it did not appear that we would ultimately be granted permission to use this resource commercially), so use of this resource was not considered. We therefore concentrated our work on a bilingual English-Chinese lexicon available through the Linguistic Data Consortium (LDC) <ref type="bibr" coords="3,189.26,102.28,55.69,10.80">[LDC 2000</ref>] and a parallel English-Chinese corpus of Hong Kong Laws.</p><p>The basic approach to linking Chinese terminology to our Conceptual Interlingua is to find the most likely Chinese translations for each English term. The LDC bilingual lexicon contains translations for 110,834 English terms (including single terms and phrases). Generating pairs for all possible translations from English to Chinese from this lexicon generates 224,427 English-Chinese translation pairs. While a simple approach would involve linking each English term in the Conceptual Interlingua to every one of the Chinese translations from the lexicon, we have investigated the use of a process of 'lexical triangulation' in order to find evidence to support the choice of the most likely translation(s) for each term when multiple translations are possible. In the first instance, we take advantage of the WordNet synsets that are retained in the Conceptual Interlingua. More often than not, a synset contains more than one synonymous term, each of which may have multiple translations from the bilingual lexicon. By applying various intersections to the set of Chinese translations, we can limit the Chinese terms to those more likely to be translations of the sense of the English terms as used in that particular concept (synset). If we take all of the Chinese translations of all synonyms in a synset and rank them by frequency of occurrence, then several criteria for selection can be applied:</p><p>1.</p><p>Strict intersection: Only the Chinese terms that are translations of all synonyms associated with the synset are selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Threshold method: Only the Chinese translations with frequency above a certain threshold are selected. We have set this threshold at 50% of the number of English terms associated with the synset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Relaxed threshold: All the Chinese terms with frequency above a threshold, and all those terms that have frequency greater than 1. We selected the same threshold value of 50% of the number of English terms associated with the synset. Observe that for synsets that have 4 or less English terms associated, this option is the same as option 2. However for synsets that have more than 5 words associated, this option tends to generate a larger number of terms.</p><p>An example of this process of lexical triangulation is presented in Figure <ref type="figure" coords="3,452.89,612.76,6.00,10.80">1</ref> below. The English concept (kidnap, verb) has four English terms associated with it. Given the Chinese translations of each of these terms from the bilingual lexicon, there is one term (w8) that is a possible translation for three of the four English synonyms. If we use criteria 1 above, the method will generate no entries in the Chinese terminology of the Conceptual Interlingua for the verb kidnap. If we use criteria 2 or 3 above however, the Chinese term w8 will be linked to the concept of the verb kidnap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: Translation of terms of the concept kidnap</head><p>When we applied this process over the entire LDC lexicon to link Chinese terms to the Conceptual Interlingua, the 'strict intersection' criteria yielded 13,337 Chinese terms linked to about 12,000 concepts. The 'threshold' method generated coverage comparable to our European languages (terms linked to about 25% of concepts), while the 'relaxed' method resulted in terms linked to about 63% of concepts, but is expected to contain more noise.</p><p>We were then further able to extend our process of lexical triangulation through the use of a parallel English-Chinese corpus as an additional source of translation evidence. Using a bilingual lexicon as a bootstrapping device, one can examine the sentence contexts of a parallel corpus to identify translations of English terms for which no translation is given in the bilingual lexicon. Given an English word W E for which a translation is sought, a context can be identified (either the sentence in which the word occurs or a fixed window of surrounding words) in the English corpus. We then use the bilingual lexicon to find translations of as many of the words in the context of W E as possible and align these with words in the context from the aligned Chinese corpus. Words remaining in the Chinese context, after stopwords have been removed, are candidate translations for W E . For any given English word, candidate selection can be performed over multiple occurrences of the word in the corpus and candidates then ranked by frequency of occurrence. Further, this can be expanded to encompass Chinese terms as candidates for translation of all synonym terms within a concept, as outlined in the process above.</p><p>While investigating our corpus processing approach however, we discovered that many translation candidates identified from the corpus intersected with translation candidates English Synset: 15 / verb /abduct/ kidnap/ nobble/ snatch/ Bilingual Dictionary Entries:</p><formula xml:id="formula_0" coords="4,108.64,205.04,169.44,6.72">$EGXFW w89&lt;Ã²</formula><p>.</p><p>LGQDS 9&lt;8w88Ã¶9Ã®8</p><formula xml:id="formula_1" coords="4,108.64,246.80,278.88,27.60">1REEOH N 6QDWFK Ã_ Â¶Ã Â¬Ã¶]?cÃP</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ÃWÃ«ÃM8ÃiÃ\Ã</head><p>from the bilingual lexicon, but which were not selected by any of our three selection criteria described above. We therefore adopted a modified translation selection approach as follows:</p><p>1. Generate candidate Chinese terms for a concept based on translation of all English synonyms from the bilingual dictionary (note: the first step was to translate the LDC lexicon from GB to Big-5 encoding to match the parallel corpus) 2. Generate frequency-ranked candidate Chinese translations for an English term from aligned contexts the parallel corpus 3. Accept Chinese terms which meet the 'threshold' criteria above 4. Accept additional Chinese terms which are candidates in both the lexicon and corpus sets (corpus-attested translations).</p><p>This combined approach generated a Chinese Conceptual Interlingua with over 63,000 terms linked in to 38,000 concepts (40% coverage of WordNet) and this is what we used in our TREC-9 experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CINDOR Chinese Retrieval</head><p>Given the Conceptual Interlingua approach encompassed in the CINDOR system, lexicalconceptual analysis of documents and queries is an integral part of the indexing process. Specifically, when dealing with Chinese, this necessitates tokenization/segmentation of input text as opposed to using character n-grams (bi-grams) as are often used for Chinese retrieval. We use the 'mansegment' segmentation module available through the Linguistic Data Consortium. An advantage of this module over other segmenters available is that it is capable (with different configuration) of segmenting Chinese text written with either traditional or simplified character sets. Chinese terms identified through segmentation are then matched against the Chinese Conceptual Interlingua terminology for mapping into concepts which are used in indexing.</p><p>It was the clear conclusion of our TREC-8 experimentation, supported by some follow-on investigation that we conducted, that retrieval performance of the CINDOR system was being negatively impacted by the use of a simplified tfÃidf retrieval mechanism in the underlying search engine that was performing well below the standard of other retrieval engines participating in the TREC evaluation. In order to address this issue, we have loosely integrated CINDOR's Conceptual Interlingua processing with the SMART retrieval system <ref type="bibr" coords="5,170.35,616.12,59.59,10.80" target="#b3">[Salton 1971</ref>]. We used the Cornell ftp version of SMART augmented with recent term weighting schemes (pivoted length normalization and BM25) and modified to handle UTF-8 encoded text. Our use of SMART therefore enabled various experiments with respect to CINDOR retrieval in the Chinese cross-language track.</p><p>Our first investigation concerned the use of multiple indexing vocabularies of Chinese text in CINDOR (known as ctypes in SMART terminology). Given the process of analyzing Chinese text in CINDOR, we had access to three possible indexing vocabularies:</p><p>â¢ Terms: output from the Chinese segmenter â¢ Concepts: assigned from the Conceptual Interlingua for Chinese terms â¢ Bi-grams: derived directly from the Chinese documents (queries)</p><p>We therefore compiled three vector representations of each Chinese document, corresponding to each vocabulary. Similarity between a query and documents was then computed using a linear combination of the vector similarities of each vocabulary:</p><p>Sim(d,q) = Î»* Sim Terms (d,q) + Î¸ * Sim Concepts (d,q) + Ï * Sim Bigrams (d,q)</p><p>Where Î», Î¸, and Ï are coefficients that weight the contribution of each vocabulary, d is the document vector and q is the query vector. We used the well known pivoted length normalization (Lnu.ltu) weighting scheme <ref type="bibr" coords="6,297.04,286.12,96.16,10.80" target="#b3">[Singhal et al 1996]</ref>. This scheme weights the documents using logarithmic average term frequency and unique term pivoted length normalization, which corresponds to the formula:</p><formula xml:id="formula_2" coords="6,194.80,338.12,222.50,49.48">terms unique of # ) 0 . 1 ( ) average log( 1 ) log( 1 Ã + Ã - + + slope pivot slope tf tf</formula><p>where tf is the term frequency, slope and pivot are parameters of the pivoted length normalization scheme. For our runs we use a slope=0.25 and the pivot is set to the average document length of the collection.</p><p>We experimented with pseudo-relevance feedback using Rocchio's formula to rank the terms in an initial retrieved set to expand the query for a feedback loop:</p><formula xml:id="formula_3" coords="6,206.56,496.94,195.56,39.94">R n w R w w w R d d R d d orig new i i i i - + + = â â â â Î³ Î² Î±</formula><p>where w orig is the weight of the term in the original query; i d w is the weight of the term in document d i ; R is the set of relevant documents; |R| is the number of relevant documents; n is the number of documents considered (in retrieval feedback this is usually set to the number of documents presented to the user); and Î±, Î², and Î³ are constant coefficients that control the contribution of each factor. Terms with negative weights are discarded. The terms are ranked by the computed weight w new and the top m terms are used to expand the query.</p><p>Our pseudo-relevance feedback method uses the original query to obtain the top 1000 retrieved documents. We assume that the top N documents are relevant and that the bottom 100 documents are not relevant. The query is then expanded with the top m ranked terms according to Rocchio's formula. Since we are using three index vocabularies, the pseudo-relevance feedback process adds m expansion terms to each vocabulary (vector).</p><p>Given this retrieval scenario, discovery of optimal settings for this retrieval model involves tuning the following parameters:</p><p>â¢ Î», Î¸ and Ï for the combination of each vocabulary vector in the final similarity score.</p><p>â¢ Î±, Î², Î³, N and m for pseudo-relevance feedback using Rocchio's formula.</p><p>We first found the best parameter combination for pseudo-relevance feedback on the TREC-5 and TREC-6 Chinese track test collections, consisting of documents from the People's Daily newspaper and the Xinhua news agency, trying all combinations of the 5 parameters using only a single vocabulary (terms) for the monolingual Chinese queries with the following sets of possible values: Our initial retrieval baseline for feedback was simple retrieval using the Lnu.ltu weighting scheme. Observe that the rationale for selecting the values for Î±, Î² and Î³ is that given a fixed value for the contribution of the original query terms (Î±=8), we explore relative weightings of the contribution of relevant and non-relevant documents (e.g. 2ÃÎ±).</p><formula xml:id="formula_4" coords="7,126.16,294.20,47.90,15.64">â¢ N = 5,</formula><p>We tried the 168 possible combinations with the above parameter values for each of the two sets of Chinese topics. Figure <ref type="figure" coords="7,262.07,483.88,6.00,10.80" target="#fig_1">2</ref> below shows the variation of performance (average precision) for the set of TREC-6 queries and N=10 (48 runs). The highest performance is obtained for N=10, m=20, Î±=8, Î²=64 and Î³=32 with an average precision of 0.5263. Therefore, the top 20 terms are selected for query expansion based on the assumption that the top 10 documents are relevant (using Î±=8, Î²=64 and Î³=32 in the Rocchio formula).</p><p>Similarly, we found through testing on the TREC-5 and TREC-6 Chinese test collections the optimal set of parameters Î» (terms), Î¸ (concepts) and Ï (bi-grams) for weighting the relative contribution of each indexing vocabulary to the final document-query similarity value. We found that monolingual retrieval and cross-language retrieval have different optimal parameter settings. For monolingual retrieval the best performance was found to be Î»=20, Î¸=1 and Ï=20 while for cross-language retrieval the best parameter settings are Î»=4, Î¸=1 and Ï=4. These parameters indicate that, while not contributing as much as the Term or Bi-gram indexing vocabularies for retrieval, our Conceptual Interlingua concepts are relatively more important in a cross-language retrieval setting than in a monolingual search environment. We have tested and verified our overall retrieval approach and Conceptual Interlingua on the TREC-5 and TREC-6 Chinese test collections through a series of retrieval experiments. Tables <ref type="table" coords="8,208.48,423.64,6.00,10.80" target="#tab_0">1</ref> and<ref type="table" coords="8,249.04,423.64,6.00,10.80" target="#tab_1">2</ref> below illustrate the incremental improvements in performance to be gained from the combination of approaches we have used. Simple term indexing results in an average precision of 0.3572 in a monolingual test over the TREC-5 collection. Term-based English-Chinese cross-language retrieval, using machine translation of terms (Alis Technology's Gist-in-Time system), gives average precision of 0.2408 in a similar test. Augmenting this run by concept indexing through the Conceptual Interlingua yields an improvement of 3.6% and 4.6% respectively. If this run is in turn augmented by pseudo-relevance feedback, there is a further 3.1% monolingual and 8.9% cross-language improvement in average precision. If bi-grams are then extracted from the documents and query (translation) and used in matching following the above linear combination, a final 9% and 9.3% improvement is observed. These improvements in performance are replicated on the TREC-6 test collection in the same way in Table <ref type="table" coords="9,185.08,88.36,4.48,10.80" target="#tab_1">2</ref>. The aggregate result is performance 16% and 10% over the termbased baseline for monolingual retrieval in TREC-5 and TREC-6, with 24.5% and 25.3% improvements in cross-language retrieval in the same way. This, we felt, provided a firm foundation from which to launch our TREC-9 submissions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TREC-5 Test Collection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">TREC-9 Results and Analysis</head><p>We submitted a monolingual run (TWmono3CItdn) and a cross-language run (TWe2c3CItdn) for evaluation by NIST. Both runs correspond to the best parameter settings for the training collection as explained in the previous section. Our final results for TREC 9 monolingual performance show an average precision of 0.3041. This monolingual run is above the median in 18 of the 25 topics. The average difference above the median is 0.052 (20.5% above the median).</p><p>Our cross-language run achieved 0.1312 average precision, which is below the median (0.1460). The cross-language results are above the median in 13 of the 25 topics and a difference with the median of -0.015 (10.9% below the median). This cross-language run achieved 42% of our monolingual run performance, which is considerably lower than the 70% we obtained in the training set. While we have not yet conducted an in-depth analysis of what caused this low cross-language performance relative to our monolingual baseline, we suspect it to be primarily related to gaps in the translation resources used. Even from a superficial analysis of the results, it is clear that there were gaps in translation, both in the machine translation and the Conceptual Interlingua. Examples are 'Daya Wan electric plant', 'computer hackers', 'Tiananmen Square', etc. We have also noticed that the machine translation system consistently translated 'China' as '}Ã®' (in the sense of "Mom's bestâ¦") instead of 'Â³S' (the nation). This was compensated for however by the fact that the correct translation of 'China' had been captured in the Conceptual Interlingua. Since most of the queries were about China however, this is likely to have impacted the final performance of some queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Our TREC-9 experiments reported here are part of an ongoing set of experiments that evaluate the performance of the CINDOR system over a wide range of languages. Our work on automatic generation of Conceptual Interlingua resources here has, as desired, generated a general approach and a corresponding set of tools that can now be applied toward the rapid addition of other languages. Our results indicate that the automatically generated Conceptual Interlingua can contribute to improved retrieval performance for cross-language information retrieval over a simple term-based baseline.</p><p>The research version of CINDOR used here has certainly benefited from integration with the retrieval capabilities of SMART. This has had the further advantage of allowing us to experiment with retrieval models using a combination of indexing vocabularies and a combination of different sources of evidence for cross-language retrieval.</p><p>Despite the apparent success of our TREC-9 participation, especially in our monolingual Chinese runs, we believe that there remain avenues along which we can further enhance the performance of the CINDOR system. We continue to pursue research directed at improving our cross-language retrieval precision in all languages by processing and matching of named entities and multi-word terms across languages and in the area of word sense disambiguation in the framework of WordNet for our Conceptual Interlingua. We hope to realize the fruits of these efforts in future evaluations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,177.30,298.12,65.48,10.80;7,126.16,309.08,189.83,15.64;7,126.16,323.72,44.64,15.64;7,126.16,338.36,84.72,15.64;7,126.16,353.00,95.51,15.64"><head></head><label></label><figDesc>10 ,15 and 20 â¢ M = 5, 10 20, 50, 100, 150 and 200 â¢ Î± = 8 â¢ Î² = 32 and 64 â¢ Î³ = 8, 16 and 32</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,121.60,354.04,368.87,10.80;8,177.52,368.68,222.22,10.80;8,402.89,364.49,31.57,15.99"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Variation of performance (Average Precision) for N=10 and 48 combinations of Rocchio parameters m and Î±, Î², Î³</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,104.56,90.42,400.32,624.34"><head>Table 1 :</head><label>1</label><figDesc>Incremental improvements in Average Precision from combination of retrieval techniques</figDesc><table coords="8,104.56,604.60,400.32,81.12"><row><cell></cell><cell>Monolingual</cell><cell cols="3">% Gain Cross-Language % Gain</cell></row><row><cell>Term Indexing (MT)</cell><cell>.3572</cell><cell></cell><cell>.2408</cell><cell></cell></row><row><cell cols="2">+ Conceptual Interlingua .3701</cell><cell>3.6%</cell><cell>.2518</cell><cell>4.6%</cell></row><row><cell>+ Relevance Feedback</cell><cell>.3817</cell><cell>3.1%</cell><cell>.2742</cell><cell>8.9%</cell></row><row><cell>+ Bi-gram Indexing</cell><cell>.4161</cell><cell>9%</cell><cell>.2998</cell><cell>9.3%</cell></row><row><cell></cell><cell></cell><cell>16%</cell><cell></cell><cell>24.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,104.56,171.40,400.32,125.28"><head>Table 2 :</head><label>2</label><figDesc>Incremental improvements in Average Precision from combination of retrieval techniques</figDesc><table coords="9,104.56,171.40,400.32,96.48"><row><cell></cell><cell cols="2">TREC-6 Test Collection</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Monolingual</cell><cell cols="3">% Gain Cross-Language % Gain</cell></row><row><cell>Term Indexing (MT)</cell><cell>.5010</cell><cell></cell><cell>.3091</cell><cell></cell></row><row><cell cols="2">+ Conceptual Interlingua .5151</cell><cell>2.8%</cell><cell>.3170</cell><cell>2.6%</cell></row><row><cell>+ Relevance Feedback</cell><cell>.5208</cell><cell>1.1%</cell><cell>.3472</cell><cell>9.5%</cell></row><row><cell>+ Bi-gram Indexing</cell><cell>.5509</cell><cell>5.8%</cell><cell>.3875</cell><cell>11.6%</cell></row><row><cell></cell><cell></cell><cell>10%</cell><cell></cell><cell>25.3%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,95.37,408.89,90.30,12.53;10,90.16,435.20,54.29,9.94;10,126.16,447.92,395.88,9.94;10,126.16,460.64,193.26,9.94" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,96.57,435.20,47.88,9.94;10,126.16,447.92,134.91,9.94;10,281.05,447.92,232.81,9.94">List of Chinese Resources over the Internet</title>
		<author>
			<persName coords=""><surname>Bibliography</surname></persName>
		</author>
		<ptr target="http://morph.ldc.upenn.edu/Projects/Chinese" />
		<imprint/>
	</monogr>
	<note>LDC 2000] Linguistic Data Consortium</note>
</biblStruct>

<biblStruct coords="10,126.16,498.56,396.00,10.08;10,126.16,511.28,217.05,10.08;10,90.16,536.48,75.20,10.08" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,189.86,498.56,194.64,9.94">WordNet: An On-line Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,403.12,498.70,119.04,9.94;10,126.16,511.42,58.38,9.94">International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1990">1990</date>
			<publisher>Special Issue</publisher>
		</imprint>
	</monogr>
	<note>Ruiz et al 2000</note>
</biblStruct>

<biblStruct coords="10,126.16,549.20,395.94,9.94;10,126.16,561.68,396.10,10.08;10,126.16,574.40,189.20,10.08" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,330.18,549.20,191.91,9.94;10,126.16,561.68,131.66,9.94">CINDOR Conceptual Interlingua Document Retrieval:TREC-8 Evaluation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Diekema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,273.04,561.82,249.22,9.94;10,126.16,574.54,41.28,9.94">Proceedings of the eighth Text Retrieval Conference (TREC-8)</title>
		<meeting>the eighth Text Retrieval Conference (TREC-8)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,126.16,612.32,395.88,10.08;10,126.16,625.04,187.80,9.94;10,90.16,650.24,87.44,10.08;10,126.16,662.96,396.24,9.94;10,126.16,675.82,99.84,9.94;10,226.00,673.44,5.40,6.26;10,235.36,675.82,286.71,9.94;10,126.16,688.40,395.95,10.08;10,126.16,700.88,28.44,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,174.40,612.46,343.04,9.94;10,313.30,662.96,185.02,9.94">The SMART retrieval system: Experiments in automatic document processing</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,126.16,675.82,99.84,9.94;10,226.00,673.44,5.40,6.26;10,235.36,675.82,286.71,9.94;10,126.16,688.54,168.85,9.94">Proceedings of the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Englewood Cliffs, NJ; New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1971-08">1971. August 1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
	<note>Pivoted Document Length Normalization</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
