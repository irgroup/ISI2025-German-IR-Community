<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.50,75.77,307.98,16.20;1,228.71,96.41,154.53,16.20;1,181.43,117.29,249.37,16.20">Question answering, relevance feedback and summarisation: TREC-9 interactive track report</title>
				<funder>
					<orgName type="full">Computing Science Research Committee</orgName>
				</funder>
				<funder ref="#_ZszCQHT">
					<orgName type="full">Library and Information Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.72,156.07,89.08,12.53"><forename type="first">Neill</forename><surname>Alexander</surname></persName>
							<email>alexannw@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.79,156.07,73.91,12.53"><forename type="first">Craig</forename><surname>Brown</surname></persName>
							<email>brownca@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.46,156.07,73.07,12.53"><forename type="first">Joemon</forename><surname>Jose</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,191.76,172.39,74.65,12.53"><forename type="first">Ian</forename><surname>Ruthven</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.28,172.39,121.03,12.53"><forename type="first">Anastasios</forename><surname>Tombros</surname></persName>
							<email>tombrosa@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.50,75.77,307.98,16.20;1,228.71,96.41,154.53,16.20;1,181.43,117.29,249.37,16.20">Question answering, relevance feedback and summarisation: TREC-9 interactive track report</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FFF5E5E098EB53CFEE0DECA889392F8B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we report on the effectiveness of query-biased summaries for a question-answering task. Our summarisation system presents searchers with short summaries of documents, composed of a series of highly matching sentences extracted from the documents. These summaries are also used as evidence for a query expansion algorithm to test the use of summaries as evidence for interactive and automatic query expansion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The main focus of Glasgow's Interactive Track study was to investigate the use of summaries in interactive searching.</p><p>Our experiments used a form of the query-biasing summarisation technique proposed by Tombros and Sanderson <ref type="bibr" coords="1,72.00,413.99,26.51,8.86" target="#b7">[TS98]</ref>, to create short document summaries that are tailored to the user's query. These summaries highlight the main points of the document that pertain to the query. The summaries are based on highly matching sentences, allowing users to view the context in which query terms are used within the document.</p><p>We hypothesised that this form of summarisation would be particularly effective for the time-limited, queryanswering task of the interactive track, in that summaries would allow users to filter out non-relevant documents more effectively and target potentially relevant documents more quickly than either title alone or the full text of the documents.</p><p>In addition, we investigated the use of summaries for relevance feedback (RF): by using the content of the summaries, rather than the full-text of the documents, to generate query expansion terms.</p><p>Our experiments indicate that although RF is generally not considered helpful, summaries can provide a popular and useful aid to finding relevant information.</p><p>The paper is structured as follows: in section 2 we describe the system we used in these experiments including details of the summarisation process, in section 3 we describe the interface, in section 4 we give details of the experimental subjects and in section 5 we analyse the results. We conclude in section 6. 1 Corresponding author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System</head><p>In section 2.1 we outline the main components of our system and in section 2.2 we describe how the summaries are created.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System architecture</head><p>Our experimental system was composed of three units: 1. retrieval system. The retrieval system (SMART) performs an initial query run using the query terms passed from the interface. The list of retrieved document identifiers and document titles are passed to the interface for display. 2. summariser. For each retrieved document, the summariser (described in section 2.2) generates a query-biased summary, which is passed to the interface on demand. 3. interface. The interface displays the retrieved document identifiers, document titles and summary. The overall look and feel of the interface is described in section 3.1. The interface is also responsible for logging user interaction and generating query expansion terms (described in section 3.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Summariser</head><p>A document summary conventionally refers to a condensed version of a document that succinctly presents the main points of the original document. Query-biased summarisation methods generate summaries in the context of an information need expressed as a query by a user. Such methods aim to identify and present to the user individual parts of the text that are more focused towards this particular information need than a generic, non-query-sensitive summary. In this way summaries can serve an indicative function, providing a preview format to support relevance assessments on the full text of documents <ref type="bibr" coords="2,237.91,561.83,32.29,8.86" target="#b5">[RSZ71]</ref>.</p><p>Query-biased text summarisation is an emerging area of summarisation research that had not been addressed until recently. Tombros and Sanderson looked into the application of such methods in information retrieval, evaluating the indicative function of the summaries <ref type="bibr" coords="2,238.17,607.91,26.26,8.86" target="#b7">[TS98]</ref>. Their study showed that users were better able to identify relevant documents when using the summaries than when using the first few sentences of a document. Recently the TIPSTER funded SUMMAC project <ref type="bibr" coords="2,224.53,630.96,71.93,8.86" target="#b3">[MHKHOFCS98]</ref> provided a framework for the evaluation of different types of summarisation systems. As part of that project, a number of query-biased summarisation systems were evaluated by measuring their ability to help users identify documents relevant to a query.</p><p>The summaries generated by our system were indicative and query-biased, aiming to provide users working on an interactive IR system with information on the relevance of documents retrieved in response to their query. The</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval system</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summariser</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieved doc ids Query terms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interface</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieved doc ids Doc full text Doc titles</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query terms</head><p>system is based on a number of sentence extraction methods that utilise information both from the documents of the collection and from the queries submitted, and is a simplified version of the system described in <ref type="bibr" coords="3,452.17,85.90,26.00,8.86" target="#b7">[TS98]</ref>.</p><p>Each document that was retrieved in response to a specific query was passed through the summarisation system, and as a result a score for each sentence of each document was computed. This score represents the sentence's importance for inclusion in the document's summary. Scores are assigned to sentences by examining the structural organisation of each document, and by utilising the inverse document frequency (IDF) weights assigned to each term. Information from the structural organisation of the documents was utilised in two ways. Terms occurring in the title section of a document were assigned a positive weight (title score) in order to reflect the fact that headlines of news articles tend to reveal the major subject of the article. In addition, a positive ordinal weight was assigned to the first two sentences of each article, capturing the informativeness of the leading text of news articles. The IDF weights of the terms in the collection were used as a source of evidence of attributing an overall measure of importance for each sentence of the source documents. In order to establish such a measure, the sum of the IDF weights of all the terms comprising a sentence was divided by the total number of terms in that sentence. In that way an importance score was attributed to each sentence in the collection.</p><p>In addition to the scores assigned to sentences, information from the query submitted by the user was also employed in order to compute the final score for each sentence. A query score was thus computed, intended to represent the distribution of query words in a sentence. The rationale for this choice was that, by allowing users to see the context in which the query terms occurred, they could better judge the relevance of a document to the query. The computation of that score was based on the distribution of query terms in each sentence. This was based on the belief that the larger the number of query terms in a sentence, the more likely that sentence conveyed a significant amount of the information need expressed in the query. The actual measure of significance of a sentence in relation to a specific query, was derived by dividing the square of the number of query terms included in that sentence by the total number of the terms comprising the query.</p><p>The final score for each sentence is calculated by summing the partial scores discussed above. The summary for each document is then generated by selecting the top-scoring sentences, and outputting them in the order in which they appear in the original document. Summary length was defined to be 20% of the document's length, up to a maximum of 6 sentences. Such a value seems to be in general agreement with suggestions made by <ref type="bibr" coords="3,465.54,409.22,26.51,8.86" target="#b1">[Ed64,</ref><ref type="bibr" coords="3,494.51,409.22,32.10,8.86" target="#b0">BMR95]</ref>.</p><p>Figure <ref type="figure" coords="3,101.12,432.50,4.92,8.86">3</ref> shows the summary produced from the document in Figure <ref type="figure" coords="3,352.69,432.50,3.72,8.86">2</ref>, retrieved in response to the query 'America national parks redwood trees'. In Figure <ref type="figure" coords="3,254.80,444.02,4.92,8.86">2</ref>  Creek Redwoods State Park in Humboldt County --are the crown jewels of the state park system and home to 2,000-year-old redwoods, among the oldest living things on Earth. &lt;/LEADPARA&gt; &lt;SECTION&gt; California News &lt;/SECTION&gt; &lt;HEADLINE&gt; STATE MAY CEDE ITS 3 REDWOOD PARKS TO U.S. &lt;/HEADLINE&gt; &lt;TEXT&gt; The proposal emerged from a review ordered by state Parks and Recreation Director Henry R. Agonia after the Wilson administration sent a directive to, state agencies asking them to identify budget cuts. The state is facing a staggering $2 billion deficit in this year's $55.7 billion budget.; The prospect of transferring California's redwood parks to the National Park Service drew praise and criticism from environmentalists and park rangers Wednesday as word spread.; "I'm strongly against it," state parks Superintendent Bill Beap said in a telephone interview from Eureka. "These are the prime jewels of the state park system."; But the proposal was welcomed by Sierra Club officials, who called it "a splendid idea." Edgar Wayburn, the club's vice president for conservation, noted that the neighboring National Redwood Park's boundaries touch all three state parks. &lt;/TEXT&gt; &lt;BYLINE&gt; Los Angeles Times &lt;/BYLINE&gt; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Interface</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Look and feel</head><p>The interface consists of four main components: list of 20 retrieved document titles and associated check boxes for marking documents relevant, summary display, query box and suggested expansion terms.</p><p>A summary was generated on demand each time the user moved the mouse pointer over a document title. The complete document could be viewed, in a separate window, by clicking on the document title.</p><p>Query expansion was both automatic (the top 6 expansion terms were automatically added to the query when the user requested more documents), and interactive. The user could request suggestions for new query terms by clicking the 'Get More Terms' button, the suggested terms appearing in the 'More Terms' box on the bottom left of the screen. Each query, and suggested, term was displayed in this box; check-boxes were used to add/delete terms from the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relevance feedback</head><p>To assist users in modifying their queries, a query expansion facility was offered. Expansion terms were selected from the summaries of marked relevant documents using Porter's term weighting function <ref type="bibr" coords="4,438.52,497.02,27.14,8.86" target="#b4">[PG88]</ref>. This is shown in Equation 1, where r equals the number of relevant summaries containing a term, R is the number of relevant documents, n is the number of documents in the collection containing the term, and N is the number of documents in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Porter = r Rn N Equation 1: Porter term weighting function</head><p>This use of Porter's term weighting function differs from other applications in that r is based on the terms appearance in a summary of a relevant document, rather than the whole document. The basis for this is that a querybiased summary of a document may be a better source of relevant terms than the full-text of the document. This may be especially true for long documents that cover many topics.</p><p>For this experiment we used only the summary to determine possible expansion terms, even if the user had viewed the full-text of the document. A natural enhancement of this may be to vary the source of the expansion terms according to the representation(s) of the document viewed by the user. For example if the user has only viewed a summary before making an assessment, then the summary should be used for feedback, if the user has viewed the full text of the document, then the full-text may be a better source of evidence for feedback.</p><p>This method of calculating relevance weights has previously been shown to give good results <ref type="bibr" coords="5,462.31,85.90,28.59,8.86" target="#b4">[PG88,</ref><ref type="bibr" coords="5,494.41,85.90,30.59,8.86" target="#b2">Efth95]</ref> for automatic and interactive query expansion. The expansion terms produced in our case, however, were not always useful. This was for two reasons: low numbers of relevant documents, and the processing of summaries for relevance weighting.</p><p>The searchers tended to find relatively low numbers of relevant documents. If a searcher only found one relevant document in the first display of documents (as many did) then the relevance weighting prioritised those terms that only appeared in the relevant document. In this case, not only were these terms not useful for retrieving further relevant documents but occasionally the terms turned out to be spelling errors in the original documents, e.g. 'armioffici', 'withth', and 'sovietunion'.</p><p>A flaw in our preparation of the summaries for relevance weighting was not to remove stop words from the summaries before weighting. Consequently, a proportion of the suggested expansion terms consisted of labels such as, 'docno' and 'bylin'. This was shown to affect a small number of queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.Experimental details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Subjects</head><p>All subjects were educated to graduate level in a non-computing, non-LIS discipline, and, with two exceptions, all our subjects were postgraduate students recruited from the Information Technology course at Glasgow University. None of the subjects had any formal training in information searching or retrieval, beyond basic training on the university library search facilities.</p><p>The average age of the subjects was 23 years, and the average previous search experience was 3 years. All subjects reported some experience with library systems but the majority of reported experience was gained using web search engines using a point-and-click interface. None of the subjects had used either the control system (ZPRISE), the experimental system or an IR system with summarisation facilities.</p><p>These subjects were relatively regular searchers, performing searches either daily or weekly, but were neutral as to how much they enjoyed the process of searching for information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Technical drawbacks</head><p>There were two main technical problems observed in our experiments, both related to the length of time taken to produce summaries.</p><p>Summaries are produced on request, section 3.1, consequently speed is an important issue for this system. The average time taken to produce a summary was 5 seconds, the range being 0.5-20 seconds. However in practice summaries took longer than average to generate, somewhere of the order of 10 seconds on average. The main reason for this is that the summarisation time is dependent on the length of the original document.</p><p>In our experiments, the retrieved documents tended to be longer than average, consequently the summaries took longer than average to produce. This was criticised by several users, as discussed in section 5.2.</p><p>Secondly, summaries were requested by running the mouse pointer over a document title. This method was intended to be an intuitive method of obtaining summaries. However, as users were unfamiliar with the interface, they often scanned the pointer over several document titles unintentionally. This would not be a problem if summaries were created instantaneously but, as summaries took longer than expected to create, this often had the unfortunate sideeffect of halting the interface until the summaries for the scanned documents had been produced. The user had then to wait until all summaries were created before being able to issue any more commands.</p><p>A further, although minor, problem was that as soon as the user moved the pointer away from a document title, the summary disappeared. This was criticised by several users who would have preferred the summary to remain visible until a new summary was requested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Analysis</head><p>The experiments were run according to the matrix supplied by the track organisers, however technical problems meant that we were unable to run the complete set of subjects. Our final submission consisted of the full results for 10 out of 16 subjects<ref type="foot" coords="6,154.08,116.84,3.00,5.40" target="#foot_0">2</ref> . Hence the following analysis is partial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quantitative analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Interface</head><p>To examine the novel features of our interface we extended the TREC post-system questionnaire to include specific questions on the use of summaries and RF.</p><p>The subjects were, on average, in favour of the summaries with an average score of 3.7<ref type="foot" coords="6,426.96,204.68,3.00,5.40" target="#foot_1">3</ref> for the question "Were the document summaries useful in answering the questions?" and 3.5 for the question "Were the document summaries a good representation of the full document text?". However, it is doubtful whether this second result was valid, as few users actually compared the full-text with the summary. 9 of 10 subjects judged the length of the summary as "About right", the remaining subject said the summaries were too short.</p><p>The subjects were less convinced about the benefits of RF with an average response of 2.7 for the question "Was relevance feedback useful?", 2.1 for the question "Did the system add good terms to your query?" and 2.5 for "How well did you understand the relevance feedback option?".</p><p>RF was also shown to be unpopular in the exit questionnaires, we shall discuss this in more detail in section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Topics</head><p>The subjects were generally unfamiliar with the topics before searching, the reported certainty before searching being on average between 1.24 -1.9. The certainty of the users increased after searching for all topics. The final certainty ranged from 2.97 for topic 6, to 4.4 for topic 1. Although the pre-search certainty for both types of topics were roughly the same (1.60 for multiple part topics, 1.59 for comparison topics), searchers reported a greater degree of post-search certainty for multiple part topics (3.51 multiple part against 3.15 for comparison topics).</p><p>Although users found slightly more relevant documents for the multiple part topics (1.04 per search vs. 1.01 for comparison topics), the greater reported certainty seems to come from the interaction rather than search success. For the multiple part topics, subjects reported that these topics were easier to start a search on, and easier to search for<ref type="foot" coords="6,534.48,472.52,3.00,5.40" target="#foot_2">4</ref> . However they reported that they were less satisfied with searches on the multiple part topics (3.00 vs. 3.27 comparison) and would have liked more time to search on these topics (3.41 multiple part vs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.45">comparison).</head><p>There was a greater pre-search familiarity with the multiple part topics (1.96 vs. 1.78) not reflected in pre-search certainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Systems</head><p>Users marked slightly more relevant documents on average with the control system (1.04 vs. 1.01 per query), found it easier to start a search with the control system (3.58 vs. 3.36) and easier to search (3.05 vs. 3) but were overall less satisfied with the control system (2.62 vs. 2.51). The subjects felt they would have preferred more time with experimental system (2.62 vs. 2.81), possibly due to the time delay in producing the summaries.</p><p>From the exit questionnaires, the subjects claimed a relatively high level of understanding of the task (4.4), a fair similarity with other searching tasks (3.5). The subjects did not feel there was a great difference between systems (3.4).</p><p>Of the ten subjects tested 6 claimed the experimental system was easier to learn to use (1 for ZPRISE, 3 undecided), 7 found the experimental system easier to use (3 ZPRISE, none undecided), and 7 preferred the simplicity of the experimental system (3 opting for ZPRISE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Search statistics</head><p>In this section we analyse the search statistics regarding the number of documents retrieved, query terms entered and documents assessed relevant for both systems. The searchers tended to use more query terms on the experimental interface than the control system and more terms were added through query expansion. Very few terms were added through the interactive query expansion facility.</p><p>As noted before the searchers assessed slightly more relevant documents with the control system than the experimental system.</p><p>The searchers appeared to do more iterations of feedback with the experimental system although this is slightly deceptive as in fact they tended to do a new search more often than modify their existing query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.5">Search results</head><p>In Table <ref type="table" coords="7,109.44,419.98,4.92,8.86" target="#tab_1">2</ref> we outline the overall search results for our experiment. The users returned a higher proportion of nonsupporting documents on the control system (41.67% -sum of columns 4, 7 and 8 in Table <ref type="table" coords="7,478.71,431.50,4.18,8.86" target="#tab_1">2</ref>) than on the experimental system (36.84%), and a lower proportion of supporting documents with the control system (58.33% control vs 63.16% experimental -sum of columns 2 and 5 in Table <ref type="table" coords="7,339.29,454.55,3.55,8.86" target="#tab_1">2</ref>).  In Table <ref type="table" coords="8,108.57,74.38,4.92,8.86" target="#tab_2">3</ref> we compare our results from both systems with the average from the TREC participants. For the multiple part topics (1-4), our subjects returned a smaller percentage of fully supporting documents than average but a higher percentage of documents that supported a partial answer. The subjects also returned slightly more than average nonsupporting documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2:2</head><p>For the comparison topics (topics 5 -8) the subjects returned noticeably higher percentage of supporting documents and fewer non-supporting documents, suggesting that these topics were easier for our subjects, although in both our control and experimental systems our searchers returned more documents for the multiple part topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic Control unique</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Control total</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental unique</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental total</head><p>Total unique for query In Table <ref type="table" coords="8,109.79,392.14,3.73,8.86" target="#tab_3">4</ref>, we present an analysis of the overlap of the supporting documents found with the two systems. These results attempt to capture the performance of subjects using either system to discover new documents that support the answer to each query. Any document returned by a subject for a specific query that was marked by TREC assessors as 'supporting the right answer for this query' was used in the calculations, irrespective of the score assigned to that response. That means that even if a subject provided a wrong answer for a query based on a document marked as 'supporting' by the assessors, that subject would still be credited with finding a document that supports the correct answer for that query, and would be included in the calculations.</p><p>The Control unique and Experimental unique columns indicate the number of unique supporting documents found by subjects for each of the two systems (Control or Experimental) for a specific query. The Control total and Experimental total columns indicate the total number of documents marked by subjects for a specific query for each of the two systems. The Total unique for query column displays the total number of unique supporting documents for each query returned by both systems. Finally, the Total TREC column indicates the number of documents for each query that were marked as 'supporting the right answer' from the TREC assessors.</p><p>The results indicate that, on average, subjects using the experimental system performed better at discovering documents that could potentially support the right answer for a query. Subjects under both systems discovered the same number of unique supporting documents (17), however subjects using the experimental system discovered these documents in fewer attempts (29 vs. 34).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.6">Search narrative</head><p>A question searchers have to answer is: Which Children's TV program was on the air longer: the original Mickey Mouse club or the original Howdy Doody Show?</p><p>The searcher starts with the query containing terms, children's, TV, programs, Mickey, Mouse, Club, Howdy, Doody, Show. That is basically used all the terms in the question description itself, suggesting the subject relied heavily on the task given. The system returned twenty documents titles and the searcher went through the list of titles in order.</p><p>The searcher viewed summaries of eighteen documents, these were not selected in the same order as the retrieved list. In addition, the searcher viewed the full text of three documents out of the twenty displayed.</p><p>There was no relevance feedback iteration and no query modification. The users returned the answer to the query as the Mickey Mouse show ran longer, based on the document, LA050690-0059. The confidence of the user in the answer is Neutral.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative</head><p>Relevance feedback was not popular amongst our searchers. As noted in the previous section searchers on the experimental system tended to enter new search terms rather than work with the modified query. We believe that the high familiarity with web search engines in our subjects may have promoted this behaviour. The subjects also claimed a poor understanding of relevance feedback. Each subject used the interactive option at least once. The RF option was also relatively unpopular on the control system.</p><p>Topic 1, "What are the names of three US national parks where one can find redwoods?" caused our subjects some difficulties as eight of the ten subjects returned document SJMN91-06312178 (shown in Figure <ref type="figure" coords="9,460.55,252.23,3.58,8.86">2</ref>), which discusses State rather than National Parks. The text of this document does make the distinction between the two categories of park, but we doubt whether the subjects read this document closely enough to pick up on this.</p><p>In answering the comparison topics, such as "Which painting did Edvard Munch complete first: "Vampire" or "Puberty"?", several subjects did not find any individual document that supplied an answer but managed to find an answer by analysing information found in more than one document. For example, on the Munch topic, several users found a date for the completion of "Vampire" in one document, a date for "Puberty" in a different document and answered the question citing both documents as evidence.</p><p>Although our analysis is not conclusive, we believe that summaries may have resulted in some false positive answers. In this case, the searcher assesses the summary relevant without reading the full text of the (nonsupporting) document.</p><p>A good example of this is the assessment of document AP890215-0071 for the topic "Name four films in which Orson Welles appeared". One summary produced for this document contained the sentence "Turner Entertainment Co. said it will not colorize Orson Welles' black-and-white film classic "Citizen Kane'' because the late director's estate may have the right to prohibit it." which correctly identified the film Citizen Kane as being one of the films of Orson Welles.</p><p>However the summary also contained the last sentence of the document, "Movie purists have previously lamented the colorizing of such classics as "It's a Wonderful Life'', "Casablanca'' and "A Christmas Carol.''" which led the searcher to credit Mr Welles as appearing in these films, even though this was not supported by the text of the full document. Although this may have affected some of our searchers, it may not be a real concern in an operational environment in which users are not so restricted by time limitations.</p><p>All subjects liked the use of summaries but felt the summaries took too long to produce. The subjects also liked the simplicity of the interface event if they ignored the RF and query expansion options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Our research aim was to investigate the use of summarisation techniques for a question-answering task. Although our subjects returned a low number of documents, the analysis showed that subjects returned a higher proportion of supporting documents and a lower proportion of non-supporting documents with our summarisation system. The subjects also viewed fewer full documents per relevant document found with the experimental system than the control system. Although our experiments were only partially completed, these two findings indicate that our experimental hypothesis that summaries can help users target relevant documents and eliminate non-relevant documents more effectively is worth investigating further. In addition, the positive response from our subjects towards the use of summaries indicate the summaries are not only effective but can also be a popular aid to searching.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,246.48,425.52,118.99,8.86"><head>Figure 1 :Figure 1 :</head><label>11</label><figDesc>Figure 1: System architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.00,432.50,468.08,8.86;3,72.00,444.02,468.00,8.86;3,72.00,455.54,39.08,8.86;3,112.56,478.58,31.87,8.86;3,112.56,490.10,177.46,8.86;3,112.56,501.62,143.59,8.86;3,112.56,513.38,263.85,8.86;3,112.56,524.91,391.81,8.86;3,112.56,536.43,391.50,8.86;3,112.56,547.95,391.38,8.86;3,112.56,559.47,391.63,8.86;3,112.56,571.00,391.67,8.86;3,112.56,582.52,383.90,8.86;3,112.56,594.04,180.17,8.86;3,112.56,605.56,363.01,8.86;3,112.56,617.32,391.69,8.86;3,112.56,628.85,391.67,8.86;3,112.56,640.37,391.33,8.86;3,112.56,651.89,391.20,8.86;3,112.56,663.41,391.30,8.86;3,112.56,674.94,391.39,8.86;3,112.56,686.46,392.11,8.86;3,112.56,697.98,391.50,8.86"><head></head><label></label><figDesc>Figure3shows the summary produced from the document in Figure2, retrieved in response to the query 'America national parks redwood trees'. In Figure2bold type marks those sentences that were extracted to form the summary. &lt;DOC&gt; &lt;DOCNO&gt; SJMN91-06312178 &lt;/DOCNO&gt; &lt;ACCESS&gt; 06312178 &lt;/ACCESS&gt; &lt;DESCRIPT&gt; CALIFORNIA; TREE; PARK; US &lt;/DESCRIPT&gt; &lt;LEADPARA&gt; California's majestic redwood parks may be ceded to the federal government under a cost-cutting proposal under study by state Parks and Recreation Department officials, the officials said Wednesday.; The three parks --Jedediah Smith Redwoods State Park and Del Norte Coast Redwoods State Park in Del Norte County, and Prairie Creek Redwoods State Park in Humboldt County --are the crown jewels of the state park system and home to 2,000-year-old redwoods, among the oldest living things on Earth. &lt;/LEADPARA&gt; &lt;SECTION&gt; California News &lt;/SECTION&gt; &lt;HEADLINE&gt; STATE MAY CEDE ITS 3 REDWOOD PARKS TO U.S. &lt;/HEADLINE&gt; &lt;TEXT&gt; The proposal emerged from a review ordered by state Parks and Recreation Director Henry R. Agonia after the Wilson administration sent a directive to, state agencies asking them to identify budget cuts. The state is facing a staggering $2 billion deficit in this year's $55.7 billion budget.; The prospect of transferring California's redwood parks to the National Park Service drew praise and criticism from environmentalists and park rangers Wednesday as word spread.; "I'm strongly against it," state parks Superintendent Bill Beap said in a telephone interview from Eureka. "These are the prime jewels of the state park system."; But the proposal was welcomed by Sierra Club officials, who called it "a splendid idea." Edgar Wayburn, the club's vice</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,250.08,120.71,111.89,8.86;4,108.00,143.74,61.94,8.86;4,108.00,155.27,272.11,8.86;4,110.46,166.79,41.16,8.86;4,108.00,178.31,169.81,8.86;4,108.00,189.83,396.60,8.86;4,108.00,201.36,396.14,8.86;4,108.00,213.12,73.95,8.86;4,108.00,224.64,396.22,8.86;4,108.00,236.16,276.87,8.86;4,108.00,247.68,64.68,8.86;4,175.20,270.72,261.39,8.86"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Sample document &lt;SUMMARY&gt; &lt;TITLE&gt; STATE MAY CEDE ITS 3 REDWOOD PARKS TO U.S. &lt;/TITLE&gt; &lt;DOCID&gt; SJMN91-06312178 &lt;/DOCID&gt; &lt;LI&gt;California's majestic redwood parks may be ceded to the federal government under a costcutting proposal under study by state Parks and Recreation Department officials, the officials said Wednesday. &lt;/LI&gt; &lt;LI&gt; " Edgar Wayburn, the club's vice president for conservation, noted that the neighboring National Redwood Park's boundaries touch all three state parks. &lt;/LI&gt; &lt;/SUMMARY&gt; Figure 3: Summary produced from document SJMN91-06312178</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,156.72,145.90,292.36,153.57"><head>Table 1 :</head><label>1</label><figDesc>Table 1 summarises the basic search statistics. Average search statistics per query</figDesc><table coords="7,343.68,169.90,105.40,20.38"><row><cell>Control</cell><cell>Experimental</cell></row><row><cell>System</cell><cell>System</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,94.08,478.31,419.14,183.09"><head>Table 2 :</head><label>2</label><figDesc>Summarised results -control system versus experimental system</figDesc><table coords="7,94.08,478.31,419.14,183.09"><row><cell></cell><cell></cell><cell></cell><cell>2:1</cell><cell>2:0</cell><cell>1:2</cell><cell></cell><cell>1:1</cell><cell>1:0</cell><cell>0:0</cell></row><row><cell cols="2">Control responses</cell><cell>8</cell><cell>-</cell><cell>-</cell><cell>6</cell><cell></cell><cell>-</cell><cell>1</cell><cell>9</cell></row><row><cell cols="2">Control average</cell><cell>33.33%</cell><cell>-</cell><cell>-</cell><cell cols="2">25.00%</cell><cell>-</cell><cell>4.17%</cell><cell>37.50%</cell></row><row><cell cols="2">Experimental responses</cell><cell>6</cell><cell>-</cell><cell>1</cell><cell>6</cell><cell></cell><cell>-</cell><cell>2</cell><cell>4</cell></row><row><cell cols="2">Experimental average</cell><cell>31.58%</cell><cell>-</cell><cell>5.26%</cell><cell cols="2">31.58%</cell><cell>-</cell><cell>10.53%</cell><cell>21.05%</cell></row><row><cell></cell><cell></cell><cell>2:2</cell><cell>2:1</cell><cell>2:0</cell><cell cols="2">1:2</cell><cell cols="2">1:1</cell><cell>1:0</cell><cell>0:0</cell></row><row><cell>Topics 1 -4</cell><cell>TREC average</cell><cell cols="2">13.91% 2.16%</cell><cell>0.96%</cell><cell cols="4">28.06% 9.35%</cell><cell>9.83%</cell><cell>35.73%</cell></row><row><cell></cell><cell>Our average</cell><cell>4.00%</cell><cell>-</cell><cell>-</cell><cell cols="2">48.00%</cell><cell>-</cell><cell>12.00% 36.00%</cell></row><row><cell cols="2">Topics 5 -8 TREC average</cell><cell>46.60%</cell><cell>-</cell><cell cols="2">14.56%</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>38.84%</cell></row><row><cell></cell><cell>Our average</cell><cell>72.22%</cell><cell>-</cell><cell>5.56%</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>22.22%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,167.76,677.74,276.40,8.86"><head>Table 3 :</head><label>3</label><figDesc>Summarised results -Glasgow results versus average results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,85.20,179.04,437.38,198.92"><head>Table 4 :</head><label>4</label><figDesc>Document analysis results</figDesc><table coords="8,442.80,179.04,79.12,20.38"><row><cell>Total</cell><cell>Averages</cell></row><row><cell>TREC</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="6,77.34,676.30,340.53,8.86"><p>Five subjects started searching on the control system, five on the experimental system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="6,77.93,687.82,461.80,8.86;6,72.00,699.34,137.20,8.86"><p>These averages, and others in the remainder of the paper, are out of a possible 5, taken from the answers given in the standard TREC questionnaires.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="6,77.34,710.86,432.08,8.86"><p>Ease to start (multiple part 4.46 vs. 3.97 comparison), ease to search (3.77 multiple part vs. 3.54 comparison).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p><rs type="person">Ian Ruthven</rs> is currently supported by the <rs type="funder">Library and Information Commission</rs> funded project '<rs type="projectName">Retrieval through explanation', Anastasios Tombros</rs> is supported by a <rs type="grantName">University of Glasgow Postgraduate Scholarship</rs>. We would also like to acknowledge the <rs type="funder">Computing Science Research Committee</rs> for funding this research and all the experimental subjects who took part in these experiments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ZszCQHT">
					<orgName type="grant-name">University of Glasgow Postgraduate Scholarship</orgName>
					<orgName type="project" subtype="full">Retrieval through explanation&apos;, Anastasios Tombros</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,115.69,185.26,424.64,8.86;10,72.00,196.78,313.24,8.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,273.49,185.26,266.83,8.86;10,72.00,196.78,201.73,8.86">Automatic condensation of electronic publications by sentence selection. Information Processing and Management</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Brandow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mitze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Rau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,101.79,219.82,425.30,8.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,165.84,219.82,135.55,8.86">Problems in automatic abstracting</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Edmundson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,307.92,219.82,113.50,8.86">Communications of the ACM</title>
		<imprint>
			<biblScope unit="page" from="259" to="263" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,109.42,243.10,430.99,8.86;10,72.01,254.62,338.89,8.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,186.97,243.10,353.44,8.86;10,72.01,254.62,229.86,8.86">User-choices: a new yardstick for the evaluation of ranking algorithms for interactive query expansion. Information Processing and Management</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="605" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.74,277.66,390.29,8.86;10,72.01,289.18,468.02,8.86;10,72.01,300.70,53.84,8.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>House</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Obrst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Firmin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chrzanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sundheim</surname></persName>
		</author>
		<title level="m" coord="10,119.29,289.18,284.75,8.86">The TIPSTER SUMMAC text summarization evaluation: final report</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>MITRE Corporation Technical</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct coords="10,104.11,323.74,435.80,8.86;10,72.01,335.50,263.44,8.86" xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Galpin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,209.78,335.50,36.35,8.86">Program</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1988">1988</date>
		</imprint>
		<respStmt>
			<orgName>Muscat at the Scott Polar Research Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.71,358.53,429.21,8.86;10,72.01,370.06,467.90,8.86;10,72.01,381.58,200.91,8.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,276.01,358.53,263.91,8.86;10,72.01,370.06,327.89,8.86">Automatic abstracting and indexing. II. Production of indicative abstracts by application of contextual inference and syntactic coherence criteria</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zamora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,407.25,370.06,132.66,8.86;10,72.01,381.58,92.33,8.86">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="260" to="274" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,113.62,404.61,426.52,8.86;10,72.01,416.14,467.98,8.86;10,72.01,427.66,84.72,8.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,174.01,404.61,303.78,8.86">Reflecting User Information Needs Through Query Biased Summaries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tombros</surname></persName>
		</author>
		<idno>TR-1997-35</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>of the Department of Computing Science at the University of Glasgow, Glasgow G12 8QQ, UK. 1997</note>
</biblStruct>

<biblStruct coords="10,105.16,450.94,434.67,8.86;10,72.01,462.46,468.70,8.86;10,72.01,473.99,105.82,8.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,246.73,450.94,289.11,8.86">The advantages of query-biased summaries in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tombros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,72.01,462.46,468.70,8.86;10,72.01,473.99,34.68,8.86">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="2" to="10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
