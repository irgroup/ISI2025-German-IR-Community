<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,241.50,165.81,127.72,12.49;1,114.75,184.56,381.27,12.49">Question Answering Considering Semantic Categories and Co-occurrence Density</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,184.50,239.54,48.08,8.32"><forename type="first">Soo-Min</forename><surname>Kim</surname></persName>
							<email>smkim@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.02,239.54,48.96,8.32"><forename type="first">Dae-Ho</forename><surname>Baek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.34,239.54,62.35,8.32"><forename type="first">Sang-Beom</forename><surname>Kim</surname></persName>
							<email>sbkim@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.27,239.54,62.79,8.32"><forename type="first">Hae-Chang</forename><surname>Rim</surname></persName>
							<email>rim@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,241.50,165.81,127.72,12.49;1,114.75,184.56,381.27,12.49">Question Answering Considering Semantic Categories and Co-occurrence Density</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">983C99829730A36F9C979D77F3DA90ED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a Question Answering system called KUQA (Korea University Question Answering system) developed by using semantic categories and co-occurrence density.</p><p>Semantic categories are used for computing the semantic similarity between a question and an answer, and co-occurrence density is used for measuring the proximity of the answer to the words of the question. KUQA is developed based on the hypothesis that the words that are semantically similar to the question and locally close to the words a ppeared in the question are likely to be the answer to the question.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Question Answering (QA) is defined to find the exact answer to the user's question in a large text collection. In other words, the answer is not the whole document that is relevant to the question, but the parts of the document that can meet the users' need more precisely. On the other hand, current IR systems allow us to locate documents but most of them leave it to the user to extract the information from top ranked documents . Recently, documents have rapidly increased in number, and we need a system that can retrieve information , not document. As a result, there has been a growing interest to QA in NLP community.</p><p>In this paper, we introduce the KUQA system developed by NLP Lab. in Korea University for the QA track of TREC-9. We try to incorporate NLP techniques with conventional IR techniques. To do this, we utilize WordNet as a kind of linguistic knowledge and a POS tagger for linguistic analyzer.</p><p>In the next section, we describe three components of KUQA system. In section 3, we analyze the performance of the system. And finally, we discuss future work in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Description</head><p>Our system consists of three modules: the question analysis module for capturing the meaning of a natural language question, the document retrieval and analysis module for selecting </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question Analysis</head><p>The question analyzer reads a question, determines the semantic categories of it by consulting automata and WordNet, and produces a category vector which represents the semantic categories assigned to the question. These classified question categories a re used for computing semantic similarity between the question and candidate answers. Also, a list of question words is extracted from the given question, and it is used for retrieving relevant documents and measuring co-occurrence density.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Classifying Question Categories</head><p>The question categories indicate the possible type of semantic categories with which the expected answer corresponds. They are decided by different methods according to the types of questions. Questions can be grouped into follo wing three types depending on their interrogatives and sentence structures:</p><p>(1) Who, Where, When   <ref type="table" coords="3,132.01,341.54,5.00,8.33" target="#tab_0">1</ref> shows the categories assigned to each type of questions. The category of the question with an interrogative Who, Where, or When is decided by its meaning of the interrogative. The category of the question with the interrogative How is determined by the meaning of an adjective or an adverb followed by the interrogative. For example, How long questions may have categories related to time or length and How many questions may have categories related to number. However, the categories of What, Which and other questions can't be determined just by the meaning of the interrogative or an adjacent adjective or adverb. To analyze these questions, we try to manually construct automata. By using the automata, the system recognizes the key phrase of the question, and then assigns the semantic categories of the question based on the semantic categories of the key phrase. The semantic categories of the key phrase are classified into one of 46 preclassified categories by using WordNet. Figure <ref type="figure" coords="3,136.38,489.29,5.00,8.33">2</ref> shows an example of the process of assigning question categories to the question: What is the fare cost for the round trip between New York and London on Concord? In this example, the key phrase "fare cost" is recognized by the automata, and the semantic category of the question is classified into "FINANCIAL LOSS" by using WordNet. Table <ref type="table" coords="4,132.00,374.54,5.00,8.33">2</ref> shows an example of category vector for the question: Where is the Orinoco? Since the semantic categories of that question are related to the location category, like COUNTRY, CITY, PENINSULA, CONTINENT, and PROVINCE, all the categories related to location are set to 1 in the vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category vector</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Extracting Question Words</head><p>In the question analysis module, a list of question words is also extracted from the given question, and it is used for retrieving relevant documents and measuring co-occurrence density. A question word is extracted from a question if their part-of-speech is noun, verb, adjective, adverb, or cardinal number, and it is restored to its root form. For example, the list of questions words &lt;fare, cost, round, trip, New, York, London, Concord&gt; is extracted from the question "What is the fare cost for the round trip between New York and London on Concord?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Relevant Document Retrieval and Candidate Answer Selection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Retrieving Relevant Documents</head><p>The document retrieval module retrieves documents relevant to the question. The document retrieval system is basically implemented based on the OKAPI ranking. However, we assign different weights to the question words according to their part-of-speeches. When the part-of-speech of a question word is proper noun, then the weight of the question word is doubled so that the documents with the same proper noun are highly ranked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Selecting Candidate Answers</head><p>We try to select several candidate answers from top 10 ranked documents according to their part-of-speeches.</p><p>As shown in table 3, we manually classify semantic categories of a question and their corresponding part-of-speeches. With one or more semantic categories of a question, we can expect the part-of-speeches of candidate answers by using table 3, and then select several candidate answers from top ranked documents based on their part -of-speeches.</p><p>In fact, the POS tagger does not tag properly to the word whose part-of-speech is cardinal number. So, we also select the word including a number in its string as candidate answers when the semantic categories of a question expects cardinal number for its candidate answers. For example, the word $600,000 can be a candidate answer when the semantic category of a question is FINANCIAL LOSS, because it contains a number in its string. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Determining Semantic Categories of Candidate answers</head><p>We also use WordNet to determine the semantic categories of a candidate answer. Semantic categories of a candidate answer are also represented by a category vector in the same way as the question category vector. The vector consists of 46 categories manually chosen from a pool of words in WordNet.</p><p>The system obtains a set of hypernyms and synonyms of a candidate answer by using WordNet.</p><p>If the set of hypernyms and synonyms of a word contains the words used as categories in the category vector, the system sets the values of those categories in the vector to 1. Some categories used in the system can be grouped into the classes called similar category  There are many named entities which are unknown in WordNet. In order to determine the semantic categories of the unknown named entities, we try to use the semantic categories of the adjacent word of the unknown named entity as a clue. As a simple example, consider the phrase: President Kim said. The category of the named entity Kim can't be determined by using WordNet. But, the category of the preceding word President can be determined as PERSON, and the category of unknown named entity Kim can be also determined as PERSON.</p><p>In the case that several words are connected by hyphens, or a number and a unit together comprise one word, we have to tokenize them as separate words. We divide 92km, for example, as 92 and km, and then determine a category of 92km. Table <ref type="table" coords="6,363.21,431.54,5.00,8.33">5</ref> shows some examples of words and their corresponding categories. Table <ref type="table" coords="6,224.06,576.29,3.66,8.33">5</ref>: Some examples of words and their categories</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>President</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ranking Candidate Answers</head><p>We use three factors to rank candidate answers: average distance weight, co-occurrence rati o, and semantic category similarity. Candidate answers are ranked according to the product of these three factors. By doing that, both semantic category similarity and co-occurrence density are reflected in computing the similarity between a question and an answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Average distance weight</head><p>By considering the phenomena that an answer to some questions tends to appear in a document locally close to the same words occurred in the question, we use the average distance weight to measure the proximity. Distance weight means the degree of proximity between the keywords of the candidate answer and words in the set of question words. It varies between 0 and 1. Average distance weight is determined by computing the average of distance weight between one candidate word and all question words in the fixed number of words around a candidate answer in a document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Co-occurrence ratio</head><p>Although </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Semantic category similarity</head><p>Average distance weight and the co-occurrence ratio are not able to reflect the semantic similarities between a question and a candidate answer. Thus, we define the category similarity between a question category vector and a candidate answer category vector. It can have one of three values: high, middle, or low. When two categories are same or similar, the category vector similarity is high. When there is no relevance to each other, the category vector similarity is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head><p>Our system uses the question set used in TREC8 as a training data. It uses TreeTagger (Helmut Schmid) as a POS tagger and WordNet as a thesaurus. The document retrieval system implemented by using OKAPI algorithm is used for retrieving relevant documents. Our TREC-9 results of 250-byte run are shown in table 6. There are 682 questions in TREC-9 test questions.</p><p>Unlike the last year, the judgment field can be one of three values: -1 ( Wrong), 1 (Correct), and 2 (Unsupported). The Unsupported judgment is given to responses that would have been judged correct but, in the judge's opinion, we could not tell it was a correct answer from the document returned with it.</p><p>There are two different evaluations: a strict evaluation which counting only the Correct as right and a lenient evaluation that counting both Correct and Unsupported as right. The first row of the </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,232.50,348.29,145.76,8.32"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of KUQA system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,173.25,307.79,264.09,8.32"><head>(</head><label></label><figDesc>Figure2: an example of the process of assigning a question category</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,105.75,114.40,315.36,235.46"><head>Table 1 :</head><label>1</label><figDesc>Category assignment tableTable</figDesc><table coords="3,186.75,114.40,234.36,173.49"><row><cell cols="2">question</cell><cell>Question categories</cell></row><row><cell>Who</cell><cell></cell><cell>PERSON</cell></row><row><cell></cell><cell></cell><cell>COUNTRY CITY CAPITAL PENINSULA</cell></row><row><cell>Where</cell><cell></cell><cell>ISLAND CONTINENT PROVINCE MOUNTAIN</cell></row><row><cell></cell><cell></cell><cell>MOUNTAIN_PEAK RIVER OCEAN</cell></row><row><cell>When</cell><cell></cell><cell>DAY YEAR TIME_PERIOD TIME_UNIT TIME</cell></row><row><cell></cell><cell>far , tall</cell><cell>LENGTH LINEAR_UNIT</cell></row><row><cell></cell><cell>long</cell><cell>LENGTH LINEAR_UNIT YEAR TIME TIME_PERIOD TIME_UNIT TIME</cell></row><row><cell>How</cell><cell>rich</cell><cell>MONETARY_VALUE MONETARY_UNIT ECONOMIC_CONDITION FINANTIAL_LOSS</cell></row><row><cell></cell><cell>much , many</cell><cell>NUMBER</cell></row><row><cell></cell><cell>Applied to</cell><cell></cell></row><row><cell>What</cell><cell>proper</cell><cell>The semantic categories of key phrase</cell></row><row><cell>Which</cell><cell>automata</cell><cell></cell></row><row><cell>others</cell><cell>No automata</cell><cell>No category</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,132.00,304.58,338.74,112.04"><head>Table 3 :</head><label>3</label><figDesc>POS of candidate answers corresponding to semantic categories</figDesc><table coords="5,132.00,304.58,338.74,81.88"><row><cell>COUNTRY, CITY, CAPITAL, PENINSULA, ISLAND, CONTINENT, PROVINCE, MOUNTAIN, MOUNTAIN_PEAK, OCEAN, RIVER, ………</cell><cell>Proper Noun</cell></row><row><cell>COMPOUND, MATERIAL, DISEASE, SORT, WORD, BOOK, CINEMA,</cell><cell>Proper Noun</cell></row><row><cell>MOVIE, MUSIC, ………</cell><cell>Noun</cell></row><row><cell>NUMBER, LENGTH, LINEAR_UNIT, MAGNITUDE_RELATION, TIME, TIME_PERIOD, YEAR , MONETARY_VALUE, ……..</cell><cell>Cardinal Number</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,105.75,569.54,399.22,75.83"><head></head><label></label><figDesc>classes, as shown in table 4. If the category of the candidate answer belongs to one of the class of similar category classes, other categories in the same class are also set to 1 in the vector of that word. For example, the word cost has FINANCIAL_LOSS as its hypernym and</figDesc><table coords="5,105.75,610.79,399.22,34.58"><row><cell>MONETARY_VALUE</cell><cell>MONETARY_UNIT</cell></row><row><cell>FINANTIAL_LOSS</cell><cell>ECONOMIC_CONDITION</cell></row><row><cell>TIME</cell><cell>TIME_PERIOD</cell></row><row><cell>TIME_UNIT</cell><cell></cell></row><row><cell>CINEMA</cell><cell>MOVIE</cell></row><row><cell>LENGTH</cell><cell>LINEAR_UNIT</cell></row><row><cell>WORD</cell><cell>NAME</cell></row><row><cell>CAPITAL</cell><cell>CITY</cell></row><row><cell cols="2">FINANCIAL_LOSS belongs to one of the similar category classes. Thus, all other categories in</cell></row><row><cell cols="2">the same class: MONETARY_VALUE, MONETARY_UNIT, ECONOMIC_CONDITION are also</cell></row><row><cell>set to 1.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,105.75,221.54,399.89,97.57"><head>Table 4 :</head><label>4</label><figDesc>Similar category classesIn some cases, two or more words have one category. In the case of words New York, although the category of New York is CITY by using WordNet, each word new and York doesn't belong to the CITY category. To solve this problem, we consider not only the current keyword but also the adjacent words of the current keyword in assigning keyword categories. If there are proper categories for two adjacent words in WordNet, the categories are assigned to the candidate answer.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,105.75,244.04,399.85,85.99"><head></head><label></label><figDesc>two candidate answers have the same value of average distance weight, one clustered with many words in the set of question words must have a higher score than the other clustered with just a few words. This is reflected in the following formula of i</figDesc><table coords="7,192.75,272.07,233.95,57.96"><row><cell></cell><cell></cell><cell></cell><cell cols="2">R :</cell><cell></cell></row><row><cell>=</cell><cell>Number</cell><cell>of ords Number question w Total of</cell><cell>question w appeared</cell><cell>ords in the</cell><cell>passage</cell></row></table><note coords="7,186.75,317.65,1.67,5.40;7,180.75,311.58,6.42,9.45"><p>i R</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,105.75,607.04,398.64,22.58"><head>table 6</head><label>6</label><figDesc>indicates the result of the strict evaluation and the second row indicates that of the lenient In this paper, we introduced our Question-Answering system, named KUQA. With the system, we tried to integrate NLP techniques and IR techniques in a way that makes maximal use of their complimentary ability. KUQA utilizes Wor dNet as a source of word class information and TreeTagger as a tool for linguistic analysis. Experimental results are encouraging and suggest that NLP techniques are useful for Question-Answering. There is certainly much room for improvement. A problem arises with questions or candidate answers containing words unknown to WordNet. Their semantic categories cannot be classified properly. Another problem arises from limited utilization of NLP techniques. In the future work, we will extend our system to include various NLP techniques including partial parsing, named entity tagging and anaphora resolution.</figDesc><table coords="7,105.75,621.29,41.46,8.33"><row><cell>evaluation.</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
