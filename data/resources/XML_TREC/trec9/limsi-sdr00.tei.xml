<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,166.80,60.70,271.92,15.55">The LIMSI SDR System for TREC-9</title>
				<funder>
					<orgName type="full">French Ministry of Defense</orgName>
				</funder>
				<funder ref="#_fG4DpdF">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,94.56,93.10,86.07,10.80"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
							<email>gauvain@limsi.fr</email>
						</author>
						<author>
							<persName coords="1,188.88,93.10,51.02,10.80"><forename type="first">Lori</forename><surname>Lamel</surname></persName>
							<email>lamel@limsi.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Gilles Adda, and Yannick de Kercardio Spoken Language Processing Group (http://www.limsi.fr/tlp)</orgName>
								<orgName type="institution">Claude Barras</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">LIMSI-CNRS</orgName>
								<address>
									<postBox>B.P. 133</postBox>
									<postCode>91403</postCode>
									<settlement>Orsay cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,166.80,60.70,271.92,15.55">The LIMSI SDR System for TREC-9</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">29A8784BE3071AB2D10B1ED0232A479B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the LIMSI Spoken Document Retrieval system used in the TREC-9 evaluation. This system combines an adapted version of the LIMSI 1999 Hub-4E transcription system for speech recognition with text-based IR methods. Compared with the LIMSI TREC-8 system, this year's system is able to index the audio data without knowledge of the story boundaries using a double windowing approach. The query expansion procedure of the information retrieval component has been revised and makes use of contemporaneous text sources.</p><p>Experimental results are reported in terms of mean average precision for both the TREC SDR'99 and SDR'00 queries using the same 557h data set. The mean average precision of this year's system is 0.5250 for SDR'99 and 0.3706 for SDR'00 for the focus unknown story boundary condition with a 20% word error rate.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This paper describes the LIMSI broadcast news indexating and retrieval system developed for the TREC-9 Spoken Document Retrieval track. Compared with the LIMSI TREC-8 SDR system, both the speech transcription system and the information retrieval component have been improved. Concerning the speech recognizer, we have both sped up the decoder and slightly reduced the word error rate. The query expansion procedure of the information retrieval component has been revised and the capability to index nonsegmented audio streams for the unknown story boundaries condition has been added.</p><p>During our developement work we investigated the impact of various system parameters on the IR results including: the transcriber speed, the epoch of the texts used for query expansion, the query expansion term weighting strategy, the query length, and the use of non-lexical information.</p><p>Most of the reported results here were obtained using the TREC-8 SDR'99 conditions, i.e. the TREC-8 data collection consisting of 557 hours of broadcast news from the period of February through June 1998. This data includes 21750 stories and has an associated set of 50 queries.</p><p>The remainder of this paper is as follows: In the next three sections we provide an overview of the broadcast news indexation and information retrieval components, followed by an investigation of the impact of decoding speed and the con-sequence of the word error rate on the information retrieval process. The subsequent two sections address query expansion and the use of non-lexical information. We then describe how we addressed the unknown story boundary condition and the terse query condition in this year's evaluation. Comparative results are given on the development queries from SDR'99 and this year's query set, and some conclusions are made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">TRANSCRIPTION SYSTEM OVERVIEW</head><p>The LIMSI broadcast news transcription system <ref type="bibr" coords="1,521.52,307.59,11.66,9.00" target="#b2">[5]</ref> consists of an audio partitioner <ref type="bibr" coords="1,422.88,319.59,16.53,9.00" target="#b7">[10]</ref> and a speech recognizer <ref type="bibr" coords="1,537.84,319.59,15.70,9.00" target="#b8">[11,</ref><ref type="bibr" coords="1,314.16,331.59,11.75,9.00" target="#b9">12]</ref>. The goal of audio partitioning is to divide the acoustic signal into homogeneous segments, labeling and structuring the acoustic content of the data. Partitioning consists of identifying and removing non-speech segments, and then clustering the speech segments and assigning bandwidth and gender labels to each segment. The result of the partitioning process is a set of speech segments with cluster, gender and telephone/wideband labels, which can be used to generate metadata annotations. The partitioning approach used in the LIMSI BN transcription system relies on an audio stream mixture model <ref type="bibr" coords="1,376.57,451.11,15.33,9.00" target="#b7">[10]</ref>. Each component audio source, representing a speaker in a particular background and channel condition, is modeled by a GMM. The segment boundaries and labels are jointly identified by an iterative maximum likelihood segmentation/clustering procedure using GMMs and agglomerative clustering.</p><p>For each speech segment, the word recognizer determines the sequence of words in the segment, associating start and end times and an optional confidence measure with each word. The speaker-independent large vocabulary, continuous speech recognizer makes use of n-gram statistics for language modeling and of continuous density HMMs with Gaussian mixtures for acoustic modeling. Word recognition is usually performed in three steps: 1) initial hypothesis generation, 2) word graph generation, 3) final hypothesis generation. The hypotheses are used in cluster-based acoustic model adaptation using the MLLR technique <ref type="bibr" coords="1,502.57,643.35,16.53,9.00" target="#b13">[16]</ref> prior to word graph generation, and all subsequent decoding passes. The final hypothesis is generated using a 4-gram language model. For all the experimental results given in this paper, the following training conditions were used. The acoustic models were trained on about 150 hours of American English broadcast news data. The phone models are position-dependent triphones, with about 11500 tied-states for the largest model set. The state-tying is obtained via a divisive, decision tree based clustering algorithm. Wideband and telephone band sets of gender-dependent acoustic models were built using MAP adaptation of SI seed models. Fixed language models were obtained by interpolation of ¢ -gram backoff language models trained on 3 different data sets: 203 M words of BN transcripts; 343 M words of NAB newspaper texts and AP Wordstream texts; 1.6 M words corresponding to the transcriptions of the acoustic training data. The interpolation coefficients of these LMs were chosen so as to minimize the perplexity on the Hub4 Nov98 evaluation data. The 4-gram LM contains 7M bigrams, 14M trigrams and 11M fourgrams.</p><p>The recognition word list contains 65122 words. The word pronunciations are based on a 48 phone set (3 of them are used for silence, filler words, and breath noises). A pronunciation graph is associated with each word so as to allow for alternate pronunciations, including optional phones. Frequent inflected forms have been verified to provide more systematic pronunciations. As done in the past, compound words for about 300 frequent word sequences subject to reduced pronunciations were included in the lexicon as well as the representation of the most frequent acronyms as words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">INFORMATION RETRIEVAL</head><p>The automatically generated partition and word transcription can be used for indexation and information retrieval purposes. Techniques commonly applied to automatic text indexation were applied to the automatic transcriptions of the broadcast news radio and TV documents. These classical techniques are based on document term frequencies, where the terms are obtained after standard text processing, such as text normalization, tokenization, stopping, stemming and named-entity identification.</p><p>In order to be able to apply the same IR system to different text data types (automatic transcriptions, closed captions, additional texts from newspapers or newswires), all of the documents are preprocessed in a homogeneous manner. This preprocessing, or tokenization, is the same as the text source preparation for training the speech recognizer language models <ref type="bibr" coords="2,110.41,595.59,10.62,9.00" target="#b4">[7]</ref>, and attempts to transform the texts to be closer to the observed American speaking style. The basic operations include translating numbers and sums into words, removing all the punctuation symbols, removing case distinctions and detecting acronyms and spelled names. However removing all punctuations implies that certain hyphenated words such as anti-communist, non-profit are rewritten as anti communist and non profit. While this offers advantages for speech recognition, it can lead to IR errors. To avoid IR problems due to this type of transformation, the output of the tokenizer (and recognizer) is checked for common prefixes, in order to rewrite a sequence of words such as anti communist as a single word. The prefixes that are handled include anti, co, bi, counter. A rewrite lexicon containing compound words formed with these prefixes and a limited number of named entities (such as Los-Angeles) is used to transform the texts. Similarly all numbers less than one hundred are treated as a single entity (such as twentyseven).</p><p>In order to reduce the number of lexical items for a given word sense, each word is translated into its stem (as defined in [2, 21]) or, more generally, into a form that is chosen as being representative of its semantic family. The stemming lexicon (derived from the UMass 'porterized' lexicon) [2] contains about 32000 entries and was constructed using Porter's algorithm on the most frequent words in the collection, and then manually corrected.</p><p>Two approaches for IR were explored for SDR'99 and this year, the first based on the popular TF£ IDF weigthing scheme and the second using a Markovian term weighting <ref type="bibr" coords="2,329.28,308.79,15.70,9.00" target="#b11">[14,</ref><ref type="bibr" coords="2,347.52,308.79,12.50,9.00" target="#b14">17,</ref><ref type="bibr" coords="2,362.40,308.79,11.87,9.00" target="#b16">19]</ref>.</p><p>For the TF£ IDF approach, the score of document ¤ for a query is given by the Okapi-BM25 formula <ref type="bibr" coords="2,485.19,332.55,17.23,9.00" target="#b19">[22,</ref><ref type="bibr" coords="2,504.96,332.55,11.75,9.00" target="#b20">23]</ref>. It is the sum over all the terms ¥ in the query of:</p><formula xml:id="formula_0" coords="2,328.32,363.51,218.14,29.99">cw¦ ¨ § © £ tf¦ ¨ § © £ ! #" %$ &amp; %$ £ (' © ) tf¦ ¨ § © £ 10 32 54 76 6 ¦ £ qtf ¦</formula><p>where tf¦ 8 § © is the number of occurrences of term ¥ in document ¤ (i.e. term frequency in document),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6</head><p>¦ is the number of documents containing term ¥ at least once,</p><formula xml:id="formula_1" coords="2,499.60,431.20,21.38,7.20">6</formula><p>is the total number of documents in the collection, ' © is the length of document ¤ divided by the average length of the documents in the collection, and qtf¦ the number of occurrences of term ¥ in the query.</p><p>For the second approach the score of a story is obtained by summing the query term weights mw¦ ¨ § © which are the unigram log probabilities of the terms given the story model once interpolated with a general English model:</p><formula xml:id="formula_2" coords="2,339.12,532.20,187.38,15.80">mw¦ 8 § © qtf ¦ £ 10 32 54 @9 BA &amp;C D ¥ FE ¤ G ! #" H9 &amp; IA &amp;C D ¥ P RQ</formula><p>The text of the query may or may not include the index terms associated with relevant documents. One way to cope with this problem is to use query expansion based on terms present in retrieved documents on the same (Blind Relevance Feedback, BRF) or other (Parallel Blind Relevance Feedback, PBRF) data collections <ref type="bibr" coords="2,438.00,619.35,15.22,9.00" target="#b21">[24]</ref>. For SDR'99 we combined the two approches in our system. For PBRF we used 6 months of commercially available broadcast news transcripts from the period jun-dec 1997 <ref type="bibr" coords="2,465.84,655.35,10.62,9.00">[1]</ref>. This corpus contains 50000 stories and 49.5 M words. For a given query, the terms found in the top S documents from the baseline search are ranked by their offer weight <ref type="bibr" coords="3,177.84,45.75,15.33,9.00" target="#b20">[23]</ref>, and the top T terms are added to the query. Since only the T terms with best offer weights are kept, the terms are filtered using a stop list of 144 common words, in order to increase the likelihood that the resulting terms are relevant.</p><p>Table <ref type="table" coords="3,86.16,105.99,5.00,9.00">1</ref> gives the results for both cw and mw term weightings for the SDR'99 data set. Four experimental configurations are reported: baseline search (base), query expansion using BRF (brf), query expansion with parallel BRF (pbrf) and query expansion using both BRF and PBRF (brf+pbrf). For BRF and PBRF, the terms are added to the query with a weight of 1. For BRF+PBRF, the terms from each source are added with a weight of 0.5. The results clearly demonstrate the interest of using both BRF and PBRF expansion techniques, as consistent improvements are obtained over the baseline system for the two conditions (R1 and S1). BRF is found to be more effective for both the S1 condition (the recognizer transcripts) and the R1 condition (the manual transcripts). The two IR approaches are seen to yield comparable results <ref type="bibr" coords="3,73.92,422.31,15.22,9.00" target="#b10">[13]</ref>. Only small differences in information retrieval performance as given by the mean average precision were observed for automatic and manual transcriptions when the story boundaries are known.</p><formula xml:id="formula_3" coords="3,57.84,287.43,17.78,9.00">data</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DECODING SPEED</head><p>Processing time is an important factor in making a speech transcription system viable for automatic indexation of radio and television broadcasts. When only concerned by the word error rate, it is common to design systems that run in 100 times real-time or more. Although it is usually assumed that processing time is not a major issue since computer power has been increasing continuously, it is also known that the amount of data appearing on information channels is increasing very rapidly. Therefore processing time is an important factor in making a speech transcription system viable for audio data mining and other related applications. Constraints on the computational resources led us to reconsider some of the system design issues, particularly those concerning the acoustic models and the decoding strategy. We investigated the design of a system which performs well with computa-tional resources in the range 1 to 10xRT on commonly available platforms. A new decoder was implemented with which broadcast data can be transcribed in few times real-time with only a slight increase in word error rate when compared to our best system.</p><p>A 4-gram single pass dynamic network decoder has been developed. It is a time-synchronous Viterbi decoder with dynamic expansion of LM state conditioned lexical trees <ref type="bibr" coords="3,528.24,120.39,10.83,9.00" target="#b0">[3,</ref><ref type="bibr" coords="3,541.20,120.39,12.34,9.00" target="#b15">18,</ref><ref type="bibr" coords="3,314.17,132.39,13.17,9.00" target="#b17">20]</ref> with acoustic and language model lookaheads. The decoder can handle position-dependent, cross-word triphones and lexicons with contextual pronunciations. It makes use of various pruning techniques to reduce the search space and computation time, including three HMM-state pruning beams and fast Gaussian likelihood computations. It can also generate word graphs and rescore them with different acoustic and language models. Faster than real-time decoding can be obtained using this decoder with a word error under 30%, running in less than 100 Mb of memory on widely available platforms such Pentium III or Alpha machines.</p><p>The decoder by itself does not solve by itself the problem of reducing the recognition time as proper models have to be used in order to optimize the recognizer accuracy at a given decoding speed. In general, better models have more parameters, and therefore require more computation. However, since the models are more accurate, it is often possible to use a tighter pruning level (thus reducing the computational load) without any loss in accuracy. Thus, limitations on the available computational resources affect the design of the acoustic and language models. For each operating point, the right balance between model complexity and pruning level must be found.</p><p>In order to assess the effect of the recognition time on the information retrieval results we transcribed the 557 hours of broadcast news data (the TREC SDR'99 data set -epoch Feb98 to Jun98) using two decoder configurations: a single pass 1.4xRT system and a three pass 10xRT system. The SDR'99 test data consists of 21750 stories and an associated set of 50 queries with on average 14 words. Although story boundaries are available, this information is not used by the speech recognizer. The information retrieval results are given in term of mean average precison (MAP), as is done for the TREC benchmarks. Word error rates are measured on a 10h test subset <ref type="bibr" coords="3,423.37,544.71,10.49,9.00" target="#b3">[6]</ref>. For comparison, results are also given for manually produced closed captions. In order for the same IR system to be applied to different text data types (automatic transcriptions, closed captions, additional texts from newspapers or newswires), all of the documents are preprocessed in a homogeneous manner. This preprocessing, or tokenization, is the same as the text source preparation for training the speech recognizer language models.</p><p>Table <ref type="table" coords="3,349.21,643.35,5.00,9.00" target="#tab_1">2</ref> gives the word error rates and IR results for the three sets of transcriptions with and without query expansion. Query expansion uses blind relevance feedback (BRF) on both the audio document collection and some commercially available broadcast news transcripts predating the audio corpus (Jun-Dec 1997 vs Feb-Jun 1998). With query expansion comparable IR results are obtained using the closed captions and the 10xRT transcriptions, and a small degradation (4% absolute) is observed using the 1.4xRT transcriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">QUERY EXPANSION</head><p>In our SDR'99 system query expansion was done by adding terms present in retrieved documents on the same data collection and in an independent set of texts. For PBRF we made use of 6 months of commercially available broadcast news transcripts for covering the period of June through December 1997 [1] (50000 stories and 49.5 M words). However, the SDR'00 specifications (as well as the SDR'99 specifications) allow us to use texts (except for BN transcripts) covering exactly the same epoch of the audio data. Therefore this year we implemeted PBRF using 3 sources of contemporary newspaper data: the New York Times, the Los Angeles Times and the Washington Post. The parallel corpus conatined a total of 42 M words and 78 K documents between Jan98 and Jun98. Experiments with these texts on the SDR'99 show that PBRF using contemporary texts offers a significant performance gain compared with a PBRF using texts predating the audio data. In fact we found that we no longer needed to combine both BRF and PBRF, since PRBF with the new texts gave comparable benefits.</p><p>This year we also changed the term weighting used with query expansion, using a weight proportional to the offer weight as defined in <ref type="bibr" coords="4,136.56,559.59,15.70,9.00" target="#b20">[23,</ref><ref type="bibr" coords="4,155.52,559.59,11.75,9.00" target="#b12">15]</ref>. This approach allowed us to significantly increase the number of expansion terms, going from 10 terms with the previous approach to 25 terms with the term weighting. The sum of the weights for the expansion terms is set to the number of added terms, i.e., 25. Table <ref type="table" coords="4,66.00,619.35,5.00,9.00" target="#tab_2">3</ref> shows the combined improvment obtained with the new query expansion scheme on the SDR'99 data. These results were obtained using the Okapi term weighting with a parameter setting (b=0.7, K=1.2) and a slighlty different stemmer from that used for the results reporter earlier in this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">NON-LEXICAL INFORMATION</head><p>The broadcast news transcription system also provides non-lexical information along with the word transcription. This information is available in the partition of the audio track, which identifies speaker turns. We investigated the use of automatically detected speaker changes for locating document boundaries. Statistics were made on the 1997 English Hub-4 training data set, which consists of about 100 hours of radio and television broadcast news with manual transcription and speaker identification. On this set, 2096 sections were manually marked as report sections and used as documents for the SDR'98 evaluation. Among them, 817 sections (about 40%) start without a manually annotated speaker change. This means that using only speaker change information for detecting document boundaries would result in 40% missed boundaries. This figure would likely increase with the use of automatically detected speaker changes. At the same time, 11,160 of the total of 12,439 speaker turns occur in the middle of a document, which gives almost a 90% false alarm rate. A more detailed analysis shows that about 50% of the sections involve a single speaker, but that the distribution of the number of speaker turns per section falls off very gradually from 2 to 20 speakers (cf. Figure <ref type="figure" coords="4,542.88,509.44,3.61,9.00" target="#fig_0">1</ref>). False alarms are not as harmful as missed detections, since it is possible to merge adjacent turns into a single document in subsequent processing. However these results show clearly that even perfect speaker turn boundaries cannot be used as the primary cue for locating document boundaries. They can be used to refine the placement of a document boundary located near a speaker change.</p><p>Besides speaker turns, changes in the background acoustic conditions can be detected by the audio partitioner and can be considered as indicators of story boundaries. We did not investigate this because the background conditions were not manually marked in the 1997 English Hub-4 corpus.</p><p>We investigated using simple statistics on the durations of the documents in the SDR'98 data set. A histogram of the 2096 sections is shown in Figure <ref type="figure" coords="5,183.84,421.59,3.75,9.00" target="#fig_1">2</ref>. One third of the sections are shorter than 30 seconds. The histogram has a sharp peak around 20 seconds, and a smaller, flat peak around 2 minutes, resulting in a bimodal distribution of document length. Very short documents are typical of headlines which are uttered by single speaker, whereas longer documents are more likely to contain data from multiple talkers. This distribution led us to consider using a multi-scale segmentation of the audio stream into documents. Similar statistics were measured on the SDR'99 data using the known document boundaries. The distribution, shown in lower part of Figure <ref type="figure" coords="5,224.16,541.11,5.00,9.00" target="#fig_1">2</ref> is quite similar to that of the SDR'98 data, with an additional, small peak at 60 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">UNKNOWN STORY BOUNDARY CONDITION</head><p>As proposed in <ref type="bibr" coords="5,126.96,619.35,10.62,9.00" target="#b6">[9]</ref>, we first segmented the audio stream into overlapping documents of a fixed duration. As a result of optimization using the TREC-8 SDR queries, we chose a 30 second window duration with a 15 second overlap. Since there are many stories significantly shorter than 30s in broad-cast shows (see Figure <ref type="figure" coords="5,407.28,33.75,4.17,9.00" target="#fig_1">2</ref>) we conjunctured that it may be of interest to use a double windowing system in order to better target short stories. The window size of the smaller window was selected to be 10 seconds. So for each query, we independently retrieved two sets of 2700 documents, one set for each window size. Then for each document set, document recombination is done by merging overlapping documents until no further merges are possible. The score of a combined document is set to maximum score of any one of the components. For each document derived from the 30s windows, we produce a time stamp located at the center point of the document. However, if any smaller documents are embedded in this document, we take the center of the best scoring document. This way we try to take avantage of both window sizes. The MAP using a single 30s window and the double windosing strategy are shown in Table <ref type="table" coords="5,498.97,213.03,3.75,9.00" target="#tab_3">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mode</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">TERSE QUERIES</head><p>A new component of this year's evaluation was the use of terse queries for indexation. Since terse forms of the 1999 queries were not available, we generated a set for use in system development. These were generated based on the instructions given to the assessors that developed the SDR'00 short and terse queries.a Different group members used these general instructions to independently generate terse versions of the SDR'99 queries. These were then compiled and a single form was selected. The resulting SDR'99 terse queries contain on average 3.3 words per query to be compared to 13.7 words for the regular "short" queries.</p><p>We carried out retrieval experiments with these terse queries using the system parameter values tuned for the short queries. The retrieval results are given on Table <ref type="table" coords="5,512.88,490.47,5.00,9.00" target="#tab_5">5</ref> for both the known and unknown story boundary conditions on the SDR'99 data. We can see that there is only about a 1% absolute reduction of the mean average precision when the short queries are replaced by the terse queries. Given this small degradation we did not try to modify our system to better optimize performance on the terse queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">RESULTS</head><p>Retrieval results for the SDR'00 evaluation system are given in Tables <ref type="table" coords="5,384.48,614.79,5.00,9.00" target="#tab_6">6</ref> and<ref type="table" coords="5,414.00,614.79,5.00,9.00" target="#tab_7">7</ref> for both SDR'99 and SDR'00 queries. It is clear from these results that the system behavoir is quite different on the two query sets. First the SDR'00 b Although no specific written guidelines were available, John Garofolo kindly described the instructions given to the assessors.  queries appear to be significantly more difficult, with a 25% relative reduction in the mean average precision compared to the SDR'99 queries. Second, we get significantly better results with the terse queries than with the short queries, while we observed a slight loss on our SDR'99 terse queries. The average length of the SDR'00 terse queries (3.0) is not significantly different from the average length of our SDR'00 terse queries (3.3), but there is a substantial difference in the number of new words compared to the short queries. The SDR'00 terse queries introduce 54 new words with 85 words in common the the SDR'00 short queries, whereas we had only 17 new words in our SDR'99 terse queries with 181 words in common. These numbers show that our SDR'99 terse queries were essentially shorter versions of the corresponding short query, whereas the SDR'00 terse queries appear to be a reformulation of the SDR'00 short queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mode</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">CONCLUSION</head><p>In this paper we have described the LIMSI TREC-9 spoken document retrieval system. This system is based on the 1999 LIMSI system, with a few substantial modifications. First, the decoder of the speech recognizer has been replaced by a new, faster decoder able to transcribes broadcast data in several (6 to 10) times real-time with only a slight increase in word error rate when compared to our best system and with a word error of about 30% for essentially real-time decoding. Second, the query expansion procedure of the information retrieval component has been revised and makes use of contemporaneous text sources. Thirdly, a double windowing approach has been developed to localize stories for the unknown boundary condition.</p><p>The experimental results show that only a moderate IR performance degradation is obtained in spoken document retrieval with a close to real-time system, and that generally speaking, the transcription quality of our system is not a limiting factor given todays IR techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,314.16,209.87,239.32,8.10;4,314.16,219.71,87.85,8.10"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Histogram of the number of speaker turns per section in the 1997 Hub-4 data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,51.84,378.59,239.55,8.10;5,51.84,388.19,64.47,8.10"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of document durations in the Hub4'97 and SDR'00 data sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,51.84,34.47,239.63,118.20"><head>Table 2 :</head><label>2</label><figDesc>Impact of the word error rate on the mean average precision using the SDR'99 conditions using a 1-gram document model.</figDesc><table coords="4,81.36,34.47,180.62,118.20"><row><cell>Transcriptions</cell><cell>Werr</cell><cell>Base</cell><cell>BRF</cell></row><row><cell>Closed-captions</cell><cell>-</cell><cell cols="2">0.4691 0.5430</cell></row><row><cell>10xRT</cell><cell cols="3">20.5% 0.4528 0.5385</cell></row><row><cell>1.4xRT</cell><cell cols="3">32.6% 0.4090 0.4938</cell></row><row><cell cols="4">pbrf '99 brf+pbrf '99 pbrf '00</cell></row><row><cell>0.5017</cell><cell>0.5397</cell><cell>0.5956</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,51.84,165.47,239.74,17.70"><head>Table 3 :</head><label>3</label><figDesc>Comparison of query expansion schemes on the SDR'99 data with known story boundaries.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,314.16,237.75,239.40,63.98"><head>Table 4 :</head><label>4</label><figDesc>Unkown story boundary condition development results on SDR'99 data.</figDesc><table coords="5,372.24,237.75,123.33,33.48"><row><cell></cell><cell>30s</cell><cell>30s + 10s</cell></row><row><cell cols="2">baseline 0.3673</cell><cell>0.3791</cell></row><row><cell>PBRF</cell><cell>0.5001</cell><cell>0.5260</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,51.84,92.51,239.52,37.38"><head>Table 5 :</head><label>5</label><figDesc>Retrieval results with short and terse queries on the SDR'99 data. R1: reference transcript. S1: automatic speech transcription. K: known story boundary condition. U: unknown story boundary condition.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,51.84,347.43,239.72,169.08"><head>Table 6 :</head><label>6</label><figDesc>Retrieval results on SDR'99 and SDR'00 data with known story boundaries. R1: reference transcript. S1: automatic speech transcription. K: known story boundary condition.</figDesc><table coords="6,81.60,347.43,180.14,169.08"><row><cell></cell><cell cols="2">Queries'99</cell><cell cols="2">Queries'00</cell></row><row><cell></cell><cell>short</cell><cell>terse</cell><cell>short</cell><cell>terse</cell></row><row><cell>R1K</cell><cell cols="4">0.5975 0.5852 0.4636 0.5132</cell></row><row><cell>S1K</cell><cell cols="4">0.5956 0.5795 0.4327 0.4812</cell></row><row><cell>Mode</cell><cell cols="2">Queries'99</cell><cell cols="2">Queries'00</cell></row><row><cell></cell><cell>short</cell><cell>terse</cell><cell>short</cell><cell>terse</cell></row><row><cell>R1U</cell><cell>0.5233</cell><cell>-</cell><cell cols="2">0.4027 0.4283</cell></row><row><cell>B1U</cell><cell>0.5034</cell><cell>-</cell><cell cols="2">0.3712 0.3922</cell></row><row><cell>S1U</cell><cell cols="4">0.5260 0.5147 0.3706 0.3982</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,51.84,529.31,239.74,37.38"><head>Table 7 :</head><label>7</label><figDesc>Retrieval results on SDR'99 and SDR'00 data with unknown story boundaries. R1: reference transcript. B1: baseline automatic speech transcription. S1: automatic speech transcription. U: unknown story boundary condition.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work has been partially financed by the <rs type="funder">European Commission</rs> under the IST-1999-10354 <rs type="projectName">ALERT</rs> project and the <rs type="funder">French Ministry of Defense</rs>. We also thank <rs type="person">Patrick Paroubek</rs> for providing the terse versions of the SDR'99 query set used for system development.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_fG4DpdF">
					<orgName type="project" subtype="full">ALERT</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,334.08,303.23,219.43,8.10;6,334.08,313.79,219.54,8.10;6,334.08,324.11,219.93,8.10;6,334.08,334.43,60.81,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,378.43,303.23,175.08,8.10;6,334.08,313.79,189.97,8.10">One Pass Cross Word Decoding for Large Vocabularies Based on a Lexical Tree Search Organization</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Aubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,534.24,313.79,19.39,8.10;6,334.08,324.11,76.44,8.10">Proc. ESCA Eurospeech&apos;99</title>
		<meeting>ESCA Eurospeech&apos;99<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1559" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,346.19,219.59,8.10;6,334.08,356.51,219.51,8.10;6,334.08,367.07,208.65,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,376.26,356.51,169.32,8.10">The 1998 BBN Byblos 10x Real Time System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,334.08,367.07,145.33,8.10">Proc. DARPA Broadcast News Workshop</title>
		<meeting>DARPA Broadcast News Workshop</meeting>
		<imprint>
			<date type="published" when="1999-03">Feb.-Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,378.59,219.57,8.10;6,334.08,388.91,219.42,8.10;6,334.08,399.47,116.49,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,481.44,378.59,72.22,8.10;6,334.08,388.91,138.70,8.10">Transcribing broadcast news for audio and video indexing</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,482.40,388.91,71.10,8.10;6,334.08,399.47,30.07,8.10">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2000-02">February 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,410.99,219.38,8.10;6,334.08,421.31,219.60,8.10;6,334.08,431.87,192.09,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,427.92,410.99,125.54,8.10;6,334.08,421.31,101.99,8.10">Trec-8 Spoken Document Retrieval Track Overview and Results</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Garofolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,446.16,421.31,107.52,8.10;6,334.08,431.87,55.31,8.10">Proc. 8th Text Retrieval Conference TREC-8</title>
		<meeting>8th Text Retrieval Conference TREC-8<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11">1999. November 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,443.39,219.48,8.10;6,334.08,453.71,219.66,8.10;6,334.08,464.27,114.57,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,508.74,443.39,44.82,8.10;6,334.08,453.71,72.30,8.10">The LIMSI Nov93 WSJ System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Adda-Decker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,418.08,453.71,135.66,8.10;6,334.08,464.27,60.61,8.10">Proc. ARPA Spoken Language Technology Workshop</title>
		<meeting>ARPA Spoken Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="1994-03">March, 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,475.79,219.59,8.10;6,334.32,486.11,219.37,8.10;6,334.08,496.67,219.55,8.10;6,334.08,506.99,59.85,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,540.18,475.79,13.49,8.10;6,334.32,486.11,115.02,8.10">The LIMSI SDR system for TREC-8</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>De Kercadio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">F</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,462.00,486.11,91.69,8.10;6,334.08,496.67,96.35,8.10">Proc. of the 8th Text Retrieval Conference TREC-8</title>
		<meeting>of the 8th Text Retrieval Conference TREC-8<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11">November 1999</date>
			<biblScope unit="page" from="405" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,518.51,219.59,8.10;6,334.08,529.07,219.61,8.10;6,334.08,539.39,219.53,8.10;6,334.08,549.95,20.25,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,540.18,518.51,13.49,8.10;6,334.08,529.07,115.88,8.10">The THISL SDR System at TREC-8</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Abberley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,462.24,529.07,91.45,8.10;6,334.08,539.39,99.23,8.10">Proc. of the 8th Text Retrieval Conference TREC-8</title>
		<meeting>of the 8th Text Retrieval Conference TREC-8<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11">November 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,561.47,219.66,8.10;6,334.08,571.79,219.57,8.10;6,334.08,582.35,59.13,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,457.41,561.47,96.34,8.10;6,334.08,571.79,103.30,8.10">Partitioning and Transcription of Broadcast News Data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,447.84,571.79,44.44,8.10">ICSLP&apos;98, 5</title>
		<imprint>
			<date type="published" when="1998-12">December 1998</date>
			<biblScope unit="page" from="1335" to="1338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,593.87,219.60,8.10;6,334.08,604.19,219.54,8.10;6,334.08,614.75,219.69,8.10;6,334.08,625.07,20.25,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,515.22,593.87,38.46,8.10;6,334.08,604.19,129.44,8.10">The LIMSI 1998 Hub-4E Transcription System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,475.44,604.19,78.18,8.10;6,334.08,614.75,75.73,8.10">Proc. DARPA Broadcast News Workshop</title>
		<meeting>DARPA Broadcast News Workshop<address><addrLine>Herndon, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-02">February 1999</date>
			<biblScope unit="page" from="99" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,334.08,636.59,219.40,8.10;6,334.08,647.15,219.63,8.10;6,334.08,657.47,219.69,8.10;6,334.08,668.03,20.25,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,477.42,636.59,76.06,8.10;6,334.08,647.15,171.17,8.10">Recent Advances in Transcribing Television and Radio Broadcasts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,517.20,647.15,36.51,8.10;6,334.08,657.47,42.76,8.10">Proc. Eurospeech&apos;99</title>
		<meeting>Eurospeech&apos;99<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="655" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,34.43,219.93,8.10;7,71.76,44.75,219.65,8.10;7,71.76,55.31,218.25,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,271.81,34.43,19.88,8.10;7,71.76,44.75,163.78,8.10">Transcription and Indexation of Broadcast Data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>De Kercadio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,248.16,44.75,43.25,8.10;7,71.76,55.31,55.15,8.10">Proc. IEEE ICASSP&apos;00, III</title>
		<meeting>IEEE ICASSP&apos;00, III<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="1663" to="1666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,67.55,219.71,8.10;7,71.76,78.11,219.80,8.10;7,71.76,88.43,167.37,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,169.56,67.55,121.91,8.10;7,71.76,78.11,93.30,8.10">Twenty-One at TREC-7: Ad-hoc and Cross-language track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wessel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,176.16,78.11,115.40,8.10;7,71.76,88.43,70.43,8.10">Proc. of the 8th Text Retrieval Conference TREC-7</title>
		<meeting>of the 8th Text Retrieval Conference TREC-7<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,100.91,219.65,8.10;7,71.76,111.23,219.78,8.10;7,71.76,121.79,219.69,8.10;7,71.76,132.11,129.93,8.10" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,76.19,111.23,215.35,8.10;7,71.76,121.79,23.77,8.10">Spoken Document Retrieval for TREC-8 at Cambridge University</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jourlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spärck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,104.88,121.79,182.03,8.10">Proc. of the 8th Text Retrieval Conference TREC-8</title>
		<meeting>of the 8th Text Retrieval Conference TREC-8<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11">November 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,144.59,219.69,8.10;7,71.76,154.91,219.70,8.10;7,71.76,165.23,219.62,8.10;7,71.76,175.79,68.01,8.10" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,192.63,144.59,98.82,8.10;7,71.76,154.91,219.70,8.10;7,71.76,165.23,71.46,8.10">Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Leggetter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,154.56,165.23,112.43,8.10">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="185" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,188.27,219.68,8.10;7,71.76,198.59,219.80,8.10;7,71.76,208.91,167.37,8.10" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,190.49,188.27,100.95,8.10;7,71.76,198.59,102.19,8.10">Using Hidden Markov Models for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,183.36,198.59,108.20,8.10;7,71.76,208.91,70.43,8.10">Proc. of the 8th Text Retrieval Conference TREC-7</title>
		<meeting>of the 8th Text Retrieval Conference TREC-7<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,221.39,219.55,8.10;7,71.76,231.71,219.83,8.10;7,71.76,242.27,219.63,8.10;7,71.76,252.59,117.93,8.10" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,278.57,221.39,12.74,8.10;7,71.76,231.71,219.83,8.10;7,71.76,242.27,71.72,8.10">Improvements in Beam Search for 10000-Word Continuous Speech Recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Haeb-Umbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oerder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,154.56,242.27,96.52,8.10">Proc. IEEE ICASSP-92, I</title>
		<meeting>IEEE ICASSP-92, I<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-03">March 1992</date>
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,265.07,219.62,8.10;7,71.76,275.39,219.69,8.10;7,71.76,285.95,177.69,8.10" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,103.33,265.07,188.05,8.10;7,71.76,275.39,20.68,8.10">A Maximum Likelihood Ratio Information Retrieval Model</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,103.68,275.39,183.23,8.10">Proc. of the 8th Text Retrieval Conference TREC-8</title>
		<meeting>of the 8th Text Retrieval Conference TREC-8<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11">November 1999</date>
			<biblScope unit="page" from="413" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,298.19,219.62,8.10;7,71.76,308.75,219.71,8.10;7,71.76,319.07,220.41,8.10;7,71.76,329.39,146.97,8.10" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,286.45,298.19,4.93,8.10;7,71.76,308.75,219.71,8.10;7,71.76,319.07,12.90,8.10">A One Pass Decoder Design for Large Vocabulary Recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Odell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Valtchev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,94.56,319.07,193.33,8.10">Proc. ARPA Human Language Technology Workshop</title>
		<meeting>ARPA Human Language Technology Workshop<address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-03">March 1994</date>
			<biblScope unit="page" from="405" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,341.87,219.93,8.10;7,71.76,352.19,83.13,8.10" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="7,127.43,341.87,119.63,8.10">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
	<note>Program, 14</note>
</biblStruct>

<biblStruct coords="7,71.76,364.67,219.78,8.10;7,71.76,374.99,219.70,8.10;7,71.76,385.55,219.56,8.10;7,71.76,395.87,143.13,8.10" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="7,164.41,374.99,64.03,8.10">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,154.56,385.55,136.76,8.10;7,71.76,395.87,76.56,8.10">Overview of the Third Text REtrieval Conference (TREC-3)</title>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
			<biblScope unit="volume">500</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,408.35,219.72,8.10;7,71.76,418.67,219.54,8.10;7,71.76,429.23,219.64,8.10;7,71.76,439.55,86.01,8.10" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="7,238.93,408.35,52.55,8.10;7,71.76,418.67,204.86,8.10">A probabilistic model of information retrieval: development and status</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Spärk</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>the Computer Laboratory, University of Cambridge, U.K.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="7,71.76,452.03,219.60,8.10;7,71.76,462.35,219.70,8.10;7,71.76,472.67,219.61,8.10;7,71.76,483.23,42.09,8.10" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="7,165.21,452.03,126.15,8.10;7,71.76,462.35,211.96,8.10">Improving subject retrieval in online catalogues: 2. Relevance feedback and query expansion</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>De Vere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,71.76,472.67,114.18,8.10">British Library Research Paper</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<date type="published" when="1990">1990</date>
			<pubPlace>British Library, London, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,71.76,495.71,219.69,8.10;7,71.76,506.03,219.63,8.10;7,71.76,516.35,219.75,8.10;7,71.76,526.91,175.77,8.10" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="7,179.95,506.03,111.45,8.10;7,71.76,516.35,211.74,8.10">Improvements in Accuracy and Speed in the HTK Broadcast News Transcription System</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Odell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Niesler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tuerk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W D</forename><surname>Whittaker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="1043" to="1046" />
		</imprint>
	</monogr>
	<note>Eurospeech&apos;99</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
