<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,185.32,75.96,241.08,16.65;1,105.64,101.16,400.72,16.65">Reflections on &quot;Aboutness &quot; TREC-9 Evaluation Experiments at Justsystem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,266.92,149.14,78.32,11.10"><forename type="first">Sumio</forename><surname>Fujita</surname></persName>
							<email>sumio_fujita@justsystem.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">JUSTSYSTEM Corporation Brains park</orgName>
								<address>
									<postCode>771-0189</postCode>
									<settlement>Tokushima</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,185.32,75.96,241.08,16.65;1,105.64,101.16,400.72,16.65">Reflections on &quot;Aboutness &quot; TREC-9 Evaluation Experiments at Justsystem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B925AA40AFF561E4CBEDA47D8F1711BA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Aboutness</term>
					<term>Supplemental Phrasal indexing</term>
					<term>phrasal terms</term>
					<term>pseudo-relevance feedback</term>
					<term>reference database</term>
					<term>vector space model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TREC-9 evaluation experiments at the Justsystem site are described with a focus on "aboutness" based approach in text retrieval. Experiments on the effects of supplemental noun phrase indexing, pseudo-relevance feedback and reference database feedback in view of the effect of various length of queries are reported. The results show that pesudo-relevance feedback is always effective while reference database feedback is effective only with very short queries. We reconfirmed that supplemental phrasal indexing is more effective with longer queries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Automatic indexing of modern information retrieval systems typically adopts bag-of-word representation, in which each word is considered as a dimension of the vector representing an information item, as internal representation of "aboutness". It is well known that such simple representation usually performs, as well as, if not better than, some more sophisticated ones according to empirical evaluations. Grammatical relations or functional words are normally considered as neutral in view of thematic discrimination of text documents. On the other hand, content words(or lexemes, if we need to be more attentive for linguistic terminology) are semiologically meaningful units in language systems which refer to conceptual/substantial entities or relations in the subject domain described by the documents. It is plausible that the author of documents and the user submitting search requests share the same terminology when describing the subject concept in question either in their documents or in queries. The notion of "aboutness" is considered as a set of terms evoking a subject concept, which is hopefully shared by many people including authors, indexers and users of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">"ABOUTNESS"</head><p>The concept of "aboutness" plays an essential role in modern information retrieval technologies where "author's aboutness" <ref type="bibr" coords="1,420.52,337.50,65.12,9.07">[Ingwersen 93</ref>] is extracted automatically from text documents by automatic indexing procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">"Aboutness" as Representation of Information Objects</head><p>The basic hypothesis behind our TREC-9 strategies is that the "aboutness" of a subject topic consists of "foreground" part and "background" part and terms belong to either one of them. This distinction is inspired by the metaphor of "aboutness" of visual information items. People are clearly distinguishing foreground images from background ones when talking about "aboutness" of for example picture images. A foreground image might be a person or some objects located in the center of the picture and constitute the motif of the picture. Background images can help to identify the scene where the motif image is located and sometimes clue images are hidden in background when some implicit information is given in the picture.</p><p>In text retrieval, we can consider concepts that directly related to the motif as foreground and concepts that simply constitute the scene of the motif as background.</p><p>The term weighting should accordingly take this into consideration so that the terms that belong to "foreground aboutness" should be more weighted than "background aboutness".</p><p>Foreground terms are mainly extracted from &lt;title&gt; or &lt;description&gt; fields of topic description.</p><p>A stratified automatic feedback strategy is adopted in order to extract mainly terms of "background aboutness" both from the target document database(wt10g) and a reference database(TREC CD4&amp;5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Single words as a minimum unit of "aboutness"</head><p>Single words are indexed as basic units of "aboutness" but also noun phrases are extracted as supplemental indexing units.</p><p>For example, from the TREC topic 468 the following terms are extracted: PH(incandescent light bulb) PH(incandescent light),PH(light bulb) incandescent, light, bulb Longer phrases have normally more specific reference consequently they seem to focus more on foreground part of subject description while a set of constituent single word terms are referring to the subject as if it is on background.</p><p>Changing relative weighting of phrases against single word terms, "aboutness" of the query, especially its focusing strength can be calibrated without introducing any semantic hierarchy from thesauri.</p><p>We observed the correlation between query length and effectiveness gained by supplemental phrasal indexing [Fujita 00a, Fujita 00b]. It is still in open question that such a difference of phrasal term effectiveness in different length of queries can be explained from the difference of "aboutness".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Reference Database as a Substitute for a Thesaurus</head><p>Since web queries are typically short and do not contain enough terms to discriminate documents, query expansion is desirable for the better results in TREC style evaluations.</p><p>For an automatic query expansion purpose, typically synonymous words from a thesaurus are utilized.</p><p>In Japanese text retrieval experiments, we once tried such a strategy and observed consistent but small improvement with a newspaper article database <ref type="bibr" coords="2,195.40,663.28,41.98,9.07">[Fujita 99b</ref>]. Such an approach is problematic since preparing and maintaining thesauri is not an easy task either for an open domain or a closed domain.</p><p>Another problem of utilizing pre-coded thesauri for query expansion is that synonymous relations described in thesauri are not necessarily mean equivalence as a query term. Semantic equivalence relations in lexicon level do not necessarily mean equivalence in subject concepts of retrieved documents.</p><p>Instead of such a semantic approach, documents themselves, which represent author's "aboutness" can be utilized as the source of query expansions. The technique is similar to pseudo-relevance feedback procedures, that is frequently used in TREC experiments but the database in pilot search is not identical to the retrieval target database itself. Since many web documents are terminologically so poor that it is natural to refer to other text sources for term extraction.</p><p>A reference database can be either general domain databases like newspaper or a specific domain database depending on the retrieval task in question.</p><p>In the case of web retrieval, a newspaper database seems to be appropriate, since it is open domain retrieval and the reference databases preferably cover the any subjects that might be in test topics. Only newspapers and encyclopaedia seem to possess such a broad coverage of content documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Another source of "aboutness": Anchor Text of Hyperlinks</head><p>When we ask what a page is talking about, sometimes anchor texts ( or link texts, the texts on which a hyperlink is set ) indicate exact and very short answer.</p><p>The anchor text is typically an explanation or denotation of the page that is linked to. Some commercial based search engines are utilizing such information for advanced searches <ref type="bibr" coords="2,403.24,500.32,41.91,9.07">[Altavista]</ref>. We treat anchor texts literally as the part of the linked document.</p><p>In total, 6,077,878 anchor texts are added to 1,173,189 linked pages out of 1,692,096 pages in the wt10g data set. So 69% document pages in the data set are attributed anchor text information on top of original page information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SYSTEM DESCRIPTION</head><p>For the TREC-9 Web track experiments, we utilized the engine of Justsystem ConceptBase Search™ version 2.0 as the base system.</p><p>A dual Pentium III™ server (670MHz) running Windows NT™ server 4.0 with 1024MB memory and 136GB hard disk is used for experiments.</p><p>The document collections are indexed wholly automatically, and converted to inverted index files of terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Term Extraction</head><p>Queries and documents in target databases are analyzed by the same module that decomposes an input text stream into a word stream and parses it using simple linguistic rules , in order to compose possible noun phrases.</p><p>Extracted units are single word nouns as well as simple linguistic noun phrases that consist of a sequence of nouns or nouns preceded by adjectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Vector Space Retrieval</head><p>Each document is represented as a vector of weighted terms by tf*idf in inverted index files and the query is converted in similar ways.</p><p>Similarity between vectors representing a query and documents are computed using the dot-product measure, and documents are ranked according to decreasing order of RSV. OKAPI BM25 function is utilized as TF part of weighting function <ref type="bibr" coords="3,92.92,374.32,59.64,9.07">[Robertson 94,</ref><ref type="bibr" coords="3,155.32,374.32,52.64,9.07">Robertson 95</ref>] so that the retrieval process can be considered as probabilistic ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Passage Retrieval</head><p>Since some pages are extremely long in the wt2g data set, we became aware of using passages rather than whole pages as the indexing unit is appropriate for the sake of retrieval effectiveness.</p><p>Passage delimiting is done by the manner that each passage becomes similar length rather than finding paragraph boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Phrasal Indexing and Weighting</head><p>Our approach consists of utilizing noun phrases extracted by linguistic processing as supplementary indexing terms in addition to single word terms contained in phrases. Phrases and constituent single terms are treated in the same way, both as independent terms, where the frequency of each term is counted independently based on its occurrences .</p><p>As we indicated in [Fujita 99a, Fujita 00a], phrasal terms are over-weighted with normal scoring function. We evaluated the following three methods: 1) Empirical down-weighting method <ref type="bibr" coords="3,211.00,687.04,47.52,9.07">[Fujita 99a]</ref> 2) Fagan's method <ref type="bibr" coords="3,134.20,703.12,44.40,9.07">[Fagan 87]</ref> 3) Approximation to Robertson's method <ref type="bibr" coords="3,486.04,73.60,60.24,9.07">[Robertson 97]</ref> As it performed always better than other methods in the pre-submission experiments, we adopted down-weighting approach although it requires empirical parameter tuning.</p><p>Another advantage of down-weighting approach is that the query specificity can be calibrated changing downweighting parameters when enough phrasal terms are provided in the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Pseudo-Relevance Feedback and Reference Database Feedback</head><p>Automatic feedback strategy using pseudo-relevant documents is adopted for automatic query expansion.</p><p>The system submits the first query generated automatically from topic descriptions against the target or reference database, and considers the top n documents from relevant ranking list as relevant.</p><p>The term selection module extracts salient terms from these pseudo-relevant documents and adds them to the query vector.</p><p>Then the expanded query vector is submitted against the target database again and the final relevance ranking is obtained.</p><p>The whole retrieval procedure is as follows:</p><p>1) Automatic initial query construction from the topic description</p><p>2) 1 st pilot search submitted against a reference database</p><p>3) Term extraction from pseudo-relevant documents and feedback 4) 2 nd pilot search submitted against the target database 5) Term extraction from pseudo-relevant documents and feedback 6) Final search to obtain the final results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Term Selection</head><p>Each term in example documents are scored by some term frequency and document frequency based heuristics measures described in <ref type="bibr" coords="3,409.48,625.36,38.70,9.07">[Evans 93</ref>].</p><p>The terms thus scored are sorted in decreasing order of each score and cut off at a threshold determined empirically.</p><p>In effect, the following parameters in feedback procedures should be decided:</p><p>1) How many documents to be used for feedback?</p><p>2) Where to cut off ranked terms?</p><p>3) How to weight these additional terms?</p><p>These parameters are carefully adjusted using TREC-8 queries (topic 401-450), wt2g data set and their relevance judgement provided by NIST and 4 parameter sets for official runs are decided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Spell Variation</head><p>Because of some spelling errors in "title" field texts of topic description, the system sometimes returned no document or few in very short query runs. In such a case, the initial queries are expanded automatically by generated spell variations.</p><p>The procedure consists of looking for similar words in the word lists extracted from the database. Spelling similarity is measured by a combination of uni-gram, bi-gram and tri-gram matching scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>We submitted six automatic runs as follows:</p><p>jscbt9wcs1: Content only, very short query run with parameter set s1 jscbt9wls1: Link, very short query run with parameter set s1 jscbt9wls2: Link, long query run with parameter set s2 jscbt9wcl1: Content only, long query run with parameter set l1 jscbt9wll1: Link, long query run with parameter set l1 jscbt9wll2: Link, long query run with parameter set l2</p><p>As for the link run evaluation, we adopted "anchor text" of hyperlink information as some web search sites do.</p><p>The experiments are designed to measure effects of phrasal term indexing, pseudo-relevance feedback and reference database feedback with regards to different query types.</p><p>From our experience in NTCIR-1 experiments for Japanese text retrieval, we are paying attention to the relation between the effectiveness of elementary techniques and the query length.</p><p>We observed that performance gain by the pseudorelevance feedback tend to be large when the query is shorter in NTCIR-1 experiments. It is easily understood that longer queries contain already so good terms that the feedback could no more find better terms in addition.</p><p>It seems more difficult to explain why supplemental phrasal indexing is more effective with longer queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Very Short Query Experiments</head><p>Very short query run using only "title" fields of topic description is recommended for all the sites.</p><p>The following settings are examined:</p><p>1. Content only, single words + phrases 2. Link, single words + phrases 3. Content only, single words</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Link, single words</head><p>For each setting, combination of with/without reference database feedback and with/without pseudo-relevance feedback are examined with the same parameter set: s1, for the convenience of comparison. Results of 16 runs in total are compared in Table <ref type="table" coords="4,432.04,518.80,3.78,9.07" target="#tab_1">2</ref>.</p><p>Since initial queries are very short ( in average, 2.1 single word terms and 0.7 phrasal terms, maximum 5 single word terms and 3 phrasal terms , minimum 0 single word terms and 0 phrasal terms ) and they do not contain enough terms, the automatic feedback procedure contributes to 4.5% to 7.5 % of consistent improvements in average precision in all cases.</p><p>The final queries contain 44.1 single word terms and 31.0 phrasal terms in average ( maximum 138 single word terms and 176 phrasal terms, minimum 0 single word terms and 0 phrasal terms).</p><p>The improvement gained by the combination of a pseudorelevance feedback and reference database feedback is 15.8% for content only run and 17.0% for link run. But without any feedback, single word runs are better in R-precision.</p><p>Again we confirmed the situation observed in Japanese text retrieval workshop NTCIR-1 [Fujita 99a], i.e. effectiveness of phrasal indexing is not clear when the queries are short.</p><p>Effectiveness of link run is not clear as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Long Query Experiments</head><p>Long query experiments examined queries automatically constructed from all fields in topic description.</p><p>Since TREC topic descriptions have a stratified explanation of topics in the sense that the subject explanations are iterated in different styles. Shorter fields contain only terms of "foreground aboutenss" and longer fields contain terms of "background aboutness" as well as terms of "foreground aboutness". It is important to adjust weighting for each term according to its "foregroundness" in the "request aboutness".</p><p>We adjusted term weights according to the fields in which the term appeared since this might be a good measure for term "foregroundness".</p><p>The same runs as very short query are examined:</p><p>1. Content only, single words + phrases 2. Link, single words + phrases 3. Content only, single words</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Link , single words</head><p>The initial queries contain 11.6 single word terms and 3.46 phrasal terms in average ( maximum 18 single word terms and 9 phrasal terms, minimum 5 single word terms and 0 phrasal terms ) and the final queries contain 76.9 single word terms and 53.6 phrasal terms in average ( maximum 239 single word terms and 218 phrasal terms, minimum 25 single word terms and 5 phrasal terms ).</p><p>Table <ref type="table" coords="5,343.96,506.80,5.04,9.07" target="#tab_3">3</ref> shows the results. Supplemental phrasal runs are consistently better than single word term runs both in average precision and R-precision.</p><p>Since initial queries are longer and they contain terms of "background aboutness", performance improvements given by automatic feedback are comparatively smaller ( o.3%-6.5% ) than in very short query experiments (4.5%-7.5%).</p><p>No search effectiveness improvement by introducing feedback from a reference database is observed.</p><p>We reconfirmed our observation from Japanese text retrieval experiments that the phrasal term indexing is effective only with enough long initial topic description containing a certain number of phrases as well as single words, otherwise its effect is rather incidental. As in the very short query runs, it is not clear at all if link runs are better or not than content only runs. In the presubmission experiments with the wt2g database and TREC-8 topics, small but consistent improvement was observed, but it is not the case with the TREC-9 main web test set. We did not yet find enough reason for this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>TREC-9 experiments at Justsystem group are described.</p><p>The following conclusions are drawn from these experiments:</p><p>1) Phrasal indexing seems to be more effective when the query is longer.</p><p>2) Pseudo-relevance feedback always contributes to the performance especially when initial queries are very short.</p><p>3) Feedback from a reference database was effective with very short queries but not with long queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>No reliable performance improvement utilizing anchor texts was observed in wt10g experiments. Sometimes it was effective but not always.</p><p>On the other hand, we need more experiments as well as careful observation on the effect of phrasal indexing with short queries.</p><p>It is also interesting to compare the effects of reference database feedback with query expansion by WordNet style pre-coded thesauri.</p><p>For the future work, it is desirable to introduce the distinction of foreground/background of "aboutness" in question answering task where identification of focus of the topic description is crucial.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,56.68,295.96,319.55,10.80;8,56.68,312.04,293.87,10.80"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Recall-precision curves of supplemental phrasal runs Left: Content only very short runs, Right: Link long runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,59.32,203.71,225.84,122.96"><head>Table 1 : Performance of official runs</head><label>1</label><figDesc></figDesc><table coords="4,59.32,203.71,225.84,100.37"><row><cell>Run tag</cell><cell cols="3">Query Link Ref</cell><cell cols="2">Avg. Prec R-Prec</cell></row><row><cell>jscbt9wcs1</cell><cell>VS</cell><cell>No</cell><cell>Yes</cell><cell>0.2011</cell><cell>0.2175</cell></row><row><cell>jscbt9wls1</cell><cell>VS</cell><cell cols="2">Yes Yes</cell><cell>0.2000</cell><cell>0.2219</cell></row><row><cell>jscbt9wls2</cell><cell>VS</cell><cell cols="2">Yes No</cell><cell>0.1838</cell><cell>0.2027</cell></row><row><cell>jscbt9wcl1</cell><cell>Long</cell><cell>No</cell><cell>Yes</cell><cell>0.2687</cell><cell>0.2841</cell></row><row><cell>jscbt9wll1</cell><cell>Long</cell><cell cols="2">Yes Yes</cell><cell>0.2659</cell><cell>0.2812</cell></row><row><cell>jscbt9wll2</cell><cell>Long</cell><cell cols="2">Yes No</cell><cell>0.2801</cell><cell>0.3054</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,46.84,97.63,238.68,494.00"><head>Table 2 : Performance comparison ( Very Short Query, s1 parameter set )</head><label>2</label><figDesc></figDesc><table coords="5,46.84,97.63,230.40,459.41"><row><cell>Run description</cell><cell>Ref</cell><cell cols="3">PFB AvgPrec R-Prec</cell></row><row><cell>Content only / very short /</cell><cell>Yes</cell><cell>Yes</cell><cell>0.2028</cell><cell>0.2185</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>Yes</cell><cell>No</cell><cell>0.1893</cell><cell>0.2267</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>No</cell><cell>Yes</cell><cell>0.1849</cell><cell>0.2135</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>No</cell><cell>No</cell><cell>0.1751</cell><cell>0.2020</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>Yes</cell><cell>Yes</cell><cell>0.2018</cell><cell>0.2228</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>Yes</cell><cell>No</cell><cell>0.1927</cell><cell>0.2228</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>No</cell><cell>Yes</cell><cell>0.1854</cell><cell>0.2082</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>No</cell><cell>No</cell><cell>0.1725</cell><cell>0.1919</cell></row><row><cell>SW + phrases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>Yes</cell><cell>Yes</cell><cell>0.1864</cell><cell>0.1949</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>Yes</cell><cell>No</cell><cell>0.1714</cell><cell>0.1987</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>No</cell><cell>Yes</cell><cell>0.1763</cell><cell>0.2022</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Content only / very short /</cell><cell>No</cell><cell>No</cell><cell>0.1683</cell><cell>0.2025</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>Yes</cell><cell>Yes</cell><cell>0.1863</cell><cell>0.1976</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>Yes</cell><cell>No</cell><cell>0.1732</cell><cell>0.1922</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>No</cell><cell>Yes</cell><cell>0.1726</cell><cell>0.1948</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link / very short /</cell><cell>No</cell><cell>No</cell><cell>0.1693</cell><cell>0.1983</cell></row><row><cell>Single words only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,62.44,609.19,236.64,21.07"><head>Table 3 : Performance comparison ( Long query, l2 parameter set ) Appendix A.</head><label>3</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">ACKNOWLEDGMENTS</head><p>Our thanks to <rs type="person">Mr. Toshiya Ueda</rs> and <rs type="person">Mr. Tatsuo Kato</rs> for their assistance.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,335.80,603.28,219.24,9.07;6,335.80,615.28,219.24,9.07;6,335.80,627.28,219.12,9.07;6,335.80,639.28,219.28,9.07;6,335.80,651.28,219.35,9.07;6,335.80,663.28,160.92,9.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,335.80,627.28,203.74,9.07">CLARIT TREC Design, Experiments and Results</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">G</forename><surname>Lefferts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Handerson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Archbold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,335.80,639.28,219.28,9.07;6,335.80,651.28,84.69,9.07">Proceedings of the First Text REtrieval Conference(TREC-1)</title>
		<meeting>the First Text REtrieval Conference(TREC-1)<address><addrLine>Washington D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="494" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.80,679.36,219.51,9.07;6,335.80,691.36,219.59,9.07;6,335.80,703.36,219.24,9.07;7,74.68,73.60,219.24,9.07;7,74.68,85.60,22.68,9.07" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,397.48,679.36,157.83,9.07;6,335.80,691.36,219.59,9.07;6,335.80,703.36,155.26,9.07">Experiments in Automatic Phrase Indexing for Document Retrieval: A Comparison of Syntactic and Non-syntactic Methods</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Fagan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987-09">Sept. 1987</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D Thesis</note>
</biblStruct>

<biblStruct coords="7,74.68,101.68,219.60,9.07;7,74.68,113.68,219.12,9.07;7,74.68,125.68,170.52,9.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,130.12,101.68,164.16,9.07;7,74.68,113.68,198.27,9.07">Notes on Phrasal Indexing-JSCB Evaluation Experiments at NTCIR AD HOC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,74.68,125.68,140.43,9.07">Proceedings of NTCIR-1 workshop</title>
		<meeting>NTCIR-1 workshop</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,141.76,219.60,9.07;7,74.68,153.76,219.44,9.07;7,74.68,165.76,165.72,9.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,128.92,141.76,165.36,9.07;7,74.68,153.76,149.08,9.07">Notes on Phrasal Indexing: JSCB Evaluation Experiments at IREX-IR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,245.08,153.76,49.04,9.07;7,74.68,165.76,75.84,9.07">Proceedings of IREX Workshop</title>
		<meeting>IREX Workshop<address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,181.84,219.36,9.07;7,74.68,193.84,219.36,9.07;7,74.68,205.84,199.80,9.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,122.20,181.84,171.84,9.07;7,74.68,193.84,142.97,9.07">Evaluation of Japanese Phrasal Indexing with a Large Test Collection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,249.64,193.84,44.40,9.07;7,74.68,205.84,95.47,9.07">RIAO2000 Conference proceedings</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1089" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,221.92,219.28,9.07;7,74.68,233.92,219.12,9.07;7,74.68,245.92,219.28,9.07;7,74.68,257.92,219.36,9.07;7,74.68,269.92,196.92,9.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,128.20,221.92,165.76,9.07;7,74.68,233.92,195.30,9.07">Discriminative Power and Retrieval Effectiveness of Phrasal Indexing Terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,74.68,245.92,219.28,9.07;7,74.68,257.92,219.36,9.07;7,74.68,269.92,86.43,9.07">Proceedings of the ACL-2000 Workshop on Recent Advances in Natural Language Processing and Information Retrieval</title>
		<meeting>the ACL-2000 Workshop on Recent Advances in Natural Language Processing and Information Retrieval<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="47" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,286.00,219.24,9.07;7,74.68,298.00,172.92,9.07" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,148.12,286.00,141.91,9.07">Information Retrieval Interaction</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ingwersen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Taylor Graham Publishing</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,314.08,219.12,9.07;7,74.68,326.08,219.60,9.07;7,74.68,338.08,219.60,9.07;7,74.68,350.08,105.96,9.07" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,136.12,314.08,157.68,9.07;7,74.68,326.08,94.11,9.07">Representation and Learning in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992-02">Feb. 1992</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer and Information Science, University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D Thesis</note>
</biblStruct>

<biblStruct coords="7,335.80,73.60,219.36,9.07;7,335.80,85.60,219.12,9.07;7,335.80,97.60,219.28,9.07;7,335.80,109.60,219.24,9.07;7,335.80,121.60,77.88,9.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,382.12,73.60,173.04,9.07;7,335.80,85.60,200.16,9.07">An Evaluation of Phrasal and Clustered representation on a Text Categorization Task</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,335.80,97.60,219.28,9.07;7,335.80,109.60,106.87,9.07">Proceedings of the Fifteenth Annual International ACM SIGIR Conference</title>
		<meeting>the Fifteenth Annual International ACM SIGIR Conference<address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992-06">June 1992</date>
			<biblScope unit="page" from="37" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.80,137.68,144.36,9.07;7,496.12,137.68,59.20,9.07;7,335.80,149.68,219.12,9.07;7,335.80,161.68,219.59,9.07;7,335.80,173.68,219.60,9.07;7,335.80,185.68,219.24,9.07;7,335.80,197.68,36.12,9.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,496.12,137.68,59.20,9.07;7,335.80,149.68,219.12,9.07;7,335.80,161.68,135.15,9.07">Some Simple Effective Approximations to the 2Poisson Model for Probabilistic Weighted Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,493.24,161.68,62.16,9.07;7,335.80,173.68,219.60,9.07;7,335.80,185.68,44.47,9.07">Proceedings of the Seventeenth Annual International ACM SIGIR Conference</title>
		<meeting>the Seventeenth Annual International ACM SIGIR Conference<address><addrLine>Dublin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1994-07">July 1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,342.04,213.76,213.12,9.07;7,335.80,225.76,219.12,9.07;7,335.80,237.76,219.28,9.07;7,335.80,249.76,219.35,9.07;7,335.80,261.76,160.92,9.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,467.08,225.76,70.73,9.07">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,335.80,237.76,219.28,9.07;7,335.80,249.76,84.69,9.07">Proceedings of the Third Text REtrieval Conference(TREC-3)</title>
		<meeting>the Third Text REtrieval Conference(TREC-3)<address><addrLine>Washington D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,335.80,277.84,219.44,9.07;7,335.80,289.84,219.59,9.07;7,335.80,301.84,219.60,9.07;7,335.80,313.84,219.35,9.07;7,335.80,325.84,12.60,9.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,467.08,277.84,88.16,9.07;7,335.80,289.84,135.59,9.07">On relevance weights with little relevance information</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,493.48,289.84,61.92,9.07;7,335.80,301.84,219.60,9.07;7,335.80,313.84,42.95,9.07">Proceedings of the 20th Annual International ACM SIGIR Conference</title>
		<meeting>the 20th Annual International ACM SIGIR Conference<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1997-07">July 1997</date>
			<biblScope unit="page" from="16" to="24" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
