<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.00,71.71,468.10,16.20">Filters and Answers: The University of Iowa TREC-9 Results</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,157.46,105.00,64.32,10.80"><forename type="first">Elena</forename><surname>Catona</surname></persName>
							<email>elena-catona@uiowa.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.57,105.00,80.99,10.80"><forename type="first">David</forename><surname>Eichmann</surname></persName>
							<email>david-eichmann@uiowa.edu</email>
							<affiliation key="aff1">
								<orgName type="department">School of Library and Information Science</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">The University of Iowa</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.88,105.00,93.67,10.80"><forename type="first">Padmini</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Library and Information Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">The University of Iowa</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.00,71.71,468.10,16.20">Filters and Answers: The University of Iowa TREC-9 Results</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">99CFFB35F88EEBC3262E23F981A816F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>participated in the adaptive filtering and question answering tracks of TREC9. The filtering system used was an extension of the one used in TREC-7 [1] and TREC-8 [2]. Question answering was done using a rule-based system that employed a combination of public domain technologies and the SMART retrieval system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">-Adaptive Filtering:</head><p>Our approach to filtering involves a two-level dynamic clustering technique. Each filtering topic is used to create a primary cluster that forms a general profile for the topic. Documents that are attracted into a primary cluster participate in a topic-specific second level clustering process yielding what we refer to as secondary clusters. These secondary clusters, depending upon their status, are responsible for declaring, i.e., retrieving, documents for the topic.</p><p>As documents are temporally processed they are attracted to a primary cluster if their similarity with the cluster vector is above a primary threshold. These documents enter the secondary clustering stage where again, based on similarity to cluster vectors and a secondary threshold, they either join an existing secondary cluster or start a new one. If at some point the similarity between a secondary cluster and the primary cluster exceeds a third declaration threshold then the document most recently added to the secondary cluster is retrieved for the user.</p><p>When deriving representations we use TF*IDF weights after stemming the terms using Porter's stemmer. We also limit document vectors and cluster vectors to the best 100 and 200 stems respectively.</p><p>In TREC-8 adaptation was explored at several different levels <ref type="bibr" coords="1,390.26,540.60,12.74,10.80" target="#b1">[2]</ref>. First a secondary cluster's future behavior would depend upon past performance. If a secondary cluster declares a document that turns out to be relevant then it is colored green. This means that it declares all documents that join it in the future. If instead the declared document is non relevant then the cluster is colored red and all future documents are not declared. A non relevant document that joins a green cluster spawns an independent red cluster allowing the original cluster to remain green. Another adaptive dimension was to have the primary cluster vector adapt as relevant judgements were obtained. A version of Rochio's feedback method is built into the system for this purpose. A differential adaptation scheme is also built in for this purpose. The key distinction is that in the differential scheme positive and negative term vectors are comprised only of terms not found in the other vector or in the original query vector.</p><p>Recent experiments conducted with TREC-8 data explored additional dimensions of adaptation. For example, we experimented with adapting the primary threshold as the performance measure varied. For this, the performance measure such as the utility score was computed at regular intervals when a "snapshot" of the system is taken. We also explored adaptation of secondary and declaration thresholds. In all these the most profitable approach appears to be adaptation of the break threshold using a step function that responds to changes in performance across snapshots. Our OHSU runs use the system as described above with adaptation of the break threshold.</p><p>Other key extensions to the system for TREC-9 include the ability to specify the type of index vectors to utilize. A phrase recognizer loads dictionaries of phrases derived from sources such as the WordNet thesaurus and matched phrases are included into the document vectors. More recently a rule-based entity recognizer has been developed that allows the indexing of documents by person names, organizations, locations and events. Our MESH run includes this technology as well special support for medical terminology. The MeSH hierarchy, an associated lexicon of synonyms and a supplementary list of concepts such as drug names were used. The MESH run involved index vectors that were populated using only the entities extracted from the source text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OHSU Runs:</head><p>For TREC-9 we submitted two OHSU runs. These runs employed word based indexing, Rochio feedback for the profile adaptation and adaptation of the declaration threshold. Both OHSU runs used the controlled vocabulary field (MeSH terms). The two runs differ only in their starting threshold values. The primary, secondary and declaration thresholds were 0.3, 0.32, and 0.3 respectively for OHSU1 and 0.25, 0.27, and 0.25 respectively for OHSU2. The declaration threshold was adapted in each case using a step-wise strategy. Figure <ref type="figure" coords="2,358.93,403.80,6.00,10.80" target="#fig_0">1</ref> shows the performance in terms of utility for our OHSU1 run. The dashed bars represent median performance across systems for each topic. There are 24 topics for which OHSU1 was better than the median and another 24 for which it was below the median.</p><p>We conducted several experiments after the official submission deadline to better understand the different aspects of our filtering system and its weak performance on the OHSU task. The first question asked was whether the primary filter was effective. In other words how good was it at filtering out non relevant documents while allowing through the relevant documents? Figure <ref type="figure" coords="2,499.50,514.80,6.00,10.80" target="#fig_1">2</ref> shows the percentages filtered through over time, with snapshots taken every 1000 documents. The figure shows that if we divide the snapshots into three groups then the primary filter allows about 50%, 60% and then 59% of the relevant documents that arrive over the first, second and third sequence of snapshots respectively. At the same time the percentage of non relevant documents allowed through stays less than 1% of the number seen. We then examined the effectiveness of the secondary filter. Note that this analysis of the secondary filter was limited to those documents allowed through by the primary filter. Figure <ref type="figure" coords="2,249.65,619.80,6.00,10.80">3</ref> shows that the secondary filter was successful in reducing the percentage of non relevant documents allowed through (dashed bars). However, at the same time it also restricts the passage of relevant documents although not as severely. Next we took a different track in our analysis and examined the effectiveness in adapting the declaration threshold. Figure <ref type="figure" coords="2,105.81,679.80,6.00,10.80" target="#fig_3">4</ref> displays these results. We can observe that if we eliminate break threshold adaptation performance degrades significantly over time (dashed bars). In contrast, the adaptive mode is able to stay somewhat steady -although on the negative side of the performance axis. At this point we suspected that our break threshold may not be restrictive enough. Figure <ref type="figure" coords="3,403.70,653.39,6.00,10.80">5</ref> shows the effect of testing this by contrasting a run where the break threshold was increased from the original 0.25 (dashed bars) to 0.3 (solid bars).  Figure <ref type="figure" coords="4,124.20,623.60,6.00,10.80">6</ref> shows the performance in terms of utility score for our MESH run. As mentioned before for this task we employed a rule-based entity recognizer which uses the MeSH hierarchy, an associated lexicon of synonyms and a supplementary list of concepts such as drug names. This run involved index vectors that were populated using only the entities extracted from the source text.</p><p>Entity-based performance on the MeSH subset proved to be quite intriguing. In 92 of the topics our system yielded the highest score -in some cases substantially higher than median performance.  At the same time, in 147 of the topics our system yielded the lowest score -again in some cases substantially lower than median performance. We conjecture that the pure entity scoring yields high quality results -but for some topics our secondary cluster scheme is generating too many highrelevance clusters that prove to be off-topic. This may be due in part to the score being generated by ancestor/descendant MeSH term tree matches. Figure <ref type="figure" coords="5,345.29,693.47,6.00,10.80">7</ref> presents performance (utility score) as a function of the number of relevant documents present for a given topic. The figure shows 500 data points one for each topic. One may observe a general trend that as the availability of relevant documents improves, performance increases. Moreover, most of the scores are on the positive side of the Y axis. Figure <ref type="figure" coords="6,171.61,638.26,6.00,10.80">8</ref> explores a different aspect. Our process extracts MeSH descriptors for each topic description from the MeSH hierarchy. In the figure we plot the maximum depth expressed by the group of extracted MeSH phrases for a topic and plot this against utility score. There are 50 data points corresponding to the first 50 MeSH topics. One may observe that except for a few outliers there is a slight trend for scores to improve with the ability to identify deeper i.e., more specific MeSH phrases. Interestingly the same sort of analysis using minimal MeSH depth for the topic, as shown in Figure <ref type="figure" coords="7,153.00,599.08,4.50,10.80">9</ref>, does not yield a recognizable trend. We also explored the effect of entity recognition on performance. Figure <ref type="figure" coords="7,228.94,614.08,12.00,10.80" target="#fig_6">10</ref> represents the number of entities recognized on the Y axis and performance on the X axis. The graph shows that barring a few exceptions there appears to be a slight trend for performance to improve as the number of entities recognized increases.</p><p>In summary, the switch in domain from the newswire domain to MEDLINE proved to be challenging. The thresholds used in our submitted run were essentially our best guesses. For the future we also plan to explore different term weighting strategies as well as query expansion strategies prior to starting the filtering run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-Question Answering:</head><p>We submitted two runs for this track, UIQA001 and UIQA002. Both utilized only the top 50 documents that were retrieved and distributed by Singhal. UIQA001 gave the better performance score with mean reciprocal rank of 0.227(strict) and 0.245 (lenient). The other run gave almost identical scores. Our overall QA approach is shown in below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document processing:</head><p>1. Extract only the textual parts of each document 2. Apply a sentence detection program to identify distinct sentences. We use the publicly available nxterminator program for this. 3. Apply part of speech tagging on each sentence 4. Apply our rule-based entity tagger on each sentence 5. Create a database of sentences formatted for the SMART retrieval system. Here each record corresponds to a single sentence with 3 different fields. The first holds the original untagged sentence, the second field holds the tagged sentence while the last field of the record holds only the particular entities extracted from each sentence. 6. Retrieve the top N sentences for each query. Maintaining the three distinct fields for each sentence record allows us to explore the relative merits of using different types of information for retrieving the sentence most likely to contain the answer. Using SMART allows us to explore different weighting schemes during retrieval. 7. Post process each of the N sentences to extract the top five 250-byte segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query processing:</head><p>1. Apply part of speech tagging on each query 2. Apply our rule-based entity tagger on each query. Notice in the case of the query where possible its focus (a specific entity type) is identified in addition to all the entities contained in the query. This focus is utilized during the post processing step in 7 above.</p><p>The two runs differ very slightly in the post processing stage. Generally, this step includes cleanup of the sentences to remove any non informative strings, reduction of each sentence to a 250 byte string around the query focus (if known), removal of duplicate answer strings, and selection of the top 5 phrases. The difference between the two is in the extent to which cleanup of the sentences was done. As our results show, this did not influence performance in any way since the two runs yield almost identical results.</p><p>Error analysis indicates much room for improvement. Due to insufficient time, we were able to implement only very simplistic 250-byte segment selection strategies that proved to be a significant problem for our system. Secondly, our performance was limited by the availability of the answer within the top 50 document sets distributed. Again with less time pressures we should be able to explore the 1K datasets and also conduct our own retrieval runs for the top 1K or so documents. The results indicate that our approach managed to extract the answers for about 38 to 40% of the questions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,162.21,306.36,287.64,10.80;3,225.52,318.36,160.99,10.80"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Performance of OHSU1. Dashed bar: OHSU1, Solid bar: median performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,206.22,617.01,199.62,10.80"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Assessment of Primary Filter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,162.07,250.60,2.61,4.34;4,159.06,216.60,6.01,4.34;4,159.06,182.61,6.01,4.34;4,159.06,148.61,6.01,4.34;4,159.06,114.62,6.01,4.34;4,156.06,80.62,9.02,4.34;4,173.07,257.59,296.16,4.34;4,310.14,265.59,21.05,4.34;4,143.69,238.80,4.34,4.17;4,143.69,230.29,4.34,4.64;4,143.69,207.67,4.34,18.75;4,143.69,176.56,4.34,27.24;4,143.69,154.25,4.34,18.44;4,143.69,131.39,4.34,18.99;4,143.69,121.83,4.34,5.69;4,143.69,92.28,4.34,25.69;4,149.70,178.36,4.34,24.61;4,149.70,156.70,4.34,16.66;4,149.70,131.31,4.34,20.40;4,224.10,277.59,95.72,4.34;4,340.16,277.59,105.23,4.34"><head></head><label></label><figDesc>Documents Filtered through by Secondary (averaged across queries) % of Relevant Documents Filtered Through % of Non Relevant Documents Filtered Through</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,200.88,290.06,210.30,10.80"><head>FigureFigure 4 :</head><label>4</label><figDesc>Figure 3: Assessment of Secondary Filter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,179.20,317.40,253.66,10.80;5,226.51,329.40,159.01,10.80"><head>Figure 5 :-Figure 6 :</head><label>56</label><figDesc>Figure 5: Assessment of Higher Break Threshold. Dashed bar: 0.25 Solid bar: 0.3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="6,120.91,306.06,370.26,10.80"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Performance versus Number of Relevant Documents for Topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,161.38,304.75,289.31,10.80"><head>Figure 10 :</head><label>10</label><figDesc>Figure 9: Minimum MeSH Depth for Topic versus Score</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,108.01,91.80,419.63,10.80;9,108.00,103.80,429.43,10.80;9,108.00,115.80,67.00,10.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,330.90,91.80,196.73,10.80;9,108.00,103.80,56.53,10.80">Cluster-Based Filtering for Adaptive and Batch Tasks</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eichmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,177.49,103.80,208.93,10.80">Seventh Conference on Text Retrieval, NIST</title>
		<meeting><address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">November 11 -13, 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.01,133.80,412.27,10.80;9,108.00,145.80,432.03,10.80;9,108.00,157.80,48.32,10.80" xml:id="b1">
	<analytic>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eichmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,271.33,133.80,248.95,10.80;9,108.00,145.80,292.57,10.80">Filters, Webs and Answers: The University of Iowa TREC-8 Results</title>
		<meeting><address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Eighth Conference on Text Retrieval, NIST</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
