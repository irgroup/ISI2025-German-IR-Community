<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.91,130.83,333.43,17.55">TREC-9 CLIR Experiments at MSRCN</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.99,162.85,57.09,9.67"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
							<email>jfgao@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.98,162.85,57.92,9.67"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
							<email>nie@iro.umontreal.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Département d&apos;informatique et de recherche opérationnelle</orgName>
								<orgName type="institution">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.06,162.85,47.49,9.67"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technology of Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.45,162.85,54.81,9.67"><forename type="first">Endong</forename><surname>Xun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,215.06,176.05,24.93,9.67"><forename type="first">Yi</forename><surname>Su</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technology of Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.02,176.05,48.57,9.67"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<email>mingzhou@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.50,176.05,78.57,9.67"><forename type="first">Changning</forename><surname>Huang</surname></persName>
							<email>cnhuang@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.91,130.83,333.43,17.55">TREC-9 CLIR Experiments at MSRCN</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4774FE17FA4F0E4400F89175F149F4BE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC-9, we participated in the English-Chinese Cross-Language Information Retrieval (CLIR) track. Our work involved two aspects: finding good methods for Chinese IR, and finding effective translation means between English and Chinese. On Chinese monolingual retrieval, we investigated the use of different entities as indexes, pseudorelevance feedback, and length normalization, and examined their impact on Chinese IR. On English-Chinese CLIR, our focus was put on finding effective ways for query translation. Our method incorporates three improvements over the simple lexicon-based translation:</p><p>(1) word/term disambiguation using co-occurrence, (2) phrase detecting and translation using a statistical language model and (3) translation coverage enhancement using a statistical translation model. This method is shown to be as effective as a good MT system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In TREC-9, Microsoft Research China (MSRCN), together with Prof. Jian-Yun Nie from University of Montreal, participated for the first time in the English-Chinese Cross-Language Information Retrieval (CLIR) track. Our work involved two aspects: Finding good methods for Chinese IR, and finding effective translation means between English and Chinese.</p><p>Finding a good monolingual IR method is a prerequisite for CLIR. On Chinese monolingual retrieval, we examined the problems such as using different entities as indexes, pseudo-relevance feedback, length normalization, as well as cutting documents done into passages. Each of these techniques gave some improvements to Chinese IR. The best combination of them is used for our Chinese monolingual IR.</p><p>On English-Chinese CLIR, our focus was put on finding effective ways for query translation. Large English-Chinese bilingual dictionaries are now available. However, beside the problem of completeness of the dictionary, we are also faced with the problem of selecting the best translation word(s) from the dictionary. To deal with this problem, we used an approach called, improved lexicon-based query term translation, which bring significant improvements over the simple approach based on bilingual lexicon. In this approach, we investigated the following three problems:</p><p>(1) word/term disambiguation using co-occurrence, (2) phrase detecting using a statistical language model, and</p><p>(3) translation coverage enhancement using a statistical translation model.</p><p>In section 2, we introduce briefly our work on finding the best indexing unit for Chinese IR. In section 3, we describe in detail the proposed method --improved lexicon-based query term translation, and compare with the method using a machine translation (MT) system in CLIR. In section 4, we describe the use of query expansion techniques. In section 5, experimental results are presented. Finally, we present our conclusion in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Finding the Best Indexing Units for Chinese IR</head><p>It is well known that the major difference between Chinese IR and IR in European languages lies in the absence of word boundaries in sentences. Words have been the basic units of indexing in traditional IR. As</p><p>Chinese sentences are written as continuous character strings, a pre-processing has to be done to segment sentences into shorter units that may be used as indexes.</p><p>Indexing units for Chinese IR may be of two kinds, words or n-grams <ref type="bibr" coords="2,141.87,166.93,43.44,8.72" target="#b11">[Nie, 2000]</ref>.</p><p>When using words, several types of knowledge may be used: manually constructed dictionary that stores a set of known words, heuristic rules on word formation, or some statistical measures based on co-occurrences of characters. A dictionary-based segmentation is widely used to identify all occurrences of the dictionary words in a sentence. If there are word segmentation ambiguities, the longest-matching strategy is usually used to select the best choice. There are mainly two problems of this approach. The first is the loss in recall.</p><p>A long word may contain several shorter words. In the longest matching, only the longest word is identified as an index, and all the included short words are ignored. For example, if</p><p>Ȓ " (operating system) is identified as a word, Ȓ (operating) and " (system) will not. However, in practice, we also refer to an "operating system" by just "system". Although the word "system" is included in "operating system", it will not be considered as a completely independent index for IR. Therefore some relevant documents will not be retrieved. The second problem is the unknown word problem. Especially, many proper nouns, which play an important role in IR, are not in the dictionary, and are not considered as indexes.</p><p>Another kind of indexing units is n-grams. This method does not require any linguistic knowledge. Usually, one chooses n-grams of lengths 1 or 2 (uni-grams or bigrams). Longer n-grams are rarely used due to the higher memory cost and their marginal improvement over bi-grams. In comparison with words, the advantage of bi-grams lies in its robustness to unknown words. For example, for proper nouns that are not in the dictionary, such as .ঔ (a place in southern China), word segmentation will segment the proper noun into three characters, i.e. , ., and ঔ. When using bi-grams, we can still use part of the proper nouns as indexes, i.e.</p><p>., .ঔ. If both bi-grams occur in the same document, there is a higher probability that the document concerns .ঔ, than the documents where the three single characters occur. Political terms or abbreviations (e.g. ƽ -three turmoils), and foreign names (e.g. ඟ \ ć ӝ -Mount Minatubo) are similar examples showing the advantage of using bi-grams.</p><p>Words and n-grams represent two different ways to represent a document -one relies on linguistic knowledge and the other on statistical information only. It is a common practice to combine different evidence to judge document relevance. So it is also reasonable to combine n-grams with words.</p><p>To sum up, we can create three possible representations for a document and a query as shown in figure <ref type="figure" coords="2,510.01,206.40,3.61,8.72" target="#fig_0">1</ref>, i.e. words, characters, and bi-grams. We also see that some correspondences may be created across representations, if different representations are integrated (for example, between words and characters).  Once Chinese sentences have been segmented into separate items, traditional IR systems may be used to index them. These separate items are called "terms" in IR. For our experiments, we used a modified version (the modifications are made in order to deal with Chinese) of the SMART system <ref type="bibr" coords="2,439.93,528.10,61.42,8.72" target="#b2">[Buckley, 1985]</ref>.</p><p>The following methods have been compared:</p><p>1. using the longest matching with a small dictionary and with a large dictionary 2. combining the first method with characters 3. using full segmentation with or without adding characters 4. using bi-grams and characters  The results of this series of experiments are summarized in the figure <ref type="figure" coords="3,121.11,300.83,3.67,8.72" target="#fig_1">2</ref>, detailed description can be found in <ref type="bibr" coords="3,273.85,300.83,19.82,8.72;3,70.47,311.87,21.12,8.72" target="#b11">[Nie, 2000]</ref>.</p><p>In order to examine the impact of dictionary in word segmentation, two different dictionaries are used. The small dictionary contains 65,502 entries. The large dictionary contains 220K entries, containing not only all entries in the small dictionary, but also a large number of phrase, including date expressions (e.g. Ư ֨year 1934), suffix structures (e.g. ȩ # -user), etc.</p><p>The second dictionary is more complete. In both cases, we use the same forward longest-matching strategy.</p><p>Using the first dictionary, we obtained an average precision of 0.3797. Using the second dictionary, the average precision is increased to 0.3907. We can see that a better dictionary can increase IR effectiveness to some extent.</p><p>To remedy the loss in recall caused by the use of the longest words, we complement the longest words by single characters. We obtain nontrivial improvements.</p><p>In the case of large dictionary, we achieve an average precision of 0.4290 (9.8% improvement). It turns out that simply adding single characters is a more effective way to increase IR performance than increase the dictionary size. Another way to increase recall is to extract the short words implied in long words, called full segmentation. In this case, we obtain an average precision of 0.4090. Although the performance is better than using the longest words alone, it is worse than the method by adding single characters. One of the reasons might be due to the cross-word segmentation phenomenon; i.e. some words extracted in full segmentation are composed of parts of two different words. For example, from the string ä (exploit a oilfield), we not only extract the correct words (exploit) and ä (oilfield), but also ä (hair oil).</p><p>Previous studies <ref type="bibr" coords="3,382.93,289.56,56.44,8.72" target="#b8">[Kwok, 1997;</ref><ref type="bibr" coords="3,444.36,289.56,43.78,8.72" target="#b10">Nie, 1999]</ref> show that when combining bi-grams with uni-grams, the IR performance is better. We repeat this experiment here, and obtained an average precision of 0.4254. This performance is comparable to the best performance we obtained using words. This is largely contributed to the robustness for dealing with unknown words by n-grams.</p><p>As bi-grams and words have their own advantages, we try to combine them to benefit from both. Theoretically, such a combination would result in a better precision (due to words) and an increased robustness for unknown words (due to n-grams). Unfortunately, the experimental result is not promising enough. We obtain slightly improvements of 2.6% (average precision 44.00%) over the uncombined case, whereas the space and the time of indexing are more than doubled.</p><p>After word segmentation, we noticed that some important proper nouns and noun phrases have not been recognized as words, but segmented into single characters, such as ඟ \ćӝ (Mount Minatubo).</p><p>Therefore, we used NLPWin 1 to recognize multi-word phrases and unknown words. NLPWin first tags texts using a Chart-parser (with a dictionary). For unknown words, a category is guessed according to its context. Special rules have also been integrated to recognize proper nouns. As a consequence, most Chinese or English proper nouns can be tagged and recognized correctly. Some political terms and abbreviations (e.g.</p><p>ƑƳ -Sino-Vietnam) can also be recognized. Using NLPWin, we created another set of words that is added 1 The NLPWin system is a natural language processing system developed by Microsoft Research. The system converts text into a parse tree that represents the syntactic structure and then into its logical form that reflects the meaning of the text. These representations can then be used for tasks such as grammar checking, machine translation, and information retrieval. to our original dictionary. From the 54 queries, 80 new words have been recognized. Most of them are proper nouns or noun phrases. The addition of unknown words had positive impact for 10 queries out of 54, while the effectiveness is reduced for 4 queries. Table <ref type="table" coords="4,250.70,334.67,4.85,8.72" target="#tab_2">1</ref> contains some examples of queries for which the addition of new words has positive impacts. As we can see in Fig. <ref type="figure" coords="4,269.29,357.11,3.67,8.72" target="#fig_1">2</ref>, the global effect of adding an unknown word detection is positive.</p><p>We can see from figure 2 that as long as different kinds of indexes are combined the IR performance increases. The question now is whether the combination is worth the cost. In taking into account both effectiveness and cost, we think the combination should go in the direction represented by the bold lines in figure 2. For our experiments in TREC9, we will use the combination of the longest words, single characters and detected unknown words for Chinese IR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Query Translation</head><p>The methods for query translation, proposed recently, fall into three categories: (1) using MT systems, (2) using parallel corpora, and (3) using bilingual lexicons. The third method is the simplest way to implement because of its simplicity and the increasing availability of machine-readable bilingual lexicons. Therefore, we decided to start with this method in TREC9 and try to improve it by adding other tools.</p><p>The main problems we observe on this simple method are: 1) the dictionary used may be incomplete; and (2) it is difficult to identify the correct word sense from the lexicon. To deal with these issues, we used an improved lexicon-based query translation. It tries to improve the lexicon-based translation through (1) word/term disambiguation using co-occurrence, (2) phrase detecting and translation using a statistical language model, and (3) translation coverage enhancement using a statistical translation model. In what follows, we will describe each of them in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Word/term disambiguation</head><p>It is assumed that the correct translations of query terms tend to co-occur in target language documents and incorrect translations do not. Therefore, given a set of original English query terms, we select for each term the best translation term such that it co-occurs most often with other translation words in Chinese documents. Finding such an optimal set is computationally very costly. Therefore, an approximate algorithm is used. It works as follows. Given a set of n original query terms {s 1 ,…,s n }, we first determine a set T i of translation words for each s i through the lexicon. Then we try to select the word in each T i that has the highest degree of cohesion with the other sets of translation words. The set of best words from each translation set forms our query translation.</p><p>The cohesion is based on term similarity calculated as follows. For terms x and y, their similarity is:</p><formula xml:id="formula_0" coords="4,368.29,576.68,64.18,9.69">) , (<label>log</label></formula><formula xml:id="formula_1" coords="4,312.25,545.48,232.34,150.33">) ) ( ) ( ) , ( ( log ) , ( ) , ( 2 2 y x Dis K y p x p y x p y x p y x SIM × - × × = where ) ( ) , ( ) ( ) , ( ) , ( y c y x c x c y x c y x p + = ∑ = x x c x c x p ) ( ) ( ) (</formula><p>and c(x,y) is the frequency that term x and term y cooccur in the same sentences in the collection, c(x) is the number of occurrence of term x in the collection,</p><p>(1) Dis(x,y) is the average distance (word count) between term x and term y in a sentence, and K is a constant coefficient.</p><p>The cohesion of a term x with a set T of other terms is the maximal similarity of this term with every term in the set, i.e.</p><formula xml:id="formula_2" coords="5,107.31,201.84,141.82,9.55">Cohesion (x, T) = Max y∈T SIM (x, y)</formula><p>The greedy algorithm used to select the word translations is as shown in figure <ref type="figure" coords="5,444.02,133.45,3.67,8.72" target="#fig_1">2</ref>.</p><p>The term-similarity matrix is obtained via a statistical model, which is trained using a large Chinese corpus of MSRCN consisting of 1.6 billion characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>===============================================================</head><p>For each s i (i = 1 to n), retrieve a set of senses T i from the lexicon;</p><p>For each set</p><formula xml:id="formula_3" coords="5,122.07,252.84,305.19,60.54">T i (i = 1 to n), do For each term t ij in T i , do For each set T k (k = 1 to n &amp; k&lt;&gt;i), compute the cohesion Cohesion(t ij , S k ); Compute the score of t ij as the sum of Cohesion(t ij , S k ) (k = 1 to n &amp; k&lt;&gt;i);</formula><p>Select the term t ij in T i with the highest score, and add the selected sense into the set T. =============================================================== Fig. <ref type="figure" coords="5,224.18,355.07,3.67,8.72">3</ref>. Greedy algorithm to find best translations</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Phrase detecting and translation</head><p>The translation of multi-word phrases is usually more precise than a word-by-word translation <ref type="bibr" coords="5,242.30,429.10,48.99,8.72;5,70.47,440.26,21.02,8.72" target="#b0">[Ballesteros, 1998]</ref>, since phrases usually have fewer senses. However, if a phrase is not stored in a lexicon, we usually can do nothing. Unfortunately, in TREC-9 query set, more than 50% phrases are not in our lexicon.</p><p>In our experiments, we try to incorporate some translation patterns between English and Chinese. For example, a (NOUN-1 NOUN-2) phrase is usually translated into the (NOUN-1 NOUN-2) sequence in Chinese, and a (NOUN-1 of NOUN-2) phrase is usually translated into the (NOUN-2 NOUN-1) sequence in Chinese. So if we can detect the English phrase of some patterns, we can guess the form(s) of the translation phrases. For instance, the translation of the multi-word phrase "drug sale" is _(drug)/Ƽ\(sale), and the translation of the multi-word phrase "security committee of UN" is ฬ (UN)/ s (security committee).</p><p>To do this, we use again NLPWin to detect phrases in the English queries. We selected a set of 40 English patterns (PAT Te ) that are often used in phrases. For each of them, we estimate the probability of the order of translation words, p(O Tc |PAT Te ). Then the best translation phrase is the one that maximizes the following function,</p><formula xml:id="formula_4" coords="5,324.49,371.99,188.13,9.55">Tc = argmax p(O Tc |PAT Te ) p(Tc) ( 2 )</formula><p>where p(Tc) is a priori probability whose value is given by the bigram language model. The bigram language model is trained using the same large Chinese corpus of MSRCN. For the moment, an approximate probability p(O Tc |PAT Te ) is assigned by a linguist because of the lack of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Using translation model</head><p>Translations stored in lexicons are always limited, no matter how complete they are. Parallel texts may contain additional translations. Therefore, we used a statistical translation model trained from a set of parallel texts as a complement of the previous methods.</p><p>Given a set of parallel texts in two languages, they are first aligned into parallel sentences. While the lexically based techniques use extensive online bilingual lexicons to match sentences [Chen 93], statistical techniques require almost no prior knowledge and are based solely on the lengths of sentences, i.e. length-based alignment method. We use a novel method that incorporates both approaches <ref type="bibr" coords="5,359.29,632.25,19.23,8.72">[Liu,</ref><ref type="bibr" coords="5,381.73,632.25,11.53,8.72">95]</ref>. First, the rough result is obtained by using the length-based method. Then anchors are identified in the text to reduce the complexity. An anchor is defined as a block that consists of n=3 successive sentences. Finally, a small, restricted set of lexical cues is applied to obtain further improvements.</p><p>Once a set of parallel sentences is obtained, word translation relations are estimated. Chinese sentences are first segmented into word strings by using a dictionary, containing approximately 80 thousand words, in conjunction with an optimization procedure described in <ref type="bibr" coords="6,80.56,144.61,45.38,8.72">[Gao, 2000]</ref>. The bilingual training process employs a variant of the model in <ref type="bibr" coords="6,162.62,155.77,57.58,8.72" target="#b1">[Brown, 1993]</ref> and it is based on an iterative EM (expectation-maximization) procedure for maximizing the likelihood of generating the English given the Chinese portion. The output of the training process is a set of potential Chinese translations for each English word, together with the probability estimate for each translation.</p><p>The problem we often have with translation models is the unavailability of parallel texts for Chinese-English.</p><p>To solve the problem, we conducted a text-mining project in the Web to find parallel texts automatically <ref type="bibr" coords="6,70.47,284.64,44.20,8.72" target="#b10">[Nie, 1999]</ref>. We select about 20,000 parallel document URLs, from which 870,414 pairs of sentences are selected for model training. The training data amounts to 74MB Chinese texts and 51MB English texts.</p><p>Let's assume that all multi-word phrases have been translated by equation ( <ref type="formula" coords="6,170.97,346.43,3.43,8.72">2</ref>). By combining translation model, we can arrive at the following equation of query phrase translation: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tests of Query Translation on TREC 5&amp;6</head><p>We carried out a series of tests to compare our improved method with the following four cases:</p><p>1. monolingual: retrieval using provided (manually translated) Chinese queries; 2. simple translation: retrieval using query translation obtained by looking up the bilingual lexicon;</p><p>3. best-sense translation: retrieval using query translation obtained by manually selecting the best senses among the senses in the bilingual lexicon for each query term;</p><p>4. machine translation: retrieval using translation queries obtained by the machine translation software system.</p><p>In our experiments, the English-Chinese bilingual lexicon we used comes from LDC (http://morph.ldc.upenn.edu/Projects/Chinese/). It contains 110,834 English entries as well as their corresponding Chinese translations. For each English entry, there are usually several Chinese translations. The simple translation works in two modes. One is u-mode that selects the most Chinese translation for each English term. The other is m-mode that selects the first three (if it contains no less than three translations) frequent-used Chinese translations.</p><p>For best-sense translation, we manually select one translation for each term in queries, for multi-word phrases not found in the lexicon, we translate it word-by word.</p><p>The improved translation makes use of the following tools described previously: (1) the term-similarity matrix for term disambiguation, (2) the language model for phrase translation, and (3) the translation model for lexicon coverage enhancement.</p><p>The use of an MT package is convenient for CLIR since it takes care of problems like word morphology, parsing, etc. On the other hand, its internal working scheme and dictionaries are proprietary, and one can only treat it as a black box and has to accept the output as is with little possibility of changing them. In our experiments, a commercial English to Chinese machine translation software system called IBM HomePage Dictionary TM 2000 is used. The system is released recently by IBM. It contains a 480K English-Chinese dictionary, which consists of both words, frequently used phrases (such as "information retrieval"), acronyms (such as "IBM"), and proper nouns (such as "Microsoft"). It can translate a word, phrase, sentence or whole document. According to our survey, this system is one of best machine translation product currently on the market. The result of query translation by the IBM system seems reasonable; less than 2% of the words are left untranslated, most phrases are translated as a whole, and the ambiguity problem of most words are solved successfully.</p><p>The results of this series of experiments on query translation are summarized in table 2. As can be expected, the simple translation methods are not very good. Their performances are lower than 60% of the monolingual performance.</p><p>The best-sense method improves the performance of the simple translation method. It achieves 73.05% of monolingual effectiveness. However, it is still worse than our improved translation method, which achieves a 75.40% performance of that of monolingual IR.</p><p>IBM HomePage Dictionary TM 2000 is a very powerful machine translation system. Using it for query translation, we can achieve 75.55% of monolingual effectiveness. On the other hand, the fact that the most powerful commercial machine translation system performs almost the same as our improved method indicates the effectiveness of our query translation technique for CLIR.</p><p>The best performance is achieved by combining linearly two sets of translation queries obtained by machine translation method and the improved translation method.</p><p>It is over 85% of monolingual effectiveness. The motivation of combination of different translation methods is that different translation systems would complement each other. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Query Expansion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pre-translation &amp; Posttranslation Query Expansion</head><p>Earlier work showed that query expansion can greatly reduce the error associated with dictionary translation <ref type="bibr" coords="7,70.47,555.45,78.39,8.72" target="#b0">[Ballesteros, 1998]</ref>. A popular method of query expansion in TREC experiments is the 2-stage pseudo relevant feedback. At first, raw queries are used to retrieve a ranked list of documents. Then the set of n top-ranked documents is used for query expansion. Usually, we expand the initial query by adding m topfrequent terms from the n top-ranked documents. Through a preliminary experiment, we established the optimal values (with respect to our test collection) of n and m.</p><p>In CLIR, queries can be expanded prior to translation, after translation or both before and after translation. In English-Chinese CLIR, pre-translation query expansion means using a separate English collection for pretranslation retrieval in order to expand the English query with highly associated English terms. These terms may help focus on the query topic and bring more translated terms that together are useful for disambiguating the translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sub-Documents 2</head><p>The purpose of dividing a document into a sequence of subdocuments (or passages) of certain length is to create a length normalization effect. It is also hoped that each passage will concentrate on a specific topic, or at least on fewer topics than a complete document. Real documents can be very long (e.g. 2 MB) and very short (e.g. a few words). When such documents form the topranked pool, one would face a lot of noise during term selection. Using sub-documents have the advantage of being able to define a more specific domain that is less noisy for query expansion. In our experiments, the medium length of subdocument is set at 550 words. We used pivot normalization <ref type="bibr" coords="7,414.72,343.79,61.77,8.72" target="#b13">[Singhal, 1996]</ref> in Smart (the ltu weight scheme), given the old weight, w, of a term, the new weight, w', can be written as:</p><formula xml:id="formula_5" coords="7,322.94,384.77,210.09,35.66">nbTerm slope pivot slope w w * ) 0 . 1 ( ' + × - = (4)</formula><p>where pivot is the average numbers of terms in a documents, nbTerm is the actual number of terms in the current document, slope is a parameter determining the impact of document length normalization, and a typical setting is slope = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Tests of Query Expansion on TREC 5&amp;6</head><p>We conducted another series of experiments to measure the effectiveness of our query expansion techniques.</p><p>The experimental results on monolingual IR are shown in table <ref type="table" coords="7,345.85,569.85,3.67,8.72" target="#tab_5">4</ref>. The indexing units used in this case are the longest words and single characters. The query expansion was performed by adding the top 500 terms from the top 20 documents of the initial ranked documents. When using the SMART ltc weighting scheme, we obtained 9.1% improvement over the initial retrieval. Move improvements are obtained when we do retrieval and feedback using sub-documents of a certain size (550 words). The document length normalization, i.e. ltu, also leads to limited improvements. It is interesting to note that the best result is achieved when we use the ltc weighting scheme at the 2-stage retrieval, but keep the ltu at the 1-stage retrieval (last row of the table <ref type="table" coords="8,92.07,155.77,3.53,8.72" target="#tab_4">3</ref>). The overall results of query expansion on CLIR are shown in table <ref type="table" coords="8,133.59,449.98,3.61,8.72" target="#tab_5">4</ref>, which provides the average retrieval precision of 1-stage retrieval (without query expansion) as a baseline, as shown in row 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub</head><p>Post-translation expansion was performed by adding the top 500 terms from the top 20 documents of the initial ranked documents after query translation. It brings about 31.4% of improvements, as shown in row 3,</p><p>We experimented with pre-translation query expansion using the Foreign Broadcasting collections of TREC and used various levels of query expansion. An English query is first used to retrieve a set of documents from this collection. The top 10 English terms from the top 10 documents are used for query expansion before query translation. As shown in Table <ref type="table" coords="8,484.56,155.77,3.67,8.72" target="#tab_5">4</ref>, the pretranslation QE brings an additional improvement of about 2.8% compared to not using it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments in TREC 9</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>We submitted 5 runs, as shown in Table <ref type="table" coords="8,472.33,465.70,3.67,8.72" target="#tab_7">6</ref>.</p><p>The monolingual run (MSRCN1) uses the longest words, single characters as well as automatically detected unknown words for indexing. The weighting scheme used is that ltu is used for the 1-stage retrieval and ltc for the 2-stage retrieval.</p><p>The MSRCN2 run is the one in which our improved method is combined with the IBM MT system MSRCN4 and MSRCN5 use respectively our improved method and the IBM MT system alone. Both pretranslation QE and post-translation QE are used in both cases.</p><p>As indicated in table 5, unlike the experimental results on TREC5&amp;6, pre-translation QE does not obtain any improvements. The similar effectiveness of MSRCN4 and MSRCN5 shows again that our approach leads to almost the same effectiveness as the IBM MT system. It is also interesting to find that the best CLIR performance is over 100% of the monolingual. In order to analyze how good our query translation approach for CLIR, we display in Fig. <ref type="figure" coords="9,170.91,660.09,4.85,8.72">4</ref> a comparison of the retrieval results for the 25 queries. Another comparison with the medium performance is given in Table <ref type="table" coords="9,225.02,682.40,3.67,8.72">7</ref>.</p><p>Through our first analysis, the queries may be classified into three categories:</p><p>1) 5 queries that have both monolingual and CLIR result of Avg.P lower than 0.1. They are #58, 61, 67, 69, and 77. The bad effectiveness in these cases is not due to translation, but because the query topics are difficult for IR.</p><p>2) 11 queries with monolingual Avg.P lower than CLIR.</p><p>There might be two possible reasons. The first is due to the multiple translations for some key words by combining different translation methods, i.e. our approach and IBM MT software. These multiple translations usually are exchangeable. Multiply translations act as the query expansion. Some examples are: "public key" in query 68# is translated to "ˤ˩w " as well as "ˤ˩w ", "Olympics" in query 70# to "' ZG" (Olympic) and "'-" (Olympic games), and "Panda bear" in query 76# to " ē" and " ē", etc. The second reason is due to better translations over the original ones. For example, "violation" in query #56 is translated to the more common "ɍң" rather than "-".</p><p>3) 9 queries with monolingual Avg.P higher than CLIR. Most of them are due to the bad translations of key concepts. For example, query 65# contains an important term "three-links" ( -), a political abbreviation. This term is not translated correctly. This situation is very similar to some cases observed in TREC5&amp;6, where we encountered the terms such as "most-favor nation" (</p><p>), "World Conference on Women" ( ), and "Project Hope" ( ). Some domain specific composition phrases, which are not included in the lexicon, such as "stealth technology" ( ܾ ) and "stealth countermeasure" ( ܾ ) in #59, "computer hacker" ( $ 6 Ҙ ) in #65, "synthetic aperture radar" ( Ѩ‫ؖ‬ ᇰ) in #66, "vehicle fatalities" ( ǅ ) in #68 have special terminology in Chinese and are also not picked up, although every word in each phrase is given the correct sense. Other cases are due to the wrong translations of words, for example, "livestock" in #69 is translated to "ଞ ", but the correct translation in this query should be " ě ", which is not included in the lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we described our work in the TREC-9 evaluation in the English-Chinese Cross-Language Information Retrieval (CLIR) track. It involved two aspects: finding good methods for Chinese IR, and finding effective translation means between English and Chinese.</p><p>On Chinese monolingual retrieval, we examined the problems such as using different entities as indexes, pseudo-relevance feedback, length normalization, as well as cutting documents done into passages. Each of these techniques gave some improvements to Chinese IR. The best combination of them is used for our Chinese monolingual IR.</p><p>On English-Chinese CLIR, our focus was put on finding effective ways for query translation. We have a large English-Chinese bilingual dictionary from LDC. However, beside the problem of completeness of the dictionary, we are also faced with the problem of selecting the best translation word(s) from the dictionary. To address this problem, the following complementary tools have been used: (1) word/term disambiguation using co-occurrence, (2) phrase detecting and translation using language model, and (3) translation coverage enhancement using translation model.</p><p>The experimental results we obtained are very encouraging. On Chinese monolingual IR, we obtained 51.50% for TREC5 and 6 Chinese data. This is favorably comparable to the best effectiveness achieved in the previous Chinese TREC experiments.</p><p>On English-Chinese CLIR of TREC5 and TREC6, we obtained 75.55% of monolingual effectiveness using our approach. To compare with an MT system, we also tested the IBM MT system, which, when used alone, leads to the same effectiveness (75.40%). When our approach is combined with IBM MT system, we obtained over 85% of monolingual effectiveness. This shows that some translation tools specially designed for query translation may be as suitable as a high-cost MT system, and even if a high-quality MT system is available, our approach can still lead to additional improvements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,332.77,348.83,179.61,8.72;2,312.26,365.75,220.77,8.72;2,312.26,376.91,220.76,8.72;2,312.26,388.07,220.76,8.72;2,312.26,399.23,220.70,8.72;2,312.26,410.51,220.77,8.72;2,312.26,421.54,220.67,8.72;2,312.26,432.82,220.70,8.72;2,312.26,443.98,220.76,8.72;2,312.26,455.26,120.37,8.72"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Possible representations in Chinese IRIn order to determine the best indexing units, we conduct a series of test tests on TREC 5&amp;6 Chinese data<ref type="bibr" coords="2,312.26,388.07,62.53,8.72" target="#b5">[Harman, 1996]</ref>. The documents in the collection are articles published in the People's Daily from 1991 to 1993, and a part of the news released by the Xinhua News Agency in 1994 and 1995. A set of 54 English queries (with translated Chinese queries) has been set up and evaluated by people in the NIST (National Institute of Standards and Technology).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,208.46,272.52,186.45,8.72"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results of indexing units for Chinese IR</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,252.14,387.70,3.00,8.10;6,236.66,387.70,3.00,8.10;6,210.86,387.70,3.00,8.10;6,194.66,387.70,1.80,8.10;6,177.03,387.70,3.00,8.10;6,147.51,387.70,15.30,8.10;6,130.83,387.70,11.46,8.10;6,240.14,387.70,9.04,8.10;6,215.30,387.70,15.06,8.10;6,198.86,387.70,9.04,8.10;6,180.51,387.70,9.04,8.10;6,170.91,387.70,4.50,8.10;6,106.59,384.76,19.94,11.73;6,270.74,386.03,11.39,8.72;6,70.47,405.59,220.76,8.72;6,70.47,416.74,220.89,8.72;6,70.47,427.90,220.80,8.72;6,70.47,439.06,220.82,8.72;6,70.47,450.34,50.18,8.72"><head></head><label></label><figDesc>Te|Tc) is the translation probability of Chinese term Tc to English term Te, and SIM(Tc) is the sum of the maximum similarity score of the selected translation set Tc, which is estimated by algorithm in figure2and equation (1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,119.67,139.73,360.13,142.00"><head>Table 1 :</head><label>1</label><figDesc>Impact of unknown word recognition on some queries.</figDesc><table coords="4,119.67,139.73,360.13,126.27"><row><cell>riginal</cell><cell>ew</cell><cell cols="2">Impr. New words added</cell></row><row><cell>vg.P.</cell><cell>vg.P.</cell><cell></cell></row><row><cell cols="4">9 0.3648 0.4173 14.4% _Ƽ\ (drug sale)</cell></row><row><cell cols="4">23 0.3940 0.5154 30.8% ฬ s (Security committee of UN), &lt;֧ၖ (peace proposal)</cell></row><row><cell cols="3">28 0.4824 0.5034 4.4%</cell><cell>(cellular), Ǟ‫ސ‬ළ (interchange network)</cell></row><row><cell cols="4">46 0.3483 0.4192 20.4% ƑƳ (Sino-Vietnam)</cell></row><row><cell cols="3">47 0.5369 0.5847 8.9%</cell><cell>ඟ \ćӝ (Mount Minatubo), %Ӏ (ozone layer)</cell></row><row><cell cols="4">54 0.6778 0.7005 3.3% F-16, I</cell><cell>(August 17)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,73.71,274.44,214.41,171.91"><head>Table 2 :</head><label>2</label><figDesc>Average retrieval precision of the English translation queries.</figDesc><table coords="7,73.71,274.44,214.41,142.39"><row><cell>Translation Method</cell><cell>Avg.P.</cell><cell>% of</cell></row><row><cell></cell><cell></cell><cell>Mono. IR</cell></row><row><cell>1 Monolingual</cell><cell>0.5150</cell><cell>*</cell></row><row><cell cols="2">2 Simple translation(m-mode) 0.2722</cell><cell>52.85%</cell></row><row><cell cols="2">3 Simple translation(u-mode) 0.3041</cell><cell>59.05%</cell></row><row><cell>4 Best-sense translation</cell><cell>0.3762</cell><cell>73.05%</cell></row><row><cell>5 Improved translation</cell><cell>0.3883</cell><cell>75.55%</cell></row><row><cell>6 Machine translation</cell><cell>0.3891</cell><cell>75.40%</cell></row><row><cell>7 5 + 6</cell><cell>0.4400</cell><cell>85.44%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,70.23,190.32,220.23,211.51"><head>Table 3 :</head><label>3</label><figDesc>Average retrieval precision of the expanded queries for Chinese IR.</figDesc><table coords="8,70.23,190.32,220.23,211.51"><row><cell>-</cell><cell>1-stage -</cell><cell cols="2">2-stage -</cell><cell>1-stage:</cell><cell>2-stage:</cell></row><row><cell>doc</cell><cell>weighting</cell><cell cols="2">weighting</cell><cell>Avg.P.</cell><cell>Avg.P.</cell></row><row><cell>No</cell><cell>ltc</cell><cell>Ltc</cell><cell></cell><cell>0.429</cell><cell>0.476</cell></row><row><cell>Yes</cell><cell>ltc</cell><cell>Ltc</cell><cell></cell><cell>0.435</cell><cell>0.485</cell></row><row><cell>Yes</cell><cell>ltu</cell><cell>Ltu</cell><cell></cell><cell>0.461</cell><cell>0.489</cell></row><row><cell>Yes</cell><cell>ltu</cell><cell>Ltc</cell><cell></cell><cell>0.461</cell><cell>0.515</cell></row><row><cell></cell><cell>Method</cell><cell></cell><cell>Avg.P.</cell><cell cols="2">% 1-stage</cell></row><row><cell></cell><cell>1-stage retrieval</cell><cell></cell><cell>0.3249</cell><cell>*</cell></row><row><cell></cell><cell cols="3">1+Post-translationQE 0.4280</cell><cell>31.7%</cell></row><row><cell></cell><cell cols="2">2+Pre-translation QE</cell><cell>0.4400</cell><cell>35.4%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,76.47,410.63,208.71,19.88"><head>Table 4 :</head><label>4</label><figDesc>Average retrieval precision of the expanded queries.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,306.97,258.00,226.05,169.15"><head>Table 5 :</head><label>5</label><figDesc>documents in the TREC 9 Chinese collection are articles published in Hong Kong Commercial Daily, Hong Kong Daily News, and Takungpao. Some statistical data are shown in table5. A set of 25 English queries (with translated Chinese queries) has been set up and evaluated by people in the NIST. TREC 9 data.</figDesc><table coords="8,306.97,348.35,224.24,61.28"><row><cell>Source</cell><cell>Dates</cell><cell>Size</cell></row><row><cell cols="2">Hong Kong Commercial Daily 8/98-7/99</cell><cell>~100MB</cell></row><row><cell>Hong Kong Daily News</cell><cell>2/99-7/99</cell><cell>~80MB</cell></row><row><cell>Takungpao</cell><cell>9/98-9/99</cell><cell>~80MB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,136.59,555.69,396.43,153.67"><head>Table 6 :</head><label>6</label><figDesc>Average precision of the submitted runs</figDesc><table coords="8,495.12,555.69,37.90,8.72"><row><cell>. No pre-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="7,317.41,708.60,210.52,7.88;7,312.26,718.68,211.70,7.88;7,312.26,728.76,81.98,7.88"><p>The idea of sub-document and its implementation details are introduced by Prof. K.L. Kwok during his one-month visit at MSRCN in June, 2000.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement.</head><p>The authors would like to thank <rs type="person">Prof. K.L. Kwok</rs> for his helpful suggestions, and <rs type="person">Aitao Chen</rs> for his comments on the paper.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,316.02,299.51,217.16,8.72;10,321.01,310.79,212.06,8.72;10,321.01,321.95,89.80,8.72;10,410.77,319.83,4.39,5.68;10,419.05,321.95,113.91,8.72;10,321.01,333.23,212.17,8.72;10,321.01,344.27,110.89,8.72" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,321.01,310.79,196.42,8.72">Resolving ambiguity for cross-language retrieval</title>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,321.01,321.95,89.80,8.72;10,410.77,319.83,4.39,5.68;10,419.05,321.95,113.91,8.72;10,321.01,333.23,208.35,8.72">Proceedings of the 21 st International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21 st International Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,312.25,361.31,220.80,8.72;10,321.01,372.59,211.98,8.72;10,321.01,383.75,211.93,8.72;10,321.01,394.79,212.05,8.72;10,321.01,406.07,58.96,8.72" xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">F</forename><surname>Brown ; Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">J</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,517.89,372.59,15.10,8.72;10,321.01,383.75,211.93,8.72;10,321.01,394.79,208.28,8.72">The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,312.25,423.11,220.88,8.72;10,321.01,434.26,214.44,8.72;10,321.01,445.42,137.41,8.72" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,440.52,423.11,92.61,8.72;10,321.01,434.26,141.51,8.72">Implementation of the SMART information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley ; Buckley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985. 1985</date>
			<biblScope unit="page" from="85" to="686" />
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="10,312.26,462.46,220.82,8.72;10,321.01,473.62,211.94,8.72;10,321.01,484.90,93.88,8.72;10,414.85,482.77,4.39,5.68;10,424.57,484.90,108.45,8.72;10,321.01,495.94,212.04,8.72;10,321.01,507.22,60.98,8.72" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,457.32,462.46,75.76,8.72;10,321.01,473.62,193.83,8.72">Aligning sentences in bilingual corpora using lexical information</title>
		<author>
			<persName coords=""><forename type="first">Stanley</forename><forename type="middle">F</forename><surname>Chen ; Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,321.01,484.90,93.88,8.72;10,414.85,482.77,4.39,5.68;10,424.57,484.90,108.45,8.72;10,321.01,495.94,180.09,8.72">Proceedings of the 31 st Annual Conference of the Association for Computational Linguistics</title>
		<meeting>the 31 st Annual Conference of the Association for Computational Linguistics<address><addrLine>Columbus, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,316.63,524.26,216.33,8.72;10,321.01,535.42,211.95,8.72;10,321.01,546.57,211.93,8.72;10,321.01,557.73,54.14,8.72" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="10,436.07,535.42,96.89,8.72;10,321.01,546.57,169.43,8.72">A Unified Approach to Statistical Language Modeling for Chinese</title>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Han-Feng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingjing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai-Fu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000. 2000. 2000</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,316.89,574.77,216.04,8.72;10,321.01,586.05,211.95,8.72;10,321.01,597.09,212.04,8.72" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman ; Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<idno>NIST SP 500-238</idno>
		<title level="m" coord="10,348.01,586.05,184.95,8.72;10,321.01,597.09,127.13,8.72">Information Technology: The Fifth Text REtrieval Conference (TREC-5)</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,321.01,608.37,211.95,8.72;10,321.01,619.53,73.33,8.72" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Gaithersburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,312.25,636.57,220.88,8.72;10,321.01,647.73,211.82,8.72;10,321.01,658.89,89.78,8.72;10,410.77,656.88,4.39,5.68;10,419.05,658.88,113.91,8.72;10,321.01,670.16,212.17,8.72;10,321.01,681.32,21.98,8.72" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,437.98,636.57,95.15,8.72;10,321.01,647.73,196.00,8.72">English-Chinese crosslanguage retrieval based on a translation package</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kowk</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kowk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,321.01,658.89,89.78,8.72;10,410.77,656.88,4.39,5.68;10,419.05,658.88,113.91,8.72;10,321.01,670.16,208.35,8.72">Proceedings of the 22 st International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22 st International Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,317.18,698.24,215.78,8.72;10,321.01,709.52,211.95,8.72;11,79.23,122.29,212.15,8.72;11,79.23,133.45,117.25,8.72" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,426.59,698.24,106.36,8.72;10,321.01,709.52,138.95,8.72">Comparing representations in Chinese information retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok ; Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,470.88,709.52,62.08,8.72;11,79.23,122.29,212.15,8.72;11,79.23,133.45,45.27,8.72">Conference on Research and Development in Information Retrieval, ACM-SIGIR</title>
		<imprint>
			<date type="published" when="1997">1997. 1997</date>
			<biblScope unit="page" from="34" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.47,150.37,220.80,8.72;11,79.23,161.65,212.07,8.72;11,79.23,172.81,211.95,8.72;11,79.23,184.08,212.07,8.72;11,79.23,195.12,185.67,8.72" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,197.54,161.65,93.76,8.72;11,79.23,172.81,211.95,8.72;11,79.23,184.08,44.35,8.72">Aligning sentences in parallel corpora using self-extracted lexical information</title>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shenghuo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Changning</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,135.87,184.08,155.43,8.72;11,79.23,195.12,33.09,8.72">Chinese Journal of Computers (in Chinese)</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="151" to="158" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
	<note>Supplement</note>
</biblStruct>

<biblStruct coords="11,70.47,212.16,220.99,8.72;11,79.23,223.44,212.07,8.72;11,79.23,234.60,193.68,8.72" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie ; Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ren</surname></persName>
		</author>
		<title level="m" coord="11,208.73,212.16,82.73,8.72;11,79.23,223.44,212.07,8.72;11,79.23,234.60,111.79,8.72">Chinese information retrieval: using characters or words? Information Processing and Management</title>
		<imprint>
			<date type="published" when="1999">1999. 1999</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="443" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.47,251.52,220.72,8.72;11,79.23,262.80,212.16,8.72;11,79.23,273.96,212.06,8.72;11,79.23,285.24,212.07,8.72;11,79.23,296.28,211.92,8.72;11,79.23,307.44,132.49,8.72" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,145.84,262.80,145.56,8.72;11,79.23,273.96,132.98,8.72">On the use of words and n-grams for Chinese information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Nie ; Jian-Yun Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,248.18,273.96,43.12,8.72;11,79.23,285.24,212.07,8.72;11,79.23,296.28,135.23,8.72">the Fifth International Workshop on Information Retrieval with Asian Languages, IRAL-2000</title>
		<meeting><address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09-30">2000. September 30 to October 1, 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.47,324.59,220.80,8.72;11,79.23,335.75,212.04,8.72;11,79.23,346.79,164.77,8.72" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,79.23,335.75,208.55,8.72">Introduction to modern information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983. 1983</date>
			<publisher>McGraw Hill Book Co</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.47,363.95,220.58,8.72;11,79.23,375.11,30.35,8.72;11,125.91,375.11,24.02,8.72;11,166.22,375.11,29.68,8.72;11,212.30,375.11,38.21,8.72;11,266.89,375.11,24.41,8.72;11,79.23,386.27,211.95,8.72;11,79.23,397.43,212.11,8.72;11,79.23,408.59,212.04,8.72;11,79.23,419.86,57.02,8.72" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,166.22,375.11,29.68,8.72;11,212.30,375.11,38.21,8.72;11,266.89,375.11,24.41,8.72;11,79.23,386.27,52.61,8.72">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,155.55,386.27,135.64,8.72;11,79.23,397.43,212.11,8.72;11,79.23,408.59,179.16,8.72">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,70.47,436.90,220.80,8.72;11,79.23,447.94,212.06,8.72;11,79.23,459.22,212.12,8.72;11,79.23,470.38,212.04,8.72;11,79.23,481.66,116.53,8.72" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,79.23,447.94,212.06,8.72;11,79.23,459.22,186.36,8.72">Extraction of Chinese compound words -an experimental study on a very large corpus</title>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,276.25,459.22,15.10,8.72;11,79.23,470.38,207.26,8.72">The second Chinese Language Processing Workshop</title>
		<meeting><address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-10-08">2000. October 8, 2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
