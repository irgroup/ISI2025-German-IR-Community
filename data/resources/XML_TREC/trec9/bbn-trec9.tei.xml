<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.86,76.56,274.32,14.36">TREC-9 Cross-lingual Retrieval at BBN</title>
				<funder ref="#_8UgPXyq">
					<orgName type="full">Defense Advanced Research Projects Agency</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,216.74,100.44,48.18,12.64"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">BBN</orgName>
								<address>
									<addrLine>Technologies 70 Fawcett Street Cambridge</addrLine>
									<postCode>02021</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,292.33,100.44,102.78,12.64"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">BBN</orgName>
								<address>
									<addrLine>Technologies 70 Fawcett Street Cambridge</addrLine>
									<postCode>02021</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.86,76.56,274.32,14.36">TREC-9 Cross-lingual Retrieval at BBN</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6863EF2D4696B08F654A49ABEF692BF2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BBN participated only in the cross-language track at TREC-9. We extended the monolingual approach of <ref type="bibr" coords="1,84.02,234.00,82.63,9.94" target="#b0">Miller et al. (1999)</ref>, which uses hidden Markov models (HMM), by incorporating translation probabilities from Chinese terms to English terms. We will describe our approach in detail in the next section. This report will explore the following issues:</p><p>1. Whether our HMM-based retrieval model is a viable approach to cross-lingual IR. This is answered by its retrieval performance relative to monolingual retrieval performance.</p><p>2. The relative contribution of bilingual lexicons and parallel corpora.</p><p>3. The impact of query expansion on cross-lingual performance. We will use two types of query expansion: using English terms and Chinese terms.</p><p>4. The impact of query length on retrieval performance. We will use three versions of queries: short, which consist of only the title fields, medium, which consist of title and description fields and long, which consist of title, description and narrative fields of the TREC topics.</p><p>5. Whether indexing English words in Chinese documents helps cross-lingual IR. Even though the documents in the corpus are in Chinese, many of them also contain some English words. English words in the documents can directly match the query words.</p><p>6. Dialect issues. The Chinese language has many dialects. Cantonese, which is used by the TREC-9 corpus, is one example. Since we had lexical resources for Mandarin (standard Chinese) and for Cantonese, we could measure the impact of dialects on cross-lingual IR.</p><p>This report includes official results for our submitted runs and results for experimental runs that are designed to help us explore the issues above.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Hidden Markov Retrieval System for Cross-lingual IR</head><p>In our approach, the IR system ranks documents by the probability that a Chinese document D is relevant given an English query Q, P(D is Rel |Q). Using Bayes Rule, and the fact that P(Q) is constant for a given query, and our initial assumption of a uniform a priori probability that a document is relevant, ranking documents according to P(Q|D is Rel) is the same as ranking them according to P(D is Rel|Q). The approach therefore estimates the probability that a query Q is generated, given the document D is relevant. A two state Hidden Markov model approximates the query generation process given a document. One state is General English, denoted by GE, in which a term e is selected from the English vocabulary. General English words do not describe the content of the document. They are chosen simply because the user is creating a natural language query in English. The other state is the document state D in which a Chinese term c from the document is selected and translated to an English word e.</p><p>After a query is generated from a state, the HMM either stays at the current state or transits to the other state to generate the next query term. The process continues until all query terms are produced.</p><p>The following parameters specify the model:</p><p>1. General English word probabilities P(e|GE), estimated by P(e|GE) = frequency of e in English corpus/size of English corpus.</p><p>Here e is an English word. English news articles in TREC disks 1-5 are used as an English corpus for this purpose.</p><p>2. Chinese word probabilities from the document D, P(c|D), estimated by</p><formula xml:id="formula_0" coords="2,220.70,214.56,170.69,9.94">P(c|D) = frequency of c in D/size of D</formula><p>Here c is a Chinese word.</p><p>3. Translation probabilities from Chinese words to English words, P(e|c). We assume that translation probabilities are independent of the document. This is not true, but reduces the number of parameters. We used simple translation probabilities from a bilingual lexicon and more sophisticated estimates from parallel texts.</p><p>4. Transition probabilities from one state to the other. We assume</p><formula xml:id="formula_1" coords="2,234.38,329.28,143.28,28.90">P(GE-&gt;D) = P(D-&gt;D) = a and P(D-&gt;GE) = P(GE-&gt;GE) = 1-a.</formula><p>Further we assume a is independent of the document. Using TREC-5/6 queries (Chinese track) as training, we chose a=0.3.</p><p>Note we did not use the standard EM (Expectation-Maximization) procedure for parameter estimation, since using EM would require many training queries for each document.</p><p>In this model, we estimate the probability of a query given a document as Our monolingual retrieval approach is the one proposed by <ref type="bibr" coords="2,335.66,534.00,79.87,9.94" target="#b0">Miller et al (1999)</ref>. It ranks documents according to:</p><formula xml:id="formula_2" coords="2,204.62,444.98,228.04,28.36">) ) | ( ) 1 ( ) | ( ( ) | ( ∏ - + = Q in e D e P a GE</formula><formula xml:id="formula_3" coords="2,189.62,560.90,232.88,28.36">∏ - + = Q in c D c P a GC c aP rel is D Q P )) | ( ) 1 ( ) | ( ( ) | (</formula><p>where P(c|GC) is general Chinese probability for word c, which was estimated from the TREC-9 Chinese corpus itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Lexical Resources</head><p>Two manually created bilingual lexicons were used in our experiments:</p><p>• one dealing with the Mandarin dialect from the Linguistic Data Consortium (LDC) and</p><p>• the CETA lexicon also dealing primarily with Mandarin.</p><p>In addition, two parallel corpora were used to generate bilingual lexicons. The parallel corpora are the Hong Kong SAR news (HKNews) and Hong Kong SAR laws (HKLaws), both from LDC. HKNews has around 18,000 pairs of documents in English and Chinese and has 6.3 million English words. HKLaws has 310,000 pairs of sentences in English and Chinese, with 6.6 million English words.</p><p>The following steps were taken to use each bilingual lexicon (whether manually generated or automatically derived from parallel copora):</p><p>1. Stem Chinese words via a simple algorithm to remove common Chinese suffixes and prefixes (such as "DE" and "BEI").</p><p>2. Use the Porter stemmer to stem the English words <ref type="bibr" coords="3,314.18,196.56,60.16,9.94" target="#b4">(Porter, 1980)</ref>.</p><p>3. Split English phrases into words. If an English phrase is a translation for a Chinese word, each word in the phrase is taken as a separate translation for the Chinese word<ref type="foot" coords="3,387.86,226.23,3.48,6.26" target="#foot_0">1</ref> .</p><p>4. Estimate translation probabilities.</p><p>The resulting lexicons consist of a number of English-Chinese word pairs together with translation probabilities.</p><p>For those experiments where no parallel corpus was employed, we assumed a uniform distribution on a word's translations. If a Chinese word c has n translations e 1 , e 2, …e n, each of them will be assigned equal probability, i.e., P(e i |c)=1/n.</p><p>For those experiments where a parallel corpus was employed, we used WEAVER to automatically extract additional translation pairs from the parallel corpora to improve the bilingual lexicons. WEAVER is a statistical machine translation toolkit developed by John Lafferty at Carnegie Mellon University. It has a component to automatically derive word translations based on sentence-aligned parallel text. The Chinese texts in the corpora were segmented by BBN's IdentiFinder TM , an information extraction system with a built-in segementor. Since the HKNews corpus in its original form was only aligned at the document level, we developed a sentence alignment algorithm to align it at the sentence level. Our algorithm works by performing an initial alignment using a (potentially small) initial bilingual lexicon (the LDC lexicon). A bilingual lexicon was induced from the initial alignment using WEAVER.</p><p>The induced lexicon supplements the initial lexicon in producing a better alignment, which in turn results in a better lexicon. The process eventually converges and outputs a list of term translations with translation probabilities.</p><p>The translations obtained by WEAVER are statistical in nature. In theory, any Chinese term can be translated to any English term with some probability; for the vast majority of word pairs, the probability approaches 0. For each Chinese term, we output up to 20 English terms and discard the rest, in order to keep the size of the lexicon manageable and to save retrieval time. Table <ref type="table" coords="3,398.90,543.61,5.52,9.94" target="#tab_1">1</ref> shows some statistics about the lexicons used in our experiments.</p><p>The lexicon used for our submitted runs is labeled "ALL" in Table <ref type="table" coords="3,369.62,575.53,4.14,9.94" target="#tab_1">1</ref>. It is a combination of all lexical resources described before, LDC, CETA, HKNews and HKLaws. The sets of English-Chinese word pairs in the individual lexicons were unioned and the translation probabilities linearly combined, with coefficients 0.2, 0.4, 0.3 and 0.1 for LDC, CETA, HKNews and HKLaws respectively. The weights were chosen to reflect the value of each lexical source based on the training queries (TREC-5/6 Chinese). To utilize English words in the documents for cross-lingual retrieval, we include an English word as a translation of itself with probability 1 and add such "translations" to our lexicons. (Such translations are not included in the statistics in Table <ref type="table" coords="4,238.22,87.84,4.00,9.94" target="#tab_1">1</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Indexing</head><p>One problem in indexing Chinese is segmenting the text, since Chinese has no spaces between words. Instead of using a Chinese segmentor, we used a sub-string match algorithm to extract words from a string of Chinese characters. The algorithm examines any sub-string of length 2 or greater and treats it as a Chinese word if it is in our bilingual lexicons. In addition, any single character that is not part of any of the recognized Chinese words in the first step is also treated as a Chinese word. Note that this algorithm can extract a compound Chinese word as well as its components. For example, the Chinese word "LiZhiWuLi" ("particle physics") as well as the Chinese words "LiZhi" ("particle") and "WuLi" ("physics") will be extracted. This seems desirable because it ensures the retrieval algorithm will match both the compound words as well as their components. The reason for using substring match instead of a more sophisticated segmentor is to improve the chance of mapping words in the Chinese document to an English term via the bilingual lexicons. A segmentor may mis-segment (e.g., a segmentation unit may cover the ending of one word and the beginning of another word). It may over-segment (e.g., producing a compound word while the lexicon only defines the components). It may also under-segment (e.g., producing individual words not defined by the lexicon). Substring matching may result in spurious matches, but we believe it is a less serious problem than being unable to map from Chinese to English due to segmentation errors. Of course, Chinese stop words are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Query Processing and Query Expansion Issues</head><p>Our first step in query processing is to remove stop words from the queries. These include functional words such as "of" and "the" as well as red herrings in TREC topics such as "relevant" and "document".</p><p>Our query expansion procedure works as follows:</p><p>1. For each query, retrieve 10 top ranked documents by an initial retrieval 2. Choose 50 expansion terms from the top ranked document. First, terms that only occur in one top ranked document were discarded. Then expansion terms were ranked by their average tfidf weight in the top ranked documents. The tfidf formula is the one reported in the UMass TREC6 report <ref type="bibr" coords="4,503.06,591.24,28.32,9.94;4,90.02,604.20,48.16,9.94" target="#b1">(Allan et al, 1998)</ref>. The top 50 terms were added to the query. The expansion terms, as well as the original query terms were "weighted" by the formula</p><formula xml:id="formula_4" coords="4,97.94,630.98,207.04,28.89">∑ &lt;= &lt;= + = 10 1 ) , ( 10 / 4 ) , ( ) , ( i i old d t tfidf Q t wt Q t wt</formula><p>Q is a query, wt old (t, Q) is the weight of term t in the original query; tfidf(t, d) is the tfidf value of t in document d; and d i 's are the retrieved documents. We interpret the "weight" of a query term in the context of our HMM retrieval approach to be the frequency with which the term is generated by the user. Therefore, the weight was used as an exponent in the retrieval function.</p><p>We submitted one monolingual run and three cross-lingual runs:</p><p>• BBN9MONO: a monolingual run with automatic query expansion. Final queries consist of the original Chinese queries and 50 expansion terms, using the query expansion procedure above.</p><p>• BBN9XLC: Cross-lingual without query expansion.</p><p>• BBN9XLB: Cross-lingual run with automatic Chinese query expansion. An initial cross-lingual retrieval was performed using the original English queries. Final queries consist of the original English queries and 50 Chinese expansion terms.</p><p>• BBN9XLA: Cross-lingual run with English query expansion and Chinese expansion. English terms were selected from top documents retrieved from an English corpus. Then the expanded English queries were run against the Chinese corpus to get 50 Chinese expansion terms. Final queries consist of the original English queries, 50 English expansion terms and 50 Chinese expansion terms.</p><p>The English corpus used for query expansion consists of news articles from TREC disks 1-5 (AP, WSJ, SJMN, FT, L. A. TIMES and FBIS) and 400,000 recent articles collected by FBIS in years 1999 and 2000.</p><p>Note queries in BBN9XLA and BBN9XLB contain both English terms and Chinese terms. To score a document against a query, two HMM scores were computed, one for the English query terms using the cross-lingual retrieval function, the other for the Chinese terms using the monolingual retrieval function. The two scores were multiplied to produce the final score for the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Official Retrieval Results</head><p>Table <ref type="table" coords="5,100.10,422.76,5.52,9.94" target="#tab_2">2</ref> shows the average precision for our submitted runs. What is striking is that all our cross-lingual runs have a higher score than our monolingual run. The results demonstrate that query expansion (BBN9XLA and BBN9XLB) improves retrieval performance, consistent with previous studies <ref type="bibr" coords="5,72.02,461.64,127.24,9.94" target="#b3">(Ballesteros and Croft, 1997)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Impact of query length and query expansion</head><p>Table <ref type="table" coords="5,100.09,585.96,5.52,9.94" target="#tab_4">3</ref> shows the impact of query expansion on cross-lingual retrieval performance. We show three versions of queries, short, medium and long. Short queries only use the words in the title field of the topics. Medium queries use title and description fields. Long queries use title, description and narrative. Query expansion improves performance for all query lengths. As expected, query expansion is more useful for short queries, and less useful for long queries. Three things are worth mentioning about the results. First, query expansion seems to neutralize the effect of query length. Without query expansion, the difference between short and long queries is 0.0669. After query expansion, it is reduced to 0.017. Second, English query expansion adds more than Chinese; apparently the benefit of a far larger corpus outweighs translation ambiguity. Third, while English expansion and Chinese expansion both improve retrieval performance, their combination does not improve performance further, except on the short queries. In fact, it is worse than either English expansion or Chinese Expansion alone for the medium queries. However, a query by query analysis shows that the surprising result is due to a statistical outlier in the retrieval results. The retrieval performance for topic 62 is 1.000 using English expansion and 0.3333 using both English and Chinese expansion. That query alone causes a difference of 0.0267 in average retrieval performance. Furthermore, topic 62 has only one relevant document; A small perturbation in the ranked output can cause a big change in retrieval performance. Under these circumstances, we cannot rule out the retrieval advantage of using both English and Chinese query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No Expansion</head><p>Only   <ref type="table" coords="6,100.10,318.84,5.52,9.94" target="#tab_6">4</ref> shows the impact of query expansion on monolingual retrieval performance. As in cross-lingual retrieval, query expansion improves retrieval performance, but the amount of improvement is smaller.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No Expansion Expansion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Impact of lexical sources on retrieval performance</head><p>The lexicon we used in our official runs is a combination of 4 lexical sources. Table <ref type="table" coords="6,449.90,464.52,5.52,9.94" target="#tab_8">5</ref> shows the contribution of each lexical source independently by reporting average precision without query expansion. The results show that the lexicon derived from the parallel corpus HKNews is the single most useful lexical resource; second is CETA, then LDC and last HKLaws. Each of these sources alone is significantly worse than the combined lexicon.</p><p>The experiment shows that different lexical sources can complement each other nicely. For our HMMbased approach, the results also show that the issue of lexicon completeness overrides that of translation ambiguity. On average, the combined lexicon has more than 1,000  Another way to determine the value of a lexical source is to measure how much it contributes to the combined lexicon by removing the source from the combined lexicon and showing the impact on retrieval performance. The remaining sources were given equal weight. Table <ref type="table" coords="7,423.74,100.80,5.52,9.94" target="#tab_10">6</ref> shows that the most useful source is HKNews and the least useful HKLaws. In fact, removing HKLaws from the lexicon improves retrieval performance slightly. We think the reason is the domain mismatch between HKLaws and the TREC-9 Chinese corpus of news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Comparing with TREC5 and TREC6 Queries</head><p>Although the TREC-5/6 Chinese corpus and TREC-9 corpus are both in Chinese, the former is in standard Chinese (Mandarin) and the latter in Cantonese. There are many differences in vocabulary between the two. As a result, using a bilingual lexicon for one dialect is sub-optimal for retrieval on a corpus in the other dialect. This effect can be seen when we compare retrieval performance using TREC-5/6 queries with TREC-9, as in Table <ref type="table" coords="7,240.38,239.40,4.14,9.94" target="#tab_11">7</ref>. The LDC and CETA lexicons are better lexical resources than HKNews for TREC-5/6 but the opposite is true for TREC-9, probably because of the difference between the vocabularies in Mandarin and Cantonese. Had we had a bilingual lexicon for Cantonese, better retrieval results on TREC-9 may have been possible.   9 Utilizing English words in Chinese documents</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ALL but LDC</head><p>Some Chinese documents in the TREC-9 corpus contain both English words and Chinese words. The English words are very useful for retrieval, for two reasons. First, they provide additional information about the content of the documents. Second, they can be utilized directly without translation, which invariably introduces errors. Such words were used in our submitted cross-lingual runs in the hope of improving retrieval. If we turned off this feature, the retrieval performance for BBN9XLC would be 0.3077 instead of 0.3099. Even though the difference is very small, we still think it is a desirable feature that can make a difference in a retrieval environment where such documents are common.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Monolingual Retrieval using Bigrams and Unigrams</head><p>Our official cross-lingual results are significantly better than our monolingual results. This anomalous result can be partly explained by the use of word-based indexing. As we discussed earlier, a word-based index is geared toward maximizing cross-lingual performance. For monolingual retrieval in Chinese, previous studies <ref type="bibr" coords="7,146.42,656.52,61.88,9.94" target="#b2">(Kwok, 1997)</ref> suggested that the best strategy may be to use bigrams. For comparison, we indexed the TREC-9 corpus using bigrams of Chinese characters and unigrams. Assuming a Chinese document is a sequence of Chinese characters, at each character position, we treat the bigram (current and the next characters) as a token. In addition, we also treat each character as a token. The resulting document is a bag of bigrams and unigrams. Stop words were discarded in the process. In a similar way, we processed the Chinese queries. Table <ref type="table" coords="8,257.18,74.88,5.52,9.94" target="#tab_12">8</ref> shows the monolingual results using bigrams and unigrams, together with our submitted results. Using bigrams and unigrams results in a huge improvement in monolingual performance. The results are also better than cross-lingual performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bigrams. No Expansion</head><p>Bigrams Our work was based on a previously reported HMM for retrieval <ref type="bibr" coords="8,361.46,222.84,85.50,9.94" target="#b0">(Miller et al., 1999)</ref>; we extended that model from monolingual to cross-lingual retrieval. Several conclusions are suggested by the experiment:</p><p>1. As expected, query expansion improved short queries more than long queries. For this set of queries, it is interesting that the query expansion reduced the gap in (cross-lingual) performance between short and long queries from 25% relative without expansion to only 5% relative.</p><p>2. Quite surprisingly, with word-based indexing, all our cross-lingual runs were better than monolingual; the best cross-lingual run was 118% of monolingual. If we had used bigram indexing for monolingual performance, the best cross-lingual (word-based indexing) would have been 90% of the best monolingual (bigram based indexing).</p><p>3. Not surprisingly, the best bilingual resource was the one closest in dialect (Cantonese) and genre (news) to the document collection, even though it was automatically derived from a parallel corpus and highly ambiguous.</p><p>4. For our probabilistic model, coverage of the bilingual lexicon seems far more important than the degree of ambiguity in the lexicon.</p><p>5. Query expansion in English proved more valuable than query expansion in Chinese, in spite of the added ambiguity, perhaps because the English corpus for unsupervised relevance feedback was so much larger in English than for Chinese.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Avg precision</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,72.02,108.07,418.79,84.96"><head>Lexicon Name # of English terms # of Chinese terms # of translation pairs</head><label></label><figDesc></figDesc><table coords="4,89.42,122.71,374.76,70.32"><row><cell>LDC</cell><cell>86,000</cell><cell>137,000</cell><cell>240,000</cell></row><row><cell>CETA</cell><cell>35,000</cell><cell>202,000</cell><cell>517,000</cell></row><row><cell>HKNews</cell><cell>21,000</cell><cell>75,000</cell><cell>1,266,000</cell></row><row><cell>HKLaws</cell><cell>14,000</cell><cell>38,000</cell><cell>543,000</cell></row><row><cell>ALL</cell><cell>108,000</cell><cell>371,000</cell><cell>2,470,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,158.42,203.04,295.17,9.94"><head>Table 1 :</head><label>1</label><figDesc>Lexicon statistics. All = combination of all four sources</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,167.42,461.64,274.77,86.94"><head>Table 2 : Retrieval results of submitted runs</head><label>2</label><figDesc>.</figDesc><table coords="5,167.42,501.79,274.77,25.68"><row><cell cols="4">BBN9MONO BBN9XLA BBN9XLB BBN9XLC</cell></row><row><cell>0.2888</cell><cell>0.3401</cell><cell>0.3326</cell><cell>0.3099</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,72.02,303.12,409.78,25.66"><head>Table 3 : Impact of query expansion on crosslingual retrieval performance Table</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,150.62,417.24,310.66,9.94"><head>Table 4 : Impact of query expansion on monolingual performance</head><label>4</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,72.02,561.24,459.08,114.30"><head></head><label></label><figDesc>Chinese translations per English query term. Even though this large figure is partly due to a few outliers, it does indicate there is a lot of translation ambiguity. The results indicate this does not have a big negative effect on retrieval performance.</figDesc><table coords="6,106.22,620.11,393.48,55.44"><row><cell></cell><cell cols="4">LDC only CETA only HKNews only HKLaws only</cell><cell>ALL</cell></row><row><cell>Short</cell><cell>0.1491</cell><cell>0.1517</cell><cell>0.1875</cell><cell>0.1386</cell><cell>0.2430</cell></row><row><cell>Medium</cell><cell>0.1839</cell><cell>0.1944</cell><cell>0.2285</cell><cell>0.1395</cell><cell>0.2869</cell></row><row><cell>Long</cell><cell>0.1725</cell><cell>0.2126</cell><cell>0.2418</cell><cell>0.1441</cell><cell>0.3099</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="6,75.38,685.56,461.28,22.90"><head>Table 5 : Impact of lexical sources on average precision of retrieval</head><label>5</label><figDesc></figDesc><table /><note coords="6,387.59,685.56,149.06,9.94;6,282.14,698.52,47.64,9.94"><p>. These results are without query expansion.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="7,80.42,362.52,451.06,69.79"><head>Table 6 : Impact of removing a lexical source on average precision of retrieval.</head><label>6</label><figDesc></figDesc><table coords="7,456.86,362.52,74.62,9.94"><row><cell>These results are</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="7,201.02,442.08,209.88,9.94"><head>Table 7 : Comparing TREC-5/6 and TREC-9</head><label>7</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="8,72.02,120.79,449.00,96.20"><head>Table 8 : Using bigrams for monolingual retrieval 11 Conclusions</head><label>8</label><figDesc></figDesc><table coords="8,88.46,120.79,432.56,39.84"><row><cell></cell><cell>. Query</cell><cell cols="4">BBN9MONO BBN8XLA BBN9XLB BBN9XLC</cell></row><row><cell></cell><cell>Expansion</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.3362</cell><cell>0.3779</cell><cell>0.2888</cell><cell>0.3401</cell><cell>0.3326</cell><cell>0.3099</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="9,72.02,433.56,426.84,22.90"><head>Table 9 :</head><label>9</label><figDesc>Monolingual results. Words = Word-based index. Bigrams = index using bigrams and unigrams of Chinese characters.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="10,72.02,97.44,417.66,544.78"><head>Table 10</head><label>10</label><figDesc>summarizes cross-lingual results in this report.</figDesc><table coords="10,121.85,120.09,367.82,522.14"><row><cell>Name</cell><cell>Title</cell><cell>Desc</cell><cell>Narr</cell><cell>ChQE</cell><cell>EnQE</cell><cell>LDC</cell><cell>CETA</cell><cell>HK</cell><cell>News</cell><cell>HK</cell><cell>Laws</cell><cell>Avg</cell><cell>Precision</cell></row><row><cell>BBN9XLA</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3401</cell></row><row><cell>BBN9XLB</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3326</cell></row><row><cell>BBN9XLC</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3099</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2430</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2991</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2871</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3231</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2869</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3282</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3183</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3038</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3420</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.3326</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1491</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1517</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1875</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.1386</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2430</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1839</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1944</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.2285</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.1395</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2869</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1725</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.2126</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.2418</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.1441</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2400</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2298</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.1967</cell></row><row><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.2462</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2816</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2678</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2252</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.2950</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2924</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2802</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell cols="2">0.2506</cell></row><row><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.3100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" coords="10,72.02,651.96,467.11,48.82"><head>Table 10 :</head><label>10</label><figDesc>Crosslingual results. Title=the title field, Desc=the description field, Narr=the narrative field, ChQE=Chinese expansion terms, EnQE=English expansion terms, LDC= the LDC lexicon, CETA= the CETA lexicon, HKNews=lexicon extracted from HKNews, HKLaws=lexicon extracted from HKLaws. A "x" indicates a topic filed, a lexical resource, or a query expansion type is used.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,78.26,678.00,453.33,9.94;3,72.02,690.96,459.94,9.94;3,72.02,703.92,378.84,9.94"><p>This is incorrect, but greatly simplified implementation. The correct method would be to treat phrases in the lexicon and in the queries as single tokens. Research in monolingual IR demonstrated that phrase processing is prone to error and does not conclusively improve retrieval performance.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We wish to thank <rs type="person">John Lafferty</rs>, whose WEAVER software was used to derive bilingual lexicons from parallel corpora. We also would like to thank <rs type="person">Rich Schwartz</rs> for his advice.</p><p>The work reported here was supported in part by the <rs type="funder">Defense Advanced Research Projects Agency</rs> under contract number <rs type="grantNumber">N66001-00-C8008</rs>. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the <rs type="institution">Defense Advanced Research Projects Agency</rs> or the <rs type="institution">United States Government</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8UgPXyq">
					<idno type="grant-number">N66001-00-C8008</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,72.02,501.72,468.02,9.94;8,81.02,514.68,458.95,9.94;8,81.02,527.64,208.08,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,280.06,501.72,249.68,9.94">A Hidden Markov Model Information Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,81.02,514.68,458.95,9.94;8,81.02,527.64,106.18,9.94">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1999">1999. 1999</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.02,543.60,453.58,9.94;8,72.02,556.56,172.68,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,421.70,543.60,103.90,9.94;8,72.02,556.56,59.21,9.94">INQUERY Does Battle With TREC-6</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.46,556.56,88.40,9.94">TREC6 Proceedings</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.02,575.52,445.78,9.94;8,72.02,588.48,442.56,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,157.82,575.52,269.87,9.94">Comparing Representations in Chinese Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,434.78,575.52,83.02,9.94;8,72.02,588.48,438.22,9.94">Proceedings of the 20th ACM SIGIR International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 20th ACM SIGIR International Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.02,607.44,437.24,9.94;8,72.02,620.40,430.68,9.94;8,72.02,633.36,285.96,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,237.62,607.44,271.64,9.94;8,72.02,620.40,133.19,9.94">Phrasal translation and query expansion techniques for crosslanguage information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,211.94,620.40,290.76,9.94;8,72.02,633.36,230.50,9.94">Proceedings of the 20th ACM SIGIR International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 20th ACM SIGIR International Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="84" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.02,652.32,352.68,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,147.62,652.32,144.11,9.94">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,298.70,652.32,49.03,9.94">In Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
