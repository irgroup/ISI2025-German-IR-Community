<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,192.40,91.76,227.22,10.80">Sheffield Interactive Experiment at TREC-9</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,212.20,120.08,59.78,10.80"><forename type="first">M</forename><surname>Beaulieu</surname></persName>
							<email>m.beaulieu@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Studies</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.30,120.08,54.03,10.80"><forename type="first">H</forename><surname>Fowkes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Studies</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.71,120.08,40.05,10.80"><forename type="first">H</forename><surname>Joho</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Studies</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,192.40,91.76,227.22,10.80">Sheffield Interactive Experiment at TREC-9</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DFA9BF239D68B202C3FEF22673EFC0DA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper reports on the experiment conducted by the University of Sheffield in the Interactive Track of TREC-9 based on the Okapi probabilistic ranking system. A failure analysis of results was undertaken to correlate search outcomes with query characteristics. A detailed comparison of Sheffield results with the aggregate for the track reveals that the time element, topic type, and searcher characteristics and behaviour are interdependent success factors. An analysis of the ranking of documents retrieved by the Okapi system and deemed relevant by the assessors also revealed that more than 50% appeared in the top 10 and 80% in the top 30. However the searchers did not necessarily view these and over half of the items deemed relevant by the assessors and examined by the searchers were actually rejected.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The experiment for TREC-9 as in previous rounds in which Sheffield has participated was based on the Okapi system. Although the experimental design included two versions of the system, one with relevance feedback and one without, it was envisaged that the five minute time limit for searching each of the interactive queries for Trec-9 would offer little opportunity for searchers to use the feedback facility for query reformulation. Our aim was thus to focus on the characteristics of the two types of queries introduced for the TREC-9 interactive task and assess their relative impact on the performance of both the searchers and the system.</p><p>The graphical user interface of the Okapi systems remained exactly the same as in the last three rounds of TREC and includes:</p><p>• a query box • a working query window containing system generated candidate terms for query expansion • a scrollable window displaying a ranked list of the top fifty retrieved items • a window for collecting documents marked as relevant and saved by the searcher • a separate overlapping window for viewing items selected from the hitlist where searchers have to make a relevance judgement.</p><p>The standard questionnaires for the interactive track were used for data collection including: session entry, pre-search, post search, post-system and session exit. In addition transaction logs and talk aloud protocols provided system data and user perceptions in the course of the search. However subjects were not very forthcoming in talking aloud due to the time constraint imposed on them and consequently the protocols provided very limited insight.</p><p>Sixteen searchers participated in the experiment and fourteen were Masters students in the Information Studies Department. None had used the Okapi system before, although most had some knowledge of ranking systems either through their general use of search engines on the Web or through a course on information retrieval in their programme of study. Half had between two to three year's online experience, with searching the Web and library catalogues being the most common types of systems. The other half was deemed to be novice users with a year or less experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Results and query characteristics</head><p>The TREC-9 interactive task included two types of topics. For the first set 901-904, searchers had to find a given number of different answers to a question, e.g. three national parks, a Roman site in France, four Orson Welles films, and three countries importing Cuban sugar. In essence these topics were not dissimilar from those used in the Interactive Track for TREC-7 and TREC-8, where searchers had to find as many different instances or answers as possible. The main difference in TREC-9 was that searchers had only five minutes to complete the task as opposed to twenty minutes in the previous rounds.</p><p>The second set of queries 905-908 required a single correct answer between two possible choices, e.g. the longest running TV programme, the painting completed first, the last Chinese dynasty, the country with the larger population. In arriving at a correct answer searchers had to find appropriate supporting evidence in different documents and save those documents.</p><p>The results of the Sheffield respondents compared to the aggregate performance of the participants in the track are presented in Tables <ref type="table" coords="2,319.73,499.88,14.32,10.80" target="#tab_0">1a,</ref><ref type="table" coords="2,337.04,499.88,9.99,10.80" target="#tab_1">1b</ref>. The following will discuss these results in relation to the characteristics of each of the eight individual topics. 901: What are the names of the three US national parks where one can find redwoods?</p><p>Sheffield respondents performed poorly on this query compared to the aggregate with 13 out of 16 finding no correct answers and the remaining 3 providing only partial answers, one of which was unsupported. The nil answers, which were twice as high as the aggregate, appear to have been influenced by some ambiguity in differentiating the meaning between "national" and "state" parks. The question may have presented some cultural bias, as a high proportion of our searchers were international students with no previous knowledge of the topic as indicated in the pre-search questionnaire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>902: Identify a site with Roman ruins in present day France?</head><p>The Sheffield results are comparable to the rest of the track with a quarter successful answers and three quarters of searchers unable to find a correct answer. The polarised results may be due to the combination of evidence required to arrive at an answer, i.e. the name of the country, the specific location as well as the type of ruin. Furthermore only 7</p><p>documents were identified by the TREC assessors as providing an answer in the retrieved pool, a small number compared to other topics (See Table <ref type="table" coords="4,370.55,117.56,4.33,10.80" target="#tab_3">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>903: Name four films in which Orson Welles appeared</head><p>Once again our searchers produced comparable results with 13 out of 16 producing partial answers, but only half provided partial supporting evidence. This question was somewhat of a trick question in that most references referred to films directed by Welles and it would appear that there was some amount of guesswork in identifying films in which he was also an actor. The one Sheffield searcher, who got all the correct answers with supporting documents, had a special interest in film studies and was confident about the answer prior to searching the system. Three other searchers had also indicated preknowledge on this topic with a high degree of confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>904: Name three countries that imported Cuban sugar during the period of time covered by the document collection</head><p>Only one Sheffield searcher identified three countries compared with over a quarter of the aggregate. In addition twice as many Sheffield searchers did not succeed in finding any answers at all, 25% compared to 12%. This topic was also undertaken in TREC-8. The performance then was equally poor even though searchers had twenty minutes to search. It was found that although searchers were essentially looking for labels, i.e. names of countries, they had to engage with the content of the document to ensure that the correct context was covered. Although the time limit may have been a factor in TREC-9, it obviously doesn't account for the poorer performance compared to other participants in the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>905: Which children's TV program was on air longer: the original Mickey Mouse Club or the original Howdy/Doody show?</head><p>Comparable results were obtained with the overall track with half of the searchers choosing the correct answer with supporting evidence. However a third of all searchers in the track provided no answer at all. As in question 902 on Roman ruins in France, few relevant documents provided the answer (See Table <ref type="table" coords="4,341.08,570.68,4.32,10.80" target="#tab_3">3</ref>). In fact the searchers commonly saved two documents, one was deemed by the assessors to support the answer whereas the other didn't.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>906: Which painting did Edward Munch complete first: Vampire or Puberty?</head><p>Sheffield performed slightly better than the aggregate with 50% getting the right answer with the correct supporting documents and 25% not finding the answer. Surprisingly 25% provided the right answer with no correct supporting evidence. Since only three documents were judged to be relevant by the assessors (see Table <ref type="table" coords="5,406.59,75.08,4.32,10.80" target="#tab_3">3</ref>), it would appear that searchers were able to make correct deductions or an informed guess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>907: Which was the dynasty of China: Qing or Ming?</head><p>Sheffield searchers outperformed the aggregate on this query with all identifying the correct answer, although just under half did not back it up with correct documents. Five of our searchers indicated that they knew the answer before searching, which may in part account for this discrepancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>908: Is Denmark larger or smaller in population than Norway?</head><p>Just under a third of Sheffield searchers got the right answer but without supporting evidence compared with a quarter in the overall track who did provide correct supporting evidence. However in both cases around three quarters failed to find the answer all together. Again the high failure rate could have been related to the need to piece together different evidence over multiple documents in a short space of time.</p><p>Table <ref type="table" coords="5,120.31,344.12,6.00,10.80" target="#tab_2">2</ref> presents a summary of the adjusted score obtained for each answer which was correctly identified and supported by an appropriate document. The difference in the level of performance between the two different types of topics 901-904 and 905-908 are clearly demarcated and reflect the overall pattern of performance in the track. It may be that the time limit was a critical success factor whereby it was more difficult to find correct multiple answers in the first type of topic and easier to find single answers in the second type. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Searcher performance vs system performance</head><p>In an attempt to isolate user effect on system performance, the session logs were analysed to ascertain what proportion of relevant documents identified by the assessors were actually retrieved by the system. Table <ref type="table" coords="5,277.63,683.72,6.00,10.80" target="#tab_3">3</ref> compares the number of documents judged as relevant by the assessors for each topic and the average retrieved by the system in the initial ranked hitlist of the top 50 documents retrieved for all of the searches. It would appear that poor searcher performance reported in Table <ref type="table" coords="6,362.58,89.24,6.00,10.80" target="#tab_2">2</ref> for topics 901 and 908 are not really borne out it terms of the average number of actual relevant documents retrieved by the system in the retrieved sets of 50 documents displayed to the searcher. Three quarters or more unique assessed relevant documents are retrieved by the system in all but one topic (908) in the first iteration which provides some evidence of the system's high level of performance. Tables 4a, 4b compare the total number of assessed relevant documents examined by searchers for each of the topics with the number actually saved or deemed relevant by the searchers and those which were not deemed to be relevant. Overall 53% of documents deemed relevant by the assessors were examined but actually rejected by searchers. There were more documents rejected for type 1 topics than for type 2, 46% compared to 39%. Table <ref type="table" coords="7,120.32,342.32,6.00,10.80" target="#tab_6">5</ref> presents the ranking position of all the assessed relevant documents retrieved by the system but not necessarily viewed by the searchers. More than half appeared in the top 10 of the hitlist displayed to the searchers and 80% in the top 30. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion of success factors</head><p>Although more failure analysis can be carried out on the data, a number of interdependent success factors appear to contribute to the above results including: time, topic type, and searcher characteristics and behaviour. Firstly there appeared to be some degree of correlation between topic type and the amount of time available for searching. 28% of searchers indicated that they didn't have enough time to undertake type 1 topics and 14% deemed they had enough time. In the case of type 2 topics there was little difference between those who felt they had enough or not enough time, 20% as opposed to18%. Searchers' perceptions regarding the time available also related to their level of satisfaction with the search outcome. There appeared to be a higher degree of confidence in the outcome of type 2 topics.</p><p>The discrepancy between the overall track performance in the two types of topics is not easily reconciled with our findings in the analysis of the degree of complexity of the TREC-8 topics and searching behaviour <ref type="bibr" coords="8,285.33,287.48,12.73,10.80" target="#b0">(1)</ref>. In TREC-8 we found that in order to arrive at a relevance judgement, more complex topics required some interpretation on the part of the searcher and a higher degree of engagement with the contents of documents being examined. Less complex topics on the other hand were more easily understood at the outset and by enlarge relevant documents were identified by scanning for highlighted query terms in the documents. Hence it could be said that in general complex topics are likely to require more effort from the searcher than less complex ones. In the current round the differences in the level of engagement with the documents was not easily discernible in the time allowed for each search. However it would seem that the number of different answers required for type 1 topics was more demanding than the single answer required for type 2. The short time element may have been a more important success factor here than the complexity of the topic.</p><p>A third element, which contributed to the success/failure of the search outcomes, relates to the behaviour and the characteristics of the searchers themselves. Although type 2 topics required searchers to engage with the documents viewed to accumulate evidence for the correct answer, there was a substantial number of correct answers from Sheffield searchers which were not supported by appropriate documents 30% (Table <ref type="table" coords="8,450.94,528.20,9.48,10.80" target="#tab_1">1b</ref>). The reason could be two-fold: firstly informed guesses could be made on partial evidence and secondly it may have been difficult for searchers to ascertain which document provided the correct evidence. The number of assessed relevant documents, which were viewed and rejected by searchers, would support this element of uncertainty, i.e. the difficulty in identifying the correct evidence and knowing which documents to save. In comparing the system performance with regard to actual assessed relevant documents retrieved by the system and the actual search outcomes for the topics, it is clear that search outcomes are highly dependent on the searchers themselves. Searchers either fail to examine relevant documents, or disagree with the assessors' judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>Since the Interactive Track was first established, much effort has been put into defining an appropriate search task. Although there is evidence to show that a realistic and reliable experimental setting can be created through simulated tasks (2), the search task for the current round of the Interactive Track was not ideal. In particular whilst it may be a common and realistic scenario for a searcher to want to find an answer as quickly as possible, the five minute time constraint in an experimental setting had an adverse effect. The participants in the experiment not only had to find the correct answer(s) but also had to provide the correct evidence, i.e. identify the documents which provided the right answer. Providing the evidence proved to be difficult and led to second guessing. With hindsight it may have been better for searchers to have had more time to engage with the documents to avoid readily rejecting items which did in fact contain the supporting evidence.</p><p>In addition to highlighting the limitations of the task, the current experiment also demonstrated the importance of comparing both user and systems performance in interactive searching. Although it is recognised a ranked output may not be the best way of presenting results (3), little research has been carried out to date on how searchers handle and interpret ranked output.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.88,541.73,445.51,167.59"><head>Table 1a : Sheffield results compared to the aggregate for Type 1 topics, 901-904 Response / Topic number</head><label>1a</label><figDesc></figDesc><table coords="2,72.88,582.41,445.51,126.91"><row><cell>Some answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied, and all are</cell><cell>1</cell><cell>38</cell><cell>-</cell><cell>-</cell><cell>8</cell><cell>44</cell><cell>7</cell><cell>35</cell></row><row><cell>supported (1,2)</cell><cell>(6%)</cell><cell>(35%)</cell><cell></cell><cell></cell><cell>(50%)</cell><cell>(41%)</cell><cell>(44%)</cell><cell>(33%)</cell></row><row><cell>Some answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and some</cell><cell>1</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>3</cell><cell>23</cell><cell>2</cell><cell>14</cell></row><row><cell>supported (1,1)</cell><cell>(6%)</cell><cell>(2%)</cell><cell></cell><cell></cell><cell>(19%)</cell><cell>(22%)</cell><cell>(13%)</cell><cell>(13%)</cell></row><row><cell>Some answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and none are</cell><cell>1</cell><cell>6</cell><cell>-</cell><cell>-</cell><cell>3</cell><cell>27</cell><cell>1</cell><cell>8</cell></row><row><cell>supported (1,0)</cell><cell>(6%)</cell><cell>(6%)</cell><cell></cell><cell></cell><cell>(19%)</cell><cell>(25%)</cell><cell>(6%)</cell><cell>(8%)</cell></row><row><cell>No answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and none are</cell><cell>13</cell><cell>50</cell><cell>12</cell><cell>80</cell><cell>2</cell><cell>6</cell><cell>4</cell><cell>13</cell></row><row><cell>supported (0,0)</cell><cell>(82%)</cell><cell>(47%)</cell><cell>(75%)</cell><cell>(82%)</cell><cell>(12%)</cell><cell>(6%)</cell><cell>(25%)</cell><cell>(12%)</cell></row><row><cell>Total number of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>searchers</cell><cell>16</cell><cell>107</cell><cell>16</cell><cell>98</cell><cell>16</cell><cell>106</cell><cell>16</cell><cell>106</cell></row><row><cell></cell><cell>901</cell><cell></cell><cell>902</cell><cell></cell><cell>903</cell><cell></cell><cell>904</cell><cell></cell></row><row><cell>All answers are</cell><cell>Shef</cell><cell>Agg</cell><cell>Shef</cell><cell>Agg</cell><cell>Shef</cell><cell>Agg</cell><cell>Shef</cell><cell>Agg</cell></row><row><cell>supplied and supported</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2,2)</cell><cell>-</cell><cell>8</cell><cell>4</cell><cell>18</cell><cell>-</cell><cell>3</cell><cell>1(</cell><cell>29</cell></row><row><cell></cell><cell></cell><cell>(7%)</cell><cell>(25%)</cell><cell>(18%)</cell><cell></cell><cell>(3%)</cell><cell>6%)</cell><cell>(27%)</cell></row><row><cell>All answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and some</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>2</cell><cell>1</cell><cell>7</cell></row><row><cell>supported (2,1)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(2%)</cell><cell>(6%)</cell><cell>(7%)</cell></row><row><cell>All answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and none are</cell><cell></cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1</cell><cell></cell><cell></cell></row><row><cell>supported (2,0)</cell><cell>-</cell><cell>(3%)</cell><cell></cell><cell></cell><cell></cell><cell>(1%)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,72.88,264.53,445.51,214.51"><head>Table 1b : Sheffield results compared to the aggregate for type 2 topics 905-908.</head><label>1b</label><figDesc></figDesc><table coords="3,72.88,293.33,445.51,185.71"><row><cell>Response /</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Topic number</cell><cell>905</cell><cell></cell><cell>906</cell><cell></cell><cell>907</cell><cell></cell><cell>908</cell><cell></cell></row><row><cell>All answers are</cell><cell>Shef</cell><cell>Agg</cell><cell>Shef</cell><cell>Agg</cell><cell>Shef</cell><cell>Agg</cell><cell>Shef</cell><cell>Agg</cell></row><row><cell>supplied and supported</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2,2)</cell><cell>8</cell><cell>65</cell><cell>8</cell><cell>41</cell><cell>9</cell><cell>77</cell><cell>-</cell><cell>9</cell></row><row><cell></cell><cell>(50%)</cell><cell>(61%)</cell><cell>(50%)</cell><cell>(41%)</cell><cell>(56%)</cell><cell>(74%)</cell><cell></cell><cell>(25%)</cell></row><row><cell>All answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and none are</cell><cell>3</cell><cell>9</cell><cell>4</cell><cell>32</cell><cell>7</cell><cell>15</cell><cell>5</cell><cell>-</cell></row><row><cell>supported (2,0)</cell><cell>(19%)</cell><cell>(9%)</cell><cell>(25%)</cell><cell>(22%)</cell><cell>(44%)</cell><cell>(14%)</cell><cell>(31%)</cell><cell></cell></row><row><cell>No answers are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>supplied and none are</cell><cell>5</cell><cell>32</cell><cell>4</cell><cell>37</cell><cell>-</cell><cell>1 3</cell><cell>11</cell><cell>78</cell></row><row><cell>supported (0,0)</cell><cell>(31%)</cell><cell>(30%)</cell><cell>(25%)</cell><cell>(37%)</cell><cell></cell><cell>(12%)</cell><cell>(69%)</cell><cell>(75%)</cell></row><row><cell>Total number of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>searchers</cell><cell>16</cell><cell>106</cell><cell>16</cell><cell>100</cell><cell>16</cell><cell>105</cell><cell>16</cell><cell>101</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,81.88,459.05,434.90,119.97"><head>Table 2 : Sheffield adjusted score for correct supported answers for each topic out of the maximum obtainable score.</head><label>2</label><figDesc></figDesc><table coords="5,81.88,511.61,434.90,67.41"><row><cell>Topic no</cell><cell>901</cell><cell>902</cell><cell>903</cell><cell>904</cell><cell>905</cell><cell>906</cell><cell>907</cell><cell>908</cell></row><row><cell>Adjusted</cell><cell>3 out of</cell><cell>4 out of</cell><cell>19 out</cell><cell>23 out</cell><cell>8 out of</cell><cell>8 out of</cell><cell>9 out of</cell><cell>0 out of</cell></row><row><cell>score</cell><cell>48</cell><cell>16</cell><cell>of 64</cell><cell>of 48</cell><cell>16</cell><cell>16</cell><cell>16</cell><cell>16</cell></row><row><cell></cell><cell>(6%)</cell><cell>(25%)</cell><cell>(30%)</cell><cell>(48%)</cell><cell>(50%)</cell><cell>(50%)</cell><cell>(56%)</cell><cell>(0%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,90.04,185.45,289.61,265.29"><head>Table 3 Assessed relevant documents retrieved in the top 50.</head><label>3</label><figDesc></figDesc><table coords="6,90.04,208.85,261.25,241.89"><row><cell></cell><cell>Total number of</cell><cell>Average no of</cell></row><row><cell>Topic no</cell><cell>unique assessed</cell><cell>assessed relevant</cell></row><row><cell></cell><cell>relevant docs out of</cell><cell>docs retrieved</cell></row><row><cell></cell><cell>the possible</cell><cell></cell></row><row><cell></cell><cell>maximum</cell><cell></cell></row><row><cell>901</cell><cell>10/13 (77%)</cell><cell>5.6 (43%)</cell></row><row><cell>902</cell><cell>6/ 7 (86%)</cell><cell>1.87 (27%)</cell></row><row><cell>903</cell><cell>13/17 (76%)</cell><cell>5.6 (33%)</cell></row><row><cell>904</cell><cell>29/39 (74%)</cell><cell>11 (44%)</cell></row><row><cell>905</cell><cell>7/7 (100%)</cell><cell>3.2 (46%)</cell></row><row><cell>906</cell><cell>3/3 (100%)</cell><cell>2.4 (80%)</cell></row><row><cell>907</cell><cell>20/23 (87%)</cell><cell>7 (30%)</cell></row><row><cell>908</cell><cell>9/15 (60%)</cell><cell>2.6 (17%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,90.04,557.57,378.58,155.37"><head>Table 4a : Assessed relevant documents viewed and saved in the top 50, Type 1 Topics 901-904</head><label>4a</label><figDesc></figDesc><table coords="6,90.04,598.25,376.98,114.69"><row><cell>Total</cell><cell>70</cell><cell>38 (54%)</cell><cell>42 (46%)</cell></row><row><cell>Topic no</cell><cell>No of relevant docs</cell><cell>No of relevant</cell><cell>No of relevant docs</cell></row><row><cell></cell><cell>viewed</cell><cell>docs saved</cell><cell>not saved</cell></row><row><cell>901</cell><cell>29</cell><cell>13 (45%)</cell><cell>16 (55%)</cell></row><row><cell>902</cell><cell>12</cell><cell>4 (33%)</cell><cell>8 (67%)</cell></row><row><cell>903</cell><cell>15</cell><cell>11 (73%)</cell><cell>4 (27%)</cell></row><row><cell>904</cell><cell>24</cell><cell>10 (42%)</cell><cell>14 (58%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,90.04,122.69,376.40,199.29"><head>Table 4b : Assessed relevant documents viewed and saved in the top 50, Type 2 Topics 905-908</head><label>4b</label><figDesc></figDesc><table coords="7,90.04,158.69,365.98,163.29"><row><cell>Topic no</cell><cell>No of documents</cell><cell>No of documents</cell><cell>No of documents</cell></row><row><cell></cell><cell>viewed</cell><cell>saved</cell><cell>Not saved</cell></row><row><cell>905</cell><cell>25</cell><cell>14 (56%)</cell><cell>11 (44%)</cell></row><row><cell>906</cell><cell>18</cell><cell>9 (50%)</cell><cell>9 (50%)</cell></row><row><cell>907</cell><cell>9</cell><cell>8 (89%)</cell><cell>1 (11%)</cell></row><row><cell>908</cell><cell>2</cell><cell>2 (100%)</cell><cell>-</cell></row><row><cell>Total</cell><cell>54</cell><cell>33 (61%)</cell><cell>21 (39%)</cell></row><row><cell>Overall</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell>134</cell><cell>71 (47%)</cell><cell>63 (53%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,90.04,400.61,420.79,274.41"><head>Table 5 : Assessed relevant document ranking for all searches for each topic.</head><label>5</label><figDesc></figDesc><table coords="7,106.72,436.25,404.11,238.77"><row><cell>Topic</cell><cell>Top 10</cell><cell>Top 20</cell><cell>Top 30</cell><cell>Top 40</cell><cell>Top 50</cell></row><row><cell>901</cell><cell>55 (65%)</cell><cell>8 (9%)</cell><cell>3 (4%)</cell><cell>1 (1%)</cell><cell>18 (21%)</cell></row><row><cell>902</cell><cell>19 (76%)</cell><cell>4 (16%)</cell><cell>2 (8%)</cell><cell>-</cell><cell>-</cell></row><row><cell>903</cell><cell>37(44%)</cell><cell>15 (18%)</cell><cell>13 (15%)</cell><cell>10 (12%)</cell><cell>9 (11%)</cell></row><row><cell>904</cell><cell>53 (36%)</cell><cell>30 (20%)</cell><cell>29 (20%)</cell><cell>17 11(%)</cell><cell>20 (13%)</cell></row><row><cell>905</cell><cell>38 (70%)</cell><cell>7 (13%)</cell><cell>5 (9%)</cell><cell>3 (6%)</cell><cell>1 (2%)</cell></row><row><cell>906</cell><cell>31 (97%)</cell><cell>1(3%)</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>907</cell><cell>36 (43%)</cell><cell>14 (17%)</cell><cell>13 (15%)</cell><cell>10 (12%)</cell><cell>11 (13%)</cell></row><row><cell>908</cell><cell>19 (59%)</cell><cell>-</cell><cell>7 (22%)</cell><cell>3 (9.5%)</cell><cell>3 (9.5%)</cell></row><row><cell>Totals</cell><cell>288 (53%)</cell><cell>79 (14%)</cell><cell>72 (13%)</cell><cell>44 (9%)</cell><cell>62 (11%)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,94.54,414.92,402.97,10.80;9,90.04,429.08,221.92,10.80;9,311.92,426.27,8.10,7.24;9,323.08,429.08,169.78,10.80;9,90.04,443.24,185.91,10.80;9,275.92,440.43,6.30,7.24;9,282.28,443.24,9.96,10.80;9,292.24,440.43,6.30,7.24;9,301.60,443.24,92.29,10.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,237.27,414.92,260.24,10.80;9,90.04,429.08,37.47,10.80">Interactive searching behaviour: Okapi experiment for TREC-8</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fowkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,152.80,429.08,159.16,10.80;9,311.92,426.27,8.10,7.24;9,323.08,429.08,169.78,10.80;9,90.04,443.24,89.16,10.80">Proceedings of the BCS-IRSG 22 nd Annual Colloquium on Information Retrieval Research</title>
		<meeting>the BCS-IRSG 22 nd Annual Colloquium on Information Retrieval Research<address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-04-07">5 th -7 th April, 2000</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,94.54,471.56,417.99,10.80;9,90.04,485.72,377.03,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,275.23,471.56,237.30,10.80;9,90.04,485.72,153.49,10.80">The Development of a Method for the Evaluation of Interactive Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Borlund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ingwersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,262.60,485.72,126.61,10.80">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="250" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,94.54,514.04,422.58,10.80;9,90.04,528.20,388.99,10.80;9,90.04,542.36,49.32,10.80" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,190.88,514.04,157.38,10.80">User Interfaces and Visualisation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<editor>Modern Information Retrieval</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison-Wesley Longman Publishing Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
