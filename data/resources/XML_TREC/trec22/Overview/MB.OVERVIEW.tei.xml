<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.72,72.36,374.28,16.84">Overview of the TREC-2013 Microblog Track</title>
				<funder>
					<orgName type="full">U.S. National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.71,118.08,53.62,11.06"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<email>jimmylin@umd.edu</email>
							<affiliation key="aff0">
								<orgName type="department">The iSchool</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.07,118.08,59.79,11.06"><forename type="first">Miles</forename><surname>Efron</surname></persName>
							<email>mefron@illinois.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Library and Information Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana-Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.72,72.36,374.28,16.84">Overview of the TREC-2013 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2DCFC96B494F60BAC6AF23BA8B3C288E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This year represents the third iteration of the TREC Microblog track, which began in 2011. There was no substantive change in the task definition, which remains nominally real-time search, best summarized as "At time T , give me the most relevant tweets about topic X." However, we introduced a radically different evaluation methodology, dubbed "evaluation as a service", which attempted to address deficiencies in how the document collection was distributed in previous years. This is the first time such an approach has been deployed at TREC. Overall, we believe that the evaluation methodology was successful, drawing participation from twenty groups around the world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EVALUATION AS A SERVICE</head><p>Understanding the rationale behind this year's new evaluation methodology requires comparisons to the approach in previous years. Here, we provide a quick recap, but refer the reader to previous track overview papers for more details [1,  2]. In TREC 2011 and 2012, the Microblog track used the Tweets2011 collection, specifically created for those evaluations. Since Twitter's terms of service prohibit redistribution of tweets, it was necessary to develop an mechanism for researchers to obtain the collection. The track organizers devised a system whereby NIST distributed the ids of the tweets, rather than the tweets themselves. Given these ids and a downloader developed by the track organizers, a participant could "recreate" the corpus. Since the downloading program accessed the twitter.com site, the tweets were delivered in accordance with Twitter's terms of service.</p><p>The "download-tweets-yourself" approach adequately addressed the no-redistribution issue: in 2011, there were 59 official participants, which meant that at least 59 teams were able to successfully acquire the collection. However, the approach has scalability limits: the speed of the downloading program, which had built-in rate limiting for "robotic politeness", set a practical upper bound on the size of the collection. The Tweets2011 collection originally contained only 16 million tweets, which is small by modern standards. For 2013, we hoped to increase the collection size by at least an order of magnitude, which required rethinking data gathering and data access procedures.</p><p>Our solution, implemented in TREC 2013, was the "evaluation as a service" model. In summary: we gathered a collection of tweets centrally, but instead of distributing the tweets themselves, we provided a service API through which participants could access the tweets to complete the task. Below, we describe this approach in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collection Construction</head><p>To build the official collection, we developed a custom crawler using the twitter4j Java library<ref type="foot" coords="1,472.58,231.67,3.65,5.28" target="#foot_0">1</ref> that gathers tweets from Twitter's streaming API. <ref type="bibr" coords="1,439.49,242.13,3.65,5.28" target="#b2">2</ref> We crawled all tweets from the public sample stream between February 1 and March 31, 2013, UTC (inclusive). This level of access is available to anyone with a Twitter account and does not require special authorization. The collection was gathered from two separate virtual machine instances on Amazon's EC2 service, one on the east coast of the US, and the other on the west coast of the US. The redundant setup guarded against network outages and other operational issues during the collection period. Fortunately, no downtime was experienced during the data collection period, so one of the copies was simply designated as the official collection.</p><p>Messages are delivered in JSON from Twitter's streaming API: these messages contain posted tweets as well as notifications of tweets that have been deleted. The crawler packages all messages in one-hour compressed chunks. Thus, the collection is comprised of 1416 gzipped files. In total, we gathered 259 million tweets, although at the time of the evaluation the collection was reduced to 243 million tweets after the removal of deleted tweets.</p><p>We made a decision early in the track planning phase that all software infrastructure associated with the evaluation would be open source and hosted on GitHub. <ref type="bibr" coords="1,529.49,472.27,3.65,5.28">3</ref> The code for the crawler was developed during January 2013, with input and discussion on a mailing list for developers. By mid-January, we had an operational crawler ready for testing by a few volunteers, and on January 23, 2013, the crawler was released to all participants.</p><p>The official collection period was publicized on the track mailing list well in advance of the actual start date, which gave participants the opportunity to run the crawler themselves to gather contemporaneous tweets. Although these crawls may not have the same content as the official collection, they are nevertheless useful for computing term statistics, background models, etc. Based on an informal survey conducted over the track mailing list in November 2013, at least half a dozen groups from around the world gathered their own local private collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">API Specification</head><p>The idea behind the "evaluation as a service" model is to provide an API that participants can use to complete the  evaluation task without needing access to the raw collection. To this end, we provided a search API built using Thrift. <ref type="bibr" coords="2,285.05,448.94,3.65,5.28">4</ref> Thrift is a software framework for developing scalable services. It was originally developed at Facebook, but is now an open-source Apache project. The framework has gained popularity over the last several years and is currently an integral part of production software stacks at many internet companies, including Facebook and Twitter. Thrift provides an Interface Definition Language (IDL) for describing services and data types. From these definitions, the Thrift compiler automatically generates RPC clients and servers as well as code for serializing, deserializing, and manipulating the defined data types. Thrift handles generation of boilerplate code for communications protocols, object transport, method invocation, and other functionalities necessary to build distributed services. The framework provides support for Java, C++, Python, Ruby, as well as many other languages, which allows the development of language-neutral services. For example, a Python Thrift client can communicate easily with a Thrift server written in Java because the communication protocols and data types are defined in a language-independent manner.</p><p>The Thrift definitions of the two main data types in the TREC Microblog search API are shown in Figure <ref type="figure" coords="2,263.44,680.82,3.58,7.92">1</ref>. The Interface Definition Language is similar to a C struct, and contains an enumeration of numbered fields, each with a type and a name. Most of the types are self-evident; i32 represents a 32-bit integer (int in Java), while i64 represents a 64-bit integer (long in Java). The TQuery object represents a query, which contains the query text, a max_id (i.e., requests the service to return only results smaller than the id), and the number of results requested. For simplicity, the service is stateless; access control is granted through a group and token, which must be passed in the query each time. The TResult object defines the retrieved result (more details later). The service definition is shown in Figure <ref type="figure" coords="2,548.75,162.19,3.58,7.92">2</ref>. The single method search, receives a TQuery object and returns a list of TResult objects.</p><p>The service for the evaluation was written in Java using the open-source Lucene search engine (version 4.3.1 at the time of the evaluation). <ref type="bibr" coords="2,414.64,212.75,3.65,5.28" target="#b0">5</ref> We provided a sample client in Java to illustrate the features of the API. In addition, we received the contribution of a Python client from the community, which was later integrated into the code base.</p><p>Search ranking was provided using Lucene's implementation of query-likelihood (LMDirichletSimilarity). Results were filtered such that tweets with ids greater than max_id (as specified in the TQuery object) were discarded. Each search result was populated with the fields described in Table <ref type="table" coords="2,355.13,308.64,4.61,7.92" target="#tab_1">1</ref> (corresponding to the Thrift definition in Figure <ref type="figure" coords="2,334.24,319.10,3.58,7.92">1</ref>). For each field, the table also provides its corresponding element in the original JSON messages from the Twitter streaming API, whether the element is optional (for example, only retweets have certain fields), the corresponding Java data type, and a short description.</p><p>The service endpoint was developed during Spring 2013 and was released to all registered TREC participants starting in June. We released two distinct services: one on the Tweets2011 collection created for the Microblog tracks in TREC 2011 and TREC 2012, and another on the new collection gathered in 2013. Both services behaved exactly the same, except on different document collections. Since evaluation data were available for the Tweets2011 collection, that service allowed participants to train their systems on old topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RESULT OVERVIEW</head><p>In this year's evaluation, we received 71 runs from twenty groups. Relevance judgments were created using the standard pooling methodology by NIST assessors. Runs were pooled to depth 90, according to the retrieval scores indicated in each run. Simple retweets were removed from the pools (as they were deemed to be non-relevant). The tweets were clustered so that textually similar tweets could be judged consistently. Relevance judgments were made on a 3-point scale ("not relevant", "relevant", "highly relevant"), but the following results consider both "relevant" and "highly relevant" tweets to be relevant.</p><p>To provide a reference baseline, we constructed a post hoc run that processed the raw API output in three minor ways:</p><p>• All retweets were discarded.</p><p>• Duplicate tweets were removed (a small number of tweets were delivered multiple times via the streaming API due to transient network glitches).  • Score ties were broken by recency (i.e., more recent tweet were ranked higher).</p><p>The effectiveness of all submitted runs is shown in Table 4, with the baseline inserted for comparison purposes. The final column ("Type") denotes whether the run received human intervention (Manual) or was completely automatic (Auto). Summary statistics are shown in Table <ref type="table" coords="3,251.90,575.14,3.58,7.92" target="#tab_2">2</ref>. We see that the median submitted run appears to be worse than the baseline.</p><p>How do these results compare to previous years? In Figures 3 and 4 we sort all submitted runs from TREC 2011-2013 by either MAP or P30. The red line corresponds to the median run and the blue line corresponds to the baseline. In TREC 2011 and TREC 2013, the median lies below the baseline, but in TREC 2012, the median system outperforms the baseline. The number and fraction of runs that beat the baseline are shown in Table <ref type="table" coords="3,204.72,679.75,3.58,7.92" target="#tab_3">3</ref>.</p><p>An important question for the community to consider is the effect of the evaluation-as-a-service model with respect to experimental innovation. It may be possible that forcing teams to interact with the collection via an API leads to less diversity in techniques than we would see if participants had direct access to the collection. The diversity of techniques contributes to the diversity of the document pools, which affects the reusability of the evaluation resources. We are currently conducting analyses that hopefully will shed some light on this question. q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0 50 100 150</p><formula xml:id="formula_0" coords="4,65.50,140.98,3.97,125.02">0.0 0.1 0.2 0.3 0.4</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2011, Mean Average Precision</head><p>Run Rank MAP q q q qqq q q q q q qq qqqq qq q qq qq qqq qqqq qq qqq q qqq qqq qqqqq qqq qqqqq qqq qqqq qqq qqqqq qqqqq qqq qq qqq q q q qqqq q qq qq q qq q qqqq q q qqq qq q q q q qq q q q qq 0 20 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2012, Mean Average Precision</head><p>Run Rank MAP q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0 10 20 q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0 50 100 150 0.0 0.1 0.2 0.3 0.4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2011, Precision @ 30</head><p>Run Rank p30 Baseline Median q q q qq qqq qqqqq qqq q qq qq qqqq qq qqqqqq q qq qqqq qqqq qqq qqqq qqqq qqqq qq qqq qqqq q qqq qqq qq q q qqqqq q qqqqq q q q qqq qqqq q qq qqq q q qq qq qq q q qq q qq q 0 20 40 60 80 100 120 0.10 0.15 0.20 0.25</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2012, Precision @ 30</head><p>Run Rank p30 q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0 10 20  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,53.80,265.66,239.10,8.02;2,53.80,276.12,71.56,8.02"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Thrift definition of a search query and a retrieval result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,132.74,307.65,344.24,8.02"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Runs from TREC 2011-2013 ranked by mean average precision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,177.67,643.39,254.38,8.02"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Runs from TREC 2011-2013 ranked by P30.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,59.18,63.76,492.31,196.79"><head>Table 1 : Detailed Description of a Search Result.</head><label>1</label><figDesc></figDesc><table coords="3,59.18,83.62,492.31,176.92"><row><cell>Thrift field</cell><cell>JSON element</cell><cell cols="2">Optional? Type</cell><cell>Description</cell></row><row><cell>id</cell><cell>status.id</cell><cell>no</cell><cell>long</cell><cell>unique tweet id assigned by Twitter</cell></row><row><cell>rsv</cell><cell></cell><cell>no</cell><cell cols="2">double retrieval status value, i.e., document score</cell></row><row><cell>screen_name</cell><cell>status.user.screen_name</cell><cell>no</cell><cell>String</cell><cell>user who posted the tweet</cell></row><row><cell>epoch</cell><cell>status.created_at (derived)</cell><cell>no</cell><cell>long</cell><cell>UNIX epoch second when the tweet was posted</cell></row><row><cell>text</cell><cell>status.text</cell><cell>no</cell><cell>String</cell><cell>text of the tweet</cell></row><row><cell>followers_count</cell><cell>status.user.followers_count</cell><cell>no</cell><cell>int</cell><cell>the number of followers the user has</cell></row><row><cell>statuses_count</cell><cell>status.user.statuses_count</cell><cell>no</cell><cell>int</cell><cell>the number of tweets the user has posted</cell></row><row><cell>lang</cell><cell>status.lang</cell><cell>yes</cell><cell>String</cell><cell>the two-character language of the tweet as de-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>scribed by the Twitter language id system</cell></row><row><cell cols="2">in_reply_to_status_id status.in_reply_to_status_id</cell><cell>yes</cell><cell>long</cell><cell>the id of the tweet that this tweet replies to</cell></row><row><cell>in_reply_to_user_id</cell><cell>status.in_reply_to_user_id</cell><cell>yes</cell><cell>long</cell><cell>the id of the user who posted the tweet that this</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>tweet replies to</cell></row><row><cell>retweeted_status_id</cell><cell>status.retweeted_status.id</cell><cell>yes</cell><cell>long</cell><cell>the id of the tweet that this tweet is a retweet of</cell></row><row><cell>retweeted_user_id</cell><cell cols="2">status.retweeted_status.user.id yes</cell><cell>long</cell><cell>the id of the user who posted the tweet that this</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>tweet is a retweet of</cell></row><row><cell>retweeted_count</cell><cell>status.retweet_count</cell><cell>yes</cell><cell>int</cell><cell>number of times this tweet has been retweeted</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,53.80,299.37,239.10,69.93"><head>Table 2 : Summary of Effectiveness Metrics. Median and Mean are calculated from all submitted runs.</head><label>2</label><figDesc></figDesc><table coords="3,101.62,327.82,143.46,41.49"><row><cell></cell><cell>MAP</cell><cell>P30</cell><cell>R-prec</cell></row><row><cell cols="4">Baseline 0.2524 0.4500 0.3008</cell></row><row><cell>Median</cell><cell cols="3">0.2217 0.4311 0.2796</cell></row><row><cell>Mean</cell><cell cols="3">0.2271 0.4111 0.2758</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,53.80,401.08,239.11,69.93"><head>Table 3 : Number and Fraction of Runs above the Baseline.</head><label>3</label><figDesc></figDesc><table coords="3,102.47,429.52,141.76,41.49"><row><cell>Year</cell><cell>Number</cell><cell></cell><cell>Fraction</cell></row><row><cell cols="3">2011 20 out of 184</cell><cell>0.109</cell></row><row><cell cols="3">2012 79 out of 122</cell><cell>0.648</cell></row><row><cell cols="2">2013 30 out of</cell><cell>71</cell><cell>0.423</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,53.80,170.98,502.12,428.14"><head>Table 4 : Overview of Retrieval Effectiveness. All 71 runs submitted to the evaluation are ranked in decreasing order of mean average precision. The entry marked baseline was not part of the original evaluation, and is included only for reference purposes.</head><label>4</label><figDesc></figDesc><table coords="5,63.76,211.63,482.20,387.49"><row><cell>Run</cell><cell>MAP</cell><cell>P30</cell><cell>R-prec</cell><cell>Type</cell><cell>Run</cell><cell>MAP</cell><cell>P30</cell><cell>R-prec Type</cell></row><row><cell>Direrank</cell><cell>0.4735</cell><cell>0.6967</cell><cell>0.5172</cell><cell>Manual</cell><cell>kobeU</cell><cell cols="3">0.2217 0.4211 0.2696 Auto</cell></row><row><cell>Avgrank</cell><cell>0.4570</cell><cell>0.7061</cell><cell>0.5033</cell><cell>Manual</cell><cell>BAUENGPGRNK</cell><cell cols="3">0.2212 0.3933 0.2866 Auto</cell></row><row><cell>FSsvm</cell><cell>0.4413</cell><cell>0.6744</cell><cell>0.4882</cell><cell>Manual</cell><cell>QEClustIDF</cell><cell cols="3">0.2196 0.5094 0.2640 Auto</cell></row><row><cell>RvsDir</cell><cell>0.4010</cell><cell>0.5822</cell><cell>0.4931</cell><cell>Manual</cell><cell cols="4">QEDiscIDF25Good 0.2188 0.5122 0.2626 Auto</cell></row><row><cell>PrisRun4</cell><cell>0.3524</cell><cell>0.5528</cell><cell>0.3861</cell><cell>Auto</cell><cell>BAUENPRKST</cell><cell cols="3">0.2187 0.3906 0.2818 Auto</cell></row><row><cell>PrisRun3</cell><cell>0.3506</cell><cell>0.5544</cell><cell>0.3850</cell><cell>Manual</cell><cell>CIRGIRDISCO2</cell><cell cols="3">0.2160 0.3817 0.2796 Auto</cell></row><row><cell>QCRI4</cell><cell>0.3494</cell><cell>0.5372</cell><cell>0.3905</cell><cell>Auto</cell><cell>CIRGIRDISCO3</cell><cell cols="3">0.2152 0.3828 0.2788 Auto</cell></row><row><cell>PKUICST3</cell><cell>0.3486</cell><cell>0.5567</cell><cell>0.3827</cell><cell>Auto</cell><cell>BAUENGFLT</cell><cell cols="3">0.2129 0.3956 0.2789 Auto</cell></row><row><cell>PrisRun2</cell><cell>0.3459</cell><cell>0.5511</cell><cell>0.3844</cell><cell>Auto</cell><cell>kobeRMU</cell><cell cols="3">0.2125 0.4311 0.2538 Auto</cell></row><row><cell>PKUICST1</cell><cell>0.3351</cell><cell>0.5478</cell><cell>0.3721</cell><cell>Auto</cell><cell>UDInfoMINT</cell><cell cols="3">0.2108 0.3978 0.2654 Auto</cell></row><row><cell>PKUICST2</cell><cell>0.3268</cell><cell>0.5311</cell><cell>0.3637</cell><cell>Auto</cell><cell>BAUENGSTAT</cell><cell cols="3">0.2092 0.3844 0.2750 Auto</cell></row><row><cell>QCRI3</cell><cell>0.3068</cell><cell>0.4817</cell><cell>0.3472</cell><cell>Auto</cell><cell>NOVAsearch01</cell><cell cols="3">0.2082 0.4367 0.2530 Auto</cell></row><row><cell>ILPSub</cell><cell>0.3008</cell><cell>0.5322</cell><cell>0.3456</cell><cell>Auto</cell><cell>ModelSEL922</cell><cell cols="3">0.2076 0.4739 0.2514 Auto</cell></row><row><cell>QCRI2</cell><cell>0.3001</cell><cell>0.4733</cell><cell>0.3441</cell><cell>Auto</cell><cell>UDInfoMTB2</cell><cell cols="3">0.2069 0.4061 0.2614 Auto</cell></row><row><cell>QCRI1</cell><cell>0.2993</cell><cell>0.4678</cell><cell>0.3476</cell><cell>Auto</cell><cell>DFRBase</cell><cell cols="3">0.2040 0.4650 0.2494 Auto</cell></row><row><cell>PrisRun1</cell><cell>0.2988</cell><cell>0.5078</cell><cell>0.3429</cell><cell>Auto</cell><cell>scunce4</cell><cell cols="3">0.1955 0.3933 0.2590 Auto</cell></row><row><cell>ILPSl2rE</cell><cell>0.2834</cell><cell>0.4894</cell><cell>0.3281</cell><cell>Auto</cell><cell>BNTSrK</cell><cell cols="3">0.1952 0.3672 0.2628 Auto</cell></row><row><cell>UDInfoMB</cell><cell>0.2811</cell><cell>0.5022</cell><cell>0.3285</cell><cell>Auto</cell><cell>scunce1</cell><cell cols="3">0.1794 0.3744 0.2457 Auto</cell></row><row><cell>PKUICST4</cell><cell>0.2768</cell><cell>0.5017</cell><cell>0.3260</cell><cell>Auto</cell><cell>scunce2</cell><cell cols="3">0.1786 0.3667 0.2494 Auto</cell></row><row><cell>QUTemporal</cell><cell>0.2748</cell><cell>0.4739</cell><cell>0.3245</cell><cell>Auto</cell><cell>scunce3</cell><cell cols="3">0.1626 0.3517 0.2335 Auto</cell></row><row><cell>NOVAsearch00</cell><cell>0.2726</cell><cell>0.4711</cell><cell>0.3171</cell><cell>Auto</cell><cell>ICTNETBASE</cell><cell cols="3">0.1613 0.3378 0.2136 Auto</cell></row><row><cell>QUQueryExp</cell><cell>0.2710</cell><cell>0.4433</cell><cell>0.3128</cell><cell>Auto</cell><cell>NOVAsearch03</cell><cell cols="3">0.1612 0.3550 0.2092 Auto</cell></row><row><cell>ICTNETBO1EXP</cell><cell>0.2663</cell><cell>0.4644</cell><cell>0.3117</cell><cell>Auto</cell><cell>ILPSdf</cell><cell cols="3">0.1527 0.4089 0.2020 Auto</cell></row><row><cell>kobeTSFRM</cell><cell>0.2640</cell><cell>0.4861</cell><cell>0.3146</cell><cell>Manual</cell><cell>UCASgem</cell><cell cols="3">0.1285 0.2844 0.2034 Auto</cell></row><row><cell>QUBaseline</cell><cell>0.2555</cell><cell>0.4294</cell><cell>0.2936</cell><cell>Auto</cell><cell>UCASqe</cell><cell cols="3">0.1276 0.2217 0.1880 Auto</cell></row><row><cell>Baseline</cell><cell cols="4">0.2524 0.4500 0.3008 Auto</cell><cell>stan4col</cell><cell cols="3">0.1097 0.2278 0.1426 Auto</cell></row><row><cell cols="2">ICTNETCOCCUR 0.2510</cell><cell>0.4594</cell><cell>0.2923</cell><cell>Auto</cell><cell>BJUTFreq</cell><cell cols="3">0.1088 0.2328 0.1610 Auto</cell></row><row><cell>UDInfoMTB1</cell><cell>0.2484</cell><cell>0.4778</cell><cell>0.2873</cell><cell>Auto</cell><cell>BNTSrKSO</cell><cell cols="3">0.1031 0.2061 0.1379 Auto</cell></row><row><cell>GSAA</cell><cell>0.2412</cell><cell>0.4061</cell><cell>0.2996</cell><cell>Auto</cell><cell>WISSySeCo</cell><cell cols="3">0.0976 0.3328 0.1430 Auto</cell></row><row><cell>stan2kl</cell><cell>0.2376</cell><cell>0.4411</cell><cell>0.2787</cell><cell>Auto</cell><cell>iritfdUrlRoc</cell><cell cols="3">0.0757 0.1461 0.1339 Auto</cell></row><row><cell>kobeTSFRMU</cell><cell>0.2365</cell><cell>0.4733</cell><cell>0.2867</cell><cell>Auto</cell><cell>BJUTEntr</cell><cell cols="3">0.0731 0.1639 0.1174 Auto</cell></row><row><cell>GSAS</cell><cell>0.2351</cell><cell>0.4044</cell><cell>0.2920</cell><cell>Auto</cell><cell>BJUTCnor</cell><cell cols="3">0.0729 0.1822 0.1137 Auto</cell></row><row><cell>GSAT</cell><cell>0.2351</cell><cell>0.4044</cell><cell>0.2920</cell><cell>Auto</cell><cell>iritfdUrl</cell><cell cols="3">0.0648 0.1394 0.1146 Auto</cell></row><row><cell>QUDocExp</cell><cell>0.2311</cell><cell>0.4478</cell><cell>0.2809</cell><cell>Auto</cell><cell>stan1kl</cell><cell cols="3">0.0325 0.0383 0.0425 Auto</cell></row><row><cell>NOVAsearch02</cell><cell>0.2239</cell><cell>0.4450</cell><cell>0.2738</cell><cell>Auto</cell><cell>stan3kl</cell><cell cols="3">0.0315 0.0300 0.0401 Auto</cell></row><row><cell>CIRGIRDISCO4</cell><cell>0.2220</cell><cell>0.4078</cell><cell>0.2871</cell><cell>Auto</cell><cell>ILPSl2rB</cell><cell cols="3">0.0131 0.0639 0.0370 Auto</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.42,690.56,140.59,7.92"><p>http://twitter4j.org/en/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,321.42,700.85,181.48,7.92"><p>https://dev.twitter.com/docs/streaming-apis</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,321.42,711.13,90.95,7.92"><p>http://twittertools.cc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,58.41,711.13,100.14,7.92"><p>http://thrift.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,321.42,711.13,103.96,7.92"><p>http://lucene.apache.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4.">ACKNOWLEDGMENTS</head><p>This work was supported in part by the <rs type="funder">U.S. National Science Foundation</rs> under IIS-1217279 and IIS-1218043. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,321.30,456.50,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,331.02,471.73,192.57,7.92;3,331.02,482.19,198.20,7.92;3,331.02,492.65,224.89,7.92;3,331.02,503.11,185.48,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,331.02,482.19,182.45,7.92">Overview of the TREC-2011 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,331.02,492.65,224.89,7.92;3,331.02,503.11,54.14,7.92">Proceedings of the Twentieth Text REtrieval Conference (TREC 2011)</title>
		<meeting>the Twentieth Text REtrieval Conference (TREC 2011)<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,331.02,514.57,192.57,7.92;3,331.02,525.03,198.20,7.92;3,331.02,535.49,190.00,7.92;3,331.02,545.95,209.05,7.92;3,331.02,556.41,20.99,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,331.02,525.03,182.45,7.92">Overview of the TREC-2012 Microblog Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,331.02,535.49,190.00,7.92;3,331.02,545.95,44.34,7.92">Proceedings of the Twenty-First Text REtrieval Conference</title>
		<meeting>the Twenty-First Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
