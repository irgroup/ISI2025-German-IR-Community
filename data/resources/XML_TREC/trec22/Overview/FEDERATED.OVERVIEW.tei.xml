<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,64.70,72.35,480.31,16.84">Overview of the TREC 2013 Federated Web Search Track</title>
				<funder>
					<orgName type="full">Ghent University -iMinds in Belgium</orgName>
				</funder>
				<funder>
					<orgName type="full">Folktales As Classifiable Texts</orgName>
					<orgName type="abbreviated">FACT</orgName>
				</funder>
				<funder ref="#_gvdvhNd">
					<orgName type="full">Dutch</orgName>
				</funder>
				<funder ref="#_qkapKA2">
					<orgName type="full">Netherlands Organization for Scientific Research, NWO</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,112.01,118.05,104.97,11.06"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
							<email>tdmeeste@intec.ugent.be</email>
							<affiliation key="aff0">
								<orgName type="institution">Ghent University -iMinds</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.77,118.05,85.11,11.06"><forename type="first">Dolf</forename><surname>Trieschnigg</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.67,118.05,72.85,11.06"><forename type="first">Dong</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,407.33,118.05,86.23,11.06"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
							<email>d.hiemstra@utwente.nl</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,64.70,72.35,480.31,16.84">Overview of the TREC 2013 Federated Web Search Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">839946BA6B799C008C0CBE4144314A1B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC Federated Web Search track is intended to promote research related to federated search in a realistic web setting, and hereto provides a large data collection gathered from a series of online search engines. This overview paper discusses the results of the first edition of the track, FedWeb 2013. The focus was on basic challenges in federated search:</p><p>(1) resource selection, and (2) results merging. After an overview of the provided data collection and the relevance judgments for the test topics, the participants' individual approaches and results on both tasks are discussed. Promising research directions and an outlook on the 2014 edition of the track are provided as well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Building large-scale search engines increasingly depends on combining search results from multiple sources. A web search engine might combine results from numerous verticals, such as: videos, books, images, scientific papers, shopping, blogs, news, recipes, music, maps, advertisements, Q&amp; A, jobs, social networks, etc. Typically, the search results provided by each source differ significantly in the provided snippets, the provided additional (structured) information, and the ranking approach used. For online shopping, for instance, the results are highly structured, and price, bids, ratings and click-through rate are important ranking criteria, whereas for scientific paper search the number of citations is an important ranking criterion. Federated search also enables the inclusion of results from otherwise hidden web collections that are not easily crawlable.</p><p>The TREC Federated Web Search (FedWeb) track 2013 provides a test collection that stimulates research in many areas related to federated search, including aggregated search, distributed search, peer-to-peer search and metasearch engines <ref type="bibr" coords="1,114.04,579.88,13.49,7.86" target="#b19">[19]</ref>. The collection relieves researchers from the burden of collecting or creating proprietary datasets <ref type="bibr" coords="1,53.80,600.80,9.20,7.86" target="#b3">[3]</ref>, or creating artificial federated search test collections by dividing existing TREC collections by topic or source <ref type="bibr" coords="1,53.80,621.72,13.49,7.86" target="#b14">[14]</ref>. The TREC FedWeb 2013 collection is different from such artificially created test collections in that it provides the actual results of 157 real web search engines, each providing their own retrieval method and heterogeneous content types including images, pdf-text, video, etc. <ref type="bibr" coords="1,280.64,663.57,9.20,7.86" target="#b2">[2]</ref>. This paper describes the first edition of the TREC FedWeb TREC 2013 Gaithersburg, USA track. A total of 11 groups (see Table <ref type="table" coords="1,470.26,210.06,4.10,7.86" target="#tab_0">1</ref>) participated in the two classic distributed search tasks <ref type="bibr" coords="1,460.84,220.53,9.20,7.86" target="#b9">[9]</ref>:</p><formula xml:id="formula_0" coords="1,321.30,240.13,125.08,7.89">Task 1: Resource Selection</formula><p>The goal of resource selection is to select the right resources from a large number of independent search engines given a query. Participants had to rank the 157 search engines for each test topic without access to the corresponding search results. The FedWeb 2013 collection contains search result pages for many other queries, as well as the HTML of the corresponding web pages. These data could be used by the participants to build resource descriptions. Some of the participants also used external sources such as Wikipedia, ODP, or WordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 2: Results Merging</head><p>The goal of results merging is to combine the results of several search engines into a single ranked list. After the deadline for Task 1 passed, the participants were given the search result pages of 157 search engines for the test topics. The result pages include titles, snippet summaries, hyperlinks, and possibly thumbnail images, all of which were used by participants for reranking and merging. In later editions of the track, these data will also be used to build aggregated search result pages.</p><p>The official track guidelines can be found online<ref type="foot" coords="1,519.12,495.32,3.65,5.24" target="#foot_0">1</ref> . Apart from studying resource selection and results merging in a web context, there are also new research challenges that readily appear, and for which the FedWeb 2013 collection could be used. Some examples are: How does the snippet quality influence results merging strategies? How well can the relevance of results be estimated based on snippets only? Can the size or the importance of search engines be reliably estimated from the provided search samples? Are people able to detect duplicate results, i.e., the same result provided by multiple search engines?</p><p>This overview paper is organized as follows: Section 2 describes the FedWeb collection; Section 3 describes the process of gathering relevance judgements for the track; Sections 4 and 5 describe the results for the resource selection task and results merging task, respectively; Section 6 gives a summary of this year's track and provides an outlook on next year's track.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">FEDWEB 2013 COLLECTION</head><p>The FedWeb 2013 Data Collection consists of search results from 157 web search engines in 24 categories ranging from news, academic articles and images to jokes and lyrics. Overview statistics of the collection are listed in Table <ref type="table" coords="2,285.75,596.12,3.58,7.86" target="#tab_1">2</ref>. The categories are listed in Table <ref type="table" coords="2,191.57,606.58,3.58,7.86" target="#tab_2">3</ref>, and the search engines are listed in Appendix A. To prevent a bias towards large general web search engines, we merged the results from a number of large web search engines into the 'BigWeb' (engine e200) search engine. A query for this engine was sent randomly to one of the large web search engines. In comparison to the 2012 collection (available for training) <ref type="bibr" coords="2,276.03,669.34,13.50,7.86" target="#b17">[17]</ref>, the 2013 collection covers more search engines and a larger variety of categories and has more samples. The collection contains both the search result snippets and the pages the search results link to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Extracting snippets</head><p>The search result snippets were scraped from the HTML search result pages using XPaths. This allowed a single approach to be used for all engines rather than to program a wrapper for each search engine API. The SearchRe-sultFinder plugin <ref type="bibr" coords="2,394.75,285.85,14.32,7.86" target="#b21">[21,</ref><ref type="bibr" coords="2,415.50,285.85,11.76,7.86" target="#b20">20]</ref> was used to quickly identify reusable XPaths to extract the snippets from search result pages. Additional (relative) XPaths were determined manually to extract the link, title, description and thumbnail from each snippet. Table <ref type="table" coords="2,436.52,327.69,4.61,7.86" target="#tab_4">4</ref> shows an example of the required information to sample search results from a single search engine. Up to 10 snippets from the first search result page were extracted for each engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sampling</head><p>2000 sample queries were issued to each of the 157 search engines. The first set of a 1000 queries was the same accross all search engines and were single words sampled from the vocabulary of the ClueWeb09-A collection. The second set of a 1000 queries was engine-dependent and consisted of single words sampled from the retrieved snippet vocabulary of that engine. The pages and thumbnails that were linked to from the snippets were downloaded and included in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Topics</head><p>The organizers created 200 topic descriptions and queries, targeted at specific categories in the collection. Similar to the sampling, for each of the topics the top 10 search result snippets and pages from each search engine were crawled. To facilitate the judgements of pages, screenshots were taken using Selenium<ref type="foot" coords="2,377.16,560.91,3.65,5.24" target="#foot_1">2</ref> (with a maximum height of 3000 pixels) of the top of each retrieved page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Duplicate page detection</head><p>The search engines in the collection have overlapping indexes, which might result in duplicate pages in the merged search results.</p><p>To prevent rewarding merged search results containing duplicate (relevant) content, we semi-automatically determined duplicate content. First, a set of candidate duplicates was determined automatically. Then, pairs of likely duplicates were checked manually to determine their state.</p><p>Pairs of pages were considered duplicate when:  2. The pages are not empty and their MD5 hashes are the same.</p><p>3. Both URLs do not appear on a manually compiled exclusion list which are known to contain false positives (e.g. from phdcomics.com), the pages contain at least 100 words, have a similar length (&lt; 2% difference) and have the same Simhash <ref type="bibr" coords="3,173.23,299.16,13.49,7.86" target="#b11">[11]</ref>.</p><p>The pairs of pages in the third category were manually checked. False positives included URLs that simply showed a "not available anymore" page and pages asking to accept cookies to view the page. 12,903 pages were flagged as duplicate, resulting in 4,601 page types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELEVANCE ASSESSMENTS</head><p>This section describes the collection of the test topics and the relevance judgments, and gives an idea of how the different resource categories contribute to the total fraction of relevant results.</p><p>To collect test topics, we first created a pool of new queries and queries from previous TREC tracks (all queries from the Web Track 2009 and 2010, and selected queries from the Million Query Track 2009). The 271 new queries are real life queries, recorded by a number of people with diverse backgrounds, who provided both the queries and the corresponding information need descriptions. We explicitly asked them to also include queries targeting other than only general web search engines. For all 506 queries in this pool, we estimated which resource categories (see Table <ref type="table" coords="3,254.50,533.35,4.09,7.86" target="#tab_2">3</ref>) each of those queries was most likely to target, and made a first selection of 200 (mostly new) queries, thereby ensuring that all resource categories were well represented. The annotation was then organized in two distinct steps. First, we judged all top-3 snippets from each resource for each of these 200 queries (in total almost 50,000 snippets), given that judging snippets goes much faster than judging pages. From those 200 queries, we selected 50 queries for which we collected the complete page judgments (i.e., for the top 10 results). These 50 queries were selected based on the relevance distribution of the judged snippets, avoiding queries with too few or too many relevant results. We also favored queries which had a substantial number of relevant results among other than only the general web search engines. For those 50 queries, the judges were asked to write down a narrative which described the information need, its context and the expected results. This narrative was used in both the snippet and page judgments. We collected over 32,000 page judgments for the 50 selected queries, not including overlapping judgments. An example of a query, with description and narrative, is given below. The graded relevance levels used in the judgements are also used in the Web Track<ref type="foot" coords="3,426.01,363.14,3.65,5.24" target="#foot_2">3</ref> : Non (not relevant), Rel (minimal relevance), HRel (highly relevant), Key (top relevance), and Nav (navigational).</p><p>There are a number of differences with respect to the 2012 test collection <ref type="bibr" coords="3,375.89,406.75,13.49,7.86" target="#b17">[17]</ref>. First of all, we judged all pages (in the top 10 result lists), whereas for the 2012 test topics we left out those with non-relevant snippets. Also, besides the information need descriptions, we introduced a narrative for each query, facilitating the assessor's consistent choice of relevance for results from different resource categories. The main difference is, however, the choice of test queries designed to avoid the strong bias towards general web search engines, mentioned in <ref type="bibr" coords="3,407.00,490.44,13.50,7.86" target="#b12">[12]</ref>. As a reference, we added the 50 selected queries in Appendix B. As an illustration, Fig. <ref type="figure" coords="3,551.31,500.90,4.61,7.86" target="#fig_0">1</ref> gives an overview of the relevance distribution over the different resource categories, in a boxplot that presents per category the fraction of results with relevance level Rel or higher for each test topic. For the most important resource categories (in terms of number or size of resources, i.e: General, Video, Blogs, Audio, . . . ), many topics provide a significant amount of relevant results. However, we also tried to select at least a few topics targeting smaller resource categories (e.g., Recipes, Travel, Jokes). In the end, only two categories (Games and Local) did not provide a notable number of relevant results for any of the test topics, despite queries that were intended to target those categories, like query 7415 ('most anticipated games of 2013') for games, or 7009 ('best place to eat pho in new york') for local, see appendix B.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESOURCE SELECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation</head><p>The evaluation results for the resource selection task are shown in Table <ref type="table" coords="4,116.45,438.14,3.58,7.86" target="#tab_7">5</ref>, displaying for a number of metrics the average per run over all topics. The primary evaluation metric for the resource selection task is the normalized discounted cumulative gain nDCG@20, where we use the nDCG variant introduced by Burges et al. <ref type="bibr" coords="4,165.21,479.98,9.20,7.86">[8]</ref>. The gain gj at rank j is calculated as gj = 2 r(j) -1, with r(j) the relevance level of the result at rank j. The relevance of a search engine for a given query is determined by calculating the graded precision <ref type="bibr" coords="4,278.59,512.43,14.32,7.86" target="#b15">[15]</ref> on the top 10 results. This takes the graded relevance levels of the documents in the top 10 into account, but not the ranking. The following weights are given to the relevance levels of documents: wNon = 0, w Rel = 0.25, w HRel = 0.5, wKey = rNav = 1. The graded relevance values are then converted to discrete relevance levels r through multiplication by 100 and taking the nearest integer value. We also reported nP@1 and nP@5, the normalized graded precision for the highest ranked resource, respectively, the top 5 resources, averaged over all topics. We define the normalized graded precision nP@k for each topic as the graded precision on all results for that topic from the top k resources (using the graded relevance weights defined above, and disregarding the ranking of results and resources), normalized by the graded precision of the top k resources for the best possible ranking for that topic. For example, nP@1 denotes the graded precision of the highest ranked resource, divided by the highest graded precision by any of the resources for that topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Participant Approaches</head><p>This section shortly describes the experiments by the Fed-Web participants for the resource selection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University of Delaware (udel)</head><p>Resources were ranked based on the average document scores (udelFAVE), the rank of the highest ranking document (udelRSMIN) and by using rankings of documents to find resource scores with a cut-off (udelODRA). Weights and cut-off values were determined from experiments on the FedWeb 2012 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University of Padova (UPD)</head><p>The University of Padova, explored the effectiveness of the TWF-IRF weighting scheme in a Federated Web Search setting <ref type="bibr" coords="4,335.40,551.83,9.20,7.86" target="#b7">[7]</ref>. The UPDFW13sh run was obtained by combining the query keywords using OR. The UPDFW13mu run was created by appending three ranked lists of search engines: First, the engines were returned matching an AND query, then the engines matching an OR query (and not included in the first list) and finally the remaining engines (ordered by id).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University of Twente (ut)</head><p>The University of Twente used the recently proposed shard selection method called 'Taily' that is based on statistics of all shards <ref type="bibr" coords="4,356.45,658.88,9.20,7.86" target="#b1">[1]</ref>. As these were not available, document samples were used instead. In comparison with their original publication, the FedWeb submission assumed that all resources are of the same size. They experimented with a baseline run (utTailyM400), and a variation using a Gaussian distribution instead of a Gamma distribution (utTailyNormM400). Resource Selection -Average topic scores by run Centrum Wiskunde &amp; Informatica (CWI)</p><p>CWI <ref type="bibr" coords="6,76.63,72.08,9.72,7.86" target="#b5">[5]</ref> explored the use of ODP category information for resource selection, by ranking the resources based on the Jaccard similarity between the ODP categories of the query and each resource (cwi13ODPJac). They also experimented with an approach using only snippets. An index was created of large documents, each created by concatenating all snippets from a resource. The resources were then ranked based on TF-IDF similarity (cwi13SniTI). The cwi13ODPTI combined the rankings of the two approached using a Borda voting mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University of Stavanger (UiS)</head><p>The University of Stanvanger explored two different approaches <ref type="bibr" coords="6,91.49,209.41,9.20,7.86" target="#b4">[4]</ref>. The UiSP run ranked individual documents in a central index of all sampled documents, based on their full page content using a language modeling approach. The relevance estimates were then aggregated on a resource level. The UiSPP run is a linear combination of the UiSP run with a model that estimated the relevance of collections based on a language modeling approach, by representing each resource as a single, large document created from the sampled snippets. UiSS used the same approach as UiSPP, but now using only snippets. Resource priors were calculated based on the total number of sampled documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>International Institute of Information Technology (IIIT_Hyderabad)</head><p>IIIT Hyderabad explored the use of Wordnet synonyms and Wikipedia categories for query expansion (iiitnaive01).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>East China Normal University (scunce)</head><p>They performed query expansion using Google search and ranked the resources based on BM25 (ECNUBM25).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Indian Statistical Institute (isi_pal)</head><p>The Indian Statistical Institute did not use the provided document and snippet samples (runs incgqd and incgqdv2) <ref type="bibr" coords="6,53.80,474.94,13.49,7.86" target="#b18">[18]</ref>. Instead, they used the Google Search API to issue the test queries to each resource. Each resource was ranked using the top 8 retrieved results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stanford University (StanfordEIG)</head><p>The StanfordEIG10 run was executed over a Cassandra database containing meta information about the search engines. The overall dataset was partitioned into Solr indexes, vectors were then calculated on a TF-IDF basis which was loaded into a dictionary map. Thresholds for term frequency were established at ≥ 10,≥ 50 and ≥ 100 respectively. Queries were tokenized before being executed over keys and fields in the Cassandra Keyspace.</p><p>Unfortunately the scoring metric was not stable and only the top result for each query was presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Organizers' baseline</head><p>As a simple baseline, we used a query-independent method by ranking resources based on their estimated size. The first size estimation method (RS_clueweb) scaled the document frequencies in the sampled data based on a reference corpus, for which we used the ClueWeb09 collection <ref type="foot" coords="6,234.36,694.02,3.65,5.24" target="#foot_3">4</ref> . The second method used query pools, similar to <ref type="bibr" coords="6,459.82,57.64,9.20,7.86" target="#b6">[6]</ref>, and resulted in moderate baseline results (RS_querypools).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>Table <ref type="table" coords="6,351.33,99.82,4.61,7.86" target="#tab_7">5</ref> lists the particpants' results on the Resource Selection task. The NDCG@20 scores range from 0.025 to 0.295 and are strongly correlated (Pearson's r = 0.9) with the nP@5. Fig. <ref type="figure" coords="6,380.95,131.21,4.61,7.86" target="#fig_1">2</ref> visualizes the topic scores per run: a boxplot shows the first and third quartiles and the median (red line) NDCG@20 values.</p><p>The Clueweb09 baseline RS_clueweb performs surprisingly well. Having a good size estimate turns out to give a solid baseline. Notable is the nP@1 of 0, caused by a flaw in estimating the size of a single search engine (which for every query returns the same set of results). Despite this flaw, the run achieves the highest nP@5. Its boxplot in Fig. <ref type="figure" coords="6,348.12,225.35,4.61,7.86" target="#fig_1">2</ref> shows stable results, with relatively few positive outliers compared to the best peforming run. The other baseline (RS_querypools) performs much worse, but similar to RS_clueweb it gives relatively stable results with a high median.</p><p>The best performing runs (UPDFW13mu, UiSP and udelFAVE) rely on indices based on single documents (rather than snippets) and combine evidence from standard retrieval approaches (variations on TF.IDF and language modeling). The best performing runs do not use external resources such as Wordnet and Wikipedia. A notable exception is the RS_clueweb baseline, which uses the collections' snippets in combination with the ClueWeb '09 collection to make size estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS MERGING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation</head><p>The evaluation results for the results merging task are shown in Table <ref type="table" coords="6,383.88,427.58,3.58,7.86" target="#tab_8">6</ref>, displaying for a number of metrics the average per run over all topics.</p><p>The primary evaluation metric for the results merging task is again the normalized discounted cumulative gain nDCG@20. We have chosen the relevance levels used to calculate the gain as rNon = 0, r Rel = 1, r HRel = 2, rKey = rNav = 3. Note that when going through the ranked results, duplicate documents (based on URL and content, see Section 2.4) of a result already seen higher in the list, are considered non-relevant (i.e., are assigned relevance level Non), when calculating this measure on the merged results.</p><p>We also reported nDCG@100, P@10, and ERR@20, using the same penalty for duplicates. P@10 is the binary precision at 10, whereby all levels from Rel and above are considered relevant, and hence represents the ability of filtering out non-relevant results. For the expected reciprocal rank ERR@20 (see Chapelle et al. <ref type="bibr" coords="6,438.75,594.95,13.63,7.86" target="#b10">[10]</ref>), we used the same relevance levels used in the TREC Web Track (i.e., 0-4 ranging from Non to Nav). In order to show that detecting duplicates is an important issue for efficient results merging in the Web setting, we also reported the nDCG@20 and ERR@20 without duplicate penalty, indicated with (*) in Table <ref type="table" coords="6,537.42,647.25,3.58,7.86" target="#tab_8">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Participant Approaches</head><p>Universidade Nova de Lisboa (NOVASEARCH)</p><p>NovaSearch experimented with three different late-fusion approaches <ref type="bibr" coords="6,355.03,711.19,13.49,7.86" target="#b16">[16]</ref>. Duplicate documents were assumed to have Task 2: Results Merging Group ID Run ID nDCG@20 nDCG@100 P@10 ERR@20 nDCG@20(*) ERR@20(*) Results Merging -Average topic scores by run the same URL. Two runs were submitted based on existing fusion approaches, Reciprocal rank fusion (nsRRF) and Condorcet Fuse (nsCondor). In addition, they submitted a run based on their own Inverse Square Rank approach (nsISR).</p><formula xml:id="formula_1" coords="7,65.23,171.50,64.97,7.86">NOVASEARCH</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University of Padova (UPD)</head><p>UPD merged results in a round robin fashion <ref type="bibr" coords="8,254.81,122.82,9.20,7.86" target="#b7">[7]</ref>. The UPDFW13rrsh run was based on the ranking from the UPDFW13sh run, the UPDFW13rrmu run used the ranking obtained in the UPDFW13mu run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese Academy of Sciences (ICTNET)</head><p>They experimented with three different methods <ref type="bibr" coords="8,254.93,188.00,13.49,7.86" target="#b13">[13]</ref>. The ICTNETRun1 run was created by scoring documents based on BM25 and combining the scores of each field (including URL, title, main content, headings) using a linear weighting method. The ICTNETRun2 run also took the Google's pagerank score into account. ICTNETRun3 filtered documents with a low score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>University of Delaware (udel)</head><p>Their baseline run (udelRMIndri) ranked the result documents using Indri. Next, they experimented with scoring the results by multiplying the natural logarithm of the resource scores with the normalized Indri-scores of the documents based on documents (udelPgLnSc ) and snippets (udelSnLnSc)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Centrum Wiskunde &amp; Informatica (CWI)</head><p>The baseline run of CWI <ref type="bibr" coords="8,160.97,370.68,9.72,7.86" target="#b5">[5]</ref> (CWI13IndriQL) scored documents based on their query likelihood. The CWI13iaTODPJ run was developed by assuming that by diversifying documents from different resources, it is more likely that at least one type of documents (resource) will satisfy the information need. The baseline run was reranked using a diversification algorithm (IA-select). They also experimented with boosting documents from reliable resources based on the resource selection scores CWI13bstTODPJ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Indian Statistical Institute (isi_pal)</head><p>Their mergv1 run was obtained by scoring documents based on he rank of the document in the results and the score of the resource (as calculated in the resource selection task) <ref type="bibr" coords="8,53.80,519.55,13.49,7.86" target="#b18">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organizers' baseline</head><p>The organizers' baseline runs used the static rankings from the corresponding size-based resource selection baselines (RM_clueweb and RM_querypools). The results of the top 5 ranked resources were combined using a round-robin merge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>Most of the submitted and better performing runs for the results merging task make two unrealistic assumptions. Firstly, they asssume that for the given query all engine results are readily available. A more realistic scenario would be to first make a selection of a small number of promising engines, and to retrieve and rerank this set of results. Secondly, they assume that the result documents are readily available during search, whereas in a realistic scenario only the snippets would be available for real-time result merging. The few runs that do not make these assumptions and only use the top-ranked resources in combination with roundrobin merging (e.g. from team UPD and the organizer's baseline runs) perform poorly in comparison to teams who indexed and searched the query search results from all engines.</p><p>As expected, not rewarding the retrieval of duplicate pages turns out to have a strong impact on the performance metrics. However, the nDCG@20 and nDCG@20(*) scores show a strong correlation (Pearson's r = 0.91, Kendall's tau = 0.79).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SUMMARY &amp; OUTLOOK</head><p>The first edition of the Federated Web Search track attracted a total of 11 participants taking part in at least one of the two tasks: resource selection and result merging. The best performing resource selection runs were based on sample document indices in combination with standard document retrieval models. A baseline run which simply returned resources by its descending estimated size showed very competitive performance. The results merging runs were also dominated by standard retrieval approaches. Most of these runs are based on indices containing the retrieved documents from all search engines, which would be unrealistic in an online system.</p><p>Next year the same collection of search engines will be used with a new set of topics. In addition a new crawl of the samples will be made available -a comparison between the new and old samples could provide insight in the dynamics of the underlying resources and be useful for resource selection. The evaluation metrics for the tasks will be reviewed, for instance taking into account duplicate pages in resource selection. Next to the existing resource selection and results merging tasks, the track will feature a vertical selection task. In this task the systems have to rank the best vertical type for a query. What vertical types will be used is to be decided, but they will probably relate to the categories listed in Table <ref type="table" coords="8,352.86,439.70,3.58,7.86" target="#tab_2">3</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,168.67,357.88,272.38,7.89"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relevance distributions over resource categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,161.20,652.37,287.33,7.89"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of runs on the Resource Selection task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,166.59,630.78,276.54,7.89"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison of runs on the Results Merging task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,69.18,58.24,465.29,253.06"><head>Table 1 :</head><label>1</label><figDesc>Participants and number of runs for Resource Selection (RS) and Results Merging (RM).</figDesc><table coords="2,69.18,58.24,417.99,253.06"><row><cell cols="2">Group ID</cell><cell>Institute</cell><cell></cell><cell>RS runs RM runs</cell></row><row><cell cols="2">CWI</cell><cell cols="2">Centrum Wiskunde &amp; Informatica</cell><cell>3</cell><cell>3</cell></row><row><cell cols="2">ICTNET</cell><cell cols="2">Chinese Avademy of Sciences</cell><cell>3</cell></row><row><cell cols="4">IIIT Hyderabad International Institute of Information Technology</cell><cell>1</cell></row><row><cell cols="4">NOVASEARCH Universidade Nova de Lisboa</cell><cell>3</cell></row><row><cell cols="2">isi pal</cell><cell cols="2">Indian Statistical Institute</cell><cell>2</cell><cell>1</cell></row><row><cell cols="2">scunce</cell><cell cols="2">East China Normal University</cell><cell>1</cell></row><row><cell cols="2">StanfordEIG</cell><cell cols="2">Stanford University</cell><cell>1</cell></row><row><cell cols="2">udel</cell><cell cols="2">University of Delaware</cell><cell>3</cell><cell>3</cell></row><row><cell cols="2">UiS</cell><cell cols="2">University of Stavanger</cell><cell>3</cell></row><row><cell cols="2">UPD</cell><cell cols="2">University of Padova</cell><cell>2</cell><cell>2</cell></row><row><cell>ut</cell><cell></cell><cell cols="2">University of Twente</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>Total</cell><cell>Per engine</cell></row><row><cell>Samples</cell><cell>Snippets</cell><cell>1,973,591</cell><cell>12,570.6</cell></row><row><cell cols="2">(2000 queries) Pages</cell><cell>1,894,463</cell><cell>12,066.6</cell></row><row><cell></cell><cell>Size (GB)</cell><cell>177.8</cell><cell>1.13</cell></row><row><cell>Topics</cell><cell>Snippets</cell><cell>143,298</cell><cell>912.7</cell></row><row><cell>(200 queries)</cell><cell>Pages</cell><cell>136,103</cell><cell>866.9</cell></row><row><cell></cell><cell>Size (GB)</cell><cell>16.7</cell><cell>0.11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,66.96,325.98,212.80,164.71"><head>Table 2 :</head><label>2</label><figDesc>FedWeb 2013 collection statistics</figDesc><table coords="2,66.96,352.79,212.80,137.90"><row><cell>Category</cell><cell>Count</cell><cell>Category</cell><cell>Count</cell></row><row><cell>Academic</cell><cell>18</cell><cell>Local</cell><cell>1</cell></row><row><cell>Audio</cell><cell>6</cell><cell>News</cell><cell>15</cell></row><row><cell>Blogs</cell><cell>4</cell><cell>Photo/Pictures</cell><cell>13</cell></row><row><cell>Books</cell><cell>5</cell><cell>Q&amp;A</cell><cell>7</cell></row><row><cell>Encyclopedia</cell><cell>5</cell><cell>Recipes</cell><cell>5</cell></row><row><cell>Entertainment</cell><cell>4</cell><cell>Shopping</cell><cell>9</cell></row><row><cell>Games</cell><cell>6</cell><cell>Social</cell><cell>3</cell></row><row><cell>General</cell><cell>6</cell><cell>Software</cell><cell>3</cell></row><row><cell>Health</cell><cell>12</cell><cell>Sports</cell><cell>9</cell></row><row><cell>Jobs</cell><cell>5</cell><cell>Tech</cell><cell>8</cell></row><row><cell>Jokes</cell><cell>2</cell><cell>Travel</cell><cell>2</cell></row><row><cell>Kids</cell><cell>10</cell><cell>Video</cell><cell>14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="2,53.80,505.90,239.11,18.35"><head>Table 3 :</head><label>3</label><figDesc>FedWeb 2013 search engine categories (an engine can be in multiple categories)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,64.58,148.05,392.38,68.94"><head>Table 4 :</head><label>4</label><figDesc>Example XPaths for scraping snippets from result pages 1. Their normalized URLs are the same. The URL is normalized by lowercasing it, removing the www. prefix of a URL, replacing https by http, removing trailing slashes and paths ending with index.html and index.php.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="5,91.06,115.29,427.60,514.81"><head>Table 5 :</head><label>5</label><figDesc>Results for the Resource Selection task.</figDesc><table coords="5,91.06,115.29,427.60,514.81"><row><cell cols="6">Task 1: Resource Selection</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Group ID</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Run ID</cell><cell></cell><cell></cell><cell cols="11">nDCG@20 nP@1 nP@5 resources used</cell><cell></cell></row><row><cell>UPD</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">UPDFW13mu UPDFW13sh</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.299 0.247</cell><cell></cell><cell>0.16 0.12</cell><cell cols="2">0.21 0.21</cell><cell cols="3">documents documents</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>UiSP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.276</cell><cell></cell><cell>0.18</cell><cell cols="2">0.27</cell><cell cols="3">documents</cell><cell></cell><cell></cell></row><row><cell>UiS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>UiSSP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.274</cell><cell></cell><cell>0.19</cell><cell cols="2">0.29</cell><cell cols="6">snippets + documents</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>UiSS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.165</cell><cell></cell><cell>0.16</cell><cell cols="2">0.21</cell><cell cols="3">snippets</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">udelFAVE</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.244</cell><cell></cell><cell>0.20</cell><cell cols="2">0.22</cell><cell cols="3">documents</cell><cell></cell><cell></cell></row><row><cell>udel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">udelODRA</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.159</cell><cell></cell><cell>0.21</cell><cell cols="2">0.18</cell><cell cols="3">documents</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">udelRSMIN</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.053</cell><cell></cell><cell>0.06</cell><cell cols="2">0.07</cell><cell cols="3">documents</cell><cell></cell><cell></cell></row><row><cell>ut</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">utTailyM400 utTailyNormM400</cell><cell></cell><cell cols="2">0.216 0.214</cell><cell></cell><cell>0.17 0.20</cell><cell cols="2">0.23 0.23</cell><cell cols="3">documents documents</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">cwi13SniTI</cell><cell></cell><cell></cell><cell cols="2">0.123</cell><cell></cell><cell>0.10</cell><cell cols="2">0.19</cell><cell cols="3">snippets</cell><cell></cell><cell></cell></row><row><cell>CWI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">cwi130DPTI</cell><cell></cell><cell></cell><cell cols="2">0.096</cell><cell></cell><cell>0.14</cell><cell cols="2">0.16</cell><cell cols="4">snippets + ODP</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">cwi130DPJac</cell><cell></cell><cell></cell><cell cols="2">0.050</cell><cell></cell><cell>0.06</cell><cell cols="2">0.09</cell><cell cols="2">ODP</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">III Hyderabad</cell><cell></cell><cell></cell><cell cols="3">iiitnaive01</cell><cell></cell><cell></cell><cell cols="2">0.107</cell><cell></cell><cell>0.13</cell><cell cols="2">0.17</cell><cell cols="6">snippets, Wikipedia, WordNet</cell></row><row><cell>scunce</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ECNUBM25</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.105</cell><cell></cell><cell>0.07</cell><cell cols="2">0.10</cell><cell cols="6">snippets, Google search</cell></row><row><cell>isi pal</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">incgqdv2 incgqd</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.037 0.025</cell><cell></cell><cell>0.11 0.09</cell><cell cols="2">0.06 0.03</cell><cell cols="4">GoogleQuery GoogleQuery</cell><cell></cell></row><row><cell cols="3">StanfordEIG</cell><cell></cell><cell></cell><cell cols="4">StanfordEIG10</cell><cell></cell><cell cols="2">0.018</cell><cell></cell><cell>0.07</cell><cell cols="2">0.02</cell><cell cols="3">documents</cell><cell></cell><cell></cell></row><row><cell cols="5">organizers (baselines)</cell><cell cols="4">RS_clueweb RS_querypools</cell><cell></cell><cell cols="2">0.298 0.185</cell><cell></cell><cell>0.00 0.07</cell><cell cols="2">0.32 0.10</cell><cell cols="3">snippets</cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NDCG@20</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>UPDFW13mu</cell><cell>RS_clueweb</cell><cell>UiSP</cell><cell>UiSSP</cell><cell>UPDFW13sh</cell><cell>udelFAVE</cell><cell>utTailyM400</cell><cell>utTailyNormM400</cell><cell>RS_querypools</cell><cell>UiSS</cell><cell>udelODRA</cell><cell>cwi13SniTI</cell><cell>iiitnaive01</cell><cell>ECNUBM25</cell><cell>cwi13ODPTI</cell><cell>udelRSMIN</cell><cell>cwi13ODPJac</cell><cell>incgqdv2</cell><cell>incgqd</cell><cell>StanfordEIG10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,65.23,161.04,465.76,447.67"><head>Table 6 :</head><label>6</label><figDesc>Results for the Results Merging task.</figDesc><table coords="7,65.23,161.04,465.76,447.67"><row><cell></cell><cell></cell><cell></cell><cell cols="2">nsRRF</cell><cell></cell><cell></cell><cell>0.257</cell><cell></cell><cell></cell><cell>0.255</cell><cell></cell><cell>0.370</cell><cell></cell><cell>0.254</cell><cell></cell><cell cols="2">0.439</cell><cell>0.428</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">nsISR</cell><cell></cell><cell></cell><cell>0.165</cell><cell></cell><cell></cell><cell>0.199</cell><cell></cell><cell>0.310</cell><cell></cell><cell>0.166</cell><cell></cell><cell cols="2">0.287</cell><cell>0.285</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">nsCondor</cell><cell></cell><cell></cell><cell>0.135</cell><cell></cell><cell></cell><cell>0.199</cell><cell></cell><cell>0.278</cell><cell></cell><cell>0.133</cell><cell></cell><cell cols="2">0.174</cell><cell>0.171</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">ICTNETRun2</cell><cell></cell><cell>0.223</cell><cell></cell><cell></cell><cell>0.341</cell><cell></cell><cell>0.414</cell><cell></cell><cell>0.213</cell><cell></cell><cell cols="2">0.290</cell><cell>0.274</cell></row><row><cell>ICTNET</cell><cell></cell><cell></cell><cell cols="3">ICTNETRun3</cell><cell></cell><cell>0.223</cell><cell></cell><cell></cell><cell>0.322</cell><cell></cell><cell>0.414</cell><cell></cell><cell>0.213</cell><cell></cell><cell cols="2">0.290</cell><cell>0.273</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">ICTNETRun1</cell><cell></cell><cell>0.216</cell><cell></cell><cell></cell><cell>0.329</cell><cell></cell><cell>0.396</cell><cell></cell><cell>0.206</cell><cell></cell><cell cols="2">0.286</cell><cell>0.270</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">udelRMIndri</cell><cell></cell><cell>0.200</cell><cell></cell><cell></cell><cell>0.369</cell><cell></cell><cell>0.332</cell><cell></cell><cell>0.190</cell><cell></cell><cell cols="2">0.366</cell><cell>0.347</cell></row><row><cell>udel</cell><cell></cell><cell></cell><cell cols="3">udelSnLnSc</cell><cell></cell><cell>0.161</cell><cell></cell><cell></cell><cell>0.257</cell><cell></cell><cell>0.318</cell><cell></cell><cell>0.159</cell><cell></cell><cell cols="2">0.255</cell><cell>0.251</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">udelPgLnSc</cell><cell></cell><cell>0.154</cell><cell></cell><cell></cell><cell>0.234</cell><cell></cell><cell>0.318</cell><cell></cell><cell>0.151</cell><cell></cell><cell cols="2">0.252</cell><cell>0.244</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">CWI13IndriQL</cell><cell></cell><cell>0.162</cell><cell></cell><cell></cell><cell>0.332</cell><cell></cell><cell>0.322</cell><cell></cell><cell>0.154</cell><cell></cell><cell cols="2">0.247</cell><cell>0.236</cell></row><row><cell>CWI</cell><cell></cell><cell></cell><cell cols="3">CWI13iaTODPJ</cell><cell></cell><cell>0.151</cell><cell></cell><cell></cell><cell>0.281</cell><cell></cell><cell>0.284</cell><cell></cell><cell>0.147</cell><cell></cell><cell cols="2">0.205</cell><cell>0.200</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">CWI13bstTODPJ</cell><cell></cell><cell>0.147</cell><cell></cell><cell></cell><cell>0.240</cell><cell></cell><cell>0.250</cell><cell></cell><cell>0.144</cell><cell></cell><cell cols="2">0.230</cell><cell>0.225</cell></row><row><cell>UPD</cell><cell></cell><cell></cell><cell cols="3">UPDFW13rrmu UPDFW13rrsh</cell><cell></cell><cell>0.135 0.129</cell><cell></cell><cell></cell><cell>0.170 0.171</cell><cell></cell><cell>0.254 0.254</cell><cell></cell><cell>0.133 0.127</cell><cell></cell><cell cols="2">0.231 0.222</cell><cell>0.228 0.219</cell></row><row><cell>isi pal</cell><cell></cell><cell></cell><cell cols="2">merv1</cell><cell></cell><cell></cell><cell>0.081</cell><cell></cell><cell></cell><cell>0.108</cell><cell></cell><cell>0.150</cell><cell></cell><cell>0.081</cell><cell></cell><cell cols="2">0.132</cell><cell>0.131</cell></row><row><cell cols="3">organizers (baselines)</cell><cell cols="3">RM_clueweb RM_querypools</cell><cell></cell><cell>0.142 0.064</cell><cell></cell><cell></cell><cell>0.260 0.196</cell><cell></cell><cell>0.262 0.186</cell><cell></cell><cell>0.140 0.063</cell><cell></cell><cell cols="2">0.167 0.060</cell><cell>0.164 0.058</cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NDCG@20</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>nsRRF</cell><cell>ICTNETRun2</cell><cell>ICTNETRun3</cell><cell>ICTNETRun1</cell><cell>udelRMIndri</cell><cell>nsISR</cell><cell>CWI13IndriQL</cell><cell>udelSnLnSc</cell><cell>udelPgLnSc</cell><cell>CWI13iaTODPJ</cell><cell>CWI13bstTODPJ</cell><cell>RM_clueweb</cell><cell>nsCondor</cell><cell>UPDFW13rrmu</cell><cell>UPDFW13rrsh</cell><cell>mergv1</cell><cell>RM_querypools</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="8,356.44,439.70,3.58,7.86"><head></head><label></label><figDesc>.</figDesc><table coords="10,53.80,55.51,452.95,613.91"><row><cell cols="2">APPENDIX</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">A. FEDWEB 2013 SEARCH ENGINES</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ID</cell><cell>Name</cell><cell>Categories</cell><cell>ID</cell><cell>Name</cell><cell>Categories</cell></row><row><cell>e001</cell><cell>arXiv.org</cell><cell>Academic</cell><cell>e099</cell><cell>Bing News</cell><cell>News</cell></row><row><cell>e002</cell><cell>CCSB</cell><cell>Academic</cell><cell>e100</cell><cell>Chronicling America</cell><cell>News</cell></row><row><cell>e003</cell><cell>CERN Documents</cell><cell>Academic</cell><cell>e101</cell><cell>CNN</cell><cell>News</cell></row><row><cell>e004</cell><cell>CiteSeerX</cell><cell>Academic</cell><cell>e102</cell><cell>Forbes</cell><cell>News</cell></row><row><cell>e005</cell><cell>CiteULike</cell><cell>Academic</cell><cell>e103</cell><cell>Google News</cell><cell>News</cell></row><row><cell>e006</cell><cell>Economists Online</cell><cell>Academic</cell><cell>e104</cell><cell>JSOnline</cell><cell>News</cell></row><row><cell>e007</cell><cell>eScholarship</cell><cell>Academic</cell><cell>e106</cell><cell>Slate</cell><cell>News</cell></row><row><cell>e008</cell><cell>KFUPM ePrints</cell><cell>Academic</cell><cell>e107</cell><cell>The Guardian</cell><cell>News</cell></row><row><cell>e009</cell><cell>MPRA</cell><cell>Academic</cell><cell>e108</cell><cell>The Street</cell><cell>News</cell></row><row><cell>e010</cell><cell>MS Academic</cell><cell>Academic</cell><cell>e109</cell><cell>Washington post</cell><cell>News</cell></row><row><cell>e011</cell><cell>Nature</cell><cell>Academic</cell><cell>e110</cell><cell>HNSearch</cell><cell>News,Tech</cell></row><row><cell>e012</cell><cell>Organic Eprints</cell><cell>Academic</cell><cell>e111</cell><cell>Slashdot</cell><cell>News,Tech</cell></row><row><cell>e013</cell><cell>SpringerLink</cell><cell>Academic</cell><cell>e112</cell><cell>The Register</cell><cell>News,Tech</cell></row><row><cell>e014</cell><cell>U. Twente</cell><cell>Academic</cell><cell>e113</cell><cell>DeviantArt</cell><cell>Photo/Pictures</cell></row><row><cell>e015</cell><cell>UAB Digital</cell><cell>Academic</cell><cell>e114</cell><cell>Flickr</cell><cell>Photo/Pictures</cell></row><row><cell>e016</cell><cell>UQ eSpace</cell><cell>Academic</cell><cell>e115</cell><cell>Fotolia</cell><cell>Photo/Pictures</cell></row><row><cell>e017</cell><cell>PubMed</cell><cell>Academic,Health</cell><cell>e117</cell><cell>Getty Images</cell><cell>Photo/Pictures</cell></row><row><cell>e018</cell><cell>LastFM</cell><cell>Audio</cell><cell>e118</cell><cell>IconFinder</cell><cell>Photo/Pictures</cell></row><row><cell>e019</cell><cell>LYRICSnMUSIC</cell><cell>Audio</cell><cell>e119</cell><cell>NYPL Gallery</cell><cell>Photo/Pictures</cell></row><row><cell>e020</cell><cell>Comedy Central</cell><cell>Audio,Video</cell><cell>e120</cell><cell>OpenClipArt</cell><cell>Photo/Pictures</cell></row><row><cell>e021</cell><cell>Dailymotion</cell><cell>Audio,Video</cell><cell>e121</cell><cell>Photobucket</cell><cell>Photo/Pictures</cell></row><row><cell>e022</cell><cell>YouTube</cell><cell>Audio,Video</cell><cell>e122</cell><cell>Picasa</cell><cell>Photo/Pictures</cell></row><row><cell>e023</cell><cell>Google Blogs</cell><cell>Blogs</cell><cell>e123</cell><cell>Picsearch</cell><cell>Photo/Pictures</cell></row><row><cell>e024</cell><cell>LinkedIn Blog</cell><cell>Blogs</cell><cell>e124</cell><cell>Wikimedia</cell><cell>Photo/Pictures</cell></row><row><cell>e025</cell><cell>Tumblr</cell><cell>Blogs</cell><cell>e126</cell><cell>Funny or Die</cell><cell>Video,Photo/Pictures</cell></row><row><cell>e026</cell><cell>WordPress</cell><cell>Blogs</cell><cell>e127</cell><cell>4Shared</cell><cell>Audio,Video,Books,Photo/Pictures</cell></row><row><cell>e027</cell><cell>Columbus Library</cell><cell>Books</cell><cell>e128</cell><cell>AllExperts</cell><cell>Q&amp;A</cell></row><row><cell>e028</cell><cell>Goodreads</cell><cell>Books</cell><cell>e129</cell><cell>Answers.com</cell><cell>Q&amp;A</cell></row><row><cell>e029</cell><cell>Google Books</cell><cell>Books</cell><cell>e130</cell><cell>Chacha</cell><cell>Q&amp;A</cell></row><row><cell>e030</cell><cell>NCSU Library</cell><cell>Books</cell><cell>e131</cell><cell>StackOverflow</cell><cell>Q&amp;A</cell></row><row><cell>e032</cell><cell>IMDb</cell><cell>Encyclopedia</cell><cell>e132</cell><cell>Yahoo Answers</cell><cell>Q&amp;A</cell></row><row><cell>e033</cell><cell>Wikibooks</cell><cell>Encyclopedia</cell><cell>e133</cell><cell>MetaOptimize</cell><cell>Academic,Q&amp;A</cell></row><row><cell>e034</cell><cell>Wikipedia</cell><cell>Encyclopedia</cell><cell>e134</cell><cell>HowStuffWorks</cell><cell>Kids,Q&amp;A</cell></row><row><cell>e036</cell><cell>Wikispecies</cell><cell>Encyclopedia</cell><cell>e135</cell><cell>AllRecipes</cell><cell>Recipes</cell></row><row><cell>e037</cell><cell>Wiktionary</cell><cell>Encyclopedia</cell><cell>e136</cell><cell>Cooking.com</cell><cell>Recipes</cell></row><row><cell>e038</cell><cell>E? Online</cell><cell>Entertainment</cell><cell>e137</cell><cell>Food Network</cell><cell>Recipes</cell></row><row><cell>e039</cell><cell>Entertainment Weekly</cell><cell>Entertainment</cell><cell>e138</cell><cell>Food.com</cell><cell>Recipes</cell></row><row><cell>e041</cell><cell>TMZ</cell><cell>Entertainment</cell><cell>e139</cell><cell>Meals.com</cell><cell>Recipes</cell></row><row><cell>e042</cell><cell>The Sun</cell><cell>Entertainment,Sports,News</cell><cell>e140</cell><cell>Amazon</cell><cell>Shopping</cell></row><row><cell>e043</cell><cell>Addicting games</cell><cell>Games</cell><cell>e141</cell><cell>ASOS</cell><cell>Shopping</cell></row><row><cell>e044</cell><cell>Amorgames</cell><cell>Games</cell><cell>e142</cell><cell>Craigslist</cell><cell>Shopping</cell></row><row><cell>e045</cell><cell>Crazy monkey games</cell><cell>Games</cell><cell>e143</cell><cell>eBay</cell><cell>Shopping</cell></row><row><cell>e047</cell><cell>GameNode</cell><cell>Games</cell><cell>e144</cell><cell>Overstock</cell><cell>Shopping</cell></row><row><cell>e048</cell><cell>Games.com</cell><cell>Games</cell><cell>e145</cell><cell>Powell's</cell><cell>Shopping</cell></row><row><cell>e049</cell><cell>Miniclip</cell><cell>Games</cell><cell>e146</cell><cell>Pronto</cell><cell>Shopping</cell></row><row><cell>e050</cell><cell>About.com</cell><cell>General</cell><cell>e147</cell><cell>Target</cell><cell>Shopping</cell></row><row><cell>e052</cell><cell>Ask</cell><cell>General</cell><cell>e148</cell><cell>Yahoo? Shopping</cell><cell>Shopping</cell></row><row><cell>e055</cell><cell>CMU ClueWeb</cell><cell>General</cell><cell>e152</cell><cell>Myspace</cell><cell>Social</cell></row><row><cell>e057</cell><cell>Gigablast</cell><cell>General</cell><cell>e153</cell><cell>Reddit</cell><cell>Social</cell></row><row><cell>e062</cell><cell>Baidu</cell><cell>General</cell><cell>e154</cell><cell>Tweepz</cell><cell>Social</cell></row><row><cell>e063</cell><cell>CDC</cell><cell>Health</cell><cell>e156</cell><cell>Cnet</cell><cell>Software</cell></row><row><cell>e064</cell><cell>Family Practice notebook</cell><cell>Health</cell><cell>e157</cell><cell>GitHub</cell><cell>Software</cell></row><row><cell>e065</cell><cell>Health Finder</cell><cell>Health</cell><cell>e158</cell><cell>SourceForge</cell><cell>Software</cell></row><row><cell>e066</cell><cell>HealthCentral</cell><cell>Health</cell><cell>e159</cell><cell>bleacher report</cell><cell>Sports</cell></row><row><cell>e067</cell><cell>HealthLine</cell><cell>Health</cell><cell>e160</cell><cell>ESPN</cell><cell>Sports</cell></row><row><cell>e068</cell><cell>Healthlinks.net</cell><cell>Health</cell><cell>e161</cell><cell>Fox Sports</cell><cell>Sports</cell></row><row><cell>e070</cell><cell>Mayo Clinic</cell><cell>Health</cell><cell>e162</cell><cell>NBA</cell><cell>Sports</cell></row><row><cell>e071</cell><cell>MedicineNet</cell><cell>Health</cell><cell>e163</cell><cell>NHL</cell><cell>Sports</cell></row><row><cell>e072</cell><cell>MedlinePlus</cell><cell>Health</cell><cell>e164</cell><cell>SB nation</cell><cell>Sports</cell></row><row><cell>e075</cell><cell>U. of Iowa hospitals and clinics</cell><cell>Health</cell><cell>e165</cell><cell>Sporting news</cell><cell>Sports</cell></row><row><cell>e076</cell><cell>WebMD</cell><cell>Health</cell><cell>e166</cell><cell>WWE</cell><cell>Sports</cell></row><row><cell>e077</cell><cell>Glassdoor</cell><cell>Jobs</cell><cell>e167</cell><cell>Ars Technica</cell><cell>Tech</cell></row><row><cell>e078</cell><cell>Jobsite</cell><cell>Jobs</cell><cell>e168</cell><cell>CNET</cell><cell>Tech</cell></row><row><cell>e079</cell><cell>LinkedIn Jobs</cell><cell>Jobs</cell><cell>e169</cell><cell>Technet</cell><cell>Tech</cell></row><row><cell>e080</cell><cell>Simply Hired</cell><cell>Jobs</cell><cell>e170</cell><cell>Technorati</cell><cell>Tech</cell></row><row><cell>e081</cell><cell>USAJobs</cell><cell>Jobs</cell><cell>e171</cell><cell>TechRepublic</cell><cell>Tech</cell></row><row><cell>e082</cell><cell>Comedy Central Jokes.com</cell><cell>Jokes</cell><cell>e172</cell><cell>TripAdvisor</cell><cell>Travel</cell></row><row><cell>e083</cell><cell>Kickass jokes</cell><cell>Jokes</cell><cell>e173</cell><cell>Wiki Travel</cell><cell>Travel</cell></row><row><cell>e085</cell><cell>Cartoon Network</cell><cell>Kids</cell><cell>e174</cell><cell>5min.com</cell><cell>Video</cell></row><row><cell>e086</cell><cell>Disney Family</cell><cell>Kids</cell><cell>e175</cell><cell>AOL Video</cell><cell>Video</cell></row><row><cell>e087</cell><cell>Factmonster</cell><cell>Kids</cell><cell>e176</cell><cell>Google Videos</cell><cell>Video</cell></row><row><cell>e088</cell><cell>Kidrex</cell><cell>Kids</cell><cell>e178</cell><cell>MeFeedia</cell><cell>Video</cell></row><row><cell>e089</cell><cell>KidsClicks?</cell><cell>Kids</cell><cell>e179</cell><cell>Metacafe</cell><cell>Video</cell></row><row><cell>e090</cell><cell>Nick jr</cell><cell>Kids</cell><cell>e181</cell><cell>National geographic</cell><cell>Video</cell></row><row><cell>e091</cell><cell>Nickelodeon</cell><cell>Kids</cell><cell>e182</cell><cell>Veoh</cell><cell>Video</cell></row><row><cell>e092</cell><cell>OER Commons</cell><cell>Kids</cell><cell>e184</cell><cell>Vimeo</cell><cell>Video</cell></row><row><cell>e093</cell><cell>Quintura Kids</cell><cell>Kids</cell><cell>e185</cell><cell>Yahoo Screen</cell><cell>Video</cell></row><row><cell>e095</cell><cell>Foursquare</cell><cell>Local</cell><cell>e200</cell><cell>BigWeb</cell><cell>General</cell></row><row><cell>e098</cell><cell>BBC</cell><cell>News</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.42,711.83,117.47,7.47"><p>http://snipdex.org/fedweb</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,321.42,711.83,98.68,7.47"><p>http://seleniumhq.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,321.42,702.87,211.93,7.47;3,316.81,711.83,66.78,7.47"><p>http://research.microsoft.com/en-us/projects/ trec-web-2013/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,58.40,711.83,159.75,7.47"><p>http://lemurproject.org/clueweb09/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">ACKNOWLEDGMENTS</head><p>This work was funded by The <rs type="funder">Netherlands Organization for Scientific Research, NWO</rs>, grant <rs type="grantNumber">639.022.809</rs>, by the <rs type="funder">Folktales As Classifiable Texts (FACT)</rs> project in The Netherlands, by the <rs type="funder">Dutch</rs> national project <rs type="projectName">COMMIT</rs>, and by <rs type="funder">Ghent University -iMinds in Belgium</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qkapKA2">
					<idno type="grant-number">639.022.809</idno>
				</org>
				<org type="funded-project" xml:id="_gvdvhNd">
					<orgName type="project" subtype="full">COMMIT</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,58.28,55.51,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,79.06,165.21,7.86;9,72.59,89.52,200.97,7.86;9,72.59,99.98,204.30,7.86;9,72.59,110.44,109.35,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,132.40,89.52,125.47,7.86">Mirex and Taily at TREC 2013</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,72.59,99.98,204.30,7.86;9,72.59,110.44,80.16,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,121.90,211.64,7.86;9,72.59,132.36,216.28,7.86;9,72.59,142.82,146.15,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,277.32,121.90,6.91,7.86;9,72.59,132.36,212.69,7.86">A methodology for evaluating aggregated search results</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,84.09,142.82,43.44,7.86">ECIR 2011</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,154.27,197.97,7.86;9,72.59,164.73,205.23,7.86;9,72.59,175.20,108.29,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,72.59,164.73,160.90,7.86">Sources of evidence for vertical selection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-F</forename><surname>Crespo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,251.74,164.73,26.09,7.86;9,72.59,175.20,17.08,7.86">SIGIR 2009</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="315" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,186.65,211.33,7.86;9,72.59,197.11,216.61,7.86;9,72.59,207.57,198.45,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,113.87,186.65,170.05,7.86;9,72.59,197.11,83.17,7.86">Collection and document language models for resource selection</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,174.01,197.11,115.20,7.86;9,72.59,207.57,169.26,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,219.03,220.32,7.86;9,72.59,229.49,214.45,7.86;9,72.59,239.95,215.00,7.86;9,72.59,250.41,190.30,7.86;9,72.59,260.87,204.30,7.86;9,72.59,271.34,109.35,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,267.60,229.49,19.44,7.86;9,72.59,239.95,215.00,7.86;9,72.59,250.41,174.99,7.86">CWI and TU Delft at TREC 2013: Contextual suggestion, federated web search, KBA, and web tracks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bellogín</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Gebremeskel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Samar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B P</forename><surname>Vuurens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,72.59,260.87,204.30,7.86;9,72.59,271.34,80.16,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,282.79,197.07,7.86;9,72.59,293.25,219.59,7.86;9,72.59,303.71,209.64,7.86;9,72.59,314.17,108.29,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,102.76,303.71,135.65,7.86">Estimating corpus size via queries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fontura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Josifovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nabar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Panigrahy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,256.77,303.71,25.45,7.86;9,72.59,314.17,17.08,7.86">CIKM 2006</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="594" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,325.63,212.98,7.86;9,72.59,336.09,214.53,7.86;9,72.59,346.55,215.80,7.86;9,72.59,357.01,109.35,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,244.31,325.63,41.26,7.86;9,72.59,336.09,210.69,7.86">University of Padua at TREC 2013: federated web search track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Buccio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Masiero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,84.09,346.55,204.30,7.86;9,72.59,357.01,80.16,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,368.47,206.93,7.86;9,72.59,378.93,209.58,7.86;9,72.59,389.39,49.58,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,232.84,368.47,46.68,7.86;9,72.59,378.93,116.89,7.86">Learning to Rank using Gradient Descent</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,208.29,378.93,44.51,7.86">ICML 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,400.85,187.55,7.86;9,72.59,411.31,209.58,7.86;9,72.59,421.77,185.35,7.86;9,72.59,432.23,98.19,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,114.14,400.85,130.95,7.86">Distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,72.59,411.31,137.31,7.86">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="127" to="150" />
		</imprint>
	</monogr>
	<note>chapter 5</note>
</biblStruct>

<biblStruct coords="9,72.59,443.69,213.91,7.86;9,72.59,454.15,198.92,7.86;9,72.59,464.61,130.46,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,72.59,454.15,183.51,7.86">Expected reciprocal rank for graded relevance</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metlzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Grinspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,72.59,464.61,39.82,7.86">CIKM &apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="621" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,476.07,216.75,7.86;9,72.59,486.53,211.46,7.86;9,72.59,496.99,20.96,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,138.08,476.07,151.26,7.86;9,72.59,486.53,79.84,7.86">Similarity estimation techniques from rounding algorithms</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Charikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,171.09,486.53,45.77,7.86">STOC 2002</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="380" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,508.45,169.34,7.86;9,72.59,518.91,200.73,7.86;9,72.59,529.37,209.90,7.86;9,72.59,539.83,83.88,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,198.51,518.91,74.81,7.86;9,72.59,529.37,144.53,7.86">What snippets say about pages in federated web search</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Develder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,235.60,529.37,42.63,7.86">AIRS 2012</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="250" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,551.29,193.07,7.86;9,72.59,561.75,193.56,7.86;9,72.59,572.21,204.30,7.86;9,72.59,582.67,109.35,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,72.59,561.75,177.87,7.86">ICTNET at federated web search track 2013</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,72.59,572.21,204.30,7.86;9,72.59,582.67,80.16,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,594.12,217.29,7.86;9,72.59,604.59,213.71,7.86;9,72.59,615.05,20.96,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,190.25,594.12,99.63,7.86;9,72.59,604.59,90.78,7.86">Server selection methods in hybrid portal search</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,181.85,604.59,46.46,7.86">SIGIR 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,626.50,181.96,7.86;9,72.59,636.96,209.48,7.86;9,72.59,647.42,202.28,7.86;9,72.59,657.89,145.44,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,198.93,626.50,55.63,7.86;9,72.59,636.96,160.88,7.86">Using Graded Relevance Assessments in IR Evaluation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,240.71,636.96,41.36,7.86;9,72.59,647.42,202.28,7.86;9,72.59,657.89,42.08,7.86">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1120" to="1129" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.59,669.34,220.32,7.86;9,72.59,679.80,171.97,7.86;9,72.59,690.26,208.73,7.86;9,72.59,700.73,217.69,7.86;9,72.59,711.19,20.96,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,246.34,669.34,46.57,7.86;9,72.59,679.80,171.97,7.86;9,72.59,690.26,118.47,7.86">NovaSearch at TREC 2013 federated web search track: Experiments with rank fusion</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mourão</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Magalhães</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,209.39,690.26,71.93,7.86;9,72.59,700.73,212.52,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,335.60,57.64,187.23,7.86;9,335.61,68.10,188.37,7.86;9,335.61,78.56,213.20,7.86;9,335.61,89.02,146.24,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,390.53,68.10,133.44,7.86;9,335.61,78.56,197.73,7.86">Federated search in the wild: the combined power of over a hundred search engines</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,335.61,89.02,45.82,7.86">CIKM 2012</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1874" to="1878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,335.60,100.48,219.16,7.86;9,335.61,110.94,190.48,7.86;9,335.61,121.40,156.95,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,424.85,100.48,129.91,7.86;9,335.61,110.94,15.39,7.86">ISI at the TREC 2013 federated task</title>
		<author>
			<persName coords=""><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,369.39,110.94,156.70,7.86;9,335.61,121.40,127.76,7.86">Proceedings of the 22nd Text REtrieval Conference Proceedings (TREC)</title>
		<meeting>the 22nd Text REtrieval Conference Proceedings (TREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,335.60,132.85,218.62,7.86;9,335.61,143.32,220.31,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,432.09,132.85,66.12,7.86">Federated search</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shokouhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,505.20,132.85,49.02,7.86;9,335.61,143.32,145.08,7.86">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="102" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,335.60,154.77,207.15,7.86;9,335.61,165.23,212.30,7.86;9,335.61,175.69,182.90,7.86;9,335.61,186.15,216.21,7.86;9,335.61,196.62,99.15,7.86" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="9,335.61,165.23,208.39,7.86">Ranking XPaths for extracting search result records</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tjin-Kam-Jet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<idno>TR-CTIT-12-08</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Enschede</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Centre for Telematics and Information Technology, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="9,335.60,208.07,207.15,7.86;9,335.61,218.53,210.83,7.86;9,335.61,228.99,146.87,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,335.61,218.53,195.53,7.86">SearchResultFinder: Federated search made easy</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tjin-Kam-Jet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,335.61,228.99,46.45,7.86">SIGIR 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1113" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
