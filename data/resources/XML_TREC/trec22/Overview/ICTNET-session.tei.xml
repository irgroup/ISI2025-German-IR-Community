<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,183.60,83.51,227.76,12.22">ICTNET at Session Track TREC 2013</title>
				<funder ref="#_MggkYVN">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_EMQs8Tg">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder ref="#_weTwXvD">
					<orgName type="full">National Key Technology R&amp;D Program</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,183.60,83.51,227.76,12.22">ICTNET at Session Track TREC 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">16CF36462C9E6B7658545532FC4A8B62</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe our solutions to the Session Track at TREC 2013. There are three main differences compared to our last year's submission <ref type="bibr" coords="1,290.24,232.69,12.63,8.85">[2]</ref>. Firstly, we use Indri[3] to build our retrieval system. Due to computing resource limited, we only index the Category B collection. Secondly, we try to take advantage of FreeBase <ref type="bibr" coords="1,208.70,263.89,13.29,8.85">[4]</ref> to recognize the entities in the given query and then weight each term or phrase accordingly. Lastly, we discard the Google virtual document and page rank features from our last year's learning to rank model. The rest of this paper is organized as follows.We detail our research structure in section 2. Section 3 describes our experiments and evaluation results. Conclusions are made in the last section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indri</head><p>We use Indri to index the Clueweb12 Category B collection. The default query model for the current query in the session is calculated as (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Spam Filter</head><p>We use Waterloo spam ranking score <ref type="bibr" coords="2,248.18,139.09,11.73,8.85" target="#b1">[5]</ref> to filter documents with "fusion" spam score [6] less than 60%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning to Rank</head><p>We implement the <ref type="bibr" coords="2,213.12,194.05,11.76,8.85" target="#b2">[7]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Expansion</head><p>Our query expansion uses the historical queries and the current query to construct the indri query. Let to stand for previous queries and stands for the current query, then denotes the weight of the word w in indri query q, calculating as (2).</p><p>(2)</p><p>In our experiments, we set λ as 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Freebase Weighted</head><p>Given a query q, we get unigram, bigram, 3-gram and 4-gram phrases as the entity candidates. Then we use Freebase API to query with each candidate and get the first ten results. For unigram candidates, if there is a result's notable id contains "location" and "country" or "location" and "citytown", we add it to the entity set . For other candidates, if there is a result's name equal to the given candidate, we add it to the entity set . Finally, the query model with Freebase Weighted is estimated as follows.</p><p>In our experiments, we set λ=0.7, =0.2, =0.5, =0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Novelty Filter</head><p>We filter documents that had been shown in previous queries of the session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we firstly introduce the preprocess we apply to clean the session data. Then we will</p><p>discuss the evaluation results on TREC 2013 Session Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Session Data Preprocess</head><p>For historical queries in the same session, if the edit distance between and is not greater than one, then we discard the interaction with fewer clicks. If two interactions have same clicks we discard the previous. For historical interactions in the same session, if they share the same results, then we discard the interaction with fewer clicks. If two interactions have same clicks we discard the previous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3Evaluation Results</head><p>Evaluation results of our submissions at TREC 2013 Session Track are showed in Table <ref type="table" coords="3,450.46,295.09,4.64,8.85" target="#tab_2">3</ref>.The highest score for each experimental condition is indicated in bold. According to Table <ref type="table" coords="3,443.42,310.69,3.78,8.85" target="#tab_2">3</ref>, we observe consistentlyimprove as last year's results. We obtain 42.65% of performance increase when we compare ICTNET13SER1.RL2 with ICTNET13SER1.RL1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we detail our work at TREC 2013 Session Track. The evaluation results show that our approaches can significantly improve the effectiveness of the search results. Though, it is still far away to outperform the state-of-the art. For the future work, we will focus on using Freebase more effectively to understand user's behavior and intent in the search session.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,90.00,357.49,386.16,326.37"><head></head><label></label><figDesc>Our research structure of TREC 2013 Session Track is listed in table 1.</figDesc><table coords="1,90.00,373.09,386.16,310.77"><row><cell></cell><cell cols="2">Table 1: Methods of submitted runs</cell></row><row><cell></cell><cell>RL1</cell><cell>RL2</cell><cell>RL3</cell></row><row><cell></cell><cell></cell><cell>Indri</cell><cell>Indri</cell></row><row><cell cols="2">ICTNET13SER1 Indri</cell><cell>SpamFilter</cell><cell>SpamFilter</cell></row><row><cell></cell><cell>SpamFilter</cell><cell></cell><cell>Query Expansion</cell></row><row><cell></cell><cell></cell><cell>Indri</cell><cell>Indri</cell></row><row><cell></cell><cell>Indri</cell><cell>SpamFilter</cell><cell>SpamFilter</cell></row><row><cell>ICTNET13SER2</cell><cell>SpamFilter</cell><cell></cell><cell>Query Expansion</cell></row><row><cell></cell><cell>Freebase Weighted</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Freebase Weighted</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Freebase Weighted</cell></row><row><cell></cell><cell></cell><cell>Indri</cell><cell>Indri</cell></row><row><cell></cell><cell>Indri</cell><cell>SpamFilter</cell><cell>SpamFilter</cell></row><row><cell>ICTNET13SER3</cell><cell>SpamFilter</cell><cell></cell><cell>Query Expansion</cell></row><row><cell></cell><cell>Freebase Weighted</cell><cell></cell></row><row><cell></cell><cell>NoveltyFilter</cell><cell>Freebase Weighted</cell></row><row><cell></cell><cell></cell><cell>NoveltyFilter</cell><cell>Freebase Weighted</cell></row><row><cell></cell><cell></cell><cell></cell><cell>NoveltyFilter</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,90.00,194.05,415.17,158.61"><head></head><label></label><figDesc>to learn from explicit relevance judgments on TREC 2011 Session Track. Used features are listed in table 2. Detail about each feature please referred to [2].</figDesc><table coords="2,90.00,240.85,345.98,111.81"><row><cell></cell><cell>Table 2: Features Used in</cell></row><row><cell>Feature</cell><cell>Feature Description</cell></row><row><cell>QE</cell><cell>the score of Query Expansion Model</cell></row><row><cell>SessionVD</cell><cell>the score of Session Virtual Document Model</cell></row><row><cell>CAT</cell><cell>the score of Optimization Based on User's Attention Time Model</cell></row><row><cell>CosSimQT</cell><cell>cosine similarity between query and title</cell></row><row><cell>BM25QC</cell><cell>BM25 score between query and content</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,120.24,357.49,305.50,73.51"><head>Table 3 :</head><label>3</label><figDesc>Results on 2012 Session Track, in terms of NDCG@10</figDesc><table coords="3,120.24,374.05,301.31,56.95"><row><cell></cell><cell>RL1</cell><cell>RL2</cell><cell>RL3</cell></row><row><cell>ICTNET13SER1</cell><cell>0.1170</cell><cell>0.1669</cell><cell>0.1659</cell></row><row><cell>ICTNET13SER2</cell><cell>0.1179</cell><cell>0.1670</cell><cell>0.1649</cell></row><row><cell>ICTNET13SER3</cell><cell>0.1179</cell><cell>0.1617</cell><cell>0.1608</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgements</head><p>We would like to thank all organizers and assessors of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is sponsored by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">61100083&amp;61272536</rs>, and by <rs type="programName">242 Program</rs> of China Grants No. <rs type="grantNumber">2012F124</rs>, and by the <rs type="funder">National Key Technology R&amp;D Program</rs> (<rs type="grantNumber">2012BAH39B04</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EMQs8Tg">
					<idno type="grant-number">61100083&amp;61272536</idno>
					<orgName type="program" subtype="full">242 Program</orgName>
				</org>
				<org type="funding" xml:id="_weTwXvD">
					<idno type="grant-number">2012F124</idno>
				</org>
				<org type="funding" xml:id="_MggkYVN">
					<idno type="grant-number">2012BAH39B04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,104.40,625.09,120.57,8.85" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,104.40,625.09,120.57,8.85">Session Track 2012 Overview</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,104.40,687.49,381.45,8.85;3,90.00,703.09,368.04,8.85" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,372.92,687.49,112.93,8.85;3,90.00,703.09,182.04,8.85">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,278.40,703.09,85.48,8.85">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,106.56,734.29,398.66,8.85;3,90.00,749.89,218.29,8.85" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m" coord="3,333.12,734.29,172.10,8.85;3,90.00,749.89,188.22,8.85">Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Training Linear SVMs in Linear Time</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
