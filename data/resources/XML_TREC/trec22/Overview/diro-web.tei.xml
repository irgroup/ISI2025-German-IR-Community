<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,68.72,72.80,472.28,16.84;1,114.25,92.72,381.22,16.84">Université de Montréal at TREC 2013: Experiments with Quantum Language Models in the Web Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,177.45,138.42,102.08,11.06"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
							<email>sordonia@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">DIRO</orgName>
								<orgName type="institution">Université de Montréal Montréal</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Québec</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.41,138.42,50.15,11.06"><forename type="first">Wei</forename><surname>Yuan</surname></persName>
							<email>yuanwei@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">DIRO</orgName>
								<orgName type="institution">Université de Montréal Montréal</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Québec</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.15,138.42,67.12,11.06"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
							<email>nie@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">DIRO</orgName>
								<orgName type="institution">Université de Montréal Montréal</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Québec</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,68.72,72.80,472.28,16.84;1,114.25,92.72,381.22,16.84">Université de Montréal at TREC 2013: Experiments with Quantum Language Models in the Web Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D1D8C6E8375909BA9EDEE15EA773FAD6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In TREC 2013, we focus on addressing the challenges posed by the Web track using our recently proposed Quantum Language Modeling (QLM) approach for IR <ref type="bibr" coords="1,254.72,243.94,9.20,7.86" target="#b1">[1]</ref>. QLM can be considered as a dependence model for IR for its capability of representing and integrating compound term dependencies into the scoring function. Among the main properties of the model, two of them make it stand out from the literature of existing dependence models (such as MRF <ref type="bibr" coords="1,277.06,296.24,9.51,7.86" target="#b3">[3]</ref>). First, QLM does not combine scores obtained from matching single terms and from matching compound dependencies, which makes it virtually parameterless. This is quite an appealing property for an IR system, especially when a new dataset such as ClueWeb12 is released and no previous training examples can be leveraged to fine-tune important parameters. The second peculiar feature of our model is its ability to automatically fallback onto the baseline bag-ofwords score in the case that the required dependence relationship does not hold in the document. This is expected to bring improved robustness w.r.t. the baseline ranking. In the light of these considerations, the Web Track ad-hoc and robustness task seem the perfect testbeds for our model. In what follows we briefly review some of the theoretical background of QLM before delving into the description of the submitted runs and obtained results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">QUANTUM LANGUAGE MODELING</head><p>The main feature of QLM is the introduction of a brand new document and query representations generalizing the classical unigram language model representation. The adjective "quantum" is not meant to give an attractive look at the model but it denotes the mathematical inheritance of such a representation. Indeed, documents and queries are associated to a mathematical object which is well-known in quantum physics and is called density matrix. In <ref type="bibr" coords="1,249.34,575.20,9.20,7.86" target="#b2">[2]</ref>, density matrices are shown to be the proper mathematical tool in order to generalize both vector space and language models for IR. From a linear algebra perspective, a density matrix ρ is symmetric, positive-semidefinite matrix of unitary trace, ρq ∈ S n + = {ρ : ρ ∈ R n×n , ρ = ρ T , ρ 0, tr(ρ) = 1}. It is a generalization of a classical unigram distribution in the sense that classical discrete probability weights can be arranged in the diagonal of the matrix. The off-diagonal entries (taking into account the symmetry) are additional parameters which do not appear in classical unigram models and are used to capture richer informations about text excerpts. The general idea is that density matrices spread a generalized probability measure µ onto the manifold of rank-one projectors P n 1 = {uu T : u ∈ R n , u 2 = 1}. The measure is called generalized because its integral over P n does not sum to unity. However, if one have a set of projectors {P1, . . . , Pn}, Pi ∈ P n 1 , for which i Pi = In, where In is the identity matrix in R n×n , then i µ(Pi) = 1. Hence, µ reduces to an ordinary probability measure over a complete set of projectors.</p><p>The core idea of the QLM approach is to embed in a projector any chosen syntactic expression one would like to take into account. This operation is defined by a mapping from a vocabulary of syntactic expressions (such as terms, bigrams or proximity features) to the set of projectors P n 1 . Differently from the MRF model <ref type="bibr" coords="1,430.20,335.59,9.71,7.86" target="#b3">[3]</ref> and its successors <ref type="bibr" coords="1,517.76,335.59,9.20,7.86" target="#b4">[4]</ref>, single terms or compound terms are not considered as atomic orthogonal entries in a concept vocabulary but automatically inherit the metric g of the embedding space R n×n . For example, one can compute the similarity between two terms, or between a term and a given compound dependency by simply taking the trace of the corresponding projectors, i.e. g(a, b) = tr(P T a P b ) = tr(PaP b ). Given that each visible syntactic expression is embedded in a projector, one can efficiently represent a document as a sequence of projectors which, by assuming classical independence, can be turned into a bag-of-projectors representation, very similarly to <ref type="bibr" coords="1,543.65,450.66,9.20,7.86" target="#b5">[5]</ref>. By approximately maximizing the likelihood of the observed projectors, one can find the best estimator ρ for a given document model (or a query). Given the estimated document and query models, the ranking is done by computing the negative of a divergence on S n + , namely the negative query to document von Neumann divergence. Given appropriate mappings, one can show that QLM is a proper generalization of the unigram LM approach to IR and reduces to unigram LM score when no compound concept is detected in a given document.</p><p>Overall, three desirable properties arise from such an approach: (1) ρ can be considered as a holistic document model capable of encoding occurrence information arising from compound and single terms in a principled way, (2) it efficiently removes any combination parameter (for example for combining single terms and compound term scores) from the scoring function <ref type="bibr" coords="1,398.21,628.50,9.71,7.86" target="#b1">[1]</ref> and (3) it falls back to a classical unigram LM score if any of the considered compound concepts is not detected in the document model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">QUERY EXPANSION WITH QLM</head><p>Query expansion with QLM was not proposed in the original QLM paper <ref type="bibr" coords="1,384.62,700.73,9.71,7.86" target="#b1">[1]</ref> but can be promptly introduced for the adhoc task addressed here. The idea is a straightforward Run ERR-IA@20 α-nDCG@20 P-IA@20 nDCG@20 ERR@20 TREC median 0. generalization of query expansion in the classical LM framework: one smooths the original query model ρO with an expanded model ρL which is supposed to encode the latent aspects of the user information need and is simply obtained by selecting relevant terms in the top-K retrieved documents (for example using a Relevance Model <ref type="bibr" coords="2,211.82,199.32,9.51,7.86" target="#b6">[6]</ref>). The amount of smoothing is determined by a parameter λ as follows:</p><formula xml:id="formula_0" coords="2,125.73,227.28,167.18,7.86">ρE = λ ρO + (1 -λ) ρL,<label>(1)</label></formula><p>where ρE indicates the obtained expanded model. These operations are legit when manipulating density matrices as the set S n + is convex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>The english portion of the ClueWeb12 corpus (Category A) was indexed using the Indri toolkit<ref type="foot" coords="2,213.83,313.40,3.65,5.24" target="#foot_0">1</ref> . All the parameters described next were chosen on the basis of preliminary experiments conducted upon the ClueWebB Web Track 10-11-12 queries. Both the index and the queries were stopped using the standard INQUERY stoplist and no stemming was performed. All the retrieval experiments were performed using our modified version of Indri, with a built-in version of QLM. As described in the original QLM paper <ref type="bibr" coords="2,265.68,388.39,9.20,7.86" target="#b1">[1]</ref>, we decided to consider the powerset of query terms as useful compound concepts to capture. We consider that such compound concepts are expressed in a document if their component terms appear unordered in a window of adaptive length L = l|κ|, where |κ| is the number of terms in the proximity expression. We set l = 1, which was found to optimize ERR@20 and NDCG@20 in preliminary experiments. For example, for the query usda food pyramid, we submit the following query expression to our modified version of Indri: #q(usda food pyramid #uw2(usda food) #uw2(food pyramid) #uw2(usda pyramid) #uw3(usda food pyramid))</p><p>Notice that in QLM, no parameters are needed for the combination of unordered and single term scores. We further extended Indri's query language in order to run expanded queries. The modified syntax goes as follows:</p><p>#qweight(0.8 #q(usda food pyramid #uw2(usda food) #uw2(food pyramid) #uw2(usda pyramid) #uw3(usda food pyramid)) 0.2 #qweight( 0.8 health 0.2 nutrition ))</p><p>where health and nutrition are considered expansion terms with their respective probability weights.</p><p>In <ref type="bibr" coords="2,336.48,147.01,9.20,7.86" target="#b1">[1]</ref>, it is shown that the QLM estimation process weakly suffers the metric divergence problem. Hence, we choose to avoid early-stopping and run the estimation algorithm until the relative change in the likelihood between iterations dropped below a threshold = 0.001. Spam-filtering was applied on the entire ClueWeb12A corpus using the publicly available Waterloo Spam Ranking for the ClueWeb12 Dataset. We filter out the bottom 30% of the documents, as determined by the spam ranking. This threshold was found to optimize ERR@20 and NDCG@20 in our preliminary experiments with the ClueWebB queries. If compared to the standard TREC setting of filtering out the bottom 70% of the documents, our spam-filtering choice is more risk-inclined. However, we found that our model is quite robust to spam.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">AD-HOC TASK</head><p>In this section we compare between the three runs submitted to the ad-hoc task of the TREC 2013 Web Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Description of the Runs</head><p>The description of the three runs is as follows:</p><p>• udemQlml1 is a "vanilla" run of QLM with the parameter settings described above. The purpose of this run was to evaluate the effectiveness of the retrieval approach on a single-pass batch retrieval setting.</p><p>• udemQlml1Fb performs query expansion using RM3 <ref type="bibr" coords="2,547.58,441.27,9.20,7.86" target="#b7">[7]</ref>. We considered the top K = 10 retrieved documents obtained by udemQlml1 and set the smoothing parameter λ = 0.8.</p><p>• udemQlml1FbWiki performs query expansion using expansion terms from Wikipedia pages. To this end, we indexed the 2009 Wikipedia dump and performed a run of QLM. We extracted expansion terms from the top K = 5 retrieved documents and set the smoothing parameter λ = 0.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Table <ref type="table" coords="2,351.16,575.20,4.61,7.86" target="#tab_0">1</ref> compares the retrieval performance of these runs for the ad-hoc task. Our baseline run stands above median values for ERR@20 and nDCG@20. It is interesting to see that even if we do not explicitly favour diversity, our baseline run generally alignes to the median performance for diversity-oriented metrics and outperforms the median value for P-IA@20. The expansion from the top-K retrieved documents from the Web collection fails to improve performance due to the noisy nature of the retrieved set. This result is in-line with past results trying to apply RM3 on Web collections. However, in our preliminary experiments, such kind of expansion showed positive effects on the ClueWeb09B collection when used with the QLM approach. The expansion from Wikipedia pages has a significant positive impact Alpha=0 ERR-IA@20 α-nDCG@20 P-IA@20 nDCG@20 ERR@20 on the retrieval performance for all the retrieval metrics reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ROBUSTNESS TASK</head><p>For the robustness task, the same runs from the ad-hoc task were submitted (we renamed them by putting "R" to the ends). The only exception is that udemQlml1Fb was spamfiltered at 70% (i.e. udemQlml1FbR), which was the standard threshold used to obtain the LM baseline comparison run. Despite the various values of Alpha, all the three runs show to be robust in ERR@20 and nDCG@20, even though we did not specifically tune our methods with respect to robustness measures. When Alpha is greater than 1, however, all our runs suffer significant losses in α-nDCG. More experiments are needed to understand such behaviours. Another interesting finding is that spam-filtering at 70% is effective, which helps udemQlml1FbR standing above the median values of ERR-IA@20 and P-IA@20 as Alpha increases. We argue that if the same spam-filtering level was applied to the other two runs, even larger improvements with respect to median values could have been reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>In TREC 2013, we participated to the Web track in order to test the effectiveness and efficiency of our novel ranking model. Results showed that a simple single-pass run by setting a very tight unordered window for capturing compound dependencies (1) outperforms median values in terms of ERR@20 and nDCG@20 and most importantly (2) offers a complexity comparable to a simple bag-of-word approach due to the limited window size. Overall, obtained results suggest that our model could be used as a powerful singlepass retrieval model or as a valuable additional feature in more complex learning to rank approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,130.49,66.45,345.36,60.53"><head>Table 1 :</head><label>1</label><figDesc>Ad-hoc task.</figDesc><table coords="2,130.49,66.45,345.36,39.74"><row><cell></cell><cell>4675</cell><cell>0.5701</cell><cell>0.2880</cell><cell>0.1738</cell><cell>0.098</cell></row><row><cell>udemQlml1</cell><cell>0.4701</cell><cell>0.5531</cell><cell>0.3147</cell><cell>0.2286</cell><cell>0.1312</cell></row><row><cell>udemQlml1Fb</cell><cell>0.4115</cell><cell>0.4946</cell><cell>0.2966</cell><cell>0.2074</cell><cell>0.1144</cell></row><row><cell>udemQlml1FbWiki</cell><cell>0.4799</cell><cell>0.5758</cell><cell>0.3425</cell><cell>0.2541</cell><cell>0.1515</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,127.10,66.45,355.52,243.41"><head>Table 2 :</head><label>2</label><figDesc>Robustness Task with different values of α.</figDesc><table coords="3,127.10,66.45,355.52,222.63"><row><cell>TREC Median</cell><cell>0.1152</cell><cell>0.1189</cell><cell>0.0275</cell><cell>0.0057</cell><cell>0.0018</cell></row><row><cell>udemQlml1R</cell><cell>0.1178</cell><cell>0.1019</cell><cell>0.0542</cell><cell>0.0605</cell><cell>0.0349</cell></row><row><cell>udemQlml1FbR</cell><cell>0.1191</cell><cell>0.0950</cell><cell>0.0473</cell><cell>0.0209</cell><cell>0.0187</cell></row><row><cell>udemQlml1FbWikiR</cell><cell>0.1276</cell><cell>0.1246</cell><cell>0.0820</cell><cell>0.0859</cell><cell>0.0552</cell></row><row><cell>Alpha=1</cell><cell cols="5">ERR-IA@20 α-nDCG@20 P-IA@20 nDCG@20 ERR@20</cell></row><row><cell>TREC Median</cell><cell>0.0742</cell><cell>0.0842</cell><cell>-0.0066</cell><cell>-0.0306</cell><cell>-0.0223</cell></row><row><cell>udemQlml1R</cell><cell>0.0531</cell><cell>0.0432</cell><cell>0.0190</cell><cell>0.0292</cell><cell>0.009</cell></row><row><cell>udemQlml1FbR</cell><cell>0.0843</cell><cell>0.0524</cell><cell>0.0259</cell><cell>-0.0076</cell><cell>0.0008</cell></row><row><cell>udemQlml1FbWikiR</cell><cell>0.0678</cell><cell>0.0644</cell><cell>0.0389</cell><cell>0.0522</cell><cell>0.0343</cell></row><row><cell>Alpha=5</cell><cell cols="5">ERR-IA@20 α-nDCG@20 P-IA@20 nDCG@20 ERR@20</cell></row><row><cell>TREC Median</cell><cell>-0.0896</cell><cell>-0.0543</cell><cell>-0.1429</cell><cell>-0.1757</cell><cell>-0.1185</cell></row><row><cell>udemQlml1R</cell><cell>-0.2052</cell><cell>-0.1915</cell><cell>-0.1214</cell><cell>-0.0959</cell><cell>-0.0944</cell></row><row><cell>udemQlml1FbR</cell><cell>-0.0549</cell><cell>-0.1181</cell><cell>-0.0600</cell><cell>-0.1216</cell><cell>-0.0706</cell></row><row><cell>udemQlml1FbWikiR</cell><cell>-0.1712</cell><cell>-0.1764</cell><cell>-0.1336</cell><cell>-0.0826</cell><cell>-0.0500</cell></row><row><cell>Alpha=10</cell><cell cols="5">ERR-IA@20 α-nDCG@20 P-IA@20 nDCG@20 ERR@20</cell></row><row><cell>TREC Median</cell><cell>-0.2943</cell><cell>-0.2275</cell><cell>-0.3133</cell><cell>-0.3571</cell><cell>-0.2388</cell></row><row><cell>udemQlml1R</cell><cell>-0.5284</cell><cell>-0.4849</cell><cell>-0.2971</cell><cell>-0.2523</cell><cell>-0.2237</cell></row><row><cell>udemQlml1FbR</cell><cell>-0.229</cell><cell>-0.3312</cell><cell>-0.1671</cell><cell>-0.2641</cell><cell>-0.1599</cell></row><row><cell>udemQlml1FbWikiR</cell><cell>-0.4701</cell><cell>-0.4775</cell><cell>-0.3483</cell><cell>-0.2510</cell><cell>-0.1544</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,58.40,711.87,108.42,6.99"><p>http://www.lemurproject.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,58.28,714.94,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,329.90,211.21,7.86;3,335.61,340.36,211.43,7.86;3,335.61,350.82,162.10,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,487.47,329.90,59.34,7.86;3,335.61,340.36,207.21,7.86">Modeling term dependencies with quantum language models for IR</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,347.10,350.82,58.89,7.86">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="653" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,362.28,218.03,7.86;3,335.61,372.74,214.93,7.86;3,335.61,383.20,47.98,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,441.84,362.28,111.80,7.86;3,335.61,372.74,175.39,7.86">A joint look to vector space and language models using density matrices</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,529.60,372.74,20.94,7.86;3,335.61,383.20,19.58,7.86">Proc. of QI</title>
		<meeting>of QI</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,394.65,211.56,7.86;3,335.61,405.11,196.71,7.86;3,335.61,415.58,83.88,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,453.78,394.65,93.38,7.86;3,335.61,405.11,114.26,7.86">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,468.65,405.11,58.89,7.86">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,427.03,220.31,7.86;3,335.61,437.49,220.32,7.86;3,335.61,447.95,217.16,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,466.40,427.03,89.51,7.86;3,335.61,437.49,220.32,7.86;3,335.61,447.95,47.67,7.86">Modeling higher-order term dependencies in information retrieval using query hypergraphs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,402.16,447.95,58.89,7.86">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="941" to="950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,459.41,200.76,7.86;3,335.61,469.87,206.16,7.86;3,335.61,480.33,93.46,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,463.21,459.41,73.15,7.86;3,335.61,469.87,155.27,7.86">Textual Similarity with a Bag-of-Embedded-Words Model</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,510.03,469.87,31.74,7.86;3,335.61,480.33,24.59,7.86">Proc. of ICTIR</title>
		<meeting>of ICTIR</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,491.79,189.97,7.86;3,335.61,502.25,209.97,7.86;3,335.61,512.71,20.96,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,460.17,491.79,65.40,7.86;3,335.61,502.25,64.47,7.86">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,418.98,502.25,58.89,7.86">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,335.60,524.17,191.39,7.86;3,335.61,534.63,218.28,7.86;3,335.61,545.09,220.32,7.86;3,335.61,555.55,20.96,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="3,428.02,524.17,98.97,7.86;3,335.61,534.63,218.28,7.86;3,335.61,545.09,66.90,7.86">A Comparative Study of Methods for Estimating Query Language Models with Pseudo Feedback</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">X</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,421.21,545.09,57.21,7.86">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1895" to="1898" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
