<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,192.74,116.95,229.89,12.62">DLDE at web track: ad-hoc task</title>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
				<funder ref="#_vR764rw">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,153.12,154.64,36.00,8.74"><forename type="first">Jie</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName coords="1,197.54,154.64,59.84,8.74"><forename type="first">Zhendong</forename><surname>Niu</surname></persName>
							<email>zniu@bit.edu.cn</email>
						</author>
						<author>
							<persName coords="1,265.33,154.64,46.22,8.74"><forename type="first">Yulong</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName coords="1,319.02,154.64,73.07,8.74"><forename type="first">Changmin</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,419.76,154.64,42.48,8.74"><forename type="first">Weiyin</forename><surname>Li</surname></persName>
							<email>li_weiyin@qq.com</email>
						</author>
						<title level="a" type="main" coord="1,192.74,116.95,229.89,12.62">DLDE at web track: ad-hoc task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D7A54962B1776915A96E98D3157807FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ad-hoc search</term>
					<term>query expansion</term>
					<term>meta search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this note paper, we report our experiment method at adhoc task of Web Track 2013. The goal of this task is to return a rank of documents order by relevance from a collection of static web pages. Our group used meta search to help query expansion as the first step, and then retrieved with the expansion query to get the search results and rerank them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ad-hoc task of web track is given some topics to search out the most relevant documents from a large number of static web pages, ClueWeb2012 <ref type="bibr" coords="1,437.86,374.00,9.96,8.74" target="#b5">[6]</ref>, which comprises about 870 million web pages collected between February 10, 2012 and May 10, 2012. Topics are short and ambiguous which are similar to queries of tradition web search. It is hard to get satisfied search results based on keyword match method. This year we use the WebClue2012-B13 dataset, a subset of WebClue2012 with 50 million web pages. Firstly, some preprocessing work was done to the dataset in order to remove the spams and noise data. Secondly, in order to get more semantic meanings, meta search approach was used to get some pages relevant to the topic as seeds , and then the semantic words were computed as expansion. Thirdly, the search results from the treated data with the expansion query were reranked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data preprocessing</head><p>Since the data set is too big to be operated directly and efficiently, the nonrelevant data and spam were removed before the final query step. In our experiments , the Indri <ref type="bibr" coords="1,208.77,573.43,10.52,8.74" target="#b6">[7]</ref> tools and waterloo spam <ref type="bibr" coords="1,328.84,573.43,10.52,8.74" target="#b1">[2]</ref> were used to build the raw index files. Second, all the relevant pages were got from the index with the topic as the query. These relevant pages are the basic data of our experiments. In the process of parsing the web page , we found there are many noises such as advertisements and copy rights in body part, so the Block web content parser <ref type="bibr" coords="1,407.56,621.25,10.52,8.74" target="#b2">[3]</ref> ,developed by our lab, was introduced into this project to extract the main content. Third, a new index file with Lucene <ref type="bibr" coords="1,253.10,645.16,10.52,8.74" target="#b7">[8]</ref> was built for subsequent experiments. The reason was that our group had developed a web search system based on Lucene package.</p><p>The query search phase was divided into two parts: query expansion and reranking. Each origin topic was expanded to a sematic word set as new query to get search results and treat them as the final results after reranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Expansion</head><p>Meta search Google search and bing search were used as meta search resource. Each search engine returns the top 200 pages about the topic, and then the page extract technology <ref type="bibr" coords="2,218.65,258.43,10.52,8.74" target="#b2">[3]</ref> was used to get main content.</p><p>Expansion Strategy Query expansion is a commonly used method helping search system to understand the origin query words. In our experiment, the local analysis <ref type="bibr" coords="2,194.98,317.86,10.52,8.74" target="#b0">[1]</ref> method was used to get the expansion words. Origin expansion words list was got by calculating occurrence number of each word and remove the stop words. With the help of Standford Parser <ref type="bibr" coords="2,357.78,341.77,10.52,8.74" target="#b8">[9]</ref> , developed by Standford Natural Language Processing Group, all the words in addition to nouns were removed and the top 30 were got as final expansion words list.</p><p>We treat the synonym of origin topic word as the denominator to get the weight of each expansion word</p><formula xml:id="formula_0" coords="2,279.61,412.67,200.98,23.22">w i = T F i T F max<label>(1)</label></formula><p>The final query expansion formula is descripted :</p><formula xml:id="formula_1" coords="2,209.92,469.06,270.67,30.32">Query expan = Query origin + n i=1 w i * Expan i (2)</formula><p>n is the count of optional expansion terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Re-ranking Model</head><p>We aimed to re-ranking the search results with learning to rank technology which is on the rise in recent years. Learning to rank is a class of methods using machine learning to solve information retrieval problems. It is an effective way to combine different data features for ranking. The public available dataset ,LETOR <ref type="bibr" coords="2,448.88,609.29,9.96,8.74" target="#b3">[4]</ref>, was used to train the rank model. Since a lot of features of LETOR we cannot get, we droped those columns and then trained the ranking model. The SVMRank <ref type="bibr" coords="2,134.77,645.16,10.52,8.74" target="#b4">[5]</ref> algorithm was used in this task and five-folds cross validation was done. The output model was directly applied to our experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Submited only one run this year and it didn't perform well. We think there are two main reasons that caused this result. One reason was our ClueWeb-B-13 dataset is too small to obtain the valid search results in the data preprocessing step. The other was caused by features we used to train the ranking model .Not only the number of features was small, but also there were gaps between LETOR dataset and ClueWeb2012.We need to do some transfer learning to train the ranking model next time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conculion</head><p>Our approach was descripted in this paper. This year we used web content technology to remove the noise of web page and used the meta search and query expansion method to understand the topic. Since the dataset we had less than on tenth of the whole one, we will validate our ideas with the whole dataset in the next year.</p></div>		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>Thank organizers of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is supported by the <rs type="funder">National Natural Science Foundation of China</rs> (no. <rs type="grantNumber">61250010</rs>) and the 111 Project of <rs type="affiliation">Beijing Institute of Technology</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vR764rw">
					<idno type="grant-number">61250010</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,138.35,435.08,342.24,7.86;3,146.91,446.04,181.90,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,236.90,435.08,243.70,7.86;3,146.91,446.04,80.15,7.86">A framework for automatic query expansion Web Information Systems and Mining</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sharan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="386" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,456.33,342.25,7.86;3,146.91,467.29,333.68,7.86;3,146.91,478.25,13.82,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="3,339.13,456.33,141.46,7.86;3,146.91,467.29,233.42,7.86">Efficient and effective spam filtering and re-ranking for large web datasets Information retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="441" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,488.54,342.24,7.86;3,146.91,499.50,333.68,7.86;3,146.91,510.46,45.57,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,254.78,488.54,225.81,7.86;3,146.91,499.50,281.69,7.86">Combining a segmentation-like approach and a densitybased approach in content extraction Tsinghua Science and Technology</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,435.43,499.50,16.22,7.86">TUP</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="256" to="264" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,520.75,342.25,7.86;3,146.91,531.71,333.68,7.86;3,146.91,542.67,224.37,7.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Letor</surname></persName>
		</author>
		<title level="m" coord="3,354.56,520.75,126.03,7.86;3,146.91,531.71,333.68,7.86;3,146.91,542.67,176.78,7.86">Benchmark dataset for research on learning to rank for information retrieval Proceedings of SIGIR 2007 workshop on learning to rank for information retrieval</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,552.96,342.24,7.86;3,146.91,563.92,150.97,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="3,258.04,552.96,222.56,7.86;3,146.91,563.92,34.93,7.86">Efficient algorithms for ranking with SVMs Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="201" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,574.21,43.91,7.86;3,197.28,574.21,27.39,7.86;3,239.69,574.21,43.08,7.86;3,297.77,574.21,15.88,7.86;3,328.67,574.21,54.78,7.86;3,398.46,574.21,31.16,7.86;3,444.63,574.21,35.96,7.86" xml:id="b5">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="3,297.77,574.21,15.88,7.86;3,328.67,574.21,54.78,7.86;3,398.46,574.21,31.16,7.86">The ClueWeb</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>Dataset. EB.OL</note>
</biblStruct>

<biblStruct coords="3,138.35,595.46,24.44,7.86;3,182.48,595.46,26.00,7.86;3,228.19,595.46,32.15,7.86;3,280.03,595.46,15.88,7.86;3,315.61,595.46,19.73,7.86;3,355.03,595.46,24.91,7.86;3,399.63,595.46,25.61,7.86;3,444.94,595.46,35.66,7.86;3,146.91,606.42,137.04,7.86" xml:id="b6">
	<monogr>
		<ptr target="http://lemurproject.org/indri.php" />
		<title level="m" coord="3,146.91,595.46,15.88,7.86;3,182.48,595.46,26.00,7.86;3,228.19,595.46,32.15,7.86;3,280.03,595.46,15.88,7.86;3,315.61,595.46,19.73,7.86;3,355.03,595.46,24.91,7.86;3,399.63,595.46,25.61,7.86;3,444.94,595.46,31.70,7.86">The Lemur Project. The Indri search engine software</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,616.71,24.44,7.86;3,179.92,616.71,64.29,7.86;3,261.33,616.71,48.26,7.86;3,326.72,616.71,15.88,7.86;3,359.73,616.71,28.28,7.86;3,405.15,616.71,26.40,7.86;3,448.68,616.71,31.91,7.86;3,146.91,627.67,103.96,7.86" xml:id="b7">
	<monogr>
		<ptr target="http://lucene.apache.org/" />
		<title level="m" coord="3,146.91,616.71,15.88,7.86;3,179.92,616.71,64.29,7.86;3,261.33,616.71,48.26,7.86;3,326.72,616.71,15.88,7.86;3,359.73,616.71,28.28,7.86;3,405.15,616.71,26.40,7.86;3,448.68,616.71,27.92,7.86">The ApacheSoftware Foundation. The Lucene Search Library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="3,138.35,637.97,342.25,7.86;3,146.91,648.92,200.73,7.86" xml:id="b8">
	<monogr>
		<ptr target="http://nlp.stanford.edu/software/lex-parser.shtml" />
		<title level="m" coord="3,146.91,637.97,329.67,7.86">The Standford Natural Language processing Group. The Standford Parser</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
