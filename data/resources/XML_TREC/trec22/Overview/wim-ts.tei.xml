<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.26,76.41,425.63,16.20">ZZISTI at TREC2013 Temporal Summarization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,188.90,105.82,41.06,10.80"><forename type="first">Yaoyi</forename><surname>Xi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Zhengzhou Information Science and Technology Institute Zhengzhou</orgName>
								<address>
									<postCode>450002</postCode>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.96,105.82,52.07,10.80"><forename type="first">Bicheng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Zhengzhou Information Science and Technology Institute Zhengzhou</orgName>
								<address>
									<postCode>450002</postCode>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.54,105.82,39.11,10.80"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Zhengzhou Information Science and Technology Institute Zhengzhou</orgName>
								<address>
									<postCode>450002</postCode>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.95,105.82,78.10,10.80"><forename type="first">Yongwang</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Zhengzhou Information Science and Technology Institute Zhengzhou</orgName>
								<address>
									<postCode>450002</postCode>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.26,76.41,425.63,16.20">ZZISTI at TREC2013 Temporal Summarization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2B6F384D529BD94CB2D7407ADA6DC03B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our team submitted runs for the first running of the TREC Temporal Summarization track. TS Track at TREC2013 contains two tasks, namely Sequential update Summarization and value tracking. Our Systems to each task are described in this paper respectively. In particular, Stanford CoreNLP was applied to extract the event attributes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of the Temporal Summarization track is to develop systems that allow users to efficiently monitor the information associated with an event over time. It focuses on two tasks, sequential update summarization and value tracking. The former requires broadcasting useful, new, and timely sentence-length updates about a developing event, while the latter needs to track the value of important event-related attributes (e.g. number of fatalities, financial impact). Document summarization technique is a hot research topic in recent years, such as single and multi-document summarization, update summarization and so on. TS differs from previous summarization techniques in two primary ways: it is oriented to an online, sequential setting, and it needs to extract and track the value of important event-related attributes in dynamic settings. TS Track at TREC2013 used the TREC KBA 2013 Stream Corpus. This corpus consists of a set of times-tamped documents from a variety of news and social media sources covering the time period October 2011 through January 2013. A document contains a set of sentences, each with a unique identifier, which is the index of the sentence in the document, beginning at zero. For the purpose of the TS track, the corpus of time-stamped documents is considered a stream and documents should be iterated over in temporal order. We have used the KBA 2013 "English-and-unknown-language" streamcorpus with all non-English documents removed and the StreamItem.body.raw text set to "". This stripped corpus is about 4.5TB and just over 500M StreamItems.</p><p>The remainder of this paper is organized as follows: Section 2 on our sequential update summarization system and Section 3 on our value tracking system. Section 4 shows the results of our submitted runs. We conclude in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Sequential Update Summarization</head><p>According to the sequential update summarization task, a system should emit relevant, important and novel sentences to an event. We submitted one run for the sequential update summarization task, and denote it as SUS1 in the following paper. The implementation of SUS1 is shown in Figure1. We described each implementation step respectively in section 2.1, 2.2, 2.3 and 2.4. Section 2.5 gives the other strategies in SUS1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tracking Relevant Documents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tracking Relevant Documents</head><p>The summary sentence must be from the document which is relevant to the topic. To quickly find these documents from the extremely large stream corpus, we assume that one document is about the topic if it contains all the query terms. In addition, to help speed up processing, SUS1 discarded the documents containing more than K sentences with the assumption that relevant documents usually do not have too much sentences. In TS2013, we set 40 K  .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentence Importance Computation</head><p>The summary sentence certainly contains important information. Based on a lot of observation results, we have found that summary sentences usually have more entities than others and the entities generally contain important topic information. Therefore, we assume that the number of entities in a sentence reflects the amount of information in it and we define the sentence importance score as follows:</p><formula xml:id="formula_0" coords="3,218.07,288.59,303.94,36.05">( , ) ( , ) ts W t d SenIMP s d usefulTokenNum    <label>(1)</label></formula><p>where ( , ) SenIMP s d denotes the importance score of sentence s in document d , ( , ) W t d defines the weight of term t in document d , usefulTokenNum denotes the number of entities in sentence s , the parameter  controls the degree of the prize when sentence s contains some of the query terms. We set 1   when s doesn"t have any of the query terms, and 1.5</p><formula xml:id="formula_1" coords="3,263.24,425.93,18.52,11.55"> </formula><p>when s contains some of the query terms. ( , ) W t d is defined as:</p><formula xml:id="formula_2" coords="3,216.24,470.69,305.78,40.61">2 ( , ) log( / ) ( , ) ( ( , ) log( / )] t t td tf t d N n W t d tf t d N n     <label>(2)</label></formula><p>where ( , ) tf t d denotes the frequency of term t appears in document d , N denotes the number of training documents, t n denotes the number of documents in the training corpus that contain term t. If term t doesn"t appear in the training corpus, we assume that 2 t n  . To avoid using "future" data, we construct the training corpus by choosing documents from the news substream in the stream corpus, ranging from November 1 to November 2, 2011.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sentence Novelty Computation</head><p>We intend to measure the novelty of a sentence by computing the similarities between it and the summary sentences existed. We define the novelty of a sentence as: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Sentence Confidence Computation</head><p>TS2013 requires the simulated system to give a confidence value for each update. This value encodes the system's confidence in this being a reasonable update, which may be used to prioritize updates if the assessors cannot judge all of the updates. We define the sentence confidence value as follows: </p><formula xml:id="formula_3" coords="4,239.79,370.98,135.19,10.79">( , )<label>( , ) ( ,</label></formula><p>where  denotes the importance threshold,  denotes the novelty threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Other Strategies</head><p>Strategy1: We judge the novelty of a sentence by computing its similarity with the existing summary sentences. Therefore, the selection of the first N summary sentences is very important. If they were chosen inaccurately, the accuracy of the subsequent sentence selection would be affected. Since the query terms are usually the most representative ones in a topic, we assume that the first N summary sentences must contain some of the query terms. In TS2013, we set 3 N  . Strategy2: By observed, we found that the sentences containing important information usually have an appropriate length, neither too long nor too short. So we filter out the sentences which length are greater than 1 L or less than 2 L . In TS2013, we set 1 40 L  , and 2 10 L  .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Value Tracking</head><p>According to the value tracking task, a system should emit accurate attribute value estimates for an event. This is analogous to extracting argument roles for a given event template. The only difference is that the value tracking task just focuses on specific event arguments, including Deaths, Injuries, Displaced, Financial Impact and Locations. For all that, we followed the rule-based method in our value tracking systems. We have used the training event data and the stream corpus that existed before the test events when we generated the extraction rules.</p><p>We submitted 2 runs for the value tracking task. Each run is described in detail in the following paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Value Tracking Run1</head><p>For simplicity, we denote our first value tracking system as VT1 in the following paper.</p><p>In VT1, we firstly tracked the relevant documents as section 2.1. Secondly, we filtered out the noise sentences from the relevant documents. Here, the noise sentence refers to the sentence that doesn"t have the event attributes. The specific filtering rules are shown in Figure <ref type="figure" coords="5,137.18,581.70,4.50,10.80">2</ref>. Thirdly, we extracted the desired event attributes from the remnant sentences using the extraction rules, and set the initial confidence value of the attribute at 0.5.</p><p>Finally, we refined the confidence value by weighting it according to the sentence importance and the number of attributes in this sentence.</p><p>1. Filtering out the sentence that is shorter than 10 words in length; 2. Filtering out the sentence which importance value is lower than 0.11; 3. Filtering out the sentence that doesn't have any of the query terms.</p><p>Figure <ref type="figure" coords="6,262.73,140.65,5.28,9.50">2</ref> The filtering rules of VT1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Value Tracking Run2</head><p>There are some limitations of the rule-based method, for example, the attribute extracted by this method may be not an event attribute at all. To improve the rule-based method, we attempt to use the Stanford CoreNLP to recognize the named entities in the sentence, such as NUMBER, MONEY, LOCATION and so on. We think the Deaths, Injuries and Displaced attributes belong to NUMBER, Financial Impact attributes belong to MONEY, and Locations attributes belong to LOCATION. Based on this, we developed the second value tracking system, VT2. The main idea of VT2 is using CoreNLP to validate the attribute extracted by the rule-based method. If the extracted results of the two methods are the same, then we retain this attribute. If not, we discarded it. The process flow of VT2 is:</p><p>Firstly, tracking the relevant documents;</p><p>Secondly, filtering out the noise sentences;</p><p>Thirdly, extracting the event attributes from the remaining sentences with the rule-based method and setting the initial confidence value of the attributes at 0.5;</p><p>Fourthly, using CoreNLP to extract named entities from the sentences. If the extracted results are the same as the ones specified in Step3, the confidence value of the attributes is increased to 0.75; Finally, refining the attributes" confidence value by weighting them according to the sentence importance and the number of attributes in this sentence. Other than the forth step, any other steps above are the same as in VT1.</p><p>The important thing to note here is the version of CoreNLP. TS2013 requires that external data must have existed before the event start time, or be time-aligned with the KBA corpus and no information after the simulation decision time can be used. So we choose Version 1.3.0 in VT2, which was released on January 8, 2012 by the Stanford Natural Language Processing Group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>In TS track2013, 26 submissions were made to the sequential update summarization task, and 7 submissions were made to the value tracking task. Among which, our team contributed 1 submission to the sequential update summarization task and 2 submissions to the value tracking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set and Evaluation Metrics</head><p>This year"s Temporal Summarization track contained 10 topics. They include 2 accidents, 2 shootings, 4 storms, 1 earthquake, and 1 bombing. For each of these topics, the summarization time window is 10 days. Some metrics were developed by the track organizers to measure the quality of runs. For Sequential Update Summarization, Expected Latency Gain (ELG) and Latency Comprehensiveness(LC) of each run were used. For Value Tracking, Expected Error(EE) was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Result Analysis</head><p>Table <ref type="table" coords="7,121.70,365.05,6.00,10.80">1</ref> and 2 report the performance of our submitted run for the sequential update summarization task in terms of expected latency gain and latency comprehensiveness respectively. Topic 7 happened in early July, but the streamcorpus doesn't have data for that time period, other than arxiv, so the organizers have ignored this topic. The performance of our run with respect to the ELG and LC metric, are below the average reported amongst all submitted runs to the track. This could be in part because we have used "StreamItem.body" 1 to filter the streamcorpus, but it is always incomplete, which led to many relevant documents not included. On the other hand, only use the named entities to measure the importance of sentence may be not appropriate.</p><p>Although the general performance, SUS1 does not take use of any other external resources and is easy to implement. It may be used as a baseline in the future. Table <ref type="table" coords="8,122.18,229.18,6.00,10.80">3</ref> shows that low expected error is achieved in VT1 and VT2, which can be attributed to the effectiveness of the extraction rules. In particular, VT2 performed better than VT1, which confirmed that using of Stanford CoreNLP can improve the extraction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we presented the implementation details of our runs for the Temporal Summarization Track. The TS Track is a very challenging task as expected and therefore very interesting. This first year allows us to comprehend what is behind TS. Overall, none of the submitted runs performed well both in expected latency gain and latency comprehensiveness, and there are still many improvements that can be done. Since this is only the first year, it will make the following years quite promising.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,225.41,588.57,161.26,9.50"><head>Figure 1</head><label>1</label><figDesc>Figure 1 The implementation of SUS1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,90.02,684.06,431.98,24.60"><head></head><label></label><figDesc>Table3reports the performance of our submitted runs for the value tracking task, VT1 and VT2, in terms of expected error. TREC2013 did not give the performance of the attribute "Displaced" in all runs. One possible reason is that all runs performed poorly in extracting the displaced attribute values. Expected Error of VT1 and VT2 Over 10 Evaluation Topics</figDesc><table coords="8,148.82,113.59,310.44,98.84"><row><cell></cell><cell>location</cell><cell>deaths</cell><cell>injuries</cell><cell>financial impact(10 9 )</cell></row><row><cell>baseline</cell><cell>20038.0</cell><cell>195.111</cell><cell>473.222</cell><cell>13.3539</cell></row><row><cell>VT1</cell><cell>14483.6</cell><cell>2726.06</cell><cell>410.092</cell><cell>13.3539</cell></row><row><cell>VT2</cell><cell>4660.76</cell><cell>2396.12</cell><cell>410.531</cell><cell>13.3539</cell></row><row><cell>AVG</cell><cell>14426.08</cell><cell>28172.55</cell><cell>39863.62</cell><cell>18.65641</cell></row><row><cell>MIN</cell><cell>4660.76</cell><cell>138.1</cell><cell>390.985</cell><cell>9.5251</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,106.94,481.59,303.39,10.80" xml:id="b0">
	<monogr>
		<ptr target="http://www.trec-ts.org/" />
		<title level="m" coord="8,106.94,481.59,153.00,10.80">TREC Temporal Summarization</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
