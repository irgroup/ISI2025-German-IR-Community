<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.39,61.75,309.21,20.73">Mirex and Taily at TREC 2013</title>
				<funder>
					<orgName type="full">Dutch national program COMMIT</orgName>
				</funder>
				<funder ref="#_kfbQaaW">
					<orgName type="full">Folktales as Classifiable Texts (FACT)</orgName>
				</funder>
				<funder ref="#_XtTqZac">
					<orgName type="full">EU</orgName>
				</funder>
				<funder>
					<orgName type="full">Ghent University</orgName>
				</funder>
				<funder>
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
				<funder>
					<orgName type="full">Netherlands</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,145.76,99.46,47.07,9.50"><forename type="first">Robin</forename><surname>Aly</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Human Media Interaction Group</orgName>
								<orgName type="institution">University of Twente</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.74,99.46,74.44,9.50"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Database Group</orgName>
								<orgName type="institution">University of Twente</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.09,99.46,75.89,9.50"><forename type="first">Dolf</forename><surname>Trieschnigg</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Human Media Interaction Group</orgName>
								<orgName type="institution">University of Twente</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.89,99.46,86.01,9.50"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Ghent University -iMinds</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.39,61.75,309.21,20.73">Mirex and Taily at TREC 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">051BD302E22129D33776AD8B1F2BF2E4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the participation of the Lowlands at the Web Track and the FedWeb track of TREC 2013. For the Web Track we used the Mirex Map-Reduce library with out-of-thebox approaches and for the FedWeb Track we adapted our shard selection method Taily for resource selection. Here, our results were above median and close to the maximum performance achieved.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In this paper we describe the contribution from University of Twente at Text Retrieval Evaluation Conference 2013. We participate in the Web Track and the Federated Web Track, which we also helped organizing. The remainder of this paper is structured as follows. Section II describes our participation in the web track and Section III describes our participation in the Federated Web Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. WEB TRACK PARTICIPATION</head><p>Our experiments are run by MIREX <ref type="bibr" coords="1,226.89,386.20,11.62,8.64" target="#b5">[6]</ref> <ref type="foot" coords="1,238.51,384.53,3.49,6.05" target="#foot_0">1</ref> (MapReduce Information Retrieval Experiments), a library of MapReduce programs to extract data and sequentially scan document representations. Built on Hadoop, sequential scanning becomes a viable approach. MIREX allows researchers to easily experiment with different retrieval models, because the framework is easy to extend.  Table <ref type="table" coords="1,84.11,554.32,3.32,8.64" target="#tab_1">I</ref> shows the precision at 5 and 10 results of the three official Web Track runs. All runs use anchor texts as document representations, which we made available for download. <ref type="foot" coords="1,277.32,576.57,3.49,6.05" target="#foot_1">2</ref> The first run, tagged ut22xact, matches the exact query string to the anchors, and ranks the documents by the number of exact matches found. This run finds exact matches for 41 out of 50 queries. We appended the results from the second run, i.e. those documents that were not already found by exact matches, to the run as the final result. The second run, tagged ut22base, uses a simple unigram language model with linear interpolation smoothing and λ = 0.95. A run without smoothing (or λ = 1) retrieves the exact same top 10 documents for 47 out of 50 queries, and therefore also achieves the same precision at 5 and 10 documents. The third run, tagged ut22spam, uses the same ranking as the second run but removes the 50 % most spammiest documents from the Waterloo spam rankings <ref type="bibr" coords="1,415.25,190.11,10.58,8.64" target="#b4">[5]</ref>. 3 The experimental results show that ut22xact, exact matching of the full query string, outperforms the other runs for precicion at 5 documents retrieved, whereas ut22base, the language model, performs best at precision at 10. Although, removing the 50 % spammiest documents helps on various ClueWeb09 test collections, in this case it hurts our results.  Table <ref type="table" coords="1,348.10,360.93,6.64,8.64" target="#tab_3">II</ref> shows the ability of the systems to retrieve documents judged as highly relevant, key, or navigational. So, documents judged as relevant were not considered in this evaluation. The results show that clearly, the exact query string matching favours highly relevant documents for 5 and 10 documents retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>J@10 J@20 J@30 ut22xact  Different topics were pooled to different depths because the original depth (20) resulted in too many documents to be judged in the allotted amount of assessing time. Tables III show the effects of the pool depth of the fraction of judged documents for each run. Although the run ut22spam was not part of the pool that was judged, it almost has all documents judged in the top 10. Of the runs that did contribute to the pool, at 20 documents retrieved, about 10 % of the documents is not judged. At 30 documents retrieved, this drops to about 22 % to 25 %.  Table <ref type="table" coords="2,84.86,58.61,10.51,8.64" target="#tab_7">IV</ref> shows general statistics of the TREC 2013 Web Track collection. Of the total number of documents that are judged, almost 29 % were judged relevant, so it is likely that many more relevant documents would have been found if more resources would have been available for judging.</p><p>We tried simple, out-of-the-box approaches to this year's Web track. It is amazing to see that very simple methods, such as counting the number of exact query string matching in anchor texts, provides relatively powerful retrieval results. Search becomes easy if you have a lot of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. FEDWEB TRACK PARTICIPATION</head><p>The Federated Web Track models a distributed search scenario where users send requests to a broker which forwards the requests to a set of search engines that are likely to produce relevant results. The track consists of two tasks: 1) the resource selection task, which requires selecting resources based on resource descriptions a search request and 2) the result merging task, which requires the fusion of the results being returned from search engines. This year we only participated in the resource selection task.</p><p>The track provided sample texts and snippets form documents sampled from each search engine. Prior to resource selection, these documents have to be transformed into a resource description. Currently, resource descriptions based directly on the sampled documents in a central sample index are the most popular. However, this approach also requires substantial storage space and administrative overhead when selecting resources.</p><p>Our approach is to adapt Taily <ref type="bibr" coords="2,200.95,416.51,10.58,8.64" target="#b0">[1]</ref>, which we recently proposed for shard selection in centralized search, for federated web search. Instead of using a centralized sample index, Taily uses vocabulary-based resource descriptions based on statistics of term related features in each shard that are used in ranking functions. Compared to this centralized setting, the full collection is only represented by a sample and and the ranking function of each individual search engine is unknown. Therefore our main contributions in this paper is to adapt the Taily method to a setting where only samples of documents are available and the ranking function is unknown.</p><p>Taily assumes a gamma distribution for scores of a query, which is inferred from the feature statistic. As we only have only few document sample instead of the full collection, some samples can overestimate the variance of the collection. As the variance strongly influences the cumulative distribution for gamma distributions, we also experiment with normal distributions.</p><p>In the following we first present an extended intuition of the Taily algorithm in Section III-A. Section III-B introduces the used score function and Section III-C describes the statistics that form Taily's resource representation. Section III-D shows how these statistics are used to estimate the parameters of the score distributions for the search engines, and for the whole collection. Section III-E describes how the number of documents with all query terms in the whole collection and per search engine can be estimated. Using the estimates for the score distribution and the number of documents, we define Taily's search engine selection criterion in Section III-F. before we adapt the algorithm to federate web search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Intuition and Reasoning</head><p>We assume that each search engine uses the same score function that assigns each document a score based on its term frequencies. The broker aims to select those resources that contain the highest ranked documents because they are the most influential for most effectiveness measures. We therefore want Taily to leave out search engines with no or only few documents in the top of the complete document ranking. The number of top-ranked documents that should be considered can vary depending on the search scenario. Our algorithm therefore considers a number of n c highly scored documents. Expressed differently, these documents are the right tail of the collection's score distribution in response to the given query, and hence we name our shard selection algorithm Taily. For example, Figure <ref type="figure" coords="2,381.07,272.21,9.40,8.64" target="#fig_0">1a</ref> shows the score frequency distribution of the query 843 pol pot in the Gov2 collection using language model scores. A broker may want to preserve, e.g., the n c = 100 top-ranked documents. This corresponds to the documents with a language model score of -14.6 or higher for this query. The broker should therefore only select search engines that index documents with score higher than -14. <ref type="bibr" coords="2,498.03,343.62,4.66,8.74" target="#b5">6</ref>.</p><p>The more accurate our model is in the right tail of the score distribution, the more accurate we can expect our resource selection to be. Score distributions are typically dominated by low scores of documents that contain no or only few of the query terms. We expect that it is difficult to model the tail of this distribution. Instead, we model the score distribution of documents that contain all query terms, which include the top-ranked documents for most queries and empirically leads to a better fit of the right tail, see Figure <ref type="figure" coords="2,483.26,451.83,8.30,8.64" target="#fig_0">1b</ref>.</p><p>Taily selects resources based on the number of documents with a score above the cut-off score of the top-n c documents. To estimate this number, Taily fits the score distribution in each of the search engines, from which the probability of a document in this shard with a score above that cut-off point can be readily calculated. Because the resources search engines index differ in size and high-scoring documents, a search engine with a low right-tail probability might still have a reasonable number of documents with scores higher than the cut-off. We therefore also estimate the total number of documents that participate in the considered score distribution and select shards based on the expected number of documents that are above the cut-off score. For example, Figure <ref type="figure" coords="2,526.17,607.54,9.40,8.64" target="#fig_0">1c</ref> shows the empirical and fitted score distribution <ref type="foot" coords="2,476.09,617.82,3.49,6.05" target="#foot_2">4</ref> of the shards 19 and 41 of topical shards generated by Kulkarni and Callan <ref type="bibr" coords="2,548.92,631.45,10.58,8.64" target="#b7">[8]</ref>. Most documents in the selected tail of the collection's score distribution belong to shard 41. Therefore, Taily prefers shard 41 over shard 19 for this query.</p><p>A popular way to estimate score distributions is to use scores of document samples from the top of the ranking <ref type="bibr" coords="2,548.92,691.51,10.58,8.64" target="#b1">[2]</ref>. However, because we avoid the use of a central sample index, this type of estimation methods is not applicable here. Instead, following Kanoulas et al. <ref type="bibr" coords="3,158.73,334.77,10.58,8.64" target="#b6">[7]</ref>, we infer the query dependent score distribution from query independent feature distributions that are summed in the score function. The parameters of the feature distributions form Taily's resource representation, which can be calculated offline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Notation</head><p>We use the following notation throughout this paper. Queries and documents are denoted by lower case q and d respectively. Sets of documents are denoted by D, and a particular set is indicated by a subscript. In particular, let D c be the set of documents in the total considered collection (the union of documents in all search engines), and let N be the number search engines and D 1 , ..., D N be the sets of documents in the respective resource. We often refer to either the set of documents in the collection or the resources, for which we use the subscript i. Terms are denoted by lower case t, the query terms of a query q are denoted by q. The length of document d is denoted by dl(d), the frequency of term t in document d is written c(t, d), and the number of documents from set D i that contain term t at least once is given by c(t, D i ).</p><p>Taily infers a query's score distribution from the distributions of the features that constitute the query's score function. In general, our algorithm can be used with any score function that is a weighted sum of term-related feature values. <ref type="foot" coords="3,280.73,644.21,3.49,6.05" target="#foot_3">5</ref> To facilitate experiments, which require a particular score function, we focus in this paper on the query likelihood model, as implemented in the Indri search engine <ref type="foot" coords="3,206.52,680.07,3.49,6.05" target="#foot_4">6</ref> . The query likelihood model uses for a term t in a document d a term feature f t (d), which is defined as follows:</p><formula xml:id="formula_0" coords="3,368.67,329.64,194.37,22.31">f t (d) = log c(t, d) + µP (t|D) dl(d) + µ<label>(1)</label></formula><p>where</p><formula xml:id="formula_1" coords="3,340.65,364.41,80.71,16.74">P (t|D) = d c(t,d) d dl(d)</formula><p>is the collection prior of term t, and µ is the Dirichlet smoothing parameter. Note that the term features in (1) are query independent. The score function s(d) of a document d for a query q is a sum of the features for the query terms:</p><formula xml:id="formula_2" coords="3,402.90,433.19,69.20,20.31">s(d) = t∈ q f t (d).</formula><p>(</p><formula xml:id="formula_3" coords="3,555.29,433.51,7.74,8.64">)<label>2</label></formula><p>where the term-related features f are defined in <ref type="bibr" coords="3,511.01,466.22,10.58,8.64" target="#b0">(1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Statistical Shard Representation</head><p>In order to infer the score distributions in search engines and the collection, we represent them by the distribution parameters of term features. The main statistics of a feature f t for term t in document set D i are the expected value E i [f t ] and the variance var i [f t ] of the feature, which can be calculated as follows, if all documents of the search engine i, d ∈ D i are available:</p><formula xml:id="formula_4" coords="3,380.00,611.58,183.03,24.36">E i [f t ] = d∈Di f t (d) c(t, D i )<label>(3)</label></formula><formula xml:id="formula_5" coords="3,374.88,638.30,188.15,40.99">E i [f 2 t ] = d∈Di f t (d) 2 c(t, D i ) var i [f t ] = E i [f 2 t ] -E i [f t ] 2<label>(4)</label></formula><p>where</p><formula xml:id="formula_6" coords="3,341.28,690.34,26.63,12.19">E i [f 2 t ]</formula><p>is the expected squared feature value. These quantities can be calculated by a single scan through the collection. In federated web search we usually do not have all documents of a resource D i but only a sample of those documents D i,s ⊆ D i . Therefore, we approximate these the expectations above through the values in the sample D i :</p><formula xml:id="formula_7" coords="4,116.70,73.90,183.32,25.33">E i [f t ] d∈Di,s f t (d) c(t, D i,s )<label>(5)</label></formula><formula xml:id="formula_8" coords="4,114.66,101.95,185.35,26.90">E i [f 2 t ] d∈Di,s f t (d) 2 c(t, D i,s )<label>(6)</label></formula><p>The language model score function used in this paper produces negative values. However, the Gamma distribution that we use for the score function is defined for positive values. To be able to shift the score distribution in the next section, we also store for each feature f its minimum value in the collection c:</p><formula xml:id="formula_9" coords="4,88.17,212.33,172.65,9.65">min c [f ] = min{f (d)|d ∈ D c , c(t, d) &gt; 0}</formula><p>The expected feature values from (3), the feature variances in (4), and the above minimum values, form the representation used to calculate the score distribution in the shards and the total collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Inferring Score Distributions</head><p>Given the shard representation described in the previous section, we derive the distribution parameters of the query specific score distribution. Because the score function used in this paper produces negative scores, we instead consider a score distribution that is shifted by its minimum value, similar to Arampatzis et al. <ref type="bibr" coords="4,133.46,366.12,10.79,8.64" target="#b2">[3]</ref>:</p><formula xml:id="formula_10" coords="4,114.04,383.83,120.90,31.40">s * (d) = s(d) + | fq| j=1 min c [f j ].</formula><p>To keep our notation lean, we continue using s instead of s * for the score function, keeping in mind that it is now positive defined. For a document set i, the expected score E i [s] and the score variance var i [s] can be derived from the definition of the score function in (2)</p><formula xml:id="formula_11" coords="4,94.46,487.75,205.56,69.88">E i [s] = | fq| j=1 E i [f j ] + | fq| j=1 min c [f j ] (7) var i [s] = | fq| j=1 var i [f j ]<label>(8)</label></formula><p>where f q is the feature vector of the query terms in (2), and f j is the jth feature in this vector. Equation 8 uses the simplifying assumption that the sum of covariances is zero. Note that we verified the validity of this assumption by repeating our experiment taking covariances into account, which did not result in a significant increase in effectiveness.</p><p>According to Kanoulas et al. <ref type="bibr" coords="4,186.00,639.44,10.58,8.64" target="#b6">[7]</ref>, the distribution of language model scores is gamma distributed. The parameters of the distribution in document set i can be derived from the expected score and the variance by using the method of moments:</p><formula xml:id="formula_12" coords="4,142.21,699.55,157.81,24.80">k i = E i [s] 2 var i [s]<label>(9)</label></formula><formula xml:id="formula_13" coords="4,142.72,727.65,157.30,23.23">θ i = var i [s] E i [s]<label>(10)</label></formula><p>where we used the definition of these parameters. Having the parameters k i and θ i for a document set i, we can define its cumulative score distribution function, which yields the probability of documents having a score greater than a score s in a document set i:</p><formula xml:id="formula_14" coords="4,333.78,104.76,229.25,39.53">7 cdf i (s ) = P i (s &gt; s ) = 1 - 1 Γ(k i ) γ k i , s θ i (11)</formula><p>where Γ is the Gamma function, γ is the incomplete Gamma function, and k i and θ i are the distribution parameters defined above. For the case of the whole collection and the example introduced previously, the values of the cumulative distribution function can be visualized as the percentage of documents with a higher score than -14.6 in Figure <ref type="figure" coords="4,463.66,211.31,7.93,8.64" target="#fig_0">1c</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. The Number of Documents With All Query Terms</head><p>To make the probabilities from the cumulative density functions comparable, Taily uses the number of documents with all query terms in this set. To reduce the strength of assuming independence between the occurrence of query terms <ref type="bibr" coords="4,533.76,291.06,10.58,8.64" target="#b3">[4]</ref>, we estimate the number of documents that contain at least one, or any query term Any i in document set i. Because we cannot access all documents of search engine's resource, we assume that the sample of search engine i, D i,s is the complete set of documents.</p><formula xml:id="formula_15" coords="4,345.04,364.56,184.93,33.53">Any i = |D i,s |   1 - | q| j=1 1 - c(t j , D i,s ) |D i,s |  </formula><p>where the term</p><formula xml:id="formula_16" coords="4,387.09,408.04,68.32,14.16">| q| j=1 (1 - c(t,Di,s)</formula><p>|Di,s| ) estimates the number of documents in sample from document set i that have none of the query terms. Among the Any i documents that contain at least one query term, we estimate the number of documents that contain all query terms All i by assuming independence of the term occurrences:</p><formula xml:id="formula_17" coords="4,379.65,486.54,183.39,31.18">All i = Any i | q| j=1 c(t j , D i,s ) Any i .<label>(12)</label></formula><p>Our experiments show that this estimate produces strong and stable results. Important to note here is that we want an efficient and lightweight algorithm, also during the preprocessing stage. Therefore, even for two-term queries, instead of counting the mutual term occurrences, which requires storage quadratic in the vocabulary size, we estimate these based on the single-term occurrences. Furthermore, assuming that D i,s = D i is a strong assumption. In particular, this estimate will not reflect the different sizes of resources behind each search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Search Engine Ranking and Selection Criterion</head><p>Given the cumulative score distribution cdf i and estimated number of documents that contain all query terms All i for both the whole collection and each search engine separately,    <ref type="figure" coords="5,146.73,298.26,3.74,8.64" target="#fig_0">1</ref>, we first estimate the cut-off score of a fixed number of top-ranked documents in the collection that at least should be in the ranking of the selected search engine. This number n c is a parameter of Taily. The probability of a document in the collection to be among the top-ranked documents can be calculated as:</p><formula xml:id="formula_18" coords="5,153.20,370.01,146.82,23.22">p c = n c All c<label>(13)</label></formula><p>where All c is the estimated number of documents in the collection with all query terms. The cut-off score s c of the top-n c documents can be estimated using the inverse of the cumulative density function:</p><formula xml:id="formula_19" coords="5,168.75,433.37,59.80,12.19">s c = cdf -1 c (p c</formula><p>) where p c is the probability defined above.</p><p>Using the score distribution in a search engine i, we can calculate the probability that a document in this search engine has a score higher than the cut-off score s c : p i = cdf i (s c ). The number of documents in search engine i that have a score above s c , written n i , can then be readily estimated 8 by n i = All i p i . The number of documents in search engine i with all query terms is a mere estimation (see 12), and the sum of estimates All i for all search engines not necessarily equals the overall estimate All c . Experimentally, this appeared to introduce inaccuracies in the results. As the improvement of score distribution estimates is an ongoing research topic <ref type="bibr" coords="5,285.91,578.80,10.58,8.64" target="#b1">[2]</ref>, we limit ourselves here to a simple solution. We assume that the estimation of the expected number of documents in the collection, All c , is accurate, such that 13 holds. A suitably normalized estimate of n i is hence</p><formula xml:id="formula_20" coords="5,114.65,639.17,185.37,24.77">n i = All i p i n c sum N j=1 p j All j .<label>(14)</label></formula><p>We are now able to define Taily's search engine selection criterion sel(q) for a query q that selects search engines with 8 In fact, we estimate the number of documents that have a score above sc and contain all query terms. This means that we have silently assumed that for the search engine to be selected, most documents above cut-off contain all query terms. Experimentally, this appears to hold if the cut-off is reasonably high, see e.g. Figure <ref type="figure" coords="5,118.78,741.35,6.64,6.91" target="#fig_0">1b</ref>.</p><p>an estimated number of documents in the top-m above a threshold:</p><formula xml:id="formula_21" coords="5,373.52,310.38,185.37,9.65">sel(q) = i i ∈ 1...N, n i &gt; v (<label>15</label></formula><formula xml:id="formula_22" coords="5,558.88,310.70,4.15,8.64">)</formula><p>where i is a shard index, and v is the selection threshold. Note that it can be beneficial for v to be higher than 0 because of the computational costs for including a shard with only very few estimated documents in the top ranks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Results</head><p>We present the results obtained based on the evaluation data. Table <ref type="table" coords="5,338.68,423.03,7.19,8.64" target="#tab_10">V</ref> shows the official overall evaluation scores of the runs utTailyM400, which uses Gamma distributions, and utTailyNormM400, which uses Normal distributions. Both runs used the parameter setting n c = 400. (We refer to the parameter n c as M in run names for legacy reasons).  We also performed additional analysis of our method. Figure <ref type="figure" coords="5,340.88,600.35,4.98,8.64" target="#fig_2">2</ref> shows the results. In Figure <ref type="figure" coords="5,462.94,600.35,9.40,8.64" target="#fig_2">2a</ref> we investigate the per query performance of utTailyM400 in terms of ndcg@20. The run shows low performance for a number of queries and significantly stronger performance for roughly the other half of the queries. Figure <ref type="figure" coords="5,428.48,648.17,9.96,8.64" target="#fig_2">2b</ref> shows the results of varying the parameter n c . We see that both Taily variants achieve stable performance close to the best achieved performance performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Conclusions</head><p>We presented an adaption of the Taily shard selection algorithm to resource selection in the Federated Web search scenario. As the expected feature value and the feature variance over the whole collection, which were used for shard selection, can be approximated by the expectation and the variance from a random sample the mathematical formalism was very similar to the original shard selection approach. There are the following areas of future work: 1) we used the number of sampled documents from each search engine as its size, which is clearly an over simplified estimate. In future work we propose to replace this estimate by existing estimates for the size of a database based on a sample. 2) The number of sample documents in Federated Web Search are small compared to the actual size of the search engines, which clearly affects the accuracy of the estimates. We expect that the case where no documents with a query term were sampled can lead to particularly large mistakes. We propose to make estimates more robust by smoothing techniques, which have improved performance performance in retrieval models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,48.96,250.91,514.07,8.82;3,48.96,262.72,514.07,9.65;3,48.96,275.00,302.73,8.64"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Intuition of the shard selection process for the web-track query 843 pol pot. The vertical bar indicates the cut-off score of the n c = 100 highest scored documents. The shown distributions are Gamma distributions fitted using the maximum likelihood and multiplied by the number of documents in the distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,140.07,233.75,97.04,7.77;5,344.34,208.84,178.14,7.56;5,424.37,215.52,4.69,7.56;5,324.95,204.90,10.73,7.56;5,325.05,185.08,10.73,7.56;5,324.95,165.25,10.73,7.56;5,325.05,145.42,10.73,7.56;5,324.95,125.59,10.73,7.56;5,325.05,105.76,10.73,7.56;5,324.95,85.94,10.73,7.56;5,325.05,66.11,10.73,7.56;5,316.23,128.12,7.56,22.78;5,358.05,73.11,22.84,9.07;5,358.05,81.45,21.03,9.07;5,368.94,233.46,108.93,8.06"><head></head><label></label><figDesc>Parameter sweep over nc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,213.24,250.43,185.50,8.64"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Unofficial experiments FedWeb Track</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="1,82.42,522.83,184.13,8.64"><head>TABLE I :</head><label>I</label><figDesc>Precision at 5 and 10 (50 queries)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="1,335.07,326.03,204.87,8.64"><head>TABLE II :</head><label>II</label><figDesc>High Relevance Precision (47 queries)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="1,324.77,484.89,225.46,8.64"><head>TABLE III</head><label>III</label><figDesc></figDesc><table /><note coords="1,368.97,484.89,181.26,8.64"><p>: Fraction of judged documents (50 queries)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="1,319.94,709.51,204.12,38.75"><head>TABLE IV :</head><label>IV</label><figDesc>Number of documents judged</figDesc><table /><note coords="1,319.94,739.83,187.15,8.43"><p>3 http://www.mansci.uwaterloo.ca/∼msmucker/cw12spam/</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="5,311.97,544.83,251.06,20.59"><head>TABLE V :</head><label>V</label><figDesc>Official FedWeb Result. Median and maximum performance shown for comparison.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,60.42,731.49,88.72,6.91"><p>http://mirex.sourceforge.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,60.42,741.35,237.86,6.91"><p>http://www.cs.utwente.nl/∼hiemstra/2013/anchor-text-for-clueweb12.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="2,323.43,714.45,239.60,6.91;2,311.97,723.42,251.06,6.91;2,311.97,732.38,251.06,6.91;2,311.97,741.35,157.56,6.91"><p>Note that Fig.1displays histograms with absolute frequencies. The fitted lines are the estimated density functions (based on the Gamma distribution), rescaled by the total number of documents included and its bin width, in order to allow visual comparison with the histograms.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="3,60.42,722.52,239.60,6.91;3,48.96,731.49,36.14,6.91"><p>Note that we consider score functions independently from their theoretical motivation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="3,60.42,742.10,162.59,5.61"><p>http://www.lemurproject.org/indri/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="4,323.43,723.42,239.60,6.91;4,311.97,732.38,251.06,6.91;4,311.97,741.35,167.21,6.91"><p>Note that cumulative distributions are usually defined in terms of the probability in the left tail. We differ from this practice because it simplifies the mathematical formalism used to describe Taily.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work was carried within and funded by several projects. <rs type="person">Robin Aly</rs> was supported by the <rs type="funder">EU</rs> Project <rs type="projectName">AXES</rs> (<rs type="grantNumber">FP7-269980</rs>), carried out at the <rs type="institution">University of Twente</rs>, The <rs type="funder">Netherlands</rs>. <rs type="person">Djoerd Hiemstra</rs> was supported by the <rs type="funder">Dutch national program COMMIT</rs>. <rs type="person">Dolf Trieschnigg</rs> was supported by the <rs type="funder">Folktales as Classifiable Texts (FACT)</rs> project, which is part of the <rs type="programName">CATCH programme</rs> funded by the <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs>. <rs type="person">Thomas Demeester</rs> was supported by the <rs type="funder">Ghent University</rs> -iMinds in Flanders. The experiments were conducted on the <rs type="institution">Hadoop Cluster from Sara</rs>, the Dutch center for super computing (www.sara.nl).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_XtTqZac">
					<idno type="grant-number">FP7-269980</idno>
					<orgName type="project" subtype="full">AXES</orgName>
				</org>
				<org type="funding" xml:id="_kfbQaaW">
					<orgName type="program" subtype="full">CATCH programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,65.56,465.08,234.46,8.64;6,65.56,477.04,234.46,8.64;6,65.56,488.82,234.46,8.59;6,65.56,500.77,234.46,8.59;6,65.56,512.73,234.46,8.82;6,65.56,524.86,234.46,8.64;6,65.56,536.81,163.10,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,249.44,465.08,50.58,8.64;6,65.56,477.04,210.75,8.64">Taily: shard selection using the tail of score distributions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Demeester</surname></persName>
		</author>
		<idno type="DOI">10.1145/2484028.2484033</idno>
		<ptr target="http://doi.acm.org/10.1145/2484028.2484033" />
	</analytic>
	<monogr>
		<title level="m" coord="6,65.56,488.82,234.46,8.59;6,65.56,500.77,234.46,8.59;6,65.56,512.73,112.73,8.82">Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, ser. SIGIR &apos;13</title>
		<meeting>the 36th international ACM SIGIR conference on Research and development in information retrieval, ser. SIGIR &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="673" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,65.56,548.77,234.46,8.64;6,65.56,560.55,234.46,8.82;6,65.56,572.68,98.71,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,219.36,548.77,80.65,8.64;6,65.56,560.73,134.40,8.64">Modeling score distributions in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,210.30,560.55,85.84,8.59">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,65.56,584.64,234.46,8.64;6,65.56,596.41,193.82,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,262.47,584.64,37.55,8.64;6,65.56,596.59,105.89,8.64">Where to stop reading a ranked list</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nussbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,193.18,596.41,36.15,8.59">TREC 08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,65.56,608.55,234.46,8.64;6,65.56,620.50,234.46,8.64;6,65.56,632.28,234.46,8.82;6,65.56,644.41,22.42,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,136.49,608.55,163.52,8.64;6,65.56,620.50,234.46,8.64;6,65.56,632.46,24.25,8.64">Some inconsistencies and misidentified modeling assumptions in probabilistic information retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,99.32,632.28,84.47,8.59">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="111" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,65.56,656.37,234.46,8.64;6,65.56,668.32,234.46,8.64;6,65.56,680.10,148.67,8.82" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,247.04,656.37,52.98,8.64;6,65.56,668.32,234.46,8.64;6,65.56,680.28,30.21,8.64">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1004.5168</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,65.56,692.23,234.46,8.64;6,65.56,704.19,234.46,8.64;6,65.56,715.96,234.46,8.82;6,65.56,727.92,234.46,8.82;6,65.56,740.05,139.02,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,188.09,692.23,111.93,8.64;6,65.56,704.19,234.46,8.64;6,65.56,716.14,15.36,8.64">Mapreduce for information retrieval evaluation: &quot;let&apos;s quickly test this on 12 tb of data</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hauff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,104.81,715.96,195.21,8.59;6,65.56,727.92,42.02,8.59">Multilingual and Multimodal Information Access Evaluation</title>
		<title level="s" coord="6,114.63,728.10,160.11,8.64">ser. Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6360</biblScope>
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.57,58.61,234.46,8.64;6,328.57,70.56,234.46,8.64;6,328.57,82.34,234.46,8.82;6,328.57,94.29,234.46,8.59;6,328.57,106.25,234.46,8.82;6,328.57,118.38,37.36,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,540.44,58.61,22.59,8.64;6,328.57,70.56,234.46,8.64;6,328.57,82.52,84.97,8.64">Score distribution models: assumptions, intuition, and robustness to score manipulation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,435.49,82.34,127.55,8.59;6,328.57,94.29,234.46,8.59;6,328.57,106.25,187.32,8.82">Proceeding of the 33rd international ACM conference on Research and development in information retrieval, ser. SIGIR. USA: ACM</title>
		<meeting>eeding of the 33rd international ACM conference on Research and development in information retrieval, ser. SIGIR. USA: ACM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,328.57,130.34,234.46,8.64;6,328.57,142.12,234.46,8.82;6,328.57,154.07,234.46,8.59;6,328.57,166.03,234.46,8.82;6,328.57,178.16,107.48,8.64" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,445.06,130.34,117.97,8.64;6,328.57,142.29,190.09,8.64">Document allocation policies for selective searching of distributed indexes</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,545.22,142.12,17.81,8.59;6,328.57,154.07,234.46,8.59;6,328.57,166.03,230.52,8.82">Proceedings of the 19th ACM international conference on Information and knowledge management, ser. CIKM &apos;10</title>
		<meeting>the 19th ACM international conference on Information and knowledge management, ser. CIKM &apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
