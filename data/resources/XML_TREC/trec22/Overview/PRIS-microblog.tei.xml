<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,175.10,82.70,245.12,14.07">PRIS at TREC 2013 Microblog Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.78,106.10,51.35,12.00"><forename type="first">Siming</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,218.09,106.10,37.46,12.00"><forename type="first">Zhe</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.93,106.10,52.40,12.00"><forename type="first">Yajing</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.42,106.10,44.07,12.00"><forename type="first">Hui</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.47,106.10,59.18,12.00"><forename type="first">Guang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,175.10,82.70,245.12,14.07">PRIS at TREC 2013 Microblog Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6141525285096B8A3F8118B5FEC12E8F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper described the real-time search system we built for TREC 2013 microblog track. We focused on query expansion and ranking algorithm and employed different strategies. For query expansion, we implied pseudo-relevance feedback using WAF algorithms and a refined 𝑡𝑓 * 𝑖𝑑𝑓 formula. For re-ranking part, our system makes use of various tweets' features, such as expansion terms, URL information, and incorporate them in a learning-to-rank framework to improve the final ranking results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relevance and recency are important factors in real-time Twitter search, which aims at addressing a search task whereby a user's information need is represented by a query at a specific time. This year's track consists of only one single task: real-time ad hoc search. The primary difference this year from the 2011-2012 microblog tracks lies in the tweet collection and the way that participants will interact with it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">system overview</head><p>The system we built for real-time search task is shown in Figure <ref type="figure" coords="1,426.68,481.61,4.40,9.77">1</ref>. We dealt with Tweet2013 corpus and topics in parallel. Firstly, we downloaded the corpus remotely via a search API and did the preprocessing work. A corpus of webpage, whose links are provided in tweets are fetched by a self-designed crawler. Then we built index of tweet corpus and webpage corpus respectively, using Lemur IR toolkit. As for the topics, we used two methods for query expansion. Finally, we used a simple but effective learning to rank model which combines useful features of tweets, and re-sorted the tweets according to their relevance scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevant tweets</head><p>Figure <ref type="figure" coords="2,230.69,418.90,5.52,9.96">1</ref> The framework of ad hoc search system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">dataset and preprocessing</head><p>For TREC 2013, the collection consists of approximately 240 million tweets over a two-month period: 1 February, <ref type="bibr" coords="2,241.28,481.61,23.49,9.77">2013</ref><ref type="bibr" coords="2,332.19,481.61,74.44,9.77">-31 March, 2013 (inclusive) (inclusive)</ref>. We get the official collection through the search API and downloaded each topic's top 10,000 tweets as our original corpus.</p><p>Due to the limited length of the tweet text, it fails to provide adequate information. We downloaded the URL links extracted from tweets to obtain external evidence. The total number of tweets with one or more URLs was 178,982.</p><p>In the preprocessing step, we performed two ways as following:</p><p> Retweets removal .Some tweets with the sign of 'RT' are regarded as retweets, we eliminated the information after RT and kept the non-RT part.</p><p> Non-English tweets removal. Microblogs are multi-lingual, as all topics are expressed in English, non-English tweets will be judged non-relevant, we use a Language-Detection to filter non-English tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query Expansion</head><p>In this stage, we are expected to mine the words that have strong connection with a given topic so as to improve document retrieval performance with more adequate information. Two algorithms were applied in this stage: the Word Activation Force algorithm and 𝑡𝑓 * 𝑖𝑑𝑓 method. Both of the two methods use pseudo-relevance feedback approach to make the most of local resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Word Activation Force Algorithm</head><p>The Word Activation Force algorithm (WAF) is based on the assumption that there's a special force in documents helping human brains activate associates of a word, such as 'papers' activates strongly 'articles' or 'letters'. It believes that there are latent structures of word network in documents. The WAF proposes an effective approach mapping syntactical and semantic information into sparse directed networks, comprehensively highlighting the features of individual word. Based on the directed networks, sensible word clusters and hierarchies can be efficiently discovered.</p><p>We used pseudo-relevance feedback approach, assuming that top-ranked tweets retrieved by API to be relevant. Thus we regarded the text of top-ranked tweets as the basic set to do query expansion.</p><p>Then words occurrence and co-occurrence were calculated in the basic set. We use the follow annotations:</p><p>• 𝑓 𝑖 ,the frequency of word 𝑖 in the basic set;</p><p>• 𝑓 𝑖𝑗 ,the co-occurrence of word 𝑖 to word 𝑗 in the basic set, which indicates the frequencies of pairs (𝑖, 𝑗) where 𝑖 precedes 𝑗 by up to 𝐿 words(𝐿 = 4 in our study); • 𝑑 𝑖𝑗 , the average word distance between word 𝑖 and word 𝑗.</p><p>Then the word activation force of word 𝑖 to word 𝑗, or 𝑤𝑎𝑓 𝑖𝑗 , can be calculated as follows:</p><formula xml:id="formula_0" coords="3,258.29,424.14,247.21,31.46">𝑤𝑎𝑓 𝑖𝑗 = 𝑓 𝑖𝑗 𝑓 𝑖 𝑓 𝑖𝑗 𝑓 𝑗 𝑑 𝑖𝑗 2 (1)</formula><p>We identify that the statistic is defined in the same form of the universal gravitation. It is obvious that all the element values in the WAF matrix is between 0 and 1. Zero means that word 𝑖 is never followed by word 𝑗 within our word window in the basic set, while one means that word 𝑖 and 𝑗 are always adjacent like a compound( 𝑓 𝑖𝑗 = 𝑓 𝑗 = 𝑓 𝑖 , 𝑑 𝑖𝑗 = 1) With the WAF Matrix above, we can calculate the closeness of word 𝑖 and 𝑗, namely affinity, as follows:</p><formula xml:id="formula_1" coords="3,165.02,573.19,307.27,27.61">𝐴 𝑖𝑗 𝑤𝑎𝑓 = 1 𝐾 𝑖𝑗 𝑂𝑅 𝑤𝑎𝑓 𝑘𝑖 , 𝑤𝑎𝑓 𝑘𝑗 𝑘∈𝐾 𝑖𝑗 • 1 𝐿 𝑖𝑗 𝑂𝑅 𝑤𝑎𝑓 𝑖𝑙 , 𝑤𝑎𝑓 𝑗𝑙 𝑙∈𝐿 𝑖𝑗 1 2</formula><p>(2)</p><p>where 𝐾 𝑖𝑗 = {𝑘|𝑤𝑎𝑓 𝑘𝑖 &gt; 0 𝑜𝑟 𝑤𝑎𝑓 𝑘𝑗 &gt; 0} and 𝐿 𝑖𝑗 = {𝑙|𝑤𝑎𝑓 𝑖𝑙 &gt; 0 𝑜𝑟 𝑤𝑎𝑓 𝑗𝑙 &gt; 0} .</p><p>And 𝑂𝑅(𝑥, 𝑦) = 𝑚𝑖𝑛(𝑥, 𝑦)/𝑚𝑎𝑥(𝑥, 𝑦). The Affinity Matrix enables us to discover the association between words in the basic set. We calculated the Affinity Matrix of basic set, and returned top-scored words that associate to the topic word, assuming that high relevant words would have larger affinity value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">𝑇𝑓 * 𝑖𝑑𝑓 method</head><p>Besides WAF algorithm, we implemented an equation that measures each term's wei ghting score.</p><p>𝑊𝑒𝑖𝑔𝑡 𝑡 = 𝑖𝑑𝑓 𝑇 * 𝑠𝑐𝑜𝑟𝑒 𝑑 * 𝑡𝑓(𝑑, 𝑇) 𝑑∈𝐷(𝐾)</p><p>(3)</p><p>Where 𝐷(𝐾) is the collection of top-K tweets retrieved by API search. 𝑖𝑑𝑓(𝑇) is the term's inverse document frequency in the whole collection. 𝑇𝑓 (𝑑, 𝑇) is the term frequency that occur in the tweet, and 𝑠𝑐𝑜𝑟𝑒(𝑑) is that tweet's score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Scoring and Ranking</head><p>Due to the limited length of the tweet text, it fails to provide adequate information. The previous research shows that whether containing URL is an important feature for a tweet. Besides, the expand words which are closely associated with the topic may contain some key information. In our ranking method, we considered both these factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Ranking Model</head><p>To rank the relevance, we use the learning to rank technique, which was successfully used in TREC 2011&amp;2012 Microblog Track. We designed a simple linear model to combine features extracted from tweets. Given a query Q and a tweet D, the relevance 𝑠𝑐𝑜𝑟𝑒(𝑄, 𝐷) can be computed as follows:</p><formula xml:id="formula_2" coords="4,245.93,370.01,259.45,14.28">𝑠 𝑄, 𝐷 = 𝜆 𝑖 𝑓 𝑖 (𝑄, 𝐷) 𝑁 𝑖 (4)</formula><p>where N is the number of the features, and 𝜆 𝑖 is the coefficient of each feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Feature Extraction</head><p>The tweets we downloaded from the search API are in JSON format, which contains various features to extract. Based on previous study, we carefully analyzed the structure of microblog, and divided the features into three parts: Text_Feature, Non_text_Feature and Author_Feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Features of tweets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text_Feature</head><p>Author_Feature Non_text_Feature</p><formula xml:id="formula_3" coords="4,130.82,563.95,314.81,92.67">Text_score(Q,D) Followers_Count(D) T_diff(Q,D) Length(D) Retweeted_count(D) Has_hashtag(D) Oov_pct(D) Statuses_count(D) Has_url(D) Stopwd_ratio(D) Friends_count(D) URL_score(Q,D) Expanded_ratio(Q,D) Listed_count(D)</formula><p>Based on the features' importance and the original information that tweets can provide, we chose the Text_score(Q,D), Expanded_ratio(Q,D) and URL_score(Q,D) in the Microblog Track.</p><p> Text_score(Q,D): Besides the relevance score provided by API, which uses Lucene's implementation of query likelihood , we also use Lemur IR toolkit Indri to build index by field. And then we use both the API search relevance scores and Indri query scores.  Expanded_ratio(Q,D): It depends on the the number of extension words appeared in the tweet and the total number of extension words.  URL_score(Q,D): As the URL in the microblog is an important feature, we crawled the URL pages which appeared in the tweets and build the index of webpages' titles and contents. Then we got the normalized relevance score. We used the 2011 and 2012 dataset as the train set. To get the maximum value of P@30,we found that the number of extension words should be about 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Results Submission</head><p>In this year's TREC Microblog Track, we submitted 4 versions of runs: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,123.62,262.90,327.77,90.57"><head>Table 2 . Four runs our team submitted</head><label>2</label><figDesc></figDesc><table coords="5,123.62,279.27,327.77,74.21"><row><cell>Run_Id</cell><cell>Text_score</cell><cell>Expanded_ratio</cell><cell>URL_score</cell></row><row><cell>PrisRun1</cell><cell>API</cell><cell>Yes(WAF)</cell><cell>No</cell></row><row><cell>PrisRun2</cell><cell>Indri</cell><cell>Yes(WAF)</cell><cell>No</cell></row><row><cell>PrisRun3</cell><cell>API</cell><cell>Yes(WAF)</cell><cell>Yes</cell></row><row><cell>PrisRun4</cell><cell>API</cell><cell>Yes(tf*idf)</cell><cell>Yes</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
