<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,70.80,72.03,468.16,17.22;1,54.48,91.95,500.91,17.22;1,237.36,111.87,135.01,17.22">University of Glasgow at TREC 2013: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,92.40,157.58,99.24,11.47"><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
						</author>
						<author>
							<persName coords="1,201.12,157.58,88.91,11.47"><forename type="first">M-Dyaa</forename><surname>Albakour</surname></persName>
						</author>
						<author>
							<persName coords="1,89.76,169.82,70.70,11.47"><forename type="first">Stuart</forename><surname>Mackie</surname></persName>
						</author>
						<author>
							<persName coords="1,169.56,169.82,96.77,11.47"><forename type="first">Nut</forename><surname>Limosopathan</surname></persName>
						</author>
						<author>
							<persName coords="1,269.88,169.82,28.37,11.47;1,122.64,182.30,58.25,11.47"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
						</author>
						<author>
							<persName coords="1,207.72,182.30,57.70,11.47"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
						</author>
						<author>
							<persName coords="1,370.68,157.58,81.98,11.47;1,452.64,151.32,1.54,6.38"><forename type="first">B</forename><forename type="middle">Taner</forename><surname>Din√ßer</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept of Statistics &amp; Computer Engineering</orgName>
								<orgName type="institution">Mugla University Mugla</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,70.80,72.03,468.16,17.22;1,54.48,91.95,500.91,17.22;1,237.36,111.87,135.01,17.22">University of Glasgow at TREC 2013: Experiments with Terrier in Contextual Suggestion, Temporal Summarisation and Web Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">12004093A0C1BDCD36C44B580666DD2D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2013, we focus on tackling the challenges posed by the new Contextual Suggestion and Temporal summarisation tracks, as well as enhancing our existing technologies to tackle the new risk-sensitive aspect of the Web track, building upon our Terrier Information Retrieval Platform. In particular, for the Contextual Suggestion track, we investigate how to exploit location-based social networks, with the aim of better identifying venues within a city that a given user might be interested in visiting. For the Temporal Summarisation track, we propose a new summarisation framework and investigate novel techniques to adaptively alter the summarisation strategy over time. For the TREC Web track, we continue to build upon our learning-to-rank approaches and novel xQuAD / Fat frameworks within Terrier, increasing effectiveness when ranking and examining two new approaches to risk-sensitive retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In TREC 2013, we participate in Web adhoc and risksensitive tasks, the Contextual Suggestion track "entertain me" task and the Temporal Summarisation sequential update summarisation task. Our focus is the development of effective and efficient approaches to these tasks, building upon our open-source Terrier Information Retrieval (IR) platform <ref type="bibr" coords="1,91.92,525.90,13.37,8.66" target="#b16">[16]</ref>. Indeed, our Web track participation focuses on further developing the core data-driven ranking models and infrastructure within Terrier, in-line with the Terrier vision <ref type="bibr" coords="1,80.03,557.22,9.11,8.66" target="#b9">[9]</ref>. Meanwhile, our Contextual Suggestion and Temporal Summarisation participations revolve around the development of new real-time streaming applications and technologies building upon Terrier.</p><p>In the Contextual Suggestion track, our aim is to develop effective approaches to identify venues that a user with a given past history might be interested in visiting within a city. This task is challenging, since without an explicit representation of the user's current information need, the potential interests of the user need to be inferred from the sparse user profile. We propose a novel approach to tackle contextual suggestion that exploits implicit knowledge within freely available location-based social networks regarding the popularity of venues, as well as venue density information * Work conducted while visiting the University of Glasgow.</p><p>to better identify the currently 'hot' venues in a city that match the user's profile. Furthermore, we also investigate a new approach that uses an explicit diversification strategy to increase the coverage of venue types in the top of the venue ranking suggested.</p><p>We also participate in the sequential update summarisation task of the Temporal Summarisation track. The major goal of our participation is to develop effective incremental summarisation approaches for a given event. To this end, we propose a new summarisation framework that combines both effective document search approaches within Terrier with state-of-the-art summarisation techniques to produce extractive summaries that update over time. Using an implementation of this framework within the Storm distributed stream processing framework, <ref type="foot" coords="1,438.48,398.56,3.65,4.16" target="#foot_0">1</ref> we developed a wide variety of summarisation strategies optimised for different conciseness, cohesiveness and diversity scenarios. Moreover, we also proposed and deployed two novel adaptive content selection techniques that use topic modelling adaptively alter the summarisation strategy over time to minimise topic drift.</p><p>In our participation in the Web track, our primary goal is to enhance our data-driven learning infrastructure within Terrier for use on the new ClueWeb12 corpus. In particular, for the adhoc ranking task, we deploy our state-of-the-art xQuAD / Fat frameworks within Terrier using a variety of relevance, authority, quality and spam features. For the risksensitive task, we employ a novel risk-sensitive learning to rank algorithm and a new approach that selectively applies one of a set of document ranking models based upon an estimate of their predicted riskiness for the current query.</p><p>The remainder of this paper is structured as follows. In Section 2, we describe our participation in the Contextual Suggestion track. Section 3 details our participation in the new Temporal Summarisation track. In Section 4, we describe our Web track adhoc and risk-sensitive task participations. Conclusions are provided in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CONTEXTUAL SUGGESTION TRACK</head><p>The main aim of our participation in the TREC 2013 Contextual Suggestion track is to extend and refine novel contextual retrieval models, which we have developed upon our Terrier IR platform to address emerging information needs in smart cities, such as the "entertain me" zero-queries tackled in this track.</p><p>The emergence of Location-based Social Networks (LSNs) such as FourSquare and Facebook Places offer enormous information that can be exploited to address the contextual recommendation problem in smart cities. Our approach aims at exploiting both the social aspect of the users in these networks, and the rich structured information available about the venues covered by these networks. We employ both aspects to effectively recommend to users venues to visit, without issuing a query. This is achieved by mining the implicit context of the users inferred from their location and the explicit interests in their profile.</p><p>To produce a personalised ranking of the venues for a given user, we build textual representations of both the user's profile and the venues available in the LSN. Using a vector representation, we construct a profile of the user from the available explicit judgements. We take the 5-rating scores (0 to 4) given by the user in the track dataset and convert them into positive and negative judgements that are then incorporated into the vector representation. For the venues, we use the home page of the venue on the LSN as a textual representation. The home page of the venue contains information about the venue such as its name, its description and the category of that venue. In addition, it incorporates a social aspect in the form of the comments provided by users. Such information enriches the vector representations of the venue. Generally, our approach aims at computing the textual similarity between the profile of the user and the venues close to the user. Using this similarity score, we can rank the venues and recommend them to the user. We then incorporate other features available about the venues from the LSN as follows:</p><p>First, we introduce a social aspect to the venue ranking by integrating an estimation of the popularity of the venue as obtained from the previous interactions of the users on the LSNs. In our estimation of the popularity, we take into account the fact that the size and the population of an area or a city may affect the volume of the user activity on the LSNs. Therefore, we normalise the popularity estimate by considering all the venues in the surrounding areas, such that venues with lower volume of LSN activity within less populated areas are boosted and vice versa.</p><p>Moreover, we recognise that a zero-query is ambiguous by definition. Hence, inspired by diversification approaches in web search to address ambiguous queries, we develop and deploy a personalisation model based on the xQuAD diversification framework <ref type="bibr" coords="2,139.42,548.94,13.37,8.66" target="#b20">[20]</ref>. Our model personalises the recommended venues to cover the categories of interest for each user -these categories of interest are inferred automatically from the user's profile.</p><p>Using the Foursquare LSN, we crawl venues for the various contexts (cities) used in the track. Using these venues, we devised three different runs to evaluate our approach described above (uogTrCF, uogTrCFX and uogTrCFP). Only the last two were submitted:</p><p>‚Ä¢ uogTrCF: This run serves as our baseline. Venues for each user profile and context pair are ranked using the similarity score between the user profile and the venue.</p><p>‚Ä¢ uogTrCFP: This run investigates the usefulness of using the social popularity feature to inform the selection of venues. similarity and the normalised popularity of the venue estimated. The normalised popularity of the venue is estimated by using the volume of the user population visits (FourSquare "checkin"s) and taking into consideration the overall volume of the user population visits in the surrounding area.</p><p>‚Ä¢ uogTrCFX: This run re-ranks venues in order to cover diverse categories of the user interests using the xQuAD framework as described above. The categories used are those available on the venue's profile on FourSquare.</p><p>In particular, we use the top level category from the hierarchy of venues' categories provided in FourSquare.</p><p>Table <ref type="table" coords="2,352.67,329.22,4.61,8.66" target="#tab_0">1</ref> reports the performance of our two submitted runs and the non-submitted run together with the TREC Median using the official measures. First, we observe that our submitted runs achieve above median performance for all measures (with the exception of P@5 for the uogTrCFX run, which provides equivalent performance). In particular, the uogTrCFP run, which incorporates the social popularity, achieves the best performance. This highlights the importance of the venue popularity signal when recommending places that a user might wish to visit. Our diversification run (uogTrCFX) that attempts to increase the number of venue categories appearing the the top ranks is also promising as it outperforms the baseline (uogTrCF), which does not consider diversification. However, we need to investigate more elaborate techniques when mapping between the user interests and a finer-grained category of the venue. For example, a better personalisation approach should differentiate between various types of cuisines, instead of targeting all the restaurants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TEMPORAL SUMMARISATION TRACK</head><p>The aim of our participation in the first year of the Temporal Summarisation track is to investigate real-time extractive models for the summarisation of events from across multiple streams. For our participation in the sequential update summarisation task, we extend the real-time search capabilities of the Terrier IR platform <ref type="bibr" coords="2,429.70,606.30,14.19,8.66" target="#b16">[16]</ref> to facilitate the incremental extractive summarisation and tracking of search topics in an extensible manner. In this way, we combine the effectiveness of state-of-the-art search techniques for finding relevant content with incremental summarisation strategies to filter down to a concise description of each event that can be updated over time. Furthermore, we investigate novel approaches to adaptively re-adjust the summarisation strategy over time with respect to the topic's prominence and the novelty of content available, as a means to tackle topic drift and reduce verbosity in the resultant summarisation. To perform summarisation, we define a core summarisation framework that enables us to examine different summarisation strategies. Under this framework, new documents are processed in temporal batches of one hour, resulting in zero or more sentences from those batches being emitted for the topic for that hour. Figure <ref type="figure" coords="3,227.04,301.02,4.61,8.66" target="#fig_0">1</ref> illustrates how an hour batch of documents is processed. In particular, each document batch is processed by three levels, namely: document; sentence and temporal. At the document level, the new batch of documents representing the current hour is indexed by the Terrier instance and then the top 10 documents are ranked by their relatedness to the topic representation (query), producing a ranked list of the most related content from within the streams from the last hour. At the sentence level, the sentences within each of the 10 ranked documents are then ranked using a second target criteria (relatedness to the document front-matter, topical relevance or documentlevel salience), identifying the sentences that are most likely to be useful for inclusion. Next, a selection strategy is applied to the ranked sentences, filtering out redundant sentences in a greedy manner. The remaining candidate sentences are then passed to the temporal level to be compared against the current representation of the event. Any novel content that was not selected from prior batches is both emitted as updates and is also used to enrich the topic representation.</p><p>Using the core summarisation framework, we deploy three different extractive summarisation strategies by employing different techniques at each level of the framework, resulting in three different runs (uogTrNSQ1, uogTrNMM and uogTrEMMQ2)</p><p>‚Ä¢ uogTrNSQ1: A precision-orientated run that focuses on filtering at the sentence level. In particular, it selects only most related sentence to the topic from each hourly batch.</p><p>‚Ä¢ uogTrNMM: Leverages a more recall-orientated multidocument summarisation strategy, using the Maximal-Marginal Relevance (MMR) <ref type="bibr" coords="3,188.98,650.94,9.63,8.66" target="#b3">[3]</ref> algorithm to select novel content from each ranked document each hour.</p><p>‚Ä¢ uogTrEMMQ2: Uses topic expansion from a timely Wikipedia corpus and WordNet at the sentence level to more accurately identify sentences related to the topic.  However, within each of the data streams, we observed a high variance in a topic's prominence as it evolves over time. As a result, during periods of low prominence, weaklyrelated or off-topic content is likely to be summarised, leading to topic drift within the final summary. Hence, there is a need to identify when to avoid incorporating off-topic content into the summaries. To tackle this issue, we proposed and deployed two novel adaptive content selection techniques that use topic modelling at the document level to gauge topic prominence for a period of time, allowing the readjustment of the volume of content to be summarised when novel updates are less frequent, resulting in two further runs (uogTrNMTm1MM3 and uogTrNMTm3FMM4):</p><p>‚Ä¢ uogTrNMTm1MM3: Uses a three-state automaton (no-content, limited-content and bursting) to determine the volume of content to select from each hourly batch. The automaton state is determined via overlap between the given topic representation and a set of topical areas generated by Gibb's sampling over the top documents ranked.</p><p>‚Ä¢ uogTrNMTm3FMM4: Uses a more recall-focused adaptive technique. Computes the degree of overlap between the given topic representation and topical areas generated by Gibb's sampling and uses it to estimate the amount of content to select. This run also leverages a post-summarisation filtering technique based on a combination of topical relevance and sub-stream priors (news vs. social, vs. forum) to increase the quality of the generated summaries.</p><p>Table <ref type="table" coords="3,350.27,480.78,4.61,8.66" target="#tab_2">2</ref> reports the performance of our five submitted runs in terms of expected latency gain and latency comprehensiveness. From our submitted runs, we observe the following points of interest. First, in terms of expected latency gain, precision-orientated runs outperform recall-orientated runs by a large margin, indicating that the recall orientated runs are being heavily penalised for returning many updates. This in turn indicates that, under the track measures, small summaries (&lt;100 sentences) are preferable. Second, of the non-adaptive runs submitted, we see that the recall-orientated run using MMR provides the best compromise between expected latency gain and latency comprehensiveness, showing that within-document diversification is an important direction for future investigation. Meanwhile, the lower performance of uogTrEMMQ2 in comparison to uogTrNMM indicates that the topic expansion strategy tested that leverages Wikipedia and WordNet was not effective. This is because the expansion process caused topic drift in the summaries produced. Finally, comparing the adaptive runs to the non-adaptive runs, we see that both adaptive runs outperform all of the non-adaptive runs submitted in terms of expected latency gain, indicating that adapting the sentence selection strategy over time is critical for effective temporal update summarisation. Indeed, the adaptive uogTrNMTm1MM3 run outperforms the average of TREC systems under expected latency gain.</p><p>Overall, we conclude that the core summarisation framework that we proposed can be effective for sequential update summarisation. However, the techniques employed at each layer should focus on increasing precision due to the high levels of redundancy in the corpus. Moreover, as illustrated by our adaptive summarisation runs, altering the sentence selection strategy over time is a promising area to improve summarisation effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">WEB TRACK</head><p>In our participation to the adhoc and risk-sensitive tasks of Web track, we have two aims. First, to enhance and assess the performance of our data-driven learning infrastructure <ref type="bibr" coords="4,89.89,232.50,14.19,8.66" target="#b10">[10]</ref> that has proven effective during previous participations <ref type="bibr" coords="4,99.95,243.06,9.63,8.66" target="#b8">[8,</ref><ref type="bibr" coords="4,114.11,243.06,11.68,8.66" target="#b12">12,</ref><ref type="bibr" coords="4,130.30,243.06,11.68,8.66" target="#b13">13,</ref><ref type="bibr" coords="4,146.50,243.06,11.68,8.66" target="#b21">21]</ref> for the more recent ClueWeb12 corpus. Second, to investigate approaches to risk-aware retrieval. To this end, we begin by investigating learning to rank approaches within Terrier using our fat framework <ref type="bibr" coords="4,278.64,274.38,14.19,8.66" target="#b11">[11]</ref> for the fast computation of document features. Similar to past TREC participations <ref type="bibr" coords="4,159.10,295.26,14.19,8.66" target="#b13">[13,</ref><ref type="bibr" coords="4,175.78,295.26,6.42,8.66" target="#b8">8]</ref>, we train upon ClueWeb09. We then propose and examine two new approaches to minimise risk-sensitivity within a learning environment, based on risk-sensitive learning to rank <ref type="bibr" coords="4,188.73,326.70,14.19,8.66" target="#b22">[22]</ref> and the predictive selection of retrieval models per-query using estimated risk.</p><p>We index category A (‚àº716M English documents) and category B (‚àº50M English documents) subsets of the Clue-Web12 corpus without stemming or stopwords. At retrieval time, we apply one of several retrieval models (DPH from the Divergence from Randomness framework <ref type="bibr" coords="4,218.72,389.46,9.11,8.66" target="#b1">[1]</ref>, DFIC from the Divergence from Independence framework <ref type="bibr" coords="4,227.97,399.90,9.63,8.66">[6]</ref> or BM25) to identify the sample documents to re-rank using the learned models. Following the recommendations of <ref type="bibr" coords="4,237.56,420.90,14.19,8.66" target="#b11">[11]</ref> for Clue-Web09, we select the top 5000 documents for re-ranking using learning to rank, where the weighting model does not consider anchor text.</p><p>For applying learning to rank, our category A and B runs both use a total of 63 features, as described in Table <ref type="table" coords="4,262.66,473.10,3.56,8.66" target="#tab_3">3</ref>. Note that many different weighting model features are computed, as they can contribute differently to the learned models <ref type="bibr" coords="4,275.98,494.10,13.39,8.66" target="#b11">[11]</ref>. We also observe that there is no need to train the hyperparameters of those weighting models that typically control document length normalisation, as the learning to rank technique will implicitly address any bias towards short or long documents as part of its learning process <ref type="bibr" coords="4,221.74,546.42,13.37,8.66" target="#b11">[11]</ref>.</p><p>The same features are computed on ClueWeb09 queries for the purposes of training. We thereafter deploy two learning to rank techniques, namely AFS <ref type="bibr" coords="4,183.82,577.74,14.19,8.66" target="#b14">[14]</ref> -which creates a linear learned model -and also the state-of-the-art LambdaMART learning to rank technique <ref type="bibr" coords="4,163.67,598.62,9.63,8.66" target="#b7">[7,</ref><ref type="bibr" coords="4,176.62,598.62,10.64,8.66" target="#b23">23]</ref>, <ref type="foot" coords="4,190.80,597.28,3.65,4.16" target="#foot_1">2</ref> which creates a learned model based on regression trees. To train the learning to rank techniques, we use 200 queries from the the TREC Web tracks 2009-2012, randomly split into training and validation sets, so as to prevent overfitting.</p><p>Moreover, we tested the sensitivity of the learned models wrt. the document weighting model that is used to generate the initial ranking of documents, by contrasting new ranking models from the Divergence from Independence (DFI) and Divergence from Randomness (DFR) families.</p><p>Next, for the purposes of the risk-sensitive retrieval task, we experimented with two techniques for reducing risk during retrieval: In particular, through a thorough statistical analysis of 115 features that are calculated for each query, we trained a novel selection technique that aimed to select the most effective/safe retrieval strategies for a given query; We also investigated the adaptation of a learning to rank technique that makes it inherently sensitive to risk when learning a ranking model, also known as URISK <ref type="bibr" coords="4,512.04,141.06,13.37,8.66" target="#b22">[22]</ref>.</p><p>We submitted six runs to the adhoc and risk-sensitive retrieval tasks of the Web track, covering both category A and category B of the ClueWeb12 corpus, and deploying 63 features on both corpora for the purposes of learning to rank. On category A: uogTrAIwLmb combines DFI and a regression trees-based learning to rank technique; uog-TrADnLrb uses instead a DFR model and a risk-sensitive learning to rank technique; uogTrAS1Lb and uogTrAS2Lb are selective approaches, using different learned models on a per-query basis; Finally, on category B, uogTrBDnLaxw and uogTrBDnLmxw deploy a DFR model and our existing effective xQuAD diversification framework <ref type="bibr" coords="4,483.20,266.58,13.37,8.66" target="#b19">[19]</ref>, differing only in the type of learning to rank technique deployed, namely linear vs. regression trees. Table <ref type="table" coords="4,451.03,287.46,4.61,8.66" target="#tab_4">4</ref> summarises the configuration of each of six submitted runs, as well as 6 unsubmitted runs that we also evaluate.</p><p>Table <ref type="table" coords="4,350.39,318.90,4.61,8.66" target="#tab_5">5</ref> reports the effectiveness of all six of our submitted Web track runs<ref type="foot" coords="4,379.44,327.89,3.65,4.16" target="#foot_2">3</ref> , as well as various unsubmitted runs, and the four provided standard baselines. Results are reported in terms of NDCG@20 and ERR@20, as well as risk-aware URISK variants for Œ± = 1 and Œ± = 5, compared to the Indri query likelihood unfiltered standard baseline for the respective category. <ref type="foot" coords="4,396.72,380.21,3.65,4.16" target="#foot_3">4</ref> Firstly, on analysing the submitted runs based on the category B subset of ClueWeb12, we have the following observations:</p><p>‚Ä¢ In contrast to previous results on the ClueWeb09 corpus <ref type="bibr" coords="4,356.88,431.46,9.63,8.66" target="#b4">[4,</ref><ref type="bibr" coords="4,370.55,431.46,10.64,8.66" target="#b18">18]</ref>, category B of ClueWeb12 provided overall lower performance than category A. This can be attributed to a much lower number of relevant documents per-topic found in the category B subset of ClueWeb12 (approx. 19%), compared to ClueWeb09 which was used for training (approx. 49% for TREC 2009 <ref type="bibr" coords="4,360.72,494.22,13.54,8.66" target="#b18">[18]</ref>).</p><p>‚Ä¢ Comparing uogTrBDnLaw with uogTrBDnLmw, and uogTrBDnLaxw with uogTrBDnLmxw, we find that the linear AFS learning to rank techniques gives generally higher effectiveness (one exception for xQuAD according to ERR@20).</p><p>‚Ä¢ The xQuAD diversification framework always improves adhoc effectiveness: uogTrBDnLaxw vs. uogTrBDnLaw, uogTrBDnLmxw vs. uogTrBDnLmw. This is in line with our previous observations for ClueWeb09 <ref type="bibr" coords="4,528.45,605.82,9.11,8.66" target="#b8">[8]</ref>.</p><p>‚Ä¢ Finally, for each adhoc effectiveness measure, the most effective run is also the most risk-averse compared to the Indri standard baseline run, according to the corresponding URISK measure.</p><p>Features Total Sample: DPH, DFIC or BM25 1 Weighting models on the whole document <ref type="bibr" coords="5,210.06,74.16,12.53,7.32" target="#b11">[11]</ref> (DFRee, DPH <ref type="bibr" coords="5,278.33,74.16,8.11,7.32" target="#b1">[1]</ref>, PL2 <ref type="bibr" coords="5,309.06,74.16,8.11,7.32" target="#b1">[1]</ref>, BM25, Dirichlet LM, MQT <ref type="bibr" coords="5,421.36,74.16,11.85,7.32" target="#b10">[10]</ref>, LGD, DFIC <ref type="bibr" coords="5,484.15,74.16,8.11,7.32">[6]</ref>, DFIZ <ref type="bibr" coords="5,519.60,74.16,8.81,7.32">[6]</ref>) 8 Weighting models as above on each field, namely: title, URL, body and anchor text; + PL2F 37 Term-dependence proximity models (MRF <ref type="bibr" coords="5,212.36,91.20,11.85,7.32" target="#b15">[15]</ref>, pBiL <ref type="bibr" coords="5,249.98,91.20,12.57,7.32" target="#b17">[17]</ref>) 2 URL (e.g. length) link (e.g. inlink counts) &amp; content quality (e.g., fraction of stopwords, table text <ref type="bibr" coords="5,412.53,99.78,8.11,7.32" target="#b2">[2]</ref>, spam classification <ref type="bibr" coords="5,494.34,99.78,8.78,7.32" target="#b5">[5]</ref>) features 15 TOTAL 63 Next, on analysing the category A runs, we obtain the following observations:</p><p>‚Ä¢ Our data-driven learning to rank approaches were all substantially above the both the TREC median performances, and the standard Indri baselines provided by the organisers.</p><p>‚Ä¢ Our most effective run, uogTrAIwLmb, deployed DFIC, weak stemming and LambdaMART.</p><p>‚Ä¢ Next, comparing the learning to rank techniques, we find no clear winner for AFS vs. LambdaMART: uog-TrAIwLmb (LambdaMART) is more effective than uog-TrAIwLab (AFS), but uogTrABwLab is more effective than uogTrABwLmb.</p><p>‚Ä¢ Comparing uogTrADnLrb and uogTrADnLmb, we observe that risk-aware LambdaMART using URISK can slightly improve adhoc ERR@20 compared to normal LambdaMART (at the cost of marginal NDCG@20 loss). This combination also markedly reduces risk, both for NDCG@20 and ERR@20. Indeed, for ERR@20, uogTrADnLrb exhibits the best URISK performance across all of our runs.</p><p>‚Ä¢ Our selective approaches, uogTrAS1Lb and uogTrAS2Lb (which selects between two runs and three runs, respectively), are very similar in effectiveness. Their observed effectiveness' intersect the performance of their respective constituent runs.</p><p>‚Ä¢ Finally, in line with our category B observations, our most effective category A run (uogTrAIwLmb) is also the most risk-averse, according to the URISK measures.</p><p>Overall, we conclude that with performances substantively about track median, our general data-driven approach based on learning to rank for Web search is effective. Diversification remains an excellent technique to enhance adhoc effectiveness. Finally, compared to standard query likelihood Indri baseline runs, we find that risk-averseness is correlated with effectiveness, but that a risk-aware version of Lamb-daMART can reduce the amount of risk observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>In TREC 2013, we participated in the Web adhoc and risk-sensitive tasks, the Contextual Suggestion track "entertain me" task and the Temporal Summarisation sequential update summarisation task, building upon our Terrier IR platform. In particular, for the Web track, we leveraged data-driven learning using our state-of-the-art xQuAD and Fat frameworks, markedly outperforming the median of TREC systems, as well as investigating new machine learning and per-query selective approaches to minimise risk when ranking. For the Contextual Suggestion track, we proposed a novel approach that leverages localised popularity and density estimations from location-based social networks to better suggest currently 'hot' venues for the user. Finally, for the Temporal Summarisation track, we proposed a new new summarisation framework that combines both effective search approaches with state-of-the-art summarisation to produce extractive summaries that update over time and examined new adaptive techniques to model how to select content as events evolve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Submitted Task Category</head><p>Adhoc URISK Œ± = 1 URISK Œ± = 5 NDCG@20 ERR@20 NDCG@20 ERR@20 NDCG@20 ERR@20 TREC median -A 0.1739 0. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,53.76,207.08,239.33,8.52;3,53.76,217.52,52.16,8.52;3,56.77,54.05,235.52,138.87"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of our core summarisation framework.</figDesc><graphic coords="3,56.77,54.05,235.52,138.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,123.59,55.14,432.41,664.46"><head>Table 1 :</head><label>1</label><figDesc>Results of our runs in the Contextual Suggestions track. Figures in bold represent the top performances. Note that the TBG cannot be estimated from the relevance assessments.</figDesc><table coords="2,328.80,55.14,215.20,51.50"><row><cell></cell><cell cols="2">Submitted P(5)</cell><cell>MRR</cell><cell>TBG</cell></row><row><cell>TREC Median</cell><cell>-</cell><cell cols="2">0.2368 0.3415 0.8593</cell></row><row><cell>uogTrCF</cell><cell></cell><cell cols="2">0.2170 0.4170</cell><cell>-</cell></row><row><cell>uogTrCFX</cell><cell></cell><cell cols="2">0.2332 0.4022 1.0894</cell></row><row><cell>uogTrCFP</cell><cell></cell><cell cols="2">0.2753 0.4327 1.3568</cell></row></table><note coords="2,123.59,710.94,169.32,8.66"><p>It uses a linear combination between the</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,316.80,119.84,239.10,18.96"><head>Table 2 :</head><label>2</label><figDesc>Performance of our submitted runs to the sequential update summarisation task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,59.63,129.20,501.01,152.82"><head>Table 3 :</head><label>3</label><figDesc>Document features used in the Web track, both Category A and Category B runs.</figDesc><table coords="5,59.63,150.69,501.01,131.33"><row><cell>ID</cell><cell cols="4">Submitted Category Stemming Sample</cell><cell>LTR</cell><cell>Other</cell></row><row><cell>uogTrAIwLab</cell><cell></cell><cell>A</cell><cell>Weak</cell><cell>DFIC</cell><cell>AFS</cell><cell>-</cell></row><row><cell>uogTrAIwLmb</cell><cell>Adhoc</cell><cell>A</cell><cell>Weak</cell><cell>DFIC</cell><cell>LambdaMART</cell><cell>-</cell></row><row><cell>uogTrADnLrb</cell><cell>Risk</cell><cell>A</cell><cell>None</cell><cell cols="2">DPH Risk-aware LambdaMART</cell><cell>-</cell></row><row><cell>uogTrADnLmb</cell><cell></cell><cell>A</cell><cell>None</cell><cell>DPH</cell><cell>LambdaMART</cell><cell>-</cell></row><row><cell>uogTrABwLab</cell><cell></cell><cell>A</cell><cell>Weak</cell><cell>BM25</cell><cell>AFS</cell><cell>-</cell></row><row><cell>uogTrABwLmb</cell><cell></cell><cell>A</cell><cell>Weak</cell><cell>BM25</cell><cell>LambdaMART</cell><cell>-</cell></row><row><cell>uogTrAS1Lb</cell><cell>Risk</cell><cell>A</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>Selective (uogTrABwLab/uogTrADnLrb)</cell></row><row><cell>uogTrAS2Lb</cell><cell>Adhoc</cell><cell>A</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>Selective (uogTrABwLab/uogTrADnLrb/uogTrAIwLmb)</cell></row><row><cell>uogTrBDnLaw</cell><cell></cell><cell>B</cell><cell>None</cell><cell>DPH</cell><cell>AFS</cell><cell>-</cell></row><row><cell>uogTrBDnLmw</cell><cell></cell><cell>B</cell><cell>None</cell><cell>DPH</cell><cell>LambdaMART</cell><cell>-</cell></row><row><cell>uogTrBDnLaxw</cell><cell>Risk</cell><cell>B</cell><cell>None</cell><cell>DPH</cell><cell>AFS</cell><cell>xQuAD</cell></row><row><cell>uogTrBDnLmxw</cell><cell>Adhoc</cell><cell>B</cell><cell>None</cell><cell>DPH</cell><cell>LambdaMART</cell><cell>xQuAD</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,53.76,295.16,502.17,8.52"><head>Table 4 :</head><label>4</label><figDesc>Summary of submitted and unsubmitted runs to the adhoc and risk-sensitive tasks of the Web track.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,53.76,76.62,502.20,264.50"><head>Table 5 :</head><label>5</label><figDesc>Results of our submitted and unsubmitted runs for the Web track under the normalised discounted cumulative gain at rank 20 (NDCG@20) and expected reciprocal rank at rank 20 (ERR@20) measures, as well as URISK equivalents for Œ± = 1 and Œ± = 5. * denotes corrected results.</figDesc><table coords="6,339.06,76.62,195.74,8.66"><row><cell>0980</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,321.36,711.14,112.83,8.27"><p>http://storm-project.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,58.44,711.14,159.15,8.27"><p>http://code.google.com/p/jforests/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,321.36,673.62,234.52,8.66;4,316.80,682.62,211.20,8.66"><p>We report revised scores for several runs, based on a corrected implementation of risk-aware LambdaMART.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,317.28,691.49,3.65,4.16;4,321.36,692.94,234.53,8.66;4,316.80,701.94,239.15,8.66;4,316.80,710.94,138.24,8.66"><p><ref type="bibr" coords="4,317.28,691.49,3.65,4.16" target="#b4">4</ref> We were unable to produce the risk-aware evaluation results provided by NIST, and as such, we do not report the TREC median for these measures.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,321.29,630.00,96.59,8.50" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.63,647.10,211.68,8.66;5,335.64,657.54,211.41,8.66;5,335.64,668.10,219.76,8.66;5,335.64,678.54,20.80,8.66" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,389.49,657.54,157.55,8.66;5,335.64,668.10,137.67,8.66">FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ambrosi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gaibisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gambosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,491.76,668.10,57.89,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,335.63,689.94,166.56,8.66;5,335.64,700.38,218.23,8.66;5,335.64,710.94,55.96,8.66" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,335.64,700.38,167.41,8.66">Quality-biased ranking of Web documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Diao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,522.12,700.38,31.75,8.26;5,335.64,710.94,25.76,8.26">Proc. of WSDM</title>
		<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,355.02,196.31,8.66;6,72.60,365.46,205.44,8.66;6,72.60,375.90,208.35,8.66" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,197.48,355.02,71.42,8.66;6,72.60,365.46,205.44,8.66;6,72.60,375.90,101.60,8.66">The use of MMR, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,193.44,375.90,58.85,8.26">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,387.42,208.18,8.66;6,72.60,397.86,215.68,8.66;6,72.60,408.30,87.52,8.66" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,113.99,397.86,158.88,8.66">Overview of the TREC 2010 Web track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,72.60,408.30,58.01,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,419.70,215.49,8.66;6,72.60,430.26,220.18,8.66;6,72.60,440.70,172.24,8.66;6,72.60,451.14,82.13,8.66" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,72.60,430.26,220.18,8.66;6,72.60,440.70,75.66,8.66">Efficient and effective spam filtering and re-ranking for large Web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,155.28,440.70,85.74,8.26">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,462.54,217.15,8.66;6,72.60,473.10,219.80,8.66;6,72.60,483.54,185.92,8.66" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,254.72,462.54,35.02,8.66;6,72.60,473.10,219.80,8.66;6,72.60,483.54,79.31,8.66">IRRA at TREC 2010: Index term weighting by divergence from independence model</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Din√ßer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Karaoglan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,171.00,483.54,58.01,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,494.94,206.17,8.66;6,72.60,505.38,217.55,8.66;6,72.60,515.94,169.83,8.66" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,246.31,494.94,32.45,8.66;6,72.60,505.38,217.55,8.66;6,72.60,515.94,59.52,8.66">Bagging gradient-boosted trees for high precision, low variance ranking models</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ganjisaffar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,151.08,515.94,62.81,8.26">Proc.s of SIGIR</title>
		<meeting>.s of SIGIR</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,527.34,200.75,8.66;6,72.60,537.78,183.11,8.66;6,72.60,548.22,207.82,8.66;6,72.60,558.78,215.80,8.66;6,72.60,569.22,128.79,8.66" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,72.60,548.22,207.82,8.66;6,72.60,558.78,215.80,8.66;6,72.60,569.22,22.86,8.66">University of Glasgow at TREC 2012: Experiments with Terrier in Medical Records, Microblog, and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limsopatham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,113.76,569.22,58.01,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,580.62,193.95,8.66;6,72.60,591.06,204.03,8.66;6,72.60,601.62,202.95,8.66" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,110.74,591.06,165.89,8.66;6,72.60,601.62,71.63,8.66">From Puppy to Maturity: Experiences in developing Terrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,151.20,601.62,95.69,8.26">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,613.02,206.02,8.66;6,72.60,623.46,181.46,8.66;6,72.60,633.90,161.08,8.66" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,235.04,613.02,43.58,8.66;6,72.60,623.46,177.55,8.66">The whens and hows of learning to rank for Web search</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,72.60,633.90,85.74,8.26">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,645.42,199.55,8.66;6,72.60,655.86,219.30,8.66;6,72.60,666.30,215.43,8.66;6,72.60,676.74,68.32,8.66" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,72.60,655.86,219.30,8.66;6,72.60,666.30,30.22,8.66">About learning models with multiple query-dependent features</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,109.80,666.30,173.94,8.26">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.59,688.26,212.06,8.66;6,72.60,698.70,220.06,8.66;6,72.60,709.14,194.30,8.66;6,335.64,355.02,217.50,8.66;6,335.64,365.46,63.27,8.66" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,140.26,698.70,152.41,8.66;6,72.60,709.14,194.30,8.66;6,335.64,355.02,178.35,8.66">University of Glasgow at TREC 2009: Experiments with Terrier-Blog, Entity, Million Query, Relevance Feedback, and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,532.32,355.02,20.82,8.26;6,335.64,365.46,33.77,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,376.86,206.19,8.66;6,335.64,387.42,191.03,8.66;6,335.64,397.86,177.83,8.66;6,335.64,408.30,213.39,8.66" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,373.66,387.42,153.01,8.66;6,335.64,397.86,177.83,8.66;6,335.64,408.30,107.45,8.66">University of Glasgow at TREC 2011: Experiments with Terrier in Crowdsourcing, Microblog, and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,461.52,408.30,57.89,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,419.70,219.76,8.66;6,335.64,430.26,219.90,8.66;6,335.64,440.70,62.67,8.66" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,384.34,419.70,171.05,8.66;6,335.64,430.26,180.68,8.66">Automatic feature selection in the Markov random field model for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,534.72,430.26,20.82,8.26;6,335.64,440.70,33.29,8.26">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,452.10,211.49,8.66;6,335.64,462.54,220.11,8.66" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="6,453.70,452.10,93.43,8.66;6,335.64,462.54,114.09,8.66">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,468.36,462.54,58.85,8.26">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,474.06,169.67,8.66;6,335.64,484.50,184.48,8.66;6,335.64,494.94,191.77,8.66;6,335.64,505.38,175.96,8.66" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,458.61,484.50,61.51,8.66;6,335.64,494.94,191.77,8.66;6,335.64,505.38,32.88,8.66">Terrier: A high performance and scalable Information Retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,387.24,505.38,95.81,8.26">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,516.90,203.56,8.66;6,335.64,527.34,214.48,8.66;6,335.64,537.78,146.91,8.66" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="6,373.66,527.34,176.45,8.66;6,335.64,537.78,40.20,8.66">Incorporating term dependency in the DFR framework</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,394.92,537.78,58.97,8.26">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,549.30,170.87,8.66;6,335.64,559.74,207.91,8.66;6,335.64,570.18,51.87,8.66" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="6,335.64,559.74,158.38,8.66">Effectiveness beyond the first crawl tier</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,511.92,559.74,31.63,8.26;6,335.64,570.18,22.49,8.26">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,581.58,183.11,8.66;6,335.64,592.14,217.62,8.66;6,335.64,602.58,161.91,8.66" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="6,335.64,592.14,217.62,8.66;6,335.64,602.58,54.69,8.66">Exploiting query reformulations for Web search result diversification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,408.48,602.58,57.75,8.26">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,613.98,183.11,8.66;6,335.64,624.42,211.63,8.66;6,335.64,634.98,52.48,8.66" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="6,335.64,624.42,161.73,8.66">Intent-aware search result diversification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,515.64,624.42,31.63,8.26;6,335.64,634.98,23.93,8.26">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,646.38,206.19,8.66;6,335.64,656.82,191.03,8.66;6,335.64,667.26,215.67,8.66;6,335.64,677.82,87.52,8.66" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="6,373.66,656.82,153.00,8.66;6,335.64,667.26,200.42,8.66">University of Glasgow at TREC 2010: Experiments with Terrier in Blog and Web tracks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,335.64,677.82,58.01,8.26">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,335.63,689.22,207.59,8.66;6,335.64,699.66,219.09,8.66;6,335.64,710.10,99.04,8.66" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="6,335.64,699.66,215.01,8.66">Robust ranking models via risk-sensitive optimization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,347.04,710.10,58.97,8.26">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,72.59,57.30,201.81,8.66;7,72.60,67.86,211.21,8.66;7,335.64,57.30,176.20,8.66" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="7,72.60,67.86,166.11,8.66">Ranking, boosting, and model adaptation</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno>MSR-TR-2008-109</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Microsoft</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
