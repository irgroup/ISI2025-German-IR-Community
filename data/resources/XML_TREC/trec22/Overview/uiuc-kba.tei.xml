<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,105.34,137.98,401.31,15.12;1,184.40,159.90,243.20,15.12">The University of Illinois&apos; Graduate School of Library and Information Science at TREC 2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-02-03">February 3, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,121.43,193.80,57.37,10.48"><forename type="first">Miles</forename><surname>Efron</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Library and Information Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<addrLine>Urbana-Champaign 501 E. Daniel St</addrLine>
									<postCode>61820</postCode>
									<settlement>Champaign</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.99,193.80,60.07,10.48"><forename type="first">Craig</forename><surname>Willis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Library and Information Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<addrLine>Urbana-Champaign 501 E. Daniel St</addrLine>
									<postCode>61820</postCode>
									<settlement>Champaign</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.65,193.80,89.24,10.48"><forename type="first">Peter</forename><surname>Organisciak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Library and Information Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<addrLine>Urbana-Champaign 501 E. Daniel St</addrLine>
									<postCode>61820</postCode>
									<settlement>Champaign</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.09,193.80,73.23,10.48"><forename type="first">Brian</forename><surname>Balsamo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Library and Information Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<addrLine>Urbana-Champaign 501 E. Daniel St</addrLine>
									<postCode>61820</postCode>
									<settlement>Champaign</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,438.06,193.80,52.51,10.48"><forename type="first">Ana</forename><surname>Lucic</surname></persName>
							<email>alucic2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Library and Information Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<addrLine>Urbana-Champaign 501 E. Daniel St</addrLine>
									<postCode>61820</postCode>
									<settlement>Champaign</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,105.34,137.98,401.31,15.12;1,184.40,159.90,243.20,15.12">The University of Illinois&apos; Graduate School of Library and Information Science at TREC 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-02-03">February 3, 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">0DE39127645375F0E6A0DF84B2C5FBD7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The University of Illinois' Graduate School of Library and Information Science (uiucGSLIS) participated in TREC's knowledge base acceleration (KBA) track in 2013. Specifically, we submitted runs for the cumulative citation recommendation (CCR) task. CCR is a type of document filtering. The use-case is that our user U is an editor of a node T in a knowledge base such as Wikipedia (for example, the entry for blogger Jamie Parsley (http://en.wikipedia.org/wiki/Jamie Parsley). Given an incoming stream of documents D,the system must emit a binary route/not-route decision for each document D i in real time. In this case, the binary decision signals whether we should recommend D i to U as a source of information for editing the entity T 's page. In other words, our goal is to monitor D, signaling to U when we find a document that contains "edit-worthy" information regarding the entity T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimental Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The 2013 KBA Stream Corpus</head><p>The KBA "Stream Corpus" is a collection of timestamped documents published on the web between October 2011 and January 2013<ref type="foot" coords="1,310.71,572.18,4.23,6.99" target="#foot_0">1</ref> . Our copy of the data consisted of 11,948 directories, each with one hour of published documents. The stream corpus includes additional metadata and derived data (e.g., part-of-speech tags) that were not used by our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Target Entities</head><p>The CCR task involves monitoring the stream corpus for documents that contain vital information about any of a set of 145 target entities. Each entity is associated with a URL -either a Wikipedia page or Twitter account. This year the entities had additional metadata that was not used by our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Data Reduction</head><p>We hypothesized that few vital documents would lack a match or near-match on the surface form name of a given entity. Based on this intuition, we performed a massive culling of the corpus, removing all documents that we judged to be not possibly vital with respect to any of the 145 targets. To accomplish this, we generated one or more Boolean AND statements per entity. Only documents that matched at least one of our Boolean statements were retained for further analysis.</p><p>For example, the entity designated by: http://en.wikipedia.org/wiki/Fargo Air Museum mapped to the Boolean filter fargo AND air AND museum. In creating these filters, any terms with length &lt; 2, as well as all punctuation were omitted. We also omitted Wikipedia qualifiers (i.e., terms in parenthesis) and terms in a list of Wikipedia-specific vocabulary such as disambiguation. Entities containing diacritics generated two separate statements. For example:</p><p>http://en.wikipedia.org/wiki/Gwenaëlle Aubry yielded the statements Gwenaëlle AND Aubry and Gwenaelle AND Aubry. Documents were filtered based on their "clean visible" text, which was tokenized using a Lucene 4.3 StandardAnalyzer with an EnglishPossessiveFilter. During processing, we scanned a total of 460,899,683 documents and retained 7,132,550 for indexing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training Data</head><p>Track organizers defined a training period as the time from the stream beginning until 1 March, 2013. Teams were permitted to analyze documents from within this "training window," as well as corresponding ground truth annotations about entity-document relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Annotation Data</head><p>The CCR task in 2013 recognized two levels of relevance with respect to an entity-document pair: useful and vital. A vital rating indicates a stronger usefulness of the document than a useful rating does. The official goal of the task was to maximize F1 based on vital ratings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Base System</head><p>For core indexing and retrieval we used the Indri search engine and API<ref type="foot" coords="3,445.73,120.95,4.23,6.99" target="#foot_1">2</ref> . Our retrieval models varied from task to task, as described below.</p><p>Very little pre-processing was used in our experiments. We did not stem documents. For a few tasks, stoplists were used; we describe these below. Otherwise, no stopping was performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Overall Approach</head><p>For assessing entity-document similarity, we used the negative KL-divergence between the language model θ i for document D i and the θ E for the entity E:</p><formula xml:id="formula_0" coords="3,207.21,270.25,308.34,29.73">sim(D i , E) = - f ∈E P (f |θ E ) log P (f |θ E ) P (f |θ i ) . (<label>1</label></formula><formula xml:id="formula_1" coords="3,515.55,277.63,4.65,9.57">)</formula><p>where f is a "feature" of the profile we defined to represent E. Usually, some feature f j is the simply a term that is highly associated with E. Additionally, sim(D i , E) was supplemented with an entity-independent feature that promotes documents based on their length. Our intuition was that relevant documents will tend to have lengths that are neither very short nor very long. Instead, we suspected that relevant documents would tend to be "well-behaved" with respect to length. We used the training data to find the length of all vital or useful documents. Let R T be the set of documents labeled as either vital or useful in the training data. If we let L(D i ) be the length of document D i , we hypothesized that L(D) ∈ R T would follow a log-normal distribution N L . Using R T , we estimated the mean and standard deviation of N L by maximum likelihood, such that</p><formula xml:id="formula_2" coords="3,245.58,470.78,274.62,10.69">(D i ) = N L (log n(D i ), μ, σ)<label>(2)</label></formula><p>where n(D i ) is the length of D i , and μ, σ are the estimated parameters (mean and standard deviation) of the log-normal distribution. This yields our final score for D i against E:</p><formula xml:id="formula_3" coords="3,213.50,544.51,306.70,10.63">score(D i , E) = sim(D i , E) + log (D i ).<label>(3)</label></formula><p>Conceptually, in Eq. 3, (D i ) plays the role of a prior over documents. However, use of KL divergence for measuring similarity does not lend itself to the proper introduction of a prior (unlike, say, query likelihood).</p><p>The decision to emit true for D i hinged on the magnitude of score(D i , E) with respect to a threshold τ . We emit true iff score(D i , E) ≥ τ .</p><p>Unless otherwise noted, τ was set simply by scoring all training documents according to Eq. 3 and finding the cutoff that maximized the F1 score with respect to the training annotations. When finding the optimal cutoff, some of our runs (those with the word vital in the name) calculated F1 using only vital documents as positives, while the others used both vital and useful in finding τ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Entity Representation</head><p>Our main research goal this year was to improve CCR effectiveness by building high-quality representations of each target entity. Entity representations were constructed by obtaining an initial representation and then (optionally) changing it in light of various sources of evidence.</p><p>To make this discussion clearer, we introduce some notation here. Let θ i be the representation of entity E i . In our case θ i is a language model over the vocabulary of the corpus. Also, let T i be a sample of text that we obtain automatically at the start of training. The text in T i is the data that we use to learn our initial estimate θi . We used different sources to obtain T i depending on the entity type:</p><p>• Wikipedia entities: Text was acquired by cleaning the HTML of the last version of the Wikpedia entry for E i available before the beginning of the training period.</p><p>• Twitter entities: The Twitter API was used to obtain the name, screen name and description field of the entity's Twitter profile<ref type="foot" coords="4,348.86,390.04,4.23,6.99" target="#foot_2">3</ref> .</p><p>Based on T i , we estimated our initial language model by simple maximum likelihood. Thus we have:</p><formula xml:id="formula_4" coords="4,272.64,437.24,247.56,25.50">θml i = n(f, T i ) n(T i ) (4)</formula><p>where n(f, T i ) is the number of times feature f appears in the training data and n(T i ) is the number of tokens in the training data.</p><p>When building profiles, we applied a stoplist that consisted of the standard indri stopwords plus 18 additional words that were common in Web documents (e.g. http, www, px ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Improving Models with Training Judgments</head><p>To improve our entity profiles, we created models that combined the initial profile θml i with a second model θR i which was obtained by analyzing the training documents marked as vital in the training annotations. This gives us:</p><formula xml:id="formula_5" coords="5,275.17,120.81,245.03,24.43">θR i = n(f, R) n(R)<label>(5)</label></formula><p>where n(f, R) is the frequency of feature f in the relevant documents R, and n(R) is the total number of tokens in all documents comprising R. In other words, our "feedback model" is simply the maximum likelihood estimator of the multinomial obtained by considering all relevant training documents as one long pseudo-document. Before using our estimated feedback models, we truncated them, retaining only the k = 50 most probable words in them.</p><p>In the runs that we called "feedback runs," we linearly interpolate our two models via:</p><formula xml:id="formula_6" coords="5,251.24,261.46,268.96,14.57">θiF = λ θml i + (1 -λ) θR i (6)</formula><p>where we simply set λ = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Dynamic Model Updating</head><p>One of our chief research questions was: can we improve the expressiveness of entity models after the training period? In other words, we hoped to use our experience during the testing phase to update our models. Of course this was difficult since any post-training learning is necessarily unsupervised. Our motivation for allowing models to "evolve" stemmed from two factors. First, for many entities the vital documents in the training corpus were rare or non-existent. Without adequate training data, any learned profile is likely to be over-fitted and weak. Since it is likely that we will see more relevant data during the evaluation time period, we stand to improve the initially poor models if we can marshal these data.</p><p>Our second motivation lays in the dynamic nature of the KBA task itself. Over the course of the KBA task, emerging events may cause new terms to become associated with vital information related to an entity. We reasoned that a model should be able to adapt in a way that promotes the current distribution of terms used to discuss an entity.</p><p>To support evolving models, we let the profile obtained at the end of the training period, θ i (here, θ i is shorthand; it might be θml i , θR i , etc.) induce a Dirichlet prior over terms, along with the concentration parameter µ. Then, terms found in predicted vital documents were used to update the model. Thus at time t during the evaluation period, let V t be the set of predicted vital documents we have accumulated for entity E i so far. In our dynamic runs, we then have the model:</p><formula xml:id="formula_7" coords="5,245.75,591.22,274.45,25.53">θit = n(f, V t ) + µP (f |θ i ) n(V t ) + µ (7)</formula><p>for some concentration hyperparameter µ, whose magnitude governs the extent to which we allow the model to diverge from the initial model θ i .</p><p>One additional notion that we implemented is based on the observation that the size of V i can never decrease. As it increases, the predicted vital documents will overwhelm the influence of the initial-putatively good-model. In a Bayesian sense, this is the correct behavior-as we learn more about E i , we rely more on our data and less on our prior. However, this intuition is problematic because of the unsupervised nature of our updating. Without recourse to any ground truth, it is likely that V t will contain some non-vital documents, despite our best efforts. Thus, updating is risky insofar as we are actually sampling documents from two populations-vital and everything-else-while we only wish to sample from the vital population.</p><p>To mitigate this risk, we implemented a heuristic that the updating process is limited by a constrained "memory" window. That is, we choose a number of documents w, and we limit V to contain no more than w of the most recently emitted documents. Once V contains w documents, when we emit a new document, the oldest member of V is discarded and replaced with the new document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Overview of Model Updating</head><p>Here we briefly describe how we approached CCR using dynamic models:</p><p>1. Use the training data and possibly training judgments to learn our initial model θ 0 .</p><p>2. Train our initial cutoff threshold τ 0 using θ 0 and the training data.</p><p>3. Begin iterating over test documents. 4. When, at time t, we find a document D with a score greater than τ 0 we emit D and then enter the updating procedure: (e) Return to iteration over evaluation corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submitted Runs</head><p>This year we submitted 11 runs. Results of these runs are shown in Table <ref type="table" coords="6,453.41,581.30,4.24,9.57" target="#tab_0">1</ref>. The names of the runs shown in the table are intended to be self-explanatory after introducing some basic vocabulary. First, we submitted two broad classes of runs:</p><p>• static. Runs where the entity model at the end of the training period was fixed and did not change during the evaluation period.</p><p>• dynamic. Runs where the entity model was allowed to adapt over the course of the evaluation period via the Bayesian updating method described above.</p><p>Unless otherwise specified, all runs began with a profile estimated using the relevance feedback method described above. The exception was static vital wikihtml. In this case, models were simply normalized word counts from Wikipedia (or Twitter) entries.</p><p>All runs labeled bayes * were adaptive. They varied along two dimensions: The only other run type was static fb vital smarthThresh. This was a heuristically implemented run that attempted to compensate for cases where the threshold obtained by optimizing F1 over the training data was sub-optimal. In this case, given that vital documents were found for an entity during training, the run was identical to static fb vital. But in those cases where we found no vital entities, all other runs would set τ = -∞. To improve on this, the static fb vital smarthThresh replaced all cases where τ = -∞ with the 95 th quantile of (non-vital) scores seen during the training phase.</p><formula xml:id="formula_8" coords="7,108.17,197.78,5.45,9.57">•</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis of Results</head><p>Tables <ref type="table" coords="7,126.10,437.02,5.45,9.57" target="#tab_0">1</ref> and<ref type="table" coords="7,156.41,437.02,5.45,9.57" target="#tab_1">2</ref> summarize the effectiveness of our runs.</p><p>Little in the way of systematic differences are obvious from these data. For instance, neither static nor dynamic models show an across-the-board advantage. Also, the bestperforming run for the vital only condition scored near the bottom using the vital+useful rubric.</p><p>Our chief interest is the comparison of the effectiveness of the static v. dynamic models. The various instantiations of each of these two types was less important. To help identify any intrinsic difference between static and dynamic models, Figure <ref type="figure" coords="7,420.90,531.87,5.45,9.57" target="#fig_2">1</ref> shows results from three static runs (top panels) and three dynamic runs (bottom panels). Each bar in the bar plots corresponds to one KBA entity. And the bar height is the number of vital documents enumerated in the ground truth annotations minus the number of predicted vital documents by a given run. Thus, a bar height of 0 means that the run emitted precisely the same number of vitals as there actually were. The dotted red lines in the plots are reference points of +/-100. The aim of this figure is to show any systematic tendency to over-or under-emit.  The figure shows very little difference among runs. The only clear exception is the case of the static vital wikihtml run. While all runs show one entity with an outsized false positive rate, static vital wikihtml shows two such entities.</p><p>Also, the dynamic models had fewer large false positives than the static models. For instance bayes window.20 mu.2500 only over-estimated the number of vitals by more than 100 four times, while the static approaches found far too many false vitals seven or eight times.</p><p>We were surprised to see a negligible difference between the static and dynamic modeling approaches. Figure <ref type="figure" coords="9,212.75,581.15,5.45,9.57">7</ref> suggests one mechanism that may have diluted any observable differences. The figure shows changes in two entity models-CorbinSpeedway and Jennifer Baumgardner)-over the span of the evaluation period. The figure's left panels (in black) give the KL divergence between the model at time x and θ i , the initial model estimated from the training documents. The right panels (in red) show the KL divergence between the model at time x and the background language model (of the training corpus).</p><p>Increases in the black graphs indicate that the model is moving "away" from the initial model. However, they say nothing about whether this motion is for the good or the bad. In red, decreases indicate that the model is becoming more similar to the background language model. In more familiar terms, as the red graphs decrease, we are losing "query clarity." Thus, increased divergence from θ i (black graphs) is possibly helpful or hurtful, decreased divergence from the background model is probably harmful, indicating drift or "dilution" of the model.</p><p>Though the dynamics vary between the two entities, in both cases, the end result is the same: the model moves away from the initial profile, winding up much closer to the background model than it started. This suggests that over time, the models are drifting off course.</p><p>However, the plots referring to the Jennifer Baumgardner models are interesting. They suggest that the updating process is doing more than (or at least something besides) simply drifting towards the background model. Instead, we see a strong spike in divergence from both the initial model and the background model early on. This is followed by a rapid return to starting-model similarity and a much slower return to drifting toward the background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Directions</head><p>Our next efforts will include two main tasks. First, we will undertake more intensive data analysis. We have only presented a cursory overview in this notebook paper. Understanding what's happening in Figure <ref type="figure" coords="10,226.59,401.16,5.45,9.57" target="#fig_2">1</ref> will require more analysis.</p><p>Additionally, we plan to make improvements in the model updating procedure described here. While probabilistically simple, the learning method that we used was clearly not optimal. As we might expect, adding pseudo-relevant documents on a wholesale basis into our model seems to have introduced more noise that we can tolerate. In future work we plan to further constrain the updating process. q q q q q q qq q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 1.335e+09 1.340e+09 1.345e+09 1.350e+09 0.9 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CorbinSpeedway</head><p>Epoch D(Qt || BG) q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q qq 1.330e+09  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,123.68,443.29,82.33,9.60;6,123.07,456.98,80.86,12.45;6,124.29,473.53,395.91,13.51;6,143.07,489.96,54.00,9.57;6,123.07,506.47,239.29,9.60"><head></head><label></label><figDesc>Using the newly estimated θit , generate a new threshold τ t over the training documents. (d) Remove any old documents from V if needed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,119.07,197.78,401.13,9.57;7,119.07,211.33,401.12,9.57;7,119.07,224.88,51.55,9.57;7,108.17,247.39,412.04,9.57;7,119.07,260.94,401.12,9.57;7,119.07,274.49,274.45,9.57"><head></head><label></label><figDesc>Window size. During updating, only most recent k emitted documents were stored for training the models. Window size refers to k. Larger values of k indicate a longer "memory." • Prior Strength. The Dirichlet concentration parameter µ governed the extent to which new information changed our models. Larger µ values gave more weight to the prior (the original model), constraining change over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,91.80,399.10,428.40,9.57;9,91.80,412.65,428.40,9.57;9,91.80,426.20,428.40,9.57;9,91.80,439.75,63.69,9.57"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Number of Vital Documents per Entity (Existent and Emitted). Each panel corresponds to one uiucGSLIS CCR run. Within panels, each bar is one KBA entity. Bar height is the true number of vital documents per entity minus the number of predicted vital per run.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,91.80,542.78,428.40,9.57;11,91.80,556.33,428.40,9.57;11,91.80,569.88,428.40,9.57;11,91.80,583.43,428.40,9.57;11,91.80,596.98,249.49,9.57"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Entity Model Clarity and Resilience. The top row shows results for the Corbin-Speedway entity, with Jennifer Baumardner in the bottom row. Left-hand columns give the KL divergence between the entity profile at time t (the x-axis) and the profile from the start of the ETR. Right panels given the KL divergence between the entity profile and the language model of the training data's full collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,91.80,124.01,428.39,211.37"><head>Table 1 :</head><label>1</label><figDesc>Results of Official GSLIS KBA CCR Runs. Vital Only. Runs are shown in decreasing order of F1.</figDesc><table coords="8,137.22,162.52,337.55,172.86"><row><cell>Run Name</cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell>SU</cell></row><row><cell>static fb vital tfidf</cell><cell>0.2370</cell><cell cols="3">0.2999 0.2648 0.2630</cell></row><row><cell>static fb vital smarthThresh</cell><cell>0.2370</cell><cell cols="3">0.2999 0.2648 0.2630</cell></row><row><cell>bayes window.20 mu.10000</cell><cell>0.2382</cell><cell cols="3">0.2758 0.2556 0.2774</cell></row><row><cell>static vital wikihtml</cell><cell>0.1855</cell><cell cols="3">0.3953 0.2525 0.2577</cell></row><row><cell>bayes window.200 mu.2500</cell><cell>0.2291</cell><cell cols="3">0.2780 0.2512 0.2701</cell></row><row><cell>bayes window.20 mu.2500</cell><cell>0.2269</cell><cell cols="3">0.2804 0.2508 0.2678</cell></row><row><cell>static fb vital</cell><cell>0.2083</cell><cell cols="3">0.3140 0.2504 0.2752</cell></row><row><cell>bayes window.50 mu.1500</cell><cell>0.2083</cell><cell cols="3">0.3140 0.2504 0.2752</cell></row><row><cell>bayes window.20 mu.5000</cell><cell>0.2083</cell><cell cols="3">0.3140 0.2504 0.2752</cell></row><row><cell>bayes window.20 mu.1500</cell><cell>0.2322</cell><cell cols="3">0.2694 0.2494 0.2738</cell></row><row><cell>bayes window.20 mu.150</cell><cell>0.2432</cell><cell cols="3">0.2546 0.2488 0.2729</cell></row><row><cell>bayes window.50 mu.2500</cell><cell>0.2243</cell><cell cols="3">0.2783 0.2484 0.2658</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,91.80,405.19,428.40,211.37"><head>Table 2 :</head><label>2</label><figDesc>Results of Official GSLIS KBA CCR Runs. Vital+Useful. Runs are shown in decreasing order of F1.</figDesc><table coords="8,137.22,443.70,337.55,172.86"><row><cell>Run Name</cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell>SU</cell></row><row><cell>static vital wikihtml</cell><cell>0.5319</cell><cell cols="3">0.4187 0.4686 0.4882</cell></row><row><cell>static fb vital</cell><cell>0.5540</cell><cell cols="3">0.3208 0.4063 0.4610</cell></row><row><cell>bayes window.50 mu.1500</cell><cell>0.5540</cell><cell cols="3">0.3208 0.4063 0.4610</cell></row><row><cell>bayes window.20 mu.5000</cell><cell>0.5540</cell><cell cols="3">0.3208 0.4063 0.4610</cell></row><row><cell>bayes window.200 mu.2500</cell><cell>0.5763</cell><cell cols="3">0.2878 0.3838 0.4434</cell></row><row><cell>bayes window.50 mu.2500</cell><cell>0.5724</cell><cell cols="3">0.2885 0.3836 0.4414</cell></row><row><cell>bayes window.20 mu.2500</cell><cell>0.5735</cell><cell cols="3">0.2869 0.3824 0.4443</cell></row><row><cell>static fb vital tfidf</cell><cell>0.5329</cell><cell cols="3">0.2902 0.3758 0.4444</cell></row><row><cell>static fb vital smarthThresh</cell><cell>0.5329</cell><cell cols="3">0.2902 0.3758 0.4444</cell></row><row><cell>bayes window.20 mu.10000</cell><cell>0.5836</cell><cell cols="3">0.2752 0.3740 0.4414</cell></row><row><cell>bayes window.20 mu.1500</cell><cell>0.5726</cell><cell cols="3">0.2765 0.3729 0.4424</cell></row><row><cell>bayes window.20 mu.150</cell><cell>0.5843</cell><cell cols="3">0.2252 0.3251 0.4230</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,108.39,636.51,225.95,7.47"><p>http://trec-kba.org/kba-stream-corpus-2013.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,108.39,643.96,108.27,7.47"><p>http://lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,108.39,610.05,411.81,7.86;4,91.80,621.01,428.40,7.86;4,91.80,631.97,330.23,7.86"><p>Admittedly, these data constitute "future" evidence in the sense that we harvested them after the timespan of the corpus. However, the Twitter profiles that we harvested were extremely terse, and we believe that their inclusion did not give any future-specific advantage to our runs.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
