<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,110.59,125.04,374.10,15.15">ICTNET at Microblog Track in TREC 2013</title>
				<funder ref="#_tbXgaCJ">
					<orgName type="full">National Key Technology R&amp;D Program</orgName>
				</funder>
				<funder ref="#_pfByW3k">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
				<funder ref="#_uFzn4S9">
					<orgName type="full">NSF of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,105.92,157.57,59.10,10.48"><forename type="first">Jinhua</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Web Data Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.48,157.57,59.26,10.48"><forename type="first">Guoxin</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Web Data Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,261.21,157.57,70.07,10.48"><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Web Data Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,343.17,157.57,40.48,10.48"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Web Data Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,418.30,157.57,66.33,10.48"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Web Data Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,110.59,125.04,374.10,15.15">ICTNET at Microblog Track in TREC 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0849D684D2809387E0CAA2AD6F322B28</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Microblogging services, in which users can publish and share personal status, are now very popular, and attracting more and more industrial and scientific interests. Twitter is one of the most famous microblogging services. On twitter, Users can post personal updates, which are called tweets and limited to 140 characters long. In tweets, users can share interesting messages to their friends by retweeting(RT), push some tweets to specific users using @ mention, and indicate the topics of their tweets using # hashtags. The short-text characteristic and social attributes such as RT, @ mention and # hashtags, make traditional problems, like search, rank, and recommendation etc, quite different in microblogging settings.</p><p>Microblog track was first introduced in 2011, and ICTNET group have participated in this track three times <ref type="bibr" coords="1,77.83,437.86,12.68,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,94.60,437.86,7.01,8.74" target="#b6">7]</ref>. In this year's track, only the realtime ad-hoc search task, which was also proposed in 2011 and 2012, was open for submission. This task requires to retrieve all the tweets that are relevant to query Q and before time T. Unlike the past two years, in which participants had to collect the corpus themselves, microblog track was first provided as a service this year, and participants could access the corpus through official APIs, which made it possible for the organizers to increase the size of corpus from 16M tweets to 260M tweets, which were collected via the Twitter streaming API over a two-month period. This report is organized as follows. Section 2 mainly focuses on the data preparation step, which contains the data collecting step and preprocessing step. The methodology and framework are illustrated in section 3, and some experiments and results are presented in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Preparation</head><p>We downloaded the twitter-tools <ref type="bibr" coords="1,218.23,603.21,12.05,8.74" target="#b4">[5]</ref> from github to interact with the service API. The service API simply returned relevant tweets' information, which included tweets text and some of their social attributes such as followers count, whether or not being a reply, and retweeted count, for submitted queries. As the number of submitted tweets for each query was limited to 1000, we retrieved 10,000 tweets for each query, and stored their details in files for later analysis. We also stored tweets for topics of 2011 and 2012 microblog tracks, since they were used as training data for our supervised framework.</p><p>Word stemming was processed using the TweetAnalyzer class extracted from the twitter-tools. Each tweet was split into terms, and terms whose length were less than 3 were dropped. Non-English tweets were also filtered. Stop words removal was not processed, as it has been shown that stop words removal might have a negative impact on the ranking results in short-text settings.</p><p>We defined this task to be a re-rank problem. We could obtain the initial ranking list through the service API, and re-rank the list to achieve our final ranking. However, the short-text characteristic and social attributes of tweets made traditional ranking method not work well. Firstly, the tweets and queries were both so short that traditional ranking model could not distinguish relevant tweets from non-relevant tweets well, which could resulted in a poor initial list, and thus influence the final ranking. Secondly, it worth studying how to incorporate the social attributes into ranking.</p><p>In order to obtain a better initial list, we expanded the query using pseudo relevance feedback, and submitted expanded query to the service API. The returned list were applied to re-ranking. To address the second problem, SVM Rank model <ref type="bibr" coords="2,177.29,215.62,13.80,8.74" target="#b3">[4]</ref> was applied, in which those social attributes were transformed into training features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Expansion</head><p>Pseudo relevance feedback is a traditional method to expand the queries. It assumes the top k documents in the returned list to be relevant, and extracts the terms that have higher weight under some weight function settings to be the expanded terms. In our method, we took top 30 tweets for expansion, and 5 terms were expanded for each query. We first checked some traditional weight functions, including tf, idf, and tf * idf. We manually checked the expanded terms, and those results turned out to be rather poor.</p><p>We further investigated the Divergence From Randomness(DFR) term weighting model <ref type="bibr" coords="2,447.70,348.58,13.19,8.74" target="#b2">[3]</ref>, whose main idea is to weight the informativeness of a term by the divergence of its distribution in the top-ranked documents from a random distribution. We chose the Bo1 model <ref type="bibr" coords="2,293.32,372.49,13.19,8.74" target="#b0">[1]</ref>, which utilized the Bose-Einstein statistics. In this model, the weight w of a term t is given by:</p><formula xml:id="formula_0" coords="2,215.90,409.18,318.44,23.23">w(t) = tf â€¢ log 2 1 + P n P n + log 2 (1 + P n ) (<label>1</label></formula><formula xml:id="formula_1" coords="2,534.33,415.92,4.24,8.74">)</formula><p>where tf is the term frequency in top-ranked documents, and P n is given by F N with F representing the term frequency in the whole collection and N indicating the number of documents in the collection.</p><p>Besides, we tried another term weighting model which took word co-occurrence into account. The relevance score of a term in a tweet was inferred by a function of the number of query term hits in that tweet, and the weight of a term was gained by summing its scores over all the top-ranked tweets. To choose the score function, we heuristically tried the linear function, in which the score was exactly the number of query term hits, and the exponential function, where the score was equal to exponential result of the number of query term hits, since we thought the more query terms it co-occurred with in a tweet, the more relevant it would be. The latter one gave better results, and was adopted in our experiment. This model was referred as the co-occurrence model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Extraction</head><p>To train the SVM Rank model, a set of features was extracted for each tweet, which could be split into two views: relevance view and intrinsic view. Features of relevance view were exactly the same as those in traditional documents ranking, as were reported in LETOR <ref type="bibr" coords="2,316.13,625.67,16.19,8.74" target="#b5">[6]</ref>, which was a benchmark dataset released by Microsoft Research Asia for learning to rank research. Those features were query-dependent, including term frequency(tf ), inverse document frequency(idf ), BM25 score, and language model score etc.</p><p>The features of intrinsic view were query-independent, and those social attributes of tweets such as @ mentions, # hashtags, and retweeted count were incorporated. The whole features extracted were listed in table 1. They were quite self-explained by their names, in which names ending with " exd" meant features calculated using expanded terms only.</p><p>There were totally 44 features to be extracted for each tweet, and those features were all query-based normalized for SVM rank. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Applying SVM Rank</head><p>SVM Rank model was adopted to obtain the final ranking. Official released relevance judgements for microblog track 2011 and 2012 were utilized as labelled training data, which consisted of 108 queries with tweets labelled using 0, 1, 2, meaning non-relevant, relevant and highly-relevant respectively. During model training process, linear kernel was adopted, and 5-fold cross validation was applied to tune the parameter C, which controlled the balance between training error and margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>We tried out two query expansion methods, and the results were shown in table 2.</p><p>It's easily seen that terms expanded using those two models shared some similarities, but the performance varied among different queries. The query "2022 fifa soccer" mainly talked about Qatar winning the bid to host 2022 world cup. Bo1 model worked fine, but co-occurrence model transferred to "fifa soccer game" topic. And the result was totally opposite on the case "bedbug epidem", which was about epidemic caused by some bedbugs. ICTNETRUN2 was based on co-occurrence model, while ICTNETRUN3 was obtained using bo1 model.</p><p>To tune the parameters C of SVM Rank model, we conducted 5-fold cross validation on 2011 and 2012's queries respectively. The result was shown in figure <ref type="figure" coords="3,280.26,632.76,3.87,8.74" target="#fig_0">1</ref>. We finally set C to be 0.30. Official relevance judgements of microblog track 2011 and 2012 were combined to serve as labelled data, and SVM Rank model was trained and applied to this year's queries to obtain our submitted runs.  The relevance judgement for microblog track 2013 has been released when this report was written, and the results of our runs were demonstrated in table <ref type="table" coords="4,261.84,397.70,3.87,8.74" target="#tab_2">3</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,201.10,355.27,193.08,8.74;4,127.56,85.04,340.16,255.12"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Parameter selection for SVM rank</figDesc><graphic coords="4,127.56,85.04,340.16,255.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,110.27,95.12,374.73,140.39"><head>Table 1 :</head><label>1</label><figDesc>Features extracted for ranking</figDesc><table coords="3,110.27,106.82,374.73,128.69"><row><cell>Intrinsic View</cell><cell>Relevance View</cell></row><row><cell>tweet length</cell><cell>tf sum, tf min, tf max, tf avg</cell></row><row><cell>hasRT</cell><cell>tf sum exd, tf min exd, tf max exd, tf avg exd</cell></row><row><cell>number of hashtags</cell><cell>idf sum, idf min, idf max, idf avg</cell></row><row><cell cols="2">number of at mentions idf sum exd, idf min exd, idf max exd, idf avg exd</cell></row><row><cell>number of urls</cell><cell>normalized tf sum</cell></row><row><cell>retweeted count</cell><cell>tf idf sum, tf idf min, tf idf max, tf idf avg</cell></row><row><cell>follower count</cell><cell>tf idf sum exd, tf idf min exd, tf idf max exd, tf idf avg exd</cell></row><row><cell>number of status</cell><cell>bm25 score, VSM score, covered term ratio</cell></row><row><cell>unique term ratio</cell><cell>bm25 score exd, VSM score exd, covered term ratio exd</cell></row><row><cell></cell><cell>retrieval score</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,79.11,259.59,437.05,106.52"><head>Table 2 :</head><label>2</label><figDesc>Query expansion results</figDesc><table coords="3,79.11,271.29,437.05,94.82"><row><cell>Queries</cell><cell>Bo1 Model</cell><cell cols="2">Expansion Method Co-occurrence Model</cell></row><row><cell>2022 fifa soccer</cell><cell cols="2">cup blatter qatar winter presid</cell><cell>plai cup 360 game hour</cell></row><row><cell>oprah winfrei half sister</cell><cell cols="2">secret famili reveal exist promi</cell><cell>secret famili love watch time</cell></row><row><cell>carbon monoxid law</cell><cell cols="2">poison detector famili car warn</cell><cell>health watch firm school judge</cell></row><row><cell>bedbug epidem</cell><cell cols="2">warn femal ruin specialist war</cell><cell>obes bite warn kid spread</cell></row><row><cell cols="4">michel obama obes campaign ladi move atlanta childhood press bachman ladi love design union</cell></row><row><cell>iran nuclear program</cell><cell cols="2">talk afp close 2012 power</cell><cell>egypt talk power obama iranian</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,174.89,687.45,245.49,67.52"><head>Table 3 :</head><label>3</label><figDesc>Evaluation results for ICTNET submitted runs</figDesc><table coords="3,203.05,697.21,189.18,57.75"><row><cell>Runtag</cell><cell cols="2">Precision @ 30 relevant highly relevant</cell></row><row><cell>ICTNETRUN1</cell><cell>0.3378</cell><cell>0.1683</cell></row><row><cell>ICTNETRUN2</cell><cell>0.4594</cell><cell>0.2289</cell></row><row><cell>ICTNETRUN3</cell><cell>0.4644</cell><cell>0.2367</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank all the organizers and assessors of <rs type="institution">TREC</rs> and <rs type="funder">NIST</rs>. This work is sponsored by <rs type="funder">NSF of China</rs> Grants No.<rs type="grantNumber">61100083</rs>, <rs type="programName">242 Program</rs> of China Grants No.<rs type="grantNumber">2013F97</rs>, and the <rs type="funder">National Key Technology R&amp;D Program</rs>(<rs type="grantNumber">2012BAH39B04</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uFzn4S9">
					<idno type="grant-number">61100083</idno>
					<orgName type="program" subtype="full">242 Program</orgName>
				</org>
				<org type="funding" xml:id="_tbXgaCJ">
					<idno type="grant-number">2013F97</idno>
				</org>
				<org type="funding" xml:id="_pfByW3k">
					<idno type="grant-number">2012BAH39B04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,72.19,549.16,466.39,8.74;4,72.19,561.11,334.79,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,165.89,549.16,367.52,8.74">Probabilistic Models for Information Retrieval Based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">Giambattista</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="4,72.19,580.36,466.40,8.74;4,72.19,592.32,128.45,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,412.76,580.36,125.83,8.74;4,72.19,592.32,49.98,8.74">ICTNET at Microblog Track TREC 2011</title>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinhua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yubao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,143.58,592.32,24.84,8.74">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.19,611.57,466.39,8.74;4,72.19,623.52,215.95,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,177.19,611.57,301.71,8.74">Combining Fields for Query Expansion and Adaptive Query Expansion</title>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,486.50,611.57,52.09,8.74;4,72.19,623.52,120.98,8.74">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1294" to="1307" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.19,642.77,466.39,8.74;4,72.19,654.73,325.35,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,166.53,642.77,169.73,8.74">Training Linear SVMs in Linear Time</title>
		<author>
			<persName coords=""><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,362.91,642.77,175.68,8.74;4,72.19,654.73,294.54,8.74">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.19,673.97,360.04,9.02" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><forename type="middle">Twitter</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tools</surname></persName>
		</author>
		<ptr target="https://github.com/lintool/twitter-tools" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.19,693.22,466.39,8.74;4,72.19,705.18,466.39,8.74;4,72.19,717.13,139.05,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,340.31,693.22,198.28,8.74;4,72.19,705.18,188.11,8.74">LETOR: Benchmark Dataset for Research on Learning to Rank for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Tieyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenying</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,281.38,705.18,257.20,8.74;4,72.19,717.13,108.89,8.74">Proceedings of SIGIR 2007 Workshop on Learning to Rank for Information Retrieval</title>
		<meeting>SIGIR 2007 Workshop on Learning to Rank for Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.19,736.38,466.40,8.74;4,72.19,748.34,203.22,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,486.47,736.38,52.12,8.74;4,72.19,748.34,124.76,8.74">ICTNET at Microblog Track TREC 2012</title>
		<author>
			<persName coords=""><forename type="first">Bolong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinhua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cunhui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,218.35,748.34,24.84,8.74">TREC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
