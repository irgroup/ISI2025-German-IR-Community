<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.46,74.67,344.11,12.22;1,127.59,89.79,339.84,12.22">Boosting Venue Page Rankings for Contextual Retrieval -Georgetown at TREC 2013 Contextual Suggestion Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,238.20,105.94,48.33,10.54"><forename type="first">Jiyun</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
								<address>
									<addrLine>37 th and O Street</addrLine>
									<postCode>20057</postCode>
									<region>NW, Washington DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,309.86,105.94,46.99,10.54"><forename type="first">Hui</forename><surname>Yang</surname></persName>
							<email>huiyang@cs.georgetown.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
								<address>
									<addrLine>37 th and O Street</addrLine>
									<postCode>20057</postCode>
									<region>NW, Washington DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.46,74.67,344.11,12.22;1,127.59,89.79,339.84,12.22">Boosting Venue Page Rankings for Contextual Retrieval -Georgetown at TREC 2013 Contextual Suggestion Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D3A4E12BCEC696449E6253D7B6C3A5E7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participate in the closed collection sub-track of the TREC 2013 Contextual Suggestion. The dataset that we use is an integrated collection of ClueWeb12 Category B, Wikitravel, and the city-specific sub-collection; all are from ClueWeb12. Since the Open Web is not used in our submissions, the task is essentially a retrieval task instead of a result merging task. Our system takes users' ratings of venues in a training city as inputs, and generates titles, document identification numbers, and descriptions for venues that fit users' interests in a new city. Ideal relevant documents for this task should be a list of Web pages each of which is a venue's homepage, which we call a "venue page". However, off-the-shelf search tools, such as Lemur, fail to retrieve such venue homepages from the collection. They either retrieve non-relevant documents or "yellow-page"-like pages that link to a long list of venue pages where the links are often broken and the destination pages are out of the collection. Therefore, large portions of the retrieved documents are not suitable as answers for contextual suggestion. To address this challenge, we experiment two different approaches, a precision-oriented approach and a recall-oriented approach, to boost the relevant venue pages' ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>TREC 2013 Contextual Suggestion Track aims to provide travel suggestions in new cities for visitors based on their personal interests and ratings for venues in a city they have been to. The personal interests are provided by a survey of about 500 users' personal judgments towards fifty tourism suggestions in Philadelphia, PA. Users' judgments are scaled from 0 to 4, corresponding to "Strongly disinterested", "Disinterested", "Neutral", "Interested" and "Strongly interested".</p><p>Last year our submissions used the Open Web to find out the venues in the new cities. It was essentially a result merging task that utilizes a personalized learning to rank framework to merge top returned results from existing commercial search engines such as Google Place and Yelp. This year, we decide not to use the Open Web; instead, we concentrate on the core retrieval challenge posed in finding good documents in a closed collection, in this case, the ClueWeb12 collection.</p><p>The ideal relevant documents for this task should be a list of Web pages each of which is a venue's homepage. However, off-the-shelf search tools, such as Lemur, fail to retrieve such venue homepages from the collection. The following problems frequently occur: too many non-relevant documents, too many "yellow-page"-like pages that link to a long list of venue pages, the links are often broken, and the destination pages are out of the collection. These various forms of non-relevant documents and list pages are overwhelming. As a result, large portions of documents retrieved by off-the-shelf search tools are not suitable to be returned as answers for contextual suggestion. To address the above challenge, we experiment two different approaches, a precision-oriented approach and a recall-oriented approach, to boost the relevant venue pages' ranking.</p><p>The precision-oriented approach employs information extraction techniques to acquire venue names from Wikitravel then formulates structured queries to perform retrieval in the collection. We extract the names of venues, such as famous restaurants and shopping centers, from a given city's Wikitravel page. The venues are automatically extracted in sections named "See", "Do", "Eat", "Drink", and "Buy". After retrieval, we calculate the similarity between venue name and anchor texts in both incoming and current pages to locate the most relevant document within the closed collection for the venue. The description of a page is automatically extracted by a linguistic-based method. The recall-oriented approach divides all training venues into a two-level venue classification system, including landmark, amusement park, and Italian restaurant, then creates a representative language model for each category. The category-specific language models are used to perform retrieval for each individual category mentioned in a user's profile. Both approaches alleviate the problem of overwhelming non-relevant documents and list pages.</p><p>The remainder of this paper is organized as follows. Section 2 describes the dataset, data preparation and indexing. Section 3 presents the precision-oriented approach and Section 4 presents the recall-oriented approach. Section 5 shows how we reorganize the retrieval results based on user interests. Section 6 briefs description generation. Section 7 describes our submitted runs and result analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data Preparation and Indexing</head><p>The dataset that we use is an integrated collection of ClueWeb12 CatB, Wikitravel, and the city-specific sub-collection; all are from ClueWeb12. The integrated dataset is from following sources:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>‚Ä¢ ClueWeb12 CatB</head><p>The full ClueWeb12 dataset contains about eight hundred million Web pages. Pages are crawling from English-speaking countries' websites, twitter 1 and Wikitravel<ref type="foot" coords="2,342.84,138.63,3.24,5.69" target="#foot_0">2</ref> . The ClueWeb12 CatB is used in our submission.</p><p>‚Ä¢ City-Annotated Sub-Collection This collection contains about thirty thousand documents. It is a sub-collection of ClueWeb12 which is distributed by the TREC organizers. Every document in this corpus has been marked with which city this website is about. All documents in this collection are tourism-related Web pages. We consider them as high-quality data. The weakness about this sub-collection is that it doesn't contain enough venues for each category, such as bar, restaurant or sightseeing.</p><p>‚Ä¢ Wikitravel Wikitravel is included in the ClueWeb12 collection. It is crawled from the English part of Wikitravel. A city's Wikitravel homepage is usually about that city's history, demographics, and what to do, to eat, to see, to drink in the city.</p><p>The dataset integration and data preparation is done in two steps. First, we merge the city-annotated sub-collection into ClueWeb12 CatB. We iterate each document in ClueWeb12 CatB. If a document's location information is provided in the city-annotated sub-collection, we add a "treccity" tag in that document and record which cities this document is about. For instance, document "clueweb12-1908wb-68-23037" is about Albany NY and Washington DC, we add the tag "&lt;treccity&gt;albany ny,washingtondc dc&lt;/treccity&gt;" for it. Later on, during the retrieval phase, we conduct structured retrieval by utilizing this &lt;treccity&gt; field. The location information helps us to retrieve webpages in the city-annotated sub-collection in a higher priority than other ClueWeb12 documents. Second, we extract Wikitravel dataset out of ClueWeb12 and form a separate corpus. We extract famous entities of each city upon the Wikitravel dataset. By splitting Wikitravel to a separate corpus, we reduce the difficulty of retrieving famous venues from this corpus.</p><p>We adopt the Lemur Search Engine<ref type="foot" coords="2,247.32,416.20,3.53,6.27" target="#foot_1">3</ref> to build index for the integrated ClueWeb12 CatB collection with stopword removal and Krovetz stemming <ref type="bibr" coords="2,297.00,431.13,10.59,8.64" target="#b1">[1]</ref>. To allow structured retrieval, we index the following fields: document number (docno), title, treccity and url. We use similar configuration to index the Wikitravel dataset.</p><p>3 Precision-Oriented Approach</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Locating Wikitravel homepage for each city</head><p>For each city, we try to locate its Wikitravel page and extract venue names from this page. To do that, we issue a Boolean Lemur query formed by the city name and the full name of its state and perform retrieval against the Wikitravel index. This gives us a ranked list of Wikitravel pages for each city. For instance, for the city of Youngstown, OH, we issue a Boolean query "#band(Youngstown Ohio)". City Youngstown, OH's retrieval list is presented in Table <ref type="table" coords="2,326.05,548.97,3.73,8.64">1</ref>.</p><p>Table <ref type="table" coords="2,234.52,562.84,7.70,8.75">1</ref> Retrieval List for Youngstown, OH 1. Northeast Ohio travel guide -Wikitravel 2. Youngstown travel guide -Wikitravel 3. Pages that link to Youngstown -Wikitravel 4. User:Cjensen/project/hotelmaker/Ohio -Wikitravel 5. Youngstown -Wikitravel 6. Talk:Northeast Ohio -Wikitravel ‚Ä¶ Note that not all the top returned documents are relevant documents for our query. Moreover, we cannot rely on the first returned result to be relevant. Therefore, in order to locate one city's Wikitravel page, first we filter out Wiki User pages 4 , Wiki Talk pages 5 , Wiki Link pages 6 and Wiki 1 https://twitter.com/ Disambiguation pages<ref type="foot" coords="3,180.12,72.28,3.53,6.27" target="#foot_5">7</ref> by filtering any page whose title are started with "user", "talk" or "page" or whose title contains word "disambiguation". Taking Table <ref type="table" coords="3,330.06,87.21,4.92,8.64">1</ref> as an example, the third, fourth and sixth retrieval results are filtered out first. Next, we extract the city name and the state full name which are used in the Boolean query, and append a suffix "travel guide" to form a pattern p. E.g. for City Youngstown, OH, we get phrase "Youngstown Ohio travel guide". Finally we calculate the cosine similarity score <ref type="bibr" coords="3,439.05,406.41,11.60,8.64" target="#b2">[2]</ref> between the extracted phrase (p) and each retrieval document's title (t j ), and keep the document with the highest score as the Wikitravel page for that city. For City Youngstown, OH, its Wikitravel page is "2. Youngstown travel guide -Wikitravel".</p><p>Wikitravel Page = the i th document, where ( ) cos , max(cos( , )) i j j p t p t =</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Exacting venue names from Wikitravel</head><p>Table <ref type="table" coords="3,174.95,499.05,4.92,8.64">2</ref> The "See" section of document "Houma travel guide -Wikitravel"</p><p>&lt;li&gt; Bayou Terrebonne Waterlife Museum <ref type="bibr" coords="3,261.33,513.63,12.09,8.00" target="#b1">[1]</ref>  After retrieving one city's Wikitravel homepage, we examine the "See", "Do", "Eat", "Drink" and "Buy" sections in that page, and extract famous venues from these sections. For each section, first we extract all bold phrases. Usually these bold phrases are venue names. Second, we extract content within HTML lists, i.e., contents are tagged with &lt;li&gt; labels. If the content contains bold phrases, it means we already dealt this information once; hence we skip this content. Otherwise we split the content with comma, and keep the first part as a new venue. Finally we filter out venue names that contain only one term or more than 10 terms since they are more likely to be noise.</p><p>Table <ref type="table" coords="3,127.76,716.97,4.92,8.64">2</ref> shows that "Bayou Terrebonne Waterlife Museum", "Chauvin Sculpture Garden" and "Southdown Plantation House" are extracted as venue names, whereas "Location" is ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Retrieving ClueWeb12 documents for Wikitravel venues</head><p>After finding famous tour spots' names, we still need to find their most relevant document in ClueWeb12. The document must be within this closed collection. We generate a structured query in the following pattern and use it to search upon ClueWeb12 CatB: ÔÇ≤ #weight(w1 #combine[title](venue name) w2 #combine(venue name) w3 #band(abbreviated location) w3 #band(full location)) where 'abbreviated location' uses the state abbreviation name, 'full location' uses the state full name. This is a weighted structured query. Keywords that occur in the title get w1 weights, and keywords that occur in the document get w2 weight. A document containing the correct location keywords, either in the abbreviation form or the full spelling, get w3 weight. We conduct several experiments to tune the weights, and empirically we set {w1,w2,w3 } as {0.5, 1.0, 0.2 }. Taking "Southdown Plantation House" as an example, the formulated query is: ÔÇ≤ #weight(0.5 #combine[title]( Southdown Plantation House) 1.0 #combine(Southdown Plantation House) 0.2 #band(houma la) 0.2 #band(houma louisiana)) This query expects that documents with "Southdown Plantation House" in the title and the body text and with "houma la" or "houma louisiana" in the content get the highest score.</p><p>After retrieval, we need to select one document that is most relevant to return as the answer for contextual suggestion. One approach is treating the document with the highest score as the Web page that best represents the query venue spot. Another more accurate approach makes use of anchor text. First, we issue the same query that we show in Section 3.3. Then, we extract all anchor texts and their outgoing urls for those anchor texts from the top five returned documents. Next, we compare the cosine similarity between the anchor text and the venue's name. Finally, we use the outgoing url of the anchor text which has the highest cosine similarity score to represent that venue. For instance, for "Southdown Plantation House", its highest scored anchor text and url pair is "southdown plantation house" and http://www.southdownmuseum.org/. We then need to map this url back to the ClueWeb12 collection to return the document id as the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall-Oriented Approach</head><p>In this approach, we perform contextual retrieval for a wide range of venues based on user interests and the city. We assume that users' information needs for traveling suggestions can be classified into 23 categories 8 . We search the fifty example suggestions in Yelp and use Yelp's category labels to determine the example suggestions' categories.</p><p>We adopt a two-level classification system to assign category labels to example suggestions. We use "top-level" to restaurants, whereas we assign more specific categories to example suggestions than "second-level" such as "Italian Restaurant" and "Turkish Restaurant" instead of labeling them all as "Restaurant". For other type of venues, we adopt "second-level" strategy to them, where category labels are more general.</p><p>We automatically generate a unigram language model for each category. We first generate some representative documents by querying the index using the category name, and then we take the words from the snippets in the retuned results, and retrieve any Wikipedia articles within them. From the snippets and Wikipedia articles we obtain top one hundred most frequent words, weighted by their counts. Table 3 lists a few example categories and their corresponding representative language model. We construct a Lemur structured query in the following format: ÔÇ≤ #weight(w1 #combine( bag of words for one category) w2 #band(abbreviated location) w2</p><p>#band(full location))</p><p>8</p><p>Italian restaurant, Turkish restaurant, Burmese restaurant, Greek Mediterranean restaurant, sandwiches restaurant, tour restaurant, restaurant, cafe, shopping, park, bar, brewery, landmark, amusement park, culture tour, zoo, performing art, spa, party event planning, game, tour, sport, museum</p><p>We set the parameters {w1, w2} as {1.0, 0.2} empirically. For instance, for City Houma, LA and Category "park", the query is: ÔÇ≤ #weight(1.0 #combine(park landscape nature) 0.2 #band(houma la) 0.2 #band(houma louisiana))</p><p>Although we increase weights of a document if it contains the correct city name, the increment is lightweight. This is because that a great deal of list pages will contain many location terms in their pages, and will be ranked high. However, they are not our search targets. We eliminate the effects by assigning a light weight to city names and state names. However, all returned documents should be geographically relevant. Therefore, after a document list is retrieved, we post-process the returned document list and make sure that every document contains the correct location terms in it. The unmatched ones are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Reorganizing the Retrieval Results</head><p>The retrieved results need to be merged according to each user's personal profile. We import all user ratings for the training city. It gives us a matrix that describes users' personal interests towards twenty three categories (Table <ref type="table" coords="5,186.53,245.13,3.60,8.64" target="#tab_2">5</ref>). A mapping between user's degree of fondness and a numeric user interest weight is listed in Table <ref type="table" coords="5,188.44,256.41,3.73,8.64" target="#tab_1">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>‚àë</head><p>If a user's fondness towards one category is bigger than the mean fondness of this user for all categories and also is bigger than the mean fondness received by this category from all users, we treat this category as this user's major interest. Besides major interests, other categories are considered as minor interests. For example, Profile 36's major interests include caf√© and landmark, minor interests include bar. The result merging goes through several iterations. We assume that user i has major interests cat 1 to cat n with weight w 1 to w n and has minor interests cat m to cat 23 with weight w m to w 23 . ùëä</p><formula xml:id="formula_0" coords="5,89.88,531.80,411.50,27.87">!"" = ùë§ ! !" !!! , W !"#$% = ùë§ ! ! !!!</formula><p>, |Major interests| = n, |Minor interests|=23-n. In an iteration, we generate contextual suggestions for categories ranked in descending order of category weight. In the first iteration, we only consider major interests and we output at least five suggestions. For cat i , we output</p><formula xml:id="formula_1" coords="5,93.67,600.04,81.47,18.45">max (5, n) √ó ! ! ! !"#$%</formula><p>pieces of cat i type suggestions. For other iterations, we consider both major and minor interests. We output 23 √ó ! ! ! !"" pieces of contextual suggestions for cat i . We stop the merging when we have 50 contextual suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Generating Descriptions</head><p>To generate the description for a suggestion, we examine a webpage's metadata for its description field. If a description is provided in the metadata, we use this description as our description; otherwise we extract the first five hundred and twelve characters from the body text and use them as our description. All HTML tags are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Submissions and Results</head><p>We submit two runs to TREC 2013 Contextual Suggestion Track, namely BOW_V17 and BOW_V18. They are similar runs. The only difference is that they use different description generation methods. Our runs give the best performance among all approaches using the closed collection.</p><p>Figure <ref type="figure" coords="6,234.71,345.40,7.70,8.75">2</ref> Lemur (left) vs. Our System (right) Figure <ref type="figure" coords="6,128.84,358.65,4.92,8.64">2</ref> shows a side-by-side comparison between the results retrieved by the default Lemur search engine and our system. The top documents retrieved by Lemur are either off-topic or list webpages. In our system, off-topic webpages rarely appear, and precision is much higher. Moreover, our retrieval results are well-balanced among various user interests in a personal profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3 the perfomances of BOW_V17 and BOW_V18</head><p>Figure <ref type="figure" coords="6,129.42,591.69,4.92,8.64">3</ref> shows the TBG@5 scores for our runs, the median and the best TREC runs. The median and the best runs are from the Open Web subtrack. Our runs' performance is roughly equal to the median Open Web run when we consider average score over different profiles. Our runs perform better on small cities (unpopular contexts) and worse on big cities (popular contexts) than the Open Web runs perform. This is because that an Open Web run can access many popular online search engines about venue suggestions; however, these search engines contain less useful information for unpopular venues.</p><p>Nonetheless, our approach investigates retrieval techniques that purely developed upon a closed collection and shows great potential for contextual retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,130.54,362.20,336.14,8.75;3,99.88,112.92,415.24,239.15"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Examples of Wikitravel's Link, User, Talk and Disambiguation Pages</figDesc><graphic coords="3,99.88,112.92,415.24,239.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,273.45,513.36,228.45,7.80;3,95.16,529.20,231.64,7.80;3,95.16,544.56,388.87,8.27;3,95.16,560.43,342.44,8.00;3,95.16,575.76,400.96,8.27;3,95.16,591.63,402.11,8.00;3,95.16,607.23,103.44,8.00;3,95.16,622.56,23.78,7.80"><head></head><label></label><figDesc>7910 West Park Avenue, Tel 580-7200. Small museum focuses on local relationship to the wetlands habitat. Admission $3.&lt;/li&gt; &lt;li&gt; Chauvin Sculpture Garden, Location 5337 Bayouside Drive, Chauvin, LA, ‚Ä¶ The NSU Folk Art Studio is open from 1pm--3pm every Monday, Wednesday and Friday and by appointment. Free. &lt;/li&gt;‚Ä¶ &lt;li&gt; Southdown Plantation House [3] 1208 Museum Drive (just off Little Bayou Black Drive in the South west part of town) Tel 851--0154. Historic plantation house is now home to the Terrebonne Museum of History and Culture. Tues--Sat 10a--4p, $6 &lt;/li&gt;‚Ä¶</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,89.88,123.18,419.30,215.99"><head></head><label></label><figDesc></figDesc><graphic coords="6,89.88,123.18,419.30,215.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,89.88,406.02,415.23,163.45"><head></head><label></label><figDesc></figDesc><graphic coords="6,89.88,406.02,415.23,163.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,89.88,575.13,412.66,86.22"><head>Table 3</head><label>3</label><figDesc>Examples of categories and their representations</figDesc><table coords="4,89.88,589.53,412.66,71.81"><row><cell>Category</cell><cell>Bag of Words</cell></row><row><cell>cafe</cell><cell>tea coffee cafe caffeine boiling Arabica chocolate cappuccino</cell></row><row><cell>landmark</cell><cell>landmarks historic buildings sites house monument structures</cell></row><row><cell></cell><cell>preservation old ruin ancient architectural</cell></row><row><cell cols="2">performing art arts performing plays theatre artists actors theater</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,91.81,267.93,397.05,89.07"><head>Table 4</head><label>4</label><figDesc></figDesc><table coords="5,91.81,267.93,397.05,89.07"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">Degree of Fondness and User Interest Weight Mapping Table</cell><cell></cell></row><row><cell cols="8">fondness strongly disinterested disinterested</cell><cell>neutral</cell><cell></cell><cell cols="2">interested</cell><cell cols="3">strongly interested</cell></row><row><cell>weight</cell><cell cols="3">-0.75</cell><cell>-0.25</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell cols="2">0.25</cell><cell>0.75</cell><cell></cell></row><row><cell cols="11">The mean fondness for a user and for a category are calculated as:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>( Mean user i</cell><cell>)</cell><cell>=</cell><cell cols="2">( weight user cat , | i Categories cat Categories | j ‚àà ‚àë</cell><cell>j</cell><cell>)</cell><cell>,</cell><cell>( Mean cat</cell><cell>j</cell><cell>)</cell><cell>i user Users</cell><cell>( weight user cat , i | | Users</cell><cell>j</cell><cell>)</cell></row></table><note coords="5,381.82,334.46,4.98,6.37;5,359.13,337.66,6.63,11.00"><p><p>‚àà</p>=</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,99.20,422.20,386.99,88.85"><head>Table 5</head><label>5</label><figDesc></figDesc><table coords="5,99.20,422.20,386.99,88.85"><row><cell></cell><cell></cell><cell cols="2">User--Interests Matrix</cell><cell></cell><cell></cell></row><row><cell></cell><cell>cafe</cell><cell>bar</cell><cell>landmark</cell><cell>‚Ä¶</cell><cell>Mean of this user</cell></row><row><cell>Profile 35</cell><cell>0</cell><cell>-0.75</cell><cell>-0.75</cell><cell>-</cell><cell>-0.43</cell></row><row><cell>Profile 36</cell><cell>1.75</cell><cell>-0.5</cell><cell>4</cell><cell>-</cell><cell>0.89</cell></row><row><cell>‚Ä¶</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Mean of this category</cell><cell>1.34</cell><cell>0.93</cell><cell>1.25</cell><cell>-</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,97.42,717.63,135.66,8.00"><p>http://Wikitravel.org/en/Main_Page</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,97.42,728.67,113.96,8.00"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="2,97.42,739.71,190.91,8.00"><p>http://en.wikipedia.org/wiki/Wikipedia:User_pages</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="2,97.42,750.51,192.63,8.00"><p>http://en.wikipedia.org/wiki/Help:Using_talk_pages</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="2,97.42,761.55,143.26,8.00"><p>http://en.wikipedia.org/wiki/Help:Link</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="3,97.42,761.55,205.49,8.00"><p>http://en.wikipedia.org/wiki/Wikipedia:Disambiguation</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,94.38,701.38,69.46,10.54" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.61,715.53,300.00,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,156.73,715.53,179.12,8.64">Viewing morphology as an inference process</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,342.54,715.53,26.01,8.64">SIGIR</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.61,727.05,411.56,8.64;6,107.88,738.57,149.38,8.64" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,373.20,727.05,131.97,8.64;6,107.88,738.57,92.16,8.64">Generalized vector spaces model in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K M</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wojciech</forename><surname>Ziarko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><forename type="middle">C N</forename><surname>Wong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
