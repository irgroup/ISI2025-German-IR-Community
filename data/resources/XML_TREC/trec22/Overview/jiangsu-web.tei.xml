<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.18,87.70,289.63,13.50">Application of Data Fusion in the Web Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,123.74,124.54,72.76,10.80"><forename type="first">Chunlan</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Telecommunication Engineering</orgName>
								<orgName type="institution">Jiangsu University</orgName>
								<address>
									<postCode>212013</postCode>
									<settlement>Zhenjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,205.32,124.54,53.28,10.80"><forename type="first">Shengli</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Telecommunication Engineering</orgName>
								<orgName type="institution">Jiangsu University</orgName>
								<address>
									<postCode>212013</postCode>
									<settlement>Zhenjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.27,124.54,50.55,10.80"><forename type="first">Jinbo</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Telecommunication Engineering</orgName>
								<orgName type="institution">Jiangsu University</orgName>
								<address>
									<postCode>212013</postCode>
									<settlement>Zhenjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.18,124.54,69.22,10.80"><forename type="first">Yongquan</forename><surname>Tao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Telecommunication Engineering</orgName>
								<orgName type="institution">Jiangsu University</orgName>
								<address>
									<postCode>212013</postCode>
									<settlement>Zhenjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,425.07,124.54,63.10,10.80"><forename type="first">Yuping</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Telecommunication Engineering</orgName>
								<orgName type="institution">Jiangsu University</orgName>
								<address>
									<postCode>212013</postCode>
									<settlement>Zhenjiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.18,87.70,289.63,13.50">Application of Data Fusion in the Web Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">95703C2D9D76BB122A61C4D7C01E7020</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report on the experiments we conducted whilst participating in the TREC 2013 Web track. We use data fusion to test how to improve the results from different information retrieval systems. Linear combination is used for fusion and multiple linear regression is used to obtain suitable weights for all the component systems involved. In our experiments, the ClueWeb09 dataset is used as training data to obtain weights for the three component systems Indri, MG4J, and Terrier. After running the official evaluation program, we find that all four runs submitted are better than all component results with one exception.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This is the first time that we have participated in TREC and we submitted four runs to the Web track. Two of them are to ad hoc and two others to risk-sensitive tasks. We choose the ClueWeb12 Catalog-B collection for both tasks. The main technology used is data fusion, which means that we run three component information retrieval systems Indri<ref type="foot" coords="1,515.14,477.22,4.02,7.24" target="#foot_0">1</ref> , MG4J<ref type="foot" coords="1,120.02,497.98,4.02,7.24" target="#foot_1">2</ref> , and Terrier<ref type="foot" coords="1,185.21,497.98,4.02,7.24" target="#foot_2">3</ref> separately to search the same document collection, and then merge the results from these different systems to obtain the final fused result.</p><p>A collection crawled from the Web is likely to contain a considerable amount of spam pages. Many approaches have been proposed to identify spam pages based on page content, hyperlink structure, URL form, the similarity between pages of a single host, and combinations of the above-mentioned features <ref type="bibr" coords="1,334.45,604.26,12.91,10.80" target="#b1">[1]</ref>. We use Waterloo's list that we downloaded from <ref type="bibr" coords="1,178.33,624.90,12.90,10.80">[2]</ref>. After checking the spam pages manually, we set the -spamminessâ€– threshold parameter to 15%, which we believe is a reasonable value to use. Figure <ref type="figure" coords="2,149.42,74.72,6.00,10.80" target="#fig_0">1</ref> and Figure <ref type="figure" coords="2,216.65,74.72,6.00,10.80">2</ref> show the main processes for ad-hoc and risk-sensitive tasks respectively. Three state-of-art systems (Indri, MG4J and Terrier) were chosen to obtain the original results, which is followed by the removal of the spam pages during the post-retrieval phase. Finally, we use linear combination to fuse the component results, with the weights obtained by using the ClueWeb09 Category B collection and 50 queries used in the TREC 2011 Web track. The remainder of this report is structured as follows. In Section 2, we describe those component systems involved. Section 3 details our data fusion strategy. In Section 4, we describe the settings of the data fusion approach and all related issues. In Section 5, we present the results for the 4 runs submitted to the ad-hoc task and the risk-sensitive task.</p><p>Conclusive remarks are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Description of Component Retrieval Systems</head><p>In this section, we briefly discuss Indri, MG4J, and Terrier. All of them are well-known retrieval systems in the information retrieval research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indri</head><p>Indri is a search engine that provides state-of-the-art text search capabilities and a rich structured query language for text collections of up to 50 million documents (single machine) or 500 million documents (distributed search). It is available for Linux, Solaris,</p><p>Windows and Mac OSX. Indri is a part of the Lemur project and developed by researchers from UMass and Carnegie Mellon University.</p><p>From an academic perspective, Indri combines inference networks with language modeling. The query language, which is reminiscent of the Inquery query language, allows researchers to experiment with proximity, document structure, text passages, and other document features without writing code. Like other academic engines, Indri can parse TREC newswire and web collections, and it is able to return results in the TREC standard format.</p><p>From an industrial perspective, Indri is efficient and easy to integrate with other software components. Indri is freely available from UMass with a flexible BSD-inspired license. Indri includes an API that is accessible from C++, Java, C# and PHP. Indri can also be distributed across a cluster of nodes for high speed query performance. In version 2.0, Indri adds true multithreaded operation, so documents can be added, queried and deleted concurrently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MG4J</head><p>MG4J (Managing Gigabytes for Java) is a free full-text search engine for large document collections written in Java. It is a customizable search engine providing state-of-the-art features (such as BM25/BM25F scoring) and new research algorithms. As described by its developers, it main characteristics are:</p><p>ï¬ Support for document collections and factories makes it possible to analyze, index and query consistently large document collections, providing easy-to-understand snippets that highlight relevant passages in the retrieved documents.</p><p>ï¬ It supports multi-index interval semantics. When a query is submitted, MG4J returns, for each index, a list of intervals satisfying the query. This provides the basis for several high-precision scorers and for very efficient implementation of sophisticated operators. The intervals are built in linear time using new research algorithms.</p><p>ï¬ MG4J provides implementations of phrase queries, proximity restrictions, ordered conjunction, and combined multiple-index queries. Each operator is represented internally by an abstract object, so a user can easily plug in one's favorite syntax.</p><p>ï¬ It supports virtual fields-fields containing text for a different, virtual document; the typical example is anchor text, which must be attributed to the target document.</p><p>ï¬ MG4J is flexible so that smaller indices are possible by dropping term positions, or even term counts. Several different types of codes can be chosen to balance efficiency and index size. Documents coming from a collection can be renumbered (e.g., to match a static rank or experiment with indexing techniques).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Terrier</head><p>Terrier is an open source search engine developed at Glasgow University. It is written in Java, readily deployable on large-scale collections of documents. Terrier provides another good platform for research and experimentation in text retrieval, especially for research carried out on standard TREC test collections.</p><p>Terrier can index large corpora of documents, and provides multiple indexing strategies, such as multi-pass, single-pass and large-scale MapReduce indexing. A user can specify fields that need to be indexed. Terrier also offers many models for retrieval, such as BM25, TF_IDF and the BB2 weighting model. When running Terrier in the experiment, we chose the multi-pass mode. During indexing, all the words in the collection were stemmed using the well-known Krovetz stemmer and stop-words were removed using the stop-word list embedded within Terrier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data Fusion Strategy</head><p>Previous studies demonstrate that data fusion, which uses a group of information retrieval systems to search the same document collection, and then merges the results from these different systems, is an attractive option to improve retrieval effectiveness.</p><p>Among different data fusion methods, linear combination is an effective method because of its flexibility in assigning different weights to different component systems. For a query q, each of the systems ir i provides a result ğ‘Ÿ ğ‘– and each ğ‘Ÿ ğ‘– comprises a ranked list of documents with associated scores. The linear combination method uses the following formula to calculate score for every document d:</p><formula xml:id="formula_0" coords="5,249.65,174.74,108.52,36.60">M d, q = Î² i * S i d, q n i=1</formula><p>Here ğ‘† ğ‘– ğ‘‘, ğ‘ is the normalized score of document d in result ğ‘Ÿ ğ‘– , ğ›½ ğ‘– is the weight assigned to system ğ‘–ğ‘Ÿ ğ‘– , and M (d, q) is the calculated score of d for q . All the documents can be ranked according to their calculated scores.</p><p>How to assign weights to the component systems is a key issue in linear combination. Multiple linear regression (LCR) is an effective method <ref type="bibr" coords="5,432.70,302.29,14.08,10.80" target="#b2">[3]</ref> that minimizes the difference between the estimated scores of all documents by linear combination and the judged scores of those documents in the sense of least squares.</p><p>Let us assume that there are n information retrieval systems ir 1 , ir 2 ,â€¦, ir n , m queries and l documents in a document collection D. Every document in at least one of the results can be represented as a score vector &lt;</p><formula xml:id="formula_1" coords="5,277.96,405.86,244.03,14.69">i k i nk i k i k y s s s , ,..., , 2 1 &gt; for i= (1, 2â€¦ m), k= (1, 2â€¦ l).</formula><p>Here ğ‘  ğ‘—ğ‘˜ ğ‘– stands for the score assigned by retrieval system j ir to document k d for query i q and i k y is the judged relevance score of d k for query q i . We want to estimate</p><formula xml:id="formula_2" coords="5,215.69,481.75,176.72,14.28">Y = ğ‘¦ ğ‘˜ ğ‘– ; ğ‘– = (1, 2, â€¦ , ğ‘š), ğ‘˜ = (1,2, â€¦ , ğ‘™)</formula><p>using the linear combination of scores from all component systems. The least squares estimates are used for the calculation of ğ›½ 0 , ğ›½ 1 , â€¦ , ğ›½ ğ‘› for which the quantity</p><formula xml:id="formula_3" coords="5,187.97,546.55,235.72,36.60">q = [y k i -(ğ›½ 0 + ğ›½ 1 ğ‘  1ğ‘˜ ğ‘– + ğ›½ 2 ğ‘  2ğ‘˜ ğ‘– + â‹¯ + ğ›½ ğ‘› ğ‘  ğ‘›ğ‘˜ ğ‘– )] 2 l k=1 m i=1</formula><p>is a minimum.</p><p>Coefficients ğ›½ 1 , ğ›½ 2 , â€¦ , ğ›½ ğ‘› , are numerical parameters that can be determined from some training data and can be used as weights by ğ‘–ğ‘Ÿ 1, ğ‘–ğ‘Ÿ 2 , â€¦ , ğ‘–ğ‘Ÿ ğ‘› for fusion.</p><p>A related issue is how to obtain reliable scores for those retrieved documents.</p><p>Sometimes scores are provided by component retrieval systems, but usually those raw scores from different retrieval systems are not comparable and some kind of score normalization is needed before fusing those documents. An alternative is to convert ranking information into scores if raw scores are not available or not reliable. In our experiment, we use a reciprocal function of rank <ref type="bibr" coords="6,325.51,116.14,14.06,10.80" target="#b3">[4]</ref> for this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental setup</head><p>In this section we provide information for the setup of the experiment including how to obtain weights, running component retrieval systems, score normalization, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Obtaining weights from training data</head><p>The ClueWeb09 Category B dataset is indexed by three information retrieval systems Indri, MG4j and Terrier, separately. 50 queries in the TREC 2011 web track are used to obtain results and each retrieves 10000 documents for every query. In the training process, documents are divided into two types, relevant and irrelevant documents, for linear regression analysis. The weights we obtain are 5.2534, 6.0191, and 5.1540 for Indri, MG4J, and Terrier, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Running component retrieval systems</head><p>When running the component retrieval systems on the ClueWeb12 Category B collection, we use all the words given by TREC for each topic. For example, the words for topic 203 are -reviews of les miserablesâ€–. Next, we remove probable spam pages (top 15% of the pages in the list downloaded from [2]). We keep two slightly different results</p><p>for each component retrieval systems: the original result and the result with the spam pages removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Normalizing scores</head><p>In order to generate reliable and comparable scores for all the documents involved, we use a reciprocal function of rank <ref type="bibr" coords="6,267.05,545.55,12.87,10.80" target="#b3">[4]</ref>. For a group of ranked documents &lt;d for 1 â‰¤ i â‰¤ n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Data fusion</head><p>For the ad hoc task, we fuse results from Indri, MG4J and Terrier with the aforementioned weights in Section 3.1. Two runs are generated: UJS13LCRAd1 from the original results of those component systems, and UJS13LCRAd2 from modified results with spam pages removed. For the risk-sensitive task, we fuse results from Indri, MG4J, Terrier and the baseline (as provided by TREC) as well. The weights for Indri, MG4J, and Terrier are the same as in the ad hoc task; we give baseline a weight equal to the average of all 3 component systems. As in the ad hoc task, we also submitted two runs UJS13LCRAd1 and UJS13LCRAd2. The former is the fused result from original results, while the latter is the one from modified results after spam page removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results analysis and conclusions</head><p>Results from component systems and fusion are presented in Tables <ref type="table" coords="7,429.62,205.66,6.00,10.80" target="#tab_1">1</ref> and<ref type="table" coords="7,461.14,205.66,6.00,10.80" target="#tab_2">2</ref> for ad hoc and risk-sensitive tasks, respectively. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,121.58,414.76,152.75,8.10;2,326.95,414.76,177.35,8.10;2,115.50,199.94,180.75,208.50"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Flow chart for the ad-hoc task Figure 2. Flow chart for the risk-sensitive task</figDesc><graphic coords="2,115.50,199.94,180.75,208.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,90.02,545.43,432.08,39.51"><head></head><label></label><figDesc>1 , d 2 â€¦, d n &gt;, whose ranks are 1, 2, â€¦, n, we normalize them by s i =</figDesc><table coords="6,355.51,564.31,16.19,20.64"><row><cell>1</cell></row><row><cell>i+60</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,112.34,258.64,374.84,193.84"><head>Table 1 .</head><label>1</label><figDesc>Performance of component and fused results in ad-hoc task</figDesc><table coords="7,112.34,289.24,374.84,163.24"><row><cell>Run</cell><cell>ERR@20</cell><cell>nDCG@20</cell><cell>P@20</cell><cell>MAP</cell></row><row><cell>UJS13LCRAd1</cell><cell>0.097</cell><cell>0.144</cell><cell>0.248</cell><cell>0.045</cell></row><row><cell>UJS13LCRAd2</cell><cell>0.107</cell><cell>0.148</cell><cell>0.251</cell><cell>0.052</cell></row><row><cell>Terrier</cell><cell>0.082</cell><cell>0.112</cell><cell>0.186</cell><cell>0.026</cell></row><row><cell>Indri</cell><cell>0.1</cell><cell>0.122</cell><cell>0.203</cell><cell>0.044</cell></row><row><cell>MG4J</cell><cell>0.082</cell><cell>0.106</cell><cell>0.175</cell><cell>0.033</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,141.62,473.58,321.09,223.73"><head>Table 2 .</head><label>2</label><figDesc>Performance of component and fused results in risk-sensitive task</figDesc><table coords="7,141.62,504.18,313.02,193.13"><row><cell>Run</cell><cell>ERR-IA@20</cell><cell>@-nDCG@20</cell><cell>NRBP</cell></row><row><cell>UJS13Risk1</cell><cell>0.451</cell><cell>0.511</cell><cell>0.415</cell></row><row><cell>UJS13Risk2</cell><cell>0.468</cell><cell>0.522</cell><cell>0.434</cell></row><row><cell>Terrier</cell><cell>0.367</cell><cell>0.431</cell><cell>0.328</cell></row><row><cell>Indri</cell><cell>0.387</cell><cell>0.450</cell><cell>0.345</cell></row><row><cell>MG4J</cell><cell>0.431</cell><cell>0.493</cell><cell>0.393</cell></row><row><cell>Baseline</cell><cell>0.326</cell><cell>0.385</cell><cell>0.291</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,97.58,691.03,148.53,8.10"><p>http://sourceforge.net/p/lemur/wiki/Indri/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,97.58,701.47,85.71,8.10"><p>http://mg4j.dsi.unimi.it/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,97.58,711.79,59.59,8.10"><p>http://terrier.org/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>From Tables <ref type="table" coords="8,178.61,74.72,6.00,10.80">1</ref> and<ref type="table" coords="8,208.71,74.72,4.50,10.80">2</ref>, we can see that the fused results are better than all component results with only one exception. When measured by ERR@20, UJS13LCRAd1 does not perform quite as well as Indri. In the ad-hoc task, UJS13LCRAd2 is the best performer outperforming the best component result (Indri) by 7.00% (measured by ERR@20), 21.31% (measured by nDCG@20), 23.65% (measured by P@20), and 18.18% (measured by MAP) -the improvement is notable. In the risk-sensitive task, UJS13Risk2 is the best, outperforming the best component result by 8.58% (measured by ERR-IA@20), 5.88% (measured by @-nDCG@20), and 10.43% (measured by NRBP). If we consider the improvement rate of the fused result to the best component result, then data fusion did better in the ad-hoc task than in the risk-sensitive task. This is not very surprising since the method of data fusion we have used was initially designed for ad hoc tasks, in particular with the measures for binary relevance judgment such as MAP and P@20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusive remarks</head><p>This is the first time that we have participated in TREC. In the future, we will investigate data fusion algorithms that are suitable for different kinds of situations such as the risk-sensitive task and measures that are based on graded relevance judgment. We will participate in more such evaluation activities to evaluate our algorithms.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,95.31,466.76,74.09,12.64" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,114.25,490.23,407.74,10.80;8,114.02,510.99,259.25,10.80;8,373.39,508.18,6.30,7.24;8,385.39,510.99,136.48,10.80;8,114.02,531.63,181.83,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,390.31,490.23,131.68,10.80;8,114.02,510.99,120.96,10.80">Detecting spam web pages through content analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fetterly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,260.93,510.99,112.34,10.80;8,373.39,508.18,6.30,7.24;8,385.39,510.99,136.48,10.80;8,114.02,531.63,79.40,10.80">Proceedings of the 15 th international conference on World Wide Web</title>
		<meeting>the 15 th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,116.41,580.62,405.61,10.80;8,114.02,601.26,210.81,10.80;8,324.91,598.45,8.10,7.24;8,337.27,601.26,184.75,10.80;8,114.02,623.10,311.24,10.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,282.65,580.62,239.36,10.80;8,114.02,601.26,99.34,10.80">The linear combination data fusion method in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,236.09,601.26,88.74,10.80;8,324.91,598.45,8.10,7.24;8,337.27,601.26,184.75,10.80;8,114.02,623.10,235.23,10.80">Proceedings of 22 nd International Conference on Database and Expert Systems Applications, Part IIï¼Œpages</title>
		<meeting>22 nd International Conference on Database and Expert Systems Applications, Part IIï¼Œpages</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="219" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.94,645.30,408.70,10.80;8,113.30,666.06,408.80,10.80;8,113.30,686.70,408.44,10.80;8,113.30,707.46,153.39,10.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,349.28,645.30,172.36,10.80;8,113.30,666.06,250.22,10.80">Reciprocal rank fusion outperforms Condorcet and individual rank learning methods</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Buettcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,393.09,666.06,129.01,10.80;8,113.30,686.70,408.44,10.80;8,113.30,707.46,42.20,10.80">Proceedings of the 32nd international ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 32nd international ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
