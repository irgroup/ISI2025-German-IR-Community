<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,186.94,116.03,238.15,15.11;1,126.25,139.04,359.54,15.11">UMass at TREC 2010 Web Track: Term Dependence, Spam Filtering and Quality Bias</title>
				<funder ref="#_8NRsCeN">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_zUW38vu">
					<orgName type="full">ARRA NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,177.99,173.64,93.52,10.48"><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.96,173.64,64.32,10.48"><forename type="first">David</forename><surname>Fisher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.18,173.64,79.82,10.48"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,186.94,116.03,238.15,15.11;1,126.25,139.04,359.54,15.11">UMass at TREC 2010 Web Track: Term Dependence, Spam Filtering and Quality Bias</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4606C7BC9DFBE6BC18132035FDF300EB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many existing retrieval approaches treat all the documents in the collection equally, and do not take into account the content quality of the retrieved documents. In our submissions for TREC 2010 Web Track, we utilize quality-biased ranking methods that are aimed to promote documents that potentially contain high-quality content, and penalize spam and low-quality documents. Our experiments with the ad hoc web topics from TREC 2010 show that features such as the spamminess of the document (as computed by the Waterloo team <ref type="bibr" coords="1,459.09,326.48,10.80,8.74" target="#b5">[6]</ref>) and the readability of the document (modeled by the fraction of stopwords in the document) are very important for improving the precision at the top ranks. Promotion of the high-quality Wikipedia pages leads to further retrieval performance improvements. In addition, we found that using Wikipedia as a high-quality document collection for query expansion can ameliorate some of the negative effects of performing pseudo-relevance feedback from a noisy web collection such as ClueWeb09.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this notebook, we describe the details of the participation of the UMass Amherst team in the adhoc task of the TREC 2010 Web Track. Our participating systems focused on three major features of information retrieval on web scale: (a) query term dependence, (b) spam filtering, and (c) document quality bias. The first two features (term dependence and spam filtering) have been previously recognized as an important part of web search systems by past TREC participants, while the third one (document quality bias) is not as well explored and understood. Next, we describe these three features in more depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Term Dependence</head><p>Several teams at Web Track 2009 (for instance, <ref type="bibr" coords="1,305.71,597.98,16.97,9.57" target="#b14">[15,</ref><ref type="bibr" coords="1,326.78,597.98,8.49,9.57" target="#b6">7]</ref>) used the Markov Random Field retrieval model (MRF-IR) <ref type="bibr" coords="1,157.19,612.21,16.97,9.57" target="#b12">[13]</ref> to model term dependencies. Similarly, several teams at the Terabyte Track <ref type="bibr" coords="1,72.00,626.44,11.52,9.57" target="#b4">[5]</ref> and the Million Query Track <ref type="bibr" coords="1,226.47,626.44,11.52,9.57" target="#b0">[1]</ref> that preceded the Web Track used the MRF-IR model to build highly effective retrieval systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Spam Filtering</head><p>Spam detection and filtering was recognized as an important component of web retrieval in Web Track 2009. Lin et al. <ref type="bibr" coords="2,188.04,111.01,16.97,9.57" target="#b11">[12]</ref> used a commercial spam detection system to improve the quality of their submissions. Cormack et al. <ref type="bibr" coords="2,248.66,125.23,11.52,9.57" target="#b5">[6]</ref> created a publicly available Waterloo Spam Ranking for the ClueWeb09 Dataset, which was found to drastically improve the performance of practically all TREC Web Track 2009 submissions, when applied as a spam filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Quality Bias</head><p>In addition to the term dependence and spam detection features, which were incorporated in our submitted retrieval systems, we also tackled the issue of document quality bias that was recently found to improve the performance of web retrieval, even after the application of a spam filter and a link-based prior <ref type="bibr" coords="2,159.71,247.55,10.91,9.57" target="#b2">[3]</ref>.</p><p>A quality of a web page is determined by a combination of many distinct factors. First, it has to contain original, trustworthy, and up-to-date content of genuine value. It should also provide metadata that accurately describes the content of a page, and contain links that can point people to other related resources. Finally, web page layout should be consistent and follow the principles of user-centric web design, by allowing readers to effortlessly navigate to the relevant information on the page. As document quality is influenced to some degree by all of these factors, the quality of a page should not be viewed as a dichotomy, but rather as a continuous spectrum.</p><p>At one end of this quality spectrum are well known resources for high-quality web documents such as Wikipedia. Wikipedia articles are constantly monitored and updated by editors, have a consistent layout and usually contain links to other related Wikipedia articles and web pages of interest. On the other end of this spectrum are spam pages that employ techniques such as content duplication, link schemes, content cloaking and keyword stuffing to artificially inflate their search engine ranking and provide no useful content (or even fraudulent and harmful content) to their readers.</p><p>Most of the pages on the web, however, are somewhere in between these two extremes on the quality spectrum. Many web pages do not have the same level of editorial supervision as Wikipedia, and might contain some outdated information, but still provide useful content to their readers. Many of the web pages also do not have a consistent easy-to-follow layout, making it harder to locate relevant portions of the text. However, these pages of lesser quality are still relevant to some user queries. This is especially true for rare and "niche" user information needs that often lack proper coverage by high quality resources such as Wikipedia. Therefore, we believe that it is important to explicitly incorporate the information about the quality of the page into the ranking produced by the search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Modeling Term Dependence</head><p>In order to model the term dependence, we make use of the sequential dependence variant of the MRF-IR model proposed by Metzler and Croft <ref type="bibr" coords="2,305.41,649.29,16.01,9.57" target="#b12">[13]</ref>. Next, we briefly describe the basics of this model.</p><p>The sequential dependence model goes beyond single query terms, and incorporates both exact phrase matches (the exact phrase appears in the document) and proximity matches (the terms in the phrase appear in close proximity to each other in the document) into the retrieval function. The sequential dependence model considers the adjacent bigrams in the query. For instance, for a query income tax return online the following bigrams will be considered: income tax, tax return, and return online. The term and bigram exact and proximity matches are assigned different weights, which are tuned to optimize the retrieval performance. Using the Indri query language <ref type="bibr" coords="3,117.46,163.38,16.01,9.57" target="#b15">[16]</ref>, the example query will be rewritten as #weight( 0.8 #combine(income tax return online) 0.15 #combine( #1(income tax) #1(tax return) #1(return online) ) 0.05 #combine( #uw8(income tax) #uw8(tax return) #uw8(return online) ) )</p><p>where the weights for the different query parts are set based on the recommendations by Metzler and Croft <ref type="bibr" coords="3,98.07,250.01,14.62,8.74" target="#b12">[13]</ref>. We refer to the score assigned to the document by the sequential dependence model as sc T D (D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Spam Filtering Stage</head><p>We used the spam filtering as described by Cormack et al. <ref type="bibr" coords="3,331.60,305.65,9.97,8.74" target="#b5">[6]</ref>. Using the publicly available Waterloo Spam Ranking for the ClueWeb09 Dataset. This ranking assigns a percentile p(D) to each of the ∼ 500 million documents in the collection. We filter out the bottom 60% of the documents, as determined by the spam ranking, as this number was found to optimize ERR@10 and NDCG@10 in our preliminary experiments with the Web Track 2009 queries. That is the documents are scored by</p><formula xml:id="formula_0" coords="3,225.23,364.97,160.34,35.05">sc SF (D) = { sc T D (D) if p(D) ≥ 60 -∞ else.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Quality Biasing Stage</head><p>While there is an abundance of features that can be associated with document quality (see, for instance, <ref type="bibr" coords="3,72.00,455.57,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="3,86.66,455.57,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="3,98.54,455.57,12.73,8.74" target="#b13">14,</ref><ref type="bibr" coords="3,115.42,455.57,12.73,8.74" target="#b16">17]</ref> for an extensive examination of such features) for our submission we chose to focus on two features that we found to have a highly positive effect on the retrieval performance in our preliminary experiments with the Web Track 2009 queries.</p><p>• I w (D) -Wikipedia Indicator. Indicates whether the document D is a part of the en.wikipedia.org domain. Wikipedia pages are known to provide good answers to many web search queries, and are often promoted to the top ranks by the commercial search engines. An examination of the relevance judgments from Web Track 2009 reveals that more than 12% of the relevant documents are Wikipedia pages, which is much higher than the proportion of the Wikipedia pages in ClueWeb09. For instance, University of Amsterdam TREC team in Web Track 2009 achieved an impressive retrieval performance by simply promoting Wikipedia pages to the top ranks <ref type="bibr" coords="3,342.25,575.33,9.97,8.74" target="#b6">[7]</ref>.</p><p>• σ(D) -Stopword to non-stopword ratio of the document D. Percentage of the terms on the page that are in the stopword list. The stopword list is constructed using the top-100 most frequent alphabetic unigrams in a large web corpus <ref type="bibr" coords="3,236.06,617.51,9.97,8.74" target="#b3">[4]</ref>. Low values of σ(D) usually characterize documents that have very poor readability and are very unlikely to contain useful and relevant information on any topic <ref type="bibr" coords="3,510.88,630.06,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="3,524.63,630.06,11.63,8.74" target="#b13">14]</ref>.</p><p>The quality biased document score is computed, based on the two features above, as</p><formula xml:id="formula_1" coords="3,196.26,658.51,343.74,35.05">sc QB (D) = { λsc SF (D) + (1 -λ)I w if σ(D) ≥ Φ -∞ else,<label>(1)</label></formula><p>where λ and Φ are free parameters that are set to 0.8 and 0.1, respectively, since these values resulted in the highest ERR@10 and NDCG@10 in our preliminary experiments with the Web Track 2009 queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Query Expansion with High Quality Documents</head><p>In addition to biasing the retrieval towards high-quality documents by explicit promotion of the Wikipedia pages, we also employed a pseudo-relevance feedback technique, which used the Wikipedia pages to improve the effect of the pseudo-relevance feedback on ClueWeb09. We found that our initial pseudo-relevance runs on the Web Track 2009 queries failed to improve performance, due to the noisy nature of the retrieved set.</p><p>For this purpose, we separately indexed the Wikipedia pages, and used this index to expand the sequential dependence model queries with 20 additional terms. The expansion terms were selected using the standard Relevance Model <ref type="bibr" coords="4,148.31,220.29,14.62,8.74" target="#b10">[11]</ref>. Next, the expanded queries were run over the entire ClueWeb09 index with the spam filter and the quality bias (see Equation <ref type="formula" coords="4,249.43,232.84,4.43,8.74" target="#formula_1">1</ref>) applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis of the Runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Setup</head><p>The English portion of the ClueWeb09 corpus (a.k.a. Category A), was indexed using the Indri toolkit<ref type="foot" coords="4,532.76,308.60,3.97,6.12" target="#foot_0">1</ref> . Both the index and the queries were stopped using a standard INQUERY stopwords list <ref type="bibr" coords="4,467.16,322.73,10.52,8.74" target="#b1">[2]</ref> and stemmed using a Krovetz stemmer <ref type="bibr" coords="4,184.23,335.28,14.62,8.74" target="#b9">[10]</ref>.</p><p>All the retrieval experiments were performed using Indri as well. Indri query language was used to create the sequential dependence model queries, as well as to perform spam filtering and query expansion. The quality biasing scoring sc QB (D), described in Section 4, was applied to the top-10K results retrieved by the spam-filtered scoring sc SF (D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison of the Runs</head><p>In this section we compare between the three runs submitted to the adhoc task of the TREC 2010 Web Track. The runs we submitted were variations of the quality-biased ranking method described in the previous sections. The description of the three runs is as follows:</p><p>1. SD -This run scored the documents based on Equation <ref type="formula" coords="4,353.34,479.67,3.88,8.74" target="#formula_1">1</ref>, with λ set to 1. The purpose of this run was to evaluate the effect of the filtering stages (spam filtering and filtering of low-quality pages with very few stopwords) on the retrieval performance. (Submitted run ID -umassSDM.)</p><p>2. SD+FB -This run employed the pseudo relevance feedback based query expansion, as described in 5. The purpose of this run was to evaluate the effect of query expansion with high quality Wikipedia documents on the retrieval performance. (Submitted run ID -umasswfb520.)</p><p>3. SD+W -This run scored the documents using the Equation <ref type="formula" coords="4,368.23,566.93,3.88,8.74" target="#formula_1">1</ref>, with λ set to 0.8. The purpose of this run was to examine the effect of the promotion of the high quality Wikipedia pages on the retrieval performance. (Submitted run ID -umassSDMW.) Table <ref type="table" coords="4,115.25,613.54,4.24,8.74">6</ref>.2 compares the retrieval performance of these runs. It is clear that both expansion from Wikipedia and promotion of Wikipedia pages have a significant positive impact on the retrieval performance, even after filtering out spam and low-quality pages. Overall, the promotion strategy of the SD+W run seems to be preferable to the expansion strategy of the SD+FB run, especially given the fact that it does not require a computationally expensive procedure of query expansion. ERR@10 NDCG@10 ≥ median 73% 71% = min 23% 23%</p><p>Table <ref type="table" coords="5,102.34,257.22,4.24,9.57">2</ref>: The percentage of queries that have above or equal to the median, or worst performance (in terms of NDCG@10 and ERR@10 of the SD+W run) compared to other TREC participants. Note: the numbers do not add up to 100% in each column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Further Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Comparison with the Other Teams</head><p>While a full comparison with the other teams is not available at this point, we can look at the distribution of our retrieval scores compared to the median and min of the overall score distributions. Looking at Table <ref type="table" coords="5,72.00,380.55,3.88,8.74">2</ref>, we can state that, overall, the performance of our runs was above the median. On a less positive note, however, there is a considerable number of cases, for which no relevant results are retrieved. We analyze these cases in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Failure Analysis</head><p>In this section we examine the queries, for which no relevant documents were retrieved at the top thirty ranks. Overall, there are eight such queries in the evaluated set. These queries are:</p><p>discovery channel store how to build a fence income tax return online to be or not to be that is the question the wall kiwi titan rice</p><p>We hypothesize that the poor performance of the three first queries on the list is actually a result of Wikipedia promotion. For these queries, the majority of the top retrieved results are Wikipedia pages, which are non-relevant to these queries. For the next two queries in the above list, stopword removal, which was performed as a part of the indexing process, is the reason that no relevant documents are retrieved. The rest of the poor-performing queries on the list are single-word queries, for which the sequential dependence model (see Section 2) fails to provide any significant benefits. In addition, the pseudo-relevance feedback fails to provide any performance improvements for most of these queries, since no relevant documents are retrieved by the original non-expanded query. For future submissions, a different, more complex, scoring method should be developed to target such single-word queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In our submissions for TREC 2010 Web Track, we utilize quality-biased ranking methods that are aimed to promote documents that potentially contain high-quality content, and penalize spam and low-quality documents. Our experiments with the ad hoc web topics from TREC 2010 show that features such as the spamminess of the document (as computed by the Waterloo team <ref type="bibr" coords="6,363.86,182.63,10.80,8.74" target="#b5">[6]</ref>) and the readability of the document (modeled fraction of stopwords in the document) are very important for improving the precision at the top ranks. Promotion of the high-quality Wikipedia pages leads to further retrieval performance improvements. In addition, we found that using Wikipedia as a high-quality document collection for query expansion can ameliorate some of the negative effects of performing pseudo-relevance feedback from a noisy web collection such as ClueWeb09.</p><p>One weak point of our submission was the failure to deal with queries that contain names or quotes, in which stopwords play an integral part (e.g., the famous "to be or not to be" quote). In addition, our methods did not perform well for many single-word queries, where both the initial retrieval and the retrieval with expanded queries yielded no relevant documents at the top ranks. We intend to explore ways of dealing with such queries in our future submissions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,72.00,74.91,467.98,102.84"><head>Table 1 : Comparison of the retrieval performance of the three submitted runs. Statistically significant differences (Wilcoxon sign test</head><label>1</label><figDesc>, α &lt; 0.05) with</figDesc><table coords="5,124.57,74.91,357.23,67.27"><row><cell></cell><cell cols="3">Binary Metrics</cell><cell></cell><cell cols="2">Graded Metrics</cell></row><row><cell></cell><cell cols="3">prec@5 b-pref MAP</cell><cell></cell><cell cols="2">NDCG@10 ERR@10</cell></row><row><cell>SD</cell><cell>32.50</cell><cell>22.80</cell><cell>11.35</cell><cell>SD</cell><cell>15.85</cell><cell>10.08</cell></row><row><cell cols="4">SD+FB 48.75  *  25.41 14.04</cell><cell>SD+FB</cell><cell>25.53  *</cell><cell>12.72</cell></row><row><cell>SD+W</cell><cell cols="3">47.50  *  24.29 14.82  *</cell><cell>SD+W</cell><cell>26.87  *</cell><cell>12.80  *</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,72.00,167.44,468.00,22.87"><head>SD are marked by * . Best result per column appears in boldface.</head><label></label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,88.59,683.99,230.58,8.11"><p>Available at http://sourceforge.net/projects/lemur/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">Acknowledgment</head><p>This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs>, in part by <rs type="funder">NSF</rs> grant #<rs type="grantNumber">CNS-0934322</rs>, and in part by <rs type="funder">ARRA NSF</rs> <rs type="grantNumber">IIS-9014442</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8NRsCeN">
					<idno type="grant-number">CNS-0934322</idno>
				</org>
				<org type="funding" xml:id="_zUW38vu">
					<idno type="grant-number">IIS-9014442</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,92.95,458.34,447.14,8.74;6,92.95,470.90,95.01,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,369.41,458.34,152.12,8.74">Million Query Track 2008 overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,92.95,470.90,62.79,8.74">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,489.43,447.16,8.74;6,92.95,501.98,95.01,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,415.26,489.43,104.46,8.74">INQUERY and TREC-9</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,92.95,501.98,62.79,8.74">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,520.51,447.05,8.74;6,92.95,533.06,85.84,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,272.40,520.51,176.10,8.74">Quality-biased ranking of web documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Diao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,468.49,520.51,64.55,8.74">Proc. of WSDM</title>
		<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,551.59,251.52,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,203.21,551.59,111.37,8.74">Web 1T 5-gram Version 1</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Franz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,570.12,447.05,8.74;6,92.95,582.68,22.70,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,264.45,570.12,188.20,8.74">Overview of the TREC 2004 Terabyte Track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,472.26,570.12,61.53,8.74">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,601.21,447.12,8.74;6,92.95,613.76,145.49,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,321.09,601.21,218.98,8.74;6,92.95,613.76,93.88,8.74">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-04">Apr 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,632.29,447.14,8.74;6,92.95,644.84,275.85,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,465.02,632.29,75.07,8.74;6,92.95,644.84,159.07,8.74">Heuristic ranking and diversification of web documents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,273.79,644.84,62.79,8.74">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,92.95,663.37,447.08,8.74;6,92.95,675.93,22.70,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,226.20,663.37,109.94,8.74">Improving web site design</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Y</forename><surname>Ivory</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,343.60,663.37,110.05,8.74">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="56" to="63" />
			<date type="published" when="2002-03">March 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,76.16,447.05,8.74;7,92.95,88.71,97.18,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,205.25,76.16,217.12,8.74">Predicting the readability of short web summaries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kanungo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Orr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,444.53,76.16,65.98,8.74">Proc. of WSDM</title>
		<meeting>of WSDM<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,107.24,429.74,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,147.63,107.24,190.81,8.74">Viewing morphology as an inference process</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,359.57,107.24,63.80,8.74">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="191" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,125.77,447.14,8.74;7,92.95,138.33,217.44,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,232.36,125.77,181.95,8.74">Relevance models in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,423.85,125.77,116.24,8.74;7,92.95,138.33,92.18,8.74">Number 13 in Information Retrieval Book Series</title>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="11" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,156.86,447.15,8.74;7,92.95,169.41,177.02,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,290.26,156.86,249.84,8.74;7,92.95,169.41,60.91,8.74">Of ivory and smurfs: Loxodontan mapreduce experiments for web search</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,174.97,169.41,62.79,8.74">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,187.94,447.06,8.74;7,92.95,200.49,117.29,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,222.56,187.94,229.42,8.74">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,473.66,187.94,66.35,8.74;7,92.95,200.49,18.51,8.74">Proc. of SIGIR 2005</title>
		<meeting>of SIGIR 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,219.02,447.05,8.74;7,92.95,231.58,80.86,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,222.75,219.02,225.19,8.74">Detecting spam web pages through content analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,469.26,219.02,62.58,8.74">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,250.11,447.11,8.74;7,92.95,262.66,160.95,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,301.46,250.11,238.60,8.74;7,92.95,262.66,44.94,8.74">Experiments with ClueWeb09: Relevance feedback and web tracks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,158.89,262.66,62.79,8.74">Proc. of TREC</title>
		<meeting>of TREC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,281.19,447.13,8.74;7,92.95,293.74,402.43,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,330.34,281.19,209.74,8.74;7,92.95,293.74,67.91,8.74">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,169.40,293.74,295.62,8.74">Proceedings of the International Conference on Intelligence Analysis</title>
		<meeting>the International Conference on Intelligence Analysis</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.95,312.27,447.04,8.74;7,92.95,324.83,63.65,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,209.39,312.27,215.86,8.74">Document quality models for web ad hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,445.25,312.27,61.75,8.74">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="331" to="332" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
