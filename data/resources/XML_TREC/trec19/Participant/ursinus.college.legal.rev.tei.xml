<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,77.04,80.11,457.95,15.24;1,278.76,100.03,54.72,15.24">Applying Latent Semantic Indexing on the TREC 2010 Legal Dataset</title>
				<funder>
					<orgName type="full">University of Saskatchewan</orgName>
				</funder>
				<funder>
					<orgName type="full">Ursinus Summer Fellows program</orgName>
				</funder>
				<funder ref="#_F9PPS2T">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,216.60,127.40,64.89,9.86"><forename type="first">Andy</forename><surname>Garron</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Ursinus College</orgName>
								<address>
									<postCode>19426</postCode>
									<settlement>Collegeville</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,307.20,127.40,88.26,9.86"><forename type="first">April</forename><surname>Kontostathis</surname></persName>
							<email>akontostathis@ursinus.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Ursinus College</orgName>
								<address>
									<postCode>19426</postCode>
									<settlement>Collegeville</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,77.04,80.11,457.95,15.24;1,278.76,100.03,54.72,15.24">Applying Latent Semantic Indexing on the TREC 2010 Legal Dataset</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">15D5E9858A25A000078C42D11F760614</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We applied both Latent Semantic Indexing (LSI) and Essential Dimensions of LSI (EDLSI) to the 2010 TREC Legal Learning task. This year the Enron email collection was used and teams were given a list of relevant and a list of non-relevant documents for each of the eight test queries. In this article we focus on our attempts to incorporate machine learning into the LSI process. We show the EDLSI continues to outperform LSI on large datasets.</p><p>For 2011 we plan to enhance our system by adding parallel and distributed approaches to LSI and EDLSI. We believe our retrieval performance would be improved if we could process more dimensions. Our current system resources limited us to 70 dimensions this year. Even with 70 dimensions our system performance was greater than or equal to the median for 6 of the 8 queries on the F1 metric.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In the 2009 TREC Legal Competition, which used the tobacco lawsuit collection, we tested a new matrix factorization for Latent Semantic Indexing (LSI). The system we used relied on MATLAB for the matrix operations, and this severely restricted our ability to process the entire term-document matrix as a unit. As a result, we relied on distributed techniques for processing the collection, and we had no way of comparing our distributed techniques to a run of the entire corpus.</p><p>For 2010 we have redeveloped and restructured our system for performance reasons, and instead of MATLAB we used a combination of CLAPACK and SVDLIBC for our matrix operations. Indexing and term weighting were provided by Lemur. We describe the process we used in section 3. Due to time constraints we were unable to develop a parallel version of this system to compare to the sequential version. That will be our primary goal for 2011.</p><p>Teams this year were permitted three runs. Our first run was a standard LSI run with the maximum number of dimensions we could process. Our second two runs used EDLSI instead of LSI, because EDLSI has been shown to work as well as or better than LSI with many fewer dimensions <ref type="bibr" coords="1,146.76,713.20,15.34,8.97" target="#b8">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section we begin with a description of vectorspace retrieval, which forms the foundation for Latent Semantic Indexing (LSI). We also present a brief overview of LSI <ref type="bibr" coords="1,384.12,298.48,10.60,8.97" target="#b4">[5]</ref>. We discuss Essential Dimensions of LSI (EDLSI) and its improvements over LSI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Vector-Space Retrieval</head><p>In vector-space retrieval, a document is represented as a vector in t-dimensional space, where t is the number of terms in the lexicon being used. If there are d documents in the collection, then the vectors representing the documents can be represented by a matrix A ∈ ℜ t×d , called the term-document matrix. Entry a i,j of matrix A indicates how important term i is to document j, where 1 ≤ i ≤ t and 1 ≤ j ≤ d.</p><p>The entries in A can be binary numbers (1 if the term appears in the document and 0 otherwise), raw term frequencies (the number of times the term appears in the document), or weighted term frequencies. Weighting can be done using either local weighting, global weighting, or a combination of both. The purpose of local weighting is to capture the relative importance of a term within a specific document; therefore, local weighting uses the frequency of the term within the document to calculate the weight and assigns a higher weight if the frequency is higher. The purpose of global weighting is to identify terms that discriminate effectively between documents; thus, global weighting uses the frequency of the term within the entire document collection to calculate the weight and assigns a higher weight if the frequency is lower. Because document size often varies widely, the weights are also usually normalized; otherwise, long documents are more likely to be retrieved. See, e.g., <ref type="bibr" coords="1,525.84,653.32,10.69,8.97" target="#b1">[2]</ref>, <ref type="bibr" coords="1,312.00,665.32,16.52,8.97" target="#b12">[14]</ref> for a comprehensive discussion of local and global weighting techniques. In our experiments we used tf-idf weighting and cosine normalization.</p><p>Common words, such as and, the, if, etc., are considered to be stop-words <ref type="bibr" coords="1,408.12,713.20,11.60,8.97" target="#b1">[2]</ref> and are not included in the term-document matrix. Words that appear infrequently are often excluded to reduce the size of the lexicon.</p><p>Like the documents, queries are represented as tdimensional vectors, and the same weighting is applied to them. Documents are retrieved by mapping q into the row (document) space of the term-document matrix, A:</p><formula xml:id="formula_0" coords="2,163.92,155.12,44.17,11.41">w = q T A.</formula><p>After this calculation, w is a d-dimensional row vector, entry j of which is a measure of how relevant document j is to query q. In a traditional search-andretrieval application, documents are sorted based on their relevance score (i.e., vector w) and returned to the user with the highest-scoring document appearing first. The order in which a document is retrieved is referred to as the rank 1 of the document with respect to the query. The experiments in this paper run multiple queries against a given dataset, so in general the query vectors q 1 , q 2 , . . . , q n are collected into a matrix Q ∈ ℜ t×n and their relevance scores are computed as</p><formula xml:id="formula_1" coords="2,161.76,326.36,48.49,11.41">W = Q T A,</formula><p>where entry w j,k in W ∈ ℜ n×d is a measure of how relevant document j is to query k.</p><p>There are two immediate deficiencies of vector-space retrieval. First, W might pick up documents that are not relevant to the queries in Q but contain some of the same words. Second, Q may overlook documents that are relevant but that do not use the exact words being queried. The partial singular value decomposition (PSVD) that forms the heart of LSI is used to capture term relationship information in the term-document space. Documents that contain relevant terms but perhaps not exact matches will ideally still end up 'close' to the query in the LSI space <ref type="bibr" coords="2,169.08,490.12,10.60,8.97" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Latent Semantic Indexing</head><p>LSI uses the PSVD to approximate A, alleviating the deficiencies of vector-space retrieval described above.</p><p>The PSVD, also known as the truncated SVD, is derived from the SVD. The (reduced) SVD decomposes the term-document matrix into the product of three matrices: U ∈ ℜ t×r , Σ ∈ ℜ r×r , and V ∈ ℜ d×r , where r is the rank of the matrix A. The columns of U and V are orthonormal, and Σ is a diagonal matrix, the diagonal entries of which are the r non-zero singular values of A, customarily arranged in non-increasing order. Thus A is factored as</p><formula xml:id="formula_2" coords="2,159.60,662.36,52.81,11.41">A = U ΣV T .</formula><p>The PSVD produces an optimal rank-k (k &lt; r) approximation to A by truncating Σ after the first (and 1. This rank is unrelated to the rank of a matrix mentioned below. largest) k singular values. The corresponding columns from k + 1 to r of U and V are also truncated, leading to matrices U k ∈ ℜ t×k , Σ k ∈ ℜ k×k , and V k ∈ ℜ d×k . A is then approximated by</p><formula xml:id="formula_3" coords="2,382.32,132.20,87.37,12.86">A ≈ A k = U k Σ k V T k .</formula><p>In the context of LSI, there is evidence to show that A k provides a better model of the semantic structure of the corpus than the original term-document matrix was able to provide for some collections <ref type="bibr" coords="2,488.88,189.40,10.60,8.97" target="#b4">[5]</ref>, <ref type="bibr" coords="2,507.36,189.40,10.60,8.97" target="#b5">[6]</ref>, <ref type="bibr" coords="2,525.84,189.40,10.69,8.97" target="#b6">[7]</ref>, <ref type="bibr" coords="2,312.00,201.28,10.60,8.97" target="#b2">[3]</ref>. For example, searchers may choose a term, t 1 , that is synonymous with a term, t 2 , that appears in a given document, d 1 . If k is chosen appropriately and there is ample use of the terms t 1 and t 2 in other documents (in similar contexts), the PSVD will give t 1 a large weight in the d 1 dimension of A k even though t 1 does not appear in d 1 . Similarly, an ancillary term t 3 that appears in d 1 , even though d 1 is not 'about' t 3 , may well receive a lower or negative weight in A k matrix entry (t 3 , d 1 ).</p><p>Choosing an optimal LSI dimension k for each collection remains elusive. Traditionally, an acceptable k has been chosen by running a set of queries with known relevant document sets for multiple values of k. The k that results in the best retrieval performance is chosen as the optimal k for each collection. Optimal k values are typically in the range of 100-300 dimensions <ref type="bibr" coords="2,501.84,380.80,10.60,8.97" target="#b5">[6]</ref>, <ref type="bibr" coords="2,519.48,380.80,15.24,8.97" target="#b10">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Essential Dimensions of LSI</head><p>As the dimension of the LSI space k approaches the rank r of the term-document matrix A, LSI approaches vector-space retrieval. In particular, vector-space retrieval is equivalent to LSI when k = r.</p><p>Figures <ref type="figure" coords="2,356.88,473.92,4.98,8.97">1</ref><ref type="figure" coords="2,361.86,473.92,4.98,8.97">2</ref><ref type="figure" coords="2,366.84,473.92,4.98,8.97">3</ref>show graphically that the performance of LSI may essentially match (or even exceed) that of vector-space retrieval even when k ≪ r. For the CACM <ref type="bibr" coords="2,345.12,509.80,16.64,8.97" target="#b13">[15]</ref> and NPL [8] collections, we see that LSI retrieval performance continues to increase as additional dimensions are added, whereas retrieval performance of LSI for the MED collection peaks when k = 75 and then decays to the level of vector-space retrieval. Thus we see that vector-space retrieval outperforms LSI on some collections, even for relatively large values of k. Other examples of collections that do not benefit from LSI can be found in <ref type="bibr" coords="2,398.64,605.44,16.52,8.97" target="#b9">[11]</ref> and <ref type="bibr" coords="2,436.56,605.44,10.60,8.97" target="#b7">[9]</ref>.</p><p>These data suggest that we can use the term relationship information captured in the first few SVD vectors, in combination with vector-space retrieval, a technique referred to as Essential Dimensions of Latent Semantic Indexing (EDLSI). Kontostathis demonstrated good performance on a variety of collections by using only the first 10 dimensions of the SVD <ref type="bibr" coords="2,475.08,689.32,15.24,8.97" target="#b8">[10]</ref>. The model obtains final document scores by computing a weighted average of the traditional LSI score using a small value for k and the vector-space retrieval score. The result vector computation is</p><formula xml:id="formula_4" coords="3,116.52,632.36,138.85,11.90">W = x(Q T A k ) + (1 -x)(Q T A),</formula><p>where x is a weighting factor (0 ≤ x ≤ 1) and k is small.</p><p>In <ref type="bibr" coords="3,94.68,677.32,15.24,8.97" target="#b8">[10]</ref>, parameter settings of k = 10 and x = 0.2 were shown to provide consistently good results across a variety of large and small collections studied. On average, EDLSI improved retrieval performance an av-erage of 12% over vector-space retrieval. All collections showed significant improvements, ranging from 8% to 19%. Significant improvements over LSI were also noted in most cases. LSI outperformed EDLSI for k = 10 and x = 0.2 on only two small datasets, MED and CRAN. It is well known that LSI happens to perform particularly well on these datasets. Optimizing k and x for these specific datasets restored the outperformance of EDLSI.</p><p>Furthermore, computation of only a few singular values and their associated singular vectors has a significantly reduced cost when compared to the usual 100-300 dimensions required for traditional LSI. EDLSI also requires minimal extra memory during query run time when compared to vector-space retrieval and much less memory than LSI <ref type="bibr" coords="3,387.72,244.96,15.34,8.97" target="#b8">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>The dataset for the 2010 TREC Legal Track Learning Task contains a large volume of information, approximately 700,000 documents in many different formats (.txt, .pst, .ppt, etc.) that take up 3.71 gigabytes of disk space. Each document needed to be added to an index in order to create the term-document matrix for the dataset. The Lemur Toolkit was used to index the collection <ref type="bibr" coords="3,520.92,365.68,15.34,8.97" target="#b11">[13]</ref>. The Lemur Toolkit is designed to take a set of documents formatted in a certain way and add them quickly to an index that can then be used to glean information about the dataset as a whole, as well as information about each document.</p><p>All terms that appeared in more than 100,000 documents were considered bad discriminators between documents and were removed from the index. Terms that included numeric characters or other characters not in the alphabet were also eliminated. Documents which contained no indexed terms after parsing were considered to be 'blank' and were removed from further processing. After pruning our term-document matrix size was 302,119 (terms) by 456,968 (documents). Pruned documents were added to our run submission file, with a probability of zero, to meet the requirements for submission.</p><p>After a final term-document matrix was created for the TREC dataset, the LSI process began. We evaluated several different libraries used to perform operations on dense vectors and matrices to determine which would adequately serve our needs. This was an important decision because LSI requires two large matrix multiplications for every query. We chose CLAPACK (a C library designed to provide the FORTRAN LAPACK library functionality in a C/C++ environment) <ref type="bibr" coords="3,417.36,677.32,11.60,8.97" target="#b0">[1]</ref> to handle the dense matrix calculations. Although CLAPACK was also our first choice for the calculation of the SVD, this proved ineffective, as CLAPACK does not work with sparse matrices. SVDLIBC was used for the decomposition and it provided much-increased speed and functionality for working with the sparse term-document matrix <ref type="bibr" coords="4,267.72,101.08,10.60,8.97" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Optimizing k</head><p>We were permitted three runs for submission to the TREC Legal learning task. We decided to use one submission using LSI, and another two using EDLSI with different k choices. The k's that were chosen were determined by a simple scoring algorithm: given that we know a subset of the relevant documents and a subset of the irrelevant documents, we can ignore the rest of the documents in our result set, and count up the knownrelevant documents that are listed below the cutoff for relevant documents (and the known-irrelevant documents that are listed above the cutoff for irrelevant documents). The sum is the score of a query result, and the higher the sum, the worse the result. The results that scored the best on average across all topics were the k-selections of 35 and 70. Due to memory restrictions on our research computer, we could not select a k value greater than 70.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND DISCUSSION</head><p>The results from our runs are shown in Figures <ref type="figure" coords="4,261.48,366.40,38.82,8.97;4,72.00,378.40,3.77,8.97" target="#fig_1">4 through  9</ref>. There are some interesting trends and there is also a lot of room for improvement.</p><p>Figure <ref type="figure" coords="4,110.88,402.28,4.98,8.97" target="#fig_1">4</ref> compares the F1 metric for our runs with the best and the median F1 metrics. Using this measure, we did reasonably well, with our EDLSIK70 run meeting or exceeding the median for 6 of the 8 queries. EDLSIK70 outperforms both of our other runs, showing that EDLSI outperforms LSI on this large collection.</p><p>Figure <ref type="figure" coords="4,111.12,474.04,4.98,8.97">5</ref> tells the opposite story. The Hypothetical F1 would be the F1 if the best cutoff was chosen. This metric is a measure of our ranking. Our runs performed lower than the median on 6 of the 8 queries. EDLSI, however, is still showing improvement over LSI, and a lower k value (k = 35 vs k = 70) is better for EDLSI.</p><p>Figure <ref type="figure" coords="4,111.60,545.80,4.98,8.97" target="#fig_2">6</ref> and 7 are measures of our ability to predict the probability of relevance for each document. Again, we show results better than the median on most of the queries. Generally, our system had a problem with queries 202 and 205. More analysis will be needed to determine the features of these requests that make them so difficult for us. All of our runs were fullyautomated, and terms were simply extracted from the short description of the request to generate our query vector. More carefully chosen terms may improve the results dramatically (but would also mean that our run would be semi-automated instead of fully-automated).</p><p>Figures <ref type="figure" coords="4,115.32,689.32,4.98,8.97">8</ref> and<ref type="figure" coords="4,141.60,689.32,4.98,8.97">9</ref> seem to provide conflicting information. The cutoff accuracy figures were pretty reasonable, doing better than the median on 6 of the 8 requests, but the cutoff values seem to be way out of line. We most often have suggested retrieval of many more documents than were needed (17 of 24 instances), and we were often orders of magnitude off the mark (ex. LSI for request 207). Interestingly we consistently under-estimated the number of documents for 205. This probably has less to do with the cutoff assignment, however, than the actual retrieval quality for that request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE DIREC-TIONS</head><p>We have developed a system that uses LSI and EDLSI on the ENRON collection. Our 2010 run results show that EDLSI outperforms LSI. However, there were two requests that did not perform well at all. We will begin 2011 with an analysis of these queries. We are curious to see if simply modifying (increasing) k can improve our results. We also are planning to do some testing that would optimize k for each request (rather than systemwide, as is typically done). Other directions for future research are noted below.</p><p>k-optimization: The selection of k in LSI and EDLSI (the extent to which we use the SVD) is a very important choice to make. If k is too low, the LSI portion of the results will be inaccurate. If k is too high, computation time increases substantially, and the effect of the approximation of the term-document matrix is mitigated; if k = total number of singular values then LSI and EDLSI are equivalent to vector-space retrieval. Finding an optimal k for a dataset is an area of ongoing research. Given a dataset where we know some of the relevant documents, we can run the query with multiple k values and select which one returns the most of the relevant documents as the optimal k. We were limited by memory resources in our current system, but should be able to overcome these limitations when we implement a parallel version of our system.</p><p>Selective Query Expansion: Knowing a handful of relevant documents for a query is useful in that if they are all relevant to one thing, they must be similar in at least one way. A method of reflecting that in a query is to find significant terms that co-occur in most or all of the documents and add them to our query. The mentality is that if document set A is relevant to a query and each member is similar to each other member, other sets of documents relevant to that query could also be similar to the members of A.</p><p>Automatic Query Expansion: Query vectors in the LSI sense are represented in the same form as document vectors. If we know a set of relevant documents for a general topic, it should be possible to create query vectors from those documents and run queries using each of those. Multiple result sets will be returned, and in  order to know the overall theme shared by each of those, an average of a document's score for each query could be taken and used as the final result for that document's relevancy to the general topic. This idea presents the most interesting possibilities due to its flexibility. A 'best estimate' query for the general topic could be used to try and perform k-optimization for the dataset first. Also, if we know a set of documents that are irrelevant to the general topic, as is the case with the TREC task, we could use those documents as queries and reject documents that have high similarities to them.</p><p>Query Analysis: Analysis of which topics EDLSI or LSI failed on and the characteristics of those topics could lead to a better machine learning process; perhaps we can find an attributed that can be used to determine which algorithm to use based on the nature of the query and the document set.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,72.00,78.17,228.02,9.22;3,72.00,89.85,84.49,9.96"><head>Fig. 1 .Fig. 2 .Fig. 3 .</head><label>123</label><figDesc>Fig. 1. LSI vs. vector-space retrieval for the CACM Corpus (r = 3 204).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,72.00,78.17,168.90,9.22"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. TREC Results Using F1 Metric</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,72.00,78.17,184.62,9.22"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. TREC Results -Relative Accuracy</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">ACKNOWLEDGEMENTS</head><p>This material is based upon work supported by the <rs type="funder">National Science Foundation</rs> under Grant No. <rs type="grantNumber">1003972</rs>. Additional funding was provided by the <rs type="funder">Ursinus Summer Fellows program</rs>. We also thank <rs type="person">Dr. Raymond J. Spiteri</rs> and <rs type="person">Erin Moulding</rs> from the <rs type="funder">University of Saskatchewan</rs> for their assistance with understanding the Matlab code and providing background on the project from prior years.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_F9PPS2T">
					<idno type="grant-number">1003972</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="5,330.24,651.44,209.71,7.17;5,330.24,660.44,209.59,7.17;5,330.24,669.44,209.55,7.17;5,330.24,678.32,209.67,7.17;5,330.24,687.32,44.71,7.17" xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Blackford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du Croz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Greenbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hammarling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mckenney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,437.16,669.44,102.63,7.17;5,330.24,678.32,128.39,7.17">LAPACK Users&apos; Guide. Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
	<note>third edition</note>
</biblStruct>

<biblStruct coords="5,330.24,696.68,209.67,7.17;5,330.24,705.56,209.71,7.17;5,330.24,714.56,34.75,7.17" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m" coord="5,514.80,696.68,25.11,7.17;5,330.24,705.56,67.67,7.17">Modern Information Retrieval</title>
		<imprint>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.24,497.24,209.53,7.17;6,90.24,506.12,209.59,7.17;6,90.24,515.12,70.03,7.17" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,259.44,497.24,40.33,7.17;6,90.24,506.12,147.78,7.17">Using linear algebra for intelligent information retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>O'brien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,252.12,506.12,44.21,7.17">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="575" to="595" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.24,524.36,209.71,7.17" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rohde</surname></persName>
		</author>
		<ptr target="http://tedlab.mit.edu/dr/svdlibc/" />
		<imprint>
			<date type="published" when="2010-07">July 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.24,533.72,209.71,7.17;6,90.24,542.60,209.65,7.17;6,90.24,551.60,209.47,7.17;6,90.24,560.60,70.03,7.17" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,173.88,542.60,126.01,7.17;6,90.24,551.60,7.79,7.17">Indexing by Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,107.76,551.60,188.70,7.17">Journal of the American Society of Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.24,569.84,209.71,7.17;6,90.24,578.84,209.57,7.17;6,90.24,587.84,209.65,7.17;6,90.24,596.72,88.15,7.17" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<title level="m" coord="6,138.24,569.84,107.62,7.17;6,114.00,578.84,185.81,7.17;6,90.24,587.84,209.65,7.17;6,90.24,596.72,10.40,7.17">The First Text REtrieval Conference (TREC1), National Institute of Standards and Technology Special Publication 500-207</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Harmon</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="137" to="152" />
		</imprint>
	</monogr>
	<note>LSI meets TREC: A status report</note>
</biblStruct>

<biblStruct coords="6,90.24,606.08,209.71,7.17;6,90.24,614.96,209.46,7.17;6,90.24,623.96,209.57,7.17;6,90.24,632.96,142.75,7.17" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,145.56,606.08,150.25,7.17">Latent semantic indexing (LSI) and TREC-2</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,169.20,614.96,130.50,7.17;6,90.24,623.96,209.57,7.17;6,90.24,632.96,64.80,7.17">The Second Text REtrieval Conference (TREC2), National Institute of Standards and Technology Special Publication 500-215</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Harmon</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.24,660.44,209.57,7.17;6,90.24,669.44,209.65,7.17;6,90.24,678.44,209.83,7.17;6,90.24,687.32,199.15,7.17" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,195.96,660.44,103.86,7.17;6,90.24,669.44,166.98,7.17">Taking a new look at the latent semantic analysis approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Jessup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,274.32,669.44,25.57,7.17;6,90.24,678.44,95.39,7.17">Computational Information Retrieval</title>
		<meeting><address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="121" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.24,696.68,209.54,7.17;6,90.24,705.56,209.46,7.17;6,90.24,714.56,109.87,7.17" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,144.48,696.68,155.31,7.17;6,90.24,705.56,12.26,7.17">Essential dimensions of latent semantic indexing (lsi)</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kontostathis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,109.80,705.56,189.90,7.17;6,90.24,714.56,85.67,7.17">Proceedings of the 40th Hawaii International Conference on System Sciences -2007</title>
		<meeting>the 40th Hawaii International Conference on System Sciences -2007</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.24,497.24,209.65,7.17;6,330.24,506.12,209.79,7.17;6,330.24,515.12,209.59,7.17;6,330.24,524.12,209.62,7.17;6,330.24,533.12,100.03,7.17" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,523.20,497.24,16.69,7.17;6,330.24,506.12,189.40,7.17">Identification of critical values in latent semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kontostathis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">M</forename><surname>Pottenger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,330.24,524.12,184.36,7.17">Foundations of Data Mining and Knowledge Discovery</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Ohsuga</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Liau</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Tsumoto</surname></persName>
		</editor>
		<imprint>
			<publisher>Spring-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="333" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.24,542.00,209.34,7.17;6,330.24,551.00,209.65,7.17;6,330.24,560.00,59.35,7.17" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,434.64,542.00,104.94,7.17;6,330.24,551.00,102.46,7.17">Large-scale information retrieval with Latent Semantic Indexing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Letsche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,443.52,551.00,67.76,7.17">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="105" to="137" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.24,569.00,209.47,7.17;6,330.24,577.88,209.46,7.17;6,330.24,586.88,209.65,7.17;6,330.24,595.88,13.87,7.17" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,416.16,569.00,120.74,7.17">Experiments using the Lemur toolkit</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,340.20,577.88,160.79,7.17">The Tenth Text REtrieval Conference (TREC</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="500" to="207" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology Special Publication</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.24,604.76,209.67,7.17;6,330.24,613.76,209.47,7.17;6,330.24,622.76,17.83,7.17" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,436.56,604.76,103.35,7.17;6,330.24,613.76,75.19,7.17">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,414.72,613.76,68.49,7.17">Inf. Process Manage</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.24,631.76,162.19,7.17" xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Smart</surname></persName>
		</author>
		<ptr target="ftp://ftp.cs.cornell.edu/pub/smart/" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
