<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.36,82.36,282.52,14.42">ICTNET at Web Track 2010 Ad-hoc Task</title>
				<funder ref="#_TBbTtGg #_DNRQKpT #_DqP2q4a">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder ref="#_jgwNqEA">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">NIST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.06,107.70,29.84,9.02"><forename type="first">Xu</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.97,107.70,40.90,9.02"><forename type="first">Zeying</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.92,107.70,45.58,9.02"><forename type="first">Jianguo</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.52,107.70,43.22,9.02"><forename type="first">Xiaoming</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.80,107.70,23.65,9.02"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.67,107.70,39.01,9.02"><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.91,107.70,43.03,9.02"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.36,82.36,282.52,14.42">ICTNET at Web Track 2010 Ad-hoc Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CE9BAA5321407B13CEE9A1F27FB44C17</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, our team -"ICTNET", participated in the ad-hoc task of Web Track of TREC 2010.</p><p>The full Category A dataset was used. The sliding window BM25 model was extended from last year's method, combining with link analysis to rank the final results. All the methods having been tried in our experiments are delineated, and the evaluation results from the organizers of Web Track are presented thereafter.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Ad-hoc task in TREC investigates the performance of systems that search a static set of documents using previously-unseen topics. The goal of the task is to return a ranking of the documents in the collection in the order of decreasing probability of relevance <ref type="bibr" coords="1,360.78,308.41,7.62,5.83">[1]</ref> . The probability of relevance of a document is considered independently of other documents that appear before it in the result list. Ad-hoc task focuses on document relevance. The results will be assessed mainly by ERR, precision, NDCG as well as MAP. This year, ClueWeb09 dataset <ref type="bibr" coords="1,237.66,378.61,7.62,5.83">[2]</ref> is continued to use. In our system, the full Category A which consists of around 500 million English pages is used. The amount of data is a real challenge for our data processing capability.</p><p>In section 2, data preparation steps are described. Section 3 gives the description of the retrieval methods for different fields that was used in experiments. Our ranking methods combined various scores from different fields are given in section4. Section 5 gives the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data Preparation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) System</head><p>We used Firtex <ref type="bibr" coords="1,174.00,534.61,7.62,5.83">[3]</ref> , an open source, high performance distributed search platform developed by our lab in recent years. Firtex was deployed over 10 servers, each of which has 8 CPU cores, 16GB memory and 1.4TB hard disk. A Python search frontend for servers and a Python client were also developed. While performing search, the client sends the query to all ten servers, and servers scan through their part of data, rank their local results and then return them to the client in an asynchronous manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Content Extraction</head><p>The content from all pages were extracted before the indexing was performed. At the beginning, some useless part of the pages were tried to be expurgated, for example, advertisements and navigation columns. But it was found that there are great varieties among the dataset. On one hand, it was hard to define uselessness; on the other hand, it is almost impossible to find a general expurgation method for all pages, many of which fail to obey the HTML standard. Thus, we simply extracted title, links, anchors and all visible text as content. Also the keywords in the metadata parts are also extracted for later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Indexing</head><p>After titles, keywords and contents had been extracted, these fields were indexed into inverse index by Firtex. It took about eight hours to index all Category A data onto ten machines, and each of them had 120GB of data. When a query is submitted, it takes approximately 30 seconds to fetch all results from the servers by the client.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Link Analysis</head><p>After extracting links and anchors from all pages, link analysis and anchor texts extraction were performed. These were computed in a map-reduce way. Anchor texts were merged and duplicates of every URL were eliminated because a large amount of anchor texts are meaningless for ad-hoc retrieval, such as "Home", "About", etc.</p><p>Having the in-links and out-links, PageRank <ref type="bibr" coords="2,294.60,261.61,7.62,5.83" target="#b0">[4]</ref> values were calculated for all pages. The classic PageRank algorithm was run until convergence was reached. It was noticed that many pages in the dataset do not have in-link while some others have thousands. This leads to great imbalance among the PageRank values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Retrieval Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Sliding Window BM25</head><p>The most commonly used retrieval model is BM25 <ref type="bibr" coords="2,339.12,370.81,7.62,5.83" target="#b1">[5]</ref> , based on the probabilistic retrieval framework developed in the 1970s and 1980s. This method has been the baseline for retrieval methods. The basic equation is:</p><formula xml:id="formula_0" coords="2,146.94,425.60,334.80,35.44">1 1 ( , ) ( 1) ( ) 0.5 25( , ) log | | ( ) 0.5 ( , )<label>(1 )</label></formula><formula xml:id="formula_1" coords="2,126.42,421.74,361.42,46.51">q Q f q D k N df q BM Q D D df q f q D k b b avgdl ∈ • + - + = • + + • -+ • ∑ ,</formula><p>where Q is query containing term q; f(q,D) is the term frequency of q in document D; |D| is the length of D; avgdl is the average length of total N documents; df(q) is the document frequency of q; k1 and b are parameters.</p><p>One problem of BM25 model is that term proximity is not taken into account. In last year's ad-hoc task, we proposed the minimum window BM25 <ref type="bibr" coords="2,315.06,550.21,7.62,5.83" target="#b2">[6]</ref> , in which the basic idea is that if all terms of a query appear in a smaller area, the document is more likely to be relevant, and should receive a higher rank. In this method, documents are ranked as following: 25( ) 25 ( , ) , log( 1)</p><formula xml:id="formula_2" coords="2,120.60,593.34,356.27,44.62">w window con Q ent q t f boost BM q BM Q Doc w MAXWINDOW w ∈ × × = ≤ + ∑ .</formula><p>where Q is a query containing terms q; DOC content is the content of a document; BM25(q) is the BM25 score of query term q; w is the minimum window size that containing all query terms; MAXWINDOW is the upper limit of w; f w is the frequent of different minimum window in DOC content ; boost is the weight of Q. A fixed threshold MAXWINDOW was defined to govern how long the distance between query words appeared in a document could be tolerated. If one document contains more windows which cover the query words, and if the windows' size is relatively smaller, this document could get a higher score.</p><p>The above method alleviates the problem of the original BM25, but still has a drawback: the threshold MAXWINDOW is pre-defined, lacking of flexibility. If the length of one query is too long, this method is not well suited here for a fixed window size may not be big enough to contain all query words. With this consideration, this year an improvement was made to let the MAXWINDOW vary with the length of a query. In fact the MAXWINDOW was calculated as:</p><formula xml:id="formula_3" coords="3,200.82,156.48,207.60,14.76">( ) ( ) MAXWINDOW length Q k length Q = + ×</formula><p>, where length(Q) denotes the number of words of one query, and k is a parameter which can be tuned.</p><p>When performing search, the retriever system moves the window along every document and accumulates the frequencies of different windows whose sizes do not exceed the MAXWINDOW.</p><p>This method was used in the content field, because a large amount of pages have a long content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Search with Titles</head><p>Usually the title of a web page is a short and compact description of the content. If the title closely relates to the query, this page may be well relevant. Also search the title would not harm the performance too much for the titles' shortness.In the title field, the BM25 model was not employed, but a simple Boolean retriever. The Boolean connective "OR" was used, otherwise for some long queries, there may be too few documents found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Search with Keywords</head><p>Here keywords are extracted from meta-data parts of a page, which usually have the form as:</p><p>&lt;META content="Template 59 Business/General Business Templates General Web Templates Sharp Business Template Sharp Simple design with warm colors neat navigation" name="Keywords"&gt;.</p><p>This part is used to do search engine optimization, so it often gives fine abstract of the page.</p><p>These keywords are generally longer than title, so they were considered to better reveal the intention of the content.In this part, the original BM25 model was used, because keywords are not as long as contents, and there is no need to use sliding window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Ranking</head><p>The different scores from different fields, the PageRank value and spamming were combined together to get the final ranker. The combined ranking function is in the following form: Dataset <ref type="bibr" coords="3,122.46,659.41,7.62,5.83">[7]</ref> and I is indicator function.</p><formula xml:id="formula_4" coords="3,187.62,604.49,242.33,12.86">1 ( , ) [<label>( , ) ( )] ( ( ) 50)</label></formula><p>The S fields (Q,D) in the right hand side of the above equation is the score of the combination of the three fields. The content, title and keyword fields were combined by simply using an "AND" connective in the Firtex retriever. Actually, the retriever would sum up the scores calculated for each fields with the methods mentioned in the previous section. Different weights for each field could also be assigned, thus the score is computed like this:</p><formula xml:id="formula_5" coords="4,120.84,84.01,324.04,11.52">1 2 3 ( , )<label>25 ( , ) ( , ) 25( ,</label></formula><p>)</p><formula xml:id="formula_6" coords="4,102.48,80.12,382.01,15.41">fields window content bool title keyword S Q D BM Q DOC Sim Q DOC BM Q DOC ω ω ω = + +</formula><p>, where BM25 window , Sim bool and BM25 denote the sliding window BM25, the simple Boolean model and the original BM25 model respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>We submitted three runs. The first run, ICTNETAD10R1, used sliding window BM25 to model the content of document, meaning that the parameters ω 1 and ω 2 were set to zero in S fields . The second run, ICTNETAD10R2, added title field and keyword field as described above. PageRank values were not combined in the first two runs. The third run submitted, ICTNETAD10R3, used sliding windows BM25 in the content field as the first run, and re-ranked the results by combining their PageRank values. All runs were anti-spammed by the Waterloo Spam Rankings.All runs were evaluated by NDCG@20, ERR@20, P@10, P@20 and MAP.The results are listed in Table <ref type="table" coords="4,403.49,263.70,3.75,9.02" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, our methods used in ad-hoc task of the TREC 2010 Web Track were described. We demonstrated our steps of system and data preparation, the way we modeled the document and query, and our ranking method.It is noticed from the results in Table <ref type="table" coords="4,341.00,453.42,5.01,9.02" target="#tab_0">1</ref> and Table <ref type="table" coords="4,390.75,453.42,5.01,9.02">2</ref> that, the first run using the simplest method is the best while the third run with PageRank the worst. Adding extra fields in the second didn't help. Maybe because simple is beauty.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,241.62,611.27,15.04,6.07;3,316.53,611.27,8.52,6.07;3,368.43,611.27,14.67,6.07;3,180.48,604.81,33.48,10.51;3,233.94,604.81,6.03,10.51;3,262.14,604.81,22.38,10.51;3,309.95,604.81,6.03,10.51;3,331.19,604.81,36.80,10.51;3,389.15,604.81,8.70,10.51;3,299.82,599.92,6.60,15.59;3,220.98,600.61,6.60,14.75;3,290.81,600.61,6.60,14.75;3,404.92,600.61,6.60,14.75;3,431.52,607.21,2.00,7.18;3,90.00,630.30,307.56,9.74;3,399.60,630.30,105.73,9.02;3,90.00,645.90,415.34,9.74"><head></head><label></label><figDesc>(D) is the log smoothed PageRank value of the document D; β 1 is a weight for PageRank value; S spam (D) denotes the spamming weight in the Waterloo Spam Rankings for the ClueWeb09</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,106.80,288.19,388.45,95.02"><head>Table 1 :</head><label>1</label><figDesc>Evaluation Results</figDesc><table coords="4,106.80,288.19,388.45,71.08"><row><cell>Run</cell><cell>Relevant</cell><cell>ERR@20</cell><cell>NDCG@20</cell><cell>P@10</cell><cell>P@20</cell><cell>MAP</cell></row><row><cell></cell><cell>Retrieved</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ICTNETAD10R1</cell><cell>1677</cell><cell>0.1015</cell><cell>0.1799</cell><cell>0.3750</cell><cell>0.3736</cell><cell>0.0932</cell></row><row><cell>ICTNETAD10R2</cell><cell>1143</cell><cell>0.0964</cell><cell>0.1473</cell><cell>0.3028</cell><cell>0.2944</cell><cell>0.0552</cell></row><row><cell>ICTNETAD10R3</cell><cell>1153</cell><cell>0.0662</cell><cell>0.1089</cell><cell>0.2139</cell><cell>0.2097</cell><cell>0.0374</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank all the organizers of <rs type="institution">TREC Web Track</rs> and <rs type="funder">NIST</rs>. We appreciate the efforts of all assessors for judging the runs. This work is supported by <rs type="funder">NSF of China</rs> Grants No. <rs type="grantNumber">60933005</rs>, No. <rs type="grantNumber">60903139</rs> and No. <rs type="grantNumber">60873245</rs>, and also by "<rs type="programName">863" Program of China</rs> Grant No. <rs type="grantNumber">2006AA010105-02</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_TBbTtGg">
					<idno type="grant-number">60933005</idno>
				</org>
				<org type="funding" xml:id="_DNRQKpT">
					<idno type="grant-number">60903139</idno>
				</org>
				<org type="funding" xml:id="_DqP2q4a">
					<idno type="grant-number">60873245</idno>
					<orgName type="program" subtype="full">863&quot; Program of China</orgName>
				</org>
				<org type="funding" xml:id="_jgwNqEA">
					<idno type="grant-number">2006AA010105-02</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,102.03,656.83,403.32,7.18;4,102.00,672.43,189.78,7.18" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,270.08,656.83,197.34,7.18">The PageRank Citation Ranking: Bringing Order to the Web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Digital Library Technologies Project</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="4,101.72,688.03,403.64,7.18;4,102.00,703.63,206.99,7.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,354.13,688.03,55.10,7.18">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,424.83,688.03,80.53,7.18;4,102.00,703.63,84.09,7.18">Proceedings of the Third Text REtrieval Conference</title>
		<meeting>the Third Text REtrieval Conference<address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,102.52,719.23,402.72,7.18;4,102.00,734.83,281.46,7.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,287.16,719.23,139.64,7.18">ICTNET at Web Track 2009 Ad-hoc Task</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,443.30,719.23,61.95,7.18;4,102.00,734.83,120.59,7.18">Proceedings of the Eighteenth Text REtrieval Conference</title>
		<meeting>the Eighteenth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">November 17-20, 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
