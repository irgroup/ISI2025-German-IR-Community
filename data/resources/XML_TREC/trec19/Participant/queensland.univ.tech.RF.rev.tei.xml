<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,57.84,107.03,479.55,12.90;1,268.30,124.97,58.62,12.90;1,128.52,140.56,338.19,10.75">Mining Specific and General Features in Both Positive and Negative Relevance Feedback QUT E-Discovery Lab at the TREC&apos;10 Relevance Feedback Track</title>
				<funder ref="#_2GbPQnJ">
					<orgName type="full">Australian Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.58,178.89,104.59,10.37"><forename type="first">Abdulmohsen</forename><surname>Algarni</surname></persName>
							<email>a1.algarni@qut.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Discipline</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,293.09,178.89,51.90,10.37"><forename type="first">Yuefeng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Discipline</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.52,178.89,56.98,10.37"><forename type="first">Xiaohui</forename><surname>Tao</surname></persName>
							<email>x.tao@qut.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Discipline</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,57.84,107.03,479.55,12.90;1,268.30,124.97,58.62,12.90;1,128.52,140.56,338.19,10.75">Mining Specific and General Features in Both Positive and Negative Relevance Feedback QUT E-Discovery Lab at the TREC&apos;10 Relevance Feedback Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">948FECFEE6E845061BA8F38C18C04208</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>User relevance feedback is usually utilized by Web systems to interpret user information needs and retrieve effective results for users. However, how to discover useful knowledge in user relevance feedback and how to wisely use the discovered knowledge are two critical problems. However, understanding what makes an individual document good or bad for feedback can lead to the solution of the previous problem. In TREC 2010, we participated in the Relevance Feedback Track and experimented two models for extracting pseudo-relevance feedback to improve the ranking of retrieved documents. The first one, the main run, was a pattern-based model, whereas the second one, the optional run, was a term-based model. The two models consisted of two stages: one using relevance feedback provided by TREC'10 to expand queries to extract pseudo-relevance feedback; one using pseudo-relevance feedback to find useful patterns and terms according to their relevance and irrelevance judgements to rank documents. In this paper, the detailed description of those models is presented.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Web users' personal interests and preferences can be drawn in their user profiles. In Web information gathering, user profiles are used by many works to search information for users according to their personal needs <ref type="bibr" coords="1,247.73,596.92,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="1,260.25,596.92,7.19,8.64" target="#b7">8]</ref>. To acquire user profiles, some techniques explicitly interview users <ref type="bibr" coords="1,73.88,620.83,15.49,8.64" target="#b15">[16]</ref>; some use user relevance feedback <ref type="bibr" coords="1,237.98,620.83,15.27,8.64" target="#b20">[21]</ref>. These mechanisms require user-effort in the user profile acquisition process. Attempting to release such burden from users, alternatively some automatic techniques have been developed to acquire user profiles from a collection of user personal information, for example, browsing history <ref type="bibr" coords="1,257.51,680.60,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="1,270.59,680.60,11.83,8.64" target="#b24">25]</ref>. User profiles acquired by such techniques, however, usually contain noise and uncertainties. Hence, a method to acquire user profiles effectively and efficiently (without the burden of user-effort) is an urgent need for personalized Web information gathering.</p><p>Relevance feedback has been used widely in the area of information retrieval. It has been reported effective when applying to different kinds of retrieval models <ref type="bibr" coords="1,504.83,309.93,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="1,517.91,309.93,12.45,8.64" target="#b18">19,</ref><ref type="bibr" coords="1,532.66,309.93,12.45,8.64" target="#b19">20,</ref><ref type="bibr" coords="1,308.86,321.89,12.45,8.64" target="#b21">22,</ref><ref type="bibr" coords="1,323.41,321.89,11.83,8.64" target="#b32">33]</ref>. The idea of relevance feedback is to involve the user in the retrieval process in order to improve the final result set. Some retrieval models also used pseudo relevance feedback <ref type="bibr" coords="1,347.86,357.75,15.77,8.64" target="#b12">[13,</ref><ref type="bibr" coords="1,365.28,357.75,13.28,8.64" target="#b13">14]</ref> especially when there were no relevance judgements available. In such models a small number of top-ranked documents in the initial retrieval results are assumed relevant, and then relevance feedback is applied <ref type="bibr" coords="1,530.02,393.62,10.58,8.64" target="#b5">[6]</ref>.</p><p>The popular term-based IR models include the Rocchio algorithm <ref type="bibr" coords="1,349.64,417.56,11.62,8.64" target="#b3">[4,</ref><ref type="bibr" coords="1,361.26,417.56,11.62,8.64" target="#b18">19]</ref>, probabilistic models, Okapi BM25 <ref type="bibr" coords="1,518.01,417.56,11.62,8.64" target="#b4">[5,</ref><ref type="bibr" coords="1,529.62,417.56,11.62,8.64" target="#b17">18]</ref>, and language models including model-based methods and relevance models <ref type="bibr" coords="1,383.28,441.47,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="1,396.36,441.47,12.45,8.64" target="#b14">15,</ref><ref type="bibr" coords="1,411.11,441.47,12.45,8.64" target="#b16">17,</ref><ref type="bibr" coords="1,425.85,441.47,12.45,8.64" target="#b30">31,</ref><ref type="bibr" coords="1,440.60,441.47,11.83,8.64" target="#b32">33]</ref>. Generally speaking, in the vector space model, terms have been extracted from feedback by using the Rocchio algorithm. Those terms are used to form a new query vector by maximizing its similarity to relevant documents and minimizing its similarity to non-relevant documents <ref type="bibr" coords="1,417.61,501.25,15.27,8.64" target="#b18">[19]</ref>. In the language modelling approaches, the key elements are the probabilities of word sequences including both words and phrases (or sentences). They are often approximated by n-gram models <ref type="bibr" coords="1,504.77,537.11,15.27,8.64" target="#b26">[27]</ref>, such as Unigram, Bigram or Trigram, for considering term dependencies.</p><p>IR models are the basis of ranking algorithm used in search engines to rank documents according to their relevance to a given query <ref type="bibr" coords="1,411.45,596.92,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="1,424.38,596.92,11.83,8.64" target="#b31">32]</ref>. Over the years, patternbased approaches have been expected to outperform termbased techniques when discovering relevance features. Patterns are more discriminative and carry more "semantics". However, according to information retrieval (IR) experiments, few significant improvements have been achieved by using pattern-based methods to replace term-based methods <ref type="bibr" coords="1,324.65,680.60,15.98,8.64" target="#b22">[23,</ref><ref type="bibr" coords="1,340.63,680.60,11.98,8.64" target="#b23">24]</ref>. When utilizing pattern mining techniques, people encountered two problems: (i) highly frequent patterns are usually general, whereas specific patterns are usually with low frequency (this is because the measuring methods for pattern learning, such as "support" and "confidences", appeared unsuitable in the filtering stage <ref type="bibr" coords="2,217.05,99.39,10.62,8.64" target="#b8">[9]</ref>); (ii) negative user feedback is difficult to use when revising the features extracted from positive user feedback. Relevance feature discovery is challenging <ref type="bibr" coords="2,149.15,135.25,10.58,8.64" target="#b7">[8]</ref>.</p><p>A promising model, Relevance Feature Discovery (RFD), has been proposed by <ref type="bibr" coords="2,177.18,159.34,16.60,8.64" target="#b9">[10]</ref> for information filtering (IF) within the data mining community. The model has shown encouraging improvements of IF effectiveness. Closed sequential patterns were discovered in positive text documents, where a pattern was a set of terms that frequently appeared in a paragraph. The deployed method was applied to the extracted patterns to overcome the low frequency problem. Based on the positive features some negative documents were selected (called offenders) that were closed to the extracted features in the positive documents. The features were extracted from selected negative documents used for groups. Low-level features (terms) were devised based on both their appearances in the higher-level features (patterns) and their categories <ref type="bibr" coords="2,208.98,314.75,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="2,221.57,314.75,11.83,8.64" target="#b9">10]</ref>. The objective of relevance feature discovery is to find useful features available in a training set, including both positive and negative documents, to describe what users want. This is a particularly challenging task in modern information analysis, from both an empirical and a theoretical perspective <ref type="bibr" coords="2,258.76,374.53,10.79,8.64" target="#b7">[8,</ref><ref type="bibr" coords="2,270.59,374.53,11.83,8.64" target="#b10">11]</ref>. Motivated by these challenges, we proposed a relevance feature discovery model, and tested the model in the Relevance Feedback Track in TREC 2010. This Relevance Feedback track was designed to to investigate what makes an individual document good or bad for feedback.</p><p>The remainder of this paper is organized as follows. Section 2 presents an overview of the Relevance Feedback Track in TREC'10. Section 3 reviews the concepts of Rocchio and cosine similarity. The query expansion based on TREC provided feedback and Rocchio model are discussed in Section 4. Section 5 reviews the concept of patterns in text documents and a detailed reviews of Relevance Feature Discovery (RFD) model. Section 6 describes the optional run based on Rocchio model and pseudo-feedback. After that, the final retrieved results are discussed in Section 7, and the last section makes conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Model</head><p>In response to a query, the first stage is to automatically retrieve a list of documents from the ClubWeb09 Category-B and rank them based on their similarity to the query. The key issue here is how to acquire user interest from limited information. In TREC'10 most of the queries have a limited number of terms, whereas the ClubWeb09 Category-B dataset has a large number of documents. Expanding the query at this stage without any feedback from the user could misleading. For example, there is many versions of interpretation that can be learned from a keyword "toilet" (e.g, toilet paper , toilet design, toilet suites, caroma toilet,...etc.). However, it is difficult to determine which one reflects the user's information need.</p><p>Based on that observation, we developed a model to work as follows:</p><p>1. Given a topic, 15000 relevant documents were extracted using Rocchio and cosine similarity via content search. The top 2500 documents were submitted as the base run results;</p><p>2. Using the highly frequent terms extracted from the user feedback (provided by TREC'10) to expand queries using Rocchio. The 15000 documents were re-ranked again using cosine similarity method;</p><p>3. The top 10 documents were selected as the positive feedback and the bottom 10 as negative. These pseudorelevance feedback were used to update user profiles in two different runs.</p><p>-Main run: The pseudo-relevance feedback went into the RFD model to generate three feature sets (the positive, specific terms, general terms, and negative, specific terms). The three feature sets were used to re-index the 15000 documents.</p><p>-Optional run: The Rocchio was used to build user profiles from pseudo-relevance feedback; then used the feedback to re-index the 15000 documents.</p><p>4. The top 2500 ranked documents were submitted as the final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Rocchio and Cosine Similarity</head><p>In the vector space model all queries and documents are represented as vectors in |V |-dimensional space, whereV is the set of all distinct terms in the collection. Restricted by a fixed similarity metric, documents with similar content have similar vectors. However, the similarity of a document d to a query q is measured based on the terminological overlap between the query and the document. Thus, those relatively rare terms have a comparatively high weight. The documents are ranked by the magnitude of the angle between the document vector and the query vector.</p><p>The core of vector space model is cosinemeasure that measures the angle between two vectors. The cosine between two vectors is determined as the dot product between each document vector -→ d and the query vector -→ q , normalized by the lengths of the document and the query. The main function of cosine similarity can be generalized as follow:</p><formula xml:id="formula_0" coords="3,119.89,91.94,95.50,31.87">cosine(q, d) = - → q . - → d | - → q || - → d |</formula><p>The vector space model does not specify how to set the document term weight and the query term weight, but in practice these weights are often calculated using their collection frequency and within-document frequency:</p><formula xml:id="formula_1" coords="3,130.37,191.13,155.99,23.23">w q,t = ln(1 + N f t )<label>(1)</label></formula><formula xml:id="formula_2" coords="3,128.54,225.09,157.82,9.65">w d,t = 1 + ln(f d,t )<label>(2)</label></formula><p>In vector space model each document d is represented as a vector</p><formula xml:id="formula_3" coords="3,97.15,249.85,59.07,16.57">- → d = (d, ,d n ).</formula><p>According to a fixed similarity metric, documents with similar content have similar vectors. Each element d n is represented by a set for terms T = {t 0 , t 1 , ,t i }. The termset T of a document d is calculated as a combination of the statistics T F (t i ; d) and DF (t i ).</p><p>The termf requency T F (t i ; d) is the number of terms t i occurred in the document d; the documentf requency IDF (t i ) is the number of documents with term t i occurred at least once <ref type="bibr" coords="3,101.85,352.73,10.58,8.64" target="#b3">[4]</ref>.</p><p>Since the query length is constant for the evaluation of a single query, we can ignore this factor, while preserving ranking order. Bringing Equations 1 and 2 into the cosine measure, we have:</p><formula xml:id="formula_4" coords="3,55.32,419.42,224.63,44.45">cosine(q, d) rank = t∈q∩d (ln(1 + N ft ) × (1 + ln(f d,t ))) t∈d (1 + ln(f d,t )) 2</formula><p>(3) Similarity score have been calculated for all documents in ClubWeb09 dataset Category-B against queries using Eq. 3. The weight of each term t in a query q is set to 1 after text pre-processing include steaming and stopword removal. As a result, Eq. 3 can be re-generalized as:</p><formula xml:id="formula_5" coords="3,95.55,547.91,144.17,31.72">cosine(q, d) rank = t∈q∩d (1 × f d,t ) |f d,t |</formula><p>The final result of this step is a ranked list of all documents with their weights. The top 2500 documents were selected as a result of the base run; the top 15000 documents were used as an input of the next stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Query Expansion</head><p>The main goal of query expansion is to optimize a query. A query is optimal if it ranks all relevant documents on top of those non-relevant. A query could lead to a good ranking result if it contains all features in relevant documents and disregards all features in non-relevant documents. However, the reformulation of an optimal query is difficult. The Rocchio algorithm <ref type="bibr" coords="3,386.61,248.28,16.60,8.64" target="#b18">[19]</ref> has been widely adopted when using relevant documents (D + ) and non-relevant documents (D -) to reformulate an initial query q:</p><formula xml:id="formula_6" coords="3,308.86,290.41,236.25,46.59">- → q = γ × - → q + α 1 |D + | - → d ∈D + - → d || - → d || -β 1 |D -| - → d ∈D - - → d || - → d || (4)</formula><p>where α = β = γ = 1.0 in this presented work as suggested by <ref type="bibr" coords="3,349.26,352.28,15.27,8.64" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Query Expansion with Given Feedback</head><p>Relevance feedback requires a user to classify documents into groups of relevant or non-relevant. Relevance feedback has been used widely in information retrieval. It has been reported effective in many IR models <ref type="bibr" coords="3,505.38,455.23,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="3,518.19,455.23,12.45,8.64" target="#b18">19,</ref><ref type="bibr" coords="3,532.66,455.23,12.45,8.64" target="#b19">20,</ref><ref type="bibr" coords="3,308.86,467.19,12.45,8.64" target="#b21">22,</ref><ref type="bibr" coords="3,322.97,467.19,11.83,8.64" target="#b32">33]</ref>. The feedback is used to expand queries and make better ranking of documents.</p><p>In TREC'10, with the main goal of understanding what makes an individual document good or bad for feedback, we used only one document explicitly provided by the user (NIST) to expand query -→ q . Thus, Eq. 4 can be simplified:</p><formula xml:id="formula_7" coords="3,366.00,546.08,120.77,36.48">- → q = γ × - → q + α - → d ∈D + - → d || - → d ||</formula><p>The updated query -→ q was used to re -rank the 15000 documents retrieved in Section 3. The top 10 weighted documents were selected as pseudo positive feedback D + ; the lowest 10 ranked documents were selected as pseudo negative feedback D -. They were used to expand the query again to re-rank the documents. In TREC'10 we provided two runs: the main run using the Relevance Feature Discovery (RFD) model, and the optional run using the Rocchio model (see Eq. 4). More details are provided in the following sections. For a given topic, the RFD model extracts from a document set a set of features, including patterns and terms, and assigns them weights. The document set, usually called a training set and denoted as D, consists of a set of positive documents (D + ) and a set of negative documents (D -). When splitting a document into paragraphs, a document d can also be represented by a set of paragraphs P S(d).</p><p>Let T = {t 1 , t 2 , . . . , t m } be a set of terms extracted from D + ; X be a set of terms (called a termset) in document d. coverset(X) denotes the covering set of X for d, which includes all paragraphs dp ∈ P S(d) where X ⊆ dp, i.e., coverset(X) = {dp|dp ∈ P S(d), X ⊆ dp}. The absolute support of X is the number of occurrences of X in P S(d): sup a (X) = |coverset(X)|. The relative support of X is the fraction of the paragraphs that contain the pattern:</p><formula xml:id="formula_8" coords="4,71.97,558.31,100.00,14.38">sup r (X) = |coverset(X)| |P S(d)|</formula><p>. A termset X is then called a frequent pattern if its sup a (or sup r ) ≥ min sup, a minimum support.</p><p>Given a set of paragraphs Y ⊆ P S(d), we can also define its termset, which satisfies</p><formula xml:id="formula_9" coords="4,88.16,630.53,160.16,8.74">termset(Y ) = {t|∀dp ∈ Y ⇒ t ∈ dp}.</formula><p>By defining the closure of X as:</p><formula xml:id="formula_10" coords="4,50.11,671.67,236.25,41.26">Cls(X) = termset(coverset(X)) a pattern (or termset) X is closed if and only if X = Cls(X).</formula><p>Let X be a closed pattern. We have</p><formula xml:id="formula_11" coords="4,381.51,98.25,163.60,9.65">sup a (X 1 ) &lt; sup a (X)<label>(5)</label></formula><p>for all patterns X 1 ⊃ X.</p><p>A taxonomy can be constructed by using closed patterns with is-a (or subset) relations. A sequential pattern s =&lt; t 1 , . . . , t r &gt; (t i ∈ T ) is an ordered list of terms. Denoted by s 1 s 2 , a sequence s 1 =&lt; x 1 , . . . , x i &gt; is a sub-sequence of s 2 =&lt; y 1 , . . . , y j &gt;, iff ∃j 1 , . . . , j i such that 1 ≤ j 1 &lt; j 2 . . . &lt; j i ≤ j and x 1 = y j1 , x 2 = y j2 , . . . , x i = y ji . Given s 1 s 2 , we call s 1 a sub-pattern of s 2 , and s 2 a super-pattern of s 1 . To simplify the explanation, we refer to sequential patterns as patterns.</p><p>As the same as those defined for normal patterns, we define the absolute support and relative support for a pattern (an ordered termset) X in d. We also denote the covering set of X as coverset(X), which includes all paragraphs ps ∈ P S(d) such that X ps, i.e., coverset(X) = {ps|ps ∈ P S(d), X ps}. X is then called a frequent pattern if sup r (X) ≥ min sup. By using Eq. ( <ref type="formula" coords="4,491.03,434.83,3.53,8.64" target="#formula_11">5</ref>), a frequent sequential pattern X is closed if any super-pattern X 1 of X such that sup a (X 1 ) = sup a (X).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Deploying High-Level Patterns on Low-Level Terms</head><p>To overcome the problem of patterns with lowfrequency, a method has been developed to deploy high level patterns over low-level terms. The evaluation of term supports (weights) in this paper is different from that in term-based approaches. For a term-based approach, the value of a term is scaled based on its appearance in documents. In our method, the value of terms are scaled based on their appearance in discovered patterns.</p><p>To improve the efficiency of the pattern taxonomy mining (PTM), an algorithm, SPMining(D + , min sup), was introduced by <ref type="bibr" coords="4,367.71,644.15,16.60,8.64" target="#b28">[29]</ref> and further developed in <ref type="bibr" coords="4,489.79,644.15,10.79,8.64" target="#b8">[9,</ref><ref type="bibr" coords="4,502.31,644.15,13.28,8.64" target="#b29">30]</ref> to find closed sequential patterns from positive documents D + . The SPMining algorithm used the well-known Apriori property to narrow down the searching space.</p><p>Let SP 1 , SP 2 , ..., SP n be the sets of discovered closed sequential patterns for all documents</p><formula xml:id="formula_12" coords="4,473.86,702.62,71.26,11.23">d i ∈ D + (i = 1, • • • , n), where n = |D + |.</formula><p>For a given term t, its weight in discovered patterns is assigned by:</p><formula xml:id="formula_13" coords="5,93.54,107.25,188.95,30.49">w(t, D + ) = n i=1 t∈p⊆SPi sup r (p, d i ) |p| (<label>6</label></formula><formula xml:id="formula_14" coords="5,282.49,117.99,3.87,8.64">)</formula><p>where |p| is the number of terms in p.</p><p>With weights assigned to the terms in D + , a function can be used to rank and judge the relevance of incoming documents:</p><formula xml:id="formula_15" coords="5,113.75,210.62,108.97,20.06">rank(d) = t∈T w(t)τ (t, d)</formula><p>where w(t) = w(t, D + ); and τ (t, d) = 1 if t ∈ d, otherwise τ (t, d) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Mining Negative Patterns for Revising Low-Level Features</head><p>In general, the concept of relevance is subjective. Normally people can describe the relevance of a topic (or document) in specificity or exhaustivity, where "specificity" describes the extent to which the topic focuses on what users want, and "exhaustivity" describes the extent to which the topic discusses what users want. It is easy for human being to do so. However, it is very difficult to use these concepts for interpreting relevance features in text documents. In this section, we first discuss how to use the concepts for understanding the different roles of the low-level feature terms for answering what users want. We also present the ideas for accurately weighting terms based on their specificity and distributions in the discovered higher level features. In addition, we describe algorithms for both the discovery of higher level features and the revision of weights of low-level terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Specificity of Low-Level Features</head><p>A term's specificity describes the extent of the term to which the topic focuses on what users want. It is very difficult to measure the specificity of terms because a term's specificity depends on users' perspectives for their information needs <ref type="bibr" coords="5,92.50,596.92,15.27,8.64" target="#b27">[28]</ref>. Basically, we can understand the specificity of terms based on their positions in a concept hierarchy. For example, terms are more general if they are in the upper part of the LCSH (Library of Congress Subject Headings) hierarchy; otherwise, they are more specific. However, in many cases, a term's specificity is measured based on what topics we are talking about. For example, "knowledge discovery" will be a general term in data mining community; however it may be a specific term when we talk about information technology.</p><p>In order to understood how terms are grouped into three groups (positive specific terms, general terms and negative specific terms) based on their appearances in a training set. Given a term t ∈ T , its coverage + is the set of positive documents that contain t, and its coverage -is the set of negative documents that contain t. We assume that terms frequently used in both positive documents and negative documents are general terms. Therefore, we want to classify terms that are more frequently used in the positive documents into the positive specific category; and the terms that are more frequently used in the negative documents into the negative specific category.</p><p>Based on the above analysis, we define the specificity of a given term t in the training set D = D + ∪ D -as follows: We present the following classification rules for determining the general terms G, the positive specific terms T + , and the negative specific terms T -:</p><formula xml:id="formula_16" coords="5,308.86,250.87,236.25,55.28">spe(t) = |coverage + (t)| -|coverage -(t)| n where coverage + (t) = {d ∈ D + |t ∈ d}, coverage -(t) = {d ∈ D -|t</formula><formula xml:id="formula_17" coords="5,359.86,379.92,134.26,32.93">G = {t ∈ T |θ 1 ≤ spe(t) ≤ θ 2 }, T + = {t ∈ T |spe(t) &gt; θ 2 },<label>and</label></formula><formula xml:id="formula_18" coords="5,370.09,420.69,113.79,11.72">T -= {t ∈ T |spe(t) &lt; θ 1 }.</formula><p>where θ 2 is an experimental coefficient, the maximum bound of the specificity for the general terms, and θ 1 is also an experimental coefficient, the minimum bound of the specificity for the general terms. We assume that θ 2 &gt; 0 and θ 2 ≥ θ 1 . It is easy to verify that G ∩ T + ∩ T -= ∅. Therefore, {G, T + , T -} is a partition of all terms.</p><p>To describe relevance features for a given topic, normally we believe that specific terms are very useful for the topic in order to distinguish it from other topics. However, many experiments show that using only specific terms is not good enough to improve the performance of RFD because user information needs cannot simply be covered by documents that contain only the specific terms. Therefore, the best way is to use the specific terms mixed with some of the general terms. We will discuss this issue in the evaluation section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Revision of Discovered Features</head><p>In PTM, relevance features are discovered from a set of positive documents. To effectively use both higher level patterns and low-level terms, discovered patterns were deployed on the space of terms in order to evaluate the supports of terms obtained from the patterns.</p><p>Because of many noises in the discovered patterns (an inherent disadvantage of data mining), the evaluated supports are not accurate enough. To improve the effectiveness of PTM, in this paper, we use negative documents in the training set in order to remove the noises. Many people believed that negative documents can be helpful if they are used appropriately. The existing methods can be grouped into two approaches: revising terms that appear in both positive and negative documents; and observing how often terms appear in positive and negative documents. However, how much accuracy improvement can be achieved by using negative feedback still remains an open question.</p><p>There are two major issues for effectively using negative documents. The first one is how to select a suitable set of negative documents because we usually can obtain a very large set of negative samples. For example, a Google search can return millions of documents; however, only a few documents are interesting to a Web user. Obviously, it is not efficient to use all of negative documents. The second issue is how to revise the features discovered in the positive documents accurately.</p><p>In this research, we present an innovative solution for these issues. We firstly show how to select a set of negative samples. We also show the process of the revision.</p><p>If a document's rank (see Eq. ( <ref type="formula" coords="6,187.86,364.36,3.73,8.64">3</ref>)) is less than or equals to zero, this document is clearly negative to the system. If a negative document has a high rank, the document is called an offender <ref type="bibr" coords="6,98.30,400.22,11.62,8.64" target="#b7">[8]</ref> because it forces the system to make a mistake. The offenders are normally defined as the top-K negative documents in a ranked set of negative documents, D -. The basics hypothesis is that the relevance features should be mainly discovered from the positive documents. Therefore, in our experiments, we set K = n 2 , the half of the number of positive documents.</p><p>Once we select the top-K negative documents, the set of negative document D -will be reduced to include only K offenders (negative documents). The next step is to classify terms into three categories, G, T + , and T -, based on D + and the updated D -. We can easily verify that the experimental coefficients θ 1 and θ 2 satisfy the following properties if K = n 2 :</p><formula xml:id="formula_19" coords="6,94.65,577.95,147.17,22.31">0 ≤ θ 2 ≤ 1, and - 1 2 ≤ θ 1 ≤ θ 2 .</formula><p>Now, we show the basic process of revising discovered features in a training set. This process can help readers to understand the proposed strategies for revising weights of low-level terms in different categories.</p><p>Formally, let DP + be the union of all discovered closed sequential patterns in D + , DP -be the union of all discovered closed sequential patterns in D -and T be the set of terms that appear in DP + or DP -, where a closed sequential pattern of D + (or D -) is called a positive pattern (or negative pattern).</p><p>It is obviously that ∃d ∈ D + such that t ∈ d for all t ∈ T + since spe(t) &gt; θ 2 ≥ 0 for all t ∈ T + . Therefore, for each t ∈ T + , it can obtain an initial weight by the deploying method on D + (using the higher level features, see Eq. ( <ref type="formula" coords="6,531.17,123.60,3.48,8.64" target="#formula_2">2</ref>)).</p><p>For the term in (T -∪ G), there are two cases. If ∃d ∈ D + such that t ∈ d, t will get its initial weight by using the deploying method on D + ; otherwise it will get a negative weight by using the deploying methods on D -.</p><p>The initial weights of terms finally are revised according to the following principles: increment the weights of the positive specific terms, decline the weights of the negative specific terms, and do not update the weights of the general terms. The details are described as follows:</p><formula xml:id="formula_20" coords="6,316.43,261.68,214.44,34.83">weight(t) =    w(t) + w(t) × spe(t), if t ∈ T + w(t), if t ∈ G w(t) -|w(t) × spe(t)|, if t ∈ T -</formula><p>where w is the initial weight (or the support in Eq. ( <ref type="formula" coords="6,515.66,309.81,3.48,8.64" target="#formula_2">2</ref>)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Mining and Revision Algorithms</head><p>The process of the revision firstly finds features in the positive documents in the training set, including higher level positive patterns and low-level terms. It then selects top-K negative samples (called offenders) in the training set according to the positive features. It also discovers negative patterns and terms from selected negative documents using the same pattern mining technique that we used for the feature discovery in positive documents. In addition, the process revises the initial features and obtains a revised weight function. To understand this process clearly, we divided this process into two algorithms: HLFMining and NRevision.</p><p>The former finds higher level positive features, selects top-K negative samples, discovers higher level negative features, and composes the set of terms. The latter revise the term weigh function based on the higher level features and the specificity of the terms.</p><p>Algorithm HLFMining describes the details of higher level feature discovery. It takes a training set and a minimum support, min sup. It firstly abstracts patterns, DP + , and then terms, T , in the set of positive documents in step 2 and step 3. It also gives the initial weights (step 4 and 5) to all terms based on their supports in DP + . After that, the algorithm ranks the negative documents in D -(step 6 to step 8), and selects offenders in step 9. Negative patterns and terms are also discovered in step 10 and 11. At last, it gives the initial weights to the terms that only appear in the negative patterns (step 12 and 13), and updates the set of terms (step 14).</p><p>The algorithm calls twice algorithm SP M ining: one for positive documents and one for offenders (a part of Method: negative documents). It also takes times for calculating weights of terms that appear in the discovered patterns, and sorts the negative documents that takes O(mlog m ), where m = |D -|. To compared with the time complexity of algorithm SP M ining, the time of calculating weights spent here can be ignored. Therefore, the time complexity of this algorithm is O(mlog m ) plus the time complexity of SP M ining.</p><formula xml:id="formula_21" coords="7,50.11,381.30,134.31,18.08">1: G = ∅, T + = ∅, T -= ∅, n = |D + |; 2: foreach t ∈ T do { //</formula><p>For a given training set D = {D + , D -}, using HLFMining(D), we can obtain the extracted features &lt; DP + , DP -, T &gt;, and an initial weight function w over T . Given the experimental parameters θ 1 and θ 2 , algorithm NRevision describes the details of revising the weights of the terms based on their specificity and distributions in both positive and negative patterns.</p><p>Step 1 initializes the sets for general terms G, positive specific terms T + , and negative specific terms T -. From step 2 to step 8, the algorithm partitions the terms into three categories. It firstly calculates the specificity for all terms, and then determines positive specific terms, negative specific terms and general terms based on the classification rules defined in Section 5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">User Profiles Using Rocchio and Pseudo</head><p>Relevance Feedback (Optional Run)</p><p>In order to compare with the pattern-based RFD model, a term-based model was implemented and tested for the optional run. The optional run used the Rocchio method to expand the query and re-rank the documents, as discuses in section 4 but using different pseudo relevance feedback. For each topic, we chose 150 terms in the pseudo positive documents based on tf*idf values. The test pre-processing again included the tasks of stopword removal and word stemming <ref type="bibr" coords="7,331.84,414.90,15.27,8.64" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Process Review</head><p>Due to the large number of documents in ClueWeb09 Category-B and the limited number of terms in queries, at the first step, for each topic we retrieved about 15,000 candidate documents based content search. The documents were ranked using the cosine similarity values for documents vectors and query vectors, as discussed in Section 3. The top 2500 of the retrieved documents (15,000) were selected to submit as the base run results.</p><p>Then, the second step was to build a user profile for each topic in each run using the query terms and the relevance feedback provided by TREC'10 (one documents at a time). The retrieved 15000 documents from the first step were reranked using the user profile (discussed in Section 4) to select pseudo-relevance feedback. Then the top 10 weighted documents were selected as positive feedback documents D + ; and the lowest 10 weight documents were selected as negative feedback documents D -. Pseudo-relevance feedback was used for the main algorithms to update user profiles and perform the optional run.</p><p>In the main run (RFD model), the relevance features were discovered from both positive and negative pseudo relevance feedback, using a model introduced in section 5. These relevance features consisted of high-level pattern features and low-level term features. Based on the high-level features, the low-level features were classified into three groups: positive specific terms, general terms, and negative specific terms. When applying negative patterns to revise the discovered features, we increased the weight of positive specific terms but declined that of negative specific terms based on specificity scour. Finally, we filtered the candidates based on document contents using the features discovered from positive and negative feedback, as discussed previously. The 15,000 candidates were re-ranked by accumulating the weight(t) of features (see Algorithm NRevision()) that occurred in document contents. After that, the top 2,500 documents were selected and submitted as the final retrieved results against the given topic.</p><p>For the optional run, the Rocchio model was used to acquire user profiles from pseudo relevance feedback, as described in Section 6. The candidate documents were reranked based on the user profiles and the top 2,500 weighted documents were submitted as the final results of the optional run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Under the framework set up by TREC 2010 Relevance Feedback Track, the work presented in this paper investigated two models: (i) the pattern-based RFD model that extracts pseudo-relevance feedback to improve the ranking of retrieved documents (the main run); (ii) a termbased model that extracts pseudo-relevance feedback to improve the ranking of retrieved documents (the optional run). Both models consist of two stages: one using the relevance feedback provided by NIST for query expansion to extract pseudo-relevance feedback; one using the pseudo-relevance feedback (including positive and negative feedback) to update user profiles. The exploration of using both positive and negative feedback for information retrieval was innovative, and the results are promising. Because negative feedback information is easily obtained comparing with positive feedback in traditional means, this work has opened a new door to improving the effectiveness of information retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,50.11,83.00,53.24,7.15;7,50.11,91.46,187.00,8.62;7,50.11,100.93,161.53,8.62;7,72.03,110.40,105.79,8.62;7,72.03,121.43,121.76,7.05;7,50.11,140.19,29.22,7.17;7,50.11,148.27,85.98,8.62;7,50.11,157.74,126.61,8.62;7,50.11,167.21,98.03,8.62;7,50.11,178.07,65.92,7.22;7,50.11,186.15,105.44,8.62;7,50.11,195.62,72.55,8.62;7,50.11,206.53,107.93,8.01;7,50.11,214.55,191.01,9.16;7,50.11,224.03,162.61,9.27;7,50.11,233.50,130.92,8.62;7,50.11,242.97,198.49,9.16;7,50.11,253.83,95.92,7.77;7,50.11,261.90,112.05,8.62;7,50.11,272.82,56.87,7.71;7,50.11,305.79,41.40,7.17;7,50.11,314.27,139.93,8.62;7,72.03,323.74,131.35,8.62;7,72.03,334.65,166.66,7.17;7,72.03,342.71,84.07,9.61;7,152.45,349.09,3.65,5.24;7,159.65,344.60,81.34,7.71;7,50.11,354.30,106.22,7.22"><head></head><label></label><figDesc>HLFMining(D) Input: A training set, D = D + ∪ D -, min sup and K; Output: extracted features &lt; DP + , DP -, T &gt;, updated training set {D + , D -}, and an initial term weight function, w. Method: 1: n = |D + |, m = |D -|; 2: DP + =SPMining(D + , min sup); 3: T = {t|t ∈ p, p ∈ DP + }; 4: foreach t ∈ T do 5: w(t) = support(t, D + ); 6: foreach d ∈ D -do 7: rank(d) = Σ t∈d∩T w(t); 8: let D -= {d 0 , d 1 , ..., dm} in descendent ranking order, 9: D -= {d i |d i ∈ D -, rank(d i ) &gt; 0, i &lt; K}; 10: DP -=SPMining(D -, min sup); 11: T 0 = {t ∈ p|p ∈ DP -}; // all terms in negative patterns 12: foreach t ∈ (T 0 -T ) do 13: w(t) = -support(t, D -); 14: T = T ∪ T 0 ; NRevision( ) Input: A updated training set, {D + , D -}; extracted features &lt; T, DP + , DP -&gt;; the initial term weight function w; and experimental parameters θ 1 and θ 2 , -1 2 ≤ θ 1 ≤ θ 2 , 0 ≤ θ 2 ≤ 1. Output: A term weight function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,418.06,135.25,127.05,8.64;7,308.86,147.03,236.25,8.82;7,308.86,159.16,54.79,8.64;7,320.82,170.94,224.29,8.82;7,308.86,183.07,236.25,8.64;7,308.86,195.03,236.25,8.64;7,308.86,206.67,159.17,8.96;7,468.31,205.09,6.23,6.12;7,475.04,206.67,70.08,8.96;7,308.86,218.62,236.25,8.96;7,308.86,230.58,60.31,8.96;7,369.45,229.00,6.23,6.12;7,376.18,230.58,146.95,8.96;7,523.40,229.00,6.23,6.12;7,530.13,230.58,14.98,8.74;7,308.86,242.53,236.25,8.96;7,308.86,254.49,71.91,8.74"><head>3 .1 5 . 1 .</head><label>351</label><figDesc>At last, it updates the initial weights of terms using the function weight defined in Section 5.3.2.The time complexity of NRevision( ) is mainly decided by the process of the partition (step 2 to step 8), where the calculation of the specificity dominates the process. For each term t, it takes O(|d|× (n + |D -|)) = O(|d| × n) for evaluating spe(t),where |d| is the average size of the documents, |D -| is the number of offenders and |D -| ≤ n. Therefore, The time complexity of this algorithm is O(|T | × |d| × n).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,360.77,82.04,132.43,94.10"><head>Table 1 . A set of paragraphs</head><label>1</label><figDesc>P aragraph T erms dp 1 t 1 t 2 dp 2 t 3 t 4 t 6 dp 3 t 3 t 4 t 5 t 6 dp 4 t 3 t 4 t 5 t 6 dp 5 t 1 t 2 t 6 t 7 dp 6 t 1 t 2 t 6 t 7</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,50.11,82.04,236.25,235.22"><head>Table 2 .</head><label>2</label><figDesc>Frequent patterns and covering sets F requent P attern Covering Set {t 3 , t 4 , t 6 } {dp 2 , dp 3 , dp 4 } {t 3 , t 4 } {dp 2 , dp 3 , dp 4 } {t 3 , t 6 } {dp 2 , dp 3 , dp 4 } {t 4 , t 6 } {dp 2 , dp 3 , dp 4 } {t 3 } {dp 2 , dp 3 , dp 4 } {t 4 } {dp 2 , dp 3 , dp 4 } {t 1 , t 2 } {dp 1 , dp 5 , dp 6 } {t 1 } {dp 1 , dp 5 , dp 6 } {t 2 } {dp 1 , dp 5 , dp 6 } {t 6 } {dp 2 , dp 3 , dp 4 , dp 5 , dp 6 }</figDesc><table coords="4,50.11,255.61,236.25,61.64"><row><cell>5 Relevance Feature Discovery (RFD) (main</cell></row><row><cell>run)</cell></row><row><cell>5.1 Frequent and Closed Sequential Pat-</cell></row><row><cell>terns</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,50.11,332.69,236.25,44.82"><head>Table 1</head><label>1</label><figDesc>lists a set of paragraphs for a sample document d, where P S(d) = {dp 1 , dp 2 , . . . , dp 6 } with duplicate terms removed. Assume min sup = 3, ten frequent patterns would be extracted as shown in Table2.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,308.86,146.15,236.25,116.82"><head></head><label></label><figDesc>Table 2 contains three closed patterns, &lt; t 3 , t 4 , t 6 &gt;, &lt; t 1 , t 2 &gt;, and &lt; t 6 &gt;, within ten frequent patterns. After pruning the non-closed patterns, a pattern taxonomy P T can be constructed, like P T = { t 3 , t 4 , t 6 , t 1 , t 2 , t 6 } in Table 2 when considering t 6 a subset of t 3 , t 4 , t 6 . Small patterns (e.g. t 6 ) in a taxonomy are usually general because they have more chance to be used frequently. Vice versa, large patterns (e.g. t 3 , t 4 , t 6 ) are relatively specific because they usually have a low frequency.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The work presented in this paper was partially supported by Grants <rs type="grantNumber">DP0988007</rs> from the <rs type="funder">Australian Research Council</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_2GbPQnJ">
					<idno type="grant-number">DP0988007</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,70.04,694.20,216.32,7.77;8,70.03,705.16,216.33,7.77;8,328.78,75.96,216.33,7.94;8,328.78,86.92,216.33,7.94;8,328.78,98.04,124.28,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,209.60,694.20,76.76,7.77;8,70.03,705.16,213.27,7.77">An effective model of using negative relevance feedback for information filtering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Algarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,339.43,75.96,205.68,7.73;8,328.78,86.92,144.61,7.73">CIKM &apos;09: Proceeding of the 18th ACM conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1605" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,113.02,216.32,7.77;8,328.78,123.82,216.33,7.93;8,328.78,134.78,113.81,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,471.84,113.02,73.27,7.77;8,328.78,123.98,108.85,7.77">Ontology-based personalized search and browsing</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gauch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaffee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pretschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,445.81,123.82,99.30,7.73;8,328.78,134.78,26.80,7.73">Web Intelligence and Agent Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="219" to="234" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,149.91,216.32,7.77;8,328.78,160.87,216.33,7.77;8,328.78,171.67,216.33,7.93;8,328.78,182.63,216.33,7.73;8,328.78,193.59,216.33,7.93;8,328.78,204.71,44.72,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,357.58,160.87,183.80,7.77">Query dependent ranking using k-nearest neighbor</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,338.94,171.67,206.17,7.73;8,328.78,182.63,216.33,7.73;8,328.78,193.59,68.03,7.73">SIGIR &apos;08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,219.69,216.32,7.77;8,328.78,230.48,216.33,7.93;8,328.78,241.44,216.33,7.73;8,328.78,252.40,216.34,7.93;8,328.78,263.52,146.22,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,381.37,219.69,163.74,7.77;8,328.78,230.64,137.86,7.77">A probabilistic analysis of the rocchio algorithm with tfidf for text categorization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,485.79,230.48,59.32,7.73;8,328.78,241.44,216.33,7.73;8,328.78,252.40,53.62,7.73">ICML &apos;97: Proceedings of the Fourteenth International Conference on Machine Learning</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="143" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,278.50,216.32,7.77;8,328.78,289.46,216.33,7.77;8,328.78,300.26,216.33,7.93;8,328.78,311.38,38.11,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,491.42,278.50,53.69,7.77;8,328.78,289.46,216.33,7.77;8,328.78,300.42,86.53,7.77">A probabilistic model of information retrieval: development and comparative experiments -part 1</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,422.30,300.26,76.38,7.73">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="779" to="808" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,326.35,216.32,7.77;8,328.78,337.15,216.33,7.93;8,328.78,348.11,150.95,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,445.62,326.35,99.49,7.77;8,328.78,337.31,95.38,7.77">Jadiel de Arma. UCSC at Relevance Feedback Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Y</forename><surname>Lanbo Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,442.19,337.15,102.92,7.73;8,328.78,348.11,75.98,7.73">Proceedings of the 18th Text Retrieval Conference</title>
		<meeting>the 18th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,363.25,216.32,7.77;8,328.78,374.04,216.33,7.93;8,328.78,385.00,216.33,7.73;8,328.78,395.96,216.33,7.93;8,328.78,407.08,83.41,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,448.23,363.25,96.88,7.77;8,328.78,374.21,24.12,7.77">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,372.79,374.04,172.32,7.73;8,328.78,385.00,216.33,7.73;8,328.78,395.96,112.57,7.73">SIGIR &apos;01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,422.06,216.32,7.77;8,328.78,432.86,216.33,7.93;8,328.78,443.82,216.33,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,412.67,422.06,132.44,7.77;8,328.78,433.02,141.76,7.77">Mining Ontology for Automatically Acquiring Web User Information Needs</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,477.45,432.86,67.67,7.73;8,328.78,443.82,132.26,7.73">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="554" to="568" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,458.95,216.32,7.77;8,328.78,469.75,216.33,7.93;8,328.78,480.71,216.33,7.73;8,328.78,491.67,216.33,7.93;8,328.78,502.79,67.14,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,501.51,458.95,43.59,7.77;8,328.78,469.91,156.65,7.77">A two-stage text mining model for information filtering</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,504.73,469.75,40.38,7.73;8,328.78,480.71,216.33,7.73;8,328.78,491.67,84.52,7.73">CIKM &apos;08: Proceeding of the 17th ACM conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1023" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,517.77,216.32,7.77;8,328.78,528.56,216.33,7.93;8,328.78,539.52,216.33,7.73;8,328.78,550.48,216.33,7.93;8,328.78,561.60,142.22,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,453.70,517.77,91.41,7.77;8,328.78,528.73,161.05,7.77">Mining positive and negative patterns for relevance feature discovery</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Algarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,508.50,528.56,36.61,7.73;8,328.78,539.52,216.33,7.73;8,328.78,550.48,168.64,7.73">KDD &apos;10: Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="753" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,576.58,216.32,7.77;8,328.78,587.54,216.33,7.77;8,328.78,598.34,216.33,7.73;8,328.78,609.29,216.33,7.73;8,328.78,620.41,182.81,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,493.22,576.58,51.89,7.77;8,328.78,587.54,201.10,7.77">Mining multifaceted overviews of arbitrary topics in a text collection</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,328.78,598.34,216.33,7.73;8,328.78,609.29,212.45,7.73">KDD &apos;08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="497" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,635.23,216.32,7.93;8,328.78,646.19,216.33,7.73;8,328.78,657.31,85.31,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,358.25,635.23,186.86,7.73;8,328.78,646.19,212.72,7.73">Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data (Data-Centric Systems and Applications)</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-01">January 2007</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,328.79,672.29,216.32,7.77;8,328.78,683.08,216.33,7.93;8,328.78,694.04,216.33,7.73;8,328.78,705.00,204.72,7.93" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,405.94,672.29,139.17,7.77;8,328.78,683.24,57.50,7.77">Adaptive relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,410.14,683.08,134.98,7.73;8,328.78,694.04,216.33,7.73;8,328.78,705.00,15.74,7.73">CIKM &apos;09: Proceeding of the 18th ACM conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,75.96,216.33,7.94;9,70.03,86.92,216.33,7.94;9,70.03,98.04,80.79,7.77" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,241.93,75.96,44.43,7.73;9,70.03,86.92,86.23,7.73">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,112.22,216.32,7.77;9,70.03,123.01,216.33,7.93;9,70.03,133.97,216.33,7.73;9,70.03,144.93,216.33,7.93;9,70.03,156.05,142.22,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,179.42,112.22,106.94,7.77;9,70.03,123.18,94.80,7.77">Latent concept expansion using markov random fields</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,185.73,123.01,100.64,7.73;9,70.03,133.97,216.33,7.73;9,70.03,144.93,170.70,7.73">SIGIR &apos;07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,170.23,216.32,7.77;9,70.03,181.02,216.33,7.93;9,70.03,191.98,213.27,7.93" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,265.44,170.23,20.92,7.77;9,70.03,181.18,164.83,7.77">Ontological user profiling in recommender systems</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Middleton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">R</forename><surname>Shadbolt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C D</forename><surname>Roure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,242.11,181.02,44.25,7.73;9,70.03,191.98,138.19,7.73">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="88" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,206.32,216.32,7.77;9,70.03,217.28,189.81,7.77" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="9,118.35,206.32,168.01,7.77;9,70.03,217.28,28.50,7.77">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Amherst, MA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct coords="9,70.04,231.29,216.33,7.93;9,70.03,242.41,139.98,7.77" xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J V</forename><surname>Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.02,231.29,135.34,7.93;9,70.03,242.41,39.22,7.77">Information Retrieval. Butterworth-Heinemann</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>Newton, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,256.42,216.33,7.93;9,70.03,267.54,216.33,7.77;9,70.03,278.50,184.78,7.77" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
		<title level="m" coord="9,112.23,256.42,154.65,7.73;9,98.11,267.54,188.25,7.77;9,70.03,278.50,106.09,7.77">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
	<note>Relevance feedback in information retrieval</note>
</biblStruct>

<biblStruct coords="9,70.04,292.67,216.32,7.77;9,70.03,303.63,138.94,7.77" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="9,210.96,292.67,75.40,7.77;9,70.03,303.63,53.32,7.77">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="143" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,317.80,216.32,7.77;9,70.03,328.60,175.57,7.93" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,194.27,317.80,92.09,7.77;9,70.03,328.76,40.44,7.77">The TREC 2002 filtering track report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,126.79,328.60,92.46,7.73">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,342.94,216.32,7.77;9,70.03,353.89,163.88,7.77" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="9,168.77,342.94,117.59,7.77;9,70.03,353.89,78.11,7.77">Improving retrieval performance by relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,368.07,216.32,7.77;9,70.03,378.87,216.33,7.93;9,70.03,389.82,216.33,7.93;9,70.03,400.94,216.33,7.77;9,70.03,411.90,26.39,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,160.32,368.07,126.04,7.77;9,70.03,379.03,25.90,7.77">Feature engineering for text classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,115.28,378.87,171.09,7.73;9,70.03,389.82,152.96,7.73">ICML &apos;99: Proceedings of the Sixteenth International Conference on Machine Learning</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="379" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,426.08,216.32,7.77;9,70.03,436.87,209.65,7.93" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="9,119.54,426.08,166.82,7.77;9,70.03,437.04,12.95,7.77">Machine learning in automated text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,89.45,436.87,119.11,7.73">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,451.21,216.32,7.77;9,70.03,462.01,216.33,7.93;9,70.03,472.97,216.33,7.73;9,70.03,483.92,216.33,7.93;9,70.03,495.04,67.14,7.77" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="9,213.96,451.21,72.39,7.77;9,70.03,462.17,141.12,7.77">Web search personalization with ontological user profiles</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sieg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,231.69,462.01,54.68,7.73;9,70.03,472.97,216.33,7.73;9,70.03,483.92,98.65,7.73">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on Conference on information and knowledge management<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="525" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,509.22,216.32,7.77;9,70.03,520.02,216.33,7.93;9,70.03,530.97,216.33,7.73;9,70.03,541.93,216.33,7.93;9,70.03,553.05,137.73,7.77" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,224.37,509.22,61.98,7.77;9,70.03,520.18,84.23,7.77">Learning routing queries in a query zone</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,173.83,520.02,112.53,7.73;9,70.03,530.97,216.33,7.73;9,70.03,541.93,173.87,7.73">SIGIR &apos;97: Proceedings of the 20th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,567.23,216.32,7.77;9,70.03,578.02,216.33,7.93;9,70.03,588.98,216.33,7.73;9,70.03,599.94,216.33,7.93" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="9,158.79,567.23,127.57,7.77;9,70.03,578.19,55.50,7.77">A general language model for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,141.14,578.02,145.22,7.73;9,70.03,588.98,216.33,7.73;9,70.03,599.94,28.39,7.73">CIKM &apos;99: Proceedings of the eighth international conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="316" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,614.28,216.32,7.77;9,70.03,625.24,216.33,7.77;9,70.03,636.19,216.33,7.77;9,70.03,647.15,216.33,7.77;9,70.03,658.11,216.18,7.77" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="9,194.24,614.28,92.12,7.77;9,70.03,625.24,139.07,7.77">A Personalized Ontology Model for Web Information Gathering</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2010.145</idno>
		<ptr target="http://doi.ieeecomputersociety.org/10.1109/TKDE.2010.145" />
	</analytic>
	<monogr>
		<title level="j" coord="9,218.47,625.24,67.89,7.77;9,70.03,636.19,132.48,7.77">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2010-08-24">24 Aug 2010</date>
			<publisher>IEEE computer Society Digital Library. IEEE Computer Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.04,672.29,216.32,7.77;9,70.03,683.08,216.33,7.93;9,70.03,694.04,216.33,7.73;9,70.03,705.00,160.79,7.93" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="9,231.81,672.29,54.55,7.77;9,70.03,683.24,152.65,7.77">Automatic pattern taxonomy exatraction for web mining</title>
		<author>
			<persName coords=""><forename type="first">S.-T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,241.94,683.08,44.42,7.73;9,70.03,694.04,216.33,7.73;9,70.03,705.00,19.22,7.73">Proceedings of IEEE/WIC/ACM International Conference on Web Intelligence</title>
		<meeting>IEEE/WIC/ACM International Conference on Web Intelligence<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="242" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,328.79,76.13,216.32,7.77;9,328.78,86.92,216.33,7.94;9,328.78,97.88,216.33,7.94;9,328.78,109.00,20.17,7.77" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="9,426.05,76.13,119.06,7.77;9,328.78,87.08,91.93,7.77">Deploying approaches for pattern refinement in text mining</title>
		<author>
			<persName coords=""><forename type="first">S.-T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,441.60,86.92,103.52,7.73;9,328.78,97.88,143.39,7.73">Proceedings of the Sixth International Conference on Data Mining</title>
		<meeting>the Sixth International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1157" to="1161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,328.79,123.95,216.32,7.77;9,328.78,134.74,216.33,7.93;9,328.78,145.70,216.33,7.73;9,328.78,156.66,216.33,7.93;9,328.78,167.78,142.22,7.77" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="9,457.19,123.95,87.91,7.77;9,328.78,134.90,99.88,7.77">A study of methods for negative relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,447.32,134.74,97.80,7.73;9,328.78,145.70,216.33,7.73;9,328.78,156.66,170.70,7.73">SIGIR &apos;08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,328.79,182.73,216.32,7.77;9,328.78,193.52,184.46,7.93" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="9,373.27,182.73,168.44,7.77">Search engines information retrieval in practice</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,328.78,193.52,100.67,7.73">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="430" to="430" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,328.79,208.63,216.32,7.77;9,328.78,219.43,216.33,7.93;9,328.78,230.38,216.33,7.73;9,328.78,241.34,216.33,7.93;9,328.78,252.46,105.34,7.77" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="9,421.53,208.63,123.58,7.77;9,328.78,219.59,177.52,7.77">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,522.70,219.43,22.42,7.73;9,328.78,230.38,216.33,7.73;9,328.78,241.34,135.82,7.73">CIKM &apos;01: Proceedings of the tenth international conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
