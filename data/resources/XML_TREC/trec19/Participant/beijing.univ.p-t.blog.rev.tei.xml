<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,100.32,82.36,394.61,14.42">PRIS at TREC 2010 Blog Track: Faceted Blog Distillation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.82,122.99,22.12,10.46"><forename type="first">Si</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,200.07,122.99,30.86,10.46"><forename type="first">Yan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.47,122.99,61.72,10.46"><forename type="first">Jiayue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.79,122.99,55.54,10.46"><forename type="first">Jingyi</forename><surname>Guan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,373.12,122.99,45.92,10.46"><forename type="first">Xueji</forename><surname>Sun</surname></persName>
							<email>sunxueji1986@yahoo.com.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,215.34,138.59,49.10,10.46"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.33,138.59,57.66,10.46"><forename type="first">Guang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.65,138.59,40.33,10.46"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,100.32,82.36,394.61,14.42">PRIS at TREC 2010 Blog Track: Faceted Blog Distillation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A9C4B37A1051C19F25A9B87D7B550371</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the system adopted for the Faceted Blog Distillation task by PRIS team. The PRIS system is submitted by Pattern Recognition and Intelligent System Lab at Beijing University of Posts and Telecommunications. And a two-stage strategy is involved for this task. First, an adaptable Voting Model is carried out for blog distillation. Then, different models are designed to judge the facets and ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We participate in the Faceted Blog Distillation task at TREC 2010 Blog Track. And the task is the same as the Faceted Blog Distillation task in 2009. And three kinds of facets are used. They are 'opinionated' vs. 'factual', 'personal' vs. 'official' and 'in-depth' vs. 'shallow'.</p><p>The PRIS system adopts a two-stage strategy in the faceted blog distillation. The first step is baseline blog distillation. This step only consists in ranking blogs which are relevant to the topic. An adaptable voting model with Posts Average algorithm (PA) is designed for blog distillation. In the second stage, different models are used for identifying different facets. For 'opinionated' vs. 'factual' facets, the opinion lexicon and the factual lexicon are adopted for sentiment analysis to make a distinction between these two facets. Then, an improved in-depth analysis model based on the L-Qtf (Length-Query term frequency) coefficient is carried out for 'in-depth' vs. 'shallow' facets. Meanwhile, a personal lexicon and an official lexicon are generated by Information Gain (IG).</p><p>In Section 2, we introduce the blog distillation algorithm and facets models respectively. In Section 3, the evaluation of the faceted blog distillation system is presented. Finally in Section 4, conclusions and comments on the future work are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Faceted Blog Distillation System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Blog distillation</head><p>The aim of the blog distillation is to identify blogs which have a recurring interest in the query topic area. In our system, we use the adaptable Voting Model <ref type="bibr" coords="1,368.77,747.43,12.27,9.16" target="#b0">[1]</ref> for blog distillation. In this model, blogs are ranked by learning the ranking of posts with respect to the query. If a blog has many associated posts highly ranked in the ranking of posts, these are seen as votes and the blog will be ranked higher than another blog with less or lower ranked posts. In the simplest technique, called Votes, blogs are ranked by the aggregation of their posts ranked in response to a query. In particular, the retrieval score for a blog B with respect to a query Q, denoted Score(B,Q) is:</p><formula xml:id="formula_0" coords="2,170.52,159.53,305.80,13.67">) ( ) ( ) , ( B posts Q R Q B Score Votes âˆ© = (1)</formula><p>where R(Q) is the underlying ranking of blog posts, and posts(B) is the set of posts belonging to blog B. Note that each post is associated to exactly one blog.</p><p>Our system ranks each blog by the sum of the relevance score of all the retrieved posts of the blog, and strengthens the highly scored posts by applying the root function (strong votes evidence):</p><formula xml:id="formula_1" coords="2,159.24,270.27,317.08,28.54">âˆ‘ âˆ© âˆˆ = ) ( ) ( ) , ( ) , ( B posts Q R p rootSum Q p score Q B Score (2)</formula><p>However, an issue using such a technique is that the productive bloggers may gain an unfair advantage in the ranking. This is because the more a blogger writes, the more likely a query term will appear at random in a blog post (e.g., many blog posts contain links to other recent posts, with the title of each post identical to the link anchor), and hence the blog will receive extra erroneous votes. To this end, we adapt a normalization technique, called Posts Average algorithm (PA), with regard to the number of posts of blog. The normalized score of a blog is adapted as follows:</p><formula xml:id="formula_2" coords="2,161.88,409.20,314.44,44.95">) ( ) , ( ) , ( ) ( ) ( B posts Q p score Q B Score B posts Q R p Norm âˆ‘ âˆ© âˆˆ = (3)</formula><p>Where |posts (B)| denotes the total number of posts of blog B.</p><p>Moreover, query expansion is added to our system to improve the retrieval accuracy. From the aspect of topic understanding, the Learning Query Expansion (LQE) model based on semi-machine learning method is designed as we have done at the Blog Track 2009 <ref type="bibr" coords="2,442.86,513.43,11.20,9.16" target="#b1">[2]</ref>.</p><p>We trained LQE model based on CRFs with the manual Blog track 2008 queries which were expanded based on the human common sense and comprehension. After the classifier was trained, it was applied to the whole Blog track 2010's queries for query expansion which contains both expansion words and their weightings with Indri query language. One of the final query examples is as the following: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Opinionated vs. Factual Model</head><p>This model contains three stages. Firstly, an existing opinion lexicon proposed in <ref type="bibr" coords="2,433.26,748.45,12.28,9.16" target="#b2">[3]</ref> is involved in our system. For the factual lexicon, it is generated automatically in this step. Secondly, the opinionated lexicon and the newly generated factual lexicon are utilized to calculate the opinion score and factual score respectively. Finally, a ranking scheme is used to generate the final ranking of opinionated and factual blogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Generating a factual lexicon</head><p>The factual lexicon is generated automatically based on Information Gain (IG) and Mutual Information (MI). For each term t in blog posts, its IG weight is calculated as follows.</p><formula xml:id="formula_3" coords="3,91.98,203.86,384.33,19.21">] ) ( ) | ( log ) | ( ) ( ) | ( log ) | ( )[ ( ] ) ( ) | ( log ) | ( ) ( ) | ( log ) | ( )[ ( ) ( F p t F p t F p O p t O p t O p t p F p t F p t F p O p t O p t O p t p t IG + + + = (4)</formula><p>O and F denote the opinionated and factual blogs respectively.</p><p>It is assumed that the number of opinionated and factual blogs in training collection is A and B respectively. Then,</p><formula xml:id="formula_4" coords="3,183.84,278.26,292.48,144.02">B A B A t df t p + = ) , | ( ) ( (5) B A A O p + = ) ( (6) ) , | ( ) | ( ) | ( B A t df A t df t O p = (7) ) , | ( ) ( ) | ( ) | ( B A t df B A A t df A t O p - + - = (8)</formula><p>p( t ), p(F), p(F|t) and p(F| t ) can be easily deduced according to the equations above. Terms whose IG values are above the threshold, we have previously set, are selected as candidates of the lexicon.</p><p>For the candidates produced above, we further compute term weight according to a document-frequency based on the version of the Mutual Information metric <ref type="bibr" coords="3,410.11,513.43,11.16,9.16" target="#b3">[4]</ref>.</p><formula xml:id="formula_5" coords="3,128.52,535.04,350.26,67.51">) ( ) ( ) , ( log ) , ( ) ( ) ( ) , ( log ) , ( ) ( fa O p t p O t p O t p F p t p F t p F t p t MI + = (9) B A A t df O t p + = ) | ( ) , (<label>(10)</label></formula><p>p(t,F), p( t ,F) and p( t ,O) can be easily deduced according to the equations above. Another threshold is used to generate the final factual lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Computing opinion score and factual score</head><p>Given a query, for each term t in the opinion lexicon or factual lexicon, we first compute a tf-idf weight w tfidf (t) in the relevant document collection provided by the baseline blog distillation task. Simultaneously, we use a Bol term weighting model <ref type="bibr" coords="3,312.40,716.23,12.17,9.16" target="#b4">[5]</ref> to compute the query weight w bol (q) in the collection. Then we add the two weight to get the opinion score score op or factual score score fa .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Ranking</head><p>First we get the relevance score Score(B,Q) in baseline for each blog. And then we use Score(B,Q)Ã—score op as the final score for ranking opinionated blogs and Score(B,Q)Ã—score fa as the final score for factual blogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">In-depth vs. Shallow Model</head><p>In the in-depth facet stage, the improved in-depth analysis model is adopted. The facet of a blog is judged based on all the posts in it. In common sense, an in-depth post expresses author's opinion on the given topic in detail with a long length in ideal situation. For minimizing the impact of spam contents, the length with average length is considered as a feature of the in-depth degree. But only using the length feature isn't sufficient, to confirm the relevance degree, considering the query term frequency in the post is also necessary. The posts' length and the query term frequency are combined as the following L-Qtf coefficient <ref type="bibr" coords="4,292.64,263.83,11.39,9.16" target="#b1">[2]</ref>:</p><formula xml:id="formula_6" coords="4,170.70,281.87,308.08,47.39">( ) ( ) âˆ‘ âˆ© âˆˆ Ã— + - + + = - D Q t qtf avdl dl s s tf Qtf L ) 1 ( ln 1 ln 1 (11)</formula><p>where tf and qtf represent the query term frequency in the post and in the query respectively. The tf and qtf are calculated after stemming. dl is the post length and avdl is the average-length of the whole relevant posts for the topic. s is a parameter which is set as 0.2 in our experiments. The L-Qtf coefficient is a kind of pivoted weighting coefficient <ref type="bibr" coords="4,338.68,388.63,12.32,9.16" target="#b5">[6]</ref> [7].</p><p>Based on the whole posts of the topic-relevant blogs given by the blog distillation, the posts are ranked according to the in-depth coefficient. In the ranking list, the top 45% of topic-relevant posts are considered as the in-depth, while the last 45% posts are the shallow. indepth(post i ,Q) and shallow(post i ,Q) represent the post whether it is in in-depth or shallow. indepth(post i ,Q) is the total number of the in-depth posts. If post i is in the top 45% of ranking list, indepth(post i ,Q) is 1, and 0 otherwise. Similarly, shallow(post i ,Q) is the total number of the shallow posts. The in-depth degree (Score) of each blog is calculated according to the relationship between the in-depth posts and shallow posts as the following equation.</p><p>(</p><formula xml:id="formula_7" coords="4,96.24,534.22,382.54,140.46">( ) n Q post shallow Q post indepth Q b Score S n i n i i i x i âˆ‘ âˆ‘ = = - = = 1 1 ) , ( , , log (12) ( ) âŽ© âŽ¨ âŽ§ = other poster indepth a is post Q post indepth i i 0 1 , (13) ( ) âŽ© âŽ¨ âŽ§ = other poster shallow a is post Q post shallow i i 0 1 , (14)<label>)</label></formula><p>The larger the Score is, the deeper the feed is. Otherwise, the shallower the feed is.</p><p>According to the experiment, the ranking according to the L-Qtf is more effective in the in-depth facet, while the shallow facet is more dependent both on L-Qtf and the length of the post.</p><p>In the in-depth facet task, the feed should be judged not only the topic relevance but also the facets. By considering these two points, the combination model is adopted. </p><formula xml:id="formula_8" coords="5,128.58,378.85,262.78,48.08">_ 2 _ 2 1 _ 1 _ 1 _ 2 2 2</formula><formula xml:id="formula_9" coords="5,474.64,396.57,4.13,8.74">)</formula><p>where t is the term we want to process. c 1 is the personal facet, and c 2 is the official facet. The essence of IG is that the term with larger IG value can distinguish the two classes. Then, we select the terms which IG values are above certain threshold. Considering the factor of sentiment, we also pick out the sentiment terms to improve the results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Scoring and Ranking</head><p>We use Vector Space Model (VSM) to score the blogs <ref type="bibr" coords="6,388.28,154.63,11.18,9.16" target="#b7">[9]</ref>. (p(t 1 |post), p(t 2 |post), p(t 3 |post) â€¦p(t i |post)) and (personal(t 1 ), personal(t 2 ), personal(t 3 ) â€¦personal(t i )) can represent a post we want to judge and personal lexicon respectively. The score of the post belonging to personal facet is calculated as follows.</p><formula xml:id="formula_10" coords="6,115.32,221.59,363.46,30.63">âˆ‘ = = n i i i t personal post t p post score personal 1 ) ( ) | ( ) ( _ (23)</formula><p>Similarly, the official facet score is calculated as follows:</p><formula xml:id="formula_11" coords="6,113.88,284.34,364.89,29.94">âˆ‘ = = n i i i t official post t p post score official 1 ) ( ) | ( ) ( _ (24)</formula><p>Since a blog is comprised of many posts, its score of personal/official facet should be the addition of posts' personal/official score. Finally the score of a blog can be as follows.</p><formula xml:id="formula_12" coords="6,94.50,357.81,387.75,38.99">n post score official post score personal b score n i i n i i âˆ‘ âˆ‘ = = - = 1 1 ) ( _ ) ( _ log) (<label>(25)</label></formula><p>We rank this score in descending order. Then from the top to the bottom of the ranking list, the blogs' inclination of personal facet becomes weaker while the inclination of official facet becomes stronger. Finally, we get 100 personal and 100 official blogs with their ranking respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submission and Evaluation Results</head><p>We have done many experiments on this track. In this section, we present empirical evaluation results of our different versions. We employed four performance metrics: mean average precision (MAP), binary preference (bPref), rPrec and P@10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Blog distillation</head><p>We submitted 2 runs. The difference between the 2 runs is query. The first run is without query expansion, the words in the title field are only used. The second run is expanded by LQE. The evaluation results of the 2 submitted runs are listed in Table1. Pris and Prisb denote the "query-only" run and the "query-expansion" run respectively. From these data, it proves that for the first value the LQE is effective while "query-only" run is effective for the second value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Faceted blog distillation</head><p>There are many runs for this sub-task, listing in Table2 and Table3. Q0 stands for the "query-only" run and QE stands for the "query-expansion" run. Std represents the standard baseline 1 that we used in our system and it means our own baseline if there is no "Std" in the run-tag label. PrisQ01, PrisQE1, PrisStdQ02, and PrisStdQE1 use both the opinion lexicon and the factual lexicon and normalization is also adapted, while PrisQ02, PrisQE2, PrisStdQ0 and PrisStdQE2 use the opinion lexicon and the normalization scheme but not the factual lexicon. The two lexicons are also utilized in PrisQ03, PrisStdQ03 and PrisStdQE3 but normalization is not adapted in them. For PrisQ04 and PrisStdQ04, only the opinion lexicon is used.</p><p>Table2 shows that PrisStdQ02 obtains the best result for MAP, PrisStdQE2 performs best at bPref. In addition, PrisStdQ02 and PrisStdQ04 get the same highest score for R-prec and P@10. In Table3, the best performance on MAP, bPref, R-prec and P@10 is PrisStdQ02, PrisStdQ02, PrisStdQE1 and PrisQE2 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table1. Blog distillation results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we present a system for the faceted blog distillation. Compared Table <ref type="table" coords="8,447.39,543.31,5.25,9.16" target="#tab_2">2</ref> and Table <ref type="table" coords="8,500.17,543.31,5.25,9.16" target="#tab_3">3</ref> with Table <ref type="table" coords="8,137.64,558.91,3.95,9.16">1</ref>, it can be concluded that most faceted models take negative feedback to the baseline. In the feature research, we will focus on exploring much more efficient faceted models for the faceted blog distillation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,104.64,196.51,379.34,550.95"><head>Table 2 . Faceted blog distillation results of the first value</head><label>2</label><figDesc></figDesc><table coords="7,289.38,196.51,192.41,9.16"><row><cell>bPref</cell><cell>R-prec</cell><cell>P@10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,108.36,76.47,375.61,367.22"><head>Table 3 . Faceted blog distillation results of the second value</head><label>3</label><figDesc></figDesc><table coords="8,108.36,102.16,375.61,341.52"><row><cell></cell><cell>MAP</cell><cell>bPref</cell><cell>R-prec</cell><cell>P@10</cell></row><row><cell>PrisQ01</cell><cell>0.0714</cell><cell>0.0631</cell><cell>0.0621</cell><cell>0.0667</cell></row><row><cell>PrisQ02</cell><cell>0.0451</cell><cell>0.0525</cell><cell>0.0623</cell><cell>0.0500</cell></row><row><cell>PrisQ03</cell><cell>0.0442</cell><cell>0.0493</cell><cell>0.0585</cell><cell>0.0417</cell></row><row><cell>PrisQ04</cell><cell>0.0448</cell><cell>0.0510</cell><cell>0.0623</cell><cell>0.0500</cell></row><row><cell>PrisQE1</cell><cell>0.0791</cell><cell>0.0813</cell><cell>0.0926</cell><cell>0.0708</cell></row><row><cell>PrisQE2</cell><cell>0.0801</cell><cell>0.0880</cell><cell>0.0856</cell><cell>0.0750</cell></row><row><cell>PrisStdQ0</cell><cell>0.0716</cell><cell>0.0667</cell><cell>0.0642</cell><cell>0.0625</cell></row><row><cell>PrisStdQ02</cell><cell>0.0956</cell><cell>0.0975</cell><cell>0.0999</cell><cell>0.0583</cell></row><row><cell>PrisStdQ03</cell><cell>0.0706</cell><cell>0.0648</cell><cell>0.0642</cell><cell>0.0625</cell></row><row><cell>PrisStdQ04</cell><cell>0.0689</cell><cell>0.0651</cell><cell>0.0642</cell><cell>0.0625</cell></row><row><cell>PrisStdQE1</cell><cell>0.0947</cell><cell>0.0952</cell><cell>0.1066</cell><cell>0.0708</cell></row><row><cell>PrisStdQE2</cell><cell>0.0432</cell><cell>0.0612</cell><cell>0.0583</cell><cell>0.0500</cell></row><row><cell>PrisStdQE3</cell><cell>0.0432</cell><cell>0.0612</cell><cell>0.0583</cell><cell>0.0500</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>S j is the final confidence value of the blog B. Score(blog x ,Q) is the facet result as Eq.( <ref type="formula" coords="5,488.13,123.43,8.61,9.16">12</ref>). Score Norm (B,Q) is got from the result of Blog distillation. The combination model use multiplication to consider both topic relevance and facets result. According to the experiment, the combine model with multiplication is more effective than the model with addition, as Eq. ( <ref type="formula" coords="5,472.00,170.23,8.75,9.16">16</ref>) <ref type="bibr" coords="5,487.72,170.23,11.19,9.16" target="#b1">[2]</ref>.</p><p>Î¼ is a weighting parameter that distributes in the interval [0, 1] and balances the scores of facet level and similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Personal vs. Official Model</head><p>For the personal vs. official facet, we get Information Gain (IG) values of the terms. After that, we extract the terms with higher IG values to build lexicons with considering the factor of sentiment at the same time. Then the lexicons are used to score and rank the related blogs respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Calculating IG</head><p>We calculate IG values of the terms using the TREC Blogs08 collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Building lexicons</head><p>In the procedure of building the lexicons <ref type="bibr" coords="5,282.45,529.03,11.20,9.16" target="#b6">[8]</ref>, the Mutual Information metric is split into two parts to gain personal and official facet weights. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,104.93,636.91,378.68,9.16;8,90.00,652.51,240.64,9.16" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,223.76,636.91,259.85,9.16;8,90.00,652.51,77.46,9.16">Voting for Candidates: Adapting data fusion techniques for an Expert Search task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,185.43,652.51,114.30,9.16">Proceedings of CIKM 2006</title>
		<meeting>CIKM 2006</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,104.92,668.11,400.25,9.16;8,90.00,683.71,139.82,9.16" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,199.39,668.11,289.98,9.16">A Study of Faceted Blog Distillation--PRIS at TREC 2009 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,107.49,699.31,397.90,9.16;8,90.00,714.91,302.35,9.16" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,352.21,699.31,153.18,9.16;8,90.00,714.91,130.40,9.16">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,241.98,714.91,118.22,9.16">proceedings of HLT/EMNLP</title>
		<meeting>HLT/EMNLP</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.02,730.51,399.37,9.16;8,90.00,746.11,94.68,9.16" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,247.01,730.51,229.62,9.16">Foundations of statistical natural language processing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.55,76.63,395.78,9.16;9,90.00,92.23,234.44,9.16" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,165.95,76.63,339.38,9.16;9,90.00,92.23,47.89,9.16">Probabilistic models for information retrieval based on divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="9,104.34,107.83,394.56,9.16;9,90.00,123.43,401.55,9.16;9,90.00,139.03,101.48,9.16" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,249.51,107.83,164.20,9.16">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,420.66,107.83,78.24,9.16;9,90.00,123.43,401.55,9.16;9,90.00,139.03,33.84,9.16">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.84,185.83,356.09,9.16;9,90.00,201.43,380.22,9.16" xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">Mostafa</forename><surname>Keikha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Carman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Gwadera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shima</forename><surname>Gerani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,424.16,185.83,36.77,9.16;9,90.00,201.43,301.08,9.16">Giacomo Inches,Az Azrinudin Alidin and Fabio Crestani.University of Lugano at</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,104.94,217.03,394.58,9.16;9,90.00,232.63,358.97,9.16" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chistopher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Manning</surname></persName>
		</author>
		<title level="m" coord="9,202.74,217.03,296.78,9.16;9,90.00,232.63,271.73,9.16">Prabhaker Raghavan and Hinrich Schutze.Scoring,term weighting and the vector space model.An Introduction to Information Retrieval</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="120" to="126" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
