<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.13,154.77,420.69,15.48;1,518.12,152.23,5.98,10.48">DUTH does Probabilities of Relevance at the Legal Track *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.75,187.29,108.50,10.75"><forename type="first">Dim</forename><forename type="middle">P</forename><surname>Papadopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Democritus University of Thrace</orgName>
								<address>
									<postCode>67100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.80,187.29,100.67,10.75"><forename type="first">Vicky</forename><forename type="middle">S</forename><surname>Kalogeiton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Democritus University of Thrace</orgName>
								<address>
									<postCode>67100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.01,187.29,79.49,10.75"><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Democritus University of Thrace</orgName>
								<address>
									<postCode>67100</postCode>
									<settlement>Xanthi</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.13,154.77,420.69,15.48;1,518.12,152.23,5.98,10.48">DUTH does Probabilities of Relevance at the Legal Track *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">998776E948100694CC0C0A1E120A9826</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participated in the Learning Task of the TREC 2010 Legal Track, focusing solely on estimating probabilities of relevance. We submitted three automated runs based on the same tf.idf ranking, produced by the topic narratives and positive-only feedback of the training data in equal contributions. The runs differ in the way the probabilities of relevance are estimated: (1) DUTHsdtA employed the Truncated Normal-Exponential model to turn scores to probabilities. (2) DUTHsdeA did not assume any specific component score distributions but estimated those on the scores of training data via Kernel Density Estimation (KDE) methods. (3) DUTHlrgA used Logistic Regression with the co-efficients estimated on the scores of training data. We found that DUTHsdeA and DUTHlrgA are greatly affected by biases in the training set, since they assume that input score data are uniformly sampled. Also, KDE was found to be very sensitive to its parameters, influencing greatly the probability estimates. In these respects, DUTHsdtA was proven to be the most robust method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we report our participation in the Learning Task of the TREC 2010 Legal Track. Task participants were given a "seed" (or training) set of documents from a larger collection that had previously been assessed by TREC as responsive or non-responsive (or-using traditional IR jargon-relevant or non-relevant) to a legal dis- * In: Proceedings of the Nineteenth Text REtrieval Conference, 2010. covery request. Using this information, participants had (a) to rank the documents in the larger collection from most likely to least likely to be relevant, and (b) for each document, to estimate the likelihood of relevance as a probability. TREC assessed the quality of rankings, as well as the quality of probability estimates.</p><p>This year we focused solely on estimating probabilities of relevance. In Section 2, we talk about the task setup. The indexing, training, and retrieval methods are mentioned in Section 3. In Section 4, we describe the methods for estimating probabilities and their underlying assumptions. In Section 5, we provide a comparative evaluation of the methods in the context of the Learning Task. Conclusions are drawn in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Setup</head><p>In this section, we briefly describe the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Test Collection</head><p>The Learning Task in the TREC 2010 Legal Track used the EDRM Enron v2 collection in either XML or PST formats. In the EDRM XML, a document is considered to be either an email message as a whole, or a particular attachment. Some documents may appear more than once in the original collection. We used the de-duplicated version of the text-only portion of XML dataset. This version has a total number of 685,592 documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Queries and Training Data</head><p>TREC provided to the participants a set of eight topics (200-207), their narrative parts only. Each topic was con-sidered as an independent query. Also, as already mentioned, TREC provided a training set of documents that had previously been assessed as relevant or non-relevant. The numbers of relevant and non-relevant documents per topic are given in Table <ref type="table" coords="2,167.92,176.10,3.74,8.64" target="#tab_0">1</ref>. During the Track, conflicting relevance judgments were discovered for some documents which appeared both as relevant and non-relevant. TREC did not provide any guideline on how to deal with those, so we decided to take them as relevant. Thus, our numbers of training documents were effectively those in Table <ref type="table" coords="2,227.71,416.21,3.74,8.64" target="#tab_1">2</ref>. We note here that the given set of training data may be biased in unknown ways; this seems to have affected two of our three runs, as we will later see. Usually, such training sets are build by the taking the union of top-ranked documents retrieved by several systems (i.e. known as pooling), assessed in previous experiments; they are certainly not uniform samples of the whole collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Indexing and Retrieval</head><p>The EDRM Enron v2 collection was indexed with the Lemur Toolkit V4.11 and Indri V2.11, using the default settings that come with these versions, except that we enabled the Krovetz stemmer. <ref type="foot" coords="2,418.58,179.61,3.49,6.05" target="#foot_0">1</ref> For the official runs, we used the tf.idf retrieval model.</p><p>In order to utilize the training set, we used the relevance feedback option in Lemur. All the feedback algorithms currently in Lemur assume that all entries in a judgment file are relevant documents, so we had to remove all the entries of judged non-relevant documents. We used the feedback model as well as the initial query (feedback-PosCoef=1), equally weighted. We added 64 terms to the initial query (feedbackTermCount=64).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Estimating Probabilities of Relevance</head><p>We investigated three methods for estimating the probabilities of relevance; the methods are based solely on document scores. The first method can be applied with or without training data, while the other two need training data. All methods are fully automated, i.e. they do not need any human intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The SD Method with Theoretical Distributions</head><p>Under the assumption of binary relevance, classic attempts model score distributions (SDs)-on a per-request basis-as a mixture of two SDs: one for relevant P (s|1) and the other for non-relevant document scores P (s|0). Given the two component SDs and their mix weight G, the probability of relevance of a document given its score s can be calculated straightforwardly <ref type="bibr" coords="2,460.42,492.59,10.79,8.64" target="#b3">[4,</ref><ref type="bibr" coords="2,473.70,492.59,7.38,8.64" target="#b6">7]</ref>:</p><formula xml:id="formula_0" coords="2,347.13,514.10,192.11,22.31">P (1|s) = G P (s|1) G P (s|1) + (1 -G) P (s|0)<label>(1)</label></formula><p>Various combinations of theoretical distributions have been proposed for modeling P (s|1) and P (s|0) since the early years of IR; for a recent review of the proposed combinations, we refer the reader to <ref type="bibr" coords="2,462.21,585.99,10.58,8.64" target="#b2">[3]</ref>. We settled for employing the latest, improved normal-exponential model which uses truncated versions of the component densities trying to deal with some of the shortcomings of the original model <ref type="bibr" coords="2,357.51,633.81,10.58,8.64" target="#b1">[2]</ref>. The last two mentioned studies suggest that normal component for relevant fits best to (a) vector space or geometrical retrieval models, (b) scoring functions in the form of linear combination of document term weights, and (c) long queries. The exponential fits best on the top-end of the non-relevant scores.</p><p>Throughout the rest of the paper, we refer to this method as SDT, i.e. Score-Distributional with Theoretical distributions, irrespective of the component choices; our officially-submitted run with normal-exponential is tagged as DUTHsdtA. The underlying assumption of SDT is not only that a chosen pair of theoretical distributions provides a good fit to observed SDs of the retrieval model at hand, but also that the components indeed represent binary relevance and not some arbitrary effect. Furthermore, the non-relevant component we chose applies to the top-end of scores, leaving us with no P (1|s) estimates for lower scores. However, the method provides an estimate of the number of relevant documents below the truncation, and using this we simply set P (1|s) uniformly to that estimate divided by the number of documents below the truncation. In summary, there are 4 parameters to estimate: the mean and variance of the normal, the mean of the exponential, and the mix weight G. This can be done with or without training data.</p><p>We recovered the parameters of the component distributions and the mix weight with Expectation Maximization (EM) <ref type="bibr" coords="3,116.89,435.13,11.62,8.64" target="#b7">[8]</ref> without using the training data. Specifically, we applied the method as described in <ref type="bibr" coords="3,260.86,447.08,10.58,8.64" target="#b1">[2]</ref>, using the Technical Truncation model, with the following differences: (1) We truncated the rankings at the top 2% of the corpus (i.e. 13,712 documents) in order to achieve better exponential fits; not having an estimate of the average query generality, this was an arbitrary choice. (2) We did a minimum of 8 and a maximum of 64 EM runs, with a cap at 32 iterations per run; thus we used lower values which exchange accuracy for speed. (3) In calculating the χ 2 of the fits, score data were binned into a minimum of 8 to a maximum of 32 bins. (4) We rejected fits with an expected relevant score lower than the expected nonrelevant score in the truncated rankings; this is reasoned in <ref type="bibr" coords="3,82.24,602.50,11.62,8.64" target="#b0">[1]</ref> as a condition for improving parameter estimation.</p><p>An important disadvantage of the currently used parameter estimation method is that it is not using the available training data. Although EM can be modified to do that, it is currently unclear to us how to do it with data of unknown biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The SD Method with Empirical Distributions</head><p>We experimented with a new score-distributional method which needs training data. The advantage of this method is that it does not assume any specific theoretical distributions, and it is capable of approximating unknown distributions. The components are deduced, one at a time, with Kernel Density Estimation (KDE) methods <ref type="bibr" coords="3,489.35,206.32,11.62,8.64" target="#b8">[9]</ref> from the corresponding scores of the training documents. The mix weight may be estimated from or without training data.</p><p>Throughout this paper, we refer to this method as SDE, i.e. Score-Distributional with Empirical distributions; our officially-submitted run is DUTHsdeA. A disadvantage of the method is that KDE needs some score data per component, which in general may not be available. Also, depending on the shapes of the estimated densities and the mix weight, SDE may not result to a monotonic transformation of scores to probabilities. This implies that rankings are sub-optimal and that they can be improved by simply re-ranking them in a descending order of the estimated probabilities. Rather than reversing the rankings, randomizing the 'offending' score ranges could also be effective. However, we did something rougher: we forced a monotonic decline of the probability of relevance in rankings by setting it to the minimum value previously seen as we go down a ranking.</p><p>Kernel density estimation (KDE) is a non-parametric way of estimating the probability density function of a random variable; it is a fundamental data-smoothing problem, where inferences about the population are made based on a finite data sample. We used a Gaussian kernel and a bandwidth of σ/5, where σ is the standard deviation of a 2% uniform score sample of a query's results (i.e. approximately 13,712 scores-we down-sampled for speed). The bandwidth is a free parameter which exhibits a strong influence on the resulting estimate.</p><p>Using EM, we only recovered the mix weight G of the two distributions on the whole score range. Again, for efficiency reasons, we run EM on a 2% uniform sample from the total distribution and not the whole collection. As theoretical component distributions in EM, we plugged in the KDEs of relevant and non-relevant. The function that provides the probability of relevance is again Equation <ref type="formula" coords="3,349.07,640.94,3.74,8.64" target="#formula_0">1</ref>.</p><p>Finally, it should be mentioned that the method assumes that the training data are a uniform sample of the collection, so that the score densities estimated with KDE are representative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Logistic Regression</head><p>Without recovering the component distributions, we mapped scores to probabilities directly by using the standard method of Logistic Regression <ref type="bibr" coords="4,220.79,199.08,11.62,8.64" target="#b4">[5]</ref> on the scores of the seed set. We refer to this method as LRG, and our officially-submitted run is DUTHlrgA.</p><p>This approach is non-parametric-that is, it is not dependent on any assumptions about or analysis of score distributions. However, it is not applicable if there are no training data, and the coefficients estimated depend heavily on the choice of the training sample <ref type="bibr" coords="4,230.28,283.42,10.58,8.64" target="#b5">[6]</ref>.</p><p>Logistic regression has two coefficients, β 1 and β 2 . In order to recover them we used once more the training data. We applied the Newton-Raphson algorithm to calculate maximum likelihood estimates of a simple logistic regression, using the training data as input. In the end, each score s was mapped to a probability of relevance according to:</p><formula xml:id="formula_1" coords="4,125.09,389.34,175.55,23.23">P (1|s) = exp(β 1 + β 2 s) 1 + exp(β 1 + β 2 s)<label>(2)</label></formula><p>An obvious problem of the method is that the training data counts are not representative of the relative density of relevant to non-relevant in the collection. In order to compensate for this, trying to remove some of the bias, we assumed an extra 100,000 non-relevant documents scoring at 0 during the estimation of the co-efficients.</p><p>Logistic regression predicts the probability of occurrence of an event by fitting a logistic curve to the data. But, this curve is defined on the whole real axis. So, the tf.idf model used may not be appropriate, and maybe it would have been better to apply the method on OKAPI scores since OKAPI scores fall on the whole real axis and not only to the positive one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>First, in Table <ref type="table" coords="4,129.10,606.49,3.74,8.64" target="#tab_2">3</ref>, we investigate the quality of our ranking. Note that we used the same ranking for all three submitted runs. The hypothetical F1 is a measure of the quality of the ranking, independent of the submitted probability estimates. It is the F1 that would have been achieved, had the best cutoff been chosen for the ranking.</p><p>We are above median only in 205, which is also very close to the best result from all participating systems. We are at the median in 200 and 203. We are below the median in the rest 5 topics, but nowhere the worst. A hypothetical system with median performance in all topics would have achieved an average hypothetical F1 of 21.86; the quality of our ranking is close to this. All in all, we consider our ranking quality to be median, i.e. a good representative of all participating rankings.</p><p>In Table <ref type="table" coords="4,355.10,235.88,3.74,8.64" target="#tab_3">4</ref>, we investigate the quality of the R estimates for all three methods. While, in principle, R can be estimated in a way that is independent of the quality of the underlying ranking, some estimation methods may be influenced by the ranking quality. For example, sdt is known to perform better on good quality queries or results <ref type="bibr" coords="4,516.19,295.65,10.58,8.64" target="#b2">[3]</ref>.</p><p>For lrg, half the topics are above median, and the other half are below; 203 has the best R estimate of all participating runs. Its average accuracy is above this of the hypothetical median system, thus, we can say that lrg performs better than median. The sde method fails with all topics performing below the median, and 3 of them have the worst submitted accuracy in estimated R. The sdt method shows a great variance in its effectiveness: while it works great for some topics (best estimates in 204 and 206), it performs below the median in others; 207 is nearly the worst. Overall, the average R accuracy of sdt is above this of the hypothetical median system. It is worth mentioning that the best two R estimates are on the topics with the worst ranking quality compared to the other topics in our ranking.</p><p>In Table <ref type="table" coords="4,358.70,486.93,3.74,8.64" target="#tab_4">5</ref>, we investigate the % accuracy of the F1 estimate. F1 is the score that would have been achieved if the estimates had been relied on selecting the cutoff. Using the same way of analysis as for the first table, we can deduce that our three methods present worse results that a median system for the accuracy of the F1 estimates. So, we have a kind of good R estimates for lrg and sdt, but they don't translate to good F1 estimates.</p><p>In Table <ref type="table" coords="4,357.52,582.58,3.74,8.64" target="#tab_5">6</ref>, we investigate the % accuracy of our cutoffs. The average accuracy of all our methods is below the median. lrg and sdt are very close to the median but as far as the sde is concerned, three topics <ref type="bibr" coords="4,478.13,618.44,20.75,8.64">(203,</ref><ref type="bibr" coords="4,501.22,618.44,17.43,8.64">204,</ref><ref type="bibr" coords="4,520.99,618.44,18.26,8.64">205)</ref> have the worst submitted accuracy of the K estimates.</p><p>In summary, our ranking quality is close to this of a median system. The lrg and sdt estimate the number of relevant documents better than a median system, but the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>First, we are not satisfied with the quality of our ranking, although it seems to be around this of a median system. We were targeting on using only the feedback model in training and discard the initial narrative query, but we misinterpreted Lemur's parameters. The ranking quality affects the quality of estimates in two out of our three methods, namely, the sdt and sde, with the latter being affected the most. However, we remind the reader that the analysis of results in this paper was based on comparisons to a hypothetical (non-existent) median system. According to the official preliminary analysis (Legal Track's overview paper in TREC Notebook), our ranking was the 3rd best in recall at 30%, and the 2nd best in Area Under the receiver operating characteristic Curve (AUC). AUC is a measure of the quality of the ranking, independent of the submitted probability estimates. Second, sde and lrg must be greatly affected by biases in the training set; sdt does not use training data. Both former methods assume training data uniformly sampled from the collection, which is clearly not the case here. Our heuristic to remove some of the bias in lrg by assuming 100,000 non-relevant documents scoring at zero does seem to have helped however. Nevertheless, this was an arbitrary number.</p><p>Third, the KDE methods used in sde was found to be very sensitive to the choice of bandwidth, influencing greatly the resulting probability estimates. We will report on these and other issues more extensively in further work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,119.25,205.29,134.14,126.16"><head>Table 1 :</head><label>1</label><figDesc>Original/given seed set</figDesc><table coords="2,119.25,226.77,134.14,104.68"><row><cell cols="3">Topic Relevant Non-relevant</cell></row><row><cell>200</cell><cell>230</cell><cell>620</cell></row><row><cell>201</cell><cell>168</cell><cell>523</cell></row><row><cell>202</cell><cell>1006</cell><cell>403</cell></row><row><cell>203</cell><cell>67</cell><cell>892</cell></row><row><cell>204</cell><cell>59</cell><cell>1132</cell></row><row><cell>205</cell><cell>333</cell><cell>1506</cell></row><row><cell>206</cell><cell>19</cell><cell>336</cell></row><row><cell>207</cell><cell>80</cell><cell>511</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,119.25,445.40,134.14,124.14"><head>Table 2 :</head><label>2</label><figDesc>Effective seed set</figDesc><table coords="2,119.25,464.87,134.14,104.68"><row><cell cols="3">Topic Relevant Non-relevant</cell></row><row><cell>200</cell><cell>230</cell><cell>596</cell></row><row><cell>201</cell><cell>168</cell><cell>520</cell></row><row><cell>202</cell><cell>994</cell><cell>396</cell></row><row><cell>203</cell><cell>67</cell><cell>876</cell></row><row><cell>204</cell><cell>59</cell><cell>1122</cell></row><row><cell>205</cell><cell>333</cell><cell>1496</cell></row><row><cell>206</cell><cell>19</cell><cell>323</cell></row><row><cell>207</cell><cell>80</cell><cell>492</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,153.89,141.40,303.47,78.74"><head>Table 3 :</head><label>3</label><figDesc>Ranking quality.</figDesc><table coords="5,153.89,162.89,303.47,57.26"><row><cell></cell><cell cols="6">200 201 202 203 204 205 206 207</cell><cell>avg.</cell></row><row><cell cols="8">hyp. F1 8.9 11.6 32.1 24.2 8.2 51.4 7.6 16.7 20.08</cell></row><row><cell>best</cell><cell cols="6">25.8 43.0 70.6 39.4 26.6 52.1 37.0 90.3</cell><cell>-</cell></row><row><cell>median</cell><cell cols="7">8.9 14.1 38.2 24.2 10.3 47.2 12.9 19.1 21.86</cell></row><row><cell>worst</cell><cell>1.8</cell><cell>1.5</cell><cell>4.5</cell><cell>3.2</cell><cell>5.3 18.0 3.4</cell><cell>6.7</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,154.42,262.13,302.41,102.97"><head>Table 4 :</head><label>4</label><figDesc>% accuracy of R estimates.</figDesc><table coords="5,154.42,283.94,302.41,81.17"><row><cell></cell><cell cols="8">200 201 202 203 204 205 206 207</cell><cell>avg.</cell></row><row><cell>lrg</cell><cell cols="6">14.5 39.4 27.3 91.2 40.6 29.3</cell><cell cols="3">5.2 78.3 40.73</cell></row><row><cell>sde</cell><cell cols="3">4.1 21.9 24.3</cell><cell>0.9</cell><cell>1.3</cell><cell>1.0</cell><cell cols="2">3.1 18.6</cell><cell>9.40</cell></row><row><cell>sdt</cell><cell cols="7">15.4 18.1 14.7 22.9 99.4 16.4 77.4</cell><cell cols="2">9.9 34.28</cell></row><row><cell>best</cell><cell cols="8">75.3 93.7 93.3 91.2 99.4 69.4 77.4 89.4</cell><cell>-</cell></row><row><cell cols="7">median 15.4 28.2 48.8 39.9 49.7 31.1</cell><cell cols="3">4.8 32.0 31.24</cell></row><row><cell>worst</cell><cell>0.9</cell><cell>0.8</cell><cell>2.0</cell><cell>0.9</cell><cell>1.3</cell><cell>1.0</cell><cell>0.3</cell><cell>7.2</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,154.42,407.09,302.41,102.97"><head>Table 5 :</head><label>5</label><figDesc>% accuracy of the F 1 estimates.</figDesc><table coords="5,154.42,428.90,302.41,81.17"><row><cell></cell><cell cols="8">200 201 202 203 204 205 206 207</cell><cell>avg.</cell></row><row><cell>lrg</cell><cell cols="6">8.2 13.1 23.6 42.4 15.3 36.6</cell><cell cols="3">4.7 15.9 19.98</cell></row><row><cell>sde</cell><cell cols="3">36.6 74.3 33.6</cell><cell>5.9</cell><cell>2.0</cell><cell>1.8</cell><cell cols="3">6.3 20.8 22.66</cell></row><row><cell>sdt</cell><cell>12.0</cell><cell cols="3">7.2 27.7 32.4</cell><cell cols="5">6.0 29.6 11.0 15.5 17.68</cell></row><row><cell>best</cell><cell cols="8">98.8 97.4 91.4 93.9 79.5 95.5 34.6 94.9</cell><cell>-</cell></row><row><cell cols="10">median 12.5 19.8 23.6 29.8 15.3 59.0 11.3 38.1 26.18</cell></row><row><cell>worst</cell><cell>1.5</cell><cell>1.3</cell><cell>2.5</cell><cell>2.4</cell><cell>2.0</cell><cell>1.8</cell><cell>0.4</cell><cell>2.9</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,154.42,552.05,302.41,102.97"><head>Table 6 :</head><label>6</label><figDesc>% accuracy of the K estimates.</figDesc><table coords="5,154.42,573.86,302.41,81.17"><row><cell></cell><cell cols="8">200 201 202 203 204 205 206 207</cell><cell>avg.</cell></row><row><cell>lrg</cell><cell cols="4">18.8 17.8 12.0 53.4</cell><cell cols="2">5.7 27.5</cell><cell cols="3">1.1 30.8 20.89</cell></row><row><cell>sde</cell><cell cols="3">11.6 22.0 39.3</cell><cell>0.3</cell><cell>0.0</cell><cell>0.5</cell><cell cols="3">0.9 21.1 11.97</cell></row><row><cell>sdt</cell><cell cols="6">26.2 12.3 39.3 28.2 10.6 15.0</cell><cell cols="3">5.2 20.9 19.71</cell></row><row><cell>best</cell><cell cols="8">90.4 87.6 99.8 78.1 89.5 91.2 26.8 99.3</cell><cell>-</cell></row><row><cell cols="7">median 11.6 12.3 32.6 37.8 15.6 42.4</cell><cell cols="3">4.7 25.7 22.84</cell></row><row><cell>worst</cell><cell>0.3</cell><cell>0.7</cell><cell>0.6</cell><cell>0.3</cell><cell>0.0</cell><cell>0.5</cell><cell>0.1</cell><cell>1.3</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,324.95,667.75,145.26,6.31"><p>http://www.lemurproject.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,327.20,144.52,212.04,8.64;6,327.20,156.31,212.04,8.81;6,327.20,168.43,22.42,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,461.48,144.52,77.77,8.64;6,327.20,156.48,68.57,8.64">Where to stop reading a ranked list?</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,411.43,156.31,123.04,8.81">Proceedings TREC 2008. NIST</title>
		<meeting>TREC 2008. NIST</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,188.36,212.04,8.64;6,327.20,200.31,212.04,8.64;6,327.20,212.27,212.04,8.64;6,327.20,224.06,212.04,8.81;6,327.20,236.18,22.42,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,348.39,200.31,190.85,8.64;6,327.20,212.27,192.87,8.64">Where to stop reading a ranked list? Threshold optimization using truncated score distributions</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,327.20,224.06,88.70,8.58">Proceedings SIGIR&apos;09</title>
		<meeting>SIGIR&apos;09</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,256.11,212.04,8.64;6,327.20,267.89,212.05,8.81;6,327.20,279.85,124.38,8.81" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,500.50,256.11,38.74,8.64;6,327.20,268.06,168.44,8.64">Modeling score distributions in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,503.83,267.89,35.42,8.58;6,327.20,279.85,52.97,8.58">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="26" to="46" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,299.94,212.04,8.64;6,327.20,311.90,212.04,8.64;6,327.20,323.68,212.04,8.81;6,327.20,335.81,138.24,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,496.80,299.94,42.44,8.64;6,327.20,311.90,212.04,8.64;6,327.20,323.85,95.62,8.64">The scoredistributional threshold optimization for adaptive binary classification tasks</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">André</forename><surname>Van Hameren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,445.62,323.68,89.11,8.58">Proceedings SIGIR&apos;01</title>
		<meeting>SIGIR&apos;01</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,355.56,212.04,8.81;6,327.20,367.69,80.53,8.64" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,372.80,355.56,110.62,8.58">The Analysis of Binary Data</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,387.61,212.04,8.64;6,327.20,399.57,212.04,8.64;6,327.20,411.52,212.04,8.64;6,327.20,423.31,212.04,8.81;6,327.20,435.43,48.80,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,488.88,399.57,50.37,8.64;6,327.20,411.52,212.04,8.64;6,327.20,423.48,81.88,8.64">Probabilistic learning approaches for indexing and retrieval with the trec-2 collection</title>
		<author>
			<persName coords=""><forename type="first">Norbert</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ulrich</forename><surname>Pfeifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><surname>Bremkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Pollmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,434.63,423.31,100.13,8.58">Proceedings TREC 1993</title>
		<meeting>TREC 1993</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,455.36,212.04,8.64;6,327.20,467.31,212.04,8.64;6,327.20,479.10,212.04,8.81;6,327.20,491.22,138.24,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,327.20,467.31,212.04,8.64;6,327.20,479.27,91.90,8.64">Modeling score distributions for combining the outputs of search engines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Toni</forename><forename type="middle">M</forename><surname>Rath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fangfang</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,444.98,479.10,89.75,8.58">Proceedings SIGIR&apos;01</title>
		<meeting>SIGIR&apos;01</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="267" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,510.98,212.04,8.81;6,327.20,522.94,212.05,8.81;6,327.20,535.06,110.81,8.64" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Ripley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L</forename><surname>Hjort</surname></persName>
		</author>
		<title level="m" coord="6,459.68,510.98,79.57,8.58;6,327.20,522.94,84.91,8.58">Pattern Recognition and Neural Networks</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,327.20,554.82,212.04,8.81;6,327.20,566.77,212.04,8.58;6,327.20,578.90,106.41,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,402.37,554.82,136.88,8.58;6,327.20,566.77,91.41,8.58">All of Statistics: A Concise Course in Statistical Inference</title>
		<author>
			<persName coords=""><forename type="first">Larry</forename><surname>Wasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,426.12,566.77,106.16,8.58">Springer Texts in Statistics</title>
		<imprint>
			<date type="published" when="2004-09">September 2004</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
