<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.20,71.96,313.29,16.59;1,99.12,91.88,411.49,16.59">University of Glasgow at TREC 2010: Experiments with Terrier in Blog and Web tracks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,119.52,137.15,100.41,10.76"><forename type="first">Rodrygo</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
							<email>rodrygo@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.81,137.15,91.10,10.76"><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
							<email>richardm@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.63,137.15,80.63,10.76"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
							<email>craigm@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,437.40,137.15,52.94,10.76"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<email>ounis@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.20,71.96,313.29,16.59;1,99.12,91.88,411.49,16.59">University of Glasgow at TREC 2010: Experiments with Terrier in Blog and Web tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B7B15C597FCB6E7BBFCB31B3B513D678</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In TREC 2010, we continue to build upon the Voting Model and experiment with our novel xQuAD framework within the auspices of the Terrier IR Platform. In particular, our focus is the development of novel applications for data-driven learning in the Blog and Web tracks, with experimentation spanning hundreds of features. In the Blog track, we propose novel feature sets for the ranking of blogs, news stories and blog posts. In the Web track, we propose novel selective approaches for adhoc and diversity search.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In TREC 2010, we participate in the Blog track faceted blog distillation and top story identification tasks, as well as the Web track adhoc and diversity tasks. Our focus is the development of novel applications for data-driven learning to each of these tasks using the Terrier IR platform <ref type="bibr" coords="1,158.21,418.56,13.70,8.07" target="#b11">[11]</ref>, increasing effectiveness through large-scale experiments using hundreds of individual features.</p><p>In the blog distillation task of the Blog track, we deploy machine learning techniques to learn both the ranking of blogs for a query, and their inclination given the facet of the query. For the top news stories identification task, we build upon our effective voting approach and experiment with data-driven learning both to rank news stories for a single day, and also to rank blog posts for a single story.</p><p>The major goal of our participation in the Web track is to investigate novel data-driven selective approaches, based on a large set of document and query features. In the adhoc task, we seek to determine, on a per-query basis, the most appropriate ranking model to be applied. In the diversity task, for each query, we determine not only whether to diversify, but also by how much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BLOG TRACK: FACETED BLOG DISTILLATION TASK</head><p>We investigate novel data-driven approaches for both the baseline and faceted blog distillation tasks of the Blog track. In particular, in the baseline blog distillation task, the aim is to identify blogs which have a principle, recurring interest in the query topic, while in the faceted task, these blogs should be further ranked with respect to a facet inclination of interest, namely opinionated, factual, indepth, shallow, personal, and official.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Baseline Blog Distillation</head><p>In our participation to the baseline blog distillation task, we extend the Voting Model <ref type="bibr" coords="1,141.05,711.24,9.51,8.07" target="#b5">[5]</ref>, which has previously been shown to Table <ref type="table" coords="1,340.32,296.04,3.71,8.07">1</ref>: Results of the submitted runs to the baseline blog distillation task.</p><p>be effective for identifying key blogs <ref type="bibr" coords="1,453.26,334.32,9.51,8.07" target="#b6">[6]</ref>. In particular, the Voting Model specifies many voting techniques, each of which aggregates evidence from a single ranking of blog posts to produce a ranking of blogs. However, instead of using a single blog post ranking and a single voting technique, we propose a novel approach to learn the aggregation of different rankings of blog posts with multiple voting techniques <ref type="bibr" coords="1,372.84,397.08,9.51,8.07">[7]</ref>. As a result, we mix the qualities of different voting techniques into a learned ensemble <ref type="bibr" coords="1,471.38,407.64,9.51,8.07">[7]</ref>. A total of 450 voting technique features are combined using the Metzler's Automatic Feature Selection (AFS) learning to rank technique <ref type="bibr" coords="1,500.46,428.52,13.70,8.07" target="#b10">[10]</ref>, trained on the TREC 2009 blog distillation task. We submitted two runs to the baseline blog distillation task, summarised below:</p><p>• uogTrapeMN5k: expCombMNZ voting technique, using the top 5000 blog posts ranked by DPH.</p><p>• uogTrLv450: learned ranking, combining many voting techniques, using a total of 450 features.</p><p>The results of our submitted runs are given in Table <ref type="table" coords="1,513.20,533.40,3.34,8.07">1</ref>. From the results, we note that both of our submitted runs outperformed the TREC median MAP. Moreover, we find that our learned approach to blog distillation is promising, as uogTrLv450 successfully improves over the early precision of the uogTrapeMN5k run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Faceted Blog Distillation</head><p>Following our data-driven theme, for the faceted blog distillation task we also apply machine learning techniques for identifying and appropriately ranking the facet inclination of a blog.</p><p>In particular, to identify the facet inclination of every retrieved blog, we deploy many features, including blog post-level and bloglevel features. For instance, the number of inlinks, or the presence of opinionated terms <ref type="bibr" coords="1,395.54,669.36,10.43,8.07" target="#b4">[4]</ref> are examples of blog post-level features that we deploy. Additionally, inspired by the work of He et al. <ref type="bibr" coords="1,545.52,679.80,10.43,8.07" target="#b4">[4]</ref> at identifying opinionated terms, we identify a dictionary of terms for each facet inclination using the relevance assessments of the TREC 2009 faceted blog distillation task. Using all of the terms in the dictionaries for each facet inclination, facet inclination feature scores for each blog post are obtained. All features are combined with the baseline blog retrieval score, in two different manners: In our first approach, we combine all features with the baseline blog retrieval score using a learning to rank approach. Secondly, we use a classifier to build a classification model using all features for each facet inclination, before integrating the confidence of the classifier with the baseline retrieval score.</p><p>We submitted four groups of runs to the faceted blog distillation task, using four baselines runs (uogTrfL728, stdbaseline1, stdbase-line2 -which is uogTrapeMN5k from Section 2.1 -and stdbase-line3). Our groups of runs, which are summarised below, use both learning to rank and classification approaches to facet ranking, and mix feature sets with and without the use of dictionary features:</p><p>• uogTrfL728: learned ranker, based on 728 features.</p><p>• uogTrfL919: learned ranker, based on 728 features, plus an additional 191 dictionary features for facet inclinations, totalling 919 features in all.</p><p>• uogTrfC728: Using the same 728 features as uogTrfL728, but using a classifier to permit the re-ranking of results by their classified inclination.</p><p>• uogTrfC919: As uogTrfC728, but using the same feature set as uogTrfL919.</p><p>Table <ref type="table" coords="2,85.80,341.63,4.48,8.07" target="#tab_0">2</ref> details the performance of our submitted faceted blog distillation runs, in terms of MAP for each facet inclination, and the mean over all inclinations. From the results, we make the following observations and conclusions:</p><p>• Our learned approaches, namely uogTrfL728 &amp; uogTrfL919 generally perform higher than the classification approaches (uogTrfC728 &amp; uogTrfC919).</p><p>• Comparing the number of features (728 vs. 919), we note that the used feature set has a different impact according to the deployed learning techniques and baseline.</p><p>• Runs based on the first of the TREC provided baselines, namely stdbaseline1, perform the best for each group of runs. This highlights the importance of a strong baseline, as this is the highest performing of the baselines that we deploy.</p><p>Overall, we conclude that our feature sets and learned approaches are effective for faceted blog distillation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">BLOG TRACK: TOP STORIES IDENTIFICATION TASK</head><p>In the top stories identification task, the goal is to produce a set of important stories for a day in question, as well as a high quality and diversified ranking of blog posts for those stories. In particular, the task comes in two distinct stages, namely news story ranking and blog post ranking. During news story ranking, for a set of query days, the stories published on each day are to be ranked by their newsworthiness on that day for each of five news categories, namely U.S., World, Sport, Business and Science/Technology. This tasks mimics a real-time setting, where blog post evidence after the time of the query cannot be used. For blog post ranking, given a set of news stories, blog posts are ranked based upon their relevance for these stories, as well as in terms of their diversity in covering different aspects of each story.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">News Story Ranking</head><p>In the top stories ranking task, we adopt a data-driven learning approach. In particular, we learn how to rank stories by their predicted importance based on the blogosphere, by inferring the magnitude of blogging activities as well as the usefulness of story representations as features. In particular, we assume that bloggers will create posts pertaining to prominent news stories for each day. Therefore, we consider that the relative magnitude of this posting activity in comparison to previous days is indicative of a story's importance on those days. To measure this blogging activity, we employ two effective voting techniques -firstly, ranking stories by their votes from blog posts <ref type="bibr" coords="2,415.84,175.19,10.43,8.07" target="#b8">[8]</ref> (referred to as Votes), and secondly a new voting technique, referred to as Relevance Weighted Aggregation (RWA), which accounts for both the relevance of blog posts in addition to their volume.</p><p>To classify each news story into the task categories, we leverage crowdsourcing to create training labels for an open source ngram language model classifier provided by LingPipe <ref type="foot" coords="2,488.52,236.15,2.99,5.38" target="#foot_0">1</ref> . In particular, we use Amazon's Mechanical Turk<ref type="foot" coords="2,432.24,246.59,2.99,5.38" target="#foot_1">2</ref> to label 3000 randomly sampled news stories from days predating the Blogs08 timespan. We integrate the classification labels in the category ranking in three different regimes: strict, lax and balanced. Strict considers stories to belong to only the most likely category, lax classifies stories into multiple likely categories using a low threshold upon the classifier confidence for each category, while balanced similarly classifies each story into multiple classes using a higher threshold.</p><p>We submitted 3 story ranking task runs. In particular, we submitted one baseline run (uogTrCh) which uses only our best voting technique, and two learned runs using either 151 restricted (safer) features or 1076 features respectively. These learned runs were trained on the 2009 top news stories ranking topics using Metzler's Automatic Feature Selection (AFS) learning to rank technique <ref type="bibr" coords="2,538.67,384.35,13.70,8.07" target="#b10">[10]</ref>. Note that each run uses a different classification regime. Our submitted runs are as follows:</p><p>• uogTrCh: Our Relevance Weighted Aggregation voting technique, upon the headline alone using a balanced classifier.</p><p>• uogTrLC151: A learned run using an intuitive set of 151 features from RWA. These features represent two story representations (headline and content), story ranking evidence from the two days preceding the query day and varying time ranges from which voting blog posts can be selected. Stories were classified by the strict classifier.</p><p>• uogTrLV1076: A learned run, using 1076 features produced from Votes and RWA. These features encompass eight different story representations, story ranking evidence from the seven days preceding the query day and varying time ranges from which voting blog posts can be selected. Stories were classified using the lax classifier.</p><p>Table <ref type="table" coords="2,347.76,590.51,4.48,8.07" target="#tab_1">3</ref> reports story ranking performance of our submitted runs in comparison to the TREC best systems. In particular, column 2 reports the story ranking performance under the official relevance assessments, i.e. after stories have been classified into the five news categories, while column 3 reports story ranking performance in general, i.e. pre-classification. To calculate pre-classification performance, we assume that if a story was important to any category then it was important overall. From Table <ref type="table" coords="2,474.30,663.83,3.34,8.07" target="#tab_1">3</ref>, we observe that the post-classification (official) performance of our submitted runs is lower than anticipated. However, we also see from column 3, that  in terms of pre-classification story ranking, our runs offer similar performance to that attained by the TREC best systems. This indicates that while our unlearned model is effective at ranking news stories, our classifier requires further improvement. Furthermore, we observe that pre-classification, our learned models (uogTrLC151 and uogTrLV1076) are less effective than the baseline. Analysis of these runs indicate that this results from poor feature generalisation between the 2009 and 2010 topics. For example, the most effective story representation (the strongest ranking feature) on the 2009 topics was the headline, while on the 2010 topics, the content was markedly more effective. Indeed, when ranking with the content, the unlearned model can achieve a preclassification performance of 0.2080 statMAP, higher than the best TREC systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Blog Post Ranking</head><p>To rank blog posts with regard to a news story, we similarly employ a data-driven approach, this time to learn the features of blog posts that are most useful when ranking with regard to story relevance. In this way, we aim to improve upon our effective DPH baseline blog post ranking used during TREC 2009. In particular, we leverage 81 different blog post features. Our proposed approach learns the extent to which each of these features is useful when ranking blog posts for a news story. In addition, we leverage information from the set of entities covered by the story, as well as the possible facet inclinations of the blog posts, in order to produce a diverse ranking within our xQuAD framework <ref type="bibr" coords="3,228.26,652.44,13.70,8.07" target="#b18">[18]</ref>.</p><p>We submitted 3 blog post ranking task runs. In particular, we submitted one adhoc learned run, and two diversified runs, each using a different representation for the aspects of each story.</p><p>• uogTrL81: A learned model which uses 81 blog post features, including retrieval, link-based and opinionatedness met- rics. This model was trained on the TREC 2009 blog post ranking topics using AFS <ref type="bibr" coords="3,432.74,352.68,13.70,8.07" target="#b10">[10]</ref>.</p><p>• uogTrdxE: A DPH ranking explicitly diversified using xQuAD, with different story aspects represented by extracted entities.</p><p>• uogTrdxF: As uogTrdxE, except that story aspects are represented by different facet inclinations.</p><p>Table <ref type="table" coords="3,348.48,420.60,4.48,8.07" target="#tab_2">4</ref> reports the performance of our three submitted runs in terms of the official TREC measure (α-nDCG@10). We observe that our learned model that uses 81 blog post features (uogTrL81) is effective at ranking blog posts related to each news story. Indeed, uogTrL81 markedly outperforms the TREC median for this task. On the other hand, our diversified runs do not perform as effectively as the learned model, indicating that neither our identified entities nor facet inclinations are sufficient to represent the aspects underlying a news story and its related blog posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">WEB TRACK: ADHOC TASK</head><p>In the adhoc task, we use a novel framework for selective information retrieval. Our novel selective framework automatically decides which ranking model (from a set of candidate learned models) is the most appropriate for an unseen query <ref type="bibr" coords="3,473.60,570.96,13.70,8.07" target="#b13">[13]</ref>. Similarly to <ref type="bibr" coords="3,538.67,570.96,13.70,8.07" target="#b17">[17]</ref>, we use many query features to decide on the best ranking model, given an unseen query.</p><p>In our participation, we use learning to rank to obtain effective candidate models and runs. In particular, we create learned models using pools of 42 and 67 features, summarised in Table <ref type="table" coords="3,514.00,623.28,3.34,8.07" target="#tab_4">5</ref>. All models are learned using TREC 2009 Web track training data and the AFS learning to rank technique <ref type="bibr" coords="3,435.52,644.28,13.70,8.07" target="#b10">[10]</ref>. Our novel selective framework chooses the most appropriate model for each query, based on over 700 query features, also summarised in Table <ref type="table" coords="3,498.92,665.16,3.34,8.07" target="#tab_4">5</ref>.</p><p>Three runs were submitted to the adhoc task:</p><p>• uogTrA42 (cat. A) deploys ranking models learned on Web queries using document features selected from pools of 42 features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Groups Document Features</head><p>Total Query Features (most from <ref type="bibr" coords="4,478.29,55.04,12.68,7.17" target="#b17">[17]</ref>) Total 42 feat. 67 feat.</p><p>Weighting models (DPH <ref type="bibr" coords="4,203.28,64.40,8.42,7.17" target="#b1">[1]</ref>, PL2 <ref type="bibr" coords="4,231.87,64.40,8.42,7.17" target="#b1">[1]</ref>, BM25 <ref type="bibr" coords="4,267.60,64.40,12.68,7.17" target="#b15">[15]</ref>) 25 NGram features 11 Fields-based models (BM25F <ref type="bibr" coords="4,219.45,73.40,12.15,7.17" target="#b19">[19]</ref>, PL2F <ref type="bibr" coords="4,256.44,73.40,8.92,7.17" target="#b1">[1]</ref>) 2 Query ambiguity 121 URL and link analysis features (e.g. PageRank, Absorbing Model <ref type="bibr" coords="4,334.56,82.28,12.68,7.17" target="#b14">[14]</ref>) 14 Query log mining 14 Spam feature (Cormack's fusion score <ref type="bibr" coords="4,246.46,91.28,8.92,7.17" target="#b2">[2]</ref>) 1 Query performance predictors 7 Term-dependence models (MRF <ref type="bibr" coords="4,228.00,100.28,8.42,7.17" target="#b9">[9]</ref>, pBiL <ref type="bibr" coords="4,259.72,100.28,12.68,7.17" target="#b12">[12]</ref>) 25 Taxonomy-based features 604 • uogTrB67 (cat. B) deploys ranking models learned on Web queries using document features selected from pools of 67 features.</p><p>• uogTrB67LTS (cat. B) deploys our novel selective framework for automatically selecting an appropriate ranking model on a per-query basis.</p><p>Table <ref type="table" coords="4,84.36,320.52,4.48,8.07" target="#tab_5">6</ref> shows the results of our submitted runs to the adhoc task. From the table, we observe that all runs perform markedly above the TREC median. However, we later found that our anchor text and URL representations were not indexed correctly. To address this issue, Table <ref type="table" coords="4,117.72,362.40,4.48,8.07" target="#tab_5">6</ref> also shows the performance of an equivalent corrected run to uogTrB67, denoted uogTrB67*. We can see that the corrected run uogTrB67* improves nDCG@20 and ERR@20 compared to uogTrB67. uogTrB67LTS, which deploys an appropriate ranking model on a per-query basis, attains the highest cat. B P@10, attesting the effectiveness of our novel selective framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">WEB TRACK: DIVERSITY TASK</head><p>Our participation in the diversity task builds upon our state-ofthe-art xQuAD framework <ref type="bibr" coords="4,150.46,460.68,14.12,8.07" target="#b16">[16,</ref><ref type="bibr" coords="4,166.66,460.68,11.12,8.07" target="#b17">17,</ref><ref type="bibr" coords="4,179.98,460.68,10.59,8.07" target="#b18">18]</ref>. Based on an initial ranking R for the query q, xQuAD iteratively builds a re-ranking S by selecting, at each iteration, a document d * ∈ R \ S such that:</p><formula xml:id="formula_0" coords="4,85.32,494.52,207.58,17.90">d * = arg max d∈R\S (1 -λ) Pr(d|q) + λ Pr(d, S|q),<label>(1)</label></formula><p>where Pr(d|q) is the probability of a document d satisfying the query q and Pr(d, S|q) is the probability of this document but none of the documents already in S satisfying q. In practice, these two probabilities can be thought of as representing the relevance and the diversity of d, respectively, with the parameter λ controlling the trade-off between the two probabilities. Additionally, the probability Pr(d, S|q) can be further expanded according to:</p><formula xml:id="formula_1" coords="4,62.64,598.32,230.26,22.03">Pr(d, S|q) = X s i ∈Q Pr(si|q) Pr(d|q, si) Y d j ∈S Pr( dj|q, si),<label>(2)</label></formula><p>where the sub-query si ∈ Q represents one of the multiple possible aspects underlying the query q, Pr(si|q) represents the importance of this sub-query in light of q, Pr(d|q, si) estimates the coverage of d with respect to si, and Q Pr( dj|q, si) estimates the novelty of any document satisfying si, in terms of how badly this sub-query is satisfied by the previously selected documents dj ∈ S.</p><p>In TREC 2010, we have two main research directions. Firstly, we investigate whether xQuAD can be improved by enhancing the estimations of Pr(d|q) (i.e., the relevance component) and Pr(d|q, si) (i.e., the coverage and novelty components) using learning-to-rank (LTR). Secondly, we investigate whether setting the trade-off parameter λ on a per-query basis can further improve xQuAD's performance. The latter research direction entails a selective approach to search result diversification, whereby we decide, for each query, not only whether to diversify, but also by how much <ref type="bibr" coords="4,505.24,201.48,13.70,8.07" target="#b17">[17]</ref>.</p><p>For our submitted runs, we generate sub-queries for each of the TREC 2010 queries based on query reformulations from Bing and Google <ref type="bibr" coords="4,346.80,232.80,13.70,8.07" target="#b18">[18]</ref>. For learning the relevance, coverage, and novelty components, we leverage the same document features used for our adhoc runs described in Section 4. For predicting the diversification trade-off λ, we deploy two different regimes:</p><p>• UNI, where we uniformly set the same λ value for all queries, based on the optimal value observed using all the 50 TREC 2009 queries for training.</p><p>• SEL, where we selectively set λ for each individual query q as the average optimal λ value observed for the three most similar queries to q from TREC 2009.</p><p>For the SEL regime, similar training queries are identified using a kNN classifier and the 757 query features described in Table <ref type="table" coords="4,535.88,372.24,3.34,8.07" target="#tab_4">5</ref>.</p><p>We produced a total of ten runs in the diversity task, three of which were officially submitted as per our participation:</p><p>• uogTrA42 (A, submitted) is a LTR adhoc run, as described in Section 4.</p><p>• uogTrA42x (A, submitted) applies xQuAD using uogTrA42 as the relevance component, with coverage and novelty estimated by DPH, and the trade-off λ set uniformly.</p><p>• uogTrBdph (B, unofficial) is an adhoc run based on DPH.</p><p>• uogTrBdphx (B, unofficial) applies xQuAD using uogTrBdph as the relevance component, with coverage and novelty estimated by DPH, and the trade-off λ set uniformly.</p><p>• uogTrBdphxS (B, submitted) is similar to uogTrBdphx, except that the trade-off λ is set selectively.</p><p>• uogTrB67 (B, submitted) is a learning-to-rank adhoc run, as described in Section 4.</p><p>• uogTrB67x (B, unofficial) applies xQuAD using uogTrB67 as the relevance component, with coverage and novelty estimated by DPH, and the trade-off λ set uniformly.</p><p>• uogTrB67xS (B, submitted) is similar to uogTrB67x, except that the trade-off λ is set selectively.</p><p>• uogTrB67lx (B, unofficial) is similar to uogTrB67x, except that the diversity components are based on LTR.</p><p>• uogTrB67lxS (B, unofficial) is similar to uogTrB67lx, except that the trade-off λ is set selectively. Table <ref type="table" coords="5,84.24,222.48,4.48,8.07" target="#tab_6">7</ref> shows the results of our unofficial as well as our officially submitted runs to the diversity task. The struck out line indicates a bug in the submitted uogTrB67xS run, which mistakenly used the wrong predicted λ values. The table is organised into three main groups, according to the run that served as the adhoc baseline in each case (i.e., uogTrA42, uogTrdph, and uogTrB67).</p><p>In the first group, we observe that xQuAD (uogTrA42x) successfully improves upon the adhoc baseline (uogTrA42) according to all considered measures. In the second group, we note that xQuAD (uogTrdphx) also improves upon the adhoc baseline (uogTrBdph), with further improvements observed when the selective regime is deployed (uogTrBdphxS). In the third group, similar results are observed when deploying xQuAD uniformly (uogTrB67x) or selectively (uogTrB67xS) on top of the adhoc baseline (uogTrB67). Analysing the impact of learning the coverage and novelty components, we observe that an estimation of these components based on LTR (uogTrB67lx) only improves compared to when DPH is used (uogTrB67x) in terms of α-nDCG@20, with slight decreases in terms of the other measures. However, when the selective regime is considered, using LTR brings further improvements (uogTrB67lxS vs. uogTrB67xS), with uogTrB67lxS attaining our overall best performance. In fact, based on the preliminary evaluations of all participants' runs (i.e., with 36 of the final 48 topics), uogTrB67lxS (ERR-IA@20 = 0.367, α-nDCG@20 = 0.509) would have ranked just above the top-performing run, uwgym (ERR-IA@20 = 0.356, α-nDCG@20 = 0.500), which was produced by querying a commercial search engine <ref type="bibr" coords="5,135.88,494.40,9.51,8.07" target="#b3">[3]</ref>. This observation further attests the effectiveness of our xQuAD framework <ref type="bibr" coords="5,191.74,504.83,14.12,8.07" target="#b16">[16,</ref><ref type="bibr" coords="5,208.42,504.83,11.87,8.07" target="#b18">18]</ref> and the potential of enhancing its underlying components, whether through learningto-rank or our proposed selective diversification approach <ref type="bibr" coords="5,262.44,525.83,13.70,8.07" target="#b17">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>In TREC 2010, we participated in the Blog and Web tracks using our Terrier IR platform. In particular, our participation focused around novel data-driven approaches, as well as improved applications of the Voting Model, enhanced search result diversification using xQuAD, and new selective approaches to ranking Web documents. Our results attest the effectiveness of our deployed machine learning approaches to both Blog and Web retrieval tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,81.48,55.04,406.58,279.57"><head>Table 2 : Results of the submitted runs to the faceted blog distillation task.</head><label>2</label><figDesc></figDesc><table coords="3,81.48,55.04,406.58,279.57"><row><cell>Run</cell><cell></cell><cell>Baseline</cell><cell>Mean Facet MAP</cell><cell cols="5">MAP by Facet opinionated factual official personal indepth shallow</cell></row><row><cell cols="2">uogTrfC728</cell><cell>uogTrLv450</cell><cell>0.0873</cell><cell>0.0883</cell><cell>0.0493 0.0461</cell><cell>0.0729</cell><cell>0.1261</cell><cell>0.1409</cell></row><row><cell cols="3">uogTrfC728s1 stdbaseline1</cell><cell>0.1383</cell><cell>0.2539</cell><cell>0.0783 0.1006</cell><cell>0.0619</cell><cell>0.2298</cell><cell>0.1051</cell></row><row><cell cols="3">uogTrfC728s2 stdbaseline2</cell><cell>0.1045</cell><cell>0.0841</cell><cell>0.2002 0.0729</cell><cell>0.0373</cell><cell>0.1070</cell><cell>0.1255</cell></row><row><cell cols="3">uogTrfC728s3 stdbaseline3</cell><cell>0.0619</cell><cell>0.0641</cell><cell>0.0395 0.0673</cell><cell>0.0415</cell><cell>0.0760</cell><cell>0.0828</cell></row><row><cell cols="2">uogTrfC919</cell><cell>uogTrLv450</cell><cell>0.0890</cell><cell>0.1044</cell><cell>0.0426 0.0570</cell><cell>0.0707</cell><cell>0.1100</cell><cell>0.1496</cell></row><row><cell cols="3">uogTrfC919s1 stdbaseline1</cell><cell>0.1386</cell><cell>0.2406</cell><cell>0.0797 0.0983</cell><cell>0.0747</cell><cell>0.2347</cell><cell>0.1037</cell></row><row><cell cols="3">uogTrfC919s2 stdbaseline2</cell><cell>0.0958</cell><cell>0.1053</cell><cell>0.1296 0.0739</cell><cell>0.0365</cell><cell>0.1312</cell><cell>0.0981</cell></row><row><cell cols="3">uogTrfC919s3 stdbaseline3</cell><cell>0.0711</cell><cell>0.1001</cell><cell>0.0341 0.0602</cell><cell>0.0549</cell><cell>0.0854</cell><cell>0.0921</cell></row><row><cell cols="2">uogTrfL728</cell><cell>uogTrLv450</cell><cell>0.1058</cell><cell>0.0885</cell><cell>0.1661 0.0907</cell><cell>0.0876</cell><cell>0.1256</cell><cell>0.0761</cell></row><row><cell cols="3">uogTrfL728s1 stdbaseline1</cell><cell>0.1730</cell><cell>0.2417</cell><cell>0.1365 0.1486</cell><cell>0.1012</cell><cell>0.2971</cell><cell>0.1129</cell></row><row><cell cols="3">uogTrfL728s2 stdbaseline2</cell><cell>0.1026</cell><cell>0.0991</cell><cell>0.1847 0.0728</cell><cell>0.0499</cell><cell>0.1258</cell><cell>0.0835</cell></row><row><cell cols="3">uogTrfL728s3 stdbaseline3</cell><cell>0.0815</cell><cell>0.0487</cell><cell>0.1323 0.0541</cell><cell>0.0713</cell><cell>0.0913</cell><cell>0.0916</cell></row><row><cell cols="2">uogTrfL919</cell><cell>uogTrLv450</cell><cell>0.0982</cell><cell>0.0875</cell><cell>0.0540 0.1140</cell><cell>0.0954</cell><cell>0.1309</cell><cell>0.1076</cell></row><row><cell cols="3">uogTrfL919s1 stdbaseline1</cell><cell>0.1837</cell><cell>0.2440</cell><cell>0.1369 0.2456</cell><cell>0.1017</cell><cell>0.2578</cell><cell>0.1162</cell></row><row><cell cols="3">uogTrfL919s2 stdbaseline2</cell><cell>0.1067</cell><cell>0.0800</cell><cell>0.1804 0.1105</cell><cell>0.0546</cell><cell>0.1333</cell><cell>0.0811</cell></row><row><cell cols="3">uogTrfL919s3 stdbaseline3</cell><cell>0.0769</cell><cell>0.0477</cell><cell>0.0973 0.0843</cell><cell>0.0524</cell><cell>0.0980</cell><cell>0.0819</cell></row><row><cell>Run</cell><cell cols="3">Post-Classification Pre-Classification</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">(official) statMAP</cell><cell>statMAP</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TREC median</cell><cell cols="2">0.1361</cell><cell>0.1355</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TREC 1st</cell><cell cols="2">0.2206</cell><cell>0.1898</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TREC 2nd</cell><cell cols="2">0.2151</cell><cell>0.1730</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TREC 3rd</cell><cell cols="2">0.2138</cell><cell>0.1497</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>uogTrCh</cell><cell cols="2">0.0828</cell><cell>0.1866</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>uogTrLC151</cell><cell cols="2">0.0360</cell><cell>0.1812</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>uogTrLV1076</cell><cell cols="2">0.0466</cell><cell>0.1759</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,53.76,347.04,239.32,18.51"><head>Table 3 : Pre-classification and post-classification story ranking performance in terms of statMAP.</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,316.80,254.39,169.86,64.36"><head>Table 4 :</head><label>4</label><figDesc>α-nDCG@10 performance</figDesc><table coords="3,385.92,254.39,100.74,43.98"><row><cell>Run</cell><cell>α-nDCG@10</cell></row><row><cell>TREC median</cell><cell>0.421</cell></row><row><cell>uogTrL81</cell><cell>0.477</cell></row><row><cell>uogTrdxF</cell><cell>0.413</cell></row><row><cell>uogTrdxE</cell><cell>0.404</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,316.80,310.68,239.18,18.63"><head>for our blog post ranking runs for the TREC Blog Track top stories identification task.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,61.56,119.40,360.90,79.97"><head>Table 5 : Document and query features used in the Web track.</head><label>5</label><figDesc></figDesc><table coords="4,61.56,146.48,223.54,52.89"><row><cell>Run</cell><cell>Cat.</cell><cell>P@5</cell><cell cols="3">P@10 nDCG@20 ERR@20</cell></row><row><cell>TREC median</cell><cell></cell><cell>-</cell><cell>-</cell><cell>0.1412</cell><cell>0.0805</cell></row><row><cell>uogTrA42</cell><cell>A</cell><cell cols="2">0.3875 0.4104</cell><cell>0.2446</cell><cell>0.1267</cell></row><row><cell>uogTrB67</cell><cell>B</cell><cell cols="2">0.4250 0.4062</cell><cell>0.2097</cell><cell>0.1191</cell></row><row><cell>uogTrB67*</cell><cell>B</cell><cell cols="2">0.4208 0.4021</cell><cell>0.2572</cell><cell>0.1413</cell></row><row><cell>uogTrB67LTS</cell><cell>B</cell><cell cols="2">0.4042 0.4083</cell><cell>0.1899</cell><cell>0.1136</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,53.76,211.68,239.26,18.51"><head>Table 6 : Results of the submitted runs to the adhoc task of the Web track. Corrected run is denoted with *.</head><label>6</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,151.80,54.95,305.82,145.84"><head>Table 7 : Results of the submitted runs to the diversity task of the Web track.</head><label>7</label><figDesc></figDesc><table coords="5,151.80,54.95,305.82,125.46"><row><cell>Run</cell><cell>Cat.</cell><cell>Rel.</cell><cell>Div.</cell><cell>λ</cell><cell cols="3">ERR-IA α-nDCG NRBP @20 @20 @1000</cell><cell>Submitted?</cell></row><row><cell>TREC median</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1947</cell><cell>0.3117</cell><cell>-</cell><cell></cell></row><row><cell>uogTrA42</cell><cell>A</cell><cell>LTR</cell><cell>-</cell><cell>-</cell><cell>0.2220</cell><cell>0.3214</cell><cell>0.1860</cell><cell>adhoc</cell></row><row><cell>uogTrA42x</cell><cell>A</cell><cell cols="4">LTR DPH UNI 0.2454</cell><cell>0.3558</cell><cell>0.2012</cell><cell>diversity</cell></row><row><cell>uogTrBdph</cell><cell>B</cell><cell>DPH</cell><cell>-</cell><cell>-</cell><cell>0.1774</cell><cell>0.2833</cell><cell>0.1295</cell><cell>unofficial</cell></row><row><cell>uogTrBdphx</cell><cell>B</cell><cell cols="4">DPH DPH UNI 0.2428</cell><cell>0.3574</cell><cell>0.2005</cell><cell>unofficial</cell></row><row><cell>uogTrBdphxS</cell><cell>B</cell><cell cols="4">DPH DPH SEL 0.2830</cell><cell>0.4051</cell><cell>0.2393</cell><cell>diversity</cell></row><row><cell>uogTrB67</cell><cell>B</cell><cell>LTR</cell><cell>-</cell><cell>-</cell><cell>0.2981</cell><cell>0.4177</cell><cell>0.2616</cell><cell>adhoc</cell></row><row><cell>uogTrB67x</cell><cell>B</cell><cell cols="4">LTR DPH UNI 0.3142</cell><cell>0.4319</cell><cell>0.2758</cell><cell>unofficial</cell></row><row><cell>uogTrB67xS</cell><cell>B</cell><cell cols="4">LTR DPH SEL 0.2981</cell><cell>0.4178</cell><cell>0.2616</cell><cell>diversity</cell></row><row><cell>uogTrB67xS</cell><cell>B</cell><cell cols="4">LTR DPH SEL 0.3056</cell><cell>0.4357</cell><cell>0.2637</cell><cell>unofficial</cell></row><row><cell>uogTrB67lx</cell><cell>B</cell><cell>LTR</cell><cell cols="3">LTR UNI 0.3098</cell><cell>0.4374</cell><cell>0.2680</cell><cell>unofficial</cell></row><row><cell>uogTrB67lxS</cell><cell>B</cell><cell>LTR</cell><cell cols="3">LTR SEL 0.3184</cell><cell>0.4440</cell><cell>0.2784</cell><cell>unofficial</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,321.24,701.04,146.26,7.05"><p>http://alias-i.com/lingpipe</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,321.24,711.72,107.98,7.05"><p>http://www.mturk.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,58.25,645.23,96.95,10.76" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,73.20,657.83,198.80,8.07;5,73.20,668.39,214.75,8.07;5,73.20,678.83,197.24,8.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,110.04,668.39,177.91,8.07;5,73.20,678.83,81.81,8.07">FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog track</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ambrosi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gaibisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gambosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,170.40,678.83,96.06,8.07">Proceedings of TREC 2007</title>
		<meeting>TREC 2007</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,73.20,690.23,189.83,8.07;5,73.20,700.67,218.18,8.07;5,73.20,711.23,162.08,8.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,73.20,700.67,218.18,8.07;5,73.20,711.23,44.33,8.07">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,123.24,711.23,86.34,8.07">In Information Retrieval</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,222.47,184.02,8.07;5,336.24,232.91,201.21,8.07;5,336.24,243.35,132.20,8.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,373.46,232.91,163.98,8.07;5,336.24,243.35,16.69,8.07">Preliminary overview of the TREC 2010 Web track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,368.40,243.35,96.06,8.07">Proceedings of TREC 2010</title>
		<meeting>TREC 2010</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,254.87,196.36,8.07;5,336.24,265.31,186.62,8.07;5,336.24,275.75,100.52,8.07" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,488.65,254.87,43.94,8.07;5,336.24,265.31,173.64,8.07">An effective statistical approach to blog post opinion retrieval</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,336.24,275.75,78.54,8.07">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,287.15,214.12,8.07;5,336.24,297.71,181.58,8.07;5,336.24,308.15,100.72,8.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,437.97,287.15,112.39,8.07;5,336.24,297.71,168.53,8.07">Voting for candidates: adapting data fusion techniques for an expert search task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,336.24,308.15,78.54,8.07">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,319.55,207.52,8.07;5,336.24,329.99,152.84,8.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,437.97,319.55,105.79,8.07;5,336.24,329.99,36.53,8.07">Key blog distillation: ranking aggregates</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,388.56,329.99,78.54,8.07">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,341.51,208.35,8.07;5,336.24,351.95,152.87,8.07" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,437.97,341.51,106.62,8.07;5,336.24,351.95,38.82,8.07">Learning Models for Ranking Aggregates</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,391.08,351.95,94.04,8.07">Proceedings of ECIR 2011</title>
		<meeting>ECIR 2011</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,363.47,206.05,8.07;5,336.24,373.91,177.81,8.07;5,336.24,384.35,98.09,8.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,494.96,363.47,47.32,8.07;5,336.24,373.91,164.14,8.07">News Article Ranking: Leveraging the Wisdom of Bloggers</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,336.24,384.35,94.09,8.07">Proceedings of RIAO 2010</title>
		<meeting>RIAO 2010</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,395.75,183.26,8.07;5,336.24,406.31,163.97,8.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,379.07,395.75,140.43,8.07;5,336.24,406.31,46.38,8.07">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,398.79,406.31,97.41,8.07">Proceedings of SIGIR 2005</title>
		<meeting>SIGIR 2005</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,417.71,194.41,8.07;5,336.24,428.15,217.76,8.07;5,336.24,438.59,53.97,8.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,379.07,417.71,151.58,8.07;5,336.24,428.15,157.72,8.07">Automatic feature selection in the Markov random field model for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,509.64,428.15,44.36,8.07;5,336.24,438.59,49.97,8.07">Proceedings of CIKM 2007</title>
		<meeting>CIKM 2007</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,450.11,218.44,8.07;5,336.24,460.55,183.36,8.07;5,336.24,470.99,196.65,8.07;5,336.24,481.43,91.64,8.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,374.64,460.55,144.96,8.07;5,336.24,470.99,105.22,8.07">Terrier: a high performance and scalable information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,457.56,470.99,75.33,8.07;5,336.24,481.43,69.33,8.07">Proceedings of OSIR Workshop at SIGIR</title>
		<meeting>OSIR Workshop at SIGIR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,492.95,210.92,8.07;5,336.24,503.39,207.42,8.07;5,336.24,513.83,100.52,8.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,336.24,503.39,193.37,8.07">Incorporating term dependency in the DFR framework</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,336.24,513.83,96.50,8.07">Proceedings of SIGIR 2007</title>
		<meeting>SIGIR 2007</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,525.35,206.20,8.07;5,336.24,535.79,176.72,8.07" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="5,470.64,525.35,71.80,8.07;5,336.24,535.79,62.94,8.07">Learning to Select a Ranking Function</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,414.96,535.79,94.01,8.07">Proceedings of ECIR 2010</title>
		<meeting>ECIR 2010</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,547.19,216.64,8.07;5,336.24,557.63,175.16,8.07;5,336.24,568.19,73.28,8.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="5,476.25,547.19,76.63,8.07;5,336.24,557.63,65.39,8.07">The Static Absorbing Model for the Web</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,408.48,557.63,99.05,8.07">Journal of Web Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="186" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,579.59,215.00,8.07;5,336.24,590.03,181.64,8.07" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="5,396.19,590.03,60.96,8.07">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,601.55,190.21,8.07;5,336.24,611.99,214.64,8.07;5,336.24,622.43,98.04,8.07" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="5,336.24,611.99,201.03,8.07">Explicit search result diversification through sub-queries</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,336.24,622.43,94.04,8.07">Proceedings of ECIR 2010</title>
		<meeting>ECIR 2010</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,633.95,213.58,8.07;5,336.24,644.39,219.75,8.07" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="5,498.37,633.95,51.45,8.07;5,336.24,644.39,103.99,8.07">Selectively diversifying Web search results</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,455.52,644.39,96.48,8.07">Proceedings of CIKM 2010</title>
		<meeting>CIKM 2010</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,655.79,110.94,8.07;5,336.24,666.23,194.92,8.07;5,336.24,676.79,213.03,8.07" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="5,384.87,666.23,146.29,8.07;5,336.24,676.79,96.79,8.07">Exploiting query reformulations for Web search result diversification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L T</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,448.68,676.79,96.59,8.07">Proceedings of WWW 2010</title>
		<meeting>WWW 2010</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,336.24,688.19,141.38,8.07;5,336.24,698.63,219.57,8.07;5,336.24,709.07,203.72,8.07" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="5,444.44,698.63,111.36,8.07;5,336.24,709.07,88.15,8.07">Microsoft Cambridge at TREC 13: Web and Hard tracks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,439.92,709.07,96.06,8.07">Proceedings of TREC 2004</title>
		<meeting>TREC 2004</meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
