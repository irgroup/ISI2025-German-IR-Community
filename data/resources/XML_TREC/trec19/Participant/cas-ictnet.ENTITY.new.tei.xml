<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,111.00,80.48,348.47,19.82">ICTNET at Entity Track TREC 2010</title>
				<funder ref="#_FsKBrp8">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder ref="#_ax63ntg">
					<orgName type="full">Key Program of NSFC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.76,109.39,27.52,9.16"><forename type="first">Lei</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,188.28,109.39,23.85,9.16"><forename type="first">Lu</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,220.14,109.39,45.69,9.16"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.60,109.39,41.01,9.16"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.38,109.39,41.30,9.16"><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,362.82,109.39,27.51,9.16"><forename type="first">Yue</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,395.10,109.39,45.88,9.16"><forename type="first">Xiaoming</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,111.00,80.48,348.47,19.82">ICTNET at Entity Track TREC 2010</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1DD538FD6A2EB8F3E691184A25EDA435</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper gives an overview of our work for related entity finding which is proposed in TREC 2010 Entity Track. The goal of the Entity Track is to find the entities relevant to a given query from the web corpus. In this paper, we propose a bipartite graph reinforcement model for entity ranking. As is well known, the entities on the web are embedded not only in the natural language text, but also in the tables and lists. Given a query, both the candidate entities and relevant tables/lists are extracted from web documents. Then the candidate entities extracted from unstructured text are ranked based on a probabilistic model. But the result contains a lot of noise. If some candidate entities are in a relevant table/list, they are more relevant to the given query. And Vice versa, if a table/list contains several candidate entities, it is also more relevant to the query. Based on the above intuition, we construct a bipartite graph and then perform a reinforcement algorithm to re-rank the candidate entities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The World Wide Web has been growing rapidly as huge knowledge repository which contains so rich information. Traditional information retrieval systems return a list of documents relevant to user's queries. However, users often show more interest in the entities instead of documents given their queries. So it is necessary to study how to automatically find the related entities given a query.</p><p>The main task of Entity Track focuses on the related entity finding (REF): given an input entity, by its name and homepage, the type of the target entity, as well as the nature of their relation, described in free text, find related entities that are of target type, standing in the required relation to the input entity [1] .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Architecture</head><p>Our approach can be summarized by the following steps: 1． Form the query based on the source entity and narrative 2． Extract the relevant text snippets from the documents and recognize the named entities with the given target type 3． Compute the initial ranking score for each candidate entity based on a probabilistic model 4． Extract the relevant tables/lists which may contain several target entities from documents 5． Construct the bipartite graph based on the candidate entities and relevant tables/lists. And then the reinforcement learning algorithm is performed over the graph to get the final score for each candidate entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6． Find the homepage for candidate entities</head><p>The following sections will explain some key steps of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query Formation</head><p>The query is formed as a keyword set based on the given entity and narrative. Words indicating the relationship should be extracted from the narrative. With a part-of-speech tagger, we parse the narrative to get the verb or noun to form the keyword set. After the initial keyword set is formed, we argument it with synonyms of the keywords from WordNet <ref type="bibr" coords="1,281.00,731.97,10.61,8.74" target="#b2">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Named Entities Identification</head><p>After the relevant documents are retrieved, we extracted the relevant text snippets from the documents.</p><p>Then the Stanford NER Tagger 1 is used to extract the named entities with the given target type from the text snippets. At the same time, we detect the boundary of named entities with the aid of anchor text.</p><p>After acquiring the initial list of candidate entities, we apply several heuristic rules to remove the duplicated entities. Finally, we get a list of candidate entities with their support snippets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Initial Candidate Entities Ranking</head><p>After acquiring the list of candidate entities, an initial ranking value is calculated for each of them. We define Q = {e s , r, T}, where e s denotes the source entity, r denotes the relationship between the source entity and the target entity, and T denotes the type of target entity. And let e t denotes the target entity.</p><p>The candidate entities are ranked by the probability p(e t |Q). By applying Bayesian Theorem and Chain rules, p(e t |Q) could be decomposed into the following form:  </p><formula xml:id="formula_0" coords="2,135.30,254.66,235.30,113.00">( | ) ( , ) t t p e Q p e Q ∝ ( , , , ) ( | , , ) ( , , ) ( | , , ) ( | , ) ( , ) ( | , , ) ( | , ) ( | ) ( ) ( | , ) ( | ) ( | )</formula><p>In equation ( <ref type="formula" coords="2,141.88,376.29,3.52,8.74" target="#formula_1">1</ref>), there are three components: p(r|e s ,e t ) the probability that r is mentioned between e s and e t ; p(T|e t ) the probability that e t mentions target type T; p(e t |e s ) the probability that e s mentions e t . This step is very similar to that in the work <ref type="bibr" coords="2,244.24,407.49,10.61,8.74" target="#b3">[3]</ref>. The only difference is the estimation for the components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Relevant Candidate Tables/Lists Extraction</head><p>The information on the web can be organized or represented as several forms such as natural language text, table, list and so on. In the task related entities finding, many target entities are found not only in the natural language text snippet, but also in the tables/lists. So the extraction of relevant tables/lists is very necessary for this task. We define the relevance of the table/list as follows:</p><p>The context of the table/list is relevant to the query</p><p>The table/list should contain several candidate entities extract from the unstructured text.</p><p>Here, we simply apply some heuristic methods such as rules to extract the relevant tables/lists. The features used for extraction of tables/lists are very similar to those used in the work. <ref type="bibr" coords="2,427.79,551.01,10.64,8.74" target="#b4">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Candidate Entities Re-Ranking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Bipartite Graph Construction</head><p>We construct a bipartite graph based on the candidate entities and relevant tables/lists. The candidate entities and relevant tables/lists are regarded as the two disjoint sets of graph vertices. If one candidate entity is in a relevant table/list, the vertices corresponding to them will be connected by an edge. For two vertices e i , l j of one edge, the weight of the edge is defined as follows：</p><formula xml:id="formula_2" coords="2,134.70,668.36,138.29,33.99">1 0 i j ij if e is connected to l w otherwise ⎧ ⎪ = ⎨ ⎪ ⎩</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Reinforcement Learning</head><p>Once the bipartite graph is constructed, we apply the reinforcement Learning algorithm over it. Similar to <ref type="bibr" coords="2,100.33,747.63,10.64,8.74" target="#b5">[5]</ref>, the Iteration equation is as follows：</p><p>(2) E 0 and L 0 are the initial Ranking value vectors of the candidate entities and relevant table/list, respectively. E n and L n are the ranking value vectors after n iterations. A is the biadjacency matrix of bipartite graph. A T is the transpose of A. D L is the diagonal matrix with its (i;i)-element equal to the sum of the i-th column of A; D E is the diagonal matrix with its (i;i)-element equal to the sum of the i-th row of A.αand β are the weight. After several iterations, we get the final score for each candidate entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Find homepages for entities</head><p>For the homepage finding, we use search engine such as Google to search for top-K urls and some heuristic rules are used to identify the real homepage. Then we search for the corresponding document from the corpus with the url.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Our Experiment</head><p>In the experiment, our focus was to retrieve the related entities, and not on finding homepages corresponding to the related entities. We computed the retrieval measure over the name of entities.</p><p>We evaluated the proposed model on a standard collection from TREC 2010 Entity Track. The collection includes: (1) ClueWeb09 Category A (about 500 million pages) (2) twenty queries of which topic Ids are from 21 to 40 (3) Relevant entities manually found from web for each query using Google.</p><p>For each query, the top 100 ranked entities are returned. We adopt the P@10 and nDCG@R as the measure to evaluate the performance. The ranking strategy based on the probabilistic model is chosen as the baseline. The result is as follows:</p><p>mean P@10 mean nDCG@R From the results, we can see that both the average P@10 and average nDCG@R are improved. So the bipartite graph reinforcement model is more effective for the related entity finding than the probabilistic model. The official results are listed in Table <ref type="table" coords="3,244.38,686.97,3.77,8.74" target="#tab_2">2</ref>. Our scores are low. One possible reason is that we fail to find the true homepages though we could find related entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Official Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion and Future Work</head><p>In this paper, we represent a bipartite graph reinforcement model for the relate entity ranking. As is well known, the entities on the web are embedded not only in the natural language text, but also in the (1 )</p><p>(1 )</p><formula xml:id="formula_3" coords="3,172.80,79.88,128.00,69.51">n n n n L T E E M L E L M E L M AD M A D α α β β + + + - - = + - ⎧ ⎨ = + - ⎩ = =</formula><p>table or list. Given a query, both the candidate entities and relevant tables/lists are extracted from web documents. The ranking of candidate entities can benefit from the relevant tables/lists which may contain several target entities. And Vice versa the ranking of relevant tables/lists may be improved if it contains several candidate entities. The mutual reinforcement between the candidate entities and relevant tables/lists will improve the effectiveness of the entity ranking However, the performance can be further improved with better techniques. In future work, we will investigate other methods for NER and homepage finding. And we will also extract the target entities from the tables/lists with high score to improve the recall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,186.72,283.98,53.58,10.19;2,186.72,302.40,107.46,10.19;2,186.72,320.76,147.23,10.19;2,186.72,339.13,175.07,10.19;2,186.72,357.49,122.57,10.19;2,175.80,280.34,6.21,13.86;2,175.80,298.76,6.21,13.86;2,175.80,317.12,6.21,13.86;2,175.80,335.48,6.21,13.86;2,175.80,353.84,6.21,13.86"><head></head><label></label><figDesc>p e e r T p r e e T p e e T p r e e T p T e e p e e p r e e T p T e e p e e p e p r e e p T e p e e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,122.40,483.33,293.10,72.16"><head>Table 1 :</head><label>1</label><figDesc>The results of our experiment for entity ranking</figDesc><table coords="3,122.40,483.33,261.51,56.08"><row><cell>Probabilistic Model</cell><cell>0.2325</cell><cell>0.4530</cell></row><row><cell>(Baseline)</cell><cell></cell><cell></cell></row><row><cell>Bipartite Graph</cell><cell>0.2975</cell><cell>0.5150</cell></row><row><cell>Reinforcement Model</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,118.02,628.35,306.51,48.64"><head>Table 2 :</head><label>2</label><figDesc>The official results for our run</figDesc><table coords="3,118.02,628.35,306.51,24.88"><row><cell>@10</cell><cell>nDCG_R</cell><cell>MAP</cell><cell>Rprec</cell></row><row><cell>0.1277</cell><cell>0.1611</cell><cell>0.0839</cell><cell>0.1305</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Acknowledgements</head><p>We would like to thank <rs type="person">Zeying Peng</rs> and <rs type="person">Xu Chen</rs> for their help with preparation for data and development of some useful tools for our task. In addition, our work is supported by <rs type="funder">Key Program of NSFC</rs> <rs type="grantNumber">60933005</rs> and <rs type="funder">NSFC</rs> <rs type="programName">60903139. 973 Program of China 2007CB311103</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ax63ntg">
					<idno type="grant-number">60933005</idno>
				</org>
				<org type="funding" xml:id="_FsKBrp8">
					<orgName type="program" subtype="full">60903139. 973 Program of China 2007CB311103</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,93.76,268.56,52.73,9.02" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.38,285.81,400.97,8.74;4,105.00,301.41,400.38,8.74;4,105.00,317.01,129.07,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,439.79,285.81,65.55,8.74;4,105.00,301.41,104.43,8.74">Overview of the TREC 2009 Entity Track</title>
		<author>
			<persName coords=""><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pavel</forename><surname>Serdyukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thijs</forename><surname>Westerveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,230.76,301.41,274.62,8.74;4,105.00,317.01,21.58,8.74">Proceedings of the Eighteenth Text REtrieval Conference (TREC 2009)</title>
		<meeting>the Eighteenth Text REtrieval Conference (TREC 2009)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.20,332.61,294.64,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,158.40,332.61,170.42,8.74">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,107.37,348.21,397.91,8.74;4,105.00,363.81,392.56,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,282.16,348.21,204.53,8.74">Related Entity Finding Based on Co-Occurance</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,105.00,363.81,285.04,8.74">Proceedings of the Eighteenth Text REtrieval Conference (TREC 2009)</title>
		<meeting>the Eighteenth Text REtrieval Conference (TREC 2009)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.49,379.41,400.80,8.74;4,105.00,395.01,198.33,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,185.62,379.41,265.34,8.74">A machine learning based approach for table detection on the web</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,469.72,379.41,35.58,8.74;4,105.00,395.01,168.89,8.74">Eleventh International World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,104.45,410.61,400.92,8.74;4,105.00,426.21,400.40,8.74;4,105.00,441.81,84.25,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,379.12,410.61,126.25,8.74;4,105.00,426.21,135.18,8.74">Bipartite Graph Reinforcement Model for Web Image Annoation</title>
		<author>
			<persName coords=""><forename type="first">Xiaoguang</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingjing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,248.15,426.21,257.24,8.74;4,105.00,441.81,57.66,8.74">Proceedings of the ACM International Multimedia Conference and Exhibition</title>
		<meeting>the ACM International Multimedia Conference and Exhibition</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
