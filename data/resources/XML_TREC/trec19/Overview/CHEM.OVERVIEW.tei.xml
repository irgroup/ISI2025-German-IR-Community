<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.96,164.71,267.33,15.39">TREC-CHEM 2010 : Notebook report</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-10-24">October 24, 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.72,197.12,57.48,10.87"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
						</author>
						<author>
							<persName coords="1,239.16,197.12,48.29,10.87"><forename type="first">John</forename><surname>Tait</surname></persName>
						</author>
						<author>
							<persName coords="1,296.16,197.12,69.12,10.87"><forename type="first">Jimmy</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName coords="1,375.36,197.12,64.21,10.87"><forename type="first">Jianhan</forename><surname>Zhu</surname></persName>
						</author>
						<title level="a" type="main" coord="1,171.96,164.71,267.33,15.39">TREC-CHEM 2010 : Notebook report</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-10-24">October 24, 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">BC84978729069F59E156D888119F9B92</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC Chemical IR Track is a domain-specific evaluation campaign working with documents containing specific lexica, including chemical formulas and specific names. The 2010 edition of the track also included supporting material in addition to text: images and structure information files. As in the previous year, we had two tasks: a patent focused prior-art (PA) task and a user-focused Technology Survey task (TS). The data collection includes patent files as well as scientific articles, together with their attachments, if any. Topics and relevance judgments were either automatically or manually created.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The 2nd TREC Chemical IR track follows closely on the principles and objectives outlined in the first edition. Through two tasks, it aims to cover both the issues of large scale retrieval, as well as in-depth analysis of the chemical domain. Like last year, one task (Prior Art) asked the systems to find relevant patents with respect to a set of 1,000 existing patents. The results returned by the systems were evaluated based on the citations in those patents and their family members. As last year, we selected a subset of 100 patents to be the Small PA task, for those systems which could not provide answers to the full set.</p><p>The second task, the Technology Survey, was designed to mimic in closer detail the kinds of queries issued by experts in the field. This year, 5 [patent] experts kindly provided a total of 30 such topics. Participants were than asked to provide results from the full data set, which this year included almost 200,000 scientific articles. The results are then evaluated manually.</p><p>Similarly to the last year, in 2010 we provided the data collection to a total of 13 groups, mostly from academia but also from industry. However, we received much fewer results back: 4 groups submitted 11 runs for the PA task, while only 2 submitted 12 runs results for the TS task. Overall, the methods applied are also similar to last year: entity recognition, standard BM25, re-ranking methods based on citations.</p><p>The remainder of the paper is organized as follows: Section 2 describes the data collection, then Sections 3 and 4 provide details on the PA and the TS tasks, respectively. A summary of approaches, as provided by the  participants is listed in Section 5 and the conclusion and outlook are in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Collection</head><p>The TREC-CHEM10 collection contains 1,277,467 patent documents and 176,528 scientific articles, which, together with their attachments (images, chemical structure files, pdfs) totaled 420GB of compressed data, that we made available for download. The download site was structured on type of file, so groups which knew that they wouldn't be able to process certain types, only downloaded the files they could actually work with.</p><p>To the best of our knowledge at this point, none of the groups worked with anything other than text data in xml files.</p><p>For the patent files, the distribution across different chemical domains is shown in Figure <ref type="figure" coords="2,240.48,574.60,3.56,8.66" target="#fig_0">1</ref>, for both the 2009 and 2010 collections. As can be seen, the emphasis on particular classes is maintained, with an increased emphasis on the biomedical field (class A61K). For the scientific articles collection, in addition to the articles we had in the 2009 collection from the Royal Society of Chemistry (31 journals), we added a lot more articles from PubMed Central Open Access collection and from four individual publishers (Hindawi, Oxford, IUCrJnls, MDPI), totaling over 1500 journals. However, given the new sources of data, we also observe in this part of the collection, an emphasis on the bio-medical part of chemistry, to the detriment of other sub-domains. Still, this can be explained by the fact that there is indeed a significantly larger industry in real life on this kind of chemistry.</p><p>Unique identifiers. Each document must have a unique identifier.</p><p>For the patent domain, this is the UCID which consists of the identifier of the issuing office, a number, and a version identifier (also called a kind code). The kind code, to put it simply, identifies the different versions of a patent document, as it evolves in the granting procedure. Unlike last year, where we considered a patent to be any version of the document, basically using only the country code and the document identifier, this year we used the full UCID.</p><p>For scientific articles, the unique identifier is the Digital Object Identifier (DOI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Prior Art (PA) Task</head><p>One of the lessons we learned last year with respect to the design of the PA task, was that, given the way we evaluated (using mostly citations from the examiner's report on the novelty of the patent application), we must provide as topics the application documents rather than the granted patents. We also had learned that our sampling procedure had been biased towards the US patents, so this year we corrected both of these issues and resulted in an equal distribution over the 3 sources of patents used in this collection: 333 from the USPTO, 333 from the WIPO and 334 from the EPO. The small topic set is slightly more imbalanced, as we selected it at random from the large set, without imposing specific limits with regards to the source: 27 from EPO, 36 from the USPTO and 37 from WIPO.</p><p>The topics for this PA task are represented by the full text of the patent application documents. The text provided to the participants contains everything, with the exception of the legal status of the document, since this is not part of the research collection. However, the legal status is irrelevant for this track. However, the text did contain the citations that the applicant or the patent examiner had added. Participants were instructed not to use them directly in their ranking process. However, given that the citations in the collection provide useful information, we did not limit the participants use of other references in other documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Relevance judgements</head><p>Like in 2009, the qrels for the PA task are created based on citations within the patent document, citations provided by applicant, patent office, or during an opposition procedure. The procedures is done in three steps, as follows: F3: contains the F1 and F2 sets to which we add the family members of the patent documents in the F1 set.</p><p>Figure <ref type="figure" coords="4,203.16,320.56,4.60,8.66" target="#fig_1">2</ref> illustrates this process, with the observation that it only marks as F1, those patents that appear after the first step, with F2 after the second and with F3 after the final step. In reality, there is a relation of inclusion between the four sets: D ⊂ F1 ⊂ F3 and D ⊂ F2 ⊂ F3. The F3 was used as the final QREL set, after having filtered out the documents which were not in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>We calculated results for the full and Small PA topic set for 6 different measures: MAP, Reciprocal Rank, Precision at 30, recall at 100, and NDCG. The results are shown in alphabetical order of the runs in Tables <ref type="table" coords="4,447.96,440.44,4.60,8.66" target="#tab_1">2</ref> and<ref type="table" coords="4,175.68,451.48,3.56,8.66" target="#tab_2">3</ref>. The tables do not include the two runs submitted by the Iowa team, as there was clearly something wrong with those runs, as none of them contained any relevant documents whatsoever, resulting in a pure zero score across the board. To avoid skewing the averages, in agreement with the team, we decided to not include them in this report. In addition, the SCAI team requested a change of their submitted runs after the deadline, as they had inadvertently used the direct citations of the topic patents in their results. In agreement with the NIST organizers, we accepted this change and the results provided here reflect these new, lower scores compared with their original submission results.</p><p>For the full PA set, we also computed the statistical significance of the difference between MAP and NDCG results of the submitted runs, using the randomization test. The results, shown in Tables <ref type="table" coords="4,399.60,583.00,4.60,8.66" target="#tab_3">4</ref> and<ref type="table" coords="4,425.16,583.00,4.60,8.66" target="#tab_4">5</ref> show the p-values and indicate that all runs are significantly different, with the exception of the (SCAI10NRMTOK, York10CaPA01) pair in the case of the NDCG.  </p><formula xml:id="formula_0" coords="5,166.68,382.08,277.93,129.08">run name BiTeM10PAx SCAI10CIENTP SCAI10CITENT SCAI10CITNP SCAI10CITTOK SCAI10NRMENT SCAI10NRMNP SCAI10NRMTOK York10CaPA01 BiTeM10PAx x 0 0.00037 0 0 0 0 0 0 SCAI10CIENTP x 0 0 0 0 0 0 0 SCAI10CITENT x 0 0 0 0 0 0 SCAI10CITNP x 0 0 0 0 0 SCAI10CITTOK x 0.00011 0 0 0 SCAI10NRMENT x 0 0 0 SCAI10NRMNP x 0 0 SCAI10NRMTOK x 0.01808</formula><formula xml:id="formula_1" coords="5,179.28,541.92,252.61,128.97">run name BiTeM10PAx SCAI10CIENTP SCAI10CITENT SCAI10CITNP SCAI10CITTOK SCAI10NRMENT SCAI10NRMNP SCAI10NRMTOK York10CaPA01 BiTeM10PAx x 0 0 0 0 0 0 0 0 SCAI10CIENTP x 0 0 0 0 0 0 0 SCAI10CITENT x 0 0 0 0 0 0 SCAI10CITNP x 0 0 0 0 0 SCAI10CITTOK x 0 0.00027 0 0 SCAI10NRMENT x 0 0 0 SCAI10NRMNP x 0 0 SCAI10NRMTOK x 0.6976</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Technical Survey (TS) Task</head><p>The TS task is similar to a traditional ad hoc retrieval task, however, the challenge is the way to deal with chemical specic problems such as synonyms and abbreviations. Five patent and academic chemical experts have kindly provided 30 topics from their experience. As mentioned in Section 2, the 2010 collection contained significantly more data than the 2009 one. This may be one of the causes for which we only received runs from 2 groups. Although together they summed 12 runs, the fact that all of these came from only two groups lead us to the decision not to evaluate the full set of topics, as the results, obtained through the usual pooling technique, would have been skewed towards these two groups and thus potentially less useful for future evaluations. However, given that these two groups did a considerable amount of work, we decided to provide relevance judgements to 6 of these topics, in order for them to further improve their systems.</p><p>Unfortunately, at the time of writing of this report, the evaluation results for these 6 topics are not yet available.</p><p>Unlike the previous year, when we asked students to evaluate results independently from the experts, and then passed these results to the experts, this year we designed a new interface that allows a junior evaluator to communicate directly with the creator of the topic, considered the expert on the matter, and quickly clarify any problems. This was a result of the observation last year, that 1. the experts often did not trust the students' evaluation and re-did everything and 2. even a limited interaction between the junior evaluator and the expert resulted in a significant agreement between the two in the final results. The new evaluation interface is briefly described in what follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation interface</head><p>The two main differences between the 2010 and the 2009 assessment interface are:</p><p>1. a discussion forum (Figure <ref type="figure" coords="6,291.00,492.16,4.07,8.66" target="#fig_2">3</ref>) 2. a "notes" section (Figure <ref type="figure" coords="6,285.00,507.16,4.07,8.66">4</ref>) Both of the new features work on a topic level and are shared between the two evaluators of the topic (the junior evaluator and the expert). The discussion is aimed to provide a platform where questions and answers are communicated and recorded. Whenever one of the two uses the feature an email is sent to the other, as well as to the administrators (i.e. organizers).</p><p>This feature not only helps the junior evaluator provide a better evaluation of the topic by a better understanding of the problems addressed, but also saves for future analysis all the issues which were discussed and therefor helps the organizers make better topics in the future.</p><p>In relation to this last objective, and as a consequence of requests from evaluators last year, we added a feature which allows the user to take notes during the evaluation. Again, these notes are shared by all those who have access to the same topic. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For TS runs:</head><p>Standard IR strategies, as well as different levels of chemical query expansion: small, medium and large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">SCAI Group</head><p>For PA runs:</p><p>All runs uses citation re-ranking, with or without thresholding. Semantic searches (chemical), text searches and noun-phrase searches were used in each of the two sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">York Group</head><p>For PA runs:</p><p>Language model with Dirichlet smoothing (µ = 100).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For TS runs:</head><p>Different weighting functions (BM25, DFR, Language Model), as well as query expansion using chemical information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This years TREC-CHEM track has been challenging from several perspectives. Collecting all the data was an issue at the beginning of the year, then it became an issue for the participants, as there was too much of it. We were satisfied to see how, for the PA task, those runs which used domain specific data really performed much better than those with generic approaches. We were less satisfied with the technique that does re-ranking based on citation patterns. While being perfectly valid, it is a generic technique which does not fit perfectly within the objectives of this campaign. Together with the participants, evaluators and other interested parties, we organized a workshop before the conference and shall continue to analyze the best ways to go forward and into the third year of this effort.</p><p>We are particularly committed to make this evaluation campaign relevant to professional users and therefore will continue to push for a stronger integration between text mining techniques and structure search. All the prerequisites are now in place for a strong performance in the third year, given that we will not change the collection and re-use many of the topics of the TS tasks which were not used this year.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,174.12,299.69,263.24,9.19;2,178.08,124.93,255.10,159.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of patent documents over IPC classes</figDesc><graphic coords="2,178.08,124.93,255.10,159.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,230.16,208.25,151.06,9.19"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Qrels creation procedure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,167.16,544.25,277.06,9.19;7,77.04,244.50,453.50,284.92"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Discussion on a topic using the ChemAssess Interface</figDesc><graphic coords="7,77.04,244.50,453.50,284.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,181.08,330.41,249.20,57.91"><head>Table 1 :</head><label>1</label><figDesc>Distribution of patent documents across sources</figDesc><table coords="2,226.44,342.23,158.47,46.09"><row><cell cols="2">Source Number of documents</cell></row><row><cell>EPO</cell><cell>134035</cell></row><row><cell>USPTO</cell><cell>907170</cell></row><row><cell>WIPO</cell><cell>236262</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,139.80,135.17,313.93,94.84"><head>Table 2 :</head><label>2</label><figDesc>Results on 6 measures for the full set of PA topics</figDesc><table coords="5,139.80,146.33,313.93,83.68"><row><cell>measure</cell><cell>map</cell><cell>bpref</cell><cell>recip rank</cell><cell>P 30</cell><cell>recall 100</cell><cell>ndcg</cell></row><row><cell>BiTeM10PAx</cell><cell>0.2657</cell><cell>0.6592</cell><cell>0.6121</cell><cell>0.3485</cell><cell>0.4724</cell><cell>0.4975</cell></row><row><cell>SCAI10CIENTP.result</cell><cell>0.4121</cell><cell>0.7075</cell><cell>0.7153</cell><cell>0.4554</cell><cell>0.5491</cell><cell>0.5834</cell></row><row><cell>SCAI10CITENT.result</cell><cell>0.2336</cell><cell>0.5468</cell><cell>0.5324</cell><cell>0.2794</cell><cell>0.3596</cell><cell>0.4119</cell></row><row><cell>SCAI10CITNP.result</cell><cell>0.2065</cell><cell>0.5110</cell><cell>0.4769</cell><cell>0.2485</cell><cell>0.3265</cell><cell>0.3764</cell></row><row><cell>SCAI10CITTOK.result</cell><cell>0.0947</cell><cell>0.2804</cell><cell>0.1956</cell><cell>0.1126</cell><cell>0.1511</cell><cell>0.1888</cell></row><row><cell>SCAI10NRMENT.result</cell><cell>0.0665</cell><cell>0.4171</cell><cell>0.3456</cell><cell>0.1169</cell><cell>0.1974</cell><cell>0.2547</cell></row><row><cell>SCAI10NRMNP.result</cell><cell>0.0551</cell><cell>0.3702</cell><cell>0.3088</cell><cell>0.1000</cell><cell>0.1743</cell><cell>0.2224</cell></row><row><cell>SCAI10NRMTOK.result</cell><cell>0.0172</cell><cell>0.1536</cell><cell>0.1133</cell><cell>0.0366</cell><cell>0.0629</cell><cell>0.0868</cell></row><row><cell>York10CaPA01</cell><cell>0.0136</cell><cell>0.1681</cell><cell>0.1022</cell><cell>0.0309</cell><cell>0.0583</cell><cell>0.0885</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,139.80,250.25,313.93,101.08"><head>Table 3 :</head><label>3</label><figDesc>Results on 6 measures for the Small set of PA topics</figDesc><table coords="5,139.80,261.29,313.93,90.04"><row><cell>measure</cell><cell>map</cell><cell>bpref</cell><cell>recip rank</cell><cell>P 30</cell><cell>recall 100</cell><cell>ndcg</cell></row><row><cell>BiTeM10PAsmx</cell><cell>0.2175</cell><cell>0.6647</cell><cell>0.5102</cell><cell>0.2567</cell><cell>0.4543</cell><cell>0.4295</cell></row><row><cell>BiTeM10PAx</cell><cell>0.2174</cell><cell>0.6647</cell><cell>0.5027</cell><cell>0.2567</cell><cell>0.4560</cell><cell>0.4285</cell></row><row><cell>SCAI10CIENTP.result</cell><cell>0.3612</cell><cell>0.7063</cell><cell>0.6452</cell><cell>0.3617</cell><cell>0.5456</cell><cell>0.5193</cell></row><row><cell>SCAI10CITENT.result</cell><cell>0.1878</cell><cell>0.5157</cell><cell>0.4442</cell><cell>0.2137</cell><cell>0.3368</cell><cell>0.3450</cell></row><row><cell>SCAI10CITNP.result</cell><cell>0.1685</cell><cell>0.4936</cell><cell>0.4480</cell><cell>0.1960</cell><cell>0.3073</cell><cell>0.3262</cell></row><row><cell>SCAI10CITTOK.result</cell><cell>0.0554</cell><cell>0.2222</cell><cell>0.1274</cell><cell>0.0633</cell><cell>0.1059</cell><cell>0.1257</cell></row><row><cell>SCAI10NRMENT.result</cell><cell>0.0750</cell><cell>0.4718</cell><cell>0.3421</cell><cell>0.0943</cell><cell>0.2651</cell><cell>0.2502</cell></row><row><cell>SCAI10NRMNP.result</cell><cell>0.0648</cell><cell>0.4434</cell><cell>0.3244</cell><cell>0.0797</cell><cell>0.2406</cell><cell>0.2300</cell></row><row><cell>SCAI10NRMTOK.result</cell><cell>0.0150</cell><cell>0.1660</cell><cell>0.0730</cell><cell>0.0197</cell><cell>0.0708</cell><cell>0.0726</cell></row><row><cell>York10CaPA01</cell><cell>0.0132</cell><cell>0.1449</cell><cell>0.0862</cell><cell>0.0223</cell><cell>0.0550</cell><cell>0.0646</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,165.72,371.57,279.80,9.19"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note coords="5,205.32,371.57,240.20,9.19"><p>p-values for the randomization test on the MAP values</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,162.36,531.41,286.52,9.19"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note coords="5,201.96,531.41,246.92,9.19"><p>p-values for the randomization test on the NDCG values</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,149.04,631.48,328.54,8.66;4,133.80,642.40,120.52,8.66"><p>A 'patent family' is a set of patents granted by different patent authorities but related to the same invention.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
