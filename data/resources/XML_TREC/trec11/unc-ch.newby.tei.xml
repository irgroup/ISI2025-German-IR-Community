<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,403.61,748.54,136.47,7.24;1,158.21,87.38,313.71,14.76">Newby -General Purpose IR Software (1) Progress in General-Purpose IR Software</title>
				<funder ref="#_eDX5egj">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Yumetech, Inc.</orgName>
				</funder>
				<funder>
					<orgName type="full">E.S.P. Das Educational Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,254.33,117.31,121.30,12.99"><forename type="first">Gregory</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UNC Chapel Hill</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,403.61,748.54,136.47,7.24;1,158.21,87.38,313.71,14.76">Newby -General Purpose IR Software (1) Progress in General-Purpose IR Software</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">195A3E1A92C8B3CBE7F33ACFD9806DE1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TREC 2002 experiments were run, but not submitted in time for inclusion in the official conference results. Post-hoc analysis is included in this paper. Progress on general-purpose IR software for experimental use has been very good, and some features of the software are described. A new focus on IR for grid computing, GridIR, is described.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The IRTools software developed by the author and his colleagues was used again this year. VSM's Lnu.Ltc and LSI retrieval models were used. Options for automatic query expansion and pseudo relevance feedback were available, as well as a variety of components for stoplist processing etc.</p><p>Unfortunately, runs were completed just a few hours too late and so were not included in the TREC conference results. Interactive track data collection is not yet completed, but the research design is presented below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Completed runs for TREC 2002 included: CLIR: Monolingual Arabic</head><p>Web: Topic Distillation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Software Overview</head><p>IRTools is intended to be a general-purpose toolkit for information retrieval research. It was funded in part by the NSF through an Information Technology Research grant. The source code for IRTools is available at http://sourceforge.net/projects/irtools.</p><p>In early 2003, IRTools is nearing readiness for use by other IR researchers. It offers high-performance indexing and retrieval, and many of the features found in other experimental IR systems -but with more of an emphasis on allowing the programmer to change parameters, extend functionality, etc. Completion of IRTools for public release is scheduled for May 2003. At that time, modules to be included are:</p><p>-Indexing for multiple document type: XML, text and HTML -Processing for English, Arabic </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLIR Arabic Monolingual Results</head><p>Two monolingual Arabic runs were completed. One utilized the entire document; the other utilized the title only (intended for high early precision). Basic tools provided by the track coordinators were applied to modify the topic character set to match the document set, but no other processing was done (i.e., no stemming, stopwords, or analysis of document structure). This "bag of words" approach was envisioned as a starting point for further experimentation.</p><p>For this run, the VSM was used with Lnu.Ltc weighting (pivoted document length normalization with the cosine measure of association).</p><p>Note that in the title only run, all other sections of each document were ignored. Indexing for both title only and the whole document ran as part of one IRTools indexing program and took about an hour for the 895MB of text (383K documents with 660K unique terms). Summary results are presented in Tables <ref type="table" coords="2,309.66,366.16,6.00,10.80" target="#tab_1">1</ref> and<ref type="table" coords="2,338.96,366.16,4.50,10.80" target="#tab_2">2</ref>.  As hoped, the title-only run yielded higher early precision, but (also as expected) failed entirely for a number of queries. Of the 50 TREC topics, only 19 yielded any results for this run (indicating that there were no Arabic collection documents with all query terms in the title for the other topics). Topics with some relevant document retrieved included AR37, AR44, AR45, AR48, AR49, AR50, AR51, AR55, AR56, AR61, AR69, and AR74. From this run, we learned that title processing can be effective alone, but fails more often than not if it is the sole basis for retrieval. Combining title retrieval (or differently weighting the title words) with other techniques is indicated.</p><p>The base run, using all terms (without differential weighting for title terms), yielded a greater number of relevant documents retrieved (730 vs. 121 for title-only) but lesser early precision and weaker precision over all. Exact precision did not suffer as much, presumably due to a smaller number of failed queries. Nevertheless, only 35 out of 50 topics yielded any results, and 15 of those had no relevant documents. Here, we suffered from working exclusively with the exact match Boolean AND of topic terms. The lack of stemming, plus the lack of any query expansion or partial-match ranking, hurt the set of documents that could be considered and ranked for retrieval.</p><p>Overall, these results provide a baseline for VSM-style processing of Arabic documents for mono-lingual runs. Obvious features for inclusion for better results include stemming, query expansion, and differential weighting based on document components such as the title.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Web Track</head><p>Two runs for the topic distillation task in the Web track were run. As for the Arabic runs, one was title-only and the other used the entire document. The IRTools indexing took about 4 days for the collection (20GB of HTML documents, about 1.2M documents and 6.37M unique terms). Summary results are in Tables <ref type="table" coords="3,348.99,690.04,6.00,10.80" target="#tab_3">3</ref> and<ref type="table" coords="3,378.29,690.04,4.50,10.80" target="#tab_4">4</ref>.  The Web results were not good. Some topics (such as 552) had perfect or nearperfect early precision, while others (such as 551) found no relevant documents at all. Analysis of these results indicates that the main problem is not having heuristics in place to identify good distillation pages, instead relying on regular topic-based matching geared towards term matching. Results were marginally better for the title-only run.</p><p>Work to improve results will focus on incorporating document structure into results; in particular the title and heading data which might better indicate good candidates for distillation. In addition, heuristics to look at the document URL itself (which was completely ignored) will help, by flagging shorter URLs are potentially more likely to be good distillation candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactive Track</head><p>For the interactive track, we are comparing two nearly identical systems using a Google-like text-based interface. Both use the same set of documents, and both make an initial set of candidate documents for ranking using a Boolean AND. They use the Web 02 collection (20GB of HTML from .gov). The difference is that one system uses LSI for ranking results, the other uses VSM with Lnu.Ltc ranking. Document summarization is via Perl modules from CPAN.</p><p>Our hypothesis is that the differences in ranking will make no difference in the user experience (i.e., results on measured variables will not be significantly different). We intend this as a base study to explore further variations:</p><p>-Systems where the ranked set of documents is different, via automatic query expansion -Systems where result sets are visualized in a 3D fly-through system Unfortunately, last year's interactive track was not completed (we intended to compare a text list of results to a browseable category hierarchy), primarily because IRTools was not up to the task. This year, however, the systems are up and running and giving reasonable results. In early 2003, the test interfaces are accessible: http://underdog.ils.unc.edu/cgi-bin/nph-lsi.cgi (text interface to LSI) http://underdog.ils.unc.edu/cgi-bin/nph-vsm.cgi (text interface to VSM) http://underdog.ils.unc.edu/cgi-bin/nph-query.cgi (VSM with database select)</p><p>The 3D interface is implemented in Web3D (essentially, Web3D is a modern VRML '97 implemented over Java3D). This interface runs by accepting user queries, running them against the LSI module of IRTools, then displaying the resulting set of term and document locations and relationships. A simple XML structure is used to communicate between the visualizer and the server.</p><p>Note that the LSI applied is only to the Boolean AND of search terms, or a slightly expanded set of search terms. This is done while the user waits (usually within a few seconds, depending on the number of terms and documents being considered). For largerscale LSI, we have constructed some very large LSI spaces into which queries may be mapped (such spaces are also good for query term expansion). For general visualization of search set results using only documents that contain the query terms, the technique described here seems to work well.</p><p>We will evaluate this visual interface in several contexts, and determine whether it is effective in determining relations among documents in post-search result sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GridIR</head><p>Grid computing is an important advance in computational techniques. It has some concepts in common with distributed computing and with massively parallel computing, but many added features. GridIR is IR on the computing grid. The author and his colleagues have worked to form a GridIR working group under the auspices of the Global Grid Forum (http://gridforum.org). We believe that GridIR offers important advantages to IR researchers, and will make experimental and mainstream IR systems more usable and better suited for large-scale research.</p><p>Grid computing has a security model built in, making GridIR suitable for publishing partial extranets or implementing security at the query, collection, document or user level. We are currently working on a draft requirements document for the GGF for delivery in spring 2003, and welcome input and efforts from other IR researchers. Reference systems for GridIR will include IRTools and Amberfish, and we welcome others. Our goal is to develop a set of actual standards for GridIR (under the GGF, following a rulemaking procedure similar to the IETF). We are building on knowledge from Z39.50 and other efforts, and hope to enable a far higher level of interoperability among content maintainers, searchers and IR systems than is now available.</p><p>Visit the GridIR Web site to learn more: http://www.gridir.org.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,72.05,74.68,443.17,10.80;6,72.05,88.48,59.30,10.80;6,72.05,99.55,449.76,338.04"><head>Figure 1</head><label>1</label><figDesc>Figure 1: 3-word query with lines denoting set membership. Clickable documents appear as small cubes.</figDesc><graphic coords="6,72.05,99.55,449.76,338.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,126.05,621.40,308.87,93.60"><head></head><label></label><figDesc>Document summarizationThe toolkit uses the BerkeleyDB for the back end database and Michael Berry's SVDPACKC for eigensystems. Other components are home-grown. The system runs on Unix and Linux systems with the GCC compiler and has been tested extensively on Linux and Solaris systems.</figDesc><table coords="1,126.05,621.40,308.87,93.60"><row><cell>-Several fundamental IR enhancements:</cell></row><row><cell>o Query expansion</cell></row><row><cell>o</cell></row><row><cell>, Chinese and other languages</cell></row><row><cell>-Local file indexing as well as remote harvesting</cell></row><row><cell>-Several fundamental IR techniques:</cell></row><row><cell>o Enhanced Boolean</cell></row><row><cell>o VSM</cell></row><row><cell>o LSI</cell></row><row><cell>o Information space</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,72.05,393.76,446.97,215.32"><head>Table 1 :</head><label>1</label><figDesc>Monolingual Arabic for irtta (title only)</figDesc><table coords="2,72.05,409.32,446.97,199.76"><row><cell cols="2">Total number of documents</cell><cell cols="3">Average precision (non-</cell></row><row><cell>over all queries</cell><cell></cell><cell cols="3">interpolated) for all rel</cell></row><row><cell>Retrieved:</cell><cell>335</cell><cell cols="3">docs(averaged over queries)</cell></row><row><cell>Relevant:</cell><cell>3055</cell><cell></cell><cell></cell><cell>0.0352</cell></row><row><cell>Rel_ret:</cell><cell>121</cell><cell cols="2">Precision:</cell><cell></cell></row><row><cell cols="2">Interpolated Recall -</cell><cell>At</cell><cell>5 docs:</cell><cell>0.2889</cell></row><row><cell>Precision Averages:</cell><cell></cell><cell>At</cell><cell>10 docs:</cell><cell>0.2111</cell></row><row><cell>at 0.00</cell><cell>0.5461</cell><cell>At</cell><cell>15 docs:</cell><cell>0.1741</cell></row><row><cell>at 0.10</cell><cell>0.1937</cell><cell>At</cell><cell>20 docs:</cell><cell>0.1611</cell></row><row><cell>at 0.20</cell><cell>0.0122</cell><cell>At</cell><cell>30 docs:</cell><cell>0.1333</cell></row><row><cell>at 0.30</cell><cell>0.0115</cell><cell cols="2">At 100 docs:</cell><cell>0.0667</cell></row><row><cell>at 0.40</cell><cell>0.0000</cell><cell cols="2">At 200 docs:</cell><cell>0.0336</cell></row><row><cell>at 0.50</cell><cell>0.0000</cell><cell cols="2">At 500 docs:</cell><cell>0.0134</cell></row><row><cell>at 0.60</cell><cell>0.0000</cell><cell cols="2">At 1000 docs:</cell><cell>0.0067</cell></row><row><cell>at 0.70</cell><cell>0.0000</cell><cell cols="3">R-Precision (precision after</cell></row><row><cell>at 0.80</cell><cell>0.0000</cell><cell cols="3">R (= num_rel for a query) docs</cell></row><row><cell>at 0.90</cell><cell>0.0000</cell><cell>retrieved):</cell><cell></cell><cell></cell></row><row><cell>at 1.00</cell><cell>0.0000</cell><cell cols="2">Exact:</cell><cell>0.0537</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,90.05,74.68,446.97,215.32"><head>Table 2 :</head><label>2</label><figDesc>Monolingual Arabic for irtba (whole document)</figDesc><table coords="3,90.05,90.24,446.97,199.76"><row><cell cols="2">Total number of documents</cell><cell cols="3">Average precision (non-</cell></row><row><cell>over all queries</cell><cell></cell><cell cols="3">interpolated) for all rel</cell></row><row><cell>Retrieved:</cell><cell>2411</cell><cell cols="3">docs(averaged over queries)</cell></row><row><cell>Relevant:</cell><cell>4370</cell><cell></cell><cell></cell><cell>0.0709</cell></row><row><cell>Rel_ret:</cell><cell>730</cell><cell cols="2">Precision:</cell><cell></cell></row><row><cell cols="2">Interpolated Recall -</cell><cell>At</cell><cell>5 docs:</cell><cell>0.2059</cell></row><row><cell>Precision Averages:</cell><cell></cell><cell>At</cell><cell>10 docs:</cell><cell>0.1882</cell></row><row><cell>at 0.00</cell><cell>0.4789</cell><cell>At</cell><cell>15 docs:</cell><cell>0.1804</cell></row><row><cell>at 0.10</cell><cell>0.1498</cell><cell>At</cell><cell>20 docs:</cell><cell>0.1691</cell></row><row><cell>at 0.20</cell><cell>0.1216</cell><cell>At</cell><cell>30 docs:</cell><cell>0.1529</cell></row><row><cell>at 0.30</cell><cell>0.0679</cell><cell cols="2">At 100 docs:</cell><cell>0.0894</cell></row><row><cell>at 0.40</cell><cell>0.0671</cell><cell cols="2">At 200 docs:</cell><cell>0.0671</cell></row><row><cell>at 0.50</cell><cell>0.0633</cell><cell cols="2">At 500 docs:</cell><cell>0.0411</cell></row><row><cell>at 0.60</cell><cell>0.0547</cell><cell cols="2">At 1000 docs:</cell><cell>0.0215</cell></row><row><cell>at 0.70</cell><cell>0.0513</cell><cell cols="3">R-Precision (precision after</cell></row><row><cell>at 0.80</cell><cell>0.0000</cell><cell cols="3">R (= num_rel for a query) docs</cell></row><row><cell>at 0.90</cell><cell>0.0000</cell><cell>retrieved):</cell><cell></cell><cell></cell></row><row><cell>at 1.00</cell><cell>0.0000</cell><cell cols="2">Exact:</cell><cell>0.0970</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,72.05,94.48,440.97,220.93"><head>Table 3 :</head><label>3</label><figDesc>Web Topic Distillation for irtwt title-only</figDesc><table coords="4,72.05,115.80,440.97,199.61"><row><cell cols="2">Total number of documents over all</cell><cell cols="3">Average precision (non-</cell></row><row><cell>queries</cell><cell></cell><cell cols="3">interpolated) for all rel</cell></row><row><cell>Retrieved:</cell><cell>901</cell><cell cols="3">docs(averaged over queries)</cell></row><row><cell>Relevant:</cell><cell>737</cell><cell></cell><cell></cell><cell>0.0237</cell></row><row><cell>Rel_ret:</cell><cell>34</cell><cell cols="2">Precision:</cell><cell></cell></row><row><cell cols="2">Interpolated Recall -Precision</cell><cell>At</cell><cell>5 docs:</cell><cell>0.0741</cell></row><row><cell>Averages:</cell><cell></cell><cell>At</cell><cell>10 docs:</cell><cell>0.0519</cell></row><row><cell>at 0.00</cell><cell>0.2232</cell><cell>At</cell><cell>15 docs:</cell><cell>0.0370</cell></row><row><cell>at 0.10</cell><cell>0.0825</cell><cell>At</cell><cell>20 docs:</cell><cell>0.0333</cell></row><row><cell>at 0.20</cell><cell>0.0236</cell><cell>At</cell><cell>30 docs:</cell><cell>0.0284</cell></row><row><cell>at 0.30</cell><cell>0.0035</cell><cell cols="2">At 100 docs:</cell><cell>0.0126</cell></row><row><cell>at 0.40</cell><cell>0.0035</cell><cell cols="2">At 200 docs:</cell><cell>0.0063</cell></row><row><cell>at 0.50</cell><cell>0.0035</cell><cell cols="2">At 500 docs:</cell><cell>0.0025</cell></row><row><cell>at 0.60</cell><cell>0.0000</cell><cell cols="2">At 1000 docs:</cell><cell>0.0013</cell></row><row><cell>at 0.70</cell><cell>0.0000</cell><cell cols="3">R-Precision (precision after R (=</cell></row><row><cell>at 0.80</cell><cell>0.0000</cell><cell cols="3">num_rel for a query) docs</cell></row><row><cell>at 0.90</cell><cell>0.0000</cell><cell cols="2">retrieved):</cell><cell></cell></row><row><cell>at 1.00</cell><cell>0.0000</cell><cell></cell><cell>Exact:</cell><cell>0.0338</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,72.05,340.96,404.97,220.93"><head>Table 4 :</head><label>4</label><figDesc>Web Topic Distillation for irtwb (whole document)</figDesc><table coords="4,72.05,362.28,404.97,199.61"><row><cell cols="2">Total number of documents over all</cell><cell cols="3">Average precision (non-</cell></row><row><cell>queries</cell><cell></cell><cell cols="3">interpolated) for all rel</cell></row><row><cell>Retrieved:</cell><cell>4728</cell><cell cols="3">docs(averaged over queries)</cell></row><row><cell>Relevant:</cell><cell>1574</cell><cell></cell><cell></cell><cell>0.0222</cell></row><row><cell>Rel_ret:</cell><cell>141</cell><cell cols="2">Precision:</cell><cell></cell></row><row><cell cols="2">Interpolated Recall -Precision</cell><cell>At</cell><cell>5 docs:</cell><cell>0.0653</cell></row><row><cell>Averages:</cell><cell></cell><cell>At</cell><cell>10 docs:</cell><cell>0.0429</cell></row><row><cell>at 0.00</cell><cell>0.1153</cell><cell>At</cell><cell>15 docs:</cell><cell>0.0408</cell></row><row><cell>at 0.10</cell><cell>0.0740</cell><cell>At</cell><cell>20 docs:</cell><cell>0.0398</cell></row><row><cell>at 0.20</cell><cell>0.0465</cell><cell>At</cell><cell>30 docs:</cell><cell>0.</cell></row><row><cell>at 0.30</cell><cell>0.0243</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 0.40</cell><cell>0.0235</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 0.50</cell><cell>0.0174</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 0.60</cell><cell>0.0042</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 0.70</cell><cell>0.0010</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 0.80</cell><cell>0.0010</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 0.90</cell><cell>0.0000</cell><cell></cell><cell></cell><cell></cell></row><row><cell>at 1.00</cell><cell>0.0000</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,315.05,464.28,197.97,97.61"><head>0381 At 100 docs: 0.0286 At 200 docs: 0.0144 At 500 docs: 0.0058 At 1000 docs: 0.0029 R-Precision (precision after R (= num_rel for a query) docs retrieved):</head><label></label><figDesc></figDesc><table coords="4,339.04,554.88,119.97,7.01"><row><cell>Exact:</cell><cell>0.0372</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported in part by the <rs type="funder">National Science Foundation</rs> (NSF award #<rs type="grantNumber">CCR-0082655</rs>).</p><p>Many students and employees have worked on the software for this year's results. Their efforts are significant and valued. Some of these fine people include: <rs type="person">Li Chen</rs>, <rs type="person">Nassib Nassar</rs>, <rs type="person">Mao Ni</rs>, <rs type="person">Li Wen</rs>, and <rs type="person">Yuehong Wang. Alan Hudson</rs> and <rs type="funder">Yumetech, Inc.</rs> of Seattle have performed work on the visualizer, under a grant from the <rs type="funder">E.S.P. Das Educational Foundation</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_eDX5egj">
					<idno type="grant-number">CCR-0082655</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>IRTools continues to develop, and despite results being late was able to handle the Web and Arabic tracks with relative ease. Continued work will make IRTools more usable, and integration with the GridIR reference implementation will help to shake out bugs and shape future developments. CLIR continues to be a focus, with new modules for Chinese and Arabic recently added.</p><p>IR researchers are urged to consider GridIR as a possible activity. Credibility and buy-in from IR systems developers, vendors, scholars, etc. will help make GridIR as beneficial as possible.</p></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
