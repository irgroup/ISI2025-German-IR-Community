<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.42,72.61,341.18,17.73;1,253.02,91.03,105.95,17.73;1,298.98,123.05,13.99,13.28">VIDEO SEARCHING AND BROWSING USING VIEWFINDER By</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,126.00,150.65,89.00,13.28;1,270.02,150.65,11.33,13.28"><roleName>Dr</roleName><forename type="first">Dan</forename><forename type="middle">E</forename><surname>Albertson</surname></persName>
						</author>
						<author>
							<persName coords="1,290.02,150.65,74.99,13.28"><forename type="first">Javed</forename><surname>Mostafa</surname></persName>
						</author>
						<author>
							<persName coords="1,413.96,150.65,61.67,13.28;1,126.00,164.45,25.84,13.28"><roleName>Ph. D</roleName><forename type="first">John</forename><surname>Fieber</surname></persName>
						</author>
						<author>
							<persName coords="1,160.67,164.45,40.02,13.28;1,270.05,164.45,99.66,13.28;1,413.93,164.45,25.84,13.28"><roleName>Associate Professor Ph. D</roleName><surname>Student</surname></persName>
						</author>
						<author>
							<persName coords="1,448.60,164.45,53.35,13.28"><surname>Candidate</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Information Science Information Science Information Science School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Indiana University Purdue University at Indianapolis (IUPUI)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.42,72.61,341.18,17.73;1,253.02,91.03,105.95,17.73;1,298.98,123.05,13.99,13.28">VIDEO SEARCHING AND BROWSING USING VIEWFINDER By</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9C68F2AA79E0F68FC16D66D68E2102E3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several researchers consisting of students and faculty from the School of Library and Information Science at Indiana University developed a video retrieval system named ViewFinder for the purpose of providing access to video content for a project named the Cultural digital Library Indexing Our Heritage (CLIOH) at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>With the accumulation of digitized video, groups and individuals are becoming more and more interested in the preservation and organization of such content. Along with this preservation and organization, there is a need for systems that can provide easy and efficient access to archived video. This problem is the focus of ViewFinder, a video retrieval information system.</p><p>The main goal of Viewfinder is to have it applied to a project being conducted at Indiana University Purdue University at Indianapolis (IUPUI) named the Cultural digital Library Indexing Our Heritage (CLIOH). This project deals with the preservation of multi-media content regarding the ancient world (Mayan ruins, etc.). One such form (of content) is video, and this is the current focus of ViewFinder. ViewFinder attempts to provide users with individual keyframes (of shots located within video files) according to the user's information need.</p><p>For the purpose of participating in the Text Retrieval Conference (TREC) and its video track, we took the existing system, made notable modifications, and applied it to the video data provided by the conference. We then followed conference procedures and performed 1 interactive ("human in the loop") search run consisting of 25 individual topics (also provided by the conference). We then generated results and submitted them to TREC, where human assessors compared our results with the number of manually identified relevant shots, and assigned an average precision for each topic. You may further explore the average precision formula used by TREC in <ref type="bibr" coords="2,396.81,102.77,96.40,10.46;2,90.00,116.57,104.01,10.46">Vorhees, E. M., and Harman, D. K. (2001)</ref>. In addition to conducting an interactive search run, our system was developed with use and knowledge of the actual search test collection, known as type-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Literature Review</head><p>In recent years there have been various advances in regards to this research problem. This is possibly due to the large increase of multimedia content (especially video) being digitized and made accessible via the World Wide Web and other multimedia information systems.</p><p>Along with this increase in video content, there is an increase in people who choose to search for such content. <ref type="bibr" coords="2,210.06,282.17,176.69,10.46" target="#b5">Spink, Goodrum, and Hurson (2001)</ref> concluded from a study on Excite query logs between the years 1997 and 1999 that queries for video content increased over 100%. In fact, video queries counted for 0.7% of overall queries in 1997 and counted for 1.6% in 1999 <ref type="bibr" coords="2,235.75,323.57,90.27,10.46" target="#b5">(Spink et al., 2001)</ref>. <ref type="bibr" coords="2,337.21,323.57,89.42,10.46" target="#b5">Spink et al. (2001)</ref> go on to further conclude "video searching became more frequent during this period with the expansion of video material on the Web."</p><p>These findings suggest that it is very important for IR researchers to explore how to better provide easier and more efficient access to video content. Cruz and <ref type="bibr" coords="2,452.06,392.57,64.31,10.46" target="#b1">James (1999)</ref> provide insight into this problem by focusing on aspects such as user query generation coupled with the user-interface design. They go on to detail their system named Delaunay <ref type="bibr" coords="2,139.04,433.91,111.85,10.46" target="#b1">(Cruz and James, 1999)</ref>. They express the importance of users having the capability for "pre-and post-query refinement" (Cruz and <ref type="bibr" coords="2,370.96,447.71,61.16,10.46" target="#b1">James, 1999)</ref>. Furthermore, Cruz and James (1999) also stress the importance of accommodating the search interface to both novice and expert users of multimedia retrieval systems. One example (of their system) is that novice users have the option of a Search Assistant, which may assist in "pre-query refinement" (Cruz and James, 1999). <ref type="bibr" coords="2,90.00,530.51,89.47,10.46" target="#b5">Spink et al. (2001)</ref> also pay close attention to query generation of the user. They claim that, "Web users generally search for multimedia information as they search for textual information" <ref type="bibr" coords="2,154.96,558.11,90.26,10.46" target="#b5">(Spink et al., 2001)</ref>. Also, <ref type="bibr" coords="2,285.10,558.11,87.48,10.46" target="#b5">Spink et al. (2001)</ref>, find that multimedia queries contain more search terms (mean of 2.4) than that of general (non-multimedia) Web queries (mean of 1.91). <ref type="bibr" coords="2,90.00,613.31,89.47,10.46" target="#b5">Spink et al. (2001)</ref> further discovered that the term "video" is the most commonly used query term when users search for video content. This brings them to suggest other search features, such as a file extension <ref type="bibr" coords="2,248.47,640.91,140.59,10.46">(.mpeg, .avi, .mov, .wav, etc)</ref> search feature, which could be very helpful in user query formation <ref type="bibr" coords="2,311.46,654.71,90.28,10.46" target="#b5">(Spink et al., 2001)</ref>.</p><p>While these search features may prove to be helpful in future (video/image) IR systems, current video/image IR systems still primarily utilize text-based searches. Other research has attempted to increase video/image IR system satisfaction by moving away from total reliance of textual searching and incorporating content-based searching. <ref type="bibr" coords="3,441.33,88.97,80.59,10.46;3,90.00,102.77,32.05,10.46" target="#b7">Zhou and Huang (2002)</ref> describe a retrieval system where contextual information (color, shape, texture, etc. described as "low-level features") is combined with user's keywords (or "high-level semantic concepts"). They go on to present that searching on contextual information alone is usually not sufficient in generating relevant results, however, would serve the purpose in thesaurus updating (or adaptation of keywords to images and vice versa) <ref type="bibr" coords="3,90.00,171.77,116.50,10.46" target="#b7">(Zhou and Huang, 2002)</ref>.</p><p>These studies, along with numerous others, reflect the many different directions video retrieval research is currently taking. For example, image and video analysis has been ongoing for many years, and the advancement of this research can be used to explore technologies of (image/video) retrieval. Also, the growing number of users searching for video content has spurred a movement toward applying user-centered design concepts in the development and evaluation of video/image IR systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem</head><p>As mentioned in the earlier sections of this paper, our problem focuses on providing easy and efficient access to video content where large archived (video) data exists. The video data provided by TREC proved to be sufficient in exploring these research problems with ViewFinder. Moreover, the total size of the video collection consisted of 68.45 hours (of MPEG-1) including 40.12 hours for the search test collection, 23.26 hours for the feature development collection, and 5.02 hours for the feature test collection <ref type="bibr" coords="3,423.61,392.57,96.31,10.46;3,90.00,406.37,25.85,10.46" target="#b3">(Smeaton and Over, 2002)</ref>.</p><p>To conduct system tests and the TREC tasks we applied the existing ViewFinder system to the data provided by the conference (through the Internet Archive). Some of the modifications we made to the system consist of a reformulating (system) queries, switch from a MySQL database to Oracle, user-interface adjustments, incorporated a textual keyword search feature, and adapted the search attributes (for proper interaction with the Internet Archive video metadata).</p><p>Due to time constraints, the Oracle database resulted in a very basic structure. The indexed metadata for individual video files include the titles, descriptions, and descriptors (provided by the Internet Archive), which are identified by an automatically generated video id. For each individual shot (keyframe) there is a thumbnail, corresponding URL (to the shot keyframe/thumbnail), and an automatically generated id for both video and shot source. There were a total of 3 tables created for the database. One table contains the shot data (keyframe/thumbnail URL, shot id, and video id), and the other tables contain data corresponding to the video files (e.g. one table contains video id, title, and description fields; and the other table contains video id and descriptor fields).</p><p>Although, this proved to be sufficient data to develop a prototype for participating in the video track, we initially assumed that it wouldn't serve the purpose of a practical video retrieval system. Moreover, although TREC evaluates search returns of individual shots (located within a video file), our database only included metadata corresponding to each individual video file. We would encounter the problem of not being capable to distinguish between shots located within the same video file (other than by visually evaluating the shots after a search has been performed). This prevented us from measuring relevancy rankings between individual shots located within the same video file (e.g. all shots of a matching video are considered "relevant" by the system). For example, once the system identifies any relevant (or matching) video(s), all corresponding keyframes are returned to the user in sequential order. Moreover, if the system matches the user's query to 2 video files, which (both) contain 50 shots, the user would be presented with a shot order such as: shot 1 from video 1, shot 1 from video 2, shot 2 from video 1, shot 2 from video 2 â€¦ up until the final shot. (Here, it is up to the user whether or not to browse the returned keyframes.) In the latter sections of this paper we discuss future improvements of ViewFinder, that we feel will eliminate these problems for upcoming TREC conferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>For our interactive ("human in the loop") search run, we allowed the user to evaluate relevancy of the returned results. Moreover, it was up to the user whether or not to reformulate the query and continue searching, or stop and settle on results. In addition, we also made no attempt to restrict or assist the user in query formulation/reformation, nor did we place any time restriction on the user (for individual search topics).</p><p>While using the ViewFinder system, the user is given several options of searching techniques (or search features). One of the features consists of a keyword search (See Appendix A for Interface Snapshot). This search allows the user to type in keywords and compare them to the description (field) for each individual video file. If there are any matches between the keyword(s) and any video description, the keyframes corresponding to matching video(s) are returned to the user. Moreover, the keyword search performs a "phrasal" search, or in the case that more than one keyword (a phrase) is entered, the exact phrase must match within the video description in order for results to be returned.</p><p>The user is also presented with several (video) attributes in which they are allowed to browse. These attributes are presented to the user in a series of drop down menus (Also See Appendix A for Interface Snapshot). One example is that the user can select "Title" in the "Search By" drop down menu, and retrieve all the video titles in the collection. The user can then select a particular title (by clicking on it and highlighting it) and click the "Search" button, which will run a query for that particular title, and return the associated keyframes.</p><p>A similar operation can be conducted with the "Descriptors" option in the drop down search menu. However, unlike the title search (which will only return results for one individual video title) it is possible for the descriptors search to return shots from several different video files (if the same descriptors overlap for multiple videos).</p><p>Another search option of ViewFinder is the "Promote" search. This is found in the drop down menus located directly below each of the individual keyframe panels (excluding the middle keyframe). This "Promote" feature will take the descriptors associated with that particular keyframe, and compare it with the descriptors for all other video files, and return any matches. Once the "Promote" search feature has been utilized, the "promoted" keyframe is then displayed in the middle (#5) image panel.</p><p>Since ViewFinder can only display up to 9 individual keyframes at one time (8 for search results, and 1 for displaying "promoted" keyframe), the user is still capable of browsing all video shots/keyframes returned (in the case of there being more than 8 matching keyframe). Utilizing the "More Clips" and "Back" buttons located on the interface allows for such browsing. The "More Clips" button becomes initialized after more than 8 keyframes are returned by a query, and the "Back Button" is initialized after the "More Clips" button has been clicked (and the user is on a page other than the first).</p><p>These search sessions ended when the user felt they exhausted all relevant video shots. After the user decided to end each of the search topics, they would select the "Finish" button, which would print out up to 100 (top) search results to the Java console, where they were gathered and formatted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Human assessors from NIST manually judged the relevancy of each returned shot. After concluding on the number of relevant shots returned as compared to the total number of relevant shots identified in the data set, an averaged precision was assigned to each search topic performed. You can read more on the averaged precision formulation in <ref type="bibr" coords="5,90.00,433.91,203.27,10.46">Vorhees, E. M., and Harman, D. K. (2001)</ref>.</p><p>We conducted 1 interactive search run where we attempted to answer all 25 search topics. The mean averaged precision of ViewFinder for all 25 search topics was 0.05472. We had a range of 0.251 with a minimum score of 0.000 (on topics 75 and 85) and a maximum of 0.251 (on topic 76). Ranking among other participating systems included a range from 1st (0.170 topic 94) to a tie for worst (0.000 topics 75 and 85). Moreover, our average ranking for the 25 topics was 17.36 out of an average of 36.88 participating runs. However, there may be some discrepancy in comparing our results with the results of other systems for the reason that search runs (for other systems) varied from interactive to manual, and system development varied from type-A to type-B. (To explore the differences between interactive and manual search runs, and type-A systems and type-B system development please refer to <ref type="bibr" coords="5,262.28,599.51,167.63,10.46" target="#b3">Smeaton, A. F, and Over, P. (2002)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>After reviewing the results, we were initially correct in assuming that the lack of metadata for each individual shot greatly inhibited ViewFinder's searching performance. In future video tracks we plan on populating a database with metadata for each individual shot, which will provide a more robust search for specific information needs. Instead of limiting the search attributes to title, description, and descriptors alone, we would like to add attributes for keywords, subject(s), notable people, important landmarks, and landscapes/cityscapes (just to name a few). Also, we hope to incorporate content-based image retrieval in future versions of ViewFinder. This will allow users to build a more diverse search strategy and allow searches for shots/keyframes with similar shapes, patterns, and colors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,90.00,279.00,431.88,337.62"><head></head><label></label><figDesc></figDesc><graphic coords="7,90.00,279.00,431.88,337.62" type="bitmap" /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>Snapshot of ViewFinder's user-interface. Several search features are being displayed. The "Search By" menu (right hand side) is querying for the titles of the video files. Video titles are then listed in the text box below the "Search By" menu, where one title is highlighted. The "Keyword Search" text field, where the phrase "New York" is entered, is located below the video title listing. Various functions including "Search", "Reset", "More Clips", "Back," and "Finish" buttons are also located below the keyword text field.</p><p>The individual thumbnails/keyframes are displayed to the left of the search features. The "Promote" feature has been utilized and the corresponding keyframe is now displayed in the middle image panel.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,90.00,199.37,403.14,10.46;6,126.00,213.17,362.62,10.46" xml:id="b0">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,277.51,199.37,215.63,10.46;6,126.00,213.17,82.11,10.46">Users&apos; relevance criteria in image retrieval in American history</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="695" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,240.77,416.23,10.46;6,126.00,254.57,383.69,10.46;6,126.00,268.37,378.36,10.46;6,126.00,282.17,21.00,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,265.12,240.77,241.11,10.46;6,126.00,254.57,216.11,10.46">User interface for distributed multimedia database querying with mediator supported refinement</title>
		<author>
			<persName coords=""><forename type="first">Cruz</forename><forename type="middle">I F</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,353.10,254.57,156.59,10.46;6,126.00,268.37,248.09,10.46">Proceedings of the International Database Engineering and Applications Symposium</title>
		<meeting>the International Database Engineering and Applications Symposium<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="433" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,309.77,427.39,10.46;6,126.00,323.57,121.73,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,238.52,309.77,175.13,10.46">Image search engine feature analysis</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,424.26,309.77,93.13,10.46;6,126.00,323.57,34.67,10.46">Online Information Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="114" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,351.17,422.03,10.46;6,126.00,364.97,378.60,10.46;6,126.00,378.77,12.00,10.46;6,138.00,375.88,6.21,6.96;6,147.24,378.77,21.00,10.46;6,168.24,375.88,8.01,6.96;6,176.28,378.77,33.00,10.46" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Over</surname></persName>
		</author>
		<title level="m" coord="6,264.30,351.17,247.73,10.46;6,126.00,364.97,224.32,10.46">The TREC 2002 Video Track Report. Presented at the Eleventh Annual Text Retrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-11-19">2002. November 19 th -22 nd , 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,406.37,409.68,10.46;6,126.00,420.23,336.73,10.46;6,126.00,433.91,195.78,10.46" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="middle">A F</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Over</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Taban</surname></persName>
		</author>
		<title level="m" coord="6,317.31,406.37,182.37,10.46;6,126.00,420.23,336.73,10.46;6,126.00,433.91,53.06,10.46">The TREC-2001 Video Track Report. NIST Special Publications 500-250: The Tenth Annual Text Retrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="52" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,461.51,430.77,10.46;6,126.00,475.31,347.77,10.46;6,126.00,489.11,309.72,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,337.79,461.51,182.98,10.46;6,126.00,475.31,46.46,10.46">Multimedia web queries: Implications for design</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Spink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Goodrum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Hurson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,183.36,475.31,290.41,10.46;6,126.00,489.11,173.10,10.46">Proceedings of the International Conference on Information Technology: Coding and Computing</title>
		<meeting>the International Conference on Information Technology: Coding and Computing<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="589" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,90.00,516.71,420.60,10.46;6,126.00,530.57,392.81,10.46;6,126.00,544.31,80.94,10.46" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Vorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Harman</surname></persName>
		</author>
		<title level="m" coord="6,290.35,516.71,146.13,10.46;6,485.94,516.71,24.66,10.46;6,126.00,530.57,319.22,10.46">NIST Special Publication 500-250: The Tenth Text Retrieval Conference</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="14" to="A23" />
		</imprint>
	</monogr>
	<note>Common Evaluation Measures</note>
</biblStruct>

<biblStruct coords="6,90.00,571.91,411.78,10.46;6,126.00,585.71,202.61,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,269.09,571.91,232.69,10.46;6,126.00,585.71,38.81,10.46">Unifying keywords and visual contents in image retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,175.14,585.71,82.10,10.46">IEEE Multimedia</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="33" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
