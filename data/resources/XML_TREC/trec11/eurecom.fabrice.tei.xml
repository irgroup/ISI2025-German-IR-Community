<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,207.60,105.02,196.08,15.49;1,169.20,126.86,272.80,15.49">Semantic Feature Extraction using Mpeg Macro-block Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,164.88,159.37,106.28,10.76"><forename type="first">Fabrice</forename><surname>Souvannavong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Département Communications Multimédias Institut Eurécom</orgName>
								<address>
									<postCode>2229, 06904</postCode>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Département Communications Multimédias Institut Eurécom</orgName>
								<address>
									<postCode>2229, 06904</postCode>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,279.56,159.37,85.35,10.76"><forename type="first">Bernard</forename><surname>Merialdo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Département Communications Multimédias Institut Eurécom</orgName>
								<address>
									<postCode>2229, 06904</postCode>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Département Communications Multimédias Institut Eurécom</orgName>
								<address>
									<postCode>2229, 06904</postCode>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,388.04,159.37,58.13,10.76"><forename type="first">Benoît</forename><surname>Huet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Département Communications Multimédias Institut Eurécom</orgName>
								<address>
									<postCode>2229, 06904</postCode>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,347.83,229.09,59.84,10.76"><forename type="first">Benoit</forename><surname>Huet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Département Communications Multimédias Institut Eurécom</orgName>
								<address>
									<postCode>2229, 06904</postCode>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,207.60,105.02,196.08,15.49;1,169.20,126.86,272.80,15.49">Semantic Feature Extraction using Mpeg Macro-block Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3919F525EF0DA1489EEDCBACFB5D4B1A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Semantic classification</term>
					<term>Discrete Cosine Transform</term>
					<term>Gaussian Mixture Models</term>
					<term>Compressed Domain</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present some first results in the extraction of semantic features from video sequences. Our approach is based on the classification of Mpeg DCT macro-blocks. Although it is clear that using macro-blocks imposes severe restrictions on the analysis accuracy of the image, it has the advantage of avoiding the complete decoding of the Mpeg stream. Our objective is to evaluate the quality of the Semantic Feature Extraction that can be obtained with this direct approach, to serve as a comparative baseline with more elaborate approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The large amount of visual information, carried by video documents as well as still images, requires efficient and effective indexing and search tools <ref type="bibr" coords="1,217.50,532.50,10.78,8.97" target="#b1">[2,</ref><ref type="bibr" coords="1,231.76,532.50,7.19,8.97" target="#b5">6]</ref>. The U.S. Institute of Standards and Technology sponsors the serie of TREC <ref type="foot" coords="1,99.48,554.54,3.72,6.64" target="#foot_0">1</ref> 2002 conferences to promote progress in contentbased retrieval from digital video. Our work takes place in this context where we focus on the feature extraction task; video shots should be classified into the high level semantic concepts indoor, outdoor, cityscape, landscape, text overlay, face and people.</p><p>To extract relevant features, the content should in principle be decoded first. Since this operation is time consuming, especially when a large video database should be processed, feature extraction directly from the compressed domain would be particularly interesting by providing fast and reliable information analysis and selection tools. Lots of work have been conducted to achieve image or video analysis <ref type="bibr" coords="1,400.45,404.94,10.60,8.97" target="#b2">[3]</ref>, however only few researchers have given solutions to this challenging task with limited decoding of the mpeg stream <ref type="bibr" coords="1,428.49,428.94,15.69,8.97">[10,</ref><ref type="bibr" coords="1,446.70,428.94,7.19,8.97" target="#b3">4]</ref>.</p><p>In this paper, we propose to extract semantic features from 16 by 16 pixels DCT macro-block classification. We have distinguished two types of features in the TREC set, the region-level features like face and text overlay and the frame-level features like indoor, outdoor, cityscape, landscape and people that require elementary concepts like building, greenery, sky and water to be detected.</p><p>The next section details the supervised classification process via Gaussian Mixture Models [9, 7] of macroblocks. Then we explain how the final decision is taken by introducing new elementary concepts to describe framelevel semantics. Finally, we will outline future improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Macro-block Classification</head><p>In the context of supervised classification, three steps are involved: feature extraction and representation, class modelisation and parameter estimation, finally classification with respect to decision rules.</p><p>In our approach, features are directly provided by the video stream after parsing since we work only on Iframes, which are encoded somehow like jpeg pictures. These frames are composed of macro-blocks that contain 6 DCT blocks, 4 for Y color component, 1 for U and 1 for V i.e. 4:2:0 video format. We can represent a DCT macro-block by a vector of size 64 corresponding to the zigzag scan of the DCT block coefficients and then make the concatenation of the 6 vectors to obtain the feature vector of the whole region. Since the first DCT coefficients are the most important i.e: to eye sensitivity and noise, the feature space dimension is simply reduced to 60 by truncation. Moreover coefficients are scaled with respect to their importance in order to increase the sensitivity of the classifier to important components and at the same time to slightly improve the initialisation of the training algorithm, which is usually obtained via k-means algorithm as explained in the next subsection.</p><p>We assume a mixture model to describe the distribution of macro-blocks for each class, and specifically a multi-dimensional Gaussian distribution. Gaussian models can capture the characteristics of a macro-block, while modeling the variation due to motion or lighting conditions. Moreover in <ref type="bibr" coords="2,148.11,425.58,10.60,8.97" target="#b4">[5]</ref>, E.Y. Lam and J.W. Goodman have proven that the distribution of macro-block DCT coefficients can be well approximated by a Gaussian when the variance is constant; in the classification situation, the latter hypothesis is more or less true and mixtures should compensate it. So the probability density function can be written as follows:</p><formula xml:id="formula_0" coords="2,72.60,514.85,210.12,41.55">For X C i ¡ P¢ X £ Φ i ¤ ¦¥ ∑ j α j p j ¢ X ¤ where α i ℜ ¡ Φ i ¥ ¢ µ j ¡ σ j ¤ and p j ¢ X ¤ ¦ § N ¢ µ j ¡ σ j ¤</formula><p>The GMM parameters α j ¡ µ j and σ j are estimated using the traditional Expectation-Maximization algorithm <ref type="bibr" coords="2,288.85,580.14,11.63,8.97" target="#b0">[1]</ref> which is initialized with a classical k-means algorithm. In our current experiments, we also make the hypothesis that feature vector components are independent, thus σ i is a diagonal matrix, or that only color components of the same frequency are correlated, thus σ i is a matrix diagonal by block. Finally the choice of the number of mixtures is simply achieved by looking at the test set loglikelihood evolution of the EM algorithm for various mixture numbers. It should not increase to much in order to avoid data overfitting.</p><p>Given an unlabeled macro-block X, the maximum a posteriori rule:</p><formula xml:id="formula_1" coords="2,382.56,192.28,89.96,18.26">Ĉ ¥ arg max i P¢ Φ i £ X ¤</formula><p>gives an estimation of the class it belongs to. The posterior probabilities can be expanded by Baye's rule:</p><formula xml:id="formula_2" coords="2,310.56,250.24,169.27,60.26">P¢ Φ i £ X ¤ ¨¥ P¢ X £ Φ i ¤ P¢ Φ i ¤ P¢ X ¤ finally, P¢ Φ i £ X ¤ ∝ P¢ X £ Φ i ¤</formula><p>since we assume the equiprobability of classes and vectors. However, it is possible that a macro-block does not belong to any predefined class. Thus we introduce for each model i a minimum bound © mb i for the loglikelihood which is selected to eliminate 10% of the training data set. Of course there is a trade-off to find between precision and recall, see figure <ref type="figure" coords="2,414.96,400.86,3.77,8.97" target="#fig_0">1</ref>. Finally the decision rule can be written:</p><formula xml:id="formula_3" coords="2,327.36,431.44,192.23,18.26">Ĉ ¥ arg max i P¢ X £ Φ i ¤ £ © log¢ P¢ X £ Φ i ¤ ¤ mb i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature detection</head><p>The presented classification method allows to detect region-level features only. In our previous work <ref type="bibr" coords="2,512.40,512.46,11.75,8.97">[8]</ref> we have underlined that macro-blocks could not carry framelevel semantic information but succeed well in providing a lower level semantic. Thus a heuristic two-step hierarchy, depicted in figure <ref type="figure" coords="2,401.16,560.22,3.77,8.97" target="#fig_1">2</ref>, was introduced to detect framelevel concepts via additional elementary semantics. The hierarchy contains three kinds of elements:</p><p>Elementary concepts at the leaves of the hierarchy that are perceivable from macro-blocks,  The detection of features present in one shot is finally achieved with respect to the following procedure:</p><p>1. Classify all macro-blocks of the shot into elementary concepts with respect to preliminary trained Gaussian Mixtures, 2. Compute a detection score for each feature.</p><p>The detection score of the feature i whose elementary childrens are J is simply defined by: Ds i ¥ ∑ j P¢ j ¤ where j J P¢ j ¤ ¦¥ Number of macro-blocks with label j Total number of macro-blocks in the shot It represents the posterior probability of a feature to be in the given shot. Finally, for each feature, shots are ordered by decreasing detection score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Nine video sequences were randomly selected in the development set in order to create training and test samples. Some Macro-blocs of these sequences were labeled with region-level concepts; half to perform the training of semantic classes and half to evaluate models. The fastidious annotation task was achieved over 232 frames and table <ref type="table" coords="3,533.96,305.22,5.03,8.97">1</ref> gives a summary of the accomplished task.</p><p>We have finally modeled classes by fifteen gaussian mixtures and truncated the space dimension to six by fifteen features. This values reveal to be a good compromise between performance and complexity. For the same reasons, we have approximated the co-variance matrix to a diagonal and not diagonal by block matrix, see table 2 that emphasizes the small improvement acquired by using a diagonal by block co-variance matrix.</p><p>Finally figures 3 and 4 show the performance of our method thanks to the assesor's judgement provided by TREC. To evaluate the feature extraction task, we have represented the classical precision and recall curves for the four Trec features outdoors, cityscape, text and face. Encouraging results were obtained for outdoors and cityscape features, however we were expecting better results for text and face features since they are relevant at the macro-block level and the development analysis was forecasting good classification capacities, see table <ref type="table" coords="3,506.89,532.38,3.77,8.97">2</ref>. Several explanations can be envisaged: heterogenous sizes of training sets leading to overtrained and undertrained models and too few training variety conducting to restricted models (for example, no cartoon sequences were used to train models). The results we obtained using a single framework for all visual features, are closely comparable to submitted runs of other labs. In particular we get</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented a method based on DCT information of macro-blocks to detect Trec visual features from video shots in a single framework. Since macro-blocks carry only local information, a heuristic hierarchy was introduced to build the final decision rule at the frame-level and region-level. In gereral this evaluation is encouraging knowing the small extract of the development set used. In future works we plan to investigate methods to automatically elaborate the hierarchy. This will set up a complete probabilistic framework to detect features from low level observations and a more realistic manual annotation at the shot level will be required to train models.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,127.44,218.82,117.71,8.97"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Threshold selection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,127.20,504.06,118.53,8.97"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Concepts hierarchy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,355.44,498.54,139.18,8.97"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Classification Evaluation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,72.00,88.48,438.33,507.34"><head></head><label></label><figDesc>Verbeek, N. Vlassis, and B. Kr. Greedy gaussian mixture learning for texture segmentation. In Workshop on Kernel and Subspace Methods for Computer Vision, 2001. [10] H. Wang and S.-F. Chang. A highly efficient system for automatic face region detection in mpeg video. In IEEE Transactions on Circuits and Systems for Video Technology, volume 7, pages 615-628, August 1997.</figDesc><table coords="5,77.04,88.48,433.29,403.78"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Precision-Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4 Recall</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell>Precision-Recall</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(a) Outdoors</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Precision-Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Precision</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.4</cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">0 0.2 [8] F. Souvannavong, B. Merialdo, and B. Huet. Clas-0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Recall (b) Cityscape Figure 3: Classification Evaluation sification semantique des macro-blocs mpeg dans le domaine compresse. In Compression et Repre-sentation des Signaux Audiovisuels, pages 235-238, 2003. [9] J. 0</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4 Recall</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,86.40,598.42,213.85,7.17;1,72.00,607.90,168.53,7.17;1,72.00,617.38,185.77,7.17"><p>TREC is a series of conferences which high-level goal is the investigation of content-based retrieval from digital video. See http://www-nlpir.nist.gov/projects/t2002v/t2002v.html</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="4,93.59,549.06,207.02,8.97;4,93.60,560.94,207.00,8.97;4,93.60,572.94,206.87,8.97;4,93.60,584.94,22.64,8.97" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,151.24,549.06,149.36,8.97;4,93.60,560.94,207.00,8.97;4,93.60,572.94,160.18,8.97">A gentle tutorial of the em algorithm and its application to parameter estimation for gaussian mixture and hidden markov models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>ICSI-TR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,93.59,604.14,206.84,8.97;4,93.60,616.02,206.98,8.97;4,332.16,306.42,206.98,8.97;4,332.16,318.30,206.91,8.97;4,332.16,330.30,207.05,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,141.78,616.02,158.80,8.97;4,332.16,306.42,203.06,8.97">A fully automated content-based video search engine supporting spatiotemporal queries</title>
		<author>
			<persName coords=""><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,344.15,318.30,194.92,8.97;4,332.16,330.30,68.61,8.97">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="602" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.15,351.54,206.88,8.97;4,332.16,363.54,165.88,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,466.26,351.54,72.76,8.97;4,332.16,363.54,95.58,8.97">Structural and semantic analysis of video</title>
		<author>
			<persName coords=""><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,446.02,363.54,21.49,8.97">ICME</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.15,384.78,206.88,8.97;4,332.16,396.78,206.89,8.97;4,332.16,408.78,207.09,8.97;4,332.16,420.66,207.28,8.97;4,332.16,432.66,22.64,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,459.19,384.78,79.83,8.97;4,332.16,396.78,115.30,8.97">Video classification using transform coefficients</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Girgensohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Foote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,476.73,396.78,62.32,8.97;4,332.16,408.78,207.09,8.97;4,332.16,420.66,86.86,8.97">Proceedings of the International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3045" to="3048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.15,453.90,206.98,8.97;4,332.16,465.90,207.01,8.97;4,332.16,477.78,206.86,8.97;4,332.16,489.78,132.03,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,454.50,453.90,84.63,8.97;4,332.16,465.90,190.74,8.97">A mathematical analysis of the dct coefficient distribution for images</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">Y</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,332.16,477.78,160.23,8.97">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2000-10">October 2000</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1661" to="1666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.15,511.02,207.23,8.97;4,332.16,523.02,206.98,8.97;4,332.16,535.02,207.01,8.97;4,332.16,546.90,105.80,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,493.11,511.02,46.26,8.97;4,332.16,523.02,190.20,8.97">Photobook: Content-based manipulation of image databases</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,332.16,535.02,207.01,8.97;4,332.16,546.90,40.22,8.97">SPIE Storage and Retrieval for Image and Video Databases</title>
		<imprint>
			<date type="published" when="1994-02">february 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,332.15,568.26,206.87,8.97;4,332.16,580.14,207.03,8.97;4,332.16,592.14,207.01,8.97;4,332.16,604.14,206.82,8.97;4,332.16,616.02,97.51,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,332.16,580.14,207.03,8.97;4,332.16,592.14,38.29,8.97">A new multiresolution algorithm for image segmentation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,396.53,592.14,142.64,8.97;4,332.16,604.14,161.63,8.97">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2753" to="2756" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
