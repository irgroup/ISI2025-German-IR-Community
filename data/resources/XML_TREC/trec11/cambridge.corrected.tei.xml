<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.64,84.12,360.40,15.49">Microsoft Cambridge at TREC 2002: Filtering track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.84,116.51,69.05,10.76"><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
						</author>
						<author>
							<persName coords="1,245.28,116.51,43.64,10.76"><forename type="first">S</forename><surname>Walker</surname></persName>
						</author>
						<author>
							<persName coords="1,326.24,116.51,55.97,10.76"><forename type="first">H</forename><surname>Zaragoza</surname></persName>
						</author>
						<author>
							<persName coords="1,419.66,116.51,53.34,10.76"><forename type="first">R</forename><surname>Herbrich</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Ltd</orgName>
								<address>
									<addrLine>7 J.J.Thomson Avenue</addrLine>
									<postCode>CB3 0FB</postCode>
									<settlement>Cambridge</settlement>
									<country>UK email</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Also at City University</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.64,84.12,360.40,15.49">Microsoft Cambridge at TREC 2002: Filtering track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">23D498DC68DAC7D8133B7703EDED1E56</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Six runs were submitted for the Adaptive Filtering track, four on the adaptive filtering task (ok11af??), and two on the routing task (msPUM?). The adaptive filtering system has been somewhat modified from the one used for TREC-10, largely for efficiency and flexibility reasons; the basic filtering algorithms remain similar to those used in recent TRECs. For the routing task, a completely new system based on perceptrons with uneven margins was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Okapi at TRECs 1-10</head><p>A summary of the contributions to TRECs 1-7 by the Okapi team, first at City University London and then at Microsoft, is presented in <ref type="bibr" coords="1,105.42,383.32,10.60,8.97" target="#b5">[6]</ref>. In TRECs 7-10 we took part in the adaptive filtering track, initially concentrating on the thresholding problem, but by TREC-9 we had a full adaptive filtering system with query expansion as well as adaptive thresholding. This adaptation could be used to optimise performance on a number of effectiveness measures and produced good results on both the TREC-9 measures, linear utility and the 'precisionoriented' measure, but performed poorly on the Reuters topics at TREC-10. In earlier TRECs on various adhoc tasks we had concentrated on the weighting schemes and pseudo relevance feedback (blind feedback), and had developed the successful BM25 weighting function but had had only limited success with blind feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Adaptive Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Okapi systems</head><p>At the Microsoft Research laboratory in Cambridge, we are developing an evaluation environment for a wide range of information retrieval experiments. This environment is called Keenbow. The various Okapi systems discussed below are seen as components of Keenbow. Many aspects of the systems, including the weighting scheme and the query expansion methods used, reflect the various components of the probabilistic model of retrieval discussed at length in <ref type="bibr" coords="1,244.83,692.92,10.60,8.97" target="#b8">[9]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Okapi Basic Search System (BSS), which has been used in all Okapi and Okapi/Keenbow TREC experiments up to TREC-9, is a set-oriented ranked output system designed primarily for probabilistic-type retrieval of textual material using inverted indexes. There is a family of built-in weighting functions collectively known as BM25, as described in <ref type="bibr" coords="1,514.44,251.44,10.78,8.97">[5,</ref> Section 3] and subsequent TREC papers. In addition to weighting and ranking facilities it has the usual boolean and quasi-boolean (positional) operations and a number of non-standard set operations. Indexes are of a fairly conventional inverted type. Preprocessing includes stopping and stemming and matching a small exceptions dictionary (selected phrases, synonyms and words marked as not suitable for query expansion).</p><p>The primary method of using the BSS in adaptive filtering upto TREC-10 was to accumulate small batches of documents, index each batch as a separate BSS database, and search the profiles against it. This was not a very efficient process, and has some limitations -for example, adaptation could only be between batches (according to the TREC filtering track rules). For TREC 2002, we developed a new Okapi/Keenbow component called the Basic Filtering Dogsbody (BFD). The primary principle of the BFD is that a database of profiles (queries) is maintained, and each incoming document is searched against this database. In some sense this makes it a true filtering system, as opposed to an adhoc search system adapted for filtering. The BFD itself does not maintain a cumulative database of documents, but does keep up-to-date the dictionary part of such a cumulative database, consisting of terms and collection frequencies.</p><p>Adaptive methods are divided into query expansion or modification and threshold adaptation. Query expansion is performed by the BFD, on the basis of the text query and the cumulated set of known relevant documents (the most recent ones only if there are many). Threshold adaptation is performed by a script built on top of the BFD. This normally involves a search on the reference database, i.e. the cumulative database of all documents received so far. This is a conventional BSS database, and as previously is built in batches (and is therefore not completely up-to-date). Other aspects of the filtering operation, including the history and current state of the profile, are also built as scripts. The master script defines a set of rules for triggering the adaptive procedures; for TREC 2002, the main trigger for updating a profile (query expansion and threshold adaptation) is the retrieval of a relevant document. In the experiments described, this happens at every relevant document, and is immediate (i.e. before the next incoming document is processed). The same procedures are triggered occasionally for documents that have failed to retrieve a relevant document for some time.</p><p>The adaptive filtering runs were done on a 550MHz Xeon (512KB Cache) with 2Gb RAM and a Dell with two 400 MHz Pentium processors and 512 Mb. Both machines were running Solaris 7. The network was 100Mbps ethernet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Algorithms and parameters</head><p>Reports from the last two years <ref type="bibr" coords="2,186.11,200.08,10.78,8.97" target="#b6">[7,</ref><ref type="bibr" coords="2,200.25,200.08,8.27,8.97" target="#b7">8]</ref> contain fairly detailed accounts of the filtering system and the adaptation methods used, in particular the relation between the optimisation measures and the threshold. In respect of the algorithms used, this year's system is very similar to last year's; Table <ref type="table" coords="2,258.88,247.96,5.03,8.97">1</ref> is an attempt to summarise the large number of parameters used. Essentially these parameters were set by a series of tuning experiments on the OHSU filtering database (the OHSUMED test collection, adapted for the filtering task for TREC-9, with the OHSU topic set). While this collection is rather different from the Reuters collection, the intention was to look for parameters that would be generally good, rather than ones that would be highly tuned to a particular database. This aim will be furthered by later work on this year's collection, to see how far from optimal the chosen values are. The one parameter which was adjusted from its best value for OHSU was the target number of documents for initial threshold setting. Since this parameter is an absolute number to be retrieved over the entire test set, it is highly dependent on test set size -in fact it would be better expressed as a proportion or probability than as an absolute number. However, on top of this consideration, the OHSU tuning suggested a rather lower value for utility optimisation than for fbeta optimisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Overview of the filtering procedure</head><p>At a particular iteration of the process, any query modification needs to take place before any threshold setting. It may also be necessary, after query reformulation but before threshold setting, to recalculate the scores of the previously-retrieved documents, for the adaptation of .</p><p>The document collection is processed a document at a time. If a document is retrieved for any profile, it is immediately checked for relevance. If relevant, the query is updated and then the threshold is updated. At intervals defined by the batch size indicated in the table, the reference database is updated with all documents which have arrived since the last batch. Also, any profile that has not been updated since the last batch is updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Filtering results</head><p>As with the official track results, the measures reported are T11SU (scaled utility), T11F (Fbeta measure with beta=0.5), set precision and set recall.</p><p>Four runs were submitted, labelled ok11af[ls][ub]. Those with final letter u were optimised for T11SU, and those with final letter f for T11F. The next-to-last letter represents the source of the text topics -l (long) indicates the full text (title, description and narrative), and s (short) denotes title only. In common with other participants, we found very large differences between our performance on the assessor and intersection topics.</p><p>The results shown in Table <ref type="table" coords="2,432.36,165.16,5.03,8.97" target="#tab_0">2</ref> relate to assessor topics only. They are also very slightly different from the official runs, following discovery of a small bug in the system used. Evaluation is based on the full relevance judgements used for the official evaluation. For the runs corresponding to the official runs, adaptation is based on the relevance judgements available for that purpose. Additional runs were made using all relevance data for adaptation. The coding of the runs is: lms long, medium or short initial topics (medium = title + description)</p><p>ub optimised for utility or FBeta OR adaptation using original or complete relevance judgements Disappointingly, the runs optimised for utility do marginally better on the FBeta measure than the run optimised for FBeta, at least when using the original relevance data. (This is the exact opposite of the result for last year!). It seems that the method for setting thresholds for FBeta, which involves estimating the total relevant in the collection, is producing somewhat erratic results. Further diagnostic testing is required.</p><p>Starting with longer topics may help a little (on utility at least) but the differences do not seem consistent (medium length topics seem to have no advantage over short ones). It seems from the assessor topic results at least that it is possible for an adaptive filtering system to bootstrap its performance reasonably well even if the starting point is not very good.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intersection topics</head><p>However, it is difficult to reconcile the tentative conclusion above with the terrible performance on the intersection topics. One possible suggestion is that the 'relevance' judgements for the intersection topics (i.e. the assignment of documents to two different topic codes by Reuters editorial staff) fail to define a set of related documents with the sort of coherence that we find in assessor relevance judgements. Another is that the pairs of topics may have been unbalanced in some way, leaving it difficult for the filtering systems to infer criteria covering both aspects.</p><p>For the run corresponding to ok11aflu, the results are: T11SU=0.251, T11F=0.040, Precision=6.6%, Recall=2.3%. All the others are similarly bad or worse. We looked in detail at two topics, R195 and R181. R195 is formed by the intersection of Reuters topic categories GVOTE (Elections) Table <ref type="table" coords="3,248.73,77.20,3.90,8.97">1</ref>: Parameters for adaptive filtering See notes below and <ref type="bibr" coords="3,173.78,96.40,10.78,8.97" target="#b6">[7,</ref><ref type="bibr" coords="3,187.08,96.40,8.27,8.97" target="#b7">8]</ref> for explanations of these parameters BM25 parameters:</p><formula xml:id="formula_0" coords="3,244.00,115.00,48.54,29.96">¡ 1.3 ¢ 0.55</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score calibration:</head><p>These parameters define the mapping from Okapi score to probability of relevance -£ ¥¤ §¦ ©¨is estimated as a linear function of score, slope Gamma and intercept Beta. At each threshold updating, Beta (but not Gamma) is re-calibrated using scores of documents of known relevance. The 'mythical reldocs' serve as a Bayesian prior in this re-calibration.</p><p>Initial beta -0.66 Mythical reldocs for beta re-calibration 3 Gamma 2.9</p><p>Threshold adaptation:</p><p>Initially, the threshold is set at a level estimated to retrieve a certain target number of documents over the whole test set. As relevant documents are retrieved, the threshold is moved up a ladder until it reaches the level defined by optimising the required parameter. All those exceeding the threshold are chosen, subject to both a minimum and a maximum number of terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reldocs used for modification 20 Maximum terms 25 Minimum terms 3 Absolute term selection value threshold 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document batching:</head><p>Determines how often the accumulated reference database is updated, and also how often the threshold updating procedure is initiated for profiles which have retrieved no relevant documents since the last such update.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Batch size 50,000</head><p>Further notes on thresholding For Utility, the threshold calibrated as a log-odds probability is raised by one ladder-step for each relevant document retrieved. This is then compared with the level defined by the utility function, and the lower of the two is chosen. After 8 relevant documents have been retrieved, the level defined by the utility function is always chosen. For Fbeta, a similar procedure is followed, but instead of the level defined by the utility function, the estimated optimum Fbeta threshold is used. The ladder function is different from last year. The target is reduced pro-rata according to the estimated remaining number of documents to come, and then further divided by ¤ ¤ "! $# % '&amp; (0) ) 1¤ 32 54 76 98 @ 0A 3B @ 0 C D E2 F# % A HG I4 76 ¥ 2 F# P! H¨.</p><p>Thus if the ladder step is set to 1, the ladder is effectively switched off. Higher values give larger steps. For topic R195, titles of the 3 training documents for adaptive filtering are given in Table <ref type="table" coords="5,176.39,130.96,3.77,8.97" target="#tab_1">3</ref>, together with most of the relevant documents from the test set, and most of those retrieved in run ok11aflu (a few, including some duplicates, have been left out in the interests of saving space).</p><p>It may be seen that the documents found by the system are broadly in the right area -some look less obviously good candidates than others, but there are several in the list which one might reasonably expect to be relevant. One issue is that it seems that in order to qualify for the Election &amp; Welfare category in Reuters, a document has to relate to a particular election. This probably excludes some of the retrieved documents, but not for example number 23, which does indeed relate to the impending British general election, exactly as do 13 and 14. However, 23 was assigned (in addition to GWELF) the code GPOL (Domestic Politics) but not GVOTE. One can only conclude that in this instance at least, the Reuters coding is just not very consistent. Number 26 is even worse -it has various headings relating to economics and finance, and GPOL and GCAT (Government/Social), but not GVOTE (despite the fact that it reports a campaign speech by someone not then in government) and not GWELF (despite the fact that a significant part is about poverty and unemployment).</p><p>We might have hoped to retrieve at least some of the relevant set. However, the filtering system is quite sensitive to adaptation -if it is getting no encouragement (in the form of positive relevance judgements) it will keep the threshold very high (the penalties for allowing through much more are too great).</p><p>In the case of topic R181, we show just the three training examples in Table <ref type="table" coords="5,128.55,472.00,5.03,8.97" target="#tab_2">4</ref> In this case, two of the titles relate to the same story. The interpretation of Reuters topic C411 (Management Moves) is supposed to be moves such as management appointments or resignations. Number 1 has a brief mention of an appointment in a story about the bankruptcy of FoxMeyer; number 2 is essentially an abbreviated version of no. 1, though the appointment part has been retained. Number 3 has (in our interpretation) no management moves in the sense given at all: the receiver is seeking not an individual but a financial institution to manage and sell a stake in another company. The ok11aflu run retrieved 12 documents, all squarely in the insolvency area, but none containing management moves. (Several of them relate to FoxMeyer, but there is also a group relating to Bulgarian banks. The one Bulgarian bank story which was marked as relevant was not selected in ok11aflu.) Thus this example seems to be an instance of one of the two original Reuters categories dominating. However, part of the reason is the choice of positive examples for training -it is certainly the case that those particular examples emphasise only one of the Reuters categories.</p><p>Reuters categories are often very broad concepts, and must be hard to assign consistently. On the evidence of these two cases, one might suggest that the intersection operation, together with the accidental choice of training examples, has significantly compounded the noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Routing</head><p>The perceptron-based system was developed for the TREC routing task independently of Okapi. The theoretical work leading to this model was carried out in 2001 and first evaluations on smaller datasets (such as Reuters-21578) were carried out at the beginning of this year <ref type="bibr" coords="5,448.17,208.60,10.60,8.97" target="#b3">[4]</ref>. Our TREC 2002 runs constituted the first full-scale implementation and evaluation of this model.</p><p>Research on Perceptrons is motivated by the recent success of soft-margin support vector machines for routing <ref type="bibr" coords="5,519.11,256.36,10.60,8.97" target="#b2">[3]</ref>. Softmargin support vector machines are high-dimensional linear classifiers that maximise a quantity called the margin while keeping the training error close to zero. Because of the intimate relationship between margin and generalisation error, maximising the former will (asymptotically) minimise the latter.</p><p>When the training set is not linearly separable in its feature space the margin is maximised while allowing a small number of misclassification errors. The cost of a misclassification is determined prior to training by a learning parameter, . An additional parameter, ¡ , is used to weight differently positive and negative misclassifications. These two parameters are set in general by -fold cross-validation ( <ref type="bibr" coords="5,462.06,411.88,10.43,8.97" target="#b2">[3]</ref>).</p><p>Different theoretical and practical reasons made us search for alternative solutions to the SVM for the task of document routing:</p><p>1. It is theoretically not clear under which conditions large margin classifiers may lead to good rankings (as opposed to good classification).</p><p>2. There are other linear classifiers which do not maximise the margin but perform as well as the SVM for many classification tasks. Generalisation error bounds for these algorithms exist and some are tighter than those of the soft margin SVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Training times for SVMs are extremely long.</p><p>4. The need to optimise and ¡ multiplies the number of times we need to train the systems.</p><p>In particular, the perceptron learning algorithm (PLA) is a fast learning algorithm for linear classifiers, and it has been shown recently that it shares with the SVM some strong theoretical properties. In particular, one can show that sparsity for the perceptron (roughly speaking, the number of training updates) works similarly to margin for the SVM, that is, high sparsity guarantees low generalisation error. Furthermore, it has been shown that the existence of a large margin solution implies the high sparsity of perceptron solutions. This means, again roughly speaking, that if there exists a good SVM solution (that is, one with a large margin) then the perceptron solution on the same dataset is likely to be good as well (see <ref type="bibr" coords="6,54.00,105.04,25.77,8.97">[1] [4]</ref> for a more formal discussion of these topics).</p><p>Our initial experiments in routing with the PLA (using the Reuters-21578 topics collection, and the average precision performance measure) showed that although it was slightly outperforming the SVM for topics with many positive examples, it underperformed significantly for smaller topics. This seems to indicate that one needs to impose some margin constraints on very small topics.</p><p>The margin-PLA <ref type="bibr" coords="6,134.69,200.68,11.63,8.97" target="#b1">[2]</ref> is a modified PLA which guarantees a solution with a minimum margin, i.e. the resulting margin is within a factor of ¡ ¤ £¢ ¤ ¦¥ ¨ § H¨of the maximum possible margin (which would be found by an SVM). is therefore a parameter (similar to ) which must be set prior to training. While experiments with the margin-PLA showed improvement in performance over the PLA for small topics, it greatly increased the training time and decreased the sparsity of the solution. One of the reasons for this is that the margin constraints are symmetrical, that is, if we wish to enforce a large margin with respect to the relevant documents, we must do the same with respect to the irrelevant documents -a task that is too expensive because of their large number.</p><p>For these reasons, we modified the margin-PLA algorithm to take account of the asymmetry of the problem, and we replaced the constant by two constants, © ¡ and ¡ , which enforce different margins with respect to the relevant (¥ § ) and irrelevant ( § ) documents. This led to a great improvement of the speed of the training algorithm and the sparsity of the resulting solutions. Furthermore, when we optimised by cross validation the parameters © ¡ and ¡ the resulting solutions outperformed the SVM on Reuters-21578 <ref type="bibr" coords="6,222.88,451.72,10.60,8.97" target="#b3">[4]</ref>.</p><p>In the following sections we describe our algorithm, the perceptron learning algorithm with uneven margins (or PLAUM), its implementation for the TREC 2002 routing task, and summarise the results obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The PLAUM algorithm</head><p>We present in Algorithm 1 the PLAUM as implemented for our TREC 2002 routing experiments. Basically, we iterate over the training sample testing for every pattern if the output</p><formula xml:id="formula_1" coords="6,54.00,575.90,107.70,16.80">of our classifier ¤ ! " $# % '&amp; ¥</formula><p>¢ ¨is of the right sign and, even more, greater than the required factor on the minimal margin for the pattern's class ( , 0) 21 . When all the patterns satisfy this condition, the algorithm stops. Despite the high dimension of documents (from hundreds to tens of thousands) linear separability cannot always be guaranteed. This condition can be relaxed by the so-called 3trick, which extends each document vector by a vector of size 4 with value 3 for the 5 th coordinate and zero elsewhere (4 is the number of training documents). To implement this it suffices to redefine the inner-product function as:</p><formula xml:id="formula_2" coords="6,58.00,705.80,137.59,17.75">" # % '&amp; ¦6 87 @9 BA C ED ¡ " C % GF C ¥ " A © 3 .</formula><p>The PLAUM algorithm with the 3 -trick is guaranteed to always stop at a solution if 3 IH QP . Nevertheless, in some pathological cases the algorithm can iterate a very large number of times. For this reason we include the parameter R which sets a maximum to the number of epochs (iterations over the training set) allowed.</p><p>Finally, for completeness we have included in the algorithm the learning parameter S . However, in our experiments this parameter was always set to § .</p><formula xml:id="formula_3" coords="6,311.04,168.90,148.46,20.00">Algorithm 1 PAUM ¤ G ¤ ¡ # T© ¡ # R # S # EU</formula><p>Require:</p><p>A linearly separable training sample</p><formula xml:id="formula_4" coords="6,311.04,197.80,215.53,50.60">U V6 87 ¤ XW # !Y ¦`¤ £a cb ed f § # ¥ § ¤g ¨A Require: A learning rate S hpi © Require: A maximum epochs parameter R Require: Two margin parameters ¡ # © ¡ pi ©</formula><p>epoch q rP ts u5 vq w § fs updated q x4 " q</p><formula xml:id="formula_5" coords="6,321.00,250.50,148.92,167.20">P ts ¢ 7 P ts 1¦ yq x v 1 ' W repeat if ( ¤ % " # &amp; ¥ ¢ ¦ T) 1 then " q " ¥ S ( % ¢ q ¢ ¥ S ( ¦ updated q d5 end if 5 eq x5 f¥ g § if ¤ G5 hH i4 ¨then 5 eq w § fs epoch q epoch¥ § end if until (5 7 updated) or (epoch j kR ) return ¤ Xl # ¢ 4.2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data representation</head><p>We considered two different representations of the documents: the usual tf b idf representation and a BM25-based representation where idf's are replaced by topic-dependent BM25 weights.</p><p>Pre-processing was kept to a minimum: no stemming was used nor were stop words removed. Punctuation marks and letter case were removed, and all character strings appearing in fewer than three documents were eliminated. All other character strings became features (terms) of the linear classifier.</p><p>For the tf b idf representation all resulting features in the training set were considered (approximately § TP mP nP fP ). For the BM25-based representation only features in relevant documents were considered (approx. 600 on average). Finally all vectors were normalised to have unit Euclidean norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Selection</head><p>Two parameters need to be set prior to training: © ¡ and ¡ .</p><p>To choose these values we proceeded as follows:</p><p>First, the training set was randomly split into two halves, one half used for training and the other used for testing. Sec- # § fg , leading to 16 different runs per topic. This procedure was repeated 5 times, choosing a different random train/test split every time, and performance on different splits was averaged. This resulted in an average precision reading per topic and per ¤ X T© ¡ # ¡ ¨setting. Finally, for each topic the best ¤ G T© ¡ # ¡ ¨parameters were selected and used to train the final model over the entire training set.</p><p>The training algorithm was run on a 2.5GHz CPU machine with 500Mb of memory. Data was accessed from a SQL server over a 100Mhz Ethernet network. The entire model selection procedure for the 100 topics and 5 splits runs under 5 hours. We believe that code properly optimised for speed could finalise this task under one hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>Due to time and resource limitations we restricted our preliminary experiments to the Reuters-21587 routing task, we have not performed any TREC runs besides those submitted.</p><p>Two runs were submitted, varying only in the size of feature set used (as discussed in section 4.2), very large for msPUMb and small for msPUMs. Results are summarised in 4.4.</p><p>The large feature set model msPUMb greatly outperformed the small feature set model on average. This is not surprising, especially when we consider i) how little pre-processing was done with the documents, and ii) the simplicity of the term selection procedure. Nevertheless, for a number of topics the small feature set was better than or similar to the larger feature set. On the left-most column of Table <ref type="table" coords="7,464.71,116.92,4.19,8.97" target="#tab_2">4</ref>.4 we show macro average precision when we average only over the topics obtaining more than 0.1 average precision (we indicated in parenthesis the number of these topics). This figure is very close for both systems, indicating that msPUMs is in fact performing similarly to msPMs for many topics, but it completely underperforms for others. If we could detect such topics at learning time we could adapt the size of the feature sets to the nature of the topics. We are currently working on this problem. There are many algorithms for feature selection and projection which we could have used. However, it has been observed empirically by several authors that using linear classifiers for text seems to benefit from the maximum number of features available. In the absence of space, memory or computational time limitations, we did away with feature selection methods. However, in real operational settings the situation is very different. As one increases the number of features (or similarly if the sparsity of a classifier decreases), the number of potentially relevant documents that need to be scored for each topic increases rapidly. This is very dangerous for systems that must filter simultaneously a large number of topics and documents. Is it then justified to use § TP mP nP fP features if 80% of the performance can be obtained using only 50 features? This difficult issue is not addressed by the present TREC evaluation measures.</p><p>In tables 4.4 and 4.4 we present some results to demonstrate the superiority of the PLAUM algorithm with respect to PLA and the interest in running a model selection procedure such as the one outlined in this paper. For these comparisons we consider only the msPUMb model. We note that these results are better than those submitted originally: after submission we discovered an error in our data normalisation procedure; after correcting it the performance of all models was increased.</p><p>In table <ref type="table" coords="7,359.96,519.28,4.19,8.97" target="#tab_2">4</ref>.4 we compare macro-average precision performance (for all topics and for only the first 50) of the original PLA algorithm, a simple PLAUM model with ¤ X 0© ¡ 7 ¥ § # T# ¡ 7 P ¨, and the PLAUM model obtained us- ing the model selection procedure discussed in 4.3. We observe that the original PLA algorithm yields very good performance already and that enforcing some positive margin (i.e. © ¡ 7 ¥ § ) increases this performance further. Nevertheless, the best results are obtained when the s are selected for each topic.</p><p>In table 4.4 we compare several figures of merit of the original PLA and our PLAUM(*) model. As expected, learning the PLAUM(*) model requires more updates and more epochs, but its sparsity is not greatly reduced and the resulting training and testing times are perfectly reasonable. In fact, once the model selection step is completed, the difference in training time is negligible compared to IO and scoring time.</p><p>The performance of the basic Okapi filtering system, tuned for OHSUMED data but run on this year's Reuters task, is fair but not outstanding. The problem of estimating the total number of relevant documents in the entire collection, which is necessary for optimising the FBeta measure, has not been investigated further since last year; it may be one reason why the FBeta-optimised runs performed worse on FBeta than the utility-optimised runs.</p><p>The PAUM method for routing appears promising. It could be applied to batch filtering (we have not yet done so); but as with many such machine learning methods, it presents problems if we want to apply it to adaptive filtering. This remains a challenge.</p><p>Our performance (with two very different methods on two different tasks) on the intersection topics was extremely poor. This may be because they are simply more difficult, but we suspect that the intersection method is not a very good way to define sufficiently coherent topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,94.32,330.28,175.61,8.97;3,92.04,342.28,177.89,8.97;3,201.24,354.28,63.77,8.97;3,90.00,371.44,80.78,8.97;3,90.00,388.84,431.73,8.97;3,90.00,400.84,431.73,8.97"><head>2</head><label>2</label><figDesc>Initial target no. of documents (FBeta) 70 Initial target no. of documents (Utility) 25 Ladder step Query modification: Query modification uses the last relevant documents retrieved (including the training sample if necessary), together with the original text query. Terms are ranked by absolute term selection value (new offer weight).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,144.36,64.00,323.04,228.21"><head>Table 2 :</head><label>2</label><figDesc>Main results</figDesc><table coords="4,144.36,78.40,323.04,213.81"><row><cell cols="2">Utility optimisation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Relevance</cell><cell>Corresponding</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Topics</cell><cell cols="2">judgements official</cell><cell cols="3">T11SU T11F Precision Recall</cell></row><row><cell></cell><cell>used for</cell><cell>run</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>adaptation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>long</cell><cell>original</cell><cell>ok11aflu</cell><cell>0.435 0.421</cell><cell>49.9</cell><cell>34.4</cell></row><row><cell>long</cell><cell>all</cell><cell></cell><cell>0.439 0.419</cell><cell>46.8</cell><cell>37.8</cell></row><row><cell cols="2">medium original</cell><cell></cell><cell>0.405 0.405</cell><cell>48.5</cell><cell>31.9</cell></row><row><cell cols="2">medium all</cell><cell></cell><cell>0.412 0.405</cell><cell>46.8</cell><cell>34.4</cell></row><row><cell>short</cell><cell>original</cell><cell>ok11afsu</cell><cell>0.406 0.404</cell><cell>48.2</cell><cell>33.0</cell></row><row><cell>short</cell><cell>all</cell><cell></cell><cell>0.418 0.413</cell><cell>46.2</cell><cell>36.7</cell></row><row><cell cols="2">FBeta optimisation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>long</cell><cell>original</cell><cell>ok11aflb</cell><cell>0.405 0.394</cell><cell>52.4</cell><cell>26.1</cell></row><row><cell>long</cell><cell>all</cell><cell></cell><cell>0.410 0.405</cell><cell>50.4</cell><cell>28.4</cell></row><row><cell cols="2">medium original</cell><cell></cell><cell>0.396 0.392</cell><cell>52.0</cell><cell>26.3</cell></row><row><cell cols="2">medium all</cell><cell></cell><cell>0.411 0.415</cell><cell>50.6</cell><cell>29.7</cell></row><row><cell>short</cell><cell>original</cell><cell>ok11afsb</cell><cell>0.404 0.393</cell><cell>52.0</cell><cell>25.9</cell></row><row><cell>short</cell><cell>all</cell><cell></cell><cell>0.418 0.411</cell><cell>50.8</cell><cell>29.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,161.76,312.04,288.43,336.93"><head>Table 3 :</head><label>3</label><figDesc>Titles of relevant and retrieved documents, topic R195</figDesc><table coords="4,161.76,328.36,288.43,320.61"><row><cell>Training</cell><cell>1 Churches put poverty on NZ election agenda</cell></row><row><cell>relevant:</cell><cell>2 Dole accuses Clinton of "mediscare" ad campaign</cell></row><row><cell></cell><cell>3 Clinton blocks federal loans to deadbeat parents</cell></row><row><cell>Test</cell><cell>4 Florida's elderly key to Dole campaign</cell></row><row><cell>relevant:</cell><cell>5 U.S. group seeks child food-aid support</cell></row><row><cell></cell><cell>6 Poverty is toughest task for next Nicaraguan leader</cell></row><row><cell></cell><cell>7 Dole visits Florida, promises to save medicare</cell></row><row><cell></cell><cell>8 Relaxed, confident Clinton stumps in central Florida</cell></row><row><cell></cell><cell>9 Clinton would mull law aiding retirees if elected</cell></row><row><cell></cell><cell>10 Arizona voters back lottery measure</cell></row><row><cell></cell><cell>11 NZ's National, Labour agree to pension referendum</cell></row><row><cell></cell><cell>12 Poland's pension reform under election cloud</cell></row><row><cell></cell><cell>13 UK's Dorrell details old age care insurance plan</cell></row><row><cell></cell><cell>14 UK welfare reform to head Major's election agenda</cell></row><row><cell></cell><cell>15 Polish Solidarity sees growth as top economic goal</cell></row><row><cell cols="2">Retrieved: 16 S. Africa releases conservative welfare blueprint</cell></row><row><cell></cell><cell>17 NYC agency says welfare poses big budget challenge</cell></row><row><cell></cell><cell>18 The inexorable GST [Australian sales tax]</cell></row><row><cell></cell><cell>19 New Moldovan leader seen backing market reforms</cell></row><row><cell></cell><cell>20 Despite good times, many in U.S. need charity</cell></row><row><cell></cell><cell>21 HUD chief warns U.S. near housing crisis for poor</cell></row><row><cell></cell><cell>22 Study finds up to 10% of Swiss are poor</cell></row><row><cell></cell><cell>23 UK's Blair to unveil welfare plans</cell></row><row><cell></cell><cell>24 British magazine offers help to homeless</cell></row><row><cell></cell><cell>25 French government approves anti-poverty plan</cell></row><row><cell></cell><cell>26 UK Labour's Brown vows no tax and spend cure-all</cell></row><row><cell></cell><cell>27 French MPs debate controversial anti-poverty bill</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,155.28,668.80,301.47,49.29"><head>Table 4 :</head><label>4</label><figDesc>Titles of training relevant documents, topic R181Training 1 FoxMeyer Drug declares bankruptcy after sale falls through relevant: 2 Foxmeyer says drug unit files for bankruptcy 3 Westa receiver seeks Prochnik manager and GWELF (Welfare, Social Services); R181 from C16 (Insolvency/liquidity) and C411 (Management Moves). In both these cases, as in many other intersection topics, there is no overlap at all between test relevant and retrieved: recall, precision, FBeta, unnormalised utility are all zero.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,54.00,64.00,476.60,243.75"><head>Table 5 :</head><label>5</label><figDesc>(Submitted Runs)  Routing results, PLAUM algorithm. Macro-Average Precision.</figDesc><table coords="7,54.00,79.10,476.60,228.65"><row><cell></cell><cell></cell><cell>Run</cell><cell>TOPICS</cell><cell>MAP MAP(H ¡  § )</cell></row><row><cell></cell><cell cols="4">msPUMb R101-151 0.355 .368 (#48)</cell></row><row><cell></cell><cell cols="4">msPUMs R101-150 0.239 .348 (#34) msPUMb R151-200 ¢ P -msPUMs R151-200 ¢ P -</cell></row><row><cell cols="5">Table 6: (Post-Submission) Effects of and Model Selection</cell></row><row><cell cols="5">(see text for details). Macro-Average Precision for all topics</cell></row><row><cell cols="5">(Test) and for topics R101-150 (Train/Test[50]).</cell></row><row><cell></cell><cell></cell><cell>Model</cell><cell cols="2">Test Test[50] Train[50]</cell></row><row><cell></cell><cell></cell><cell>PLA</cell><cell>0.211</cell><cell>0.376</cell><cell>0.4801</cell></row><row><cell></cell><cell cols="3">PLAUM (+1,0) 0.219</cell><cell>0.385</cell><cell>0.513</cell></row><row><cell></cell><cell cols="2">PLAUM(*)</cell><cell>0.224</cell><cell>0.403</cell><cell>0.54</cell></row><row><cell cols="5">ond, the 100 models corresponding to the 100 topics were trained independently for © ¡ `d P #  § #  § TP #  § TP nP ug and ¡ dn</cell></row><row><cell>§ P</cell><cell>#  §</cell><cell># P</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,54.00,601.60,246.84,116.61"><head>Table 7</head><label>7</label><figDesc></figDesc><table coords="7,54.00,601.60,246.84,116.61"><row><cell cols="3">: (Post-Submission) Some figures of merit of the PLA</cell></row><row><cell cols="3">and the selected PLAUM(*), averaged over all 100 topics.</cell></row><row><cell></cell><cell cols="2">PLA PLAUM(*)</cell></row><row><cell>Average Precision</cell><cell>.211</cell><cell>.224</cell></row><row><cell>Non-Zero Weights</cell><cell>1179</cell><cell>2236</cell></row><row><cell>Epochs</cell><cell>3.6</cell><cell>13.1</cell></row><row><cell>Updates</cell><cell>17.5</cell><cell>77.8</cell></row><row><cell>Selection time</cell><cell>-</cell><cell>1.87 s.</cell></row><row><cell>Train time</cell><cell>.22 s.</cell><cell>-</cell></row><row><cell cols="2">Train+Test+Submit time 45s.</cell><cell>45s.</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,70.54,337.96,230.37,8.97;8,70.56,349.96,230.38,8.97;8,70.56,361.96,200.71,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,70.56,349.96,94.75,8.97">From margin to sparsity</title>
		<author>
			<persName coords=""><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,183.95,349.96,116.98,8.97;8,70.56,361.96,106.67,8.97">Advances in Neural Information Processing Systems 13</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="210" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.54,380.56,230.37,8.97;8,70.56,392.56,230.27,8.97;8,70.56,404.56,75.23,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,183.09,380.56,117.83,8.97;8,70.56,392.56,132.91,8.97">Learning algorithms with optimal stability in neural networks</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Krauth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mézard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,213.57,392.56,82.94,8.97">Journal of Physics A</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="745" to="752" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.54,423.16,230.25,8.97;8,70.56,435.16,230.27,8.97;8,70.56,447.16,213.07,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,132.52,423.16,168.27,8.97;8,70.56,435.16,172.45,8.97">Applying support vector machines to the trec-2001 batch filtering and routing tasks</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,267.01,435.16,33.81,8.97;8,70.56,447.16,118.64,8.97">Text Retrieval Conference (TREC-10)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="286" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.54,465.88,230.35,8.97;8,70.56,477.76,230.24,8.97;8,70.56,489.76,230.36,8.97;8,70.56,501.64,230.23,8.97;8,70.56,513.64,230.47,8.97;8,70.56,525.64,44.24,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,176.86,477.76,123.94,8.97;8,70.56,489.76,63.01,8.97">The perceptron algorithm with uneven margins</title>
		<author>
			<persName coords=""><forename type="first">Yaoyong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaz</forename><surname>Kandola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.50,501.64,159.28,8.97;8,70.56,513.64,125.95,8.97">Nineteenth International Conference on Machine Learning, ICML&apos;2002</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.54,544.24,230.31,8.97;8,70.56,556.24,230.27,8.97;8,70.56,568.24,230.23,8.97;8,70.56,580.12,166.23,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,163.46,544.24,71.77,8.97">Okapi at TREC-3</title>
		<author>
			<persName coords=""><surname>S E Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,120.77,556.24,180.06,8.97;8,70.56,568.24,59.04,8.97">Overview of the Third Text REtrieval Conference (TREC-3)</title>
		<editor>
			<persName><forename type="first">D K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="500" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.54,598.84,230.28,8.97;8,70.56,610.84,230.28,8.97;8,70.56,622.72,230.38,8.97;8,70.56,634.72,230.38,8.97;8,70.56,646.72,62.90,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,192.70,598.84,108.12,8.97;8,70.56,610.84,3.77,8.97">Okapi/Keenbow at TREC-8</title>
		<author>
			<persName coords=""><forename type="first">S E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,285.86,610.84,14.98,8.97;8,70.56,622.72,176.89,8.97">The Eighth Text REtrieval Conference (TREC-8)</title>
		<title level="s" coord="8,220.13,634.72,76.74,8.97">NIST Special Publi</title>
		<editor>
			<persName><forename type="first">E M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="500" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.54,665.32,230.54,8.97;8,70.56,677.32,230.45,8.97;8,70.56,689.32,230.29,8.97;8,70.56,701.20,230.23,8.97;8,70.56,713.20,166.24,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,212.02,665.32,89.07,8.97;8,70.56,677.32,116.99,8.97">Microsoft Cambridge at TREC-9: Filtering track</title>
		<author>
			<persName coords=""><forename type="first">S E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,164.29,689.32,136.56,8.97;8,70.56,701.20,59.04,8.97">The Ninth Text REtrieval Conference (TREC-9)</title>
		<editor>
			<persName><forename type="first">E M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="500" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,327.58,57.16,230.40,8.97;8,327.60,69.16,230.17,8.97;8,327.60,81.04,230.27,8.97;8,327.60,93.04,230.22,8.97;8,327.60,105.04,230.40,8.97;8,327.60,116.92,17.60,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,518.55,57.16,39.44,8.97;8,327.60,69.16,195.34,8.97">Microsoft Cambridge at TREC-10: Filtering and web tracks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>S E Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,478.97,81.04,78.90,8.97;8,327.60,93.04,71.61,8.97">The Tenth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">E M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2001">2001. 2002</date>
			<biblScope unit="page" from="500" to="250" />
		</imprint>
	</monogr>
	<note>TREC</note>
</biblStruct>

<biblStruct coords="8,327.58,136.84,230.38,8.97;8,327.60,148.84,230.26,8.97;8,327.60,160.72,230.24,8.97;8,327.60,172.72,230.22,8.97;8,327.60,184.72,22.64,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,521.65,136.84,36.31,8.97;8,327.60,148.84,230.26,8.97;8,327.60,160.72,100.35,8.97">A probabilistic model of information retrieval: development and comparative experiments</title>
		<author>
			<persName coords=""><forename type="first">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,442.30,160.72,115.54,8.97;8,327.60,172.72,49.57,8.97">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="809" to="840" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Part 2</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
