<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.60,75.65,339.17,14.47;1,249.63,94.13,112.91,14.47">TREC-10 Experiments at University of Maryland CLIR and Video</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,102.28,124.94,77.38,9.94"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Advanced Computer Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,191.79,124.94,77.33,9.94"><forename type="first">David</forename><surname>Doermann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Advanced Computer Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.95,124.94,51.94,9.94"><forename type="first">Ryan</forename><surname>Jones</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Advanced Computer Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.71,124.94,65.66,9.94"><forename type="first">Douglas</forename><surname>Oard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Advanced Computer Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,426.50,124.94,79.82,9.94"><forename type="first">Mika</forename><surname>Rautiainen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Advanced Computer Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.60,75.65,339.17,14.47;1,249.63,94.13,112.91,14.47">TREC-10 Experiments at University of Maryland CLIR and Video</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7A122A1634B8DB91D171081A33A1D2A4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The University of Maryland Researchers participated in both the Arabic-English Cross Language Information Retrieval (CLIR) and Video tracks of TREC-10. In the CLIR track, our goal was to explore effective monolingual Arabic IR techniques and effective query translation from English to Arabic for cross language IR. For the monolingual part, the use of the different index terms including words, stems, roots, and character n-grams were explored. For the English-Arabic CLIR, the use of MT, wordlist based translation, and non-dictionary words transliteration was explored. In the video track, we participated in the shot boundary detection, and known item search with the primary goals being to evaluate existing technology for shot detection and a new approach to extending simple visual image queries to video sequences. We present a general overview of the approaches, summarize the results in discuss how the algorithms are being extended.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">CLIR Track 1.Introduction</head><p>For the CLIR track, we were interested in testing the effects of the choice of Arabic index terms, the use of morphology, and transliteration of words that are not in the dictionary. To test the effects before the ad-hoc TREC runs, we used a small Arabic collection called Zad. In the ad-hoc experiments we relied on insight gained from the small Arabic collection. In post-hoc TREC experiments, we examined the effects of different index terms on the Arabic monolingual and English to Arabic cross language retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Methodology</head><p>Many new techniques were employed for ad-hoc TREC runs. The ideas were initially tested on a small side collection to verify the effectiveness of the proposed techniques. The collection is called Zad which was provided by Al-Areeb Electronic Publishers, LLC <ref type="bibr" coords="1,335.55,472.20,11.61,9.94">[2]</ref>. The collection contains 4,000 documents. The documents were extracted from writings of the thirteenth century scholar Ibn Al-Qayim and cover issues of history, jurisprudence, spirituality, and mannerisms. Also, there are 25 queries with their relevance judgments associated with the collection. The queries are typically 3-6 words long and are available in Arabic and English. The author developed the queries in Arabic, generated the relevance judgments by exhaustively examining the documents in the collection, and translated them to English.</p><p>The techniques addressed the choice of Arabic index terms, the use of morphology, and transliteration of words that are not in the dictionary.</p><p>To ease work in Arabic, Arabic letters were transliterated to English letters. Also, some letters normalizations were applied and all diacritics were removed. Table <ref type="table" coords="1,362.42,585.96,5.52,9.94" target="#tab_0">1</ref> shows the mappings between the Arabic letters and their transliterated representations. 1 Authors are listed in alphabetical order 2 Visiting from the Media Team, University of Oulu Finland  Notice that some letters such as {I , F } and { § , P , Q , R , ¨ S ¢ } were normalized to "y" and "A" respectively. For the case of {I , F }, they are often used interchangeably for each other because of different orthographic conventions or common spelling errors. For the case of { § , P , Q , R , ¨ }, they represent different forms of the letter hamza.</p><p>As for a stop-word list, we used the list that is distributed with Sebawai which includes 130 particles and pronouns <ref type="bibr" coords="2,106.84,297.73,11.61,9.94">[6]</ref>. Finally we used the default settings of InQuery with stemming disabled and case sensitivity using the -nostem and -case switches respectively.</p><p>For query translation, we used an online machine translation (MT) system developed by Sakhr called Tarjim and a bilingual dictionary <ref type="bibr" coords="2,211.23,335.65,11.61,9.94" target="#b16">[9]</ref>. The dictionary was built by extracting unique terms from a 200megabyte collection of news articles sending them to Tarjim for translation <ref type="bibr" coords="2,396.75,348.13,11.61,9.94">[8]</ref>. When our wordlist was sent to Tarjim, Tarjim produced single word translations of the words without regard for context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1">Arabic index terms</head><p>Several papers were published comparing the use of words, stems, and roots as index terms for purposes of retrieval. All of the studies showed that stems outperformed words and roots outperformed stems <ref type="bibr" coords="2,507.38,413.88,12.19,9.94" target="#b0">[1]</ref> <ref type="bibr" coords="2,519.57,413.88,12.19,9.94">[3]</ref>. We tested the claim using the Zad Arabic document collection. By testing on Zad, we noticed no statistical significance in mean average precision between words, stems, and roots. We thus tried using a combination of words and roots as index terms and the performance was significantly better than using any of them alone. This is a case when using a combination of evidence outperforms using any single evidence alone. For significance testing, we used a paired two-tailed t-test. If the p-value of the test was below 0.05, we assumed the difference to be significant.</p><p>We investigated other index terms which were character n-grams for both words and roots. We used a combination of character n-grams of different length. For words we used a combination of 3-5 grams and for roots we used 2-4 grams. In combining the n-grams, all the n-gram tuples replace the existing word. For example, the word "Arabic" would be replaced by {Ara, rab, abi, bic}, {Arab, rabi, abic}, and {Arabi, rabic}. Although character n-grams did not outperform words or roots, using the combination of words, roots, and character n-grams of words and roots together was significantly better than any pervious run.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2">Arabic morphology</head><p>Since previous research indicated that using roots as index terms improved mean average precision, two morphology engines capable of generating roots were compared. The first is ALPNET <ref type="bibr" coords="3,414.26,265.74,11.06,9.07">[4]</ref> <ref type="bibr" coords="3,425.32,265.74,11.06,9.07">[5]</ref>. ALPNET has an inventory of 4,500 roots and for any given word, it generates possible roots in random order. The second is Sebawai, which was developed by the first author. Sebawai has an inventory of 10,500 roots and uses a heuristic that guesses which of the roots is most likely.</p><p>On the Zad collection, we conducted 4 experiments in which we examined indexing using roots only. The first two experiments involved indexing one root and two roots from ALPNET. For the other two, the experiments involved indexing using the top root and the top two roots from Sebawai. Using Sebawai's guess of the most likely root resulted in a higher mean average precision than when using one root from ALPNET. Further, using the first two roots from ALPNET slightly improved mean average precision, but the improvement was not statistically significant. Using the top two roots of Sebawai significantly harmed retrieval. A likely reason for the fall in mean average precision when the second root was introduced is that the second root amounted to noise. Table <ref type="table" coords="3,371.78,380.70,5.04,9.07" target="#tab_4">3</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.3">Transliteration and matching of words that are not in the dictionary</head><p>For cross-language (CL) runs, we used an MT system in addition to a bilingual English to Arabic dictionary. Each English query was replaced with the full MT suggested translation and the word-by-word translation of query using the bilingual dictionary.</p><p>The MT system automatically transliterated words that did not appear in its internal dictionary. However, the suggested MT transliterations were often crude and incorrect. Detecting which words were in the MT lexicon and which ones were transliterations was beyond the scope of the work.</p><p>For the word-by-word dictionary based translation, we employed a transliteration technique for words that were not found in the dictionary. We assumed that the words that were not in the dictionary were mostly named entities and required transliteration. The goal of the transliteration technique is to find possible Arabic words that correspond to the given English word. The process involved transliteration, matching, and clustering.</p><p>Transliteration: All the English letters are mapped to the closest Arabic sounding letters. For example, the letter "r" is mapped to " ". Letter combinations such as "ch" and "sh" are recognized and mapped to Arabic. Some letters such "j" and "g" are normalized to one letter.   Matching: For the matching the transliterated words to the words in the collection to be searched, the prefixes {w,wAl,Al,wb,[wlbfk]} were removed from all the words; all the vowels are dropped; and some Arabic letters were normalized. Table <ref type="table" coords="4,234.99,279.72,5.52,9.94" target="#tab_7">5</ref> lists all the normalizations of Arabic letters.</p><formula xml:id="formula_0" coords="4,199.95,87.79,211.13,126.96">A b b c[iey] s c k d d [aeiou] # ** f f g g h h j g k k l l m m n n p b q q r r s s t t v f x k y y z z th O al- # ala A [sc]h P</formula><p>[Ss] s Clustering: after the possible Arabic transliterations are found, all are used together in the Arabic queries using InQuery's #syn operator which sets all of them as synonyms to each other.</p><formula xml:id="formula_1" coords="4,205.95,280.75,222.74,39.36">¡ Zz ¢ z [xk] k [AE] A [Hh] h [Tt] t [gj] g p #</formula><p>The effect of this technique is not completely clear given that most of the words in the queries for the side collection and TREC were in the bilingual dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Experiment Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1">Arabic Monolingual Run</head><p>Automatic Arabic Run: Based on our experiments on Zad collection, we used words, stems, roots, character n-grams for words, and character n-grams for roots to index the TREC collection. To obtain stems and roots, we used the top suggestions of Sebawai. For n-grams, we used 2-4 character n-grams for roots and 3-5 character n-grams for words.</p><p>Manual Arabic Run: For the manual runs, the title, description, and narratives were used along with words that were manual introduced by the authors. We removed stop structures from queries such as " £ ¥¤ §¦ © § © § " (the articles relating to) and examples of what is not relevant. The final queries were run in exactly the same way as the automatic Arabic setup.</p><p>Post-hoc experiments: After the relevance judgments were available we explored the use of different index terms on our retrieval effectiveness. We examined indexing using words only, stems only, roots only, word character trigrams, root character bigrams, and words, stems, and roots together. The queries were automatically formulated using the full text of the title and descriptions of the queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.2">English-Arabic CLIR Runs</head><p>For the CLIR runs, we tested three different configurations as follows:</p><p>Basic Configuration: All the queries were translated using Tarjim only. The output of the MT system was fed to the automatic Arabic IR configuration described above. It is noteworthy that Tarjim transliterates the words that do not appear its dictionary. Full Configuration: In this configuration, the English queries were translated using Tarjim and the bilingual dictionary. If a word is not found in the dictionary, the word is transliterated, matched to Arabic words in the TREC collection, and the matches were clustered in the manner described above. The outputs of the MT system, the dictionary based translation, and the transliteration are combined and fed to the automatic Arabic IR configuration.</p><p>Expansion Configuration: The expansion configuration is identical to the full configuration but with expansion using blind relevance feedback on the English and the Arabic sides. For expansion on the English side, we used Associated Press articles from 1994-1998. They were part of the North American News Text Corpus (Supplement) and AP World Stream English Collection from the Linguistic Data Consortium <ref type="bibr" coords="5,510.98,238.68,11.61,9.94">[7]</ref>. The expansion collection was searched using the English queries without modification and the top 10 returned documents for every query were used to expand the query. For the expansion on the Arabic side, the TREC collection was used for expansion. The AFP collection was searched using the Arabic queries, which include the roots and n-grams, and the top 10 retrieved documents for ever query were used to expand the queries.</p><p>Post-hoc experiments: We examined indexing using words only, stems only, roots only, word character trigrams, root character bigrams, and words, stems, and roots together. The titles and descriptions of the queries were automatically translated using Tarjim alone. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Discussion</head><p>The results point to a few important conclusions:</p><p>1. The translation technique used was effective. In fact, for the official results the mean average precision of the non-expanded CLIR run was 89% relative to the mean average precision of the automatic Arabic run. Also, none of the CLIR runs were significantly better or worse than any of the Arabic run.</p><p>2. For the official runs, the results of individual queries were better than the median in 10 queries and 18 queries for the automatic non-expanded monolingual and cross language runs respectively.</p><p>3. Perhaps the use of n-grams for roots may have hurt the monolingual result.. When we tried using roots only as the index terms in later monolingual experiments, the resulting mean average precision was significantly better than any of our official results. However, the CLIR results were slightly hurt, but not significantly by the use of n-grams. Also using bigrams for roots seems to be a bad idea especially for CLIR runs.</p><p>4. The use of word character trigrams and stems produced the best results among the post-hoc experiments. Perhaps other experiments examining the effect of indexing using other n-grams, terms produced by morphological analysis, or combinations of both are warranted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Introduction</head><p>Our primary focus in this track was to get exposure to the process, test existing algorithms and determine the types of queries our current approaches was suited for. As previously stated, we participated in both the shot boundary detection and known item search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Shot Boundary Detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Overview</head><p>There has been a tremendous amount of work done on problem of "shot" detection in video. Our system was originally developed and extended in 1995 to process large quantities of MPEG-compressed video and provide a visual summary. In order to provide such a summary, we originally defined a shot change not only as a cut or gradual change, but also as the point where a significant amount of new content was introduced in the scene, either by new subjects appearing, or the camera panning to a new view of the current environment.</p><p>The system runs at about 3x real-time and relies on a consistent and predictable coding of the video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Approach</head><p>MERIT <ref type="bibr" coords="7,100.36,309.72,18.32,9.94">[21]</ref> detects cut shot changes by examining the MPEG macroblocks and DCT coefficients. If macroblocks of a frame rely very little on the proceeding or succeeding frames for encoding, the likelihood is high that there is shot change since same shot frames use the same information. Shot changes are determined by calculating the faction of macroblocks using information from other frames' macroblock to the total number of macroblocks. If this faction is below a threshold then is the potential for a shot change. All selfencoded frames are considered a potential for further processing the validation phase if it comes directly after a previous potential frame. In the validation phase DCT values of potential shot changes frames are decoded. If there is sufficient change in the DCT values, then the shot change is kept in the results. A shot change is validated by determining the difference between the DCT values of the frames before and after the potential frame. If the difference is above a threshold then it is considered a shot change. The thresholds for the system were determined by separately testing 12 minutes of video data of various genres (animations, commercials, movies, news, sports, and surveillance) that minimized the number of false and undetected transitions.</p><p>No training was done with TREC collection. Details of the algorithm can be found in <ref type="bibr" coords="7,427.22,461.39,16.80,9.94">[21]</ref>. The MERIT system is available upon request to research organizations. Gradual scene change detections are detected by projecting the DCT coefficient feature vector into a low dimensional space using a linear time reduction algorithm know as FastMap. The layout of these low dimensional points are tracked and if they do not cluster, a gradual change is detected. Details can be found in <ref type="bibr" coords="7,74.44,524.75,16.80,9.94" target="#b28">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Experiments</head><p>Overall the system performed worse than the weighted median in all performance categories (Figure <ref type="figure" coords="7,507.62,577.55,8.46,9.94" target="#fig_2">1a</ref>). Incorrect cut transition had a severe impact on the overall results (Figure <ref type="figure" coords="7,385.47,590.27,8.70,9.94" target="#fig_2">1b</ref>). In gradual shot scene detection, the system performed better but missed more than the median performance system (Figure <ref type="figure" coords="7,463.94,602.99,8.34,9.94" target="#fig_2">1c</ref>). The system achieves its best results with database videos (ahf1, eal1, pfm1) with a bit-rate of 1.4MB/sec. Although some videos (ann. i005, anni009) had higher bit-rates, the grainy quality of the video degraded the accuracy of the macroblocks and DCT coefficients. Database clips with lower bit rates had lower performance rates. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Discussion</head><p>An examination of the undetected transitions indicates that reliance of DCT values for validation of shot changes makes it difficult to detect certain shot change situations. Cut transitions in which the two scenes were very similar in color or very dark were problematic. For example, in BOR08.mpg, there where many shot changes involving transition between old photographs that were prominently gold in color. Since the difference in the DCT would be minimal the difference did not produce a value above the threshold to indicate a shot change. This problem also occurred with gradual transitions that involved fades to black, fades from black, similar color or were dark in nature. The difference between frames did not produce a value greater than the threshold since the DCT values of the dark areas dominated varied very little from each other.</p><p>Our system often found transitions in clips where there were none.. The situations in which this error occurred were typically either camera jitter, when the camera made a sudden movement in a new direction, when a background object moved into a prominent position in the foreground, or when the camera zoomed in on a object. The macroblocks indicate a large change and was confirmed in the validation process since was a substantial change in color.</p><p>Although working with in the MPEG compressed domain is a quick way to analyze video it can produce errors. The reliance on DCT values makes it difficult to detect transitions that involve scenes that are dark or have similar prominent color scheme. In these cases the probability is high that the changes will not register above a threshold. In the future an adaptive threshold is needed to detect the presence of these situations during the validation phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Known Item and General Search</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Overview</head><p>Content-based retrieval has been subject to active research since the early 1990's <ref type="bibr" coords="8,422.42,657.47,12.80,9.94">[3]</ref> and a large number of experimental image retrieval systems have been introduced, such as BlobWorld <ref type="bibr" coords="8,419.06,669.95,11.61,9.94">[4]</ref>, Chabot <ref type="bibr" coords="8,472.10,669.95,11.61,9.94">[5]</ref>, Mars <ref type="bibr" coords="8,516.02,669.95,11.61,9.94">[6]</ref>, NeTra <ref type="bibr" coords="8,94.12,682.67,11.61,9.94">[7]</ref>, Photobook <ref type="bibr" coords="8,162.51,682.67,11.61,9.94">[8]</ref>, QBIC <ref type="bibr" coords="8,210.03,682.67,11.61,9.94" target="#b16">[9]</ref>, Surfimage <ref type="bibr" coords="8,276.75,682.67,18.32,9.94" target="#b17">[10]</ref> and VisualSEEK <ref type="bibr" coords="8,375.62,682.67,16.80,9.94" target="#b18">[11]</ref>. These systems retrieve images based on cues such as color, texture, and shape, of which color remains as the most powerful and most useful feature for general purpose retrieval. Color-based retrieval first evolved from simple statistical measures such as average color to color histograms <ref type="bibr" coords="9,224.91,74.29,12.11,9.94" target="#b16">[9,</ref><ref type="bibr" coords="9,237.02,74.29,8.07,9.94">5,</ref><ref type="bibr" coords="9,245.09,74.29,8.07,9.94">8]</ref>, but histograms alone suffer for large collections since different configurations can produce the same histogram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Approach</head><p>The spatial correlation of colors as a function of spatial distance is an image feature introduced by Huang et al. <ref type="bibr" coords="9,77.56,139.81,18.32,9.94" target="#b19">[12]</ref> known as a correlogram. Our approach extends this method and uses a novel color content method, the Temporal Color Correlogram (TCC), to capture the spatio-temporal relationship of colors in a video shot using co-occurrence statistics. TCC is an extension of HSV Color Correlogram (CC), which is found very effective in content-based image retrieval <ref type="bibr" coords="9,248.43,177.73,11.61,9.94" target="#b0">[1]</ref>. Temporal Color Correlogram computes autocorrelation of the quantized HSV color values from a set of frame samples taken from a video shot. In this paper, the efficiencies of TCC and HSV Color Correlogram (CC) are evaluated against other retrieval systems participating VideoTREC track evaluation. Tests are executed using our retrieval system, CMRS, which is specifically developed for multimedia information retrieval purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.1">Correlogram extension in temporal domain</head><p>In digital video, color and intensity information change temporally over a shot, creating the illusion of object or observer movement. This knowledge is also used in modern video compression algorithms, where motion is estimated by moving rectangular blocks of quantized illumination and colors towards the expected direction of motion (MPEG) <ref type="bibr" coords="9,149.56,319.32,16.80,9.94" target="#b26">[19]</ref>. In order to create a content-based descriptor for a video shot, such structural information should be trasferred into computable features.</p><p>The temporal changes of video shot contents can be described using the temporal correlogram. The benefits over more traditional approaches, such as color histograms, derive from its ability to encapsulate the temporal changes in small spatial color environments. Figure <ref type="figure" coords="9,292.83,382.44,5.52,9.94" target="#fig_3">2</ref> depicts a temporal color change in a small spatial environment. Whereas the color histogram would only portray the proportional amount of color in these frames, temporal correlogram will capture information about the spatial changes of these colors occurring over time.  For computational benefits <ref type="bibr" coords="9,184.35,657.95,11.61,9.94" target="#b0">[1]</ref>, the Temporal Color Correlogram (noted here as TCC) used for this study is computed as an autocorrelogram, which is obtained from Eq. 3. by replacing cj with ci. The quantization of HSV color space for TCC follows the quantization of CC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Experiments</head><p>To evaluate the temporal correlogram efficiency, we used 11 hours database of MPEG1 videos available for VideoTREC track participants <ref type="bibr" coords="10,199.71,102.61,11.61,9.94">[2]</ref>. First, the video material was segmented to create shots using VideoLogger video editing software from Virage [20] and our own system (above) but the Virage results were used. For the 11 hours of video, 7375 shot segments were created with the average shot length of approximately 5 seconds. From the shot frames, the beginning frame was selected as a representative key frame, from which the static image feature, CC, was obtained. In order to calculate TCC non-exhaustively and to keep the number of samples in equal for varying shot lengths, each shot was sampled evenly with a respective sampling delay so that the number of sample frames did not exceed 40. After segmentation, shot features were fed into our CMRS retrieval system and queries were defined using either example videos or example images depending on the respective VideoTREC topic specification <ref type="bibr" coords="10,281.79,203.89,11.61,9.94">[2]</ref>.</p><p>VideoTREC result submission contained retrieval results of two system configurations. First configuration was obtained using TCC for the retrieval topics that contained video examples in the topic definition. Second configuration used CC for topics that contained example images in their definition. Table <ref type="table" coords="10,458.90,254.28,5.52,9.94" target="#tab_10">6</ref> shows the average precisions of General Search results for the TCC feature in different topic categories. As the results show, TCC as a purely automatic method did worse in Interactive and Automatic+Interactive topics, since no other cues than this color structure feature were used in a query (meaning there was no human involvement to prune the results). The General Search overall results were not impressive in contrast to other participating systems as can be seen from the Figure <ref type="figure" coords="10,200.19,317.64,5.52,9.94" target="#fig_5">3</ref> that depicts all system precisions ranked into evolving curve starting from worst system on the left. However, the average precision in Automatic topics ranks TCC higher, just below the median of all systems.   Table <ref type="table" coords="11,90.76,74.29,5.52,9.94" target="#tab_12">7</ref> shows the Known Item Search results with different match parameters. The parameters define when a retrieved item is a successful match to a known item. The loosest criteria (0.333/0.333) for the match expects the retrieved shot to be overlapping with known item at least one third of the shot duration having the same rule for the known item sequence. The tightest criteria require two thirds of the shot durations to overlap. It can be seen that the results for the CC configuration are dismal whereas TCC is doing better. In Figure <ref type="figure" coords="11,517.70,124.93,5.52,9.94" target="#fig_7">4</ref> one can see that the TCC recall is ranked in the median (11 th out of 21) of all systems for Known Item Searches.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RECALL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Discussion</head><p>The semantic gap is too large for video analysis features like TCC and CC in search problems such as in the General Search topics and the topics containing an example image. In other words, the structural, 'mechanical', content of example images and video shots doesn't convey the meaning of the semantic request that the person defining a query actually pursues. This can be improved by combining other cues such as audio and text to focus the search towards more meaningful locations in a video.</p><p>Better results were obtained in the topics that seek Known Items with similar structural shot properties. Topics that tried to locate footage from the same target with different camera angles or object positions gave the most successful results. The evaluation criteria for a search hit was rather strict. It leaves many questions whether people searching video databases want the exact locations of the known items returned, or rather, just a pointer inside a video where one can start to examine the video by himself. Is it more beneficial to provide the user with accurate segments together with very low retrieval ranks, rather than giving less accurate results with higher ranks? Surely users will rather watch a couple of longer segments from the top ranks than to wade through tens of useless clips in order to find the exact match with low rank. What makes the problem worse is that no automatic system will be accurate enough to successfully encapsulate the varieties in semantic definitions that people will use in their queries into heterogeneous video databases. In the retrieval results there will always exist loads of useless segments among the really significant ones.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,204.03,87.79,5.33,10.81"><head></head><label></label><figDesc>a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,240.03,308.70,131.91,9.07"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall Performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,64.12,511.74,483.82,9.07;9,207.63,523.25,196.91,9.07;9,63.16,540.83,174.55,9.94;9,237.63,538.58,3.48,6.26;9,244.11,540.83,280.17,9.94;9,63.16,553.55,347.48,9.94;9,275.31,573.01,3.93,29.21;9,376.11,573.01,3.93,29.21"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Temporal color change illustrated by frame sequence. Temporal correlogram captures the dispersion of the color element whereas histogram does not. Let N be the amount of sample frames I n taken from a shot S. Values of n vary from 1 to N indicating the index in the sample frame sequence. The temporal correlogram is calculated as [ ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,422.66,587.49,3.98,10.76;9,417.14,587.49,5.98,10.76;9,413.30,587.49,3.98,10.76;9,214.83,587.49,3.98,10.76;9,203.31,587.49,3.98,10.76;9,350.19,594.01,3.49,6.28;9,327.15,594.01,3.49,6.28;9,285.63,594.01,3.49,6.28;9,252.27,598.81,1.74,6.28;9,196.59,585.61,2.32,6.28;9,189.15,585.61,2.32,6.28;9,259.47,602.09,2.49,4.48;9,235.47,602.09,2.49,4.48;9,192.99,597.05,1.25,4.48;9,368.43,587.49,5.98,10.76;9,344.19,587.49,5.98,10.76;9,321.87,587.49,5.98,10.76;9,302.43,587.49,3.98,10.76;9,279.63,587.49,5.98,10.76;9,247.23,587.49,11.85,10.76;9,207.63,587.49,5.98,10.76;9,308.19,585.61,3.49,6.28;9,306.99,594.01,3.10,6.28;9,267.87,598.81,2.32,6.28;9,255.39,598.81,3.49,6.28;9,243.63,598.81,2.32,6.28;9,232.11,598.81,3.49,6.28;9,192.03,585.61,3.49,6.28;9,194.91,594.01,3.10,6.28;9,187.71,594.01,3.10,6.28;9,311.31,597.05,1.38,4.48;9,271.71,597.05,2.49,4.48;9,247.47,597.05,2.49,4.48;9,248.91,603.29,1.38,4.48;9,246.75,602.09,2.21,4.48;9,199.23,597.05,1.38,4.48;9,191.07,597.05,1.38,4.48;9,359.07,583.58,6.56,15.58;9,333.63,583.58,6.56,15.58;9,291.63,583.58,8.53,15.58;9,221.79,583.58,6.56,15.58;9,262.83,596.53,4.97,9.09;9,238.59,596.53,4.97,9.09;9,180.99,582.89,4.91,16.47;9,63.16,620.03,479.38,9.94;9,63.16,632.75,204.07,9.94;9,267.15,630.49,3.49,6.28;9,270.75,632.75,2.76,9.94"><head></head><label></label><figDesc>probability that given any pixel p1 of color ci, a pixel p2 at a distance d from the given pixel p1 is of color cj among the shot's sample frames I n .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,75.40,671.09,461.74,9.07;10,154.60,682.61,302.75,9.07"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: TCC General Search performance against other systems. The curve indicates ranked list of system precisions, worst being in the left and best in the right end of the curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="11,63.64,478.14,485.34,9.07;11,110.68,489.66,390.82,9.07"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: TCC and CC recall and precision against respective values of other systems. The curve indicates ranked list of system precisions/recalls, worst being in the left and best in the right end of the curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,192.51,213.43,227.11,9.07"><head>Table 1 : English transliteration of Arabic characters</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,63.16,565.56,447.82,22.66"><head>Table 2</head><label>2</label><figDesc>summarizes the results of using different Arabic index terms on the side collection.</figDesc><table coords="3,208.59,76.69,198.59,119.86"><row><cell>Index term</cell><cell>Mean Avg. Precision</cell></row><row><cell>Words</cell><cell>0.3939</cell></row><row><cell>Stems</cell><cell>0.4158</cell></row><row><cell>Roots</cell><cell>0.4486</cell></row><row><cell>Word &amp; Roots</cell><cell>0.4979</cell></row><row><cell>Word character n-grams</cell><cell>0.4885</cell></row><row><cell>Word and root character n-grams</cell><cell>0.5717</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,134.92,215.35,342.34,9.07"><head>Table 2 : Summary of results on side collection of choosing different index terms.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,63.16,380.70,464.46,118.93"><head></head><label></label><figDesc>summarizes the results of using roots from the two analyzers.</figDesc><table coords="3,202.59,417.78,184.67,81.85"><row><cell>Index term</cell><cell>Mean Avg. Precision</cell></row><row><cell>ALPNET -1 root</cell><cell>0.34</cell></row><row><cell>ALPNET -2 root</cell><cell>0.36</cell></row><row><cell>Sebawai -1 root</cell><cell>0.45</cell></row><row><cell>Sebawai -1 root</cell><cell>0.29</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,115.48,511.26,381.18,9.07"><head>Table 3 : summary of results on side collection of using different morphological analyzers</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="3,63.16,692.03,450.09,22.66"><head>Table 4</head><label>4</label><figDesc></figDesc><table /><note coords="3,399.14,692.03,114.10,9.94;3,63.16,704.74,112.92,9.94"><p>lists the English to Arabic Transliteration mappings.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="4,77.56,236.95,457.18,9.07"><head>Table 4 : English to Arabic transliteration mappings</head><label>4</label><figDesc></figDesc><table /><note coords="4,303.87,236.95,230.87,9.07"><p>(* initial letter(s) in the word, ** # represents nothing)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="4,162.03,334.38,265.19,9.07"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note coords="4,202.59,334.38,224.63,9.07"><p>Arabic letter normalizations (* # represents nothing)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="5,94.36,393.06,404.93,190.44"><head>Post hoc runs (all basic configuration)</head><label></label><figDesc></figDesc><table coords="5,94.36,393.06,404.93,190.44"><row><cell cols="2">Official monolingual runs (Ad hoc)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell>Mean Avg. Precision</cell><cell></cell><cell></cell><cell cols="3">Monolingual Results</cell></row><row><cell></cell><cell></cell><cell cols="2">0.45</cell><cell></cell><cell></cell></row><row><cell>aa -Automatic Arabic</cell><cell>0.22</cell><cell cols="2">0.4</cell><cell></cell><cell></cell><cell>Automatic Arabic</cell></row><row><cell cols="2">ma -Manual Arabic Post hoc runs (all automatic) 0.29 w -words only 0.22 r -roots only 0.28 s -stems only 0.29 wsr -words, stems, and 0.28 roots rg2 -root bigram 0.15</cell><cell cols="2">0.1 0.15 0.2 0.25 0.3 0.35 Mean Avg. Precision 0.05 0</cell><cell>Ad Hoc</cell><cell>Post Hoc</cell><cell>Manual Arabic words only roots only stems only words, stems, and roots roots bi-gram only word tri-gram only</cell></row><row><cell>wg3 -word trigram</cell><cell>0.31</cell><cell></cell><cell></cell><cell cols="2">Runs</cell></row><row><cell cols="2">Official cross language runs (Ad hoc)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Results</cell></row><row><cell>Run</cell><cell>Mean Avg. Precision</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">bc -Basic configuration 0.19</cell><cell></cell><cell>0.25</cell><cell></cell><cell></cell><cell>Basic configuration</cell></row><row><cell>fc -Full configuration xp -Expanded configuration w -words only r -roots only s -stems only</cell><cell>0.20 0.23 0.12 0.20 0.21</cell><cell>Mean Avg. Precision</cell><cell>0.05 0.1 0.15 0.2</cell><cell></cell><cell></cell><cell>Full configuration Expanded configuration words only roots only stems only words, stems, and</cell></row><row><cell>wsr -words, stems, and roots</cell><cell>0.23</cell><cell></cell><cell>0</cell><cell>Ad hoc</cell><cell>Post hoc</cell><cell>roots root bi-gram only words tri-grams only</cell></row><row><cell>rg2 -root bigram</cell><cell>0.05</cell><cell></cell><cell></cell><cell></cell><cell>Run</cell></row><row><cell>wg3 -word trigram</cell><cell>0.24</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="10,151.48,469.50,309.23,175.92"><head>Table 6 :.General Search Results for TCC with different topic categories.</head><label>6</label><figDesc></figDesc><table coords="10,197.49,505.76,147.51,139.66"><row><cell></cell><cell></cell><cell cols="2">General Search Precisions</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0,9</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0,8</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0,7</cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0,4 0,5 0,6</cell><cell>TCC, Overall Precision (0,19)</cell><cell>TCC, Automatic Precision (0,24)</cell></row><row><cell></cell><cell>0,3</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0,2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0,1</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>All systems</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="11,82.36,285.42,447.46,9.07"><head>Table 7 : Recall and Precision averages for TCC and CC configurations with different match parameters.</head><label>7</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="11,63.16,507.23,475.43,134.95"><head>Table 8</head><label>8</label><figDesc>shows the top 5 topics for the Known Item Searches. Topic 3 was the most successful. It considered finding video segments that depict a lunar vehicle traveling on the moon. Other topics in the list considered problems of finding a yellow boat, snow capped mountains or a student from classroom footage.</figDesc><table coords="11,241.95,559.85,126.00,82.33"><row><cell></cell><cell>Precision</cell><cell>Recall</cell></row><row><cell cols="3">1 st 2 nd Topic 35 Topic 6 Topic 3 Topic 3</cell></row><row><cell>3 rd 4 th</cell><cell cols="2">Topic 36 Topic 35 Topic 4 Topic 36</cell></row><row><cell>5 th</cell><cell>Topic 6</cell><cell>Topic 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="11,197.79,662.69,216.39,9.07"><head>Table 8 : Top 5 topic results by precision and recall</head><label>8</label><figDesc></figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,99.16,541.79,407.58,9.94;6,99.16,554.51,397.55,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,368.96,541.79,137.78,9.94;6,99.16,554.51,252.95,9.94">Stemming Methodologies Over Individual Query Words for Arabic Information Retrieval</title>
		<author>
			<persName coords=""><surname>Abu-Salem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mahmoud</forename><surname>Hani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Al-Omari</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Evens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,363.62,554.51,25.70,9.94">JASIS</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="524" to="529" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,567.23,372.28,9.94" xml:id="b1">
	<monogr>
		<title level="m" coord="6,242.91,567.23,111.75,9.94">LLC. 16013 Malcolm Dr</title>
		<meeting><address><addrLine>Laurel, MD 20707, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Al-Areeb Electronic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,579.95,446.63,9.94;6,99.16,592.43,271.79,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,287.69,579.95,258.09,9.94;6,99.16,592.43,127.00,9.94">Comparing Words, Stems, and Roots as Index Terms in an Arabic Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ibrahim</forename><surname>Al-Kharashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Evens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,237.63,592.43,31.08,9.94">JASIS</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="548" to="560" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,605.15,448.66,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,187.18,605.15,261.69,9.94">Arabic Finite-State Morphological Analysis and Generation</title>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Beesley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,461.06,605.15,53.03,9.94">COLING-96</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,617.87,441.93,9.94;6,99.15,630.35,397.79,9.94;6,99.15,643.07,121.32,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,352.89,617.87,188.19,9.94;6,99.15,630.35,52.09,9.94">Two-Level Finite-State Analysis of Arabic Morphology</title>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Beesley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Buckwalter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stuart</forename><surname>Newton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,164.43,630.35,327.99,9.94">Proceedings of the Seminar on Bilingual Computing in Arabic and English</title>
		<meeting>the Seminar on Bilingual Computing in Arabic and English<address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,655.79,344.99,9.94;6,63.16,668.27,256.66,9.94" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,187.02,655.79,246.71,9.94">Building a Shallow Morphological Analyzer in One Day</title>
		<author>
			<persName coords=""><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
		<ptr target="www.glue.umd.edu/~kareem/hamlet/arabic/sebawai.tar.gz" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,680.99,388.19,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,191.15,680.99,174.65,9.94">North American News Text Supplement</title>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Macintyre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,378.75,680.99,47.68,9.94">LDC98T30</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,99.16,693.71,244.43,9.94" xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName coords=""><surname>Nist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,129.16,693.71,111.60,9.94">Text Research Collection</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="1997-04">April 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,348.06,437.14,9.07;12,99.16,359.34,335.39,9.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,336.03,348.06,196.02,9.07">Semantic image retrieval with HSV correlograms</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rautiainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Matinmikko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aittola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,99.16,359.34,221.83,9.07">Proc. 12th Scandinavian Conference on Image Analysis</title>
		<meeting>12th Scandinavian Conference on Image Analysis<address><addrLine>Bergen, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="621" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,372.78,246.95,9.07;12,99.16,384.30,198.63,9.07" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="12,99.16,372.78,187.72,9.07">TREC-2001 Video Retrieval Track Home Page</title>
		<ptr target="http://www-nlpir.nist.gov/projects/t01v/t01v.html" />
		<imprint>
			<date type="published" when="2001">10/25/2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,397.74,437.58,9.07;12,99.16,409.26,427.54,9.07;12,99.16,420.54,210.35,9.07" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,221.07,397.74,315.67,9.07;12,99.16,409.26,44.39,9.07">Content-Based Image Retrieval: A report to the JISC Technology Applications Programme</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Eakins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Graham</surname></persName>
		</author>
		<ptr target="http://www.unn.ac.uk/iidr/research/cbir/report.html" />
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>United Kingdom</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute for Image Data Research, University of Northumbria at Newcastle</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,433.98,445.42,9.07;12,99.16,445.50,335.15,9.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,318.27,433.98,118.05,9.07">Region-based image querying</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,443.06,433.98,101.52,9.07;12,99.16,445.50,209.62,9.07">Proc. IEEE Workshop on Content-Based Access of Image and Video Libraries</title>
		<meeting>IEEE Workshop on Content-Based Access of Image and Video Libraries<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,458.94,417.58,9.07;12,99.16,470.46,80.52,9.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,232.59,458.94,213.11,9.07">Chabot: retrieval from a relational database of images</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ogle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,452.66,458.94,64.07,9.07;12,99.16,470.46,39.75,9.07">IEEE Computer Magazine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,483.90,417.10,9.07;12,99.16,495.18,392.98,9.07" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,406.59,483.90,109.67,9.07;12,99.16,495.18,107.28,9.07">Supporting ranked Boolean similarity queries in MARS</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Porkaew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,215.07,495.18,226.07,9.07">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="905" to="925" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,508.61,431.90,9.07;12,99.16,520.13,260.75,9.07" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,234.27,508.61,215.64,9.07">NeTra: a toolbox for navigating large image databases</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,456.74,508.61,74.32,9.07;12,99.16,520.13,130.36,9.07">Proc. International Conference on Image Processing</title>
		<meeting>International Conference on Image essing<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="568" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,533.57,409.54,9.07;12,99.16,544.85,216.59,9.07" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,268.59,533.57,236.04,9.07">Photobook: content-based manipulation of image databases</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,99.16,544.85,165.59,9.07">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="233" to="254" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,558.29,429.94,9.07;12,99.16,569.81,442.94,9.07;12,99.16,581.33,38.76,9.07" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,215.55,569.81,213.28,9.07">Query by image and video content: The QBIC system</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dom</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gorkani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Petkovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,435.87,569.81,106.23,9.07">IEEE Computer Magazine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,594.77,428.02,9.07;12,99.16,606.29,326.27,9.07" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,289.71,594.77,233.20,9.07">Surfimage: a flexible content-based image retrieval system</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitschke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Meilhac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,99.16,606.29,231.59,9.07">Proc. Sixth ACM International Conference on Multimedia</title>
		<meeting>Sixth ACM International Conference on Multimedia<address><addrLine>Bristol, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="339" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,619.73,439.66,9.07;12,99.16,631.01,272.03,9.07" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,217.24,619.73,264.57,9.07">VisualSEEK: a fully automated content-based image query system</title>
		<author>
			<persName coords=""><forename type="first">J &amp;</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,488.90,619.73,49.92,9.07;12,99.16,631.01,184.77,9.07">Proc. Fourth ACM International Conference on Multimedia</title>
		<meeting>Fourth ACM International Conference on Multimedia<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="87" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,644.45,410.54,9.07;12,99.16,655.97,438.58,9.07" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,294.75,644.45,163.38,9.07">Image indexing using color correlograms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,464.91,644.45,44.80,9.07;12,99.16,655.97,302.56,9.07">Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Society Conference on Computer Vision and Pattern Recognition<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="762" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,669.41,418.86,9.07;12,99.16,680.69,246.59,9.07" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,240.04,669.41,195.91,9.07">Comparing images using color coherence vectors</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,442.59,669.41,75.44,9.07;12,99.16,680.69,159.57,9.07">Proc. Fourth ACM International Conference on Multimedia</title>
		<meeting>Fourth ACM International Conference on Multimedia<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="65" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,99.16,694.13,401.02,9.07;12,99.16,705.65,287.15,9.07" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,294.99,694.13,154.37,9.07">Spatial color indexing and applications</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,455.79,694.13,44.40,9.07;12,99.16,705.65,180.03,9.07">Proc. Sixth International conference on Computer Vision</title>
		<meeting>Sixth International conference on Computer Vision<address><addrLine>Bombay, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="602" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,99.16,75.91,432.22,9.07;13,99.16,87.43,417.22,9.07" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="13,258.03,75.91,273.34,9.07;13,99.16,87.43,84.58,9.07">Combining supervised learning with color correlograms for contentbased image retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,189.87,87.43,229.89,9.07">Proc. Fifth ACM International Conference on Multimedia</title>
		<meeting>Fifth ACM International Conference on Multimedia<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,99.16,100.87,442.78,9.07;13,99.16,112.15,320.03,9.07" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="13,215.55,100.87,237.46,9.07">Benchmarking of image features for content-based retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,459.14,100.87,82.79,9.07;13,99.16,112.15,190.13,9.07">Proc. 32nd Asilomar Conference on Signals, Systems and Computers</title>
		<meeting>32nd Asilomar Conference on Signals, Systems and Computers<address><addrLine>Pacific Grove, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="253" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,99.16,125.59,415.90,9.07;13,99.16,137.11,432.94,9.07;13,99.16,148.63,17.64,9.07" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="13,363.15,125.59,151.91,9.07;13,99.16,137.11,132.70,9.07">Efficient color histogram indexing for quadratic form distance functions</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">S</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Equitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,238.35,137.11,260.07,9.07">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="729" to="736" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,99.16,162.07,370.42,9.07" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="13,177.40,162.07,96.06,9.07">Digital video processing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Tekalp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Prentice Hall signal processing series, US</publisher>
			<biblScope unit="page">526</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,99.16,175.27,271.35,9.07" xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Mpeg</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Org</surname></persName>
		</author>
		<ptr target="http://www.mpeg.org/MPEG/video.html" />
		<imprint>
			<date type="published" when="2001">10/25/2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,99.16,202.15,446.78,9.07;13,99.16,213.43,235.55,9.07" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="13,283.23,202.15,160.46,9.07">Compressed domain video segmentation</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kobla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<idno>CS-TR-3688</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">CfAR Technical Report</note>
</biblStruct>

<biblStruct coords="13,99.16,226.87,447.82,9.07;13,99.16,238.39,441.18,9.07;13,99.16,249.91,59.88,9.07" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="13,282.27,226.87,264.71,9.07;13,99.16,238.39,75.44,9.07">Special effect edit detection using VideoTrails: a comparison with existing techniques</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kobla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dementhon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,181.24,238.39,359.11,9.07;13,99.16,249.91,12.33,9.07">Proceedings of SPIE conference on Storage and Retrieval for Image and Video Databases VII</title>
		<meeting>SPIE conference on Storage and Retrieval for Image and Video Databases VII</meeting>
		<imprint>
			<date type="published" when="1999-01">Jan, 1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
