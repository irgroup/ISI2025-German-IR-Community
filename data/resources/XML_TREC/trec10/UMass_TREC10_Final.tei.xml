<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,116.67,87.29,378.60,14.76">Arabic Information Retrieval at UMass in TREC-10</title>
				<funder ref="#_h3zfKnn">
					<orgName type="full">SPAWARSYSCEN-SD</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,198.86,104.78,80.90,11.10"><forename type="first">Leah</forename><forename type="middle">S</forename><surname>Larkey</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01002</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,306.40,104.78,106.69,11.10"><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Connell</surname></persName>
							<email>larkey|connell@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01002</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,116.67,87.29,378.60,14.76">Arabic Information Retrieval at UMass in TREC-10</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">10EEFC167EFB8A9EB2312E1791286EF0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The University of Massachusetts took on the TREC10 cross-language track with no prior experience with Arabic, and no Arabic speakers among any of our researchers or students. We intended to implement some standard approaches, and to extend a language modeling approach to handle co-occurrences. Given the lack of resources -training data, electronic bilingual dictionaries, and stemmers, and our unfamiliarity with Arabic, we had our hands full carrying out some standard approaches to monolingual and cross-language Arabic retrieval, and did not submit any runs based on novel approaches.</p><p>We submitted three monolingual runs and one cross-language run. We first describe the models, techniques, and resources we used, then we describe each run in detail. Our official runs performed moderately well, in the second tier (3 rd or 4 th place). Since submitting these results, we have improved normalization and stemming, improved dictionary construction, expanded Arabic queries, improved estimation and smoothing in language models, and added combination of evidence, increasing performance by a substantial amount.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Information Retrieval Engines</head><p>We used INQUERY <ref type="bibr" coords="1,166.53,410.63,12.92,9.94" target="#b2">[2]</ref> for two of our three monolingual runs and our cross-language run, and language modeling (LM) for one monolingual run. The processing was carried out using in-house software which implemented both engines, to insure that the stop lists, tokenization, and other details were identical. The same tokenization was used in indexing the Arabic corpus and processing Arabic queries. In fact, except for one minor difference in tokenization, Arabic strings were treated exactly like English strings -as a simple string of bytes, regardless of how they would be rendered on the screen. For both English and Arabic, text was broken up into words at any white space or punctuation characters. The minor difference in Arabic tokenization consisted of five additional Arabic punctuation characters included in the definition of punctuation. Words of one-byte length (in CP1256 encoding) were not indexed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Inquery</head><p>Two of the three monolingual runs and the cross-language run used a version of INQUERY as the search engine. This version computes the belief function reported in UMass's TREC9 report <ref type="bibr" coords="1,472.71,567.09,11.70,9.94" target="#b1">[1]</ref>. The main difference between this version and "real" INQUERY is that proximity information is not stored in the index, so that INQUERY operators requiring proximity information are not implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Language Modelling (LM)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Monolingual</head><p>In language modeling, documents are represented as probability distributions over a vocabulary. Documents are ranked by the probability of generating the query by randomly sampling the document model. The language models here are simple unigram models, similar to those of <ref type="bibr" coords="1,429.75,686.00,12.80,9.94" target="#b7">[7]</ref> and <ref type="bibr" coords="1,469.26,686.00,11.71,9.94">[9]</ref>. Unigram probabilities in our official run were estimated as a mixture of maximum likelihood probability estimates from the document and the corpus, as follows:</p><formula xml:id="formula_0" coords="2,110.19,100.13,234.08,29.72">( ) ( ) ∏ ∈ - + = Q q BG q P Doc q P Doc Q P ) | ( 1 ) | ( ) | ( λ λ</formula><p>where P(Q/Doc) is the probability of generating the query from the document model, q are the words in the query, λ is a mixture parameter, P(q/BG) is the probability of the query word in the background model, and P(q/DOC) is the probability of the query word in the document. Normally, the maximum likelihood probabilities are estimated as:</p><p>( )</p><formula xml:id="formula_1" coords="2,110.19,198.32,88.30,29.51">Doc tf Doc q P Doc q, | =</formula><p>where tf q,Doc is the number of occurrences of term q in document, and |Doc| is the length of document, that is, the number of total term occurrences in the document. In an analogous manner, the background probabilities are estimated from a collection C which may or may not be the collection in which the document resides, as:</p><p>( )</p><formula xml:id="formula_2" coords="2,110.19,297.91,77.11,29.51">C tf BG q P C q, | =</formula><p>where tf q,C is the number of occurrences of term q in the collection C, and |C| is the number of total occurrences of all terms in C.</p><p>For our official run, we estimated background probabilities as above, and we estimated λ via the Witten Bell method <ref type="bibr" coords="2,128.95,383.87,16.89,9.94" target="#b10">[10]</ref>, in which Posthoc work on Arabic and other data has shown improvements in monolingual LM retrieval by modifying how λ, the mixture parameter, is calculated. For long (expanded) queries, we set λ to a constant value of .4. For short (unexpanded) queries we use Dirichlet smoothing <ref type="bibr" coords="2,391.57,471.82,16.88,9.94" target="#b11">[11]</ref>, that is,</p><formula xml:id="formula_3" coords="2,109.71,492.64,61.85,30.20">k Doc Doc + = λ</formula><p>where k = 800.</p><p>We have also found better LM performance on Arabic and other data if we use document frequencies rather than term frequencies for background models, as in <ref type="bibr" coords="2,329.18,547.06,11.79,9.94" target="#b3">[3]</ref>, that is:</p><formula xml:id="formula_4" coords="2,110.19,566.67,92.98,40.49">( ) ∑ ∈ = C t C t C q df df BG q P , , |</formula><p>where df q,C is the number of documents in C containing term q, and the summation is over all the terms in the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Arabic Corpus</head><p>The AFP ARB corpus of 383,872 documents in Arabic was converted to CP1256 encoding and normalized in the manner described above. The corpus was indexed in two different ways. For the nonstemmed conditions (UMass4), the corpus was normalized, tokenized using the Arabic tokenizer, and every token longer than one byte in length was indexed. For the stemmed conditions (UMass1, UMass2, and UMass3), stemmed tokens longer than one byte in length were indexed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Arabic Resources and Techniques</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Normalization of Arabic</head><p>In order to handle the variations in the way text can be represented in Arabic, we performed several kinds of normalization on text in the corpus and in the queries. The normalized form of the corpus was used for indexing (in the non-stemmed conditions), and queries were normalized before they were submitted to the search engine. Dictionaries were also normalized, so that their output would match the forms found in the queries and the corpus.</p><p>In our official runs, normalization consisted of the following steps:</p><p>• Convert to Windows Arabic encoding (CP1256), if necessary • Remove punctuation • Remove diacritics (mainly weak vowels) Most of the corpus did not contain weak vowels. Some of the dictionary entries contained weak vowels. This made everything consistent.</p><formula xml:id="formula_5" coords="3,90.03,261.58,175.78,88.35">• Remove non letters • Replace initial ‫إ‬ or ‫أ‬ with bare alif ‫.ا‬ • Replace ‫ﺁ‬ with ‫ا‬ • Replace the sequence ‫ىء‬ with ‫ئ‬ • Replace final ‫ى‬ with ‫ي‬ • Replace final ‫ة‬ with ‫ﻩ‬</formula><p>The definitions of punctuation, diacritics, and non-letters came from the Khoja stemmer, below.</p><p>We later improved normalization substantially via two minor changes -replacing ‫إ‬ or ‫أ‬ with bare alif ‫ا‬ regardless of position in the word, and removing tatweel. The label norm refers to the original normalization. Norm2 refers to the modified normalization, and includes stop word removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Stemming</head><p>We obtained a stemmer from Shereen Khoja of the Computing Department at Lancaster University <ref type="bibr" coords="3,524.51,439.78,11.72,9.94" target="#b4">[4]</ref>, which we modified to suit our needs. The stemmer included several useful data files such as a list of all diacritic characters, punctuation characters, definite articles, and 168 stop words, etc. We used some of these files in our normalization algorithm above. This stemmer attempts to find roots for Arabic words, which are far more abstract than stems. It first removes definite articles, prefixes, and suffixes, then attempts to find the root for the stripped form. If no root is found, then the word is left intact. The stemmer also removes stop words. We know both that roots are too abstract for effective information retrieval, and that the overall approach of not stripping any affixes at all is faulty. Although this stemmer made many mistakes, it improved performance immensely, nevertheless.</p><p>The changes we made to the Khoja stemmer were (1) If a root were not found, the normalized form was returned, rather than returning the original unmodified word. <ref type="bibr" coords="3,350.13,572.37,12.80,9.94" target="#b2">(2)</ref> We added the list of place names described in section 4.3.4 as "unbreakable" words exempt from stemming.</p><p>In addition to the Arabic stop word list included in the Khoja stemmer, we applied a script to remove stop phrases, which were translations of the stop phrases we had in our English stop-phrase removal script.</p><p>After TREC we developed a light stemmer which strips definite articles ) ‫ﻓﺎل‬ ‫آﺎل،‬ ‫ﺑﺎل،‬ ‫وال،‬ ‫ال،‬ ( and ‫و‬ (and) from the beginnings of normalized words and strips 10 suffixes from the ends of words ( ‫ات،‬ ‫ان،‬ ‫هﺎ،‬ ‫ي‬ ‫ة،‬ ‫ﻩ،‬ ‫ﻳﺔ،‬ ‫ﻳﻪ،‬ ‫ﻳﻦ،‬ ‫ون،‬ ) <ref type="bibr" coords="3,188.07,663.93,11.70,9.94" target="#b6">[6]</ref>. With stop word removal this stemmer yielded higher performance than the khoja stemmer. In the Results sections below, khoja refers to the original Khoja stemmer, khoja-u refers to the version where words on city and country list are considered unbreakable and exempt from stemming. Light refers to the light stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Dictionaries</head><p>Our structural approach to query translation for cross-language retrieval required that we look up each individual English word in each query (including words added by query expansion), and get all available translations into Arabic words or phrases. We put together several different sources of translations for English words into Arabic, using free resources from the web as much as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">The Ectaco dictionary</head><p>The Ectaco dictionary is available online, at http://www.ectaco.com/online. We could not query this dictionary under program control, so we collected entries manually from the web site. For each English query term and expanded query term, we collected entries by cutting and pasting all the Arabic translations that were available. If an English word were not found, we searched for the word as stemmed by the kstem stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">The Sakhr multilingual dictionary</head><p>The Sakhr multilingual dictionary is found at http://dictionary.ajeeb.com/en.htm. We were able to harvest entries from this dictionary under the control of a Java program which repeatedly queried the English to Arabic page with English words. We collected all available definitions for query words and expansion words. In addition, we collected Arabic-English entries for all available Arabic words in the AFP_ARB corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Sakhr SET machine translation</head><p>The Sakhr SET machine translation engine was made available to TREC participants by Mark Meinke at http://217.52.128.36/set/English/. This was not used to translate queries. We used it only to look up individual words that we did not find in either of the two dictionaries. This MT engine has a transliteration component, which converts the English word into Arabic characters if a translation is not found. We used this as a substitute for a transliteration algorithm, which we did not yet have available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4.">Place name lexicon</head><p>A small bilingual lexicon of country and city names was derived from a list of world cities we found on the web at http://www.fourmilab.ch/earthview/cities.html. This list had 489 entries, and listed the names of most countries of the world, their capitals, and a few other major cities. To get the Arabic translations, we used the Sakhr SET engine, which performed machine translation from English to Arabic. Many of these translations were transliterations. This list of place names (and only this list, which was made independently of the queries) was hand corrected by an Arabic speaking consultant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5.">Small and large lexicons</head><p>Two bilingual lexicons were built. The first (small) consisted of the place names plus all the English-Arabic translations found for all of the English query words, including the additional query words added via expansion of the English query for the cross-language run. The second (large) lexicon consisted of all the entries from the small lexicon, plus the all the inverted Arabic-English entries. For convenience, we built stemmed versions of the lexicons for each stemmer that we tested. The small normalized English to Arabic lexicon contained 28,868 English words, 269,526 different Arabic translations, for an average of 9.3 different translations per word. The large normalized lexicon contained 50,358 English words, 1,692,408 translations, for an average of 33.6 different translations per word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Other Resources and Techniques</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Stop words and phrases</head><p>English stop words (used only for cross-language retrieval) are from INQUERY's standard list of 418 stop words. English stop phrases are defined by regular expressions in a script we have used before in TREC (in English). We built a list of Arabic stop phrases from this by translating the phrases. Arabic stop words are from the Khoja stemmer's list of 168 stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Query Expansion</head><p>We expanded English queries in our official cross-language run, using the AP news articles from 1994 through 1998 in the Linguistic Data Consortium's NA News corpus. This corpus was indexed without stemming, but normalized to lower case. We retrieved the top 20 documents for each query, and ranked the terms from these documents using the ratio method described in Ponte's thesis, chapter 5 <ref type="bibr" coords="5,499.66,238.92,11.70,9.94" target="#b8">[8]</ref>. The five top ranked new English terms were then added to the query. Each term in the query received a final weight of 2w o + w e where w o is the original weight in the unexpanded query, and w e is the score the term received by the ratio method expansion.</p><p>After submitting the official runs, we changed the expansion method. Terms from the top 10 documents received an expansion score which was the sum across the ten documents of the Inquery belief score for the term in the document. The 5 terms with the highest expansion score were added to the query. Final weights were set to 2w o + w e where w o is the original weight in the unexpanded query and w e =1.</p><p>Due to technical problems involving the interaction of Arabic stemming with query expansion, and lack of time we did not submit any official runs in which the Arabic queries (monolingual, or translated for cross-language) had been expanded.</p><p>After TREC, we added Arabic query expansion, performed as follows: retrieve the top 10 documents for the Arabic query, using LM retrieval if the expanded query would be run in an LM condition, and using Inquery retrieval if the expanded query would run in an Inquery condition. Terms from the top ten documents were ranked using the same expansion score used in the post-hoc English expansion. The top 50 terms that were not already part of the original query were added. For Inquery conditions, the added terms were added to the original query as additional terms under the top level #wsum operator. For both Inquery and LM conditions, the weights on original terms were doubled, and the new terms received a weight of 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Monolingual Runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Description of Runs</head><p>We entered three monolingual runs, which differed in stemming and in retrieval algorithms:</p><p>1. Inquery Baseline. (UMass4) : normalized but not stemmed 2. Inquery Stemmed (UMass1): stemmed using Khoja-u stemmer 3. LM Stemmed (UMass2): stemmed using Khoja-u stemmer. LM as described in section 2.2.1.</p><p>The following steps were carried out in processing all monolingual runs.</p><p>1. Convert queries to CP1256 encoding.</p><p>2. Remove all but the title and description fields.</p><p>3. Remove stop phrases from Arabic queries.</p><p>4. Normalize or stem the query, depending on the condition.</p><p>5. Rank the documents using either INQUERY or LM, depending on condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Results</head><p>Without stemming our system performed very poorly. With stemming it performed quite well, as summarized in Table <ref type="table" coords="6,151.99,148.33,4.15,9.94" target="#tab_0">1</ref>. The table shows average precision for each run, and summarizes a query-by-query comparison with the median performance over 20 monolingual manual and automatic runs, with respect to average precision and the number of relevant documents returned in the top 1000.</p><p>As the table shows, stemming improves the results immensely. With stemming, average precision improved 49% over the INQUERY baseline. The LM stemmed condition was not as good as the Inquery stemmed condition. A striking pattern apparent in the table is a recall bias due to stemming. In both stemmed conditions the number of queries above the median in relevant documents returned in the top 1000 is larger than the number of queries above the median in average precision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Posthoc Monolingual Experiments</head><p>We compare the official results with runs using improved normalization, stemming, and with query expansion, and better language modeling. Table <ref type="table" coords="6,282.48,428.86,5.52,9.94" target="#tab_0">1</ref> shows the old and new conditions including the official runs, which are asterisked. Raw means that no stemming or stop word removal was applied. Norm, norm2, khoja-u, khoja, and light are defined in section 4.2 above. Since roots and lightly stemmed words are quite different representations of Arabic words, we reasoned that they could be productively combined. Light+khoja is a combination of evidence run, where the ranked lists from the light and khoja runs were averaged without any normalization of scores. Shaded cells were conditions that were not run. It is apparent from these runs that the light stemmer is superior to the khoja stemmer. Although it seemed like a good idea to have the list of unbreakable place names as part of the Khoja stemmer, performance was better without it. These results also show that the changes in background model estimation and smoothing bring language model performance to a level comparable to that of Inquery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Cross Language Retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Description</head><p>Our official cross language run (UMass3) used the INQUERY search engine, the Khoja stemmer (with unbreakables) for Arabic, the kstem stemmer for English <ref type="bibr" coords="7,330.22,170.41,11.70,9.94" target="#b5">[5]</ref>, and query expansion of the English query, dictionary lookup of query terms in the small dictionary. The steps were as follows:</p><p>1. Remove stop phrases from English queries. e. If a set of translations was found, enclose all the alternatives in a #syn (synonym) operator 5. Build a weighted sum query out of all the stemmed translations of the query terms by subsumimg all the synonym sets under a #wsum (weighted sum) operator. Each synonym set was given the weight described above in the query expansion section.</p><p>6. Submit the weighted sum query to Inquery to retrieve Arabic documents. Table <ref type="table" coords="7,101.07,647.61,5.52,9.94" target="#tab_3">3</ref> shows the results for the Cross Language run in the same format as the Table <ref type="table" coords="7,469.75,647.61,4.15,9.94" target="#tab_0">1</ref>. In this case, query-by-query performance is compared with the median of 28 cross language runs, which include 2 French to Arabic, and 1 manual run. In 20 out of 25 queries, we performed at or above the median in both average precision and in the number of relevant documents returned in the top 1000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Results</head><p>Subsequent experiments showed improved results using the same general approach, but with the light stemmer, the large dictionary, and Arabic query expansion as well as English.</p><p>We compared the small and large dictionaries, described in Section 4.3.5. Table <ref type="table" coords="8,100.18,233.52,5.52,9.94" target="#tab_4">4</ref> shows that the large dictionary performed substantially better than the smaller dictionary, in spite of the large number of translations for each word in the large dictionary.</p><p>The final set of experiments, summarized in Table <ref type="table" coords="8,299.27,264.84,4.14,9.94" target="#tab_5">5</ref>, show that expanding both English and Arabic queries with the large dictionary and the light8 stemmer give the most effective cross-language retrieval. Raw means that no normalization or stemming were applied, norm, khoja-u, khoja, and light conditions refer to normalization only, Khoja stemmer with unbreakables, Khoja stemmer without unbreakables, and light stemming, respectively. Light+khoja is a combination of evidence run, in which scores from the light and khoja runs were averaged. Combination of evidence improves performance, but only slightly. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,176.19,429.58,11.63,6.31;2,166.83,423.16,8.01,10.81;2,132.87,423.16,19.97,10.81;2,150.39,404.68,19.97,10.81;2,157.11,419.23,6.59,15.65;2,120.15,409.87,6.59,15.65;2,109.71,409.18,6.59,16.54;2,204.02,414.47,37.12,9.94;2,241.10,418.78,11.63,6.31;2,255.38,414.47,216.00,9.94"><head></head><label></label><figDesc>is the number of different terms in the document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,72.04,261.50,439.62,114.91"><head>Table 1 : Monolingual Results -official runs with normalization and khoja-u stemmer CONDITION Name of Run Average Precision Number of Queries at or Above Median Average Precision Rel Ret in top 1000</head><label>1</label><figDesc></figDesc><table coords="6,72.04,310.19,408.19,66.21"><row><cell cols="2">Inquery baseline UMass4</cell><cell>.2104</cell><cell>10/25</cell><cell>10/25</cell></row><row><cell cols="2">Inquery stemmed UMass1</cell><cell>.3129</cell><cell>18/25</cell><cell>24/25</cell></row><row><cell>LM baseline</cell><cell>not submitted</cell><cell>.1858</cell><cell></cell><cell></cell></row><row><cell>LM stemmed</cell><cell>UMass2</cell><cell>.2597</cell><cell>16/25</cell><cell>20/25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,72.04,512.64,444.84,167.22"><head>Table 2 : Monolingual results with improved normalization, stemming, and language modeling, with and without query expansion Raw Norm Norm2 Khoja-u Khoja Light Light+ Khoja</head><label>2</label><figDesc></figDesc><table coords="6,95.19,575.13,414.44,104.73"><row><cell>Inquery</cell><cell>.1935 .2104* .2408</cell><cell>.3129*</cell><cell>.3410 .3894 .4088</cell></row><row><cell cols="2">Inquery + Query Expansion .2709 .3002 .3303</cell><cell>.3595</cell><cell>.3778 .4274 .4408</cell></row><row><cell>LM</cell><cell>.1858</cell><cell>.2597*</cell><cell></cell></row><row><cell>LMnew</cell><cell>.1879 .2020 .2431</cell><cell>.3189</cell><cell>.3479 .3736 .3981</cell></row><row><cell>LMnew+Query Expansion</cell><cell>.2629 .2990 .3335</cell><cell>.3490</cell><cell>.3772 .4130 .4465</cell></row><row><cell>* official runs</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,90.03,220.32,437.56,173.36"><head></head><label></label><figDesc>Look for a set of translations in all of the English to Arabic lexicons described above b. If not found, stem the English word using the kstem stemmer and look it up again. Use all translations found in the dictionary.</figDesc><table coords="7,90.03,220.32,200.51,65.85"><row><cell>2. Remove stop words from English queries</cell></row><row><cell>3. Expand the English query</cell></row><row><cell>4. For each English word:</cell></row><row><cell>a.</cell></row></table><note coords="7,126.03,326.27,142.99,9.94;7,126.03,344.87,398.80,9.94;7,144.03,357.71,383.57,9.94;7,144.03,371.15,381.99,9.94;7,144.03,383.75,206.05,9.94"><p>c. Stem the Arabic translations d. If any of the translations consist of an Arabic phrase rather than a single word, enclose the phrase in a #filreq operator. #filreq is like a Boolean and. If this version of INQUERY had proximity information, we would have used phrase or ordered window operators instead, but these were not available.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,72.04,540.71,439.62,78.31"><head>Table 3 : Cross Language Results -official run -Inquery, expanded English, unexpanded Arabic CONDITION Name of Run Average Precision Number of Queries at or Above Median Average Precision Rel Ret in top 1000</head><label>3</label><figDesc></figDesc><table coords="7,72.04,589.41,408.19,29.61"><row><cell>Inquery baseline not submitted</cell><cell>.1691</cell><cell></cell><cell></cell></row><row><cell>Inquery stemmed UMass3</cell><cell>.2795</cell><cell>20/25</cell><cell>20/25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,162.39,126.27,287.22,78.67"><head>Table 4 : Comparison of small and large English-to-Arabic lexicons. Unexpanded cross-language retrieval norm khoja-u light8</head><label>4</label><figDesc></figDesc><table coords="8,213.26,176.05,183.47,28.89"><row><cell>Small lexicon .1660 .2069</cell><cell>.3655</cell></row><row><cell>Large lexicon .2624 .2514</cell><cell>.3794</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,98.55,365.41,413.28,104.23"><head>Table 5 : Cross-language retrieval using large lexicon, different stemmers, and query expansion raw norm khoja-u khoja light light+khoja</head><label>5</label><figDesc></figDesc><table coords="8,98.55,403.67,383.37,65.97"><row><cell>No query expansion</cell><cell>.1128</cell><cell>.2624 .2514</cell><cell>.2598 .3794 .3830</cell></row><row><cell>Expanded English</cell><cell>.1389</cell><cell>.3056 .2934</cell><cell>.3077 .4222 .4348</cell></row><row><cell>Expanded Arabic</cell><cell>.1544</cell><cell>.3371 .2917</cell><cell>.2931 .4106 .4189</cell></row><row><cell>Expanded English and Arabic</cell><cell>.1690</cell><cell>.3480 .3516</cell><cell>.3589 .4502 .4629</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">Acknowledgments</head><p>We would like to thank <rs type="person">Shereen Khoja</rs> for providing her stemmer, <rs type="person">Nicholas J. DuFresne</rs> for writing some of the stemming and dictionary code, <rs type="person">Fang-fang Feng</rs> for helping with dictionary collection over the web, <rs type="person">Mohamed Taha Mohamed</rs> , <rs type="person">Mohamed Elgadi</rs>, and <rs type="person">Nasreen Abdul-Jaleel</rs> for help with the Arabic language, <rs type="person">Victor Lavrenko</rs> for the use of his vector and language modeling code and his advice. This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs> and in part by <rs type="funder">SPAWARSYSCEN-SD</rs> grant number <rs type="grantNumber">N66001-99-1-8912</rs>. Any opinions, findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_h3zfKnn">
					<idno type="grant-number">N66001-99-1-8912</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,77.30,650.72,78.11,12.63" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,108.03,668.84,429.72,9.94;8,108.03,681.56,410.58,9.94" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F.-F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trec-9</forename><surname>Inquery</surname></persName>
		</author>
		<title level="m" coord="8,163.59,681.56,211.11,9.94">The Ninth Text REtrieval Conference (TREC-9)</title>
		<meeting><address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.00,74.41,414.48,9.94;9,108.03,87.01,304.64,9.94" xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Broglio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,284.05,74.41,238.43,9.94;9,108.03,87.01,180.98,9.94">J. TREC and TIPSTER Experiments with INQUERY. Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="343" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.06,105.73,419.61,9.94;9,108.03,118.33,423.36,9.94;9,108.03,131.05,157.38,9.94" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,241.82,105.73,285.85,9.94;9,108.03,118.33,119.48,9.94">Relating the new language models of information retrieval to the traditional retrieval models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De Vries</surname></persName>
		</author>
		<idno>TR-CTIT-00-09</idno>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<pubPlace>Enschede, The Netherlands</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">CTIT Technical Report</note>
</biblStruct>

<biblStruct coords="9,107.99,149.65,422.92,9.94;9,108.03,162.25,427.14,9.94;9,108.03,174.97,24.84,9.94" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,223.34,149.65,96.21,9.94">Stemming Arabic Text</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khoja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Garside</surname></persName>
		</author>
		<ptr target="http://www.comp.lancs.ac.uk/computing/users/khoja/stemmer.ps" />
		<imprint>
			<date type="published" when="1999-09-22">September 22, 1999</date>
			<pubPlace>Lancaster, U.K.</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computing Department, Lancaster University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.03,193.57,431.95,9.94;9,108.03,206.29,423.21,9.94;9,108.03,218.88,83.39,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,161.75,193.57,199.66,9.94">Viewing Morphology as an Inference Process</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,379.93,193.57,160.04,9.94;9,108.03,206.29,418.91,9.94">Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="191" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.02,237.48,412.92,9.94;9,108.03,250.20,413.10,9.94;9,108.03,262.80,304.56,9.94" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,327.13,237.48,193.80,9.94;9,108.03,250.20,235.32,9.94">Improving stemming for Arabic information retrieval: Light stemming and co-occurrence analysis</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Connell</surname></persName>
		</author>
		<idno>IR-249</idno>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Amherst, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">CIIR Technical Report</note>
	<note>submitted to SIGIR 2002</note>
</biblStruct>

<biblStruct coords="9,108.01,281.52,421.60,9.94;9,108.03,294.12,383.97,9.94;9,108.03,306.84,358.62,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,319.31,281.52,210.29,9.94;9,108.03,294.12,30.03,9.94">A Hidden Markov Model Information Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Leek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,157.23,294.12,334.77,9.94;9,108.03,306.84,166.31,9.94">Proceedings of SIGIR &apos;99: 22nd International Conference on Research and Development in Information Retrieval</title>
		<meeting>SIGIR &apos;99: 22nd International Conference on Research and Development in Information Retrieval<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.03,325.44,427.17,9.94;9,108.03,338.04,386.50,9.94" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,163.81,325.44,253.69,9.94">A Language Modeling Approach to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">158</biblScope>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science. Amherst, MA: University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Dissertation</note>
</biblStruct>

<biblStruct coords="9,108.03,356.75,424.23,9.94;9,108.03,369.35,425.82,9.94;9,108.03,382.07,112.17,9.94" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,223.87,356.75,224.28,9.94">A general language model for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,465.96,356.75,66.30,9.94;9,108.03,369.35,394.05,9.94">Proceedings of the Eighth International Conference on Information Knowledge Management (CIKM &apos;99)</title>
		<meeting>the Eighth International Conference on Information Knowledge Management (CIKM &apos;99)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="316" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.03,400.67,420.52,9.94;9,108.03,413.27,413.80,9.94;9,108.03,425.99,52.32,9.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,233.55,400.67,295.01,9.94;9,108.03,413.27,154.98,9.94">The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,270.62,413.27,184.97,9.94">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1085" to="1094" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.03,444.59,412.31,9.94;9,108.03,457.31,388.03,9.94;9,108.03,469.91,410.35,9.94;9,108.03,482.51,83.39,9.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,216.50,444.59,303.84,9.94;9,108.03,457.31,115.21,9.94">A Study of Smoothing Methods for Language Models Applied to Ad Hoc Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,241.58,457.31,254.48,9.94;9,108.03,469.91,286.20,9.94">Proceedings of the 24th annual international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on research and development in information retrieval<address><addrLine>New Orleans</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
