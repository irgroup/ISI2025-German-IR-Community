<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.55,108.50,322.28,12.30">Multilingual Question/Answering: the DIOGENE System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,155.51,134.01,75.34,8.72"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
							<email>magnini@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica Via Sommarive</orgName>
								<orgName type="institution">ITC-Irst</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo</settlement>
									<region>TN</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.94,134.01,53.57,8.72"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
							<email>negri@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica Via Sommarive</orgName>
								<orgName type="institution">ITC-Irst</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo</settlement>
									<region>TN</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.30,134.01,67.78,8.72"><forename type="first">Roberto</forename><surname>Prevete</surname></persName>
							<email>prevete@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica Via Sommarive</orgName>
								<orgName type="institution">ITC-Irst</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo</settlement>
									<region>TN</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.81,134.01,55.00,8.72"><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
							<email>tanev@itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Tecnologica Via Sommarive</orgName>
								<orgName type="institution">ITC-Irst</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo</settlement>
									<region>TN</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.55,108.50,322.28,12.30">Multilingual Question/Answering: the DIOGENE System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A455411CFC5390B2BA81F6E3AD6FB160</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This</head><p>paper presents the DIOGENE question/answering system developed at ITC-Irst. The system is based on a rather standard architecture which includes three components for question processing, search and answer extraction. Linguistic processing strongly relies on MULTIWORDNET, an extended version of the English WORDNET. The system has been designed to address two promising directions: multilingual question/answering and question/answering on the Web. The results obtained in the TREC-10 main task will be presented and discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the last few years, under the promotion of the TREC-8 <ref type="bibr" coords="1,108.85,453.54,113.61,9.67" target="#b16">(Voorhees and Tice 1999)</ref> and TREC-9 <ref type="bibr" coords="1,69.38,465.78,73.53,9.67" target="#b17">(Voorhees 2000)</ref> competitions, there has been a large interest in developing QA systems. Being our first participation at TREC-QA we adopted, for the DIOGENE system, a rather common architecture with three basic components: a question processing component, based on several linguistic processors and resources including WORDNET; a search component, based on information retrieval techniques; and an answer processing component, which exploits the similarity between the question and the documents to identify the correct answer. In order to identify which modules are appropriated both previous experiences in QA and modules already available at ITC-Irst have been considered. Among the proposals that we have found of interest for the linguistic analysis, we have considered the taxonomy of question types implemented in LASSO <ref type="bibr" coords="1,206.67,687.52,73.84,9.67;1,69.40,699.76,25.18,9.67" target="#b12">(Moldovan et al. 1999)</ref> for identifying both the question type and the answer type; the term extraction capabilities developed for the QALC system <ref type="bibr" coords="1,222.99,724.36,57.52,9.67;1,314.91,207.08,23.39,9.67" target="#b7">(Ferret et al. 2000)</ref>; and the use of lexical knowledge contained in WORDNET for the retrieval of semantic relations, as proposed in <ref type="bibr" coords="1,467.30,231.56,58.90,9.67;1,314.91,243.92,36.24,9.67" target="#b13">(Moldovan et al. 2000)</ref>. In addition, during the design phase of the system, two directions for future developments have been taken into consideration: multilingual QA and QA on the Web. Multilinguality is a crucial aspect when the language of the search question and the language of the text collection are different. We experimented with an Italian/English scenario, where the question can be posed either in English or Italian, the search is performed either in English or Italian, and the answer is given in the language of the question. In the paper we will discuss the solutions adopted for multilinguality, even if they are currently out of the scope of the TREC competition. As for QA on the Web, this perspective raises a number of specific issues, the most evident being that the implication of an answer with respect to its question for a Web user is generally weaker than for controlled text collections, where human judges apply rigid tests. A reason for this is that the relevance of a Web document relies on several factors. For instance, a retrieved document could not include the answer in itself, but could nevertheless provide links to other documents useful to find the answer. Elements that provide implicit knowledge are the document structure, hypertextual links, multimedia co-reference, and generally, a strong use of contextual information.</p><p>This paper is structured as follows. Section 2 introduces the overall architecture of the system. Section 3 addresses the linguistic analysis of the question, including word sense disambiguation, answer type identification and query expansion. Section 4 describes the searching modalities. Section 5 presents the answer extraction component, including paragraph filtering, named entities recognition and answer identification. Section 6 illustrates the TREC results, with a discussion on strengths and weaknesses of DIOGENE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architecture</head><p>DIOGENE relies on a rather standard architecture based on three basic components (see Figure <ref type="figure" coords="2,268.67,229.64,3.96,9.67" target="#fig_0">1</ref>): a question processing component, a search component and an answer processing component.</p><p>The question processing component is in charge of the linguistic analysis of input questions that can be formulated either in English or in Italian. At this step of the process, we confront the multilinguality problem using language specific resources.</p><p>The analysis is performed sequentially by the following modules.</p><p>• Tokenization and pos tagging. First the question is tokenized and words are disambiguated with their lexical category by means of statistical part of speech taggers.</p><p>The Treetagger developed at the University of Stuttgart <ref type="bibr" coords="2,104.43,439.74,71.73,9.67" target="#b15">(Schmid, 1994)</ref> is in charge of the disambiguation of English words. Italian questions are processed by a part of speech tagger developed at ITC-Irst.</p><p>• Multiwords recognition. About five thousand multiwords (i.e. collocations, compounds and complex terms) have been automatically extracted from different resources and are recognized by pattern matching rules. English multiwords have been extracted from WORDNET <ref type="bibr" coords="2,406.09,218.96,78.96,9.67" target="#b6">(Fellbaum, 1998)</ref>; Italian multiwords have been extracted from a monolingual Italian dictionary (Disc, 1997) • Word sense disambiguation. This module, described in Section 3.1, disambiguates words in the query with respect to their senses. MULTIWORDNET <ref type="bibr" coords="2,349.95,318.20,91.53,9.67" target="#b14">(Pianta et al., 2002)</ref> was adopted as a sense repository. Word sense disambiguation is crucial for providing reasonable keyword expansions and correct translations between the two languages.</p><p>• Answer type identification. The answer type for a question represents the entity to be searched as answer. This module relies on a taxonomy of answer types and a pattern matching rule system, both described in Section 3.2. • Keywords expansion. Two kinds of expansions, described in Section 3.3, are carried out: word synonyms and morphological derivations. Also in this case, multilinguality is guaranteed by the use of MULTIWORDNET.</p><p>The search component first composes the question keywords and their lexical expansions and then performs the document retrieval. For the participation at TREC-10 the ZPrise search engine, described in section 4, has been used.</p><p>The answer extraction component implements a paragraph filtering module that extracts text paragraphs from the top scored retrieved documents. This is done by maximizing the number of keywords and expansions produced in the question processing phase within a window of a fixed length of words. The output is composed by the text paragraphs that should contain the answer to the question. Then, a named entities recognition module identifies the entities in the text paragraphs corresponding to the answer type category. We are using an adaptation of Learning-PINOCCHIO <ref type="bibr" coords="3,230.30,415.99,50.32,9.67;3,69.39,428.23,23.14,9.67" target="#b1">(Ciravegna, 2000)</ref>, which makes use of learning algorithms to recognize named entities, such as persons, organizations, locations, measures and dates.</p><p>Finally, the answer identification module highlights the portion of text containing the answer to the question which is then presented to the user.</p><p>3 Linguistic Expansions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Semantic Disambiguation</head><p>The identification of the correct sense of a word in a question is necessary to add either synonyms or translations for that word without the risk of introducing disturbing elements in the search query. There are two crucial questions to address: first, a repository of word senses has to be identified; second, it is important to develop a disambiguation technique able to cope with the specificity of questions, particularly with the availability of a limited context (i.e. few words).</p><p>As for sense repository we have adopted MULTIWORDNET <ref type="bibr" coords="3,402.16,119.61,103.93,9.67" target="#b14">(Pianta et al. 2002)</ref>, a multilingual lexical database including information about English and Italian words. MULTIWORDNET is an extension of English WORDNET <ref type="bibr" coords="3,373.84,168.93,81.35,9.67" target="#b6">(Fellbaum, 1998)</ref>, a semantic network of English words grouped into synonym sets called synsets. Words and synsets are linked by means of various relations, distinguished into semantic relations, which link concepts, and lexical relations, which link individual words. The main lexical relations represented in WORDNET are synonymy and antonymy, while hyponymy, hypernymy, meronymy, entailment and conceptual opposition are the main semantic relations that link the synsets. MULTIWORDNET has been developed keeping as much as possible of the semantic relations available in the English WORDNET: Italian synsets have been created in correspondence with English synsets, importing lexical and semantic relations from the corresponding English synsets. The Italian part of MULTIWORDNET currently covers about 40,000 lemmas, completely aligned with the English WORDNET 1.6 (i.e. with correspondences to English senses). As far as word disambiguation is concerned we have applied Word Domain Disambiguation (WDD), a technique already experimented for the disambiguation of short news <ref type="bibr" coords="3,483.67,464.46,42.40,9.67;3,314.97,476.70,81.85,9.67" target="#b11">(Magnini, Strapparava 2000)</ref>, and further extended by adding domain frequency information. Word Domain Disambiguation is a variant of Word Sense Disambiguation (WSD) where for each word in a text a domain label, (among those allowed by the word) has to be chosen instead of a sense label. Domain labels, such as MEDICINE and ARCHITECTURE, provide a natural way to establish semantic relations among word senses, grouping them into homogeneous clusters. In MULTIWORDNET the synsets have been annotated with one or more domain labels selected from a set of about two hundred labels hierarchically organized (see <ref type="bibr" coords="3,483.69,636.65,42.40,9.67;3,314.99,649.13,69.45,9.67" target="#b9">(Magnini, Cavaglià, 2000)</ref> for the annotation methodology and for the evaluation of the resource). The WDD algorithm works in two steps. First, for each content word in the query and for each sense of the word, the corresponding domain labels in MULTIWORDNET are collected with a score determined by the frequency of the label among the senses of the word. Let us consider as example an ambiguous query from the TREC corpus. In "What is the brightest star visible from Earth?" the situation after the first step of the WDD algorithm is represented in Figure <ref type="figure" coords="4,261.35,156.57,3.92,9.67">2</ref> At the second step, all the possible tuples of domain labels for each word are scored by means of a similarity function, and the best tuple is selected. The similarity between two domains is computed according to the probability of the two domains to co-occur within a text. This information has been computed over several balanced corpora, both for English (i.e. the Brown corpus, the LOB corpus and the Reuters news corpus) and for Italian (i.e. the Elsnet corpus and a large collection of newspaper news). In our example, the algorithm selects ASTRONOMY for "star", PHYSICS for "bright", ASTRONOMY for "visible" and ASTRONOMY for "earth", which correspond to our intuition about the involved word senses.</p><p>Results obtained over the 200 TREC questions, previously manually annotated with the correct domain label for each keyword, are very encouraging, showing a limited loss in accuracy with respect to WDD over longer texts, where larger pieces of context are available for disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Answer Type Identification</head><p>The answer type for a question represents the entity to be searched as answer. In order to extract this information, a taxonomy of answer types was manually defined starting from the 200 TREC-8 questions. The taxonomy includes categories such as "LOCATION", "PERSON", "TIME-PERIOD", "MEASURE" and "GENERIC". Then, each category is associated with a set of rules that check different features of the question; in particular a rule may detect the presence of a particular word occurrence, of words of a given part of speech, and of words belonging to a given semantic category. For instance, the rule described in (1) matches any question starting with "quale" ("what"), whose first noun, if any, is a person.</p><p>( The output of a rule gives two pieces of information: the category of the answer type and the focus of the question <ref type="bibr" coords="5,177.47,193.65,97.33,9.67" target="#b12">(Moldovan et al. 1999)</ref>, i.e. the word that expresses the answer type in the question. In the examples above, the answer type is the category PERSON, while the focus is the word "leader". This information will be used to retrieve the correct answer to the question in the documents retrieved by the search engine. In particular, knowing the category of the entity we are looking for (i.e. a PERSON) the focus will be used to determine if any "candidate answer" we find in a document (i.e. person names) is an appropriate instantiation of that category. This can be done by accessing the MULTIWORDNET taxonomy and checking if the candidate answer is a synonym of the focus or is subsumed by the focus.</p><p>Currently we use about 90 answer type rules for Italian and about 70 for English. They have been checked on the TREC corpus resulting respectively in a 93% accuracy and 91%. Failures are due mainly to pos-tagging and disambiguation errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Keyword Expansion</head><p>At this step of the linguistic processing of the question, a stop words filter is applied that cuts off both non content words and non relevant content words. The remaining words (we call them "basic keywords") are then passed to an expansion phase which considers both morphological derivations and synonyms.</p><p>Morphological derivation. The approach adopted is answer oriented, in that it considers the expansions with the higher probability to appear in the answer. For instance, given the question "Who invented the electric light?", five expansions are automatically generated for the basic keyword "invent": the past participle masculine "inventato", because this is the actual form of the lemma; the past participle female "inventata", because the direct object of the verb is female; the past indicative "inventò", because in Italian it can substitute the past participle; the noun "inventore", because it is the nominalization of the subject of the verb; finally, the noun "invenzione", because it is the nominalization of the object of the verb.</p><p>Derivations have been automatically extracted from an Italian monolingual dictionary (Disc, 1997).</p><p>Synonyms. The approach adopted for disambiguation, i.e. word domain disambiguation, is in line with this assumption: domains allow the clustering of related WORDNET senses. Once a domain label for a word is selected by the disambiguation algorithm, synonyms are collected from all the MULTIWORDNET synsets for that word belonging to the selected domain. For instance, given the morphological expansions described above for the verb "invent", a number of synonyms extracted from MULTIWORDNET are added, including discover and discoverer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Definition questions</head><p>In the TREC10 main-task there are several definition questions, whose answer requires a definition of the focus. For these questions a number of specific patterns have been defined, which consider the following features:</p><p>• definition questions typically begin with "Who" or "What"; • they confine to the pattern "Who/What be sNP?", where "be" stands for the different possible forms of the verb "to be" and sNP is a simple noun phrase, which consists of a noun or adjective + noun (eventually preceded by article). For example: "Who was Galileo?" or "What is an atom?". • Anther specific pattern for definition question is "What does ABBREV stand for?" (e.g. "What does NASA stand for?") The peculiarity of these questions is that the keywords themselves do not provide enough information for extracting the proper answer. For the above mentioned questions the keywords are just "Galileo","atom" and "NASA". By restricting ourselves to simple NPs consisting of noun or adjective + noun, we avoid the improper coverage of non-definition questions.</p><p>For example the what-where questions described in <ref type="bibr" coords="6,83.28,132.09,107.73,9.67" target="#b12">(Moldovan et al. 1999)</ref> are not considered definitions because they usually use complex NPs (e.g. "What is the capital of Uruguay?"). In the case of a definition question, DIOGENE makes use of the WORDNET glosses to expand the focus of the question. The intuition behind the WORDNET gloss expansion is that because the expected answer for a definition question will be a definition of the question focus, it is reasonable to expect that it contains words that also appear in the WORDNET gloss of the focus (i.e. its definition). For instance, in the case of "Who is Galileo?" the related keywords and multiwords extracted from the gloss of "Galileo" are "astronomer", "Italian", "mathematician", and "refracting telescope". The gloss keywords are used to extend the query and they are also considered during answer extraction.</p><p>The gloss keywords extraction takes into account the gloss nouns, because we consider nouns more informative than verbs, adjectives and adverbs. All the other parts of speech are considered only if they begin with a capital letter (in the Galileo gloss -"Italian"), because usually they denote names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Search Component</head><p>At this moment DIOGENE makes use of the ZPrise <ref type="bibr" coords="6,101.68,500.58,70.21,9.67">(Dimmick, 1998</ref><ref type="bibr" coords="6,171.88,500.58,77.00,9.67" target="#b4">, Downey, 1999)</ref> search engine developed by the Retrieval Group at NIST. In particular, we used PRISE 2.0, which is part of the Z39.50/PRISE2.0 package. ZPrise is based on vector techniques and supports term feedback; on the other hand it does not support Boolean search and has restricted phrase search capabilities. Query composition is performed after keywords are extracted from the question and every word is supplied with an expansion list containing its word form and its expansions. Let's see how the query composition looks in the case of the question "Who is the inventor of the electric light?" After part-of-speech tagging and multiword extraction, the following keywords (key-phrases) are taken: "electric light" and "inventor". The lexical expansion produces the following expansion list for every key-phrase: "electric light", "electric light bulb", "incandescent lamp", and also morphological derivatives for these nouns: for "inventor" the expansion is "inventor" "artificer" "discoverer" "inventors" "artificers" "discoverers". For definition questions, gloss keywords are also extracted. Previous experiments on search modalities <ref type="bibr" coords="6,314.94,205.88,131.61,9.67" target="#b10">(Magnini and Prevete, 2000)</ref> have proven the advantage of a Cartesian product search modality, in which a Boolean expression based on the Cartesian product of the expansion lists is generated. Because of the lack of Boolean expression support in ZPrise we realised the AND expressions as a single ZPrise query and the OR expressions were transformed into multiline queries. Given the weak support of phrases in ZPrise we had to decompose multiword units into separate words, which diminishes the precision of the search. In addition, in the process of query composition no more than ten keywords for a question are taken into account because ZPrise slows down significantly when a big number of keywords are presented in one query line. Keywords are scored taking into account their part of speech (e.g. nouns score better then verbs), their polysemy (i.e. polysemous words score worse that less polysemous) and the first character of the word. The speed of the search engine turned out to be a set-back during the time of the TREC-10 questions processing. To speed up the performance we divided the document collection into four sub-collections and created a separate index for every sub-collection. This made possible a parallel search with four instances of ZPrise running on four different computers simultaneously, while every instance processes its own sub-index. After that the results are unified using UNIX shell scripts specifically developed for this purpose. This strategy significantly improved the time for the search. The method of parallel work was also used in the final stage of the question processing. A paragraph filtering module extracts text paragraphs from the top scored retrieved documents. This is done maximizing the number of keywords and expansions produced in the question processing phase, within a window of a fixed length of words. The output is composed by text paragraphs that should contain the answer to the question. Paragraph filtering can be tuned with three parameters: (i) the length of the paragraphs to be extracted, which was set at 200 words; (ii) the percentage of keywords and expansions that need to be present in the paragraph; (iii) a list, eventually empty, of obligatory keywords, whose presence is necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Named Entities Recognition</head><p>Once the relevant paragraphs have been selected, the named entities recognition module identifies, among possible candidate answers, the entities that match the answer type category (i.e. PERSON, ORGANIZATION, LOCATION, MEASURE and DATE). The task is performed by Learning-PINOCCHIO <ref type="bibr" coords="7,133.34,462.30,78.83,9.67" target="#b1">(Ciravegna, 2000)</ref>, a system for adaptive information extraction developed at ITC-Irst. Learning-PINOCCHIO learns template filling rules that insert SGML tags into texts without any other user intervention than corpus tagging. During the training phase the system induces a large set of rules by bottom-up generalization of instances in a tagged training corpus where texts have been manually marked with SGML tags locating the information to be extracted (in our case the tags &lt;person&gt;, &lt;\person&gt;, &lt;organization&gt; &lt;\organization&gt;, &lt;location&gt; &lt;\location&gt;, &lt;measure&gt;, &lt;\measure&gt;, &lt;date&gt; and &lt;\date&gt; have been used). Rule induction is also supported by dictionaries, such as repositories of person's first and last names, geographical and organization names extracted from gazetteers, online resources and WORDNET.</p><p>The training corpus used (~400Kb) was randomly extracted from the TIPSTER collection, part of the TREC material at our disposal. As expected, system performances are highly affected by the dimension, format and domain of the training corpus: documents contained in the TIPSTER collection proved to be rather heterogeneous, hampering the construction of a representative training corpus. Results obtained on the training corpus vary among categories, ranging from 74.5% precision and 82% recall for the category DATE, to 60% precision and 57% recall for the ORGANIZATION category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Answer Identification</head><p>Answer identification is performed after named entities are recognised by Learning-PINOCCHIO. In case the answer type of the question is consistent with the type of an entity c in a given paragraph p, the entity is accepted as a candidate answer. Then, the candidate entity is scored considering the presence of relevant keywords in a fifty byte interval around it. More formally, given:</p><p>• t 1 , t 2 , …,t m is the sequence of tokens composing the paragraph p, with i denoting the position of the i-th token t i . • k, s and e are functions such that c is composed of k(c) tokens, s(c) is the position of the first token and e(c) is the position of the last token of c in p. • kl(p) is the list of keywords belonging to p. • len is the kl length • member(i,p) is a function which gives as output 1 if the token t i is a kl(p) member, otherwise 0. We define the left key density and the right key density of the answer candidate c in paragraph p, indicated respectively LKD(c,p) and RKD(c,p), using the following pair of functions:</p><formula xml:id="formula_0" coords="7,314.85,646.61,53.22,58.99">LKD(c,p) = RKD(c,p) =</formula><p>Where α is a tuned parameter.</p><p>In order to build a 50 byte answer for a candidate entity c, we initially consider a default string A composed of the words in c (an entity can be composed of more than one word, for instance "Bill Clinton" is an entity whose type is PERSON). If A is composed of less than 50 characters other characters are appended to A both on its left and on its right. The number of characters added to the left is defined by LKD(c,p), while the number of characters added to the right is defined by RKD(c,p).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>Being our first experience with a QA system and given the high number of different modules assembled in DIOGENE, we did not expect high performance. The system correctly answered just 10% of the questions of the TREC main task. A manual analysis over a small set of questions was carried out to evaluate problems related to single modules. Four modules were considered: answer type identification, search engine, paragraph filtering and named-entities recognition. Each module was evaluated in term of its error rate, given a small amount of correct inputs. The estimated error rate for the answer type module was 11%, which is comparable with the performances calculated at training time (see Section 3.2). ZPrise produced a very high error rate (53%), which means that for less than half of the questions the search engine retrieved a document containing the answer. The main reason is that filters (i.e. no more than 10 documents for a question and no document with length exceeding 2000 words) applied to ZPrise output are actually too restrictive. They were implemented to take the processing time under control, but their effects were underestimated. As for paragraph filtering, its estimated error rate is around 40%, which also indicates that the techniques for paragraph extraction can be significantly improved. Finally, the estimated error rate for Learning-Pinocchio was around 60%, which was mainly due to the low homogeneity between training and test corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Future Work</head><p>The system described in this paper participated to the main task of the TREC-10 competition. Even though it relies on a rather standard architecture, DIOGENE deals with two important issues related to QA: multilingual QA and QA on the Web. For these purposes, some modules already available in ITC-Irst have been used. The results obtained by the whole system and the performance of each module have been described in the paper. Another crucial issue for the future is the automatic evaluation of a QA system. The basic idea is to develop an evaluation methodology that does not rely on the human judgment of thousands of answers. Although there is some recent work in this direction <ref type="bibr" coords="8,441.41,317.12,80.05,9.67" target="#b0">(Breck et al. 2000)</ref>, the approach we are testing considers the Web as the main information source to evaluate the relevance of an answer. Our work is based on the assumption that if a certain answer is relevant with respect to a given question, then there should be many documents containing keywords extracted both from the question and from the answer. Moreover, these documents should be semantically similar documents, i.e. they should maximize the overlapping of semantic features, such as the set of domains labels (see Section 3.1) extracted from each text.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,242.93,723.08,109.58,7.88"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. System Architecture.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,314.96,525.66,211.11,9.67;8,326.12,538.02,200.00,9.67;8,326.12,550.26,199.98,9.67;8,326.12,562.49,199.95,9.67;8,326.12,574.97,52.42,9.67;8,395.96,574.97,8.98,9.67;8,422.23,574.97,55.00,9.67;8,494.71,574.97,31.53,9.67;8,326.12,587.21,199.88,9.67;8,326.12,599.57,194.19,9.67" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,491.94,538.02,34.17,9.67;8,326.12,550.26,199.98,9.67;8,326.12,562.49,194.78,9.67">How to Evaluate Your Question Answering System Every Day …and Still Get Real Work Done</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>House</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,326.12,574.97,52.42,9.67;8,395.96,574.97,8.98,9.67;8,422.23,574.97,55.00,9.67;8,494.71,574.97,31.53,9.67;8,326.12,587.21,199.88,9.67;8,326.12,599.57,111.32,9.67">Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation</title>
		<meeting>LREC-2000, Second International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1495" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,314.97,624.05,211.28,9.67;8,323.73,636.41,202.35,9.67;8,323.73,648.77,202.40,9.67;8,323.73,661.13,202.47,9.67;8,323.73,673.37,60.64,9.67" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,381.80,624.05,144.44,9.67;8,323.73,636.41,89.91,9.67">Learning to Tag for Information Extraction from Text</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ciravegna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,438.32,648.77,87.80,9.67;8,323.73,661.13,198.17,9.67">ECAI Workshop on Machine Learning for Information Extraction</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Ciravegna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Basili</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,314.97,685.72,211.16,9.67;8,323.73,697.96,15.83,9.67;8,355.05,697.96,26.25,9.67;8,396.92,697.96,8.37,9.67;8,420.80,697.96,79.06,9.67;8,515.47,697.96,10.54,9.67;8,323.73,710.32,50.80,9.67;8,394.88,710.32,16.65,9.67;8,431.84,710.32,15.33,9.67;8,467.48,710.32,58.60,9.67" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dimmick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Over</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Rogers</surname></persName>
		</author>
		<title level="m" coord="8,355.05,697.96,26.25,9.67;8,396.92,697.96,8.37,9.67;8,420.80,697.96,79.06,9.67;8,515.47,697.96,10.54,9.67;8,323.73,710.32,50.80,9.67;8,394.88,710.32,16.65,9.67;8,431.84,710.32,15.33,9.67;8,467.48,710.32,54.09,9.67">Guide to Z39.50/PRISE2.0: Its Installation, Use and Modification</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,78.11,107.37,202.35,9.67;9,78.12,119.61,31.24,9.67" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Usa</forename><surname>Gaithersburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>unpublished resource</note>
</biblStruct>

<biblStruct coords="9,69.36,132.09,211.40,9.67;9,78.12,144.33,202.52,9.67;9,78.12,156.57,202.35,9.67;9,78.12,168.93,31.24,9.67" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,171.59,132.09,109.16,9.67;9,78.12,144.33,127.76,9.67">A Usability Case Study Using TREC and ZPrise</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,229.55,144.33,51.09,9.67;9,78.12,156.57,120.96,9.67">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="589" to="603" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.36,181.17,211.11,9.67;9,78.12,193.65,98.85,9.67" xml:id="b5">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="9,69.36,181.17,17.89,9.67">Disc</title>
		<meeting><address><addrLine>Firenze</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.36,205.88,211.17,9.67;9,78.13,218.24,142.71,9.67" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,131.88,205.88,148.66,9.67;9,78.13,218.24,37.37,9.67">WORDNET, An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.37,230.48,211.11,9.67;9,78.13,242.72,202.41,9.67;9,78.13,255.20,202.28,9.67;9,78.13,267.44,202.41,9.67;9,78.13,279.80,202.35,9.67;9,78.13,292.04,53.92,9.67" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,78.13,255.20,202.28,9.67;9,78.13,267.44,51.77,9.67">QALC -The Question Answering System of LIMSI-CNR</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hurault-Plantet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Illouz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jacquemin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lecuyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,141.00,267.44,139.54,9.67;9,78.13,279.80,135.68,9.67">Proceedings of the Ninth Text Retrieval Conference (TREC-9)</title>
		<meeting>the Ninth Text Retrieval Conference (TREC-9)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.37,304.28,211.17,9.67;9,78.13,316.64,202.41,9.67;9,78.13,328.99,202.40,9.67;9,78.14,341.35,60.04,9.67" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,78.13,316.64,202.41,9.67;9,78.13,328.99,88.43,9.67">Experiments with Open-Domain Textual Question Answering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Maiorano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,176.65,328.99,103.89,9.67;9,78.14,341.35,21.57,9.67">Proceedings of Coling-2000</title>
		<meeting>Coling-2000</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.38,353.59,211.17,9.67;9,78.14,365.83,202.52,9.67;9,78.14,378.19,202.39,9.67;9,78.14,390.55,202.40,9.67;9,78.14,402.91,49.12,9.67" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,196.21,353.59,84.34,9.67;9,78.14,365.83,124.20,9.67">Integrating Subject Field Codes into WORDNET</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cavaglià</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,213.85,365.83,66.81,9.67;9,78.14,378.19,202.39,9.67;9,78.14,390.55,170.96,9.67">Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation</title>
		<meeting>LREC-2000, Second International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1413" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.38,415.15,211.17,9.67;9,78.14,427.39,202.40,9.67;9,78.15,439.74,202.51,9.67;9,78.15,452.10,202.41,9.67;9,78.15,464.46,42.21,9.67;9,135.98,464.46,46.65,9.67;9,198.14,464.46,15.57,9.67;9,229.46,464.46,51.09,9.67;9,78.15,476.70,156.39,9.67" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,196.33,415.15,84.22,9.67;9,78.14,427.39,202.40,9.67;9,78.15,439.74,67.14,9.67">Exploiting Lexical Expansions and Boolean Compositions for Web Querying</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Prevete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,158.78,439.74,121.88,9.67;9,78.15,452.10,202.41,9.67;9,78.15,464.46,42.21,9.67;9,135.98,464.46,46.65,9.67;9,198.14,464.46,15.57,9.67;9,229.46,464.46,51.09,9.67;9,78.15,476.70,37.84,9.67">Proceedings of the ACL workshop on Recent Advances in Natural Language Processing and Information Retrieval</title>
		<meeting>the ACL workshop on Recent Advances in Natural Language Processing and Information Retrieval<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.39,488.94,211.16,9.67;9,78.15,501.30,202.41,9.67;9,78.15,513.66,202.40,9.67;9,78.16,526.02,202.52,9.67;9,78.16,538.26,58.96,9.67" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,211.94,488.94,68.61,9.67;9,78.15,501.30,202.41,9.67;9,78.15,513.66,22.14,9.67">Experiments in Word Domain Disambiguation for Parallel Texts</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,109.23,513.66,171.32,9.67;9,78.16,526.02,143.18,9.67">Proceedings of the ACL workshop on Word Senses and Multilinguality</title>
		<meeting>the ACL workshop on Word Senses and Multilinguality<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="27" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.40,550.62,211.23,9.67;9,78.16,562.85,202.41,9.67;9,78.16,575.09,202.35,9.67;9,78.16,587.57,202.53,9.67;9,78.16,599.81,156.99,9.67" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,78.16,575.09,197.81,9.67">LASSO: A Tool for Surfing Answer Net</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Goodrum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,78.16,587.57,202.53,9.67;9,78.16,599.81,49.41,9.67">Proceedings of the Eight Text Retrieval Conference</title>
		<meeting>the Eight Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.40,612.17,211.23,9.67;9,78.16,624.41,202.40,9.67;9,78.16,636.65,202.52,9.67;9,78.17,649.13,197.24,9.67;9,275.31,646.90,5.32,6.13;9,78.17,661.37,202.40,9.67;9,78.17,673.73,202.52,9.67;9,78.17,685.96,60.40,9.67" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,193.35,624.41,87.21,9.67;9,78.16,636.65,202.52,9.67;9,78.17,649.13,82.40,9.67">The Structure and Performance of an Open-Domain Question Answering System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Goodrum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,171.76,649.13,103.64,9.67;9,275.31,646.90,5.32,6.13;9,78.17,661.37,202.40,9.67;9,78.17,673.73,161.41,9.67">Proceedings of the 38 th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 38 th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.41,698.20,211.17,9.67;9,78.17,710.68,202.40,9.67;9,78.17,722.92,197.96,9.67;9,276.04,720.69,4.65,6.13;9,323.67,107.37,202.35,9.67;9,323.67,119.61,91.41,9.67" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,78.17,710.68,202.40,9.67;9,78.17,722.92,95.34,9.67">MultiWordNet: Developing an Aligned Multilingual Database</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pianta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Girardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,182.92,722.92,93.21,9.67;9,276.04,720.69,4.65,6.13;9,323.67,107.37,197.62,9.67">Proceedings of the 1 st International Global WordNet Conference</title>
		<meeting>the 1 st International Global WordNet Conference<address><addrLine>Mysore, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,314.92,132.09,211.16,9.67;9,323.68,144.33,202.40,9.67;9,323.68,156.57,202.52,9.67;9,323.68,168.93,136.23,9.67" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,391.59,132.09,134.48,9.67;9,323.68,144.33,130.53,9.67">Probabilistic Part-Of-Speech Tagging Using Decision Trees</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,461.79,144.33,64.29,9.67;9,323.68,156.57,202.52,9.67;9,323.68,168.93,102.44,9.67">Proceedings of the International Conference on New Methods in Language Processing</title>
		<meeting>the International Conference on New Methods in Language Processing</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,314.92,181.17,211.16,9.67;9,323.68,193.65,202.47,9.67;9,323.68,205.88,202.53,9.67;9,323.69,218.24,129.39,9.67" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,464.55,181.17,61.53,9.67;9,323.68,193.65,197.99,9.67">The TREC-8 Question Answering Track Evaluation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,323.68,205.88,202.53,9.67;9,323.69,218.24,49.41,9.67">Proceedings of the Eight Text Retrieval Conference</title>
		<meeting>the Eight Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,314.93,230.48,211.15,9.67;9,323.69,242.72,202.39,9.67;9,323.69,255.20,202.52,9.67;9,323.69,267.44,31.24,9.67" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,401.56,230.48,124.52,9.67;9,323.69,242.72,114.61,9.67">Overview of the TREC9 Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,445.84,242.72,80.24,9.67;9,323.69,255.20,197.08,9.67">Proceedings of the Ninth Text Retrieval Conference (TREC-9</title>
		<meeting>the Ninth Text Retrieval Conference (TREC-9</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
