<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,216.60,75.72,175.42,12.21;1,85.80,91.92,441.29,12.21">Selecting versus Describing: A Preliminary Analysis of the Efficacy of Categories in Exploring the Web</title>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council of Canada</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,187.80,107.45,51.08,9.99"><forename type="first">E</forename><forename type="middle">G</forename><surname>Toms</surname></persName>
							<email>toms@fis.utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Studies</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.60,107.45,57.60,9.99"><forename type="first">R</forename><forename type="middle">W</forename><surname>Kopak</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Library, Archival and Information Studies</orgName>
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<region>British Columbia</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.80,107.45,45.60,9.99"><forename type="first">J</forename><surname>Bartlett</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Studies</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.00,107.45,46.20,9.99"><forename type="first">L</forename><surname>Freund</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Studies</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,216.60,75.72,175.42,12.21;1,85.80,91.92,441.29,12.21">Selecting versus Describing: A Preliminary Analysis of the Efficacy of Categories in Exploring the Web</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6634E78F6C64E5B2D05EB1E9F4D5ADD6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports the findings of an exploratory study carried out as part of the Interactive Track at the 10 th annual Text Retrieval Conference (TREC). Forty-eight, non-expert participants each completed four Web search tasks from among four specified topic areas: shopping, medicine, travel, and research. Participants were given a choice of initiating the search with a query or with a selection of a category from a pre-defined list. Participants were also asked to phrase a selected number of their search queries in the form of a complete statement or question. Results showed that there was little effect of the task domain on the search outcome. Exceptions to this were the problematic nature of the Shopping tasks, and the preference for query over category when the search task was general, i.e. when the semantics of the task did not map directly onto one of the available categories. Participants also evidenced a reluctance/inability to phrase search queries in the form of a complete statement or question. When keywords were used, they were short, averaging around two terms per query statement.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>We are working toward improved search interfaces. We have observed that to date multiple approaches to the search processes have been suggested <ref type="bibr" coords="1,355.20,525.05,12.60,9.99" target="#b0">[1,</ref><ref type="bibr" coords="1,367.80,525.05,8.40,9.99" target="#b2">3,</ref><ref type="bibr" coords="1,376.20,525.05,8.40,9.99" target="#b3">4,</ref><ref type="bibr" coords="1,384.61,525.05,8.40,9.99" target="#b4">5]</ref>, but these discuss the search process at a macro level, offering guidance and orientation on how that task may be implemented{2]. At the 'keystroke' level -the point of interaction with the system, the search task is procedural; commands are entered and responses received. Missing from the literature to date is an understanding of component steps used to perform the search task at that micro level. In our work, we are taking a holistic approach to how interfaces might be designed to facilitate information searching, browsing and encountering. As a first step, we are observing how non-experts seek information on the World Wide Web (the 'Web'), noting in particular their mode of interaction with the system.</p><p>In this exploratory study we compared how participants used pre-defined categories versus standard search statements. By doing so, we hope to understand the interplay between browsing and searching while in the process of information seeking. In addition, we also examined participant behaviour across three additional factors: the way a search was entered (as question or as keyword), by the source of the task (researcher-specified versus user-personalized), and by task domain (medicine, travel, shopping, and research). We assessed the outcomes among these factors using a series of efficiency, effectiveness, and satisfaction metrics. We added verbal protocol data so that we could better understand the reasoning behind participants' use of category and string searching, and to provide a rich description of strategies used and rationales for observed patterns. In this version of our analysis, only an analysis of quantitative data is included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Our criteria for selection specified that participants be adult members of the general public (including but not limited to the university community) who have used the Web, who may have searched the Web previously, and who may have had some training, but who had not taken professional search courses. Information science/studies students were eligible only if they were in first term, and had not yet taken a professional search course. The sample was one of convenience. Participants were recruited by printed posters posted on bulletin boards on campus, or in libraries and coffee shops in the surrounding area, and via e-mail posted on listservs or enotice boards at the Universities of Toronto and British Columbia.</p><p>The 48 participants (29 women and 19 men) ranged in age from 18-20 to over 65 years; 80% were under 35. Most had university level education, mainly at the bachelor (38%) or masters (30%) level, predominantly from the humanities or social sciences. About half were students; the remainder were from a diverse range of occupations. Most (94%) of the participants had been using the Internet for more than two years, frequently using it for 6 or more hours (50%) per week. Email was the most frequently used application, with all but one person using it daily. All but one participant reported searching the web on a daily or weekly basis. Almost all had no search training of any sort. Overall, they were a relatively young, educated group who were experienced in terms of web use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Interface</head><p>We used Google as our Web search engine, and modified the standard Google interface to include both the search box/button, and the Google top level category list (directory). The resulting screen retained Google's simplicity. An instruction to either enter a query in the search box or select a category from the directory was added (See Figure <ref type="figure" coords="2,390.38,538.85,4.19,9.99">1</ref>). Beyond this initial page, the standard Google interface screens were retained.</p><p>Choice of Google as the search engine was based on its current status as the most popular search engine (http://www.searchenginewatch.com/reports/perday.html). Like many search engines, Google accepts natural language queries, joining terms with AND by default. Google uses a stop list, and displays to the user terms which were eliminated from the search. Words such as the questions' terms (who, what, where, when, why) and many other common words seem to appear on that stoplist. A query seems to be limited to ten non-stop word terms and to not be stemmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Modified Google interface</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks</head><p>Sixteen tasks (devised by the TREC 10 Interactive Track participants) were used in the study. The questions came from four domains: Medical, Research, Travel and Shopping. Of the 16 tasks, half were fully specified and half were partially specified so that participants could personalize them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>The participants were recruited in August and September of 2001 in Toronto and Vancouver. Each participant was given four search tasks, one from each of the four domains. Two of the four tasks contained specific questions or imperatives to which the participant was to respond by finding relevant Web pages. For the remaining two tasks, participants were asked to provide a topic of personal interest, but within the general topic domain pertaining to the task, e.g. Medicine. We used a modified latin squares method to distribute the question variations among the participants.</p><p>We also used two different sets of search instructions. For the first two topics, we asked the participant to either enter the query as a list of one or more words or phrases, or to select a category from the directory. For the last two topics, we asked the participant to either enter the query as a complete question or sentence, or to select a category from the directory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Each participant session lasted approximately two hours. During this time, participants</head><p>• completed a demographics and web/search experience questionnaire.</p><p>• were assigned four search tasks in sequence. For each task the participant completed a pre-search questionnaire to establish their familiarity with the topic, searched for the topic using the Web interface, and responded to a post-search questionnaire about the search process and their satisfaction with the results.</p><p>• described their search while a screen-capture video of the search was replaying. During these retrospective interviews, we tried to elicit the decision-making process used at each stage in the search process.</p><p>• responded to a series of questions regarding the search process as a whole. This final interview, which lasted about 10 minutes, was intended to get the participant to comment in a personal way on their personal challenges when searching the Web.</p><p>This paper reports, primarily, on the results of the data collected in steps 1 and 2 above.</p><p>Data was collected using four mechanisms:</p><p>1. Questionnaires for demographics, and pre-and post-search evaluations.</p><p>2. Audio-tape for all semi-structured interviews.</p><p>3. Transaction logs; the WinWhatWhere software used captured the titles and URLs of all sites visited, and all keystrokes entered.</p><p>4. Screen capture to visually record the user process; Lotus Screencam software records in real-time each user session and stores it for playback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>Data from the pre-and post-search questionnaires and the demographics survey data were combined with data from the transaction logs. Because of the way that WinWhatWhere outputted data, we manually coded the search state, such as query use, category selection, hit list selection, URL, viewing and so on, by reviewing the ScreenCam files and the WinWhatWhere files together. The additional coding made it possible to identify the path taken in each search, to determine the amount of time spent at each state, and to identify the rank position on a hit list page of each selected URL. In addition, audio-tapes were transcribed and the content is being analyzed (but is not included in this report).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of Results</head><p>The 48 participants spent about 7 minutes doing each task. They used the search box for about 66% of the tasks and selected from the directory categories for the remainder. On average, they examined about 5 URLs and about 6 links within each of those URLs. They tended to select about the fourth item on a hitlist and on average examined about two pages of hitlists.</p><p>Participants reported little familiarity with the topics for each of the assigned tasks, with few having ever done a search on any of the topics prior to the session. On a five-point scale with one being the poorest rating and five being the best rating, they indicated the degree of certainty with which they found their answer, the ease of finding the answer, and their satisfaction with the process of finding their answer at around four.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User-Specified vs. Researcher Specified Task</head><p>Half the questions were completely specified and half were fill-in-the-blanks, allowing some user modification toward personalizing the task. There were no significant differences between the two types on any measure. This finding challenges the assumption that information retrieval experimentation with pre-defined queries alters user behaviour in experimental settings. Our participants performed about the same regardless of whether they were assigned a task or allowed to create their own. That said, it is likely that the artificially of the process, e.g., time constraints, lab setting, and so on, may have a greater impact than the nature of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tactic Used</head><p>Participant search paths were analyzed according to the strategy taken in finding information. To start, they could have elected to use a query or a category, and could have changed that tactic to the other technique at any time during the process. Some participants, for example, used a single tactic such as queries only, while some used novel strategies that combined queries and categories as illustrated below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy</head><p>N Code used in Table <ref type="table" coords="5,427.76,476.88,5.67,9.44">1</ref> used queries only 104 Qry used categories only 25 Cat used queries and then selected categories 24 Qry -&gt; Cat used categories and then selected queries 39 Cat -&gt; Qry A caveat of this result is the effect of an inherent bias towards the query. While the initial start page contained both categories and a query box, once a query was used, the categories had to be sought out. On the other hand, the query box is an integral part of the second and subsequent category pages, appearing at the top of each, and on each hitlist page.</p><p>Twenty efficiency, effectiveness, and satisfactory metrics assessed the strategies used by participants. Most of this data was derived from the transaction logs or self-reported by the participant in pre-and post task questionnaires. Results from analyses of variance for each of the measures appear in Table <ref type="table" coords="6,200.40,75.05,4.50,9.99">1</ref>. There were two key differences in the strategy data. There was a key distinction between the two single-tactic strategies and between the single and mixed strategies. Participants who used only Categories looked at significantly fewer hit lists and spent less time looking at those lists than those who used only Queries. The use of categories seems to have led participants to sites that were more specifically related to the topic, while those who used Queries seemed to examine more pages of hitlists and spent more time doing so. But there were no user perception differences between those who used the single tactic strategies. Both query only and category only participants were equally satisfied with the task and with the ease with which the task was completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Results on all measures by approaches used in the search</head><p>Participants who chose the single tactic strategies i.e., categories-or queries-only, tended to find it easier and more satisfying, and were more certain about their results than when using mixed approaches. In addition, participants who use a single tactic seemed to be more successful.</p><p>Those who used mixed tactics felt the task was more difficult and seemed less satisfied than those using the single tactic strategies. Mixed tactic users also, selectedly, scored lower on some of the count and time efficiency measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search as Question vs. Search as Keyword</head><p>Participants were required to carry out half the tasks using a question or statement and half using keywords or phrases. Because of the interface, they could, however, choose to use the search box or select from the categories. In general participants used the searchbox 66% of the time, but the selection from categories versus use of the searchbox was clearly related to the way that participants were required to enter the query. When asked to search with a question, the use of categories increased significantly (? 2 =6.0, p=.014). Participants examined fewer hitlists (4.3 and 6.3, respectively) when using categories than when using a searchbox (F(1,192)=161.461, p=.017). In addition, when asked to provide a question, they tended to provide keywords or phrases for a significant number of the questionbased queries (F(2,189)=3.844, p=.023). Participants also tended to rate the task-as-question as more difficult that the task-as-keyword (F(2,189)=5.986, p=.015). We believe that participants were challenged by this task as it did not represent the way that they normally conceptualize the search process. Thus to avoid asking a question, they opted for categories.</p><p>Additionally, those who asked questions tended to create longer queries -from 2.6 to 5.8 words (F(2,165)=421.469, p&lt;.001). But the increase in size was accounted for primarily by stopwords (F(1, 166)=65.663, p&lt;.001). Queries as questions had approximately 3.7 stopwords while those entered as keywords had on average about 2.5 stopwords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type of Task</head><p>Four different task domains were used in this study: Medicine, Research, Shopping and Travel. Results for various measures across each task domain appear in Table <ref type="table" coords="7,415.20,517.85,4.50,9.99" target="#tab_2">3</ref>. There are few significant differences among the four domains.</p><p>There were however differences in post hoc Bonferroni adjusted tests. Participants did more printing in Research than Shopping (p=.035) and spent less time in Categories while responding to a Research task than a Travel task (p=.010). Research was perhaps the most complex and cognitively challenging task. Categories were rarely used for Research tasks, and participants spent little time examining categories while doing them. However, Categories were used almost identically across the other three tasks. We can speculate that the presence of top level categories that were semantically related to the assigned task made it easier to use in Shopping, Medicine and Travel queries, and, additionally, that those tasks were more specific than the Research task.</p><p>The type of task had an effect on user perception. In general participants found the Shopping task more difficult and less satisfying than the other tasks, rating these on average between 3.1 and 3.3 on a five-point scale. In addition, we mapped strategies by domain as illustrated in Figure <ref type="figure" coords="8,408.62,555.65,4.49,9.99" target="#fig_0">2</ref>. The mixed strategies are evenly used across the four domains. But when the directory categories were used as a tactic, it tended to be for travel topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion and Conclusions</head><p>We discovered that researcher-specified versus participant-personalized queries had no effect on results, suggesting that experimental tasks are as effective in experimental settings as userdefined tasks. The domain of the task, too, appears to have had little effect, although the Shopping tasks tended to be more difficult to complete, and were generally the least satisfying. The use of categories seems to have influenced the search process itself, where more time was spent contemplating the nature of the search task at the beginning of the process, resulting in fewer items being selected from the hit list, and marginally less navigation within a site once there. Anecdotally, participants indicated a need to develop a broad perspective before focusing on specific results. Once focused, they were able to make clear choices from the hiltlists than those who issued queries.</p><p>When participants were asked to express a search statement in the form of a question or statement, they had only modest success. The choice between initiating a search with a search box or with a selection from the categories seems dependent at least partially on the manner in which the query is entered. Participants were more likely to search using the categories when they were requested to create the query as question. It seems the prospect of using a question posed difficulties for participants. When entering keyword queries, the number of keywords used, on average, was quite small. Likely participants have learned one way of conceptualizing the search process and have developed a fixed mental model of that process, which constrained their ability to provide richer search statements.</p><p>Future analyses of the data will use the verbal protocol data collected to enhance our interpretation of the current findings. From the examination of this protocol data we hope to gain a richer explanation of not only what was observed in the findings reported here, but of why participants chose the courses of action they did for the various tasks performed. For example, why was the query constructed in that particular manner? What did the participant think it would achieve? Why did they choose to search using categories or queries? How did they select from the results list? And, how did they decide if a site was useful? In addition, we hope to pinpoint the problems within the search process. When participants appeared to be off course, what might have been useful to help get them back on track?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Research</head><p>Based on this current work, we also hope to carry out two additional studies that will focus on: i) developing a more refined experimental approach to the category and query integrated search, and ii) manipulating how people conceptualize the query process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="9,71.40,389.28,164.59,9.44"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Domain by Strategy Used</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,70.80,73.80,468.00,350.40"><head></head><label></label><figDesc></figDesc><graphic coords="3,70.80,73.80,468.00,350.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,72.00,232.68,445.47,70.63"><head>Table 2 . Participants first tactic by the type of search entry</head><label>2</label><figDesc></figDesc><table coords="7,73.20,244.68,444.27,58.63"><row><cell></cell><cell cols="2">Search Entered</cell><cell></cell></row><row><cell></cell><cell>in question form</cell><cell>as keyword(s) Total</cell><cell></cell></row><row><cell>Start With: Directory</cell><cell>40</cell><cell>24</cell><cell>64</cell></row><row><cell>Searchbox</cell><cell>56</cell><cell>72</cell><cell>128</cell></row><row><cell>Total</cell><cell>96</cell><cell>96</cell><cell>192</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,72.00,127.85,440.05,398.07"><head>Table 3 . Various Metrics across Type of Task</head><label>3</label><figDesc></figDesc><table coords="8,267.60,140.28,60.27,9.44"><row><cell>Type of Task</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially funded by a <rs type="funder">Natural Sciences and Engineering Research Council of Canada</rs> grant to the first author. The authors wish to thank <rs type="person">Research Assistants</rs>, <rs type="person">J. Heaton</rs> and <rs type="person">A. Olsen in Vancouver</rs> and <rs type="person">A. Lebowitz</rs> in Toronto.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,87.60,325.85,437.32,9.99;10,72.00,339.65,197.40,9.99" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,152.59,325.85,323.27,9.99">Locating information in documents: examination of a cognitive model</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">T</forename><surname>Guthrie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,484.20,325.85,40.72,9.99;10,72.00,339.65,92.40,9.99">Reading Research Quarterly</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="178" to="199" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,87.60,357.05,421.23,9.99;10,72.00,370.25,370.20,9.99" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,149.71,357.05,354.29,9.99">Inside the search process: information seeking from the user&apos;s perspective</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Kuhlthau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,72.00,370.25,267.17,9.99">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="361" to="371" />
			<date type="published" when="1991-05">5 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,87.60,388.25,415.84,9.99;10,72.00,402.05,111.00,9.99" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,163.20,388.25,223.91,9.99">Information seeking in electronic environments</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marchionini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,87.60,418.85,437.40,9.99;10,72.00,432.65,432.00,9.99;10,72.00,446.45,163.84,9.99" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,158.46,418.85,101.54,9.99">Cognitive engineering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,457.20,418.85,67.80,9.99;10,72.00,432.65,311.76,9.99">User centered system design: new perspectives on human-computer interaction</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Draper</surname></persName>
		</editor>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="31" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,87.60,463.85,442.22,9.99;10,72.00,477.05,303.60,9.99" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,278.51,463.85,251.31,9.99;10,72.00,477.05,61.49,9.99">Sorting our searching: a user interface framework for text searches</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,141.60,477.05,138.55,9.99">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="95" to="98" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
