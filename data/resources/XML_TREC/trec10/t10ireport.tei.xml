<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,79.80,97.31,128.00,16.20;1,225.80,97.31,128.97,16.20;1,372.77,97.31,65.00,16.20;1,455.77,97.31,76.48,16.20">T R E C -2 0 0 1 I n t e r a c t i v e T r a c k R e p o r t</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,269.00,129.30,70.99,10.80"><forename type="first">William</forename><surname>Hersh</surname></persName>
							<email>hersh@ohsu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Division of Medical Informatics and Outcomes Research</orgName>
								<orgName type="institution">Oregon Health Sciences University Portland</orgName>
								<address>
									<postCode>97201</postCode>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.30,209.10,48.32,10.80"><forename type="first">Paul</forename><surname>Over</surname></persName>
							<email>over@nist.gov</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Retrieval Group Information Access Division</orgName>
								<orgName type="institution">National Institute of Standards and Technology Gaithersburg</orgName>
								<address>
									<postCode>20899</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,79.80,97.31,128.00,16.20;1,225.80,97.31,128.97,16.20;1,372.77,97.31,65.00,16.20;1,455.77,97.31,76.48,16.20">T R E C -2 0 0 1 I n t e r a c t i v e T r a c k R e p o r t</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E569F2058C4881EDE881132F2ACF9E7D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motivating principles</head><p>In the TREC 2001 Interactive Track six research teams carried out observational studies which increased the realism of the searching by allowing the use of data and search systems/tools publicly accessible via the Internet. To the extent possible, searchers were allowed to choose tasks and systems/tools for accomplishing those tasks.</p><p>At the same time, the studies for TREC 2001 were designed to maximize the likelihood that groups would find in their observations the germ of a hypothesis they could test for TREC 2002. This suggested that there be restrictions -some across all sites, some only within a given site -to make it more likely that patterns would emerge. The restrictions were formalized in two sorts of guidelines: one set for all sites and another set that applied only within a site.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-site guidelines</head><p>Each site observed as many searchers as possible and appropriate. A target number of 24 was suggested.</p><p>Each searcher worked in one or more of the following domains provided by the track to all sites: finding consumer medical information on a given subject buying a given item planning travel to a given place collecting material for a project on a given subject Each searcher carried out four searches -two from a list of fully specified tasks provided to all sites and two for which only the format was predetermined but which were otherwise up to the site/searcher to create.</p><p>Each site collected a minimal standard set of data defined roughly by the track and covering searcher characteristics and satisfaction, effectiveness, and efficiency.</p><p>Each site collected at least the urls of all pages visited during all searches.</p><p>The only real submission required was the notebook paper, which was to include among other things a testable hypothesis for TREC-2002.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks</head><p>Here are the eight fully specified tasks:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical</head><p>Tell me three categories of people who should or should not get a flu shot and why. Find a website likely to contain reliable information on the effect of second-hand smoke.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Buying</head><p>Get two price quotes for a new digital camera (3 or more megapixels and 2x or more zoom). Find two websites that allow people to buy soy milk online. Travel I want to visit Antarctica. Find a website with information on organized tours/trips there. Identify three interesting things to do during a weekend in Kyoto, Japan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Project</head><p>Find three articles that a high school student could use in writing a report on the Titannic Tell me the name of a website where I can find material on global warming.</p><p>Here are the eight partially specified tasks:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical</head><p>List two of the generally recommended treatments for _____. Identify two pros or cons of taking large doses of _____.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Buying</head><p>Name three features to consider in buying a(n) _____.</p><p>Find two websites that will let me buy a(n) _____ online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Travel</head><p>Identify three interesting places to visit in _____. I'd like to go on a sailing vacation in _____, but I don't know how to sail. Tell me where can I get some information about organized sailing cruises in that area. Project Find three different information sources that may be useful to a high school student in writing a biography of ________. Locate a site with lots of information for a high school report on the history of _____.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Within-site guidelines</head><p>Within the cross-site guidelines, each site could impose further restrictions of its own choice on ALL its searchers to define an area of interest for observation -to be reported to the track before the observations begin. Each site could define its own time limits for searches. For example, a site could have imposed inclusive or exclusive restrictions on any (combinations) of the following: the choice/assignment of domain from the 4 provided, the data to be searched, the search system/tools to be used (e.g., search systems, meta-search systems, directories,...), functionality within a given search system/tool, the characteristics of searchers, the time allowed, the pre-search training provided, etc. Sites were also encouraged to coordinate their plans with other sites, form small teams sharing guidelines, etc. Each site evaluated their searches using any criteria defined in the cross-site guidelines plus any site specific evaluations. As part of the data analysis for TREC 2001, each site was to attempt to formulate a testable hypothesis for TREC 2002 and report this as part of the results for TREC 2001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of results</head><p>A total of six groups participated in this year's Interactive Track and submitted reports for the proceedings. Even though there was no official correct "answer" for any of the tasks, most groups attempted to assess some aspect of user searching performance, usually comparing two or more groups and/or systems. See each group's report for information about the formulation of testable hypotheses.</p><p>Toms et al. <ref type="bibr" coords="3,138.66,250.20,13.99,10.80" target="#b0">[1]</ref> had 48 subjects who were given a choice of initiating the search with a query or with a selection of a category from a pre-defined list. Participants were also asked to phrase a selected number of their search queries in the form of a complete statement or question. The results showed that there was little effect of the task domain (medical, buying, travel, report) on the search outcome. There was a preference for the use of queries over categories when the semantics of the search task did not map well to one of the available catetories.</p><p>Bhavhani <ref type="bibr" coords="3,131.00,343.30,13.99,10.80" target="#b1">[2]</ref> compared the searching behaviors of expert vs. non-expert searchers, with medical librarians and those experienced with on-line shopping performing both the flu-shot and camera tasks. There were substantial differences in how each group, with expertise in one area but not the other, performed the tasks. When searching in an area of expertise, the searchers tended to use more efficient, domain-specific resources and procedures, e.g., a site devoted to selling items of type X. When searching in an area outside their expertise they used more general-pupose methods (e.g. a general search engine to find a site for buying an X)</p><p>Belkin et al. <ref type="bibr" coords="3,143.33,449.70,13.99,10.80" target="#b2">[3]</ref> looked at the role of increasing query length to see if it had any impact in task performance and/or interaction. Thirty-four subjects searched in one of two conditions: a "box" query input mode and a "line" query input mode. One-half of the subjects were instructed to enter their queries as complete sentences or questions; the other half as lists of words or phrases. The results showed that queries entered as questions or statements were longer than those entered as words or phrases (twice as long), that there was no difference in query length between the box and line modes, and that longer queries led to better performance.</p><p>Hersh et al. <ref type="bibr" coords="3,139.98,556.10,13.99,10.80" target="#b3">[4]</ref> carried out a pure observational study, with users having their choice of which search engine or other resources to use. They measured time taken for searching, the number of pages viewed, satisfaction of users, and what topics users selected for their partially-formed searches. Their results showed that all the tasks took between six to ten minutes, with the buying task taking longest, followed by the medical, project, and travel tasks. User satisfaction was generally high, and the Google search engine was by far the most common starting point.</p><p>Craswell et al. <ref type="bibr" coords="3,153.99,649.20,13.99,10.80" target="#b4">[5]</ref> assessed whether there was any correlation between delivery (searching/presentation) mechanisms and searching tasks. Their experiment involved three user interfaces and two types of searching tasks. The interfaces included a ranked list interface, a clustering interface, and an integrated interface with ranked list, clustering structure, and Expert Links. The two searching tasks were searching for an individual document and for a set of documents. Their results showed that subjects usually used only one interface regardless of the searching task. No delivery mechanism was found to be superior to any other for any particular task. The only difference noted was the time used to complete a search, which was less for the ranked list interface.</p><p>White et al. <ref type="bibr" coords="4,140.66,141.10,13.99,10.80" target="#b5">[6]</ref> examined whether implicit feedback (where the system attempts to estimate what the user may be interested in) could act as a substitute for explicit feedback (where searchers explicitly mark documents relevant). They hypothesized that implicit and explicit feedback were interchangeable as sources of relevance information for relevance feedback, comparing the two approaches in terms of search effectiveness. No significant difference between the two approaches was found.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,71.00,263.50,452.96,10.80;4,82.00,276.80,441.59,10.80;4,82.00,290.10,218.96,10.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,312.65,263.50,211.31,10.80;4,82.00,276.80,286.87,10.80">Selecting Versus Describing: A Preliminary Analysis of the Efficacy of Categories in Exploring the Web</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">G</forename><surname>Toms</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>Kopak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Freund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,378.28,276.80,145.31,10.80;4,82.00,290.10,170.80,10.80">Proceedings of the Tenth Text REtrieval Conference (TREC 2001)</title>
		<meeting>the Tenth Text REtrieval Conference (TREC 2001)</meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="4,71.00,303.40,446.62,10.80;4,82.00,316.70,367.27,10.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,161.33,303.40,350.46,10.80">Important Cognitive Components of Domain-Specific Search Knowledge</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Bhavhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,82.00,316.70,319.11,10.80">Proceedings of the Tenth Text REtrieval Conference (TREC 2001)</title>
		<meeting>the Tenth Text REtrieval Conference (TREC 2001)</meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="4,71.00,330.00,483.62,10.80;4,82.00,343.30,458.56,10.80;4,82.00,356.60,111.66,10.80" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H-J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M-C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X-J</forename><surname>Yuan</surname></persName>
		</author>
		<title level="m" coord="4,287.94,343.30,252.61,10.80;4,82.00,356.60,63.50,10.80">Proceedings of the Tenth Text REtrieval Conference (TREC 2001)</title>
		<meeting>the Tenth Text REtrieval Conference (TREC 2001)</meeting>
		<imprint/>
	</monogr>
	<note>Rutgers&apos; TREC 2001 Interactive Track Experience. in press</note>
</biblStruct>

<biblStruct coords="4,71.00,369.90,455.58,10.80;4,82.00,383.20,401.26,10.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,246.63,369.90,279.95,10.80;4,82.00,383.20,25.82,10.80">Observations of Searchers: OHSU TREC 2001 Interactive Track</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sacherek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,115.98,383.20,319.11,10.80">Proceedings of the Tenth Text REtrieval Conference (TREC 2001)</title>
		<meeting>the Tenth Text REtrieval Conference (TREC 2001)</meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="4,71.00,396.50,480.61,10.80;4,82.00,409.80,367.27,10.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,319.98,396.50,225.23,10.80">TREC10 Web and Interactive Tracks at CSIRO</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,82.00,409.80,319.11,10.80">Proceedings of the Tenth Text REtrieval Conference (TREC 2001)</title>
		<meeting>the Tenth Text REtrieval Conference (TREC 2001)</meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="4,71.00,423.10,462.96,10.80;4,82.00,436.40,443.92,10.80;4,82.00,449.70,169.97,10.80" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ruthven</surname></persName>
		</author>
		<title level="m" coord="4,253.32,423.10,280.63,10.80;4,82.00,436.40,443.92,10.80;4,82.00,449.70,121.81,10.80">Comparing Explicit and Implicit Feedback Techniques for Web Retrieval: TREC-10 Interactive Track Report, Proceedings of the Tenth Text REtrieval Conference (TREC 2001)</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
