<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.73,123.72,416.00,16.20;1,219.81,159.72,155.70,16.20">TREC-10 Experiments at KAIST: Batch Filtering and Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.13,199.74,79.92,12.64"><forename type="first">Jong-Hoon</forename><surname>Oh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="department" key="dep3">Terminology Research Center for Language and Knowledge Engineering (KORTERM) Korea Advanced Institute of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>Kusong-Dong, Yusong-Gu Taejon</addrLine>
									<postCode>305-701</postCode>
									<country>Korea Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,179.39,199.74,93.76,12.64"><forename type="first">Kyung-Soon</forename><surname>Lee</surname></persName>
							<email>kslee@world.kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="department" key="dep3">Terminology Research Center for Language and Knowledge Engineering (KORTERM) Korea Advanced Institute of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>Kusong-Dong, Yusong-Gu Taejon</addrLine>
									<postCode>305-701</postCode>
									<country>Korea Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.75,199.74,94.31,12.64"><forename type="first">Du-Seong</forename><surname>Chang</surname></persName>
							<email>dschang@world.kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="department" key="dep3">Terminology Research Center for Language and Knowledge Engineering (KORTERM) Korea Advanced Institute of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>Kusong-Dong, Yusong-Gu Taejon</addrLine>
									<postCode>305-701</postCode>
									<country>Korea Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,387.25,199.74,89.05,12.64"><forename type="first">Chung</forename><forename type="middle">Won</forename><surname>Seo</surname></persName>
							<email>cwseo@world.kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="department" key="dep3">Terminology Research Center for Language and Knowledge Engineering (KORTERM) Korea Advanced Institute of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>Kusong-Dong, Yusong-Gu Taejon</addrLine>
									<postCode>305-701</postCode>
									<country>Korea Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.81,217.74,52.30,12.64"><forename type="first">Sun</forename><surname>Choi</surname></persName>
							<email>kschoi@world.kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="department" key="dep3">Terminology Research Center for Language and Knowledge Engineering (KORTERM) Korea Advanced Institute of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>Kusong-Dong, Yusong-Gu Taejon</addrLine>
									<postCode>305-701</postCode>
									<country>Korea Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.73,123.72,416.00,16.20;1,219.81,159.72,155.70,16.20">TREC-10 Experiments at KAIST: Batch Filtering and Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D1AA741D0EFF918AAC15F1EC5CA54C22</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T14:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.Introduction</head><p>In TREC-10, we participated in two tasks: batch filtering task in the filtering task, and question answering task. In question answering task, we participated in three sub-tasks (main task, list task, and context task).</p><p>In batching filtering task, we experimented a filtering technique, which unifies the results of support vector machines for subtopics subdivided by incremental clustering. For a topic, we generated subtopics by detecting similar documents in training relevant documents, and unified the results of SVM classifier for subtopics by OR set operation.</p><p>In question answering task, we submitted two runs for main task (KAISTQAMAIN1, KAISTQAMAIN2), two runs for list task (KAISTQALIST1, KAISTQALIST2), and one run for context task (KAISTQACTX).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Batch Filtering track 2.1 Experimental Procedure</head><p>We experimented a filtering technique, which unifies the results of support vector machines <ref type="bibr" coords="1,152.14,617.71,71.62,9.94">(Vapnick, 1995)</ref> for subtopics subdivided by incremental clustering. For a topic, we generated subtopics by grouping similar documents in training relevant documents, and unified the results of SVM classifiers for subtopics by OR set operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Subdividing a topic into several subtopics by incremental clustering</head><p>For each topic, we generated subtopics by incremental clustering. In incremental clustering, the input documents consist of relevant documents among training documents for a topic.</p><p>Incremental clustering sequentially processes the input documents and grows clusters incrementally. The first input document itself becomes one cluster. A new document is assigned to a member of all the clusters if the similarity between the document and the pregenerated cluster is above threshold. (A document could be a member of several clusters.) Otherwise, the document becomes a new cluster.</p><p>In our experiment, we set a cluster threshold to 0.1. It is a random selection. The comparative experiment was not conducted according to various cluster thresholds. Each cluster has a centroid vector which represents all the documents included in the cluster. We used cosine coefficient as a measure to calculate similarity between a document vector and a centroid vector. For 84 topics of Reuters test collection, we generated 275 clusters. For a topic, a cluster represents a subtopic. Therefore, we generated 275 subtopics. Training relevant documents of a subtopic are the subset of those of a topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Filtering based on SVM for each subtopic</head><p>Support vector machines are based on the Structural Risk Minimization principle <ref type="bibr" coords="2,472.78,302.71,37.55,9.94;2,107.13,320.71,25.83,9.94">(Vapnik, 1995)</ref> from computational learning theory. We tested RBF (radial basis function) models offered by SVM light system <ref type="bibr" coords="2,236.32,338.71,76.72,9.94" target="#b1">(Joachims, 1998)</ref>, which is an implementation of Vapnik's Support Vector Machine for the problem of pattern recognition. SV learning is based on sub-relevant documents subdivided by incremental clustering and all non-relevant documents for each topic. For each subtopic, we filtered the test documents by using SVM classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Unifying the results of subtopics</head><p>We unified the results generated from SVM classifiers by OR set operation. If the binary decision of SVM classifier has true (+1) for at least one subtopic, we decided the document to be relevant for the user's interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results</head><p>We submitted two runs, KAIST10bfo1 and KAIST10bfo2, for the batch filtering track. The TREC-10 filtering track used the Reuters test collection. In batch filtering, the number of training documents is 23,208 and the number of test documents is 822,805. We didn't use any other data. The number of features is 51,265. The weights of terms are calculated by ltc weighting scheme in SMART <ref type="bibr" coords="2,248.33,590.71,63.03,9.94" target="#b4">(Salton, 1983)</ref>. The KAIST10bf01 run was generated by SVM, and the KAIST10bf02 run was generated by our method.</p><p>The batch filtering task was evaluated according to a utility measure (T10SU), a version of the F measure (beta=0.5), precision, and recall. We also evaluated the results according to macro averaged F1 and micro averaged F1. Table <ref type="table" coords="2,349.95,662.71,4.61,9.94">4</ref>.1 shows the results. The result of KAIST10bfo1 differ little from KAIST10bfo2.</p><p>We expected that the unified results of SVM for subtopics might perform much better than SVM for a topic. However, the result is negative. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.Question and Answering Track</head><p>We participate in main task, list task, and context task in TREC-10. Our QA system operates on a set of documents retrieved by information retrieval system. For convenience, we worked with the top-ranked document set generated by NIST. First, 'Question Analyzer' analyzes the given question. It generates question types and extracts keywords of the given question. Then top documents retrieved by the information retrieval system are analyzed for extracting relevant answer. POS tagger and Named entity tagger are used for the purpose. Finally, 'Answer Extractor' generates relevant answers from named entity tagged documents using question type and keywords of the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Main Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Question Analyzer</head><p>A question analyzer parses the given question to identify question types and extract keywords. We define seven kinds of question type for the expected answer as following:</p><p>&lt;Person&gt;, &lt;Location&gt;, &lt;Organization&gt;, &lt;Time&gt;, &lt;Currency&gt;, &lt;Measure&gt;, &lt;OTHERS&gt; They are detected by various patterns <ref type="bibr" coords="3,278.71,660.67,77.44,9.94">(Lee, et.al, 2000)</ref> and <ref type="bibr" coords="3,378.86,660.67,131.54,9.94">WordNet (Miller, et.al, 1991)</ref> synsets. &lt;OTHERS&gt; question type is assigned to a question, when there is no pattern for the question.</p><p>For extracting keywords, POS tagger <ref type="bibr" coords="3,274.89,732.67,55.20,9.94">(Brill, 1992)</ref> and WordNet are used. Noun, adjective, countable numeric and verb except "be (is, are, was, were)" and "do (do, does, did)" are extracted as keywords. Noun phrases in the question are also considered and are extracted with a CFG-styled grammar rule.</p><formula xml:id="formula_0" coords="4,107.13,176.44,276.43,10.21">NP = ( DT (JJ | JJR | JJS ) ) { NN | NNS | NNP | NNPS }*</formula><p>If there is an acronym, its expanded form is added to keyword lists. For example, 'Cable News Network', which is expanded form of CNN, is added into keyword list for the question containing word 'CNN'. A query expansion technique is used for a noun phrase and a keyword, which is the only keyword for the given question. They are expanded with noun phrases in the WordNet definition. In the question "What is autism<ref type="foot" coords="4,434.25,282.46,3.48,6.26" target="#foot_0">1</ref> ?", for example, 'abnormal absorption', 'communication disorders' and 'short attention span' is added to keyword lists</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Answer Extractor</head><p>Our answer extractor generates top-5 ranked 50byte phrases. Its inputs are keyword, question type of the given question and top-50 retrieved texts. The top-50 texts are tagged with a POS tagger and a named entity tagger. There are two steps in answer extractor. First, a candidate sentence group is selected. Since, we believe that the context is very important for selecting relevant sentences, we group the previous two sentences, the current sentence and the next two sentences. Among these groups, top-50 sentence groups are selected with a keyword and a question type. there is no answer for the question in the text.</p><p>We expected that the results of this year might perform much better than that of last year <ref type="bibr" coords="5,107.13,212.71,75.33,9.94">(Lee, et.al, 2000)</ref>. However, the result is negative. Since, list task and context task use the module of main task, the result of those is not really good.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">List Task</head><p>List task requires the given number of answers. In TREC-10 list task, each question has information of required answer number. Question analyzer should give a question type and the number of the answer. Answer extractor should give the proper number of answers.</p><p>For example, "Question Number 1: Name 20 countries that produce coffee.", the question requires twenty answers. Question analyzer just finds number sequence and passes it to the answer extractor.</p><p>Answer extraction processes of list task are similar to those of main task except for the limitation of number of the answer. We extended the passage search algorithm for giving the right number of answer.</p><p>Answer extractor consists of two phases.</p><p>1) Candidate answer listing 2) Finding the right number of answers First, 'Candidate answer listing' finds the passages and candidate answer set of the passages. We sort the candidate answer by the frequency. Candidate answers are marked with named entity tagger and if a question type and a named-entity type are equal, the entity is added to an answer list. The answer list is sorted by the frequency of the each candidate.</p><p>Second, 'Finding the right number of answers' explores the passages for making the answer set. Answer set select by the rules as follow. 1) Answers in the same passages are selected all or nothing.</p><p>2) Answers that are on the previous answer passages are deleted from the list.</p><p>3) Answers that are included at the highly ranked passages but not in the list are excluded from the output. 4) If the numbers of the candidate answer list are smaller than the needed answer number, we uses the same methods for main task and stop when reached the right number of the output.</p><p>Answers are weighted by normalized frequency of answers and passage weight. The passage-weighting scheme is the same as that of main task. Frequencies are normalized by total frequency and scaled up for balancing passage weights. Frequencies of answer sets are just added to each answer's frequency. It makes the passages to contain more candidates in top-rank.</p><p>We combine the frequency and the passage weight using the geometric mean. </p><formula xml:id="formula_1" coords="6,165.21,256.80,108.06,30.88">•         • = ∑ ∈</formula><p>If passages have no candidate answer, the weight is zero; it is similar to context that contains no support information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Context Task</head><p>In this TREC-10, the context task is introduced for the QA system to exploit context when answering questions. Each individual question in this task has short, fact-based answers as in the main task, and each question has an answer in the collection. However, the interpretation of the question depends on the meaning of and answers to one or more earlier questions in a series. Interpreting a question correctly often involve resolution of referential links within and across sentences (TREC, 2001).</p><p>The QA system for the main task did not prepare any solution for this referential link problem. An anaphora resolution module and a keyword expansion module were made up for this weak point of the main task QA system. The system architecture is shown at figure 1. The anaphora resolution module recognizes the anaphora and finds its referent. This resolved referent could be added to the question keyword list.  These rules were implemented as FSN (Finite State Network). And, after some rules are exchanged, this FSN is also used to find the anaphora from the question. For all extracted NP, keyword type was given as 'PERSON', 'LOCATION', …, 'Other'.</p><p>When it finds the anaphora for the given question, the anaphora resolution module does its duty, looking up the referent candidate list as following sequences.</p><p>1) It tries to match the keyword type and agreement between anaphora and referent candidates of the previous question.</p><p>2) If the referent was not found, it considers others of the given question series.</p><p>3) If the decided referent is WH-pronoun, It selects the real referent from the answer list.</p><p>The resolved referent could be added to the question keyword list, and real QA process is working on the top 50 documents of the first one of question list.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,200.61,398.95,194.16,9.94"><head>Fig 1</head><label>1</label><figDesc>Fig 1 System Description for context task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,166.05,105.19,310.68,229.66"><head>Table 1 . TREC-10 Batch Filtering Results</head><label>1</label><figDesc></figDesc><table coords="3,166.05,105.19,310.68,201.10"><row><cell>Topic</cell><cell></cell><cell></cell></row><row><cell>set</cell><cell>KAIST10bfo1</cell><cell>KAIST10bfo2</cell></row><row><cell>Measure</cell><cell></cell><cell></cell></row><row><cell>MeanT10SU</cell><cell>0.295</cell><cell>0.298</cell></row><row><cell>F-beta</cell><cell>0.496</cell><cell>0.498</cell></row><row><cell>Set Precision</cell><cell>0.788</cell><cell>0.785</cell></row><row><cell>Set Recall</cell><cell>0.288</cell><cell>0.292</cell></row><row><cell>Macro averaged F1</cell><cell>0.379</cell><cell>0.384</cell></row><row><cell>Micro averaged F1</cell><cell>0.578</cell><cell>0.585</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,94.17,708.79,395.82,9.94;4,85.17,721.51,403.82,9.94;4,85.17,734.11,38.14,9.94"><p>Its definition in WordNet is "autism --((psychiatry) an abnormal absorption with the self; marked by communication disorders and short attention span and inability to treat others as people)"</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,85.17,139.03,425.24,9.94;8,99.33,153.07,281.64,9.94;8,85.17,166.99,427.96,9.94;8,99.33,181.03,171.14,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,159.27,139.03,351.13,9.94;8,99.33,153.07,156.46,9.94;8,400.84,166.99,106.84,9.94">Transformation-Based error-driven learning and natural language processing: a case study in part of speech tagging</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Linguistics</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,99.33,181.03,166.20,9.94">International Journal of Lexicography</title>
		<imprint>
			<date type="published" when="1991">1995. 1991</date>
		</imprint>
	</monogr>
	<note>Five Papers on WordNet</note>
</biblStruct>

<biblStruct coords="8,85.17,195.07,425.29,9.94;8,99.33,208.99,411.07,9.94;8,99.33,223.03,40.78,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,181.39,195.07,329.07,9.94;8,99.33,208.99,81.22,9.94">Text Categorization with Support Vector Machines: Learning with Many Relevant Features</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,206.95,208.99,303.45,9.94;8,99.33,223.03,34.95,9.94">Proceedings of the European Conference on Machine Learning (ECML)</title>
		<meeting>the European Conference on Machine Learning (ECML)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,85.17,237.07,425.30,9.94;8,99.33,250.99,202.60,9.94" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Choi</surname></persName>
		</author>
		<idno>TREC-9</idno>
		<title level="m" coord="8,398.49,237.07,111.98,9.94;8,99.33,250.99,158.37,9.94">TREC-9 Experiments at KAIST : QA, CLIR, Batch Filtering</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,85.17,265.03,425.22,9.94;8,99.33,279.07,410.92,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,183.80,265.03,198.69,9.94">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,404.23,265.03,106.16,9.94;8,99.33,279.07,256.60,9.94">THe SMART Retrieval System -Experiments in Automatic Document Processing</title>
		<imprint>
			<publisher>Prentice Hall, Inc</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,85.17,292.99,425.38,9.94;8,99.33,307.03,16.90,9.94;8,85.17,321.07,425.35,9.94;8,99.33,334.99,369.72,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,239.66,292.99,200.99,9.94;8,292.66,321.07,217.85,9.94;8,99.33,334.99,37.99,9.94">Improving retrieval performance by relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,144.84,334.99,250.03,9.94">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="288" to="297" />
			<date type="published" when="1983">1983. 1990</date>
			<publisher>McGraw-Hill, Inc</publisher>
			<pubPlace>Salton, Gerard &amp; Buckley, Chris</pubPlace>
		</imprint>
	</monogr>
	<note>Introduction to Modern Information Retrieval</note>
</biblStruct>

<biblStruct coords="8,85.17,349.03,425.36,9.94;8,99.33,363.07,411.06,9.94;8,99.33,376.99,228.29,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,353.18,349.03,157.35,9.94;8,99.33,363.07,18.93,9.94">Learning routing queries in a query zone</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mandar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,147.72,363.07,362.68,9.94;8,99.33,376.99,168.63,9.94">Proceedings of the Twentieth ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the Twentieth ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,85.17,391.03,425.37,9.94;8,99.33,405.07,126.20,9.94;8,85.17,418.99,425.31,9.94;8,99.33,433.03,25.44,9.94" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><surname>Trec</surname></persName>
		</author>
		<ptr target="http://trec.nist.gov/act_part/guidelines/qa_track_spec.html" />
		<title level="m" coord="8,414.21,391.03,96.33,9.94;8,99.33,405.07,121.56,9.94;8,220.13,418.99,184.22,9.94">TREC 2001 Question Answering Track Guideline</title>
		<meeting><address><addrLine>Vapnick, Vladimir N.; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">2001. 1995</date>
		</imprint>
	</monogr>
	<note>The Nature of Statistical Learning Theory</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
