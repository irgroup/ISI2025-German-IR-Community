<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.32,78.87,269.34,15.06;1,194.75,96.81,222.46,15.06">A Hybrid Method for Opinion Finding Task (KUNLP at TREC 2008 Blog Track)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,101.52,148.72,58.28,12.55"><forename type="first">Linh</forename><surname>Hoang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,168.94,148.72,84.03,12.55"><forename type="first">Seung-Wook</forename><surname>Lee</surname></persName>
							<email>swlee@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,261.35,148.72,74.73,12.55"><forename type="first">Gumwon</forename><surname>Hong</surname></persName>
							<email>gwhong@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,345.25,148.72,73.45,12.55"><forename type="first">Joo-Young</forename><surname>Lee</surname></persName>
							<email>jylee@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,427.08,148.72,83.34,12.55"><forename type="first">Hae-Chang</forename><surname>Rim</surname></persName>
							<email>rim@nlp.korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.32,78.87,269.34,15.06;1,194.75,96.81,222.46,15.06">A Hybrid Method for Opinion Finding Task (KUNLP at TREC 2008 Blog Track)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0678A9AB752515702BE48740DEC3866E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an approach for the Opinion Finding task at TREC 2008 Blog Track. For the Ad-hoc Retrieval subtask, we adopt language model to retrieve relevant documents. For the Opinion Retrieval subtask, we propose a hybrid model of lexicon-based approach and machine learning approach for estimating and ranking the opinionated documents. For the Polarized Opinion Retrieval subtask, we employ machine learning for predicting the polarity and linear combination technique for ranking polar documents. The hybrid model which utilize both lexicon-based approach and machine learning approach to predict and rank opinionated documents are the focuses of our participation this year. Regarding the hybrid method for opinion retrieval subtask, our submitted runs yield 15% improvement over baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>TREC 2008 Blog Track defines two main tasks: the Opinion Finding and the Blog Distillation. We participated in the Opinion Finding task which is split into three separate subtasks (our system structure for the retrieval subtasks is shown in Figure <ref type="figure" coords="1,249.71,598.14,3.94,11.46" target="#fig_0">1</ref>).</p><p>The first subtask, Ad-hoc Retrieval, involves finding blog posts which contain relevant information about a given topic. To be considered as baseline, this subtask is supposed to turn off all opinion finding features. In order to concentrate on the opinion finding methods, we simply adopted out-of-the-box models supported by Lemur toolkit<ref type="foot" coords="1,223.80,691.53,3.99,8.37" target="#foot_0">1</ref> for this subtask.</p><p>According to our empirical runs, language model turned out to be relatively better than vector space model for Ad-hoc Retrieval. We also applied several techniques for query expansion but neither proposed cluster-based expanding nor classic pseudorelevance feedback did not help to improve the retrieval performance.</p><p>The second subtask, Opinion Retrieval, involves locating blog posts that express an opinion about a given topic. The relevant blog post must have an opinion presented in the post or in one of its comments. To deal with this subtask, we structured our approach as a two-step process, including detecting opinionated documents and ranking them. To detect the opinionated blog posts, we employed both lexicon-based approach (LE) and machine learning approach (ML). The opinion scores estimated by LE and ML are then linearly combined with topic relevance score to produce the final ranking for detected documents. For this two-step process, we proposed a hybrid method utilizing LE and ML at both the detecting step and the ranking step. In addition, we applied spam filtering as a post-processing step of the Opinion Retrieval subtask, that conducted a marginal improvement of retrieval performance.</p><p>The Polarized Opinion Retrieval subtask involves not only locating positive (resp. negative) opinionated blog posts but also ranking them according to the degree of polarity. Ranking is a new requirement for this subtask in 2008. To deal with requirement of excluding mixed documents (i.e, ones contain both positive and negative opinions), we trained a ternary classifier to classify opinionated documents into positive, negative, and mixed class. After re- 2 Ad-hoc Retrieval</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The Blog06 collection is used again in TREC 2008. For all the three mentioned subtasks, we indexed only permalinks as the retrieval component. At the pre-processing step, we discarded all HTML tags and redundant scripts from permalink documents. Porter stemming and standard stop-word removing are early applied for indexing but they slightly harmed the preliminary retrieval results. Therefore, we did not use neither stemming nor stop-word removal at the final indexing version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Processing</head><p>Query expansion is the process of adding terms to the original search query. To study the effectiveness of query expansion for Ad-hoc Retrieval, we empirically exploited two simple techniques as follows:</p><p>Cluster-based analysis: The first technique for expanding query comes from the hypothesis that clustering can provide retrieval extra information. We deployed this idea by using Clusty search engine<ref type="foot" coords="2,331.98,551.57,3.99,8.37" target="#foot_1">2</ref> . Clusty is a text clustering search engine allows grouping search results into folder topics. Empirically, we issue an original query to Clusty and take the titles of top n clusters<ref type="foot" coords="2,443.98,592.22,3.99,8.37" target="#foot_2">3</ref> as expanded terms.</p><p>Pseudo-relevance feedback: The intuition of pseudo-relevance feedback is that top ranked retrieved documents would be the most relevant ones to the given query. Consequently, those documents might contain terms which are highly related to the topic. For simply examining this method, we se- lected n most frequent terms in top ranked documents and add them to the original query.</p><p>Using topic description has been reported to be marginally beneficial to opinion finding task <ref type="bibr" coords="3,269.18,242.23,29.71,11.46;3,72.00,255.79,50.53,11.46" target="#b3">(Ounis et al., 2006)</ref>. For this analysis, we used terms in the topic description after removing standard stop words as expanded terms for the original query. Given query Windows Vista, Table <ref type="table" coords="3,218.87,296.43,5.46,11.46" target="#tab_0">1</ref> shows an example of processed queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Language Model</head><p>As mentioned earlier, we empirically adopted several out-of-the-box models for Ad-hoc Retrieval. According to our experiments, Kullback-Leibler (KL) divergence was shown to be the bestperformed model comparing to other ones. KL is a statistical language model which scores and ranks documents by the KL-divergence (i.e, relative entropy) between the query language model and the document language model <ref type="bibr" coords="3,212.54,460.51,86.34,11.46;3,72.00,474.06,23.49,11.46">(Lafferty and Zhai, 2001)</ref>. Since ranking documents is of interests, KLdivergence is rewritten as the cross entropy of the query model with respect to the document model. For the reason of performance, we used KL model for both of two submitted baseline runs. Additionally, we applied Bayesian smoothing method using Dirichlet priors with default prior parameter set to 1000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Opinion Retrieval</head><p>So far, two effective approaches to detect opinionated documents are lexicon-based approach and machine learning approach. In this work, we employed both of these two approaches for identifying opinionated blog posts and ranking them. The intuition here is that individual approach likely retrieves the different set of documents; the combined system hence performed better due to the increase of recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Lexicon-based Approach</head><p>In general, lexicon-based approach starts at constructing a dictionary of terms indicating opinion. The opinionated documents are then decided if opinion terms occur in those documents. Following the general framework, we first compiled a list of opinion words from several sources:</p><p>General Inquirer: General Inquirer <ref type="bibr" coords="3,485.20,305.19,54.85,11.46;3,313.20,318.74,25.46,11.46" target="#b6">(Stone et al., 1966)</ref> is a manually-constructed lexicon that consists of many semantic and emotional categories. We selected the words within opinion-related categories<ref type="foot" coords="3,344.55,357.93,3.99,8.37" target="#foot_3">4</ref> and added them to the final opinion-word list.</p><p>Word Net: Starting with a small set of annotated words (seeds), we iteratively looked for synonyms and antonyms of seeds in the WordNet <ref type="bibr" coords="3,506.87,415.34,33.22,11.46;3,313.20,428.89,23.49,11.46" target="#b1">(Miller, 1992)</ref>. At each iteration, the newly found words were added to the seed list for the next searching iteration. This process was stopped when there was no new word to be found. Final expanded word set was concatenated to the opinion-word list.</p><p>Wilson Word Set: This word set is constructed by <ref type="bibr" coords="3,326.46,511.94,119.97,11.46">Wilson (Wilson et al., 2003)</ref>, which includes subjective clues for identifying opinionated sentences. We concatenate this word set to the final opinionword list.</p><p>After removing duplicate words from the final opinion-word list, we obtained a dictionary of 29,876 words. The weights of words were trained on the assessment for 100 topics in 2006 and 2007. Empirically, the assessed blog posts were split into opinionated (O) and non-opinionated (N) set. Each word in the dictionary was then assigned a weight given by: weight(w i ) =</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P(w i |O) -P(w i |N) P(w i |O) + P(w i |N)</head><p>(1)</p><p>Equation 1 is inherited from <ref type="bibr" coords="4,215.52,116.55,83.35,11.46" target="#b5">(Dave et al., 2003)</ref> where P(w i |O) (resp., P(w i |N)) is estimated by the occurrences of w i in O (resp., N) over the occurrences of all tokens in O (resp., N).</p><p>Using the weighted dictionary, a document retrieved from ad-hoc retrieval is scored as follows:</p><formula xml:id="formula_0" coords="4,98.78,217.93,200.03,31.51">score LE (d) = w i ∈d tfidf(w i ).weight(w i ) nearest(w i ,topic) (2)</formula><p>where nearest(w i ,topic) is the distance (by word) between opinion word w i and the original topic. Document d is determined to be opinionated if score LE (d) is positive and non-opinionated otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Machine Learning Approach</head><p>In the context of machine learning, detecting opinionated documents can be considered as a binary classification task. We thus train a binary classifier on the last-two-year assessment. SVM light package<ref type="foot" coords="4,294.32,380.18,3.99,8.37" target="#foot_4">5</ref> is employed for the classification task. Further believing that machine learning can benefit from the opinion-indicated terms, we used opinion words in the compiled dictionary for LE instead of all lexical unigrams as training features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">A Hybrid Method</head><p>Opinion Retrieval subtask requires ranking opinionated documents after identifying their subjectivity. Considering that the opinion retrieval subtask contains classifying step and ranking step, we adopt a hybrid method for each step. At classifying step, the documents classified as non-opinionated by both of LE and ML are removed. At ranking step, both LE and ML scores are combined with topic relevance score to produce final ranking score as below:</p><formula xml:id="formula_1" coords="4,74.32,636.96,221.67,12.55">score OR = λ 1 score T R + λ 2 score LE + λ 3 score M L</formula><p>(3) where score T R , score LE , score M L are the topic relevance score of ad-hoc retrieval, the opinion score estimated by equation 2 and the output score of binary SVM classifier respectively. In our experiments, the weights for each component score are heuristically tuned to maximize the MAP of opinion ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Spam Filtering</head><p>Since splogs cause negative effects to retrieval, we adopt spam filtering method similar to the one in <ref type="bibr" coords="4,313.20,174.36,66.37,11.46" target="#b3">(Mishne, 2006)</ref>. We trained naive Bayesian classifier to detect splogs. The training spam data was collected by querying casino to Google web search engine<ref type="foot" coords="4,342.29,213.55,3.99,8.37" target="#foot_5">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Polarized Opinion Retrieval</head><p>Polarized Opinion Retrieval can be referred to polarity classification subtask in Blog Track 2007 <ref type="bibr" coords="4,513.42,280.24,21.33,11.46;4,313.20,293.80,81.54,11.46" target="#b0">(Macdonald et al., 2007)</ref>. Ranking polar opinionated documents (positive and negative ones) is a new issue this year. As mentioned earlier, although mixed documents are not required to be retrieved, identifying them is deemed to make the retrieval accurate. Due to this intuition, we employed machine learning approach for dealing with this task since lexicon-based approach turned out to be poor-performed at preliminary experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Classifying Polar Opinionated Documents</head><p>In our experiments, we used SVM multiclass in SVM package for training a ternary classifier. The training corpus was the last-two-year assessments for 100 topics. The features for classification were still opinion words in the compiled dictionary mentioned in section 3.1. At the classifying step, trained classifier categorizes opinionated documents into positive, negative, and mixed category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ranking Polar Opinionated Documents</head><p>At ranking step, mixed opinionated documents are ruled out, only positive and negative opinionated ones are retained for ranking. The final ranking score is the linear combination of opinion ranking score and polar score of ternary SVM classifier.</p><formula xml:id="formula_2" coords="4,318.66,686.61,221.34,12.55">score P OR = λ 4 score OR + (1 -λ 4 ).score SV M (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>MAP R-prec P@10 kunlpKLtt title only 0.2713 0.3544 0.5800 kunlpKLtd title+description 0.2666 0.3465 0.6567    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Submissions</head><p>We submitted two baseline runs for Ad-hoc Retrieval subtask. Both of them were based on KLdivergence model. Whereas kunlpKLtt is the title-only run, kunlpKLtd is the title-description run. Table <ref type="table" coords="5,119.18,656.71,5.46,11.46" target="#tab_1">2</ref> shows the evaluation of these two baseline runs for 150 topics from Blog Track 2006 to 2008. Interestingly note that using description is effective to improve the early precision of ad-hoc retrieval (P@10 is boosted at 13.2% from 0.58 to 0.6567). Additionally, table 3 demonstrates the effects of query expansion techniques for ad-hoc retrieval. It can be shown that neither cluster-based analysis nor pseudo-relevance feedback helped increasing performance.</p><p>From each baseline run, we generated two runs based on the hybrid model for Opinion Retrieval subtask (in two runs, parameter λ is empirically adapted to optimize MAP of opinion ranking). Table 4 shows the evaluation of four submissions after filtering splogs. The experimental results showed that the proposed hybrid method remarkably improved opinion retrieval performance over baseline (the best run boosted MAP at 14.8% from 0.1991 to 0.2285). In addition, spam filtering conducted a marginal contribution for opinion retrieval (our experiment resulted in an average increase of MAP at 1%, as shown in table <ref type="table" coords="6,169.92,168.70,3.94,11.46" target="#tab_4">5</ref>).</p><p>For the Polarized Opinion Retrieval, we submitted two runs corresponding to the two best runs of Opinion Retrieval (i.e., kunlpKLttOc and kunlpKLtdOc). Table <ref type="table" coords="6,184.29,222.91,5.46,11.46" target="#tab_5">6</ref> shows the evaluation of these two runs with respect to positive ranking and negative ranking. It can be shown in detail from table 6 that Polarized Opinion Retrieval is strongly dominated by the underlying Opinion Retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper described our approaches for Opinion Finding task at TREC Blog Track 2008. For Ad-hoc Retrieval, KL-divergence model achieved the best results among the others. Utilizing description of topic was shown to be helpful for boosting early precision of Ad-hoc Retrieval. For Opinion Retrieval, hybrid model of lexicon-based approach and machine learning approach was proposed to detect and rank opinionated documents. Spam filtering slightly helped improving the performance of Opinion Retrieval. For Polarized Opinion Retrieval, machine learning approach was employed for predicting polar opinionated documents. Polar score estimated by classifier was then linearly combined with opinion score to produce the final ranking score of those polar opinionated documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,204.00,391.62,204.01,10.46;2,72.00,72.18,468.00,304.40"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System structure of Opinion Finding task</figDesc><graphic coords="2,72.00,72.18,468.00,304.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,104.48,241.69,20.01,11.46;5,177.03,241.69,53.95,11.46;5,388.33,241.69,24.85,11.46;5,430.28,241.69,71.59,11.46;5,104.48,255.65,45.47,11.46;5,177.03,255.65,37.58,11.46;5,388.33,255.65,115.82,11.46;5,104.48,269.19,146.18,11.46;5,250.66,273.33,4.24,8.37;5,258.42,269.19,36.67,11.46;5,295.09,273.33,4.24,8.37;5,302.85,269.19,28.17,11.46;5,331.03,273.33,4.24,8.37;5,338.79,269.19,29.09,11.46;5,388.33,269.19,115.82,11.46;5,104.48,282.75,146.18,11.46;5,250.66,286.88,4.24,8.37;5,258.42,282.75,36.67,11.46;5,295.09,286.88,4.24,8.37;5,302.85,282.75,36.67,11.46;5,339.51,286.88,4.24,8.37;5,347.28,282.75,156.88,11.46;5,104.48,296.69,47.90,11.46;5,177.03,296.69,37.58,11.46;5,388.33,296.69,119.21,11.46;5,104.48,310.24,146.18,11.46;5,250.66,314.37,4.24,8.37;5,258.42,310.24,36.67,11.46;5,295.09,314.37,4.24,8.37;5,302.85,310.24,28.17,11.46;5,331.03,314.37,4.24,8.37;5,338.79,310.24,29.09,11.46;5,388.33,310.24,115.82,11.46;5,104.48,323.79,146.18,11.46;5,250.66,327.93,4.24,8.37;5,258.42,323.79,36.67,11.46;5,295.09,327.93,4.24,8.37;5,302.85,323.79,36.67,11.46;5,339.51,327.93,4.24,8.37;5,347.28,323.79,156.88,11.46"><head></head><label></label><figDesc>model (λ 1 = 0.3, λ 2 = 0, λ 3 = 0.7) 0.2234 0.3045 0.5553 kunlpKLttOc Hybrid model (λ 1 = 0.3, λ 2 = 0.1, λ 3 = 0.6) 0.2285 0.3138 0.5600 kunlpKLtd Baseline 0.1953 0.2739 0. 4553 kunlpKLtdOs Hybrid model (λ 1 = 0.3, λ 2 = 0, λ 3 = 0.7) 0.2186 0.3030 0.5500 kunlpKLtdOc Hybrid model (λ 1 = 0.3, λ 2 = 0.1, λ 3 = 0.6) 0.2191 0.3037 0.5620</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,95.62,72.79,420.80,106.62"><head>Table 1 :</head><label>1</label><figDesc>Example of processed queries for the original query Windows Vista.</figDesc><table coords="3,95.62,72.79,420.80,79.61"><row><cell>Cluster-based analysis</cell><cell>Pseudo-relevance feedback</cell><cell cols="2">Using topic's description</cell></row><row><cell>Windows Vista Microsoft</cell><cell>Windows Vista Microsoft</cell><cell>Windows Vista</cell><cell>Find</cell></row><row><cell>Software Operating system</cell><cell>Software beta (top 3 most fre-</cell><cell cols="2">opinion Microsoft operating</cell></row><row><cell>(top 3 clusters's title are</cell><cell>quent terms of top 50 ranked</cell><cell>system any features</cell><cell></cell></row><row><cell>added to the original query)</cell><cell>retrieved documents are added</cell><cell></cell><cell></cell></row><row><cell></cell><cell>to the original query)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,186.20,128.29,239.61,73.68"><head>Table 2 :</head><label>2</label><figDesc>Results of Ad-hoc Retrieval.</figDesc><table coords="5,186.20,149.46,239.61,52.51"><row><cell>Expansion techniques</cell><cell>MAP</cell><cell>R-prec P@10</cell></row><row><cell>None (title only)</cell><cell cols="2">0.2713 0.3544 0.5800</cell></row><row><cell>Cluster-based analysis</cell><cell cols="2">0.2089 0.2919 0.5240</cell></row><row><cell cols="3">Local-relevance feedback 0.2105 0.2841 0.4720</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,189.38,218.52,233.25,10.46"><head>Table 3 :</head><label>3</label><figDesc>Effects of query expansions for Ad-hoc Retrieval.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,208.70,351.79,192.51,75.70"><head>Table 4 :</head><label>4</label><figDesc>Results of Opinion Retrieval.</figDesc><table coords="5,208.70,374.98,192.51,52.51"><row><cell>Spam</cell><cell>Average</cell><cell>Average</cell><cell>Average</cell></row><row><cell>filtering</cell><cell>MAP</cell><cell>R-prec</cell><cell>P@10</cell></row><row><cell>No</cell><cell>0.2193</cell><cell>0.3013</cell><cell>0.5400</cell></row><row><cell>Yes</cell><cell>0.2224</cell><cell>0.3069</cell><cell>0.5563</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,144.56,444.04,322.89,90.68"><head>Table 5 :</head><label>5</label><figDesc>Effects of spam filtering for Opinion Retrieval.</figDesc><table coords="5,144.56,467.23,322.89,67.50"><row><cell>Run</cell><cell>Description</cell><cell>MAP</cell><cell>R-prec P@10</cell></row><row><cell cols="4">kunlpKLttPc Positive ranking (λ 4 = 0.8) 0.1454 0.2153 0.3329</cell></row><row><cell></cell><cell cols="3">Negative ranking (λ 4 = 0.8) 0.1229 0.1853 0.2754</cell></row><row><cell cols="4">kunlpKLtdPc Positive ranking (λ 4 = 0.8) 0.1361 0.2086 0.3262</cell></row><row><cell></cell><cell cols="3">Negative ranking (λ 4 = 0.8) 0.1234 0.1846 0.2718</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,210.19,550.22,191.63,10.46"><head>Table 6 :</head><label>6</label><figDesc>Results of Polarized Opinion Retrieval.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,88.14,712.56,102.32,9.41"><p>http://www.lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,329.34,701.39,59.92,9.41"><p>http://clusty.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,329.34,712.56,210.56,9.41"><p>In Clusty, clusters are sorted by their number of documents</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,329.34,690.65,210.61,9.41;3,313.20,701.60,209.72,9.41;3,313.20,712.56,176.83,9.41"><p>We considered the categories Positive, Negative, Arousal, Emotion, Feel, Pain, Pleasure, Virtue, Self, Our as opinion-related ones</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,88.14,712.56,103.92,9.41"><p>http://svmlight.joachims.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,329.34,712.56,84.56,9.41"><p>http://www.google.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,72.00,591.25,226.80,10.46;6,82.91,603.20,215.88,10.46;6,82.91,615.17,49.26,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,247.98,591.25,50.82,10.46;6,82.91,603.20,110.42,10.46">Overview of the TREC-2007 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,202.80,603.20,96.00,10.46;6,82.91,615.17,24.36,10.46">Proceedings of the 16th TREC</title>
		<meeting>the 16th TREC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,627.42,226.80,10.46;6,82.91,639.37,215.89,10.46;6,82.91,651.33,87.40,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,128.97,627.42,165.72,10.46">WordNet: a Lexical Database for English</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,82.91,639.37,215.89,10.46;6,82.91,651.33,62.51,10.46">Proceedings of the workshop on Speech and Natural Language, ACL</title>
		<meeting>the workshop on Speech and Natural Language, ACL</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,663.59,226.80,10.46;6,82.91,675.54,213.24,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,120.28,663.59,178.52,10.46;6,82.91,675.54,59.13,10.46">Multiple Ranking Strategies for Opinion Retrieval in Blogs</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,149.93,675.54,121.31,10.46">Proceedings of the 15th TREC</title>
		<meeting>the 15th TREC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.00,687.81,226.80,10.46;6,82.91,699.76,215.89,10.46;6,82.91,711.71,146.22,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,127.81,699.76,166.77,10.46">Overview of the TREC-2006 Blog Track</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,82.91,711.71,121.31,10.46">Proceedings of the 15th TREC</title>
		<meeting>the 15th TREC</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,74.67,226.80,10.46;6,324.11,86.63,215.89,10.46;6,324.11,98.58,135.33,10.46" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,418.84,74.67,121.16,10.46;6,324.11,86.63,215.89,10.46;6,324.11,98.58,34.66,10.46">Document Language Models, Query Models, and Risk Minimization for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>24th ACM SIGIR 2001</note>
</biblStruct>

<biblStruct coords="6,313.20,111.28,226.80,10.46;6,324.11,123.24,215.89,10.46;6,324.11,135.19,190.70,10.46" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,510.66,111.28,29.34,10.46;6,324.11,123.24,215.89,10.46;6,324.11,135.19,132.78,10.46">Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,147.90,226.80,10.46;6,324.11,159.85,138.82,10.46" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C</forename><surname>Dunphy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
		<title level="m" coord="6,447.66,147.90,92.35,10.46;6,324.11,159.85,68.90,10.46">Computer Approach to Content Analysis</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,313.20,172.55,226.80,10.46;6,324.11,184.51,215.89,10.46;6,324.11,196.47,45.32,10.46" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<title level="m" coord="6,469.82,172.55,70.18,10.46;6,324.11,184.51,215.89,10.46;6,324.11,196.47,45.32,10.46">Identifying Opinionated Sentences ACL 2003 on Human Language Technology</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
