<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.36,72.23,294.93,16.98;1,116.02,92.15,377.62,16.98">H5 at TREC 2008 Legal Interactive: User Modeling, Assessment &amp; Measurement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,108.35,137.77,100.49,11.32"><forename type="first">Christopher</forename><surname>Hogan</surname></persName>
							<email>chogan@h5.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Teresa Jade</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.36,137.77,60.99,11.32"><forename type="first">Dan</forename><surname>Brassil</surname></persName>
							<email>dbrassil@h5.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Teresa Jade</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,389.64,137.77,89.79,11.32"><forename type="first">Shana</forename><forename type="middle">M</forename><surname>Rugani</surname></persName>
							<email>srugani@h5.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Teresa Jade</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,113.03,168.12,91.13,11.32"><forename type="first">Jennifer</forename><surname>Reinhart</surname></persName>
							<email>jreinhart@h5.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Teresa Jade</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.31,168.12,65.08,11.32"><forename type="first">Misti</forename><surname>Gerber</surname></persName>
							<email>mgerber@h5.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Teresa Jade</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.81,206.94,82.11,9.44"><roleName>CA</roleName><forename type="first">San</forename><surname>Francisco</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Teresa Jade</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.36,72.23,294.93,16.98;1,116.02,92.15,377.62,16.98">H5 at TREC 2008 Legal Interactive: User Modeling, Assessment &amp; Measurement</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9B2A4D45CF1689AE69E1AB8A88CACCE4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Treating the information retrieval task as one of classification has been shown to be the most effective way to achieve high performance on a particular task. In this paper, we describe a hybrid human-computer system that addresses the problem of achieving high performance on IR tasks by systematically and replicably creating large numbers of document assessments. We demonstrate how User Modeling, Document Assessment and Measurement combine to provide a shared understanding of relevance, a means for representing that understanding to an automated system, and a mechanism for iterating and correcting such a system so as to converge on a desired result.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The extraordinary effectiveness of the Relevance Feedback (RF) paradigm is well established. Recent work <ref type="bibr" coords="1,244.54,419.49,14.32,7.86" target="#b19">[19]</ref> treating the information retrieval task as a form of classification has demonstrated that the most effective way to achieve high performance on a particular task is to acquire a large number of document assessments. How these assessments are acquired, however, is often left unspecified: within evaluations, such as the TREC series of conferences, assessments performed for a particular task one year are reused for Relevance Feedback the next. In real world, time-synchronous tasks, we cannot wait for assessments before addressing the task: such assessments, if they are to be used, must be created while addressing the task. In this paper, we describe a hybrid human-computer system that addresses the problem of achieving high performance on IR tasks by systematically and replicably creating large numbers of document assessments.</p><p>The impact of large number of document assessments has been indirectly tested in previous TREC tasks, including those within the Legal Track <ref type="bibr" coords="1,175.24,618.25,13.49,7.86" target="#b18">[18]</ref>. In several cases, TREC tasks have been created to test the capabilities of Relevance Feedback systems. Testing such systems, however, imposes a fundamental challenge to the organizers of such a task: (non-pseudo) relevance feedback presumes the existence of feedback judgments by a user who is knowledgeable about the topic. Generating such assessments, however, is a po-tentially expensive proposition, and acquiring a sufficient quantity of assessments to test the asymptotic properties of the tested systems is even more so. A simple accommodation is therefore applied, wherein assessments produced for a topic during evaluation of the ad-hoc task in previous years are reused to stand in for actual relevance assessments within the RF task in subsequent years. Approaching the development of training data in this manner has the effect of easily affording the creation of large amounts of relevance data for the RF task.</p><p>The reuse of evaluation assessments in the RF task also enables us to perform a kind of gedankenexperiment to assess the effect of various sources of information in the IR task. In both the original ad-hoc task, conducted the first year, and the relevance feedback task, conducted in subsequent years, the topic is the same, allowing comparison of results. In some cases, results have improved substantially between the original run of the topic and subsequent runs. We must therefore examine what has changed between the two runs in order to afford improved results. It is possible that additional understanding of the topic by the experimenters enabled better system design, but the general focus on general designs suggests that this is not the case. It is also possible that new or improved algorithms became available in the intervening period and that these algorithms produced better results. That the RF results were produced using algorithms that have been known for some time, such as SVM, also suggests that algorithmic improvements are not responsible for the improvement. After eliminating other possibilities, it is clear that the obvious difference between the runs is also that most responsible for the exhibited improvements: namely the additional information available in the form of document assessments. The performance of information retrieval systems is therefore seen to be a function not only of the inherent properties of the system, such as the algorithms used, but also of the information available as input to the system. Indeed, the nature of the input information, including specifically the quality and quantity of such information is a critical determinant of performance. That additional information can bring improved results has been recognized within the evaluation community for some time, as expressed through the existence of evaluation tasks such as the Interactive <ref type="bibr" coords="1,524.19,705.73,14.32,7.86" target="#b10">[10]</ref> and HARD <ref type="bibr" coords="2,85.67,57.64,9.71,7.86" target="#b1">[1]</ref> tracks. Such evaluations have sought to bring additional information to the information retrieval task in a controlled manner, limiting both the degree and the manner of information transfer. To some extent, such limitations were driven by the need to pose a controlled experimental paradigm wherein observed improvements could be reasonably attributed to the effect of the additional information. Some of the limitations, must, however, be attributed to the difficulty of making available the resources necessary to perform information transfer experiments at large scale. The results of such experiments, while showing that additional information does indeed help, are limited by the fact that the nature and amount of information was limited by the experimental conditions.</p><p>For the first time, the Legal Interactive task admits the possibility of experimenting with large amounts of information as input to the IR task. As stated in the guidelines, the purpose of the interactive task is ". . . to enable the task to model more completely and accurately the conditions and objectives of e-discovery in the real world" <ref type="bibr" coords="2,199.23,266.86,11.41,7.86" target="#b3">[3]</ref>. One such property being modeled is that of the Lead Attorney as user: although document review is typically delegated to more junior attorneys or out-sourced, it is ultimately the Lead Attorney whose notion of relevance must be considered. Although the amount of time (10 hours) allocated within the Interactive Task for consultation with the Topic Authority (TA) is less than that typically experienced in document reviews of this magnitude, it is sufficient to explore more sophisticated approaches to interactive IR than have been explored in TREC in the past. In particular, because the interaction is not limited to a single exchange, iterative exploration of the topic becomes possible, as explained in our analysis, below.</p><p>At the same time that the Interactive Task guidelines provide for the possibility for incorporating larger amounts of input information into the Information Retrieval task, they also impose a much more stringent notion of relevance than has been required in the past. While relevance was in prior years based on the consensus of the reviewers, and therefore not completely defined until after the task had been completed, this year's Interative guidelines require that the TA come to a fairly complete understanding of what relevance means for a particular topic prior to providing guidance to the individual teams. Of course this ideal is not always met: the TA may change his or her mind regarding relevance, and cannot help but be influenced by discussions of relevance and exposure to particular documents. Interactive systems, therefore, must take into account not only the possibility that relevance is being defined external to a particular representation, but that the very notion of what is relevant may be changing over time. In exchange for this added complication, however, systems are provided with a single target of relevance, and are not limited by the amount of agreement that can be achieved by uninformed assessors.</p><p>The key questions to be answered are therefore these: How can we most effectively harness the knowledge that the user makes available to the system in order to improve performance? Given limitations on the user's time and attention, what is the best way to structure the conversation with the user so as to acquire the most information with the least effort? Given a certain amount of information, how best to go about the task of representing it in a way that is consumable by an automatic system? And finally, how can such a system deal with the real world exigencies posed by operating in such an environment, including a fallible user whose interpretation is subject to change? These are the questions with which this paper is concerned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SYSTEM OVERVIEW</head><p>Our system comprises one main agent, the proxy, and four separate, yet interconnected, processes: User Modeling, Assessment, Classification and Measurement. A diagram is shown in Figure <ref type="figure" coords="2,384.49,279.59,3.58,7.86">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Proxy</head><p>The proxy is an internal agent who co-constructs a theory of relevance with the user via User Modeling. The proxy provides guidance to document assessors and resolves intraand inter-assessor discrepancies to ensure that errors are resolved in favor of the proper interpretation of relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">User Modeling</head><p>User Modeling is the process by which the proxy co-determines a theory of relevance with the user (in this case the TA), iterating the process to increase the likelihood of relevance within the system's output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Assessment</head><p>The assessment process is designed to (i) generate a large amount of training data (ii) of the appropriate kind (iii) with minimal error. The assessment process consists of an initial assessment of all documents of interest and subsequent error correction procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Classification</head><p>Document-assessment pairs generated during assessment are used as training data for a supervised classification system. The classifier is trained over available assessments and the resulting model used to perform a binary classification of all documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Measurement</head><p>The performance of the classification system is regularly evaluated in order to test its efficacy. The classification system is run over all documents in the corpus. Following classification, a random sample is drawn and reviewed by document assessors. Data generated by the evaluation process are used to tune the system and may result in the proxy and user modifying the theory of relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">USER MODELING 3.1 Introduction</head><p>The effectiveness of an IR system is measured on how well it retrieves relevant text from a corpus. <ref type="foot" coords="3,212.34,66.33,3.65,5.24" target="#foot_0">1</ref> Relevance is a derived property that entails a user and an information need: a text is deemed relevant by a user if it satisfies that user's information need (cf. <ref type="bibr" coords="3,146.60,99.48,13.63,7.86" target="#b16">[16]</ref>). Thus, at some level of an IR system, there must exist a representation of a user and his information need (User Modeling). Moreover, User Modeling (UM) serves as a powerful source of input by providing a mechanism by which external knowledge can be formalized into the system via query development, vocabularies, etc. Indeed, this year's Interactive Task appears-in partpredicated on this aspect of IR by incorporating into its design a Topic Authority to serve as a knowledgeable yet "needful" user.</p><p>UM is understood as a two-fold endeavor: (i) constructing a definition of relevance and (ii) iteratively interacting with a user to increase the likelihood of relevance in the output.</p><p>We follow <ref type="bibr" coords="3,98.18,245.93,14.32,7.86" target="#b17">[17]</ref> in positing that mediated interaction, that is interaction of a user, a human intermediary and an IR system, is the most effective form of UM in IR. Within such a model, an intermediary is an "intelligent agent constructing, implementing and modifying user models in all their complexity with considerable feedback" <ref type="bibr" coords="3,209.05,298.24,15.68,7.86" target="#b17">[17]</ref>.<ref type="foot" coords="3,228.66,296.47,3.65,5.24" target="#foot_1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">UM as co-construction</head><p>There are two central tenets of our approach to UM: (i) a user is seeking to resolve an "anomalous state of knowledge" and (ii) the user is unable to precisely specify what information is needed to resolve the anomalous knowledge-state <ref type="bibr" coords="3,280.63,364.24,9.20,7.86" target="#b4">[4]</ref>. These tenets underlie our own endeavors as intermediaries: we are seeking to resolve an anomalous state of knowledge as it pertains to satisfying the user's information need and we are unable to precisely define what information will satisfy the user's information need. Moreover, we recognize that users and intermediaries have access to external knowledge sources (personal knowledge, reference guides, the target corpus, etc.) that can be leveraged to inform and refine the model. Thus, the act of UM is a co-construction of information needs and mutual knowledge<ref type="foot" coords="3,220.87,467.08,3.65,5.24" target="#foot_2">3</ref> in a shared representation.</p><p>We assume a model, based on <ref type="bibr" coords="3,177.98,500.23,9.71,7.86" target="#b6">[6]</ref> and depicted in Figure <ref type="figure" coords="3,285.69,500.23,3.58,7.86" target="#fig_1">2</ref>, in which the representation serves as the common ground through which external knowledge is shared, mediated, negotiated and synthesized. It is this aspect of our approach to UM that allows the intermediary to become a proxy for the user thereby permitting the proxy to arbitrate whether information is assessed as relevant or not relevant (which allowed H5 assessors-at the direction and guidance of the proxyto generate nearly 8000 assessments for training data; see §4 for further discussion). Alternative approaches to UM could require the user to make all 8000 assessments to serve as training data. However, the time constraints of TREC's Interactive Task make such an approach infeasible if not impossible.</p><p>For the Interactive Task, UM comprised four component areas: (i) use case, (ii) scope (iii) nuance and (iv) linguistic variability. The resultant representation is a description of subject matter, that, if found in a document, would make that document relevant (henceforth Subject Matter Model).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Use Case</head><p>Use case discussions allowed us to take into account the user's objectives: to produce to opposing counsel a set of documents deemed responsive to the Request for Production (RFP) [primary objective] and to mitigate the risk of being accused of under-producing (i.e. intentionally withholding responsive documents) or over-producing (i.e. intentionally delivering non-responsive documents) [secondary objective]. The decision to prioritize one risk over the other has far-reaching design decisions: under-production &gt; overproduction implies a narrow, more exclusive conception of relevance whereas under-production &lt; over-production implies a broad, more inclusive conception of relevance. During UM, we learned the user felt that the risk of underproduction accusations outweighed the risk of over-production accusations. Thus, when entering into scope, nuance and linguistic variability discussions, we tested where and how the user's risk-mitigation considerations might manifest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Scope</head><p>We define scope as the breadth of concepts considered relevant by the user. When engaging in scope discussions, we seek to define the boundaries of relevance for a given conceptual domain. For example, when engaging with the user for RFP 103 <ref type="foot" coords="4,89.13,55.87,3.65,5.24" target="#foot_3">4</ref> we sought to understand how the user interpreted retail marketing campaigns. We analyzed the phrase, creating questions that tested the scope of each word: types of retail outlets, the activities that constitute marketing, and the characteristics of a campaign. Based on these questions, we provided the user examples to assess, discussing the ramifications and logical extensions of her responses. We iterated the process until a shared definition was agreed to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Nuance</head><p>Nuance refers to the degree of specificity required to be relevant.</p><p>In the context of the TREC Interactive Task, discussions of nuance and specificity centered on the semantic relations hyponymy and hypernymy <ref type="foot" coords="4,200.16,195.31,3.65,5.24" target="#foot_4">5</ref> . For instance, it was agreed to that a hyponym of campaign, such as Marlboro Ranch (a name of a specific marketing campaign) should be considered, in and of itself, a marker of relevance, whereas the non-specific hypernym campaign should not be considered, in and of itself, a marker of relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Linguistic Variability</head><p>Linguistic variability is related to, but distinct from, nuance. We define linguistic variability as the variety of ways a concept can be expressed, whether lexically or syntactically. During UM, linguistic variability was discussed in the context of cigarette brands, activities that constitute retail marketing, advertising slogans, etc. Two approaches were evaluated: defining each concept as a closed set or defining each concept in terms of pertinent characteristics. It was determined that the user's use case (see §3.2.1) favored the latter over the former and thus, definition-by-characteristic was built into the representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Modification</head><p>Belkin <ref type="bibr" coords="4,82.66,423.66,9.71,7.86" target="#b4">[4]</ref> notes that "a change in one's state of knowledge, by virtue of having engaged with text, will be reflected in some change in the anomalous state of knowledge". Because our approach to UM assumes anomalous states of knowledge on the part of both the user and proxy, we built into the UM process a "check-in" procedure to occur during week 7 of the task: we supplied the user with 16 documents, each chosen to test whether the proxy's interpretation of relevance aligned with the user's for various aspects of the Subject Matter Model (SMM). Of the 16 documents, the user's assessment matched the proxy's for 14 of the 16 (one was resolved as H5-internal assessor error; the other discrepancy triggered a modification to the SMM).</p><p>In subsequent discussions concerning this discrepancy, two documents were discussed: dug65f00 and ccq45f00. The user suggested the documents differed only in degree of specificity as it pertained to the promotion of cigarette brands via media outlets. Guidance was provided to modify the SMM in order to allow for a broader interpretation of relevance for the portion of the SMM under review. We modified the SMM which necessitated a course correction for our system (see §6 for further discussion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DOCUMENT ASSESSMENT</head><p>The representation and quality of training data is a, if not the, primary determiner of the success of supervised learning <ref type="bibr" coords="4,316.81,134.93,13.49,7.86" target="#b13">[13]</ref>. The presence of much irrelevant or unreliable data can significantly reduce the ability of a learner to generalize or, at best, increase the amount of training data needed to generalize properly. <ref type="foot" coords="4,394.32,164.54,3.65,5.24" target="#foot_5">6</ref> In this section, we describe the process we used to generate training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Goals</head><p>The motivation for the process described here is to (i) generate a large amount of training data (ii) of the appropriate kind (iii) with minimal error. Assessed documents and associated annotations form the primary input to classification.</p><p>As descibed in the introduction, the amount of information contained in these artifacts is determinative of a high quality result.</p><p>It is generally accepted at this time that increased amounts of training data result in improved classification accuracy <ref type="bibr" coords="4,316.81,316.82,9.20,7.86">[9]</ref>. During participation in the task, we assessed over 8000 documents. While this represents a large number of assessments, it represents less than 1% of the population, and by itself cannot ensure proper representability of the topic. Additional mechanisms are therefore employed to actively determine likely sources of additional relevant documents with distinct language.</p><p>As is usual, we distinguish two sources of error: random error and systematic error. Random errors are the less serious of the two types of error, and the most easily handled by ordinary error checking mechanisms, such as doubleassessment. Random errors also have less serious conseqences for the classification task, and can be dealt with by increasing the number of assessments. <ref type="bibr" coords="4,468.00,463.27,11.86,7.86" target="#b2">[2]</ref> Systematic errors, on the other hand, pose a much more serious challenge, particularly for a task with a very well-defined target, such as the interactive task. If systematic error is allowed to infiltrate the assessments, the resulting system could become very highly targeted on a topic other than that co-defined with the user. Although simple consensus mechanisms cannot combat systematic error, we discuss additional properties of our error correction procedures that are deployed to minimize systematic error. Our approach to minimizing error is critically dependent on user modeling.</p><p>In order to ensure consistency between assessors, a fraction of assessed documents are independently assessed a second time by another assessor. The resulting assessments are compared, and disagreements are resolved. While this is a fairly standard operating procedure in linguistic annotation tasks, the additional constraints imposed by the inter-active task mean that non-standard mechanisms must be employed to address the disagreements. If the requirement of the assessment task were merely to ensure that consensus had been achieved among assessors, then it would suffice to resolve disagreements at the level of the assessors themselves, perhaps by majority vote, or by asking assessors to resolve their differences in order to come to an agreement. Such methods, however, while they are able to address random error such as might occur through an oversight on the part of an assessor who then might be persuaded to overturn his or her mistake, cannot ensure that systematic errors do not overwhelm the true intent of the topic. Bringing mismatches to the attention of the proxy, who was instrumental in the co-constuction of the theory of relevance, ensures that systematic errors are resolved in the favor of proper topic interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Assessment Guide</head><p>The work of assessors is informed by the theory of relevance that the proxy has co-determined with the user. In order to communicate this intent, and to give added guidance to assessors in specific cases, assessment guidelines are drawn up by the proxy and communicated to and among the assessors. It has been shown, by e.g. <ref type="bibr" coords="5,167.68,302.10,13.49,7.86" target="#b14">[14]</ref>, that annotator agreement can be enhanced by increasing amounts of detail in an annotation guide. The purpose of the assessment guide, then, is to provide detailed direction to assessors beyond that shared between the user and the proxy. To be sure, the guidance provided by the proxy is grounded in his or her understanding of the theory as shared with the user. The assessment guide, however, provides additional direction to the assessors on how to handle known and anticipated specific instances of the topic. The assessment guide is also maintained as a continuous record of decisions made about particular cases and the reasoning behind those decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Assessment Process</head><p>The assessment process we use is designed to address the above goals while providing a straightforward and efficient workflow. The process consists of an initial assessment performed on all documents of interest, and subsequent error correction steps, performed on samples of the population with specific characteristics. Although shown as unitary, the process actually takes place over time, and provides for evolution of interpretation as new exemplars are sought and identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Initial Assessment</head><p>Assessors review documents drawn randomly using internal sampling procedures. Documents are assessed for relevance (R) or non-relevance (NR).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Relevant Passage Identification</head><p>Following initial assessment, a portion of the documents that have been asssessed as R undergo a second round of assessment to identify relevant passages in the document. Relevant passages form one of the inputs of the classifier, where they serve to narrow the focus to highly relevant portions of potentially very long documents.</p><p>To extract relevant passages, assessors re-read R-assessed documents, and attempt to identify portions of the text that serve as indicators of relevance.</p><p>In addition to generating additional training information, passage extraction serves the secondary purpose of validating the initial assessment of relevant documents. Documents for which no relevant passage can be found are flagged for review by the proxy. Upon review, the proxy may either indicate the relevant passage, leaving the document as R, or overturn the R assessment in light of the lack of passage evidence, changing the document assessment to NR.</p><p>Although logically related to assessment, passage extraction is performed separately by an assessor other than the one who provided the initial assessment. This is done to ensure that passage extraction fulfills its function as a part of quality control, insofar as a portion of the relevant documents are assessed independently by more than one assessor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Cross Check</head><p>Like R documents, documents with an initial assessment of NR must be quality checked via an independent second assessment. However, unlike R documents, no relevant passages can be expected in NR documents, and there is little marginal benefit to entertaining a distinct process. Therefore, a portion of NR documents are re-reviewed by a second asssessor. Disagreements between the initial and second review are identified and flagged for review by the proxy. Upon review, the proxy may choose to leave the document as NR, or may overturn the initial assessment and make the document R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Other Quality Controls</head><p>In addition to the Relevant Passage Identification and Cross Check procedures described above, which have been explicitly designed for quality control, improperly assessed documents are sometimes detected in other parts of the system. Although these ad-hoc controls individually contribute to only a small degree, taken together they form a third branch of quality control.</p><p>Because assessors differ in their capabilities, level of expertise and knowledge of the topic, additional quality control measures are employed on a per-assessor basis. The proxy therefore randomly selects documents that have been reviewed by each assessor for spot-checking until the proxy is confident of the assessor's abilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">MEASUREMENT</head><p>Iterative approaches to information retrieval, such as relevance feedback, clearly offer benefits over a one-shot approach. Additional retrieval iterations provide the opportunity to uncover additional relevant documents or to refine judgments on previously identified documents, and can therefore potentially boost either Recall or Precision or both. However, in order to attain any advantage over a singleshot system, the iterative system must incorporate additional knowledge during the iteration process. Nevertheless, blindly incorporating additional information with no attention paid to the current state of the system or the likely effect of such knowledge, is a blunt instrument that neither offers insight into the progress of the retrieval process nor provides direction concerning those next steps which may be most effective.</p><p>The alternative paradigm, which we espouse, incorporates explicit measurement of the system at different stages of processing. While measurement entails a certain amount of effort, the benefits are great. Among the primary benefits of measurement is the insight it provides to establish the current state of the system and the degree to which it has attained desired outcomes. While the goal of systems in the TREC task is to establish the relative effectiveness of different approaches to Information Retrieval, in real-world applications, it is often possible to set minimum standards which will ensure that the information needs of the user are being met subject to other constraints. Measurement, therefore determines not only the current state of the system, but also determines how many iterations must be performed in order to achieve the desired outcome.</p><p>In addition to providing insight into an iterative process, measurement also informs decisions made during execution of the process and provides the direction that is necessary to make considered changes in the approach. Thus, for example, if precision is seen to be low, additional effort can be expended to more carefully refine training assessments to reduce errorful R assessments. If, on the other hand, recall is low, additional efforts can be expended to find and assess additional relevant documents. Beyond the ordinary decisions regularly taken during exercise of a task, measurement can also be brought to bear to deal with extraordinary circumstances, such as the topic reinterpretation discussed in §3.3 and §6.</p><p>An important component of measurement is yield, the estimated number of relevant documents in the population. Calculation of yield is essential to establish a target for the review process and to determine progress toward that target. Yield is calculated by drawing a random sample of the entire population and assessing it according to the current interpretation of relevance. As with all aspects of relevance, however, yield is dependent on a correct interpretation of relevance, which can and does change as user modeling progresses. Yield measurements, therefore, must be interpreted with the understanding that they may change in the future, and should be repeated as relevance changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CASE STUDY</head><p>We present in this section an example of User Modeling requiring modification to the co-determined theory of relevance and subsequent corrections made to the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Course correction</head><p>As mentioned in §3.3, designed into UM was a "check-in" procedure to occur during week 7 of the task. The checkin was implemented as a mechanism by which the proxy could evaluate interpretation discrepancies that might have arisen between the user and proxy, in recognition that interaction with external knowledge sources (such as the corpus) impacts knowledge states and thus might necessitate updating the co-defined theory of relevance (cf. <ref type="bibr" coords="6,243.29,648.43,9.51,7.86" target="#b7">[7]</ref>). During the check-in, such a discrepancy was discovered: the user presented an alternate interpretation of relevance concerning the degree of specificity required for a determination of relevance for discussions of cigarette brand promotions via media outlets. Prior to the check-in, a discussion of promoting a cigarette brand through a media outlet required a specific brand and specific media outlet be discussed for an assessment of relevant to be valid (e.g. A marketing budget indicating an advertisement for Lucky Strike being placed in Newsweek). Generality in either domain did not meet the definition of relevance (cf. For example, cug12d00 (Figure <ref type="figure" coords="6,447.89,193.53,4.10,7.86" target="#fig_2">3</ref>) contains a discussion of promoting KOOL cigarettes in various media outlets such as True Story, TV Guide, and Us. Because the document contains a discussion of promoting a specific brand via specific media outlets, the document was assessed as relevant.</p><p>The user's alternate interpretation allowed for non-specificity in one domain but not both (cf. Table <ref type="table" coords="6,497.93,266.76,3.58,7.86">2</ref>).</p><p>Specific Media Non-specific Media Specific Brand R R Non-specific Brand R NR</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2: Final Definition of Relevance -Promotions and Media</head><p>Based on this change in interpretation, the definition of relevance was modified (as was the SMM and attendant materials such as the Assessment Guide). ais35e00 (Figure <ref type="figure" coords="6,547.73,381.73,4.10,7.86">4</ref>) and cyo18e00 (Figure <ref type="figure" coords="6,411.86,392.19,4.10,7.86" target="#fig_3">5</ref>) are examples of previously NRassessed documents becoming R-assessed documents due to the change in interpretation.</p><p>ais35e00 contains a discussion of promoting a specific brand MARLBO (Marlboro) in a non-specific media outlet MAGAZIhC (magazine). On the initial interpretation, the specificity of the brand was not sufficient to overcome the generality of the media outlet to trigger an R assessment. On the revised interpretation, specificity of the brand was sufficient to trigger an assessment of R even with a general media outlet. The same held true for cyo18e00 in which running an advertisement for Marlboro (specific brand) in a newspaper (non-specific media outlet) was discussed.</p><p>The interpretation modification discussed resulted in an increase in overall yield since documents which contain discussions of placing promotional material of specific brands in non-specific media outlets like those found ais35e00 and cyo18e00, constitute a fair number of the documents changed from NR to R (for further discussion of yield, see §7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RESULTS</head><p>In the 2008 TREC Legal Track Interactive Task, we explored the application of the process described above on Topic 103. We iterated, nine times, the User Modeling process described in §3, accumulating 490 minutes of interaction with the user. The vast majority of that interaction (380 minutes; 77.55% of total time) occurred in weeks two through four in order to establish an initial definition of relevance prior to starting work on the topic. The remaining  The!agency is to submit a layout for a 12M shipping case that incorporates a backto-back replica of'the package on the face. A sample of the Marlboro soft-pack case will be sent to the agency Monday.  tion of this size. After initial uncertainty during early user modeling (weeks 1-2), yield settles on a downward trend, reaching a low of 9.2% in week 5, due to increasingly strict relevance definition. Following the check-in with the Topic Authority described in §6, however, relevance expanded, and this is reflected in the measurements with yield eventually rising to 10.5%.</p><p>Table <ref type="table" coords="8,343.57,374.97,4.61,7.86" target="#tab_3">3</ref> shows final, post-adjudicated results reported by TREC, as well as final internal estimates. Although the internal estimates are slightly higher than the final TREC results, the difference is well within the confidence interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>We have presented a novel approach to addressing the task of large-scale information retrieval in an interactive task where relevance is defined primarily by the judgments of a single individual. The triad of User Modeling, Document Assessment and Measurement combine to provide a shared understanding of relevance, a means for representing that understanding to an automated system, and a mechanism for iterating and correcting such a system so as to converge on a desired result.</p><p>The problem of how external notions of relevance are converted into a computerized representation is deserving of further research, with consequences not only for the Legal community but for all areas of human endeavor with massive, comprehensive Information Retrieval problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,365.32,131.49,142.11,7.89"><head></head><label></label><figDesc>Figure 1: System Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,316.81,262.94,239.13,7.89;3,316.81,273.40,239.07,7.89;3,316.81,283.86,31.79,7.89;3,340.90,54.62,190.91,193.36"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Representation of User Modeling. The portion within the dashed lines is internal to the system</figDesc><graphic coords="3,340.90,54.62,190.91,193.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,122.11,283.82,365.50,8.14"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: cug12d00: Initial Assessment (R) unchanged during course correction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,118.89,696.86,371.95,8.14"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: cyo18e00: Assessment changed from NR to R during course correction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,322.19,99.48,232.92,50.65"><head>Table 1</head><label>1</label><figDesc>).</figDesc><table coords="6,322.19,120.85,232.92,29.28"><row><cell></cell><cell cols="2">Specific Media Non-specific Media</cell></row><row><cell>Specific Brand</cell><cell>R</cell><cell>NR</cell></row><row><cell>Non-specific Brand</cell><cell>NR</cell><cell>NR</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,316.81,163.02,239.16,18.35"><head>Table 1 : Initial Definition of Relevance -Promotions and Media</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,53.80,335.27,437.04,308.26"><head>Figure 4: ais35e00: Assessment changed from NR to R during course correction</head><label></label><figDesc></figDesc><table coords="7,53.80,335.27,380.45,308.26"><row><cell>12/31/77 DATE 08/17/77</cell></row><row><cell>EST N,]: 7815</cell></row><row><cell>PRODUCT VARIOUS DESCRIPTION MARLBO</cell></row><row><cell>FOOT t3A RO CTHER PROMOTIONS</cell></row><row><cell>LL PAGE I</cell></row><row><cell>REPCRT PfN5o-1-1</cell></row><row><cell>ISSUE CLOSE ON CANCL BILL GROSS GROSS C/D TAX AD. PR</cell></row><row><cell>PRC-NFL ILLUSTRATED PR.OG SALE MNTH LESS C/D t R NUNBER IC</cell></row><row><cell>THIRC C-3VER 4/COLOR BLEED AUG 77 06/15 08/01 06/15 07 61,095.00 60,056.38 2.CC L</cell></row><row><cell>PCS/ED: 1577-78 SEASON</cell></row><row><cell>61,095.00 60,056.38 PUBLICATICK TCTAL</cell></row><row><cell>61,095.00 60,056.38 ESTIMATE TCTAl,</cell></row><row><cell>Run only one ad (newspaper)' during the week beginning JuIy 21, then</cell></row><row><cell>start general schedule the following week.</cell></row><row><cell>3~. The "B" market schedule will be spread out., andiw3.11 be tailored to</cell></row><row><cell>jibe with d'istribution, Mr. Early will get from Mr.,0!'Connor a</cell></row><row><cell>good'estimate of the,time lag between distribution in major cities</cell></row><row><cell>and! 'IBn markets.,</cell></row><row><cell>MTS CELLANDCIUS</cell></row><row><cell>Code numbers for shipping cartons wil7.' be:</cell></row><row><cell>Flush -080</cell></row><row><cell>Recess -083</cell></row><row><cell>C</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,72.60,121.81,283.82,356.32"><head>Table 3 : Final Results Figure 6: Time spent with Topic Authority</head><label>3</label><figDesc></figDesc><table coords="8,83.02,305.25,180.08,172.88"><row><cell></cell><cell></cell><cell cols="2">7992</cell><cell></cell></row><row><cell>Assessment</cell><cell></cell><cell>875 R</cell><cell>7117 NR</cell><cell></cell></row><row><cell>Annotation</cell><cell>766 R</cell><cell>109 NR</cell><cell></cell><cell></cell></row><row><cell>Cross Check</cell><cell></cell><cell></cell><cell>373 R</cell><cell>6744 NR</cell></row><row><cell>Subtotal</cell><cell></cell><cell>1139 R</cell><cell cols="2">6853 NR</cell></row><row><cell>Other QC</cell><cell>1137 R</cell><cell>2 NR</cell><cell>43 R</cell><cell>6810 NR</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,53.80,147.09,453.68,571.96"><head>Figure 7: Document Assessments 110</head><label></label><figDesc>minutes (22.45% of total time) was taken by the check-in in week seven, described in §6, above. User Modeling time is shown in Figure6).During our participation in the Interactive task, assessors viewed 7992 documents to provide training data for classification. Following the description in §4, Figure7provides a breakdown of the different assessment flows that documents took, breaking results out by number of relevant (R) and non-relevant (NR) documents. The end result was that 7992 documents were available for training: 1180 R, and 6812 NR for a training set yield of 14.76%.Over the running of the task, measurements were conducted at regular intervals, as described in §5. Yield measurements (estimated number of relevant documents) are shown in Table 4. Note that while relevance varied from a 9.2% to 10.7%, this reflects a substantial number of documents in a popula-</figDesc><table coords="8,365.23,147.09,142.25,102.51"><row><cell></cell><cell cols="2"># Relevant % Relevant</cell></row><row><cell>Week 2</cell><cell cols="2">693,693 10.03874</cell></row><row><cell>Week 3</cell><cell cols="2">744,515 10.77420</cell></row><row><cell>Week 4</cell><cell>666,828</cell><cell>9.64996</cell></row><row><cell>Week 5</cell><cell>636,587</cell><cell>9.21233</cell></row><row><cell>Week 6</cell><cell>673,329</cell><cell>9.74403</cell></row><row><cell>Week 7</cell><cell cols="2">720,810 10.43115</cell></row><row><cell>Week 8</cell><cell cols="2">729,099 10.55110</cell></row><row><cell>Week 9</cell><cell cols="2">729,099 10.55110</cell></row><row><cell>Final</cell><cell cols="2">787,762 11.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,352.51,262.49,167.74,7.89"><head>Table 4 : Estimated Yield over Time</head><label>4</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,58.40,609.83,234.47,7.86;3,53.80,618.80,239.06,7.86;3,53.80,627.76,194.41,7.86"><p>We follow<ref type="bibr" coords="3,102.84,609.83,9.71,7.86" target="#b5">[5]</ref> in using text to be an information-bearing object. Corpus is to be taken as any collection of texts, that is, any collection of information-bearing objects.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,58.40,638.10,234.48,7.86;3,53.80,647.06,239.08,7.86;3,53.80,656.03,239.08,7.86;3,53.80,664.99,239.09,7.86;3,53.80,673.96,239.08,7.86;3,53.80,682.93,239.07,7.86;3,53.80,691.89,132.60,7.86"><p>The relationship of the intermediary to the user and the IR system is one of systems boundaries. Buckland and Plaunt<ref type="bibr" coords="3,53.80,656.03,9.71,7.86" target="#b8">[8]</ref> write that "systems boundaries define what is considered the 'system' and what is considered the 'environment' ". On this definition, whether or not the intermediary is within the system is determined by how integrated the intermediary is into design of the overall system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,58.40,702.22,234.57,7.86;3,53.80,711.19,115.14,7.86"><p>For more on co-construction of knowledge and mutual understanding, see<ref type="bibr" coords="3,121.42,711.19,9.71,7.86" target="#b7">[7]</ref> and<ref type="bibr" coords="3,152.08,711.19,13.49,7.86" target="#b15">[15]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,58.40,638.10,234.49,7.86;4,53.80,647.06,239.13,7.86;4,53.80,656.03,203.96,7.86"><p>RFP 103-"All documents which describe, refer to, report on, or mention any "in-store", "on-counter", "point of sale", or other retail marketing campaign for cigarettes."</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,58.40,666.36,234.47,7.86;4,53.80,675.32,239.08,7.86;4,53.80,684.29,239.07,7.86;4,53.80,693.26,239.06,7.86;4,53.80,702.22,239.09,7.86;4,53.80,711.19,47.72,7.86"><p>Hyponymy is the semantic relation in which the extension of a word is subsumed in the extension of another word (e.g. dachshund is a hyponym of dog). Hypernymy is the semantic relation in which the extension of a word subsumes the extension of another word (e.g. dog is the hypernym of dachshund).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,321.42,657.39,234.48,7.86;4,316.81,666.36,239.13,7.86;4,316.81,675.32,239.03,7.86;4,316.81,684.29,239.07,7.86;4,316.81,693.26,239.05,7.86;4,316.81,702.22,239.10,7.86;4,316.81,711.19,84.52,7.86"><p>The problem of training data quality has also been investigated within the framework of computational learning theory, where it has been shown that while it is possible to learn in the presence of random noise<ref type="bibr" coords="4,468.53,684.29,13.49,7.86" target="#b11">[11]</ref>, learning is not in general possible with malicious errors<ref type="bibr" coords="4,470.94,693.26,13.49,7.86" target="#b12">[12]</ref>. In any case, the amount of training data required to learn in the presence of noise is increased<ref type="bibr" coords="4,389.07,711.19,9.20,7.86" target="#b2">[2]</ref>.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,321.29,613.09,96.81,10.53" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.59,625.51,195.80,7.86;8,335.61,635.97,212.77,7.86;8,335.61,646.43,111.07,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,373.28,625.51,158.12,7.86;8,335.61,635.97,136.97,7.86">Hard track overview in trec 2003: High accuracy retrieval from documents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,491.70,635.97,56.68,7.86;8,335.61,646.43,46.48,7.86">Proceedings of TREC 2003</title>
		<meeting>TREC 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.59,657.89,184.92,7.86;8,335.61,668.35,186.24,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,439.50,657.89,81.02,7.86;8,335.61,668.35,34.82,7.86">Learning from noisy examples</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Angluin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,377.85,668.35,70.80,7.86">Machine Learning</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="343" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,335.59,679.81,220.25,7.86;8,335.61,690.27,206.53,7.86;8,335.61,700.63,127.95,7.96;8,335.61,711.09,201.50,7.96" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,335.61,690.27,202.72,7.86">Trec-2008 legal track interactive task -guidelines</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hedin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tomlinson</surname></persName>
		</author>
		<ptr target="http://trec-legal.umiacs.umd.edu/2008InteractiveGuidelines.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,57.64,211.33,7.86;9,72.59,68.10,185.84,7.86;9,72.59,78.56,152.56,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,116.40,57.64,167.51,7.86;9,72.59,68.10,95.99,7.86">Anomolous states of knowledge as a basis for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,175.21,68.10,83.22,7.86;9,72.59,78.56,79.52,7.86">Canadian Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="133" to="143" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,90.02,196.16,7.86;9,72.59,100.48,177.88,7.86;9,72.59,110.94,212.75,7.86;9,72.59,121.40,215.70,7.86;9,72.59,131.86,120.14,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,126.75,90.02,141.99,7.86;9,72.59,100.48,162.25,7.86">Interaction with texts: Information retrieval as information-seeking behavior</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,72.59,110.94,212.75,7.86;9,72.59,121.40,44.00,7.86">Information Retrieval &apos;93: Von der Modellierung zur Anwendung</title>
		<meeting><address><addrLine>Konstanz</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-09">September 1993</date>
			<biblScope unit="page" from="55" to="66" />
		</imprint>
		<respStmt>
			<orgName>Universitaetsverlag Konstanz</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,143.32,217.57,7.86;9,72.59,153.78,214.50,7.86;9,72.59,164.24,184.16,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,256.88,143.32,33.27,7.86;9,72.59,153.78,210.55,7.86">ASK for information retrieval: Part I. background and theory</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Oddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,72.59,164.24,103.45,7.86">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="66" to="71" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,175.70,212.65,7.86;9,72.59,186.16,167.90,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,125.54,175.70,155.30,7.86">A Symbiotic Theory Formation System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="9,72.58,197.62,220.32,7.86;9,72.59,208.08,164.75,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,202.02,197.62,90.89,7.86;9,72.59,208.08,66.81,7.86">On the construction of selection systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Buckland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Plaunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,146.70,208.08,62.39,7.86">Library Hi Tech</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,219.53,212.77,7.86;9,72.59,229.99,212.22,7.86;9,72.59,240.46,215.84,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,207.87,219.53,77.48,7.86;9,72.59,229.99,212.22,7.86;9,72.59,240.46,28.89,7.86">Introduction to the special issue on computational linguistics using large corpora</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,108.67,240.46,104.35,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,251.91,220.25,7.86;9,72.59,262.37,168.42,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,168.16,251.91,120.76,7.86">Trec-8 interactive track report</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Over</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,84.09,262.37,91.36,7.86">Proceedings of TREC-8</title>
		<meeting>TREC-8</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,273.83,195.67,7.86;9,72.59,284.29,213.71,7.86;9,72.59,294.75,20.97,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,120.45,273.83,147.80,7.86;9,72.59,284.29,68.70,7.86">Efficient noise-tolerant learning from statistical queries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,148.19,284.29,77.91,7.86">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="983" to="1006" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,306.21,200.57,7.86;9,72.59,316.67,192.37,7.86;9,72.59,327.13,200.82,7.86;9,72.59,337.59,83.91,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,163.75,306.21,109.40,7.86;9,72.59,316.67,62.45,7.86">Learning in the presence of malicious errors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,153.29,316.67,111.67,7.86;9,72.59,327.13,196.47,7.86">Proceedings of the twentieth annual ACM symposium on Theory of computing</title>
		<meeting>the twentieth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="267" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,349.05,218.49,7.86;9,72.59,359.51,203.19,7.86;9,72.59,369.97,200.51,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,271.24,349.05,19.83,7.86;9,72.59,359.51,143.64,7.86">Data preprocessing for supervised leaning</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kotsiantis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kanellopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pintelas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,223.21,359.51,52.57,7.86;9,72.59,369.97,115.69,7.86">International Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="117" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,381.43,195.60,7.86;9,72.59,391.89,215.27,7.86;9,72.59,402.35,177.87,7.86;9,72.59,412.81,126.04,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,228.66,381.43,39.52,7.86;9,72.59,391.89,184.11,7.86">Enhanced annotation and parsing of the arabic treebank</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maamouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kulick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,275.40,391.89,12.46,7.86;9,72.59,402.35,177.87,7.86;9,72.59,412.81,44.96,7.86">6th International Conference on Computers and Informatics</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,424.27,192.92,7.86;9,72.59,434.73,216.68,7.86;9,72.59,445.19,216.30,7.86;9,72.59,455.65,205.04,7.86;9,72.59,466.11,62.75,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,186.43,424.27,79.08,7.86;9,72.59,434.73,201.37,7.86">The construction of shared knowledge in collaborative problem solving</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Roschelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Teasley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,155.72,445.19,133.17,7.86;9,72.59,455.65,30.79,7.86">Computer-supported collaborative learning</title>
		<editor>
			<persName><forename type="first">C</forename><surname>O'malley</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,477.57,204.51,7.86;9,72.59,488.03,186.44,7.86;9,72.59,498.49,220.07,7.86;9,72.59,508.95,197.51,7.86;9,72.59,519.41,219.00,7.86;9,72.59,529.87,20.97,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,128.07,477.57,149.02,7.86;9,72.59,488.03,186.44,7.86;9,72.59,498.49,220.07,7.86;9,72.59,508.95,45.73,7.86">Relevance: A review of the literature and a framework for thinking on the notion in information science. part ii: nature and manifestations of relevance</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Saracevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,125.29,508.95,144.81,7.86;9,72.59,519.41,144.22,7.86">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1915" to="1933" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,541.33,201.57,7.86;9,72.59,551.79,218.77,7.86;9,72.59,562.25,209.42,7.86;9,72.59,572.71,210.31,7.86;9,72.59,583.17,105.93,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,234.39,541.33,39.76,7.86;9,72.59,551.79,218.77,7.86;9,72.59,562.25,58.54,7.86">Users and intermediaries in information retrieval: What are they talking about?</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Saracevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Spink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,146.70,562.25,135.31,7.86;9,72.59,572.71,151.16,7.86">User modeling. Proceedings of the Sixth International Conference, UM97</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,594.63,179.53,7.86;9,72.59,605.09,210.67,7.86;9,72.59,615.55,146.22,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,131.82,605.09,147.60,7.86">Overview of the trec 2007 legal track</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,84.09,615.55,106.43,7.86">Proceedings of TREC 2007</title>
		<meeting>TREC 2007</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,72.58,627.01,182.61,7.86;9,72.59,637.47,211.32,7.86;9,72.59,647.93,74.77,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,72.59,637.47,136.15,7.86">Structured queries for legal search</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,227.23,637.47,56.68,7.86;9,72.59,647.93,45.68,7.86">Proceedings of TREC-2007</title>
		<meeting>TREC-2007</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
