<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,116.52,81.08,378.96,12.91">KLE at TREC 2008 Blog Track: Blog Post and Feed Retrieval</title>
				<funder ref="#_XUMUqkY">
					<orgName type="full">MKE &amp; IITA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,75.30,129.28,44.41,10.76"><forename type="first">Yeha</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Electrical and Computer Engineering Pohang</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>San 31, Hyoja-Dong, Nam-Gu</addrLine>
									<postCode>790-784</postCode>
									<settlement>Pohang</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,128.09,129.28,77.83,10.76"><forename type="first">Seung-Hoon</forename><surname>Na</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Electrical and Computer Engineering Pohang</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>San 31, Hyoja-Dong, Nam-Gu</addrLine>
									<postCode>790-784</postCode>
									<settlement>Pohang</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.78,129.28,50.56,10.76"><forename type="first">Jungi</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Electrical and Computer Engineering Pohang</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>San 31, Hyoja-Dong, Nam-Gu</addrLine>
									<postCode>790-784</postCode>
									<settlement>Pohang</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.72,129.28,80.49,10.76"><forename type="first">Sang-Hyob</forename><surname>Nam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Electrical and Computer Engineering Pohang</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>San 31, Hyoja-Dong, Nam-Gu</addrLine>
									<postCode>790-784</postCode>
									<settlement>Pohang</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.09,129.28,82.95,10.76"><forename type="first">Hun-Young</forename><surname>Jung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Electrical and Computer Engineering Pohang</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>San 31, Hyoja-Dong, Nam-Gu</addrLine>
									<postCode>790-784</postCode>
									<settlement>Pohang</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,456.63,129.28,83.05,10.76"><forename type="first">Jong-Hyeok</forename><surname>Lee</surname></persName>
							<email>jhlee@postech.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Division of Electrical and Computer Engineering Pohang</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>San 31, Hyoja-Dong, Nam-Gu</addrLine>
									<postCode>790-784</postCode>
									<settlement>Pohang</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,116.52,81.08,378.96,12.91">KLE at TREC 2008 Blog Track: Blog Post and Feed Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">38533391C4860092A6E2ADB1C597558B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the TREC 2008 Blog Track. For the opinion task, we made an opinion retrieval model that consists of preprocessing, topic retrieval, opinion finding, and sentiment classification parts. For topic retrieval, our system is based on the passage-based retrieval model and feedback. For the opinion analysis, we created a pseudo opinionated word (POW), O, which is representative of all opinion words, and expanded the original query with O.</p><p>For the blog distillation task, we integrated the average score of all posts within a feed, and the average score of the most relevant N post scores. We also examined the pseudorelevance feedback for the distillation task by focusing on various document selection schemes to expand the query terms. The experimental results show a significant improvement over previous results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Blog track explores information seeking behavior in the blogosphere. Blog track was first introduced in TREC 2006. In TREC 2008, the Blog track has two main tasks: the opinion finding task and the blog distillation task.</p><p>Our approach to the opinion finding task is a three-step process. The first is preprocessing step. HTML tags and non-relevant contents provided by blog providers such as site description and menus are removed. In the topic retrieval step, we select the top 3, 000 documents ordered by topic-relevance. Our topic retrieval system, based on the passagelevel retrieval model, estimates the relevance between a document and a given topic. To find documents which express an opinion about a given topic, we first estimate the degree of how opinionated a document is. Finally, we interpolate the topically relevant score and the opinion score of a document, and select the top 1, 000 documents as documents that express an opinion about a given topic. Our opinion analysis system is based on the lexiconbased approach. For opinion analysis, we created a pseudo opinionated word (POW), O, which is representative of all opinion words, and expand the original query with O.</p><p>Blog distillation is similar to the resource selection problem in distributed information retrieval. We formed two hypotheses to evaluate the degree of relevance between a blog feed and a given topic, and made two models to support these hypotheses. Furthermore, we propose a novel approach to select feedback documents for the pseudo relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preprocessing</head><p>TREC Blog06 collection contains permalinks, feed files and blog homepages. We only used the permalink pages for the opinion retrieval task and the feed distillation task. The permalinks are encoded by HTML, and there are many different styles of permalinks. Beside the relevant textual parts, the permalinks contain many non-topical or nonrelevant content such as HTML tags, advertisements, site descriptions, and menus, as well as topical contents.</p><p>The non-relevant content consist of many different types of blog templates which may be provided from commercial blog service venders to personal users. We propose a simple and effective algorithm, DiffPost, to deal with the non-relevant content. Much of the non-relevant content does not change in the same blog feed over a long period of time. DiffPost assumes that unchanged content between blog posts within the same blog feed are non-relevant (non-topical) content, and regards only changed content as relevant (topical) content.</p><p>To preprocess corpus, we firstly discarded all HTML tags, and applied DiffPost algorithm to remove non-relevant content. DiffPost segments each document into lines using the carriage return as a separator. DiffPost tries to compare sets of lines, and then regards the intersection of sets as the noncontent information.</p><p>For example, let P i and P j be blog posts within the same blog feed. Let S i and S j be the sets of lines correspond to P i and P j , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N oisyInf ormation(P</head><formula xml:id="formula_0" coords="2,192.21,373.91,106.59,10.63">i , P j ) = S i ∩ S j (1)</formula><p>We discard non-relevant contents through the set difference between a document and noisyinformation. Finally, we removed stopwords from the content results of the DiffPost algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Topic Retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Passage Based Ranking</head><p>Generally, a blog post consists of several topics, rather than presenting a single topic. Thus, even if a blog post is relevant, it does not mean that all parts of the blog post are relevant. Instead, only some parts of the blog post will be relevant to a query. Therefore, we extract some part or snippet of the blog post known to be relevant to the query, and use it as evidence for the topic retrieval.</p><p>To this end, we adopted the passage-based language model for the topic retrieval task. One of the most important issues in passage retrieval is the definition of the passage. We used a completelyarbitrary passage <ref type="bibr" coords="2,148.93,671.32,74.05,9.82">(Na et al., 2008c)</ref>.</p><p>We used the score of the best passage, which indicates the passage that maximizes its relevance to a query, as the passage-level evidence. Our ranking function is as follows:</p><formula xml:id="formula_1" coords="2,327.37,100.81,212.63,17.07">Score P (Q, D) = max P ∈SP (D) Score(Q, P )<label>(2)</label></formula><p>In Eq. 2, Q is a given query, Score P (Q, D) indicates the passage-level evidence of a document D. SP (D) is the pre-defined set of all possible passages. We can use the interpolation of the documentlevel evidence, Score D (Q, D), and the passagelevel evidence as follows:</p><formula xml:id="formula_2" coords="2,311.38,225.40,238.79,10.69">Score(Q,D) = (1-α)Score D (Q,D)+αScore P (Q,D) (3)</formula><p>where α is the interpolation parameter, controlling the impact of the passage-level evidence on the final similarity score.</p><p>Each score is calculated based on the language modeling approach. The relevance scores of document, D, and passage, P , are defined as loglikelihood of query of the document, D, and the passage, P , respectively. For the document language model, we used the modified Dirichlet prior smoothing, DirV <ref type="bibr" coords="2,400.19,372.91,82.18,9.82">(Na et al., 2008a)</ref>, which improves the precision and handles the low performance of retrieval for verbose type of queries at the same time. Due to its high precision, DirV allow us to obtain a more improved performance after the pseudo-relevance feedback. For the passage language model, we used the Jelinek-Mercer smoothing <ref type="bibr" coords="2,329.86,467.75,108.53,9.82" target="#b9">(Zhai and Lafferty, 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pseudo Relevance Feedback</head><p>Traditional pseudo-relevance feedback is documentlevel feedback which assumes that the entire content of a feedback document is relevant to a query <ref type="bibr" coords="2,516.37,536.15,23.63,9.82;2,313.20,549.70,85.89,9.82" target="#b2">(Zhai and Lafferty, 2001)</ref>. However, normal blog posts are topically diverse so that they may contain nonrelevant parts as well as relevant parts about a given topic. To remedy this problem, we adopted the completely arbitrary passage-level feedback <ref type="bibr" coords="2,494.34,603.89,45.65,9.82;2,313.20,617.44,28.83,9.82">(Na et al., 2008b)</ref>.</p><p>In a completely arbitrary passage-level feedback, for top N documents, the best passages are extended by enlarging their context by maximally L length in the forward and backward directions. We use them as feedback context instead of top N documents, and update the query model based on the model-based feedback <ref type="bibr" coords="2,355.29,712.55,108.53,9.82" target="#b2">(Zhai and Lafferty, 2001)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Topic Retrieval Runs</head><p>In the baseline adhoc retrieval task, we submitted 5 runs, as follows: The results of our Baseline Adhoc Retrieval Task are shown in table <ref type="table" coords="3,154.12,571.37,4.09,9.82" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Opinion Finding</head><p>In this step, we evaluate the degree of how opinionated a blog post is about a given topic. In the previous step, the top 3, 000 documents are returned according to the degree of topical relevance. We evaluate their opinion scores, and interpolate their opinion scores and topically relevant scores. And then, we select the top 1, 000 documents as results of the opinion finding task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Opinion Scoring</head><p>For the opinion scoring module, most previous approaches can be divided into two types, classification-based approach and lexicon-based approach <ref type="bibr" coords="3,346.24,133.74,84.11,9.82">(Ounis et al., 2006;</ref><ref type="bibr" coords="3,433.16,133.74,102.14,9.82" target="#b3">Macdonald et al., 2007)</ref>. Our approach is based on the lexical-based approach.</p><p>To determine the opinionatedness of a blog post, we create a pseudo opinionated word (P OW ), O, which is a representative of all opinionated words, and make a new query, POW-annotated query, Q ′ , by adding O to the original query. For the opinion finding task, we calculate the relevant score between a document and a POW-annotated query, Q ′ , as follows:</p><formula xml:id="formula_3" coords="3,313.48,289.99,226.52,14.73">Score(Q ′ ,D) = (1-α)S rel (Q ′ ,D) + αS op (Q ′ , D) (4)</formula><p>where α is the interpolation parameter.</p><formula xml:id="formula_4" coords="3,489.98,315.20,50.02,14.04">S op (Q ′ , D)</formula><p>and S rel (Q ′ , D) are an opinion score and a topically relevant score of a document, respectively. A topically relevant score of a document does not have any relation with opinionated words. Therefore, we can rewrite Eq. 4 as follows:</p><formula xml:id="formula_5" coords="3,315.07,407.12,224.93,14.72">Score(Q ′ ,D) = (1-α)S rel (Q,D) + αS op (Q ′ , D) (5)</formula><p>where S rel (Q, D) is a topically relevant score obtained from the previous step, Section 3.</p><p>To estimate the opinion score of a document, S op (Q ′ , D), it is a simple and effective approach to add up the opinion scores of all words within a document. Because POW represents all opinionated words, S op (Q ′ , D) is calculated as follows:</p><formula xml:id="formula_6" coords="3,333.37,533.34,206.63,57.97">S op (Q ′ , D) = ∑ w P (Sub|w)tf (w; D) = ∑ w∈O P (Sub|w)tf (w; D) (6)</formula><p>where P (Sub|w) represents the subjectivity of a word, w, that is, an opinion score of a word. However, there are some problems with Eq. 6. Each blog post has a different number of words. A long blog post has more chance to contain opinionated words than a short blog post. Therefore, blog posts should be normalized according to their length. There are many studies about document length normalization in IR communities. We use the Okapi framework as the method of document length normalization. When using the Okapi model, S op (Q ′ , D) of Eq. 6 is re-written as follows:</p><formula xml:id="formula_7" coords="4,73.15,126.72,225.65,30.50">S op (Q ′ ,D) ∝ tf (O; D) tf (O; D)+k 1 { (1-b)+b LEN (D) avgLEN } (7)</formula><p>where LEN (D) is the length function of the blog post, and avgLEN indicates the average length function value of all posts. We used unique term count of a post as the length function, and estimated the term frequency of Eq. 7, tf (O; D), using Eq. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constructing the Opinion Lexicon</head><p>In the lexicon-based approach, one of the most important problems is to define the subjectivity of a word. We use different types of lexicons for defining the subjectivity of a word -SentiWordNet, automatically learned model from the review corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">SentiWordNet</head><p>SentiWordNet <ref type="bibr" coords="4,149.44,359.66,123.35,9.82" target="#b1">(Esuli and Sebastiani, 2006</ref>) is a lexical resource for opinion mining. SentiWordNet assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity. We use the maximum value of the positive scores and the negative scores for all senses of a word as the degree of subjectivity of a word. Let synset(w) be the set of synsets of a word, w. P (Sub|w) = max s∈synset(w) (max(P (pos|s), P (neg|s)))</p><p>where P (pos|s) and P (neg|s) represent the positive and negative score of the synset of the word, respectively.</p><p>That is, P (Sub|w) means the subjectivity of w when w is maximally opinionated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Corpus-Based Lexicon</head><p>In addition to SentiWordNet, we use Amazon's product review corpus and product specification corpus to create the opinionated lexical resource. Users of Amazon represent their opinion about products through reviews and product ratings. Therefore, the reviews contain opinionated words which the users use to express their opinion. The product specification is an objective document that consists of objective information such as product name, properties of the product, and product manual. We regard the review corpus as a subjective corpus, and the product specification corpus as an objective corpus. Then, we set the generative model of a word by two mixture models, P (w|Sub), P (w|Obj).</p><p>Let R = w 1 , • • • , w n be a large review document, which concatenates all reviews in the review corpus. The generative process of R is defined by the mixture:</p><formula xml:id="formula_8" coords="4,326.67,211.56,213.33,45.01">P (w) = λP (w|Sub)+(1-λ)P (w|Obj)(8) logP (R) = n ∑ i=1 logP (w)<label>(9)</label></formula><p>To maximize the log-likelihood, we iteratively update P (w|Sub) by applying the EM algorithm. After updating through iterations, we can obtain the probability that a word is generated from the subjective model, P (w|Sub). We also obtain the subjectivity of a word, P (Sub|w), using the Bayesian rule.</p><p>Finally, to combine the subjectivities defined in SentiWordNet and learned from the corpus, we use the term-specific mixture model where the prior probability of term w for opinion class is assumed to be P (Sub|w) of SentiWordNet. In other words, a generative model for word w in a review is modeled by P (w) = λ w P (w|Sub) + (1 -λ w )P (w|Obj) <ref type="bibr" coords="4,521.83,474.12,18.17,9.82">(10)</ref> where λ w is P (Sub|w) of SentiWordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Query-Specific Opinion Lexicon</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Feedback-Style Learning</head><p>In this section, we address the query-specific opinion lexicon. There are differences in the words used to express user's opinion, according to each query (domain). Therefore, we should deal with opinionated lexicon according to query. To this end, we propose a feedback-style learning method to make a query-specific opinionated lexicon.</p><p>Let T opN be the set of top-retrieved documents in response to a given query. For each document, we assign document-level subjectivity, P (Sub|D), from the initial lexicon model. Then, the new model of the opinion lexicon, P ′ (Sub|w), is estimated from the initial model of the opinion lexicon and the document-level subjectivities as follows:</p><formula xml:id="formula_9" coords="5,82.50,103.30,216.30,31.07">P ′ (Sub|w) = ∑ D∈T opN P (Sub|D)P (D|w) (11)</formula><p>where P (D|w) indicates how dominated a word w in document D is. Let T opN (w) be the subset of feedback documents which contain w. We assume that P (D|w) is uniformly distributed on T opN (w).</p><p>To estimate P (Sub|D), we introduce the following simple expectation of the subjectivity for each opinionated word w in document D:</p><formula xml:id="formula_10" coords="5,90.96,240.81,207.84,63.04">E w (Sub|D) = ∑ w∈D P (Sub|w) |D| (12) P (Sub|D) ≈ E w (Sub|D) max D∈T opN E w (Sub|D)<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Using Passage Context</head><p>As mentioned above, a blog post consists of several topics rather than presenting a single topic. Therefore, we propose passage-level learning for query-specific lexicon, instead of the whole document. We firstly extract a best passage using complete-arbitrary passage, and expand its context by maximally L length in the forward and backward directions. After extracting the extended passage, we calculate P (Sub|D) and P (D|w) for Eq. 11 based on the passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Opinion Finding Runs</head><p>In the opinion finding task, we submitted 4 runs, as follows:</p><p>1. KLEDocOpinT uses corpus-based lexicon for opinionated lexicon resource, with the title field of a topic 2. KLEDocOpinTD is KLEDocOpinT, with the title and the description fields of a topic 3. KLEPsgOpinT uses query-specific opinion lexicon for opinionated lexicon resource, with the title field of a topic 4. KLEPsgOpinTD is KLEPsgOpinT, with the title and the description fields of a topic</p><p>Table <ref type="table" coords="5,109.91,699.00,5.45,9.82" target="#tab_1">2</ref> shows our results of the Opinion Finding Task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Polarity Classification</head><p>The polarity task is similar to the opinion finding task. The difference is that the polarity task classifies the semantic orientation of a blog post into positive and negative orientations. Therefore, the approaches which are applied to the opinion finding task are almost applied to the polarity task, too. In the polarity task, we have to estimate the semantic orientations (polarities) of a word, P (P os|w) and P (N eg|w), instead of the subjectivity of a word, P (Sub|w). After estimating the semantic orientations of a word, we again applied Eq. 7 to calculate positive and negative scores of blog posts by using P (P os|w) and P (N eg|w), respectively.</p><formula xml:id="formula_11" coords="5,313.20,481.81,231.69,47.02">pol(D) =      positive if S polarity (D) &gt; λ negative if S polarity (D) &lt; -λ neutral otherwise (14)</formula><p>where S polarity (D) is the difference between positive and negative scores, and λ is the threshold for classifying the polarity.</p><p>Similar to the opinion finding task, we use the Amazon review corpus to estimate the semantic orientations of words. All reviews have user ratings, and thus user ratings are used to decide the semantic orientations of the reviews. That is, we regard the reviews whose user rating is 4 and 5 as the positive review corpus, and the reviews whose user rating is 1 and 2 as the negative. We estimate P (P os|w) and P (N eg|w) using the EM training with each review corpus.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Polarity Runs</head><p>We submitted 1 run in the polarity task, as follows:</p><p>1. KLEPolarity uses corpus-based lexicon for polarity-tagged lexicon resource, with the title field of a topic.</p><p>Table <ref type="table" coords="6,109.59,274.85,5.45,9.82" target="#tab_2">3</ref> shows the results of the Polarity Task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Feed Distillation</head><p>Blog distillation task aims to find the blog feeds which are recurrently interested in a given topic. Thus, in the blog distillation system, the retrieval unit is the blog feed rather than the blog post. We form two hypotheses to estimate the degree of relevance between a blog feed and a given topic.</p><p>• Global Evidence Model (GEM) : We believe that a blog feed which has more relevant posts at a higher rate is more relevant. For example, a blog feed that has 10 relevant posts out of total 20 posts is more relevant than a blog feed that has 10 relevant posts out of total 100 posts.</p><p>• Local Evidence Model (LEM) : We believe that a few posts that are highly relevant with a given topic represent the blog feed. Typically a blog feed addresses several topics. Therefore, the relevance of the blog feed about a given topic depends on some posts related to a given topic, rather than all posts within the blog feed.</p><p>To estimate the degree of the relevance between a blog feed and a given topic, we made two models to satisfy these hypotheses. Furthermore, to update the original query model, we proposed a novel approach to select feedback documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Distillation Retrieval Model</head><p>To find blog feeds devoted to a given topic, we integrate two models, Global Evidence Model (GEM) and Local Evidence Model (LEM). Let S(Q, F ) be the final relevant score between a feed and a given query, and let S GEM (Q, F ) and S LEM (Q, F ) be relevant scores obtained from GEM and LEM, respectively.</p><formula xml:id="formula_12" coords="6,321.54,151.73,218.46,10.69">S(Q,F) = (1-λ)S GEM (Q,F)+λS LEM (Q,F) (15)</formula><p>where λ is the interpolation parameter, which controls the weight of the GEM score and the LEM score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Global Evidence Model</head><p>GEM is originated from the assumption that the blog feed which has relevant posts at higher rates is more relevant.</p><p>GEM views a blog feed as a collection of blog posts. In this regard, we can view the blog distillation problem as a resource selection problem. Our GEM is similar to the Small Document Model <ref type="bibr" coords="6,523.03,318.66,12.72,9.82;6,313.20,332.20,69.27,9.82" target="#b0">(Elsas et al., 2008)</ref>. When regarding a blog feed as a collection of blog posts, there are some considerations. One is the problem when a small number of very long posts represent the blog feed. Each post has a different length. Therefore, a few very long posts may represent the blog feed. The other is the problem related to the size of the blog feed. Each blog feed has a different number of posts. Therefore, feeds with more posts have a higher probability of being relevant. To remedy this problem, we should normalize the blog feeds using the number of posts within them.</p><p>To handle these problems, we made a scoring function for GEM using the average score of all documents in a blog feed:</p><formula xml:id="formula_13" coords="6,321.28,534.20,218.72,31.07">S GEM (Q, F ) = ∑ D∈F Score(Q, D)P (D|F ) (16)</formula><p>where F represents the blog feed, and Score(Q, D) represents relevant score of between a given query and a document, and P (D|F ) indicates the probability that the document, D, is generated from the blog feed, F . In GEM, the usage of the average score resolves the second problem.</p><p>To remedy the first problem, we regard the generative probability of the blog post, P (D|F ), as the uniform distribution.</p><formula xml:id="formula_14" coords="6,391.89,700.44,148.11,25.04">P (D|F ) = 1 |F | (17)</formula><p>where |F | is the number of total blog posts within a blog feed. The usage of the uniform distribution can remedy the first problem since it assigns the same weight to each blog post. We used the KL-divergence framework <ref type="bibr" coords="7,259.70,129.71,39.11,9.82;7,72.00,143.26,69.50,9.82" target="#b2">(Lafferty and Zhai, 2001)</ref> to measure the relevance between a document and a given query, Score(Q, D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Local Evidence Model</head><p>LEM is originated from the belief that a few highly relevant posts represent the relevance of the blog feed about a given topic.</p><p>LEM uses the top N most relevant posts to estimate the relevance between a feed and a given topic. The view of the LEM is similar to Pseudo Cluster Selection <ref type="bibr" coords="7,115.11,275.06,92.57,9.82" target="#b7">(Seo and Croft, 2008)</ref>. That is, a blog feed addresses several topics. Therefore, the relevance of the blog feed about a given topic should be estimated by using the relevant posts about a given topic, not all posts within the blog feed. In this regard, we can regard top N relevant posts as posts which are devoted about a given topic.</p><p>The ranking function of LEM is formed as follows:</p><formula xml:id="formula_15" coords="7,78.87,398.27,219.93,31.07">S LEM (Q,F) = ∑ D∈T opN Score(Q, D)P(D|T opN) (18)</formula><p>where T opN is the set of top N relevant posts that are regarded as the same topic.</p><p>In Eq. 18, Score(Q, D) and p(D|T opN ) are the same as in Eq. 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Feedback Model</head><p>Relevance feedback is known to be effective for improving retrieval performance. Performance of the relevance feedback depends on how documents for relevance feedback are chosen so that the system can learn most from the feedback information <ref type="bibr" coords="7,255.14,577.06,43.66,9.82;7,72.00,590.61,49.30,9.82" target="#b8">(Shen and Zhai, 2005)</ref>. The traditional pseudo relevance feedback (PRF) assumes top N documents as relevant documents, and uses them as feedback documents. In this approach, the feedback information can be under a bias toward dominant information within the feedback documents. The biased information will be harmful for improving entire system performance through PRF. As the diversity of the feedback information increases, we can expect a more robust feedback search. To obtain diverse information about a given topic, we propose a feed-based approach to select feedback documents. We empirically show that our approach improves the performance of the blog distillation task. We used the model-based feedback as feedback method.</p><p>Each blog feed consists of many posts which have various viewpoints and represent various properties (sub-topics) about a given topic. Therefore, when we select feedback documents from various feeds, we can obtain diverse information about a given topic.</p><p>We propose two approaches for selecting feedback documents, as follows:</p><p>• Document-Based Selection uses top K documents as feedback documents as most PRFs do.</p><p>• Feed-Based Selection uses top N feeds to feedback. For each feed, top K documents are selected as the pseudo relevance documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Distillation Runs</head><p>In the distillation task, we submitted 4 runs, as follows:</p><p>1. KLEDistLMT uses GEM and LEM, with the title field of a topic 2. KLEDistLMB is KLEDistLMT, with the title and the description fields of a topic 3. KLEDistFBT uses GEM, LEM and Feed-Based selection method to feedback, with the title field of a topic 4. KLEDistFBB is KLEDistFBB, with the title and the description fields of a topic Table <ref type="table" coords="7,351.19,699.00,5.45,9.82" target="#tab_3">4</ref> shows the results of the Blog Distillation Task.</p><p>We have described our participation in the TREC 2008 Blog track. We developed an opinion finding system based on the lexicon-based approach and Okapi model. Our opinion finding system uses Sen-tiWordNet and Amazon's review corpus to create an opinionated lexicon resource. We also proposed a novel approach to make a query (domain)-specific opinionated lexicon resource. The experimental results show that our approach significantly improves previous performances in the opinion finding task.</p><p>For the blog distillation task, we made two assumptions about relevance between a blog feed and a given topic. The experimental results have empirically shown that our hypotheses is effective at capturing the relevance between the topic and the blog feeds. Furthermore, we developed a novel approach to select feedback documents. This approach increased the diversity of the feedback documents, and led to significantly improve the distillation performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,80.66,344.81,218.13,9.82;3,93.82,358.36,107.56,9.82;3,80.66,381.99,218.14,9.82;3,93.82,395.54,161.79,9.82;3,80.66,419.18,218.13,9.82;3,93.82,432.73,204.98,9.82;3,93.82,446.27,37.87,9.82;3,80.66,469.91,218.14,9.82;3,93.82,483.46,204.98,9.82;3,93.82,497.01,49.68,9.82;3,80.66,520.64,218.13,9.82;3,93.82,534.19,175.43,9.82"><head>1.</head><label></label><figDesc>KLEPsgRetT uses passage based ranking with the title field of the topic 2. KLEPsgRetTD is KLEPsgRetT, with the title and the description fields of the topic 3. KLEPsgRetTDN is KLEPsgRetT, with the title, the description and the narrative fields of the topic 4. KLEPsgFeedT uses passage based ranking and passage based feedback with the title field of the topic 5. KLEPsgFeedTD is KLEPsgFeedT, with the title and the description fields of the topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,72.00,81.96,226.82,181.56"><head>Table 1 :</head><label>1</label><figDesc>The topic and opinion retrieval scores (topic/opinion) for the Baseline Adhoc Retrieval Task runs</figDesc><table coords="3,79.71,116.21,208.65,147.31"><row><cell></cell><cell>run id</cell><cell>MAP</cell><cell>p@10</cell></row><row><cell>1</cell><cell cols="3">08 Overall 0.4304/0.3252 0.6773/0.5000 0.4483/0.3671 0.6720/0.5560</cell></row><row><cell>2</cell><cell cols="3">08 Overall 0.4567/0.3418 0.7640/0.5340 0.4532/0.3684 0.7180/0.5860</cell></row><row><cell>3</cell><cell cols="3">08 Overall 0.4330/0.3250 0.7573/0.5527 0.4297/0.3484 0.7200/0.6060</cell></row><row><cell>4</cell><cell cols="3">08 Overall 0.4696/0.3485 0.7560/0.5487 0.4954/0.4052 0.7920/0.6440</cell></row><row><cell>5</cell><cell cols="3">08 Overall 0.4776/0.3543 0.7867/0.5580 0.4724/0.3822 0.7440/0.6160</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,313.20,81.96,226.81,182.80"><head>Table 2 :</head><label>2</label><figDesc>The topic and opinion retrieval scores (topic/opinion) for the Opinion Finding Task runs</figDesc><table coords="5,313.20,106.30,216.36,158.45"><row><cell></cell><cell>run id</cell><cell>MAP</cell><cell>p@10</cell></row><row><cell>1</cell><cell cols="3">08 Overall 0.4937/0.4061 0.7767/0.6287 0.5190/0.4569 0.8020/0.7200</cell></row><row><cell>2</cell><cell cols="3">08 Overall 0.4896/0.3937 0.8093/0.6273 0.4809/0.4160 0.7680/0.6740</cell></row><row><cell>3</cell><cell cols="3">08 Overall 0.4855/0.4024 0.7767/0.6200 0.5190/0.4515 0.8240/0.7100</cell></row><row><cell>4</cell><cell cols="3">08 Overall 0.4896/0.3984 0.8307/0.6467 0.4951/0.4219 0.7860/0.6640</cell></row><row><cell cols="2">5 Polarity Task</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,93.35,152.29,184.12,8.97"><head>Table 3 :</head><label>3</label><figDesc>The performance of the Polarity Task</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,316.97,81.96,219.27,77.99"><head>Table 4 :</head><label>4</label><figDesc>The performance of the Blog Distillation Task</figDesc><table coords="7,329.83,94.34,190.81,65.61"><row><cell>run id</cell><cell>MAP p@10 R-prec</cell></row><row><cell cols="2">KLEDistLMT 0.3015 0.4480 0.3601</cell></row><row><cell cols="2">KLEDistLMB 0.2852 0.4380 0.3428</cell></row><row><cell cols="2">KLEDistFBT 0.3031 0.4260 0.3454</cell></row><row><cell cols="2">KLEDistFBB 0.2994 0.4560 0.3508</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">Acknowledgement</head><p>This work was supported in part by <rs type="funder">MKE &amp; IITA</rs> through IT Leading R&amp;D Support Project and also in part by the <rs type="projectName">BK 21</rs> Project in 2008.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_XUMUqkY">
					<orgName type="project" subtype="full">BK 21</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,72.00,481.94,226.81,8.97;8,82.91,493.90,215.90,8.97;8,82.91,505.85,215.90,8.97;8,82.91,517.81,215.90,8.97;8,82.91,529.76,215.90,8.97;8,82.91,541.72,215.90,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,204.52,493.90,94.29,8.97;8,82.91,505.85,111.03,8.97">Retrieval and feedback models for blog feed search</title>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Elsas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,214.26,505.85,84.55,8.97;8,82.91,517.81,215.90,8.97;8,82.91,529.76,215.90,8.97;8,82.91,541.72,32.65,8.97">SIGIR &apos;08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,554.70,226.82,8.97;8,82.91,566.65,215.90,8.97;8,82.91,578.61,215.88,8.97;8,82.91,590.56,17.44,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,257.40,554.70,41.42,8.97;8,82.91,566.65,215.90,8.97;8,82.91,578.61,26.34,8.97">Sentwordnet: A publicly available lexical resource for opinion mining</title>
		<author>
			<persName coords=""><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,133.28,578.61,110.63,8.97">Proceedings of LREC 2006</title>
		<meeting>LREC 2006</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="417" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,603.55,226.81,8.97;8,82.91,615.50,215.90,8.97;8,82.91,627.46,215.90,8.97;8,82.91,639.41,215.91,8.97;8,82.91,651.37,215.91,8.97;8,82.91,663.32,209.07,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,257.30,603.55,41.51,8.97;8,82.91,615.50,215.90,8.97;8,82.91,627.46,96.68,8.97">Document language models, query models, and risk minimization for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,200.33,627.46,98.48,8.97;8,82.91,639.41,215.91,8.97;8,82.91,651.37,215.91,8.97;8,82.91,663.32,24.81,8.97">SIGIR &apos;01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="111" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,676.31,226.81,8.97;8,82.91,688.26,207.10,8.97" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,82.91,688.26,146.37,8.97">Overview of the trec-2007 blog track</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<idno>TREC &apos;07</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,701.24,226.81,8.97;8,82.91,713.20,215.90,8.97;8,324.11,76.16,215.90,8.97;8,324.11,88.11,207.23,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,117.19,713.20,181.62,8.97;8,324.11,76.16,215.90,8.97;8,324.11,88.11,83.12,8.97">Improving term frequency normalization for multi-topical documents and application to language modeling approaches</title>
		<author>
			<persName coords=""><forename type="first">Seung-Hoon</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">In-Su</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong-Hyeok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,425.92,88.11,36.45,8.97">ECIR &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="382" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,313.20,100.82,226.81,8.97;8,324.11,112.77,215.90,8.97;8,324.11,124.73,215.90,8.97;8,324.11,136.68,147.73,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,377.36,112.77,162.65,8.97;8,324.11,124.73,215.90,8.97;8,324.11,136.68,25.37,8.97">Applying complete-arbitrary passage for pseudo-relevance feedback in language modeling approach</title>
		<author>
			<persName coords=""><forename type="first">Seung-Hoon</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">In-Su</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yeha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong-Hyeok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,368.08,136.68,34.80,8.97">AIRS &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="626" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,313.20,149.38,226.81,8.97;8,324.11,161.34,215.90,8.97;8,324.11,173.29,215.89,8.97;8,324.11,185.25,12.45,8.97;8,313.20,197.95,226.81,8.97;8,324.11,209.91,215.90,8.97;8,324.11,221.86,140.27,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,376.53,161.34,163.48,8.97;8,324.11,173.29,113.80,8.97;8,472.69,209.91,67.32,8.97;8,324.11,221.86,79.54,8.97">Completely-arbitrary passage retrieval in language modeling approach</title>
		<author>
			<persName coords=""><forename type="first">Seung-Hoon</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">In-Su</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yeha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong-Hyeok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,457.77,173.29,35.06,8.97">AIRS &apos;08</title>
		<editor>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2006">2008. 2006</date>
			<biblScope unit="page" from="22" to="33" />
		</imprint>
		<respStmt>
			<orgName>Iadh Ounis, Maarten de Rijke</orgName>
		</respStmt>
	</monogr>
	<note>Overview of the trec-2006 blog track. In TREC &apos;06</note>
</biblStruct>

<biblStruct coords="8,313.20,234.56,226.81,8.97;8,324.11,246.52,215.90,8.97;8,324.11,258.48,215.90,8.97;8,324.11,270.43,142.92,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,476.91,234.56,63.10,8.97;8,324.11,246.52,95.92,8.97">Blog site search using resource selection</title>
		<author>
			<persName coords=""><forename type="first">Jangwon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,441.33,246.52,98.68,8.97;8,324.11,258.48,215.90,8.97;8,324.11,270.43,110.79,8.97">CIKM &apos;08: Proceedings of the tenth international conference on Information and knowledge management</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,313.20,283.13,226.81,8.97;8,324.11,295.09,215.88,8.97;8,324.11,307.04,215.90,8.97;8,324.11,319.00,215.91,8.97;8,324.11,330.95,215.89,8.97;8,324.11,342.91,24.79,8.97;8,313.20,355.61,226.81,8.97;8,324.11,367.57,215.90,8.97;8,324.11,379.52,215.89,8.97;8,324.11,391.48,215.90,8.97;8,324.11,403.43,215.90,8.97;8,324.11,415.39,67.78,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,490.73,283.13,49.28,8.97;8,324.11,295.09,147.65,8.97;8,487.99,355.61,52.02,8.97;8,324.11,367.57,215.90,8.97;8,324.11,379.52,75.40,8.97">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xuehua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,494.79,295.09,45.20,8.97;8,324.11,307.04,215.90,8.97;8,324.11,319.00,215.91,8.97;8,324.11,330.95,63.59,8.97;8,324.11,342.91,24.79,8.97;8,313.20,355.61,140.55,8.97;8,425.55,379.52,114.45,8.97;8,324.11,391.48,215.90,8.97;8,324.11,403.43,94.68,8.97">SIGIR &apos;05: Proceedings of the 28th annual international ACM SI-GIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2005. 2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
	<note>CIKM &apos;01: Proceedings of the tenth international conference on Information and knowledge management</note>
</biblStruct>

<biblStruct coords="8,313.20,428.09,226.81,8.97;8,324.11,440.04,215.90,8.97;8,324.11,452.00,215.89,8.97;8,324.11,463.95,17.44,8.97" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,496.11,428.09,43.90,8.97;8,324.11,440.04,215.90,8.97;8,324.11,452.00,73.56,8.97">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,405.10,452.00,84.50,8.97">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
