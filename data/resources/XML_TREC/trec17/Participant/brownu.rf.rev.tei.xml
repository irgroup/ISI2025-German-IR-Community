<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,54.00,90.04,503.89,12.93;1,230.88,105.88,150.43,12.93;1,163.20,130.16,276.88,9.79;1,440.16,130.21,4.23,5.70">Incorporating Relevance and Psuedo-relevance Feedback in the Markov Random Field Model Brown at the TREC&apos;08 Relevance Feedback Track *</title>
				<funder ref="#_eNsFQEU">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,261.12,157.47,89.91,10.77"><forename type="first">Matthew</forename><surname>Lease</surname></persName>
							<email>mlease@cs.brown.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Brown Laboratory for Linguistic Information Processing (BLLIP</orgName>
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,54.00,90.04,503.89,12.93;1,230.88,105.88,150.43,12.93;1,163.20,130.16,276.88,9.79;1,440.16,130.21,4.23,5.70">Incorporating Relevance and Psuedo-relevance Feedback in the Markov Random Field Model Brown at the TREC&apos;08 Relevance Feedback Track *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">73A393362E0EC5692C76091225E971F7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a new document retrieval approach combining relevance feedback, pseudo-relevance feedback, and Markov random field modeling of term interaction. Overall effectiveness of our combined model and the relative contribution from each component is evaluated on the GOV2 webpage collection. Given 0-5 feedback documents, we find each component contributes unique value to the overall ensemble, achieving significant improvement individually and in combination. Comparative evaluation in the 2008 TREC Relevance Feedback track further shows our complete system typically performs as well or better than peer systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>User queries can be understood as surrogates for underlying information needs. While we might assume the information needs are fairly well-defined, the corresponding queries are often terse and incomplete. Consequently, performing retrieval strictly on the basis of an observed query often yields low retrieval accuracy and especially poor recall. A common strategy for addressing this is to infer additional details regarding the information need given a set of documents either known or thought to be relevant. When the user provides one or more such feedback documents in addition to his query, we have the scenario known as relevance feedback (RF).</p><p>This paper presents a strategy for effectively leveraging varying amounts of feedback (documents): none (a.k.a. ad hoc retrieval), one, a few, or many. One technique we employ, pseudo-relevance feedback (PRF), automatically induces additional feedback documents and uses them to further expand the query <ref type="bibr" coords="1,236.19,569.01,56.24,9.96;1,54.00,580.05,49.34,9.96" target="#b7">(Lavrenko &amp; Croft 2001;</ref><ref type="bibr" coords="1,106.57,580.05,94.08,9.96">Zhai &amp; Lafferty 2001)</ref>. Although PRF has been primarily investigated with ad hoc retrieval, it has the potential for greater effectiveness in the RF setting since explicit feedback improves system ranking for automatically identifying related documents. Alongside PRF, we also investigate the benefit of modeling term interactions in the RF scenario. Specifically, we adopt Markov random field (MRF) modeling of sequential dependencies between terms <ref type="bibr" coords="1,170.38,667.65,99.84,9.96">(Metzler &amp; Croft 2005)</ref>.</p><p>Given these two techniques, PRF and MRF modeling, we evaluate the benefit from applying each individually and in combination across varying RF conditions. Given 0-5 feedback documents, we find each component contributes unique value to the overall ensemble, achieving significant improvement individually and in combination. Additional experiments using RF in absence of MRF or PRF yield results consistent with community wisdom that a little feedback can make a big difference. Finally, comparative evaluation of our complete system in the 2008 TREC Relevance Feedback track shows our approach typically performs as well or better than peer systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This section describes our overall approach. After briefly summarizing our combined model, we proceed to review the individual techniques employed: query-likelihood <ref type="bibr" coords="1,392.90,418.77,98.16,9.96">(Lafferty &amp; Zhai 2001)</ref>, relevance and pseudo-relevance feedback <ref type="bibr" coords="1,440.64,429.57,113.05,9.96" target="#b7">(Lavrenko &amp; Croft 2001)</ref>, and Markov random field modeling of sequential term dependencies <ref type="bibr" coords="1,379.68,451.65,99.83,9.96">(Metzler &amp; Croft 2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Summary</head><p>Given an input query Q and feedback documents F , our overall method may be summarized as follows: 0. Unigram document models Θ D are estimated for each document via Dirichlet smoothing (Equation <ref type="formula" coords="1,528.28,521.49,4.46,9.96">3</ref>) <ref type="formula" coords="1,468.27,546.93,4.46,9.96">2</ref>) 2. A unigram RF model Θ F is estimated as the average document model over the set of positive (i.e. relevant) feedback documents (Equation <ref type="formula" coords="1,492.99,583.41,4.46,9.96">4</ref>)</p><formula xml:id="formula_0" coords="1,316.80,535.10,241.39,21.79">1. A unigram query model Θ Q is estimated from Q via maximum-likelihood (Equation</formula><p>3. An improved unigram query model Θ Q is produced by linearly mixing Θ Q and Θ F models (Equation <ref type="formula" coords="1,547.21,611.01,4.46,9.96">6</ref>)</p><p>4. Θ Q is used as the unigram component f T in the MRF model to yield P Λ (D|Q) (Equation <ref type="formula" coords="1,484.82,638.37,9.30,9.96">11</ref>) 5. A unigram psuedo-relevance model Θ P is estimated based on P Λ (D|Q) (Equation <ref type="formula" coords="1,460.58,665.01,9.30,9.96">12</ref>)</p><p>6. The PRF unigram likelihood Θ P • Θ D is linearly mixed with the P Λ (D|Q) MRF model (Equation <ref type="formula" coords="1,544.10,691.89,9.30,9.96">14</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query-Likelihood</head><p>We adopt the query-likelihood (Ponte &amp; Croft 1998) paradigm for information retrieval. In this language model (LM) approach, we assume each observed document D (of |D| words) is generated by an underlying LM parameterized by Θ D (the document model). Given an input query Q (of |Q| words), we infer D's relevance to Q as the probability of observing Q as a random sample drawn from Θ D . Assuming bag-of-words, Θ D specifies a unigram distribution {θ D w1 . . . θ D wN } over the collection vocabulary V = {w 1 . . . w N }. Finally, letting f Q w denote the frequency of word w in Q, querylikelihood can be expressed in log form as:</p><formula xml:id="formula_1" coords="2,70.80,208.94,221.80,22.47">log p(Q|D) = w∈Q f Q w log θ D w = f Q • log Θ D (1)</formula><p>where the final dot product is taken over the entire collection vocabulary (equivalent since f Q w = 0 for all terms not observed in the query).</p><p>While this formulation of query-likelihood is perfectly valid, incorporating lexical statistics from feedback documents into it is cumbersome since the relative importance of terms can only be expressed through repetition. To address this, Equation 1 can be generalized by assuming the observed Q is merely representative of a latent query model parameterized by Θ Q = {θ Q w1 . . . θ Q wV }, consistent with intuition that the underlying information need might be verbalized in other ways besides Q. Query likelihood may then be re-expressed in terms of</p><formula xml:id="formula_2" coords="2,54.00,382.61,238.60,35.56">Θ Q 's maximum-likelihood (ML) estimate Θ Q = 1 |Q| f Q f Q • log Θ D = |Q| Θ Q • log Θ D rank = -D( Θ Q ||Θ D ) (2)</formula><p>This shows inferring document relevance on the basis of P (Q|D) is equivalent to ranking according to minimal KL-divergence D(Θ Q ||Θ D ) when Θ Q is estimated by ML <ref type="bibr" coords="2,88.09,458.37,99.84,9.96">(Lafferty &amp; Zhai 2001)</ref>. Intuitively, better retrieval can be achieved by forgoing strict equivalence with Equation 1 and instead seeking more accurate inference of Θ Q . This is where relevance feedback fits in: it can be leveraged in conjunction with the observed query to better estimate Θ Q . Regarding Θ D , we apply standard Dirichlet smoothing to estimate it as a mixture between document D and collection C (of |C| words) ML estimates <ref type="bibr" coords="2,269.27,545.97,23.17,9.96;2,54.00,557.01,71.89,9.96" target="#b18">(Zhai &amp; Lafferty 2004;</ref><ref type="bibr" coords="2,129.12,557.01,163.58,9.96">Zaragoza, Hiemstra, &amp; Tipping 2003;</ref><ref type="bibr" coords="2,54.00,568.05,104.15,9.96" target="#b8">Lease &amp; Charniak 2008)</ref>:</p><formula xml:id="formula_3" coords="2,81.36,585.02,211.24,24.67">θD w = λ f D w |D| + (1 -λ) f C w |C| , λ = |D| |D| + µ (3)</formula><p>where µ specifies hyper-parameter strength of the prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance Feedback</head><p>Given a query, our retrieval model (Equation <ref type="formula" coords="2,256.37,650.61,4.46,9.96">2</ref>) infers relevance on the basis of similarity between (our estimates of) query and document models, Θ Q and Θ D . While we have thus far focused on document ranking for a given query, let us now consider the other direction of query formulation. Given a set of relevant documents R that match a user's information need, the optimal query model Θ Q under Equation 2 will exhibit greater similarity to R's latent document models ∀ D∈R Θ D than those of other documents. This suggests that given partial knowledge of R in the form of |F | feedback documents where F ⊆ R, Θ Q might be estimated on the basis of similarity to F . For example, a simple idea would be to estimate Θ Q as the average document model over the set of positive (i.e. relevant) feedback documents:</p><formula xml:id="formula_4" coords="2,388.56,169.89,169.48,27.68">Θ F = 1 |F | D∈F Θ D (4)</formula><p>While the classic Rocchio method (Rocchio &amp; others 1971) also incorporates negative feedback (γ term):</p><formula xml:id="formula_5" coords="2,359.28,228.14,198.76,30.64">q r = α q 0 + β 1 N r Nr i d i -γ 1 N r Nr i d i<label>(5)</label></formula><p>negative feedback has typically been found to be far less useful than positive feedback, and so we omit it completely in our system. Since retrieval time is typically proportional to the number of terms used, a common efficiency heuristic is to approximate Θ F by its k F most likely terms and re-normalize<ref type="foot" coords="2,446.64,315.65,3.97,6.97" target="#foot_0">1</ref> . Although the approach in Equation 4 does provide broader lexical coverage of R than available in the original query string, it suffers from a different problem. Whereas Q tends to closely focus on the core information need, the average feedback document model may diverge from it since documents in F likely discuss many topics. Rocchio's α q 0 mixing term helps prevent such drift, and we adopt the same solution here by inferring Θ Q on the basis of both the original query and the feedback documents in the form of a linear mixture:</p><formula xml:id="formula_6" coords="2,366.48,439.34,183.05,11.92">Θ Q = (1 -λ F ) Θ Q + λ F Θ F<label>(</label></formula><p>6) Despite the simplicity of this approach, recent studies have shown it comparable to more sophisticated strategies <ref type="bibr" coords="2,339.83,477.09,164.30,9.96" target="#b2">(Balog, Weerkamp, &amp; de Rijke 2008;</ref><ref type="bibr" coords="2,508.09,477.09,50.19,9.96;2,319.44,488.13,22.31,9.96" target="#b16">Yi &amp; Allan 2008)</ref>. Consequently, we adopt it here in our work.</p><p>Combining Equations 1, 2, and 6, we see that unigram feedback can be equivalently interpreted as a mixture of query models used in the original ranking function (Equation <ref type="formula" coords="2,386.67,531.81,4.46,9.96">1</ref>) or as a mixture of ranking functions:</p><formula xml:id="formula_7" coords="2,321.12,547.10,235.33,64.72">P (Q|D) rank = log Θ D • Θ Q = log Θ D • [(1 -λ F ) Θ Q + λ F Θ F ] = (1 -λ F )[ log Θ D • Θ Q ] + λ F [ log Θ D • Θ F ] rank = (1 -λ F ) D(Θ Q ||Θ D ) + λ F D(Θ F ||Θ D )</formula><p>However, once we move away from unigram modeling to perform MRF modeling instead, we will see that this dual interpretation is no longer applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Markov Random Field Model</head><p>The Markov random field (MRF) approach <ref type="bibr" coords="3,244.84,70.29,47.59,9.96;3,54.00,81.09,44.68,9.96">(Metzler &amp; Croft 2005</ref>) models the joint distribution P Λ (Q, D) over queries Q and documents D. It is constructed from a graph G consisting of a document node and nodes for each query term. Nodes in the graph represent random variables and edges define the independence semantics between the variables. In particular, a random variable in the graph is independent of its non-neighbors given observed values for its neighbors. Therefore, different edge configurations impose different independence assumptions. The joint distribution over the random variables in G is defined by:</p><formula xml:id="formula_8" coords="3,108.00,206.13,184.59,28.16">P Λ (Q, D) = 1 Z Λ c∈C(G) ψ(c; Λ) (7)</formula><p>where C(G) is the set of cliques in G, each ψ(•; Λ) is a non-negative potential function over clique configurations parameterized by Λ, and</p><formula xml:id="formula_9" coords="3,64.56,264.45,227.83,22.88">Z Λ = Q,D</formula><p>c∈C(G) ψ(c; Λ) computes the partition function. For document ranking, we can skip the expensive computation of Z Λ and simply score each document D by its unnormalized joint probability with Q under the MRF. If we define our potential functions as ψ(c; Λ) = exp[λ c f(c)], where f(c) is some real-valued feature function over clique values and λ c is that feature function's assigned weight, the posterior P Λ (D|Q) is computed as:</p><formula xml:id="formula_10" coords="3,97.20,370.77,195.40,82.40">P Λ (D|Q) = P Λ (Q, D) P Λ (Q) rank = c∈C(G) log ψ(c; Λ) = c∈C(G) λ c f(c)<label>(8)</label></formula><p>The graph G can be constructed in various ways depending on various possible assumptions regarding independence between terms. In the case of full independence, query term nodes share an edge with the document only. With sequential dependence, adjacent terms in the query share an additional edge in G. Finally, assuming full dependence constructs an edge between each pair of query term nodes. The choice of graph structure determines the set of cliques present in G and thereby the set of features used in ranking. We use the sequential dependence MRF in our work since the full dependence model is expensive to compute due to its combinatorial feature growth and provides only slight improvement in accuracy <ref type="bibr" coords="3,166.81,603.33,99.83,9.96">(Metzler &amp; Croft 2005)</ref>.</p><p>All of the potential functions used in the MRF can be expressed in the following generic form:</p><formula xml:id="formula_11" coords="3,62.16,641.97,230.44,23.40">log ψ i (c; Λ) = λ i log (1 -α D i ) S i (c) |D| + α D i S i (c) |C| (9)</formula><p>where S i (c) denotes a given statistic computed for the given clique c, |D| and |C| indicate respective token counts of the document and entire collection (statistics other than term frequency are only approximately normalized), and α D i = µi µi +|D| , where µ i denotes a smoothing hyper-parameter specific to the potential function ψ i (c; Λ) <ref type="bibr" coords="3,356.16,91.41,97.68,9.96" target="#b18">(Zhai &amp; Lafferty 2004)</ref>. Note that use of term frequency as the statistic S i computes the standard Dirichlet-smoothed unigram (Equation <ref type="formula" coords="3,492.03,113.49,3.88,9.96">3</ref>).</p><p>Potential functions are primarily distinguished by the particular statistic S i they employ. The MRF model exploits three classes of lexical features: individual terms, contiguous phrases, and proximity. Each of these corresponds to a distinct statistic S i : term frequency, phrase frequency (i.e. "ordered" Indri #1 operator), and frequency of a set of terms within some parameter N -sized window (i.e. "unordered" Indri #uwN operator). The latter two multi-term statistics' corresponding potential functions are applicable when some form of dependency is assumed between query terms in the graph structure. In particular, the phrasal potential function is only applied to cliques connecting contiguous query terms, whereas the proximity potential function is applied to all multi-term cliques, contiguous and noncontiguous alike. This means each pair of contiguous query terms generates a clique c whose potential function is defined by the product ψ o (c)ψ u (c) of ordered and unordered potential functions.</p><p>Using these three classes of potential functions, the MRF can be expressed as a three component mixture model computed over term, phrase, and proximity feature classes. Omitting clique parameterization and computation of the partition function, we can see that each class effectively computes its own ranking function which is then mixed with that of the other classes:</p><formula xml:id="formula_12" coords="3,363.60,414.69,194.44,10.65">P Λ (Q, D) ∝ λ T f T + λ O f O + λ U f U (10)</formula><p>Note that unigram likelihood (Equation <ref type="formula" coords="3,511.49,431.01,4.46,9.96">2</ref>) can be equivalently formulated as an MRF in which λ T = 1 and λ O = λ U = 0. This means an improved unigram model Θ Q (e.g. better estimated via feedback) can be used in place of the MRF's standard f T unigram model:</p><formula xml:id="formula_13" coords="3,329.76,492.86,228.28,13.36">P Λ (D, Q) ∝ λ T [Θ Q • log Θ D ] + λ O f O + λ U f U (11)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudo-Relevance Feedback</head><p>PRF is quite similar to RF except that now we must factor in our uncertainty regarding each feedback document's relevance to the query. While our original setup in Equation 4 made a simplifying assumption that all feedback documents were equally relevant, this estimate can be improved by accounting for varying degree of relevance across the feedback set. The straightforward way to accomplish this is to generalize from the simple average of Equation 4 to instead compute an expectation respecting some arbitrary estimate p(D|Q) of feedback document relevance with respect to the query Q:</p><formula xml:id="formula_14" coords="3,341.04,655.34,217.00,22.24">Θ P = E D∼p(D|Q) [Θ D ] = D∈C p(D|Q) Θ D (12)</formula><p>where C denotes the document collection. Recall the MRF model defines a joint distribution P Λ (Q, D)</p><p>expressed unnormalized in Equation <ref type="formula" coords="4,225.15,56.61,8.57,9.96">10</ref>. While we could compute the full partition function to normalize P Λ (Q, D) over the entire document collection, this is unnecessary unless we want to use the entire collection for feedback. Besides the large computational cost this would incur, there is diminishing return and increasing harm from query drift as we start sifting through lower ranks. Instead, we can simply normalize with respect to the set of PRF documents P only:</p><formula xml:id="formula_15" coords="4,108.24,161.25,184.36,25.52">P N Λ (D|Q) = P Λ (Q, D) D∈P P Λ (Q, D)<label>(13)</label></formula><p>The expected PRF document model can then be easily computed by Equation 12 above. As with RF, a common efficiency heuristic is to approximate Θ P by its k P most likely terms and re-normalize. The original estimate of Θ Q is also typically mixed with the Θ P , similar to what was done with explicit feedback (Equation <ref type="formula" coords="4,279.40,247.65,3.88,9.96">6</ref>). When using PRF in conjunction with the MRF model, we must specify how Θ P is mixed with original model: query model mixing (i.e. in the f T component) or ranking function mixing. We adopt Indri's formulation <ref type="bibr" coords="4,82.81,302.37,92.91,9.96">(Metzler et al. 2005)</ref> incorporating PRF at the level of the ranking function: <ref type="formula" coords="4,279.25,330.93,8.90,9.96">14</ref>) using P Λ (D|Q) as defined in Equation <ref type="formula" coords="4,221.55,348.45,8.57,9.96">11</ref>. Note PRF is limited here to unigram modeling; we do not estimate dependency statistics from PRF for revising f O and f U components since previous work has shown little benefit from doing so <ref type="bibr" coords="4,116.89,392.37,104.79,9.96">(Metzler &amp; Croft 2007a)</ref>.</p><formula xml:id="formula_16" coords="4,60.24,329.42,219.01,13.12">P Λ (D|Q) = λ P [ log Θ P • Θ D ] + (1-λ P )P Λ (D|Q) (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>This section describes evaluation performed in developing and testing our model. Table <ref type="table" coords="4,198.98,439.65,4.98,9.96">1</ref> provides a complete listing of all model parameters and identifies which remain fixed in our experiments. We follow previous work in setting MRF proximity parameters for window size w proximity and Dirichlet smoothing µ proximity .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Track Protocol and Metrics</head><p>Model evaluation was performed as part of our participation in the 2008 TREC Relevance Feedback Track. A goal of the track was to establish strong baselines for current RF techniques under varying amounts of explicit feedback: A: no feedback (i.e. ad hoc retrieval) B: 1 relevant document C: 3 relevant and 3 non-relevant documents D: 10 judged documents E: large amounts of feedback (40-800 documents) Each feedback set was included as a subset of its larger successors. Retrieval experiments were conducted on the GOV2 webpage collection <ref type="bibr" coords="4,188.88,672.69,18.13,9.96">(25,</ref><ref type="bibr" coords="4,207.02,672.69,18.13,9.96">205,</ref><ref type="bibr" coords="4,225.15,672.69,13.60,9.96">179</ref>  Cumulative metric performance across topics is generally computed by a simple (arithmetic) average over per-query metric performance. The one exception, geometric-mean average precision (gmap), adopts the geometric mean instead in order to focus metric attention on difficult topics. Primary metrics used were (arithmetic-mean) average precision (AP) and top-10 precision (P@10), as reported by trec_eval 8.1<ref type="foot" coords="4,529.68,418.85,3.97,6.97" target="#foot_2">2</ref> . Besides gmap, we also report R-Precision (rprec): precision after R documents retrieved, where R is the number of relevant documents for each topic. Results marked as significant † (p &lt; .05), highly significant ‡ (p &lt; .01), or neither reflect agreement between a two-sided paired t-test and random shuffling statistics computed by Indri's ireval <ref type="bibr" coords="4,397.92,497.01,155.76,9.96" target="#b14">(Smucker, Allan, &amp; Carterette 2007)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup</head><p>Indri <ref type="bibr" coords="4,345.13,532.77,99.86,9.96" target="#b15">(Strohman et al. 2004</ref>) formed the basis of our retrieval model. Since Indri does not provide a facility for performing RF, however, we estimated the feedback model Θ F externally. Queries were stopped at query time using a 418 word INQUERY stop list <ref type="bibr" coords="4,505.69,576.69,52.24,9.96;4,319.44,587.73,24.04,9.96" target="#b0">(Allan et al. 2000)</ref> and then Porter stemmed<ref type="foot" coords="4,455.76,586.37,3.97,6.97" target="#foot_3">3</ref> . Recall that term pair features f O and f U from the dependency model (Equation 10) correspond to co-occurrence statistics tracking pairs of words occurring consecutively or within some proximity of one another. It is worth noting that Indri replaces stopwords with out-of-vocabulary tokens and so use of stopwords does not affect distance between terms in computed co-occurrence statistics. For model development, track protocol did not specify which documents to use for feedback with non-test topics. While it would have been ideal to choose documents achieving high rank under ad hoc retrieval, mirroring testing conditions, we simply took feedback documents for each topic according to their order in the collection assessments. Initially we tried evaluating crossvalidated performance over different choices of feedback documents, but we ended up abandoning this practice due to time constraints. Since our RF method made no use of negative-feedback, our choice of feedback involved only relevant documents. For condition D, we always used 5 relevant documents rather than vary the number per topic as in testing conditions. Finally, with condition E we simply used all relevant documents under an assumption that once so many feedback documents were available, the exact number would make little difference. We did not test this assumption, however, and so it bears some scrutiny in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Tuning was performed with feedback documents included in evaluation due to a misinterpretation of track protocol. This led to selection of parameter settings which likely overfit feedback. Despite the nonoptimality of this tuning process, our development set results presented below do properly exclude feedback documents and so support useful analysis. Of the 98 topics originally used in tuning, we discard three which have fewer than five non-feedback relevant documents, leaving 95 for evaluation. Since condition E tuning used all relevant documents as feedback, its performance can only be evaluated with feedback documents included. Consequently, this condition is largely omitted in our discussion of development set results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on Development Topics</head><p>Parameter values were tuned on development topics via grid search <ref type="bibr" coords="5,106.80,617.73,108.09,9.96">(Metzler &amp; Croft 2007b)</ref>, resulting in the values listed in Table <ref type="table" coords="5,153.61,628.77,3.90,9.96">3</ref>. Results in Table <ref type="table" coords="5,246.49,628.77,4.98,9.96">2</ref> compare baseline unigram AP with that achieved using PRF, MRF, and MRF+PRF combined. While results generally show improvement with increasing feedback, the more interesting observation is seeing how the techniques contribute and interact with one another in comparison to the baseline and across feedback conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Run We submitted nine runs for official evaluation: five unigram runs with no PRF (conditions A-E) and four MRF+PRF runs (conditions A-D). No MRF+PRF run was submitted for condition E since we did not observe improvement from either technique on this condition while tuning. Evaluation of these runs on development topics is shown in Table <ref type="table" coords="5,429.61,581.25,3.90,9.96" target="#tab_2">4</ref>. Results show fairly steady improvement for unigram runs but a more complicated picture for MRF+PRF runs. While gmap, rprec, and P@10 steadily improve with increasing feedback, map is flat for A-C. However, both map and P@10 show significant improvement for condition D.</p><formula xml:id="formula_17" coords="5,326.16,55.05,218.19,42.72">k F λ F λ T λ O λ P Unigram A2 - - - - - B2 250 0.3 - - - C2<label>150</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on Test Topics</head><p>Official test set results of our nine submitted runs are presented in Unigram results demonstrate a steady improvement in retrieval accuracy across all but gmap metrics with growing amounts of feedback. The largest AP improvement is seen moving to condition E's large amount of feedback (4.11% absolute over condition D). A slightly smaller AP improvement is seen as we go from ad hoc retrieval (condition A) to condition B's having a single relevant document: 3.66% (absolute). Similar trending is observed with high-rank P@10 retrieval: 11.61% and 5.49%, respectively (absolute). Regarding gmap, it would seem topic drift caused by feedback is seen to hurt performance, though this loss diminishes as greater feedback reduces drift. However, note a very different trend is observed on development topics (Table 4). It may be this difference in trends is simply a byproduct of differences between how feedback documents were selected for development and test sets. On the other hand, since official evaluation only included top-10 ranked documents in pooling, assessment may have been biased in favor of easier topics for which many relevant documents would be seen early in the ranked list. Finally, since we use identical system configurations for conditions C and D (which provide comparable feedback), we expected their results should be quite similar, and MTC and statAP metrics bear this out.</p><p>MRF+PRF results are less clear in that condition B results decline in comparison to ad hoc retrieval under AP and rprec metrics while improving under all other metrics. This drop is likely due to overfitting. Otherwise similar trends are observed: we see improvement with increasing feedback. C and D conditions again appear roughly comparable, with D generally performing slightly better except in the case of statAP.</p><p>Table <ref type="table" coords="6,358.80,558.69,4.98,9.96" target="#tab_5">6</ref> shows the relative strength of our overall system in comparison to four other competitive submissions to the 2008 TREC Relevance Feedback track. Performance is summarized by simply averaging official MAP and P@10 accuracies across the various feedback conditions. Results shown our system typically performed as well or better than peer systems. The track overview <ref type="bibr" coords="6,360.00,635.25,123.40,9.96" target="#b4">(Buckley &amp; Robertson 2008)</ref> and official track results provide more thorough details for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This paper investigated combination of relevance feedback, pseudo-relevance feedback, and Markov random field modeling techniques for document retrieval. Using a large web collection, we evaluated an overall combination strategy while assessing the contribution from each component in presence of the others. Given 0-5 feedback documents, we found each component contributed unique value to the overall ensemble, achieving significant improvement individually and in combination.</p><p>Comparative evaluation in the 2008 TREC Relevance Feedback track further showed our complete system typically performs as well or better than other peer systems. Use of proximity (e.g. features in our MRF model) and/or PRF was generally seen to help in combination with RF across participating systems that employed one or the other. Use of negative feedback (e.g. via Rocchio) generally provided little benefit. Interestingly, all of the competitive participants' systems displayed some form on non-monotonicity in accuracy with increasing feedback. While we identified problems with overfitting in our system, as discussed earlier, it remains to be seen this is explanation is sufficient in general.</p><p>While our approach to RF in this paper was limited to unigram feedback, future work will explore term dependency selection from feedback documents for incorporation into f O and f U MRF components (Equation 10). Previous work has shown little benefit from PRF dependency modeling <ref type="bibr" coords="7,179.30,332.13,108.87,9.96">(Metzler &amp; Croft 2007a)</ref>, but RF dependency modeling may prove to be more helpful. We would also like to explore use of RF in conjunction with supervised unigram modeling <ref type="bibr" coords="7,243.40,365.01,48.70,9.96;7,54.00,376.05,60.38,9.96" target="#b3">(Bendersky &amp; Croft 2008;</ref><ref type="bibr" coords="7,117.37,376.05,119.52,9.96" target="#b9">Lease, Allan, &amp; Croft 2009)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,319.44,87.81,238.85,426.36"><head>Table 4 :</head><label>4</label><figDesc>Unigram and MRF+PRF results on development topics. Statistical significance is reported for map and P@10 (only) by prefix † and ‡ comparing against cell above (i.e. less feedback) while suffix compares Unigram vs. MRF+PRF runs using comparable feedback.</figDesc><table coords="5,319.44,87.81,238.85,426.36"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.45 -</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>D2</cell><cell cols="3">150 0.45 -</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>E1</cell><cell cols="2">250 0.8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>A1</cell><cell>-</cell><cell>-</cell><cell>0.8 0.1</cell><cell>0.5</cell></row><row><cell cols="2">MRF+PRF</cell><cell>B1 C1</cell><cell cols="3">150 0.3 150 0.45 0.9 0.05 0.85 0.8 0.1 0.75</cell></row><row><cell></cell><cell></cell><cell>D1</cell><cell cols="3">150 0.45 0.9 0.05 0.85</cell></row><row><cell>Table 3:</cell><cell></cell><cell cols="4">Parameterization of submitted runs.</cell></row><row><cell cols="6">MRF+PRF values are identical for C and D conditions.</cell></row><row><cell>Model</cell><cell cols="3">Run AP</cell><cell cols="2">gmap rprec P@10</cell></row><row><cell></cell><cell></cell><cell>A2</cell><cell>29.18</cell><cell>21.65</cell><cell>35.27</cell><cell>54.32</cell></row><row><cell></cell><cell></cell><cell cols="2">B2  ‡30.84</cell><cell>24.22</cell><cell>36.52</cell><cell>†57.89</cell></row><row><cell>Unigram</cell><cell></cell><cell cols="2">C2  †31.94</cell><cell>26.27</cell><cell>38.14</cell><cell>57.37</cell></row><row><cell></cell><cell></cell><cell cols="2">D2  ‡33.49</cell><cell>27.89</cell><cell>39.15</cell><cell>‡62.42</cell></row><row><cell></cell><cell></cell><cell>A1</cell><cell cols="2">35.28 ‡ 26.42</cell><cell>38.62</cell><cell>60.53 ‡</cell></row><row><cell>MRF+PRF</cell><cell></cell><cell>B1 C1</cell><cell cols="2">34.78 ‡ 28.33 35.37 ‡ 29.88</cell><cell>39.50 40.15</cell><cell>61.68 † 61.89 †</cell></row><row><cell></cell><cell></cell><cell cols="3">D1  †36.66 ‡ 31.42</cell><cell>40.88</cell><cell>†64.95</cell></row><row><cell cols="6">With the sole exception of PRF in condition C, we</cell></row><row><cell cols="6">see PRF and MRF modeling each yield improvement</cell></row><row><cell cols="6">over the baseline across feedback conditions with MRF</cell></row><row><cell cols="6">seen to be the stronger of the two. Furthermore, the</cell></row><row><cell cols="6">MRF+PRF combination achieves additional significant</cell></row><row><cell cols="6">improvement over MRF modeling alone. With condi-</cell></row><row><cell cols="6">tion E (not shown), neither PRF or the MRF model im-</cell></row><row><cell cols="6">proved over the baseline. However, this result is incon-</cell></row><row><cell cols="6">clusive since condition E development set results could</cell></row><row><cell cols="6">not be evaluated without retrieved feedback documents.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,319.44,683.49,238.75,21.00"><head>Table 5 .</head><label>5</label><figDesc>AP, gmap, rprec, and P@10 metrics are computed on top-1000 retrieved documents</figDesc><table coords="6,139.92,55.19,332.31,108.82"><row><cell>Model</cell><cell cols="2">Run AP</cell><cell cols="5">gmap rprec P@10 MTC statAP</cell></row><row><cell></cell><cell>A2</cell><cell>13.43</cell><cell>4.05</cell><cell>16.48</cell><cell>24.19</cell><cell>4.90</cell><cell>22.91</cell></row><row><cell></cell><cell>B2</cell><cell>‡17.09</cell><cell>6.99</cell><cell>21.09</cell><cell cols="2">†29.68 6.22</cell><cell>29.07</cell></row><row><cell>Unigram</cell><cell>C2</cell><cell>‡19.50</cell><cell>8.66</cell><cell>22.66</cell><cell>32.58</cell><cell>7.03</cell><cell>32.27</cell></row><row><cell></cell><cell>D2</cell><cell>20.64</cell><cell>9.29</cell><cell>23.67</cell><cell cols="2">†36.45 7.06</cell><cell>32.16</cell></row><row><cell></cell><cell>E1</cell><cell>†24.75</cell><cell>14.85</cell><cell>27.35</cell><cell cols="2">‡48.06 7.32</cell><cell>35.00</cell></row><row><cell></cell><cell>A1</cell><cell>21.46 ‡</cell><cell>11.43</cell><cell>25.15</cell><cell>32.90</cell><cell>5.64</cell><cell>27.99</cell></row><row><cell>MRF+PRF</cell><cell>B1 C1</cell><cell cols="2">20.96  †22.96 † 13.68 11.63</cell><cell>23.56 25.75</cell><cell>33.87 37.74</cell><cell>6.04 7.01</cell><cell>29.59 33.87</cell></row><row><cell></cell><cell>D1</cell><cell cols="2">†24.29 † 14.93</cell><cell>27.42</cell><cell>40.65</cell><cell>7.03</cell><cell>32.16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,54.00,180.69,504.14,120.36"><head>Table 5 :</head><label>5</label><figDesc>Official results of our runs on test topics. Run name indicates feedback condition and run ID. Runs are divided between unigram results (no PRF) and results using both sequential dependency(Metzler &amp; Croft 2005)  and PRF. Statistical significance is reported for map and P@10 (only) following the same conventions used in Table4.</figDesc><table coords="6,198.48,225.59,215.38,75.46"><row><cell></cell><cell cols="2">MAP</cell><cell cols="2">P@10</cell></row><row><cell>System</cell><cell>A-E</cell><cell>B-E</cell><cell>A-E</cell><cell>B-E</cell></row><row><cell>Brown</cell><cell>22.89</cell><cell>23.23</cell><cell>38.64</cell><cell>40.08</cell></row><row><cell>uogRF09</cell><cell>22.08</cell><cell>22.68</cell><cell>38.64</cell><cell>38.87</cell></row><row><cell cols="2">UAmsR08PD 19.22</cell><cell cols="3">20.09 35.17 † 36.78 †</cell></row><row><cell>UIUC</cell><cell cols="4">18.55 † 20.09 † 32.52 † 35.41 ‡</cell></row><row><cell>FubRF08</cell><cell cols="4">17.85 † 19.58 † 32.26 † 35.48 ‡</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,54.00,317.73,504.24,184.68"><head>Table 6 :</head><label>6</label><figDesc>Relative performance achieved by five of the top systems participating in the track, as measured by simply averaging official test topic MAP and P@10 accuracies across the various feedback conditions. Column "A-E"</figDesc><table coords="6,54.00,393.81,239.03,108.60"><row><cell>with relevance determined by NIST pooling assessment</cell></row><row><cell>of 31 Terabyte track topics. The pool consisted of the</cell></row><row><cell>top-10 ranked documents from each run submitted by a</cell></row><row><cell>participant. MTC corresponds to Carterette et al.'s Min-</cell></row><row><cell>imal Test Collections evaluation algorithm (Carterette,</cell></row><row><cell>Allan, &amp; Sitaraman 2006) and statAP comes from</cell></row><row><cell>Aslam and Pavlu's statistical MAP estimation proce-</cell></row><row><cell>dure (Aslam, Pavlu, &amp; Yilmaz 2006); both algorithms</cell></row><row><cell>were used in the TREC Million-query Track. Million-</cell></row><row><cell>query track runs also contributed to the pools.</cell></row></table><note coords="6,54.00,339.57,504.15,9.96;6,54.00,350.61,504.13,9.96;6,54.00,361.65,471.26,9.96"><p><p><p>averages over all conditions, while "B-E" compares feedback conditions only (no ad hoc "A"). Statistical significance measured by a two-tailed paired t-test is reported for low significance † (p &lt; .05) and high significance ‡ (p &lt; .01). Refer to track overview</p><ref type="bibr" coords="6,159.12,361.65,124.84,9.96" target="#b4">(Buckley &amp; Robertson 2008)</ref> </p>and official track results for more detailed comparison.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,336.00,655.44,60.55,8.96"><p>Since Equation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,407.51,655.44,150.41,8.96;2,319.44,665.28,238.62,8.96;2,319.44,675.36,232.49,8.96;2,552.00,674.18,4.63,5.55;2,319.44,685.20,238.29,8.96;2,319.44,695.28,214.91,8.96"><p>is a linear model, ranking is invariant under any scaling of the weight vector and so normalization does not affect ranking. However, if we wish to later use Θ F in some mixture model, choice of kF will have a side-effect on mixture weight unless normalization is performed.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="4,336.00,685.22,141.99,8.27"><p>http://trec.nist.gov/trec_eval</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="4,336.00,695.78,207.99,8.27"><p>http://www.tartarus.org/martin/PorterStemmer</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Support for this work was provided in part by <rs type="funder">NSF</rs> <rs type="grantName">PIRE Grant</rs> No <rs type="grantNumber">OISE-0530118</rs> and the <rs type="institution">Center for Intelligent Information Retrieval (CIIR) at the University of Massachusetts Amherst</rs>. Any opinions, findings, and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors. We thank <rs type="person">James Allan</rs> and <rs type="person">Micha Elsner</rs> for their valuable feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_eNsFQEU">
					<idno type="grant-number">OISE-0530118</idno>
					<orgName type="grant-name">PIRE Grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,59.04,535.20,233.27,8.96;7,59.04,545.04,233.44,8.96;7,59.04,555.12,34.48,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,108.71,545.04,94.52,8.96">INQUERY and TREC-9</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,222.00,545.04,65.24,8.96">Proc. of TREC-9</title>
		<meeting>of TREC-9</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="551" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,59.04,568.56,233.37,8.96;7,59.04,578.64,233.15,8.96;7,59.04,588.48,233.70,8.96;7,59.04,598.56,233.71,8.96;7,59.04,608.40,207.76,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,243.06,568.56,49.35,8.96;7,59.04,578.64,228.77,8.96">A statistical method for system evaluation using incomplete judgments</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,71.04,588.48,221.70,8.96;7,59.04,598.56,233.71,8.96;7,59.04,608.40,51.28,8.96">Proceedings of the 29th annual international ACM SI-GIR conference on Research and development in information retrieval</title>
		<meeting>the 29th annual international ACM SI-GIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="541" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,59.04,622.08,233.39,8.96;7,59.04,631.92,233.47,8.96;7,59.04,642.00,233.71,8.96;7,59.04,651.84,233.91,8.96;7,59.04,661.92,205.36,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,268.74,622.08,23.69,8.96;7,59.04,631.92,233.47,8.96;7,59.04,642.00,116.08,8.96">A few examples go a long way: constructing query models from elaborate query formulations</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,198.48,642.00,94.27,8.96;7,59.04,651.84,233.91,8.96;7,59.04,661.92,164.57,8.96">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="371" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,59.04,675.36,233.18,8.96;7,59.04,685.20,233.57,8.96;7,59.04,695.28,86.56,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,209.49,675.36,82.73,8.96;7,59.04,685.20,91.85,8.96">Discovering key concepts in verbose queries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,168.48,685.20,57.73,8.96">Proc. of SIGIR</title>
		<meeting>of SIGIR<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="491" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,57.35,233.29,8.96;7,324.48,67.19,233.69,8.96;7,324.48,77.27,180.16,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,478.04,57.35,79.73,8.96;7,324.48,67.19,118.12,8.96">Relevance Feedback Track Overview: TREC 2008</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,464.40,67.19,93.77,8.96;7,324.48,77.27,174.99,8.96">Proceedings of the Seventeenth Text Retrieval Conference (TREC)</title>
		<meeting>the Seventeenth Text Retrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,89.75,233.38,8.96;7,324.48,99.83,233.71,8.96;7,324.48,109.67,233.66,8.96;7,324.48,119.75,233.33,8.96;7,324.48,129.59,131.92,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,524.36,89.75,33.50,8.96;7,324.48,99.83,154.57,8.96">Minimal test collections for retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sitaraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,500.88,99.83,57.31,8.96;7,324.48,109.67,233.66,8.96;7,324.48,119.75,207.53,8.96">Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 29th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="268" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,142.31,233.44,8.96;7,324.48,152.39,233.52,8.96;7,324.48,162.23,152.56,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,454.29,142.31,103.63,8.96;7,324.48,152.39,233.52,8.96;7,324.48,162.23,32.10,8.96">Document language models, query models, and risk minimization for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,375.60,162.23,59.41,8.96">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="111" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,174.95,233.31,8.96;7,324.48,185.03,233.77,8.96;7,324.48,194.87,81.52,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,491.49,174.95,66.30,8.96;7,324.48,185.03,64.68,8.96">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,410.16,185.03,148.09,8.96;7,324.48,194.87,40.72,8.96">Proceedings of the 24th ACM SIGIR conference</title>
		<meeting>the 24th ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,207.59,233.31,8.96;7,324.48,217.43,233.70,8.96;7,324.48,227.51,233.65,8.96;7,324.48,237.35,205.35,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,470.84,207.59,86.95,8.96;7,324.48,217.43,194.82,8.96">A Dirichlet-smoothed Bigram Model for Retrieving Spontaneous Speech</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,537.12,217.43,21.06,8.96;7,324.48,227.51,233.65,8.96;7,324.48,237.35,42.48,8.96">Proc. of 8th Workshop of the Cross-Language Evaluation Forum (CLEF&apos;07)</title>
		<meeting>of 8th Workshop of the Cross-Language Evaluation Forum (CLEF&apos;07)</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="687" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,250.07,233.13,8.96;7,324.48,260.15,233.40,8.96;7,324.48,269.99,233.93,8.96;7,324.48,280.07,119.67,8.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,488.60,250.07,69.01,8.96;7,324.48,260.15,229.30,8.96">Regression Rank: Learning to Meet the Opportunity of Descriptive Queries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,336.48,269.99,221.93,8.96;7,324.48,280.07,67.64,8.96">Proc. of the 31st European Conference on Information Retrieval (ECIR)</title>
		<meeting>of the 31st European Conference on Information Retrieval (ECIR)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="7,324.48,292.79,233.57,8.96;7,324.48,302.63,233.20,8.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,463.42,292.79,94.63,8.96;7,324.48,302.63,113.05,8.96">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,457.20,302.63,58.69,8.96">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,315.35,233.22,8.96;7,324.48,325.19,233.67,8.96;7,324.48,335.27,233.91,8.96;7,324.48,345.11,233.56,8.96;7,324.48,355.19,110.79,8.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,467.50,315.35,90.20,8.96;7,324.48,325.19,126.20,8.96">Latent concept expansion using markov random fields</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,467.76,325.19,90.39,8.96;7,324.48,335.27,233.91,8.96;7,324.48,345.11,165.53,8.96">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,367.91,233.44,8.96;7,324.48,377.75,233.71,8.96;7,324.48,387.83,86.33,8.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,496.53,367.91,61.39,8.96;7,324.48,377.75,156.87,8.96">Linear featurebased models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,492.00,377.75,66.19,8.96;7,324.48,387.83,25.63,8.96">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="274" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,400.55,233.39,8.96;7,324.48,410.39,231.75,8.96;7,324.48,423.11,233.29,8.96;7,324.48,432.95,233.33,8.96;7,324.48,443.03,16.24,8.96;7,324.48,455.75,233.55,8.96;7,324.48,465.60,233.66,8.96;7,324.48,475.68,167.68,8.96" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,324.48,410.39,148.31,8.96;7,473.97,423.11,83.80,8.96;7,324.48,432.95,131.70,8.96">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Trec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,492.72,410.39,31.87,8.96;7,474.00,432.95,58.45,8.96;7,421.42,455.75,136.61,8.96;7,324.48,465.60,233.66,8.96;7,324.48,475.68,130.72,8.96">Relevance feedback in information retrieval. The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<imprint>
			<date type="published" when="1971">2005. 1998. 1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
	<note>Proc. of SIGIR</note>
</biblStruct>

<biblStruct coords="7,324.48,488.40,233.43,8.96;7,324.48,498.24,233.60,8.96;7,324.48,508.32,196.24,8.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,550.99,488.40,6.91,8.96;7,324.48,498.24,233.60,8.96;7,324.48,508.32,75.85,8.96">A comparison of statistical significance tests for information retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,420.00,508.32,57.25,8.96">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,520.80,233.38,8.96;7,324.48,530.88,233.31,8.96;7,324.48,540.72,233.66,8.96;7,324.48,550.80,85.83,8.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,324.48,530.88,233.31,8.96;7,324.48,540.72,26.58,8.96">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,370.08,540.72,188.06,8.96;7,324.48,550.80,81.74,8.96">Proceedings of the International Conference on Intelligence Analysis</title>
		<meeting>the International Conference on Intelligence Analysis</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,563.52,233.48,8.96;7,324.48,573.36,211.59,8.96;7,324.48,586.08,233.40,8.96;7,324.48,596.16,233.45,8.96;7,324.48,606.00,176.55,8.96" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,444.22,563.52,113.74,8.96;7,324.48,573.36,82.01,8.96;7,324.48,596.16,233.45,8.96;7,324.48,606.00,74.33,8.96">Bayesian extension to the language model for ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tipping</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,425.76,573.36,105.96,8.96;7,418.08,606.00,59.17,8.96">Proceedings of CIKM 2008</title>
		<meeting>CIKM 2008</meeting>
		<imprint>
			<date type="published" when="2003">2008. 2003</date>
			<biblScope unit="page" from="4" to="9" />
		</imprint>
	</monogr>
	<note>Proc. of SIGIR</note>
</biblStruct>

<biblStruct coords="7,324.48,618.72,233.56,8.96;7,324.48,628.56,233.65,8.96;7,324.48,638.64,112.24,8.96" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,458.14,618.72,99.91,8.96;7,324.48,628.56,230.09,8.96">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,336.00,638.64,57.25,8.96">Proc. of CIKM</title>
		<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,324.48,651.36,233.44,8.96;7,324.48,661.20,233.64,8.96;7,324.48,671.28,151.85,8.96" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="7,447.58,651.36,110.35,8.96;7,324.48,661.20,230.07,8.96">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,324.48,671.28,91.16,8.96">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
