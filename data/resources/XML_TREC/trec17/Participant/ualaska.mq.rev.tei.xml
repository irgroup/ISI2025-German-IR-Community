<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.00,78.53,448.84,17.48;1,72.00,102.95,209.55,17.48;11,52.75,30.88,506.00,25.23;11,52.75,61.32,353.61,25.23">Distributed multisearch and resource selection for the TREC Million Query Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.00,154.02,57.33,10.50"><forename type="first">Chris</forename><surname>Fallen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Arctic Region Supercomputing Center</orgName>
								<orgName type="institution">University of Alaska Fairbanks</orgName>
								<address>
									<postCode>99775</postCode>
									<settlement>Fairbanks</settlement>
									<region>AK</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Arctic Region Supercomputing Center</orgName>
								<orgName type="institution">University of Alaska Fairbanks</orgName>
								<address>
									<postCode>99775</postCode>
									<settlement>Fairbanks</settlement>
									<region>AK</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,153.06,154.02,61.37,10.50"><forename type="first">Greg</forename><surname>Newby</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Arctic Region Supercomputing Center</orgName>
								<orgName type="institution">University of Alaska Fairbanks</orgName>
								<address>
									<postCode>99775</postCode>
									<settlement>Fairbanks</settlement>
									<region>AK</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Arctic Region Supercomputing Center</orgName>
								<orgName type="institution">University of Alaska Fairbanks</orgName>
								<address>
									<postCode>99775</postCode>
									<settlement>Fairbanks</settlement>
									<region>AK</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,72.00,198.00,82.96,10.50"><forename type="first">Kylie</forename><surname>Mccormick</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Mount Holyoke College</orgName>
								<address>
									<addrLine>South Hadley</addrLine>
									<postCode>01075</postCode>
									<region>MA</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Mount Holyoke College</orgName>
								<address>
									<addrLine>South Hadley</addrLine>
									<postCode>01075</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.00,78.53,448.84,17.48;1,72.00,102.95,209.55,17.48;11,52.75,30.88,506.00,25.23;11,52.75,61.32,353.61,25.23">Distributed multisearch and resource selection for the TREC Million Query Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EB56B087EDD42FD1512D125C05448042</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A distributed information retrieval system with resource-selection and result-set merging capability was used to search subsets of the GOV2 document corpus for the 2008 TREC Million Query Track. The GOV2 collection was partitioned into host-name subcollections and distributed to multiple remote machines. The Multisearch demonstration application restricted each search to a fraction of the available sub-collections that was pre-determined by a resource-selection algorithm. Experiment results from topic-by-topic resource selection and aggregate topic resource selection are compared. The sensitivity of Multisearch retrieval performance to variations in the resource selection algorithm is discussed. www.nps.gov 0.2484 www.epa.gov 0.1064 xxx.bnl.gov 0.0974 www.nal.usda.gov 0.0929 www.fs.usda.gov 0.0511 fnalpubs.fnal.gov 0.0599 www.cr.nps.gov 0.0310 www-library.lbl.gov … … … … -0.0306 usinfo.state.gov -0.0586 www.cdc.gov -0.0354 www.nlm.nih.gov -0.0878 nih-library.nih.gov -0.0621 www.uspto.gov -0.0913 www1.uspto.gov -0.1181 catalog.tempe.gov -0.1121 landview.census.gov -0.1907 www1.uspto.gov -0.1175 www.nps.gov -0.5084 www.cdc.gov -0.8545 www.census.gov Table <ref type="table" coords="6,97.86,236.44,3.86,8.77">1</ref>. Coefficients of eigenvectors 7 and 9 of the collection correlation matrix calculated from the SVD of the term-collection matrix. The coefficients have been sorted in descending numerical order and listed next to the host-names of the associated vector components.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Overview</head><p>The information processing research group at ARSC works on problems affecting the performance of distributed information retrieval applications such as metasearch <ref type="bibr" coords="1,226.38,443.82,10.93,8.95" target="#b1">[1]</ref>, federated search <ref type="bibr" coords="1,107.34,457.80,10.93,8.95" target="#b2">[2]</ref>, and collection sampling <ref type="bibr" coords="1,247.11,457.80,10.93,8.95" target="#b3">[3]</ref>. An ongoing goal of this research is to guide the selection of standards and reference implementations for Grid Information Retrieval (GIR) applications <ref type="bibr" coords="1,151.83,513.84,10.95,8.95" target="#b4">[4]</ref>. Prototype GIR applications developed at ARSC help to evaluate theoretical research and gain experience with the capabilities and limitations of existing APIs, middleware, and security requirements. The TREC experiments provide an additional context to test and develop distributed IR technology.</p><p>Prior TREC Terabyte (TB) and Million Query (MQ) Track experiments performed at ARSC have explored the IR performance and search efficiency of result-set merging and ranking across small numbers of heterogeneous systems and large numbers of homogeneous systems. In the 2005 TREC <ref type="bibr" coords="1,197.00,695.82,12.53,8.95">[5]</ref> TB Track <ref type="bibr" coords="1,256.28,695.82,10.93,8.95" target="#b6">[6]</ref>, the ARSC IR group used a variant of the logistic regression merging strategy <ref type="bibr" coords="1,460.78,387.18,10.93,8.95" target="#b7">[7]</ref>, modified for efficiency, to merge results from a metasearchstyle application that searched and merged results from two indexed copies of the GOV2 corpus <ref type="bibr" coords="1,525.49,429.18,10.93,8.95" target="#b8">[8]</ref>. One index was constructed with the Lucene Toolkit and the other index was constructed with the Amberfish application <ref type="bibr" coords="1,438.04,471.18,10.93,8.95" target="#b9">[9]</ref>. For the 2006 TREC <ref type="bibr" coords="1,324.00,485.15,18.08,8.95" target="#b11">[10]</ref> TB Track <ref type="bibr" coords="1,403.23,485.15,16.10,8.95" target="#b12">[11]</ref>, the GOV2 corpus was partitioned into approximately 17,000 collections by grouping documents with identical URL host names <ref type="bibr" coords="1,357.15,527.15,16.10,8.95" target="#b14">[12]</ref>. Each query was searched against every collection and the ranked results from each collection were merged using the logistic regression algorithm used in the 2005 TB track. The large number of document collections used in the 2006 experiment, coupled with the distribution of collection size (measured in number of documents contained) that spanned five orders of magnitude, introduced significant wall-clock, bandwidth, and IR performance problems.</p><p>Follow-up work found that the bandwidth performance could be improved somewhat without sacrificing IR performance by using a simple relation based on collection size to truncate the result sets before merging <ref type="bibr" coords="2,240.21,90.48,16.02,8.95" target="#b15">[13]</ref>.</p><p>The host-name partition of the GOV2 corpus used in 2006 was used again for a distributed IR simulation for the 2007 TREC <ref type="bibr" coords="2,269.94,132.48,18.08,8.95" target="#b16">[14]</ref> MQ track <ref type="bibr" coords="2,115.17,146.52,18.10,8.95" target="#b17">[15]</ref> but the full set of collections could no longer be searched for every query with the resources available because the resources required to complete the track using a distributed collection approach increase as the product of the number of queries and the number of collections searched rather than just the number of queries alone. Consequently, only a small fraction of the host-name collections, comprising less than 20% of the documents in GOV2, was searched <ref type="bibr" coords="2,247.03,272.52,16.12,8.95" target="#b18">[16]</ref>. The collections were chosen according to historical performance in the previous TREC TB Tracks by ranking the collections in decreasing order of total number of "relevant" relevance judgments (qrels) associated with their respective documents and the top 100 collections were searched.</p><p>For the 2008 MQ track, the ARSC IR group ran several resource-selection experiments on the host-partitioned GOV2 collection. The purpose of each experiment was similar in motivation to the 2007 MQ experiment: quickly identify the collections most likely to be relevant to the queries, then search only the top 50 relevant collections, and finally merge the retrieved results into a single relevance-ranked list. The union of the largest 50 of 996 host-name collections available in the experiment contains less than 10% of the total documents in GOV2 so each MQ topic search was restricted to about a tenth of the GOV2 collection.</p><p>Each collection-ranking technique was based on a virtual "big document" representation of each collection relative to a fixed basis of terms. One of two document relevance-ranking algorithms was modified to relevance-rank the document collections or resources before sending the MQ track queries to the Multisearch application: the conventional vector space model (VSM) <ref type="bibr" coords="2,101.10,678.47,18.07,8.95" target="#b19">[17]</ref> or Latent Semantic Indexing (LSI) <ref type="bibr" coords="2,267.90,678.47,16.09,8.95" target="#b20">[18]</ref>. Prior work on resource selection techniques using variations of standard document retrieval algorithms applied to big-document representations of collections or resources is discussed in <ref type="bibr" coords="2,378.42,104.51,10.90,8.95" target="#b2">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System description</head><p>Our goal for the 2008 MQ track was to efficiently search a large number of document collections using the Multisearch distributed IR research system developed at ARSC. Each document collection provides a search service to the Multisearch portal. The bandwidth cost for each query is approximately proportional to the number of document collections available and this bandwidth cost is split between the transmission of the query to the document collections and the transmission of the response from each document collection. Therefore, reducing the number of collections searched for each query was important. A resource or collection-selection algorithm was developed to restrict each search to a small number of presumably relevant document collections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multisearch</head><p>Multisearch 2.0 is coded entirely in Java with Apache Tomcat and OGSA-DAI WSI 2.2 as middleware. Tomcat is a servlet container, and it is also a necessary piece of architecture for OGSA-DAI. OGSA-DAI is a middleware for grid services, and it was used because it enables quick, easy launching of literally hundreds of backend web services using Axis. OGSA-DAI also provides methods of searching secured information by having structures for grid credentials, although we did not utilize this ability.</p><p>Three different servers were used for the TREC runs. Snowy is a Sun x4500 machine with two dual core Opteron processors at 2.6 GHz with 16 GB of memory and 48 TB of disk space, and it runs Ubuntu Linux 7.10. Pileus is an ASL server with two hyperthreaded Xeon 3.6 GHz CPUs, 8 GB of memory, and 7 TB of disk space. It also runs Ubuntu 7.10. Finally, Nimbus is a Sun v20z with two Opteron processors at 2.2 GHz with 12 GB of memory and 73 GB of disk space. It runs Fedora Core 9. Snowy has the majority of the back ends loaded onto it due to its disk space and speed. It had 873 back end services running, all loaded from the OGSA-DAI architecture. Pileus hosted the remaining 121 back ends. Nimbus ran the frontend client, so all the back ends had to transfer data back and forth over the network.</p><p>A query is sent over the network to any number of backend services, as shown in Figure <ref type="figure" coords="3,280.45,481.19,3.79,8.95" target="#fig_0">1</ref>. Each service has at least one Data Service Resource (DSR), although some might have multiple resources available. A DSR provides access and to the data within the service, as well as the appropriate methods of getting that data, including a credential system if necessary. In the case of Multisearch, each service was in fact its own search engine. It takes the query and passes it to the DSR which runs the query against the data, compiling a result set to be returned to the requesting query. Multisearch had a minimum result set requirement of five and a maximum result set of twenty. If a result set had too many results, only the first twenty would be taken. If there were not enough results, then none would be returned.</p><p>After the result set is completed, it is sent back to the Multisearch front end over the network. There, it is combined with the other result sets from the other back ends. This requires the work of a merge algorithm. In our experiments, we used Naïve Merge (or "log merge" in <ref type="bibr" coords="3,381.78,155.63,17.53,8.95" target="#b14">[12]</ref>) to bring results together. Essentially, Multisearch takes the separate result sets and attempts to merge them into one final, reasonable result set. After this, the final set is produced to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Resource selection</head><p>The resource selection component of Multisearch described can relevance-rank many minimally cooperative document collection servers that provide a typical "search" interface that accepts text queries. To build the data set used by the resource selection component, the number of document hits in each collection for each potential query term is required. This data could, at least in principle, be constructed by searching each document collection one basis term (defined below) at a time through the search interface provided by the document collection server but in this experiment the indexed document collections were directly accessed to build the resourceselector data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Vector representation of resources</head><p>The search resources, or back ends, in this experiment were Lucene indexes built from nearly 1,000 of the largest host-name document collections in the GOV2 corpus. Collection size is defined here as the number of unique documents contained in a document collection. The largest 1,000 host-name collections in GOV2 contain approximately 21 million documents out of a total of 25 million GOV2 documents. For each of the 10,000 topics in the 2008 MQ Track, collections were ranked in decreasing order of relevance to the query. Once the collections were ranked for each query, the ranked lists of collections were read by the Multisearch application and each search was sent to a restricted set of the top 50 relevant collections.</p><p>Although the ranked TREC 17 Million Query Track NOTEBOOK: Multisearch and resource selection 4 / 10 resource lists were pre-computed for all queries before using the Multisearch system to generate TREC result sets, it is straightforward to modify Multisearch to dynamically select resources as each query is received.</p><p>A set of Lucene-indexed host-name document collections for each fully qualified host name found in the document location fields of the GOV2 documents was available from prior TREC TB track experiments <ref type="bibr" coords="4,185.80,202.50,16.63,8.95" target="#b14">[12,</ref><ref type="bibr" coords="4,211.17,202.50,12.47,8.95" target="#b18">16]</ref>.</p><p>A "termdocument" matrix was constructed and saved for each of the 996 n = Lucene-indexed collections using Matlab, the Distributed Computing Toolkit, and Lucene through the Matlab-JAVA external interface on the Midnight Sun Opteron Cluster at ARSC. The row of each matrix corresponded to a document in the collection and each column corresponded to a term in a term basis. Matrix entries corresponding to a (document, term) pair were assigned '1' if the term occurred in the document and '0' otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Term basis</head><p>The term basis in one-to-one correspondence with the columns of each term-document matrix was constructed by taking the union of the English terms in the SCOWL wordlist <ref type="bibr" coords="4,205.46,440.52,18.09,8.95" target="#b21">[19]</ref> and removing the terms that did not retrieve any document in the n document collections. Note that variations in suffix or punctuation were not filtered from the term basis. The size of the filtered term basis was 401, 200 p = terms so each document-term matrix corresponding to a document collection had the same number of columns (terms) as the other document-term matrices but the number of rows (documents) of each matrix varied with the number of documents in the corresponding document collection. Finally, the column sum of each matrix was taken to form a single row or big document vector for each collection and the row vectors were stacked to form a single collection term matrix. The entries in each big document vector are the number of documents in the collection containing the corresponding term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Resource ranking</head><p>Let A % be the n p × collection-term matrix described above and A be the matrix formed by centering and normalizing the columns of A % to unit length. A query q is represented by a 1 p × row vector by setting the column entries corresponding with the query terms to one and setting all other entries to zero. Then a vector of cosine similarity scores can be calculated for the big-document collections relative to a query analogous to calculating a vector of document similarity scores in the canonical vector space model <ref type="bibr" coords="4,356.51,328.50,18.07,8.95" target="#b19">[17]</ref> by forming the vector-matrix product</p><formula xml:id="formula_0" coords="4,325.50,338.23,48.37,14.77">VSM ′ s =qA .</formula><p>Following the notation and definitions of similarity scores summarized in <ref type="bibr" coords="4,491.72,370.50,16.13,8.95" target="#b23">[20]</ref>, only substituting "collection big documents" for "documents," the similarity model can be augmented by introducing the term-correlation matrix R in the query-document inner product as in the generalized vector space model. The similarity model can be augmented yet again by replacing the term correlation matrix with the reduced rank k term-correlation matrix k R , as in Latent Semantic Indexing <ref type="bibr" coords="4,451.03,496.50,16.08,8.95" target="#b20">[18]</ref>, and then by calculating the product LSI k ′ s =qR A . The matrix</p><formula xml:id="formula_1" coords="4,325.86,520.62,54.88,14.46">2 k k k k = ′ Σ R D D</formula><p>is a product of matrices from the reduced rank-k singular value decomposition of the collection-term matrix </p><formula xml:id="formula_2" coords="4,324.00,548.23,216.04,42.79">k k k ′ = A T Σ D where k T is the n k × orthogonal matrix of left singular vectors, k Σ is the k k × diagonal</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Resource-level observations</head><p>The degree to which redundant information exists at all in the collection-term matrix is unknown, so it is not immediately clear that the dimensionreduction approach in LSI will aid in selecting document collections that are rich with documents relevant to a query. Furthermore, the specialization of web host-name document collections may not be sufficient to use a document-sum of keyword counts to identify collections containing documents relevant to a few query terms. Anecdotal evidence presented in Figure <ref type="figure" coords="5,107.04,516.00,3.79,8.95" target="#fig_2">2</ref>, a projection of the collection bigdocument vectors onto the vector space spanned by two of the largest (in the singular value sense) eigenvectors of the host-name collection correlation matrix, shows that a dimension reduction approach may be useful in classifying document collections using document sums of key words.</p><p>In particular note that collections with (presumably) many documents relating to human health, like a National Institutes of Health website nihlibrary.nih.gov and the Centers for Disease Control and Prevention main site www.cdc.gov, are the collection-vector components with the largest magnitude coefficients in eigenvector 7; while collections likely to contain many documents on the microbiological effects of chemical compounds, such as a Brookhaven National Laboratory site xxx.bnl.gov or the Environmental Protection Agency main site www.epa.gov, are among the largest coefficients of eigenvector 9. One important limitation to this approach is also evident: the large coefficient associated with the US Census Bureau site www.census.gov on the same axis defined by sites with pages on microbiological research is not readily explained by term associations. The largest coefficients of eigenvectors 5 and 7 of the collection correlation matrix and their associated collection names are listed in Table <ref type="table" coords="5,386.41,328.49,3.80,8.95">1</ref>.</p><p>Note a few practical considerations when working with matrix factorizations of collectionterm matrices similar to the one described here. In this experiment the sparse collection-term matrix A was about 10% dense so approximately 6 40 10 × integers were required for storage but the full-rank matrices of left and right singular vectors are dense so the minimum storage required is about 8 <ref type="bibr" coords="5,353.46,454.78,4.76,8.56" target="#b4">4</ref> 10 × floating-point numbers; or if double precision is used about 3.2 GB, near the current maximum available RAM in commodity workstations. The storage required to write the dense reduced-rank matrix factors is linear in the parameter k, set to 150 in this experiment, so the matrix factorizations required about 500 MB to store. About one hour of CPU time and 50 GB of RAM on a x4600 node of the Midnight cluster at ARSC were required to calculate the SVD of the collection-term matrix and the term-correlation matrix with Matlab R2007a. This calculation needs to be made only once unless additional documents or document collections are added to the system.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment description and results</head><p>The TREC 2008 MQ results reported here are from the first use of the Multisearch demonstration system in a TREC task and are the first significant tests of the Multisearch resource selection component.</p><p>The document collections were ranked using the resource selection algorithms described above and the ranked document collection lists were sent with the unmodified MQ queries to the Multisearch system for document search and retrieval. Most of the 996 indexed document collections were available to the Multisearch system at the time of the experiments, but the set of collections actually used varied somewhat from experiment to experiment due to minor technical problems.</p><p>Two types of experiments were performed: dynamic resource selection for each query and static resource selection for a composite query.</p><p>In the dynamic resource selection runs, lsi150dyn and vsmdyn, a ranked list of document collections was generated for each MQ track query that was mapped to a vector in the vector space spanned by the term basis as described above. In the lsi150dyn experiment, the collections were ranked with respect to each query by calculating the latent semantic indexing similarity score LSI s for 150 k = dimensions and in the vsmdyn experiment the collections were ranked by calculating the canonical vector space similarity score VSM s . For the static resource selection runs: lsi150stat, vsmstat, and vsm07stat; a composite query formed by mapping each MQ query to a vector in the term basis and taking the vector sum of the query vectors was used to generate a single ranked list of document collections for all of the MQ queries. The collections were ranked with this composite query by forming the respective vector-matrix products and the highest-ranked collections were searched for all MQ queries. In the lsi150stat and vsmstat experiments, the composite query was calculated from the 2008 MQ queries and in vsm07stat, the composite query was calculated using the 2007 MQ queries. Queries from a previous MQ track were used in the vsm07stat experiment to test the sensitivity of IR performance to the resource selection component of Multisearch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multisearch system performance</head><p>One issue in a large, distributed system is time required between entering a query and receiving results. Searching one large index can take time, but searching multiple indexes and merging results together can take even more time, causing a delay in retrieving results. In a world where users are used to results in less than a second, this can make GIR impossibly slow. For this reason, Multisearch uses restriction algorithms to limit the number of back-end services to be searched for a particular query. This decreases the time spent sending information over the network, but we hope that it also reduces noisy data as well.</p><p>The TREC runs were all done with a limit of fifty back ends, which were selected by various restriction algorithms relative to the query. After the services were limited to fifty, each query took approximately three to five seconds to run. This includes time sending information back and forth over the network, merging the results, and printing the results to disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Resource selection performance</head><p>Estimating the performance of the resource selection component separate from the Multisearch system in a meaningful way is not possible using the estimated AP alone due to the dependence of the metric on the underlying document retrieval algorithm. However, the performance of the resource selection component could be estimated at the relevance judgment (qrel) level, for instance, by treating each ranked list of document collections as "hits" and judging each document-collection hit as relevant if the collection contains a relevant qrel. Then several document-retrieval performance measures such as AP could be extended naturally to include resource-selection performance under the assumption that the resource selection performance will serve as an upper bound of the retrieval performance of the Multisearch system as a whole. (See <ref type="bibr" coords="7,161.61,496.50,18.07,8.95" target="#b18">[16]</ref> for an analysis of the distribution of TREC Terabyte track qrels among the GOV2 host-name collections.) Estimating the performance of the resource selector is an area of future work but a few descriptive parameters relevant to the resource selection algorithm used here are summarized below.</p><p>Each document collection is represented as a "big document" vector in a fixed vector space of terms so the distribution of the number of nonzero elements in each big-document vector (plotted in Figure , central tendency summarized in Table <ref type="table" coords="7,117.53,664.49,4.68,8.95" target="#tab_1">2</ref>) is important, combined with the distribution of collection sizes <ref type="bibr" coords="7,246.32,678.47,16.09,8.95" target="#b15">[13]</ref>, in determining how likely a random query will be relevant to any particular collection and how   likely any two collections will be similar to each other in the sense of the inner product.</p><p>About 50,000 terms from the SCOWL wordlist are contained in at least one document in each collection and about 400,000 terms are contained in at least one document in the largest 1,000 host-name collections in GOV2. Consequently, each big-document vector is approximately 10% dense. No attempt was made to stem the wordlist before forming the term basis so the stemmed term counts will be less than reported here but the matrix density is not likely to change significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Document retrieval performance</head><p>The minimal test collection estimated average precision (mtcAP) and (statAP) performance metrics applied to the five experiment runs submitted by ARSC are summarized in Table <ref type="table" coords="8,280.39,328.50,3.80,8.95" target="#tab_2">3</ref>. The probability distribution and cumulative probability distribution functions of mtcAP from the ARSC 2008 MQ experiments are plotted in Figure <ref type="figure" coords="8,106.99,384.48,23.52,8.95">along</ref> with the estimated distributions of the TREC participant median performance. As in prior years, the ARSC system performance is below the TREC median, due in part to the additional difficulty involved in a federated search and also to the relative weakness of the base "demonstration" search application distributed with the Lucene Toolkit.</p><p>The main result is that the dynamic resource selection runs, lsi150dyn and vsmdyn, perform significantly better than the static resource selection runs, lsi150stat, vsmstat, and vsm07stat.</p><p>There is no clear performance advantage to either the latent semantic indexing or the canonical vector space model methods of ranking document collections in either of the dynamic or static resource selection experiments. While the vector space model appears to perform slightly better than latent semantic indexing, the set of document collections used in the two experiments differed by about 10 collections and could result in a slight difference in retrieval performance alone.</p><p>The dynamic resource selection runs did not perform as well as the historical resource selection run ffind07d <ref type="bibr" coords="8,509.64,244.49,18.03,8.95" target="#b18">[16]</ref> in the 2007 MQ track, where the collections were ranked according to the number of relevant TB track qrels contained in each collection; however, about twice as many collections and documents were searched in ffind07d than in any of the experiment runs reported here.</p><p>A secondary result is that selecting document collections to search from the top of a list of document collections ranked relative to an aggregate of several thousand queries is not effective. Note that the run vsm07stat, where the collections were ranked relative to an aggregate query formed from the MQ 2007 queries performed just as well as the static runs where the aggregate query was formed from the same set of queries that was used to search the collections. This could imply that there is very little variation in the total term counts of the MQ 2007 and the MQ 2008 queries or that the set of collections relevant to the aggregate query is not particularly relevant to any particular query. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Summary and Future Work</head><p>The Multisearch system is currently performing at three to five seconds per query, but this is still a long wait for results. Furthermore, the searches were over 50 services, rather than the possible 996 services. One possible exploration is the best number at which to limit the searches. Multisearch is also tied down to Tomcat and has been for quite a while. Multisearch 3.0 aims to be separate from web services, although include them as an additional (but not required) middleware.</p><p>Additional back end search capability is needed, as the Lucene demonstration search application is a significant limiting factor of the Multisearch retrieval performance.</p><p>To improve IR performance, the Indri search engine, part of the Lemur toolkit, will be added Multisearch back-end search service. The size of the term basis used for the resource selection component adversely affects memory and compute time usage when performing matrix factorizations and computations on the termcollection matrix or the term correlation matrix. Stemming the term basis, compiled from the SCOWL wordlist, is the first step to making the singular value decomposition of the collectionterm matrix more accessible to typical commodity workstations. Additional theoretical work could be pursued on incorporating collection-ranks in the document result-set merging step. The sensitivity of document retrieval performance to the dimension parameter k in Latent Semantic Indexing similarity ranking will be explored.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,331.80,655.18,201.03,8.77;2,331.80,667.36,201.07,8.77;2,331.80,679.60,201.05,8.77;2,331.79,691.78,200.99,8.77;2,331.79,704.02,28.08,8.77;2,333.30,431.22,194.40,208.74"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Schematic of the ARSC Multisearch system. The resource selector is contained in the Multisearch front-end block and the host-name document collections are contained in the data blocks.</figDesc><graphic coords="2,333.30,431.22,194.40,208.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,463.91,580.50,76.04,8.95;4,324.00,594.48,48.78,8.95;4,385.50,599.69,2.62,5.31;4,377.88,594.11,65.25,9.31;4,431.64,590.83,108.33,12.59;4,324.00,608.52,93.58,8.95;5,72.00,735.10,313.65,8.77;5,516.42,735.10,23.62,8.77"><head></head><label></label><figDesc>matrix of singular values, and k D is the p k × orthogonal matrix of right singular vectors. TREC 17 Million Query Track NOTEBOOK: Multisearch and resource selection 5 / 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,79.20,250.00,200.89,8.77;5,79.20,262.24,200.87,8.77;5,79.20,274.42,200.91,8.77;5,79.20,286.66,200.95,8.77;5,79.20,298.84,200.94,8.77;5,79.20,311.08,200.95,8.77;5,79.20,323.26,159.48,8.77"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Projection of host-name collection bigdocument vectors onto eigenvectors 7 and 9 of the collection correlation matrix as calculated by the SVD of the basis term by big-document matrix. The number of documents in each collection is represented by color and a nonlinear color scale is used to enhance contrast.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,331.92,625.78,200.91,8.77;7,331.92,638.02,200.90,8.77;7,331.92,650.20,200.93,8.77;7,331.92,662.44,200.95,8.77;7,331.92,674.62,121.19,8.77;7,469.62,674.62,63.25,8.77;7,331.92,686.86,200.92,8.77;7,331.92,699.04,72.66,8.77"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Probability distribution function (top) and cumulative probability distribution function (bottom) of the minimal test collection estimated AP from the ARSC MQ results and TREC participant median results.Plotted points represent centers of the logarithmically spaced and sized AP bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,331.92,232.48,196.51,8.77;7,331.92,244.66,187.81,8.77;7,331.92,256.90,185.28,8.77;7,331.92,269.08,85.83,8.77"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Probability distribution function of the number of unique basis terms drawn from the SCOWL wordlist contained in each host-name document collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="11,178.92,463.12,119.01,7.30;11,178.92,472.30,115.60,6.90;11,178.92,481.10,113.62,6.90;11,178.92,489.90,123.18,6.90;11,178.92,498.70,111.94,6.90;11,178.92,507.50,21.67,6.90;11,179.03,324.95,122.66,131.18"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Schematic of the ARSC Multisearch system. The resource selector is contained in the Multisearch frontend block and the host-name document collections are contained in the data blocks.</figDesc><graphic coords="11,179.03,324.95,122.66,131.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="11,441.14,441.12,101.01,7.30;11,441.14,450.30,110.60,6.90;11,441.14,459.10,113.95,6.90;11,441.14,467.90,116.73,6.90;11,441.14,476.70,113.50,6.90;11,441.14,485.50,117.53,6.90;11,441.14,494.30,108.15,6.90;11,441.14,503.10,109.65,6.90;11,441.14,511.90,14.57,6.90"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Probability distribution function (top) and cumulative probability distribution function (bottom) of the minimal test collection estimated AP from the ARSC MQ results and TREC participant median results. Plotted points represent centers of the logarithmically spaced and sized AP bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="11,441.14,525.33,99.83,7.30;11,441.14,534.51,103.13,6.90;11,441.14,543.31,109.78,6.90;11,441.14,552.11,116.26,6.90;11,441.14,560.91,32.00,6.90"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Probability distribution function of the number of unique basis terms drawn from the SCOWL word list contained in each document collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,72.00,577.47,464.33,77.23"><head>Table 2 .</head><label>2</label><figDesc>Average number of SCOWL basis terms per host-name document collection used in the experiment. Also listed is the average number of document collections and documents containing each basis term.</figDesc><table coords="8,361.38,577.47,126.48,8.77"><row><cell>Median</cell><cell>Standard deviation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,72.00,204.70,467.98,21.01"><head>Table 3 .</head><label>3</label><figDesc>Minimal test collection estimated AP for the ARSC MQ experiment runs and the TREC participant summary statistics.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Selected eigenvectors with color used to distinguish individual eigenvectors (c). In (a-c) the eigenvector components with magnitude greater than 2/3 have been labeled with the associated GOV2 host names. Projections of the document collection vectors onto the planes spanned by selected pairs of eigenvectors (d-f) where the projected vectors with magnitude greater than 3/20 have been labeled with the associated host names. The size (in number of contained documents) of each labeled collection is represented on a logarithmic color scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eigenvector representation of document collections</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>Vector representation of document collections may be used to improve minimally cooperative federated search efϐiciency by selecting a fraction of available collections likely to contain relevant documents.</p><p>Retrieval performance of federated search that is constrained to a fraction of available collections for each query may be improved by restricting each search using variants of the vector space similarity model (VSM) or latent semantic indexing (LSI).</p><p>Targeted federated search using VSM or LSI to relevance-rank document collections to each query yields comparable retrieval performance surpassing the performance of federated search on a set of document collections relevance-ranked to a single aggregate query. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,328.63,253.62,65.29,10.50" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,276.38,3.42,8.04;9,359.99,276.38,152.36,8.04;9,360.00,286.94,177.54,8.04;9,360.00,297.50,162.91,8.04" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,480.66,276.38,31.70,8.04;9,360.00,286.94,153.75,8.04">Building efficient and effective metasearch engines</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,519.54,286.94,18.00,8.04;9,360.00,297.50,72.62,8.04">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="49" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,308.06,3.42,8.04;9,360.01,308.06,173.33,8.04;9,360.00,318.62,168.61,8.04;9,360.00,329.18,166.86,8.04;9,360.00,339.68,41.79,8.04" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,381.36,308.06,151.99,8.04;9,360.00,318.62,115.71,8.04">Federated Search of Text Search Engines in Uncooperative Environments</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,491.40,318.62,37.21,8.04;9,360.00,329.18,75.45,8.04">Language Technology Institute</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,350.24,3.42,8.04;9,360.00,350.24,148.86,8.04;9,360.00,360.80,138.62,8.04;9,360.00,371.36,165.72,8.04;9,360.00,381.92,71.53,8.04" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,467.88,350.24,40.98,8.04;9,360.00,360.80,138.62,8.04;9,360.00,371.36,38.93,8.04">Evaluating Sampling Methods for Uncooperative Collections</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,414.00,371.36,18.74,8.04">SIGIR</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,392.48,3.42,8.04;9,359.99,392.48,161.99,8.04;9,360.00,402.98,172.91,8.04;9,360.00,413.54,149.12,8.04" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,505.86,392.48,16.12,8.04;9,360.00,402.98,172.91,8.04;9,360.00,413.54,75.93,8.04">Grid Information Retrieval Requirements (GFD.27). in Global Grid Forum</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gamiel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nassar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Lamont, IL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,424.10,3.42,8.04;9,360.00,424.10,165.76,8.04;9,360.00,434.66,166.44,8.04;9,360.00,445.22,150.24,8.04;9,360.00,455.78,58.33,8.04" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,411.06,424.10,66.34,8.04">Overview of TREC</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,511.68,424.10,14.07,8.04;9,360.00,434.66,138.72,8.04">The Fourteenth Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,466.34,3.42,8.04;9,360.00,466.34,166.69,8.04;9,360.00,476.84,147.21,8.04;9,360.00,487.40,154.08,8.04;9,360.00,497.96,164.59,8.04" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<title level="m" coord="9,469.26,466.34,57.42,8.04;9,360.00,476.84,55.55,8.04;9,430.98,476.84,76.23,8.04;9,360.00,487.40,76.50,8.04">The Fourteenth Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publications</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>The TREC 2005 Terabyte Track</note>
</biblStruct>

<biblStruct coords="9,327.42,508.52,3.42,8.04;9,360.01,508.52,159.31,8.04;9,360.00,519.08,137.68,8.04;9,360.00,529.64,160.21,8.04;9,360.00,540.20,94.22,8.04" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,450.36,508.52,68.95,8.04;9,360.00,519.08,133.98,8.04">Database merging strategy based on logistic regression</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Calvé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,360.00,529.64,155.50,8.04">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,550.70,3.42,8.04;9,360.00,550.70,179.13,8.04;9,360.00,561.26,172.17,8.04;9,360.00,571.82,153.29,8.04;9,360.00,582.38,169.14,8.04;9,360.00,592.94,112.64,8.04" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,467.34,550.70,71.79,8.04;9,360.00,561.26,172.17,8.04;9,360.00,571.82,24.92,8.04">Logistic Regression Merging of Amberfish and Lucene Multisearch Results</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Fallen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,400.02,571.82,113.27,8.04;9,360.00,582.38,39.53,8.04">The Fourteenth Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publications</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,327.42,603.50,3.41,8.04;9,359.99,603.50,147.38,8.04" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,402.00,603.50,84.41,8.04">Amberfish at the TREC</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nassar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,360.00,614.06,145.47,8.04;9,360.00,624.56,154.08,8.04;9,360.00,635.12,164.59,8.04" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Terabyte</forename><surname>Track</surname></persName>
		</author>
		<title level="m" coord="9,430.98,614.06,74.49,8.04;9,360.00,624.56,76.50,8.04;9,466.15,624.56,47.93,8.04;9,360.00,635.12,46.10,8.04">The Thirteenth Text REtrieval Conference</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>NIST Special Publications</note>
</biblStruct>

<biblStruct coords="9,331.88,645.68,3.94,8.04;9,360.00,645.68,167.18,8.04;9,360.00,656.24,151.50,8.04;9,360.00,666.80,134.20,8.04;9,360.00,677.36,69.73,8.04" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,409.20,645.68,66.34,8.04">Overview of TREC</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,509.82,645.68,17.36,8.04;9,360.00,656.24,123.78,8.04">15th Annual Text REtrieval Conference</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,331.88,687.92,3.94,8.04;9,360.00,687.92,171.18,8.04;9,360.00,698.42,172.67,8.04;10,72.00,735.10,313.65,8.77;10,511.32,735.10,28.72,8.77" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,473.70,687.92,57.48,8.04;9,360.00,698.42,172.67,8.04;10,72.00,735.10,313.65,8.77">The TREC 2006 Terabyte Track. in 15th Annual Text REtrieval TREC 17 Million Query Track NOTEBOOK: Multisearch and resource selection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Buttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.00,74.48,152.04,8.04;10,108.00,85.04,171.31,8.04" xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">(</forename><surname>Conference</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Trec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<publisher>NIST</publisher>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,79.88,95.60,3.94,8.04;10,108.01,95.60,167.06,8.04;10,108.00,106.16,155.47,8.04;10,108.00,116.66,178.76,8.04;10,108.00,127.22,174.01,8.04;10,108.00,137.78,164.59,8.04" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,215.34,95.60,59.73,8.04;10,108.00,106.16,155.47,8.04;10,108.00,116.66,113.29,8.04">Partitioning the Gov2 Corpus by Internet Domain Name: A Resultset Merging Experiment</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Fallen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,236.88,116.66,49.88,8.04;10,108.00,127.22,96.28,8.04">The Fifteenth Text REtrieval Converence</title>
		<meeting><address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publications</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,79.88,148.34,3.94,8.04;10,108.01,148.34,168.54,8.04;10,108.00,158.90,178.64,8.04;10,108.00,169.46,173.17,8.04;10,108.00,180.02,30.05,8.04" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,215.34,148.34,61.20,8.04;10,108.00,158.90,178.64,8.04;10,108.00,169.46,10.07,8.04">Distributed Web Search Efficiency by Truncating Results, in JCDL &apos;07</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Fallen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,147.20,169.46,61.17,8.04">ACM: Vancouver</title>
		<meeting><address><addrLine>British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,79.88,190.52,3.94,8.04;10,108.00,190.52,167.18,8.04;10,108.00,201.08,151.51,8.04;10,108.00,211.64,134.20,8.04;10,108.00,222.20,69.73,8.04" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,157.20,190.52,84.92,8.04">Overview of TREC 2007</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,257.82,190.52,17.36,8.04;10,108.00,201.08,123.78,8.04">16th Annual Text REtrieval Conference</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,79.89,232.76,3.94,8.04;10,108.01,232.76,147.65,8.04;10,108.00,243.32,149.81,8.04;10,108.00,253.88,146.15,8.04;10,108.00,264.38,126.95,8.04" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,160.32,232.76,95.34,8.04;10,108.00,243.32,32.57,8.04">Million Query Track 2007 Overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,156.12,243.32,101.69,8.04;10,108.00,253.88,39.53,8.04">16th Annual Text REtrieval Conference</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,79.88,274.94,3.94,8.04;10,108.01,274.94,144.49,8.04;10,108.00,285.50,171.42,8.04;10,108.00,296.06,159.41,8.04;10,360.00,74.48,150.07,8.04;10,360.00,85.04,171.31,8.04" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,215.34,274.94,37.16,8.04;10,108.00,285.50,171.42,8.04;10,108.00,296.06,71.24,8.04">Collection Selection Based on Historical Performance for Efficient Processing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">T</forename><surname>Fallen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Newby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,194.58,296.06,72.83,8.04;10,360.00,74.48,87.13,8.04">16th Text REtrieval Conference (TREC2007)</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,331.88,95.60,3.94,8.04;10,360.01,95.60,158.75,8.04;10,360.00,106.16,177.43,8.04;10,360.00,116.66,157.20,8.04;10,360.00,127.22,145.64,8.04;10,360.00,137.78,156.49,8.04;10,360.00,148.34,151.64,8.04;10,360.00,158.90,30.05,8.04" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,360.00,106.16,177.43,8.04;10,360.00,116.66,30.82,8.04">Generalized vector spaces model in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K M</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ziarko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C N</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,405.78,116.66,111.42,8.04;10,360.00,127.22,145.64,8.04;10,360.00,137.78,156.49,8.04;10,360.00,148.34,30.82,8.04">Proceedings of the 8th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 8th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Montreal</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,331.88,169.46,3.94,8.04;10,360.00,169.46,150.65,8.04;10,360.00,180.02,162.11,8.04;10,360.00,190.52,172.45,8.04;10,360.00,201.08,43.57,8.04" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,440.76,169.46,69.89,8.04;10,360.00,180.02,65.51,8.04">Indexing by Latent Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,431.10,180.02,91.01,8.04;10,360.00,190.52,117.99,8.04">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,331.89,211.64,3.94,8.04;10,360.02,211.64,159.29,8.04" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="10,407.94,211.64,83.39,8.04">Kevin&apos;s Word List Page</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Atkinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,360.00,222.20,105.09,8.04;10,360.00,232.76,127.78,8.04" xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Aug</surname></persName>
		</author>
		<ptr target="http://wordlist.sourceforge.net/" />
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,331.88,243.32,3.94,8.04;10,360.01,243.32,164.11,8.04;10,360.00,253.88,174.96,8.04;10,360.00,264.38,175.38,8.04;10,360.00,274.94,142.70,8.04" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,398.28,243.32,125.84,8.04;10,360.00,253.88,117.18,8.04">Eigenvaluebased model selection during latent semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,482.94,253.88,52.02,8.04;10,360.00,264.38,175.38,8.04;10,360.00,274.94,42.29,8.04">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="969" to="988" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
