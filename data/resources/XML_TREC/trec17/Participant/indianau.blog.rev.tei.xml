<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,82.82,75.37,446.08,12.64;1,280.37,91.47,51.47,12.64">WIDIT in TREC-2008 Blog Track: Leveraging multiple sources of opinion evidence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,281.45,120.18,49.10,8.96"><forename type="first">Kiduk</forename><surname>Yang</surname></persName>
							<email>kiyang@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Library and Information Science</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>Indiana</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,82.82,75.37,446.08,12.64;1,280.37,91.47,51.47,12.64">WIDIT in TREC-2008 Blog Track: Leveraging multiple sources of opinion evidence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F831B291ACE0DD849F8CDB7F2A0222DF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Indiana University"s WIDIT Lab<ref type="foot" coords="1,220.25,198.91,3.48,6.26" target="#foot_0">1</ref> participated in the Blog track"s opinion task and the polarity subtask, where we combined multiple opinion detection methods to leverage a variety of complementary evidences rather than trying to optimize the utilization of a single source of evidence.</p><p>To address the weakness of our past topical retrieval strategy, which generated mediocre baseline results with short queries (i.e., title only queries), we explored Web-based query expansion (WebX) methods to increase the initial retrieval performance for the short query. Our WebX methods consisted of the Google module, which harvests expansion terms from Google search results using various term selection methods, and Wikipedia module, which extracts noun phrases and related terms from Wikipedia articles and Wikipedia thesaurus. Web-expanded queries were combined using ad-hoc heuristics based on observation, trial and error, and some basic assumptions regarding quality of individual WebX methods.</p><p>For opinion detection, we leveraged the complementary opinion evidences of Opinion Lexicon (e.g., suck, cool), Opinion Collocation (e.g., I believe, to me), and Opinion Morphology (e.g., sooooo, metacool) in the form of semi-automatically constructed opinion lexicons. In creating the opinion lexicons, we extracted terms from external sources (e.g., IMDb movie reviews and plot summaries) as well as the blog collection. Opinion lexicons were utilized by opinion scoring modules to compute opinion scores of documents, and the combined opinion score in conjunction with the on-topic retrieval score was used to boost the ranks of opinionated documents. To optimize the fusion formula for combining opinion and polarity scores, WIDIT used the "Dynamic Tuning Interface", an interactive system optimization mechanism that displays the effects of tuning parameter changes in real time so as to guide its user towards the discovery of a system optimization state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM DEFINITION</head><p>Opinion finding task combines the problems of topical retrieval with opinion detection. The task of finding blogs that express opinion on a given target calls for an approach that can not only retrieve blogs about a target topic but also effectively measure the degree of opinion towards the topic. Opinion classification, which relies on the overall characteristic of a document to classify a document as opinionated without regard to the target of opinion, will produce false results when dealing with largely opinionated documents that contain no opinion towards the target topic (false positive) or mostly factual documents about a target with only brief expressions of opinion (false negative). Therefore, key strategies in opinion finding task are to optimize topical retrieval and to devise an effective opinion detection method that identifies opinion expressions associated with the target topic. For the task of topical retrieval, the strategy should be to optimize the differentiation of topically relevant documents from topically non-relevant ones rather than to optimize the ranking of the documents by the degree of topical relevance. In other words, the topical retrieval should be broad (i.e. recall-oriented) rather than specific (i.e. precision-oriented) with the provision that opinion detection will assist in increasing precision.</p><p>The opinion detection component of a targeted opinion detection system needs to first identify expressions of opinion and then to determine whether detected opinions are about a given target. An intuitive approach is to apply opinion detection at a subdocument level (e.g., paragraph, sentence) and look for the presence of target in proximity. At the subdocument level, opinion classification methods may be used in place of opinion detection since the overall characteristic of a document is strongly influenced by the presence of opinion evidence as a document gets shorter. Even so, the machine learning approach of opinion classification still has to contend with the scarcity of features in a short document. The association of opinion to a target by proximity is likely produce a high rate of true positives but may do so at the cost of false negatives. Opinion expressions that occur outside the proximity window, subdocument boundaries, or near the target that is described in a non-standard manner (e.g., synonyms, anaphors, spelling variations) will not be detected by the proximity method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">METHODOLOGY</head><p>Our approach to targeted opinion detection has two main components: a topical retrieval component and an opinion detection component. The topical retrieval process starts with an initial topic search to retrieve documents about a target topic, after which topical reranking is applied to optimize the ranking of the initial topic search result. The opinion detection component is comprised of multiple opinion scoring modules that leverage different sources of opinion evidence to maximize the coverage of opinion expressions.</p><p>Figure <ref type="figure" coords="2,120.37,324.79,5.52,9.94" target="#fig_0">1</ref> displays the architecture of WIDIT blog opinion retrieval system. On the left side is the topical retrieval component and the right side shows the opinion detection component. The noise reduction, which was shown to be effective in 2007 <ref type="bibr" coords="2,226.73,350.11,118.63,9.94">(Yang, Yu &amp; Zhang, 2007)</ref>, is applied to exclude non-English blogs as well as non-content portions of each blog (e.g., navigation, advertisement). Web-based query expansion is applied to short queries to increase the initial topical retrieval performance, which is optimized by the Topic Reranking Module that utilizes topical clues not leveraged in the initial retrieval. Opinion scores computed by opinion detection modules are combined linearly to produce an overall opinion score of each document, which is used to rerank the topic-reranked results by the estimated degree of opinion. A set of opinion-reranked results with varying parameters (e.g., query expansion, opinion scoring) are combined to produce the final opinion result, to which polarity detection module is applied to generate the polarity result. To optimize topic reranking, opinion reranking, and polarity detection, all of which involve combining a large number of system parameters, we employed an interactive system optimization mechanism called Dynamic Tuning that harnesses human intelligence along with machine processing power in an iterative, bio-feedback like process to facilitate the discovery of local optimum solutions <ref type="bibr" coords="2,512.74,489.21,27.57,9.94;2,72.02,501.93,54.04,9.94" target="#b5">(Yang &amp; Yu, 2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Web-based Query Expansion</head><p>Among the common query expansion strategies of pseudo-feedback, syntactic expansion by thesaurus (e.g., WordNet), and Web-based expansion, we chose the Web-based expansion to strengthen the short queries. Short queries of the blog opinion finding task tend to be one or two word descriptions of target entities and thus do not benefit much by syntactic expansion (e.g., synonym expansion). Pseudo-feedback, which relies on top ranked documents being relevant, can be problematic for short queries that produce poor initial retrieval results due to incomplete descriptions of entities. Web-based expansion, on the other hand, searches much larger external data sources of the Web, and has shown to be an effective query expansion strategy for difficult queries <ref type="bibr" coords="2,197.90,634.44,142.98,9.94" target="#b1">(Kwok, Grunfeld &amp; Deng, 2005)</ref>.</p><p>Our Web-based query expansion (QE) consists of the Wikipedia QE module, which extracts terms from Wikipedia articles and Wikipedia Thesaurus, and the Google QE module, which extends the PIRC approach that harvests expansion terms from Google search results <ref type="bibr" coords="2,369.31,672.36,142.97,9.94" target="#b1">(Kwok, Grunfeld &amp; Deng, 2005)</ref>. The second type of wiki-expanded query consists of Wikipedia title and thesaurus terms. First, n-grams of decreasing length are extracted from the original query by a sliding window (e.g., "computer monitor price", "computer monitor", "monitor price", "computer", "monitor", "price") and checked against Wikipedia to identify phrases. The titles of Wikipedia pages ("e.g., "visual display unit", "price") retrieved by the longest n-grams (e.g., "computer monitor", "price") are then used to find synonyms and related terms from the Wikipedea Thesaurus<ref type="foot" coords="3,208.61,574.08,3.48,6.26" target="#foot_1">2</ref> . Title terms from article pages are given the weight of 1, while title terms from search and disambiguation pages are given reduced weights (e.g., 0.8). The term weights of synonyms are even reduced further (1/2 of title term weights for synonyms, 1/3 for related terms). If the Wikipedia result is not an article, only the synonyms are added to reduce the adverse effect of incorrect expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Google QE (GQE) Module</head><p>While WQE mines the manually constructed knowledge base of Wikipedia, GQE utilizes the rich information on the Web effectively searched by Google to identify related terms. Like WQE, GQE module generates multiple types of google-expanded queries by varying the source and weighting of expansion terms. The first step of GQE is to query Google with the short query and harvest the titles, snippets, and full-texts of the top n search results that are HTML pages. The first type of google-expanded query consists of top k most frequently occurring terms from titles and snippets. The second and third types of google-expanded queries are composed of top k weighted terms from the full-texts of search results, where the term weight is computed by a modified version of the local context analysis (LCA) formula (equation 2) using the original query and a combination of expanded queries.</p><p>The original LCA formula, shown in equation 1, selects expansion terms based on co-occurrence with query terms, co(c,w i ), and their frequency in the whole collection, idf(c), normalized over n <ref type="bibr" coords="4,482.11,175.60,58.03,9.94;4,72.02,188.32,23.80,9.94" target="#b2">(Xu &amp; Croft, 2000)</ref>. The idf component of LCA, which modifies the standard inverse document frequency with an upper bound, estimates the absolute importance of a term by its discriminating value, while the co-occurrence component estimates the relative term importance with respect to a given query. Since the collection frequency is unknown in the Web setting, we use term frequencies normalized by term distance to compensate for the lack of idf. The normalized frequency of term c in document d, is computed by first summing the word distances between occurrences of c and nearest query term w i in d and taking the inverse of its log value. The normalized frequency of query term w i in d is computed in a similar manner by taking the inverse log of the sum of minimum word distances between occurrences of query term w i and c in d. The normalized term frequency modifies the weight of each term occurrence with co-occurrence distance in order to reward terms that occur closer to query terms. (2)</p><formula xml:id="formula_0" coords="4,73.39,327.58,263.56,159.07">) 0 . 5 / ) / ( log , 0 . 1 min( ) ( ) , ( ) , ( ) , ( ) ( log / ) ( ) 1 ) , ( ( log ) , ( deg _ 10 10 10 c S in d i i i i N N c idf d w tf d c tf w c co n c idf w c co w c ree co      (1)           d in w i i norm d in c i norm S in d i norm norm i i i i c w dist d w tf w c dist d c tf d w tf d c tf w c co n w c co w c ree co ) 1 ) , ( (min log 1 ) , ( ) 1 ) , ( (min log 1 ) , ( ) , ( ) , ( ) , ( ) ( log / ) 1 ) , (<label>( log )</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">OnTopic Retrieval Optimization</head><p>Optimizing the results of initial topic search is not only an efficient way to incorporate topical clues (e.g., phrases) not considered in initial retrieval <ref type="bibr" coords="4,267.77,552.81,87.12,9.94">(Yang et. al, 2007;</ref><ref type="bibr" coords="4,359.25,552.81,120.84,9.94" target="#b4">Yang, Yu &amp; Zhang, 2008)</ref>, but also an effective way to supplement the recall-oriented initial retrieval by boosting the precision. The layered approach of first executing a recall-oriented search to produce retrieval results with high recall and then applying a post-retrieval reranking method to increases precision without degrading recall is a practical alternative to single-pass retrieval approaches that attempt to maximize the system performance by minimizing the recall-precision tradeoff <ref type="bibr" coords="4,250.49,616.08,107.45,9.94" target="#b0">(Buckland &amp; Gey, 1994)</ref>.</p><p>Our on-topic retrieval optimization method reranks the initial retrieval results based on a set of topic-related reranking factors, which consist of topical clues not used in initial ranking of documents. The topic reranking factors used in the study are: Exact Match, which is the frequency of exact query string occurrence in document, Proximity Match, which is the frequency of padded 3 query string occurrence in document, Noun Phrase Match, which is the frequency of query noun phrases occurrence in document, and Non-Rel Match<ref type="foot" coords="5,139.70,72.17,3.48,6.26" target="#foot_3">4</ref> , which is the frequency of non-relevant nouns and noun phrase occurrence in documents. All the reranking factors are normalized by document length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Opinion Detection</head><p>Our opinion detection approach, which is entirely lexicon-based to avoid the pitfalls of the machine learning problems, relies on a set of opinion lexicons that leverage various evidences of opinion. The key idea underlying our opinion detection strategy is to rely on a variety of complementary evidences rather than trying to optimize the utilization of a single source of opinion evidence. In keeping with the main research question of the study, we leveraged the complementary opinion evidences of Opinion Lexicon (e.g., suck, cool), Opinion Collocation (e.g., I believe, to me), and Opinion Morphology (e.g., sooooo, metacool) in the form of semi-automatically constructed opinion lexicons. Opinion lexicons are utilized by opinion scoring modules to compute opinion scores of documents, and the combined opinion score in conjunction with the on-topic score is used to boost the ranks of opinionated documents in a manner similar to the on-topic retrieval optimization.</p><p>Opinion scoring modules used in this study are High Frequency module, which identifies opinions based on the frequency of opinion terms (i.e., terms that occur frequently in opinionated documents), Wilson's lexicon module, which uses a collection-independent opinion lexicon based on Wilson"s subjectivity terms, Low Frequency module, which makes use of uncommon/rare terms that express strong sentiments, IU module, which leverages n-grams with IU (I and you) anchor terms (e.g., I believe, You will love), Opinion Acronym module, which utilizes a small set of opinion acronyms (e.g., imho), and Adjective-Verb Module, which uses the density of potential subjective elements learned from training data to determine the subjectivity of documents. Each module except for the Adjective-Verb module computes three types of opinion scores for each lexicon used: a simple frequency-based score, a proximity score based on the frequency of lexicon terms that occur near the query string in a document, and a distance-based score computed as a sum of inverse word distances between lexicon terms and the query string. Equation 3 describes the generalized formula for opinion scoring</p><formula xml:id="formula_1" coords="5,91.47,428.44,173.49,32.73">) ( ) ( ) ( ) ( d len t s t f d opSC D L t      (3)</formula><p>where L and D denote the term sets of a given lexicon and document d respectively, len(d) is the number of tokens in d, s(t) is the strength of term t as designated in the lexicon, and f(t) is the frequency function that returns either the frequency of t in d (simple score), the frequency of t that co-occurs with the query string in d in a fixed-size window (proximity score), the sum of inverse word distances between occurrences of t and the nearest query string (distance score). The proximity score, which is a strict measure that ensures the opinion found is on target, is liable to miss opinion expressions located outside the proximity window as well as those near the target that is expressed differently from the query string. The simple score, therefore, can supplement the proximity score, especially when used in conjunction with the on-topic optimization. The distance score can be thought of as normalized frequency weighted by proximity similar to the normalized frequencies in the modified LCA formula (equation 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Polarity Detection</head><p>For polarity detection, positive and negative polarity scores are first computed by the opinion scoring modules using the score and polarity from lexicons. Equation below describes the generalized formula for computing opinion polarity scores:</p><formula xml:id="formula_2" coords="6,91.47,87.77,173.49,35.14">) ( ) ( ) ( ) ( d len t s t f d opSC D L t pol pol     (4)</formula><p>In equation 4, L pol describes the lexicon term subset whose polarity is pol (positive or negative). The default term polarity from the lexicon is reversed if the term appears near a valence shifter (e.g., not, never, no, without, hardly, barely, scarcely, etc.) in d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">High Frequency Module</head><p>The basic idea behind the High Frequency Module (HFM) is to identify opinions based on common opinion terms. Since common opinion terms, which are words often used to express opinions, occur frequently in opinionated text and infrequently in non-opinionated text, a candidate HF lexicon can be constructed by identifying high frequency terms from the positive training data (i.e., opinionated documents) and excluding those that also have high frequency in the negative training data (i.e., objective documents). The resulting term set can then be manually reviewed to filter out spurious terms and to assign polarity and opinion strength.</p><p>In creating the HF lexicon, we used movie reviews and plot summaries to supplement the blog training data. The blog training data consist of 11,448 on-topic and opinionated (positive sample) and 8,301 on-topic but not opinionated (negative sample) blogs flagged in 2006 blog relevance judgments<ref type="foot" coords="6,490.78,330.82,3.48,6.26" target="#foot_4">5</ref> . Since the quality of blog training data is degraded by document-level relevance judgments that are based on opinion detection rather than opinion classification, we decided to strengthen our lexicon base by adding terms extracted from a high quality sentiment-analysis data such as movie reviews<ref type="foot" coords="6,425.95,368.74,3.48,6.26" target="#foot_5">6</ref> (positive sample) and a harvest of movie plot summaries (negative sample) from the Internet Movie Database<ref type="foot" coords="6,453.55,381.46,3.48,6.26" target="#foot_6">7</ref> (IMDb). The final HF lexicon with 1,559 entries of opinion terms and associated polarity and strength were expanded with morphological variations such as inflections, superlatives, and alternate word forms (e.g., adjective to noun, adjective to adverb).</p><p>In addition to manually determined term weights, a second set of term weights that combine the manual weight with opinion probabilities of terms are computed using the training data. The combined weight formula, which is applied to all the lexicons, is shown in equation 5.</p><formula xml:id="formula_3" coords="6,91.81,485.21,174.24,1038.33">) | ( ) | ( ) ( ) ( ' nopD t p opD t p t wt t wt  (5)</formula><p>In equation 5, the probability of a term t occurring in an opinionated document, p(t|opD), is estimated by the proportion of the documents with t in positive training data (i.e., opinionated documents), and the probability of a term t occurring in a non-opinionated document, p(t|nopD), is estimated by the proportion of the documents with t in negative training data. To compute the combined weight, the manual weight, wt(t), is multiplied by the probabilistic weight to adjust the human judgment of term importance with the training data evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Wilson"s Lexicon Module</head><p>To supplement the HF lexicon, which is collection-dependent and possibly domain-specific, we constructed a set of opinion lexicons from Wilson"s subjectivity terms 8 <ref type="bibr" coords="7,401.95,102.76,85.91,9.94" target="#b6">(Wiebe et. al, 2004</ref>). Wilson's Lexicon Module (WLM) uses three collection-independent lexicons, which consists of 4,747 strong and 2,190 weak subjective terms extracted from Wilson"s subjectivity term list, and 240 emphasis terms selected from Wilson"s intensifiers. Both strong and weak subjective lexicons inherit the polarity and strength from Wilson"s subjectivity terms, but the emphasis lexicon includes neither the strength nor polarity values since the strength and polarity of an emphasis term depend on the term it emphasizes (e.g., absolutely wonderful). In computing opinion scores (equation 3), emphasis terms are assigned the strength of 1, which is the minimum value for term strength. No polarity scores are generated with the emphasis lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.">Low Frequency Module</head><p>While HFM and WLM leverage the most common type of opinion evidence in standard opinion expressions, Low Frequency Module (LFM) looks to low frequency terms for opinion evidence. LFM is derived from the hypothesis that people become creative when expressing opinions and tend to use uncommon or rare term patterns <ref type="bibr" coords="7,217.01,288.91,86.09,9.94" target="#b6">(Wiebe et. al, 2004)</ref>. These creative expressions, or Opinion Morphology (OM) terms as we call it, may be intentionally misspelled words (e.g., luv, hizzarious), compounded words (e.g., metacool, crazygood), repeat-character words (e.g., sooo, fantaaastic, grrreat), or some combination of the three (e.g., metacoool, superrrrv).</p><p>Since OM terms occur infrequently due to their creative and non-standard nature, we started the construction of the OM lexicon by identifying low frequency (e.g., df &lt; 100) terms in the blog collection and excluding those that occur frequently in negative training data. Words with three of more repeated characters in the low frequency term sets were examined to detect repeat-character OM patterns, which were encapsulated in a compilation of regular expressions. Resulting regular expressions (OM regex) were refined iteratively as described below:</p><p>1. Apply OM regex to the low frequency term set.</p><p>2. Examine the results of step 1 to identify the false positives (non-opinion terms captured by OM regex) and false negatives (OM terms missed by OM regex).</p><p>3. Stop if there are no false positives and false negatives converge or fall below a threshold. Otherwise, go to step 2.</p><p>To round out the OM regex, regular expressions that simulate misspellings by vowel substitutions (e.g., luv) and regular expressions for capturing compound morphing were constructed from HF and Wilson terms, applied to the LF term set, and refined iteratively in the same manner as the repeat-character regex described above. LF terms not captured by OM regex but are nevertheless determined to be opinion terms form a basis for the OM lexicon. 352 entries in the final OM lexicon consist of opinion terms flagged during the OM regex construction process as well as those identified during the review of the LF term subset not matched by the final OM regex. The format of OM regex is consistent with other lexicons in that each entry is composed of a regular expression and associated polarity and strength. The OM regex contained 102 regular expressions of varying length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5.">IU Module</head><p>IU Module (IUM) is motivated by the observation that pronouns such as "I" and "you" appear very frequently in opinionated texts. IU collocations, which are n-grams with IU (I and you) anchor terms (e.g., I believe, you will love), mark adjacent statements as opinions (e.g., "I believe God exists", "God is dead to 8 Wilson"s subjectivity terms were obtained from http://www.cs.pitt.edu/mpqa/opinionfinderrelease/.</p><p>me"). In this regard, IU collocations provide yet another type of opinion evidence to complement the opinion lexicons of HFM/WLM and the opinion morphology of LFM.</p><p>For IU lexicon construction, we first extracted n-grams that begin or end with IU anchors (e.g., I, you, we, my, your, our, me, etc.) from the positive blog training data. Since IU collocations are not collection-dependent, movie reviews were also used to broaden and strengthen the IU n-gram harvest.</p><p>Extracted n-grams were then manually filtered to create a lexicon of IU collocations (e.g., "I believe", "my assessment", "good for you", etc.) with associated polarity and strength, after which the lexicon was expanded with additional IU collocations formed by coupling IU anchors with appropriate HF and Wilson terms (e.g., "I" + verb, adjective + preposition + "me"). As was done with the HF lexicon, morphological variations were applied to the final IU lexicon of 1037 entries (e.g., "I think" to "I think, thought, thinking").</p><p>In order to accommodate the various forms of an IU collocation (e.g., I believe, I cannot but believe, I have always believed, etc.), IUM applies the IU lexicon in a slightly different manner than other modules. First, documents are pre-processed to compress certain prepositions, conjunctions, and articles (e.g., of, with, and, or, a, the, etc.) as well as to convert IU texts with valence shifters to normalized forms (e.g., "I truly and seriously cannot" to "I-NOT") via regular expressions. Then IU collocations in the lexicon is "padded" in such a way that document texts with up to two words in-between IU collocation words will be matched by IUM (e.g., "I really truly think", "I am thinking").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.6.">Opinion Acronym Module</head><p>The Opinion Acronym lexicon used by Opinion Acronym Module (OAM) complements the IU lexicon with common IU collocation acronyms (e.g., imho). The OA lexicon consists of a manually filtered subset of Netlingo"s chat acronyms and text message shorthand (http://www.netlingo.com/emailsh.cfm) in both acronym and expanded forms. Since opinion acronyms represent long phrases that serve as a clear indicator of opinion or sentiment, they were generally given higher opinion strength values than other lexicon entries. Like emphasis terms, no polarity was assigned to the 32 entries in the OA lexicon since they all turned out to be opinion indicators without orientation (e.g, jmtc for "just my two cents").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.7.">Adjective-Verb Module</head><p>While all preceding opinion modules are lexicon-based, the Adjective-Verb Module (AVM) attempts to learn the subjective language by utilizing adjectives and verbs with high distributional similarity to the seed adjective and verb set in the training data <ref type="bibr" coords="8,263.21,471.93,87.18,9.94" target="#b6">(Wiebe et. al, 2004)</ref>. A small set of adjectives and verbs (e.g., good, bad, support, against, like, hate) expanded with synonyms and antonyms from lexical sources such as WordNet is used as a seed set to find a cluster of distributionally similar (i.e., high co-occurrence) adjectives and verbs in the positive training data. Based on the assumption that a document with a high concentration of subjective adjectives and verbs are likely to be opinionated, AVM uses the density of subjective adjectives and verbs, otherwise known as potentially subjective elements, to classify documents as opinionated or non-opinionated. A more detailed description of AVM can be found in <ref type="bibr" coords="8,483.10,547.89,57.08,9.94;8,72.02,560.49,23.80,9.94">(Yang et. al, 2007)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.8.">Opinion Reranking</head><p>After applying the opinion modules to top 500 documents of the topical (i.e., baseline) retrieval result, the weighted sum of the opinion scores are combined with the topical score to rerank the topical results. Equation 6 describes the reranking formula, where the min-max normalized original score of document d, NS orig (d), is combined with the weighted sum of opinion scores 9 , opS i (d).  and  estimate the relative contributions of the original and combined opinion score in a way that enables the documents with high opinion score to float to the top without unduly influencing the existing document ranking. In the min-max normalization, (equation 7), S i (d) is the raw score of document d by component i, and min{S i } and max{S i } are the minimum and maximum scores by the component i.</p><formula xml:id="formula_4" coords="9,109.83,114.49,210.21,51.91">      k i i i orig d opS w d NS d RS 1 )) ( ( * ) ( ) (   (6) } min{ } max{ } min{ ) ( ) ( i i i i i S S S d S d NS    (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Dynamic Tuning</head><p>To facilitate the determination of fusion weights (w i in equation 6) as well as original and reranking score weights ( and  in equation 6) in the reranking formula, we devised an interactive system tuning method called Dynamic Tuning. Dynamic Tuning is implemented in a Web-based interface that displays the effects of tuning parameter changes in real time so as to guide its user towards the discovery of a system optimization state in a biofeedback-like manner. To combine human intelligence, especially the pattern recognition ability, with the computational power of the machine, Dynamic Tuning allows the human to examine not only the immediate effect of his/her system tuning but also the possible explanation of the tuning effect in the form of data patterns. By engaging in iterative dynamic tuning process that successively fine-tune the reranking parameters based on the cognitive analysis of immediate system feedback, system performance can be improved without resorting to an exhaustive evaluation of parameter combinations that can be prohibitively resource intensive with a large number of parameters. Dynamic Tuning can also accommodate nonlinear combinations of factors that may arise from iterations of cognitive pattern analysis by incorporating them heuristically (e.g., decision rules) in conjunction with the weighted sum formula.</p><p>Figure <ref type="figure" coords="9,121.80,636.24,5.52,9.94" target="#fig_3">2</ref> shows the dynamic tuning interface for optimizing the fusion formula that combines opinion reranking scores. The top portion of the interface displays in real time the effect of manually set fusion formula weights in terms of retrieval performance averaged over all topics as well as for the given topic. The bottom portion shows individual reranking factor scores for the ranked list of documents so that the human user may detect patterns that can be reflected in another cycle of tuning to beat the best performance (displayed in purple). Dynamic tuning can be thought of as a kind of human-driven genetic algorithm that can facilitate searching of vast solution spaces by harnessing human"s cognitive abilities to shortcut the purely algorithmic navigation towards the optimized solution. Since the processing power and speed of human falls far short of machine, however, the candidate solutions evaluated by dynamic tuning will normally span a much smaller area of the solution space than those covered by genetic algorithms. Consequently, dynamic tuning is likely to lead to only local optimum solutions. One way to compensate for this weakness is to integrate genetic algorithm with dynamic tuning so that human and machine can guide each other in the search of the optimal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Performance Overview</head><p>Table <ref type="table" coords="10,100.21,225.52,5.52,9.94" target="#tab_0">1</ref> shows the performance of our opinion finding runs (IU-SLIS) in comparison with the best TREC official results (KLE, UIC_IR, fub) using short (i.e. title only) queries and standard baselines<ref type="foot" coords="10,485.14,235.99,6.96,6.26" target="#foot_8">10</ref> . Our three runs in the table, which are identical in all aspects except for the baseline used, used manual lexicon weights with the reranking formula optimized with dynamic tuning. Top3dt1mRd, which used the combined result of the best three baselines, achieved the second best opinion finding performance. If we consider the performance improvement over baseline or runs using the baseline 4, however, our best run (b4dt1mRd) is ranked third. Table <ref type="table" coords="10,99.86,458.37,4.14,9.94" target="#tab_1">2</ref>, which shows the performance of our polarity runs (IU-SLIS) along with top TREC official results (KLE, UIC_IR, fub) using short (i.e. title only) queries, clearly demonstrates the effectiveness of our polarity detection approach, especially in identifying negative opinions. We attribute this to our strategy of flagging valence shifters near opinion clues rather than attempting to determine the opinion polarity as a whole as must be done with machine learning approaches.  The height of the bars represents the average performance difference between system pairs<ref type="foot" coords="11,93.50,128.83,6.96,6.26" target="#foot_9">11</ref> that are identical in all aspects except for the parameter in question (e.g., baseline vs. opinion reranking with dynamic tuning). In addition to the beneficial effect of opinion reranking , which is clearly reflected in the upward direction of the bars across all performance measures (MAP, MRP, P@10), the chart also demonstrates the positive effect of dynamic tuning with the height differentials between runs with and without dynamic tuning. Markedly taller red bars indicate that dynamic tuning is quite effective in optimizing the reranking formula. For opinion reranking, the average gain in opinion MAP with dynamic tuning is almost 4 times that without dynamic tuning (20.03% vs. 5.89%). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Dynamic Tuning Effect</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Opinion Reranking Factors</head><p>Charts in Figure <ref type="figure" coords="11,145.09,602.28,5.52,9.94">3</ref> compare the effects of opinion evidences on opinion finding performance. In the chart on the left, which displays the individual performances of opinion reranking factors in an ascending order of effectiveness for the best short query run, "topicRR" bar shows the opinion MAP before opinion reranking, "all" shows the performance of the run that combines all opinion reranking factors with weights optimized via dynamic tuning, and the rest of the bars represent performances of single or combined opinion factors<ref type="foot" coords="11,530.38,650.55,6.96,6.26" target="#foot_10">12</ref> .</p><p>The suffix "x" of opinion factor names indicates frequency plus proximity scores, suffix "d" indicates frequency plus distance scores, and neither "x" or "d" indicates combination of both. The chart on the right clusters reranking factors by type and plots the percent improvement in opinion MAP over topic reranked performance.</p><p>The charts show that all components of the opinion module contribute to opinion detection and the combined result outperforms the best single method by a significant margin (0.3199 vs. 0.3059: 46% increase). The best individual performance by the IU module suggests that the opinion collocation is a valuable source of evidence for opinion detection and thus should be leveraged along with the commonly used opinion lexicon evidence. The marginal performance gain by the AC module can be attributed to the small size of the acronym lexicon (32 entries). The poor performance of Adjective-Verb module could be affected by the manual intervention during AV lexicon expansion process. Manual filtering of lexicon terms that worked well with other lexicon-based approach may have inadvertently contaminated the construction of the AV model, which in theory should be learned from training data as whole regardless of individual term"s semantic value.</p><p>It is easy to see from the bar cluster chart that the best source of opinion evidence is Opinion Collocation, followed by Opinion Lexicon (HF, WL) and Opinion Morphology (LF). The chart also shows that while proximity scoring is much better than distance scoring in general, combining both is quite beneficial. A notable exception is with LF, where distance scoring outperforms proximity scoring. This may be due to the usage pattern of opinion morphology that is less target-oriented than other opinion evidences. In other words, LF expressions may sometimes be used by themselves as exclamations of strong sentiments, whereas HF terms, for example, are more likely to be used in proximity of a target to denote targeted opinions (e.g., "I used Skype for the first time last night and it worked like a charm. Grrrrreat!" vs. "Skype is a great product.").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Manual vs. Probabilistic Lexicon Weights</head><p>Figure <ref type="figure" coords="12,103.33,396.67,4.14,9.94">4</ref>, which compares the recall-precision curve of the best short query run using the combined lexicon weights with a run that is identical in all respect except for the use of manual lexicon weights, shows that the outcome of using manual verses combined weights are nearly identical. This is probably due to the fact that combining probabilistic weights with manual weights by multiplication did not result in significant enough change in term weights as a whole to affect noticeable differences in outcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUDING REMARKS</head><p>Figure <ref type="figure" coords="12,103.94,503.85,4.14,9.94">5</ref>, which plots %MAP improvement over baseline of TREC participants" best runs<ref type="foot" coords="12,470.71,501.60,6.96,6.26" target="#foot_11">13</ref> , and figure <ref type="figure" coords="12,532.06,503.85,4.08,9.94">6</ref>, which plots %mixMAP improvement over baseline of TREC participants" best runs, give further evidence to the effectiveness of our approach of combining multiple complementary sources of evidence for opinion detection and demonstrate in an unequivocal fashion the effectiveness of our polarity detection approach that employs the detection of valence shifters in proximity of opinion terms with the polarity assignment at the lexicon level. The analysis of the results also reveals that Dynamic Tuning is an effective mechanism for optimizing the fusion of various opinion scores In addition to establishing an effective approach to targeted opinion detection that leverages multiple sources of evidence in an integrated fashion, we have also constructed opinion lexicons<ref type="foot" coords="12,199.70,602.91,6.96,6.26" target="#foot_12">14</ref> for public use and presented a novel approach to system tuning that could prove useful for complex system optimization tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,160.82,377.71,290.24,9.94;3,81.80,82.80,431.75,292.25"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. WIDIT Blog Opinion Retrieval System Architecture</figDesc><graphic coords="3,81.80,82.80,431.75,292.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,137.66,452.44,282.62,8.10;9,71.90,212.85,430.75,230.70"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Dynamic Tuning Interface for Opinion Reranking Optimization</figDesc><graphic coords="9,71.90,212.85,430.75,230.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,72.02,93.04,468.13,9.94;11,72.02,105.76,467.86,9.94;11,72.02,118.36,467.81,9.94;11,72.02,131.08,21.44,9.94;11,93.50,128.83,6.96,6.26;11,103.34,131.08,436.29,9.94;11,72.02,143.68,468.09,9.94;11,72.02,156.28,467.76,9.94;11,72.02,169.00,467.75,9.94;11,72.02,181.60,467.96,9.94;11,72.02,194.32,467.71,9.94;11,72.02,206.92,325.55,9.94;11,72.00,229.70,218.05,117.10"><head>Figure 2</head><label>2</label><figDesc>Figure 2 displays average performance improvements over baseline by opinion reranking (r2-r0), where green bars (s0R) indicate reranking without dynamic tuning and the red bars (s0R1) indicate reranking with dynamic tuning.The height of the bars represents the average performance difference between system pairs 11 that are identical in all aspects except for the parameter in question (e.g., baseline vs. opinion reranking with dynamic tuning). In addition to the beneficial effect of opinion reranking , which is clearly reflected in the upward direction of the bars across all performance measures (MAP, MRP, P@10), the chart also demonstrates the positive effect of dynamic tuning with the height differentials between runs with and without dynamic tuning. Markedly taller red bars indicate that dynamic tuning is quite effective in optimizing the reranking formula. For opinion reranking, the average gain in opinion MAP with dynamic tuning is almost 4 times that without dynamic tuning (20.03% vs. 5.89%).</figDesc><graphic coords="11,72.00,229.70,218.05,117.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,115.94,349.05,134.42,8.96;11,86.30,372.00,193.80,165.85"><head>Figure 2 :Figure 4 :</head><label>24</label><figDesc>Figure 2: Dynamic Tuning Effect</figDesc><graphic coords="11,86.30,372.00,193.80,165.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="10,129.14,326.13,345.38,109.30"><head>Table 1 : Opinion Finding results (Title only, Topics 1001-1050)</head><label>1</label><figDesc></figDesc><table coords="10,129.14,344.73,345.38,90.70"><row><cell></cell><cell></cell><cell></cell><cell>Opinion</cell><cell> over</cell></row><row><cell>Group</cell><cell>Run</cell><cell>Baseline</cell><cell>MAP</cell><cell>Baseline</cell></row><row><cell>KLE</cell><cell>KLEDocOpinT</cell><cell>N/A</cell><cell>.4569</cell><cell>N/A</cell></row><row><cell>IU-SLIS</cell><cell>top3dt1mRd</cell><cell>2+3+4</cell><cell>.4335</cell><cell>4.1%</cell></row><row><cell>KLE</cell><cell>B4PsgOpinAZN</cell><cell>4</cell><cell>.4189</cell><cell>9.6%</cell></row><row><cell>UIC_IR</cell><cell>uicop2bl4r</cell><cell>4</cell><cell>.4067</cell><cell>6.4%</cell></row><row><cell>IU-SLIS</cell><cell>b4dt1mRd</cell><cell>4</cell><cell>.4023</cell><cell>5.3%</cell></row><row><cell>fub</cell><cell>FIUBL4DFR</cell><cell>4</cell><cell>.4006</cell><cell>4.8%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,84.98,533.63,430.36,120.71"><head>Table 2 : Polarity Detection results (Title only, Topics 1001-1050)</head><label>2</label><figDesc></figDesc><table coords="10,84.98,552.11,430.36,102.23"><row><cell>Group</cell><cell>Run</cell><cell>Baseline</cell><cell>MixMAP ()</cell><cell>Positive MAP</cell><cell>Negative MAP</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>()</cell><cell>()</cell></row><row><cell>IU-SLIS</cell><cell>top3dt1mP5</cell><cell>2+3+4</cell><cell>.1677 (6.6%)</cell><cell>.1752 (2.3%)</cell><cell>.1601 (11.9%)</cell></row><row><cell>KLE</cell><cell>KLEPolarity</cell><cell>N/A</cell><cell>.1662 (N/A)</cell><cell>.1828 (N/A)</cell><cell>.1496 (N/A)</cell></row><row><cell>IU-SLIS</cell><cell>b4dt1mP5</cell><cell>4</cell><cell>.1572 (11.5%)</cell><cell>.1570 (2.5%)</cell><cell>.1574 (22.2%)</cell></row><row><cell>KobeU</cell><cell>KobeU</cell><cell>4</cell><cell>.1448 (2.7%)</cell><cell>.1566 (2.2%)</cell><cell>.1329 (3.2%)</cell></row><row><cell>THUIR</cell><cell>THUpolTmfPNR</cell><cell>THUrelTwpmf</cell><cell>.1353 (7.2%)</cell><cell>.1289 (6.3%)</cell><cell>.1417 (8.0%)</cell></row><row><cell>UoGtr</cell><cell>UoGtr</cell><cell>4</cell><cell>.1348 (-4.4%)</cell><cell>.1394 (-9.0%)</cell><cell>.1301 (1.0%)</cell></row><row><cell>UWaterloo</cell><cell>UWaterloo</cell><cell>1</cell><cell>.1278 (0.7%)</cell><cell>.1430 (4.8%)</cell><cell>.1126 (-4.2%)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,77.78,686.77,461.46,8.96;1,72.02,698.29,467.99,8.96;1,72.02,709.93,41.22,8.96"><p>Web Information Discovery Integrated Tool (WIDIT) Laboratory at the Indiana University School of Library and Information Science is a research lab that explores a fusion approach to information retrieval and knowledge discovery.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,77.78,709.93,217.77,8.96"><p>http://wikipedia-lab.org:8080/WikipediaThesaurusV2/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,77.78,710.67,377.07,9.06"><p>"Padded" query string is a query string with up to k number of words in between query words.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,77.90,698.29,461.77,8.96;5,72.02,709.93,36.78,8.96"><p>Non-rel Match is used to suppress the document rankings, while other reranking factors are used to boost the rankings.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,77.78,684.98,228.48,8.96"><p>Documents with more than 50,000 words were excluded.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,77.78,697.45,407.55,8.96"><p>The movie review data was obtained from http://www.cs.cornell.edu/people/pabo/movie-review-data/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,77.78,709.93,150.25,8.96"><p>http://www.imdb.com/Sections/Plots/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7" coords="8,77.78,709.93,385.97,8.96"><p>Opinion scores are not min-max normalized since they are already document-length normalized.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8" coords="10,81.02,709.93,303.11,8.96"><p>KLE run with the best opinion finding MAP did not submit its baseline run.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9" coords="11,81.02,685.93,393.75,8.96"><p>System pairs consist of all our experimental runs including those that use our own baseline results.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_10" coords="11,81.02,698.19,458.58,9.05;11,72.02,709.83,438.61,9.06"><p>WLM"s strong subjectivity terms are represented as "W1", and weak subjectivity terms as "W2". "W12" denotes both strong and weak subjectivity terms and "WL" represents all Wilson"s lexicon terms including emphasis terms.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_11" coords="12,81.02,697.45,130.08,8.96"><p>Red bars indicate our top 3 runs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_12" coords="12,81.02,709.93,152.60,8.96"><p>http://elvis.slis.indiana.edu/lexlist.htm</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,72.02,347.95,465.59,9.94;13,97.58,360.67,202.23,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,216.59,347.95,206.49,9.94">The Relationship between Recall and Precision</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Buckland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,430.27,347.95,107.34,9.94;13,97.58,360.67,137.31,9.94">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.02,379.27,468.05,9.94;13,97.58,391.87,239.79,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,273.41,379.27,266.66,9.94;13,97.58,391.87,26.01,9.94">Improving weak ad-hoc retrieval by Web assistance and data fusion</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,133.46,391.87,176.24,9.94">Asian Information Retrieval Symposium</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.02,410.59,439.74,9.94;13,72.02,423.21,301.01,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,201.62,410.59,310.15,9.94;13,72.02,423.21,33.98,9.94">Improving the effectiveness of information retrieval with local context analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,115.82,423.21,183.84,9.94">ACM Transaction on Information Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.02,441.93,467.51,9.94;13,97.22,454.53,11.04,9.94;13,108.26,452.28,5.40,6.26;13,116.42,454.53,178.57,9.94" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Valerio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m" coord="13,303.41,441.93,236.12,9.94;13,97.22,454.53,11.04,9.94;13,108.26,452.28,5.40,6.26;13,116.42,454.53,115.47,9.94">WIDIT in TREC2006 Blog track. Proceedings of the 15 th Text Retrieval Conference</title>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2006">2007. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.02,473.13,441.41,9.94;13,72.02,485.85,265.30,9.94;13,337.37,483.60,5.40,6.26;13,345.55,485.85,178.42,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,248.81,473.13,264.62,9.94;13,72.02,485.85,158.72,9.94">WIDIT in TREC2007 Blog track: Combining lexicon-based methods to detect opinionated Blogs</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,241.13,485.85,96.19,9.94;13,337.37,483.60,5.40,6.26;13,345.55,485.85,115.36,9.94">Proceedings of the 16 th Text Retrieval Conference</title>
		<meeting>the 16 th Text Retrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2006">2008. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.02,504.45,431.56,9.94;13,72.02,517.17,176.07,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,198.86,504.45,269.34,9.94">WIDIT: Fusion-based Approach to Web Search Optimization</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,478.51,504.45,25.07,9.94;13,72.02,517.17,148.53,9.94">Asian Information Retrieval Symposium</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,72.02,535.77,436.51,9.94;13,72.02,548.37,152.82,9.94;13,224.93,546.12,4.69,6.26;13,232.25,548.37,241.97,9.94;13,72.02,567.09,414.75,9.94;13,72.02,579.69,195.98,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,337.73,535.77,170.80,9.94;13,72.02,548.37,51.89,9.94;13,354.39,567.09,127.64,9.94">Fusion approach to finding opinions in blogosphere</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Valerio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,134.18,548.37,90.66,9.94;13,224.93,546.12,4.69,6.26;13,232.25,548.37,241.97,9.94">Proceedings of the 1 st International Conference on Weblog and Social Media</title>
		<meeting>the 1 st International Conference on Weblog and Social Media</meeting>
		<imprint>
			<date type="published" when="2004">2007. 2004</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="277" to="308" />
		</imprint>
	</monogr>
	<note>Learning subjective language</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
