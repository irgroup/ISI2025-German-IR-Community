<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.15,83.76,287.40,15.48;1,448.56,81.23,5.98,10.48">Where to Stop Reading a Ranked List? *</title>
				<funder ref="#_g7KHjMS #_4xDuww2 #_MEF7v56">
					<orgName type="full">Netherlands Organization for Scientific Research (NWO</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,201.15,116.28,79.49,10.75"><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Humanities</orgName>
								<orgName type="laboratory">Archives and Information Studies</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.32,116.28,63.92,10.75"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Humanities</orgName>
								<orgName type="laboratory">Archives and Information Studies</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution" key="instit1">ISLA</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.15,83.76,287.40,15.48;1,448.56,81.23,5.98,10.48">Where to Stop Reading a Ranked List? *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0CB65EB58D0182D68806DA6E36158FAB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We document our participation in the TREC 2008 Legal Track. This year we focused solely on selecting rank cut-offs for optimizing the given evaluation measure per topic. * The programming code implementing the methods described in this paper will be made publicly available; for information on how to obtain it, please contact the authors.</p><p>1 In fact, to the surprise of many, at the TREC 2007 Legal Track the Boolean reference run outperformed the ranked retrieval models at the rank cut-off of the Boolean set size.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recall-oriented retrieval setups, such as the Legal Track, ranked retrieval has a particular disadvantage in comparison with traditional Boolean retrieval: there is no clear cut-off point where to stop consulting results. It is expensive to give a ranked list with too many results to litigation support professionals paid by the hour. This may be one of the reasons why ranked retrieval has been adopted very slowly in professional legal search. 1  The "missing" cut-off remains unnoticed by standard evaluation measures: there is no penalty and only possible gain for padding a run with further results. The TREC 2008 Legal Track addresses this head-on by requiring participants to submit such a cut-off value K per topic where precision and recall are best balanced. This year we focused solely on selecting K for optimizing the given F 1 -measure. We believe that this will have the biggest impact on this year's comparative evaluation.</p><p>The rest of this paper is organized as follows. The method for determining K is presented in Section 2. It depends on the underlying score distributions of relevant and nonrelevant documents, which we elaborate on in Section 3. In Section 4 we describe the parameter estimation methods. In Section 5 we discuss the experimental setup, our official submissions, results, and additional experiments. Finally, we summarize the findings in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Thresholding a Ranked List</head><p>Essentially, the task of selecting K is equivalent to thresholding in binary classification or filtering. Thus, we recruited and adapted a method first appeared in the TREC 2000 Filtering Track, namely, the score-distributional threshold optimization (s-d) <ref type="bibr" coords="1,117.45,646.33,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="1,130.73,646.33,7.19,8.64" target="#b2">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The S-D Threshold Optimization</head><p>Let us assume an item collection of size n, and a query for which all items are scored and ranked. Let P (s|1) and P (s|0) be the probability densities of relevant and non-relevant documents as a function of the score s, and F (s|1) and F (s|0) their corresponding cumulative distribution functions (cdfs). Let G n ∈ [0, 1] be the fraction of relevant documents in the collection of all n documents, also known as generality. The total number of relevant documents in the collection is given by</p><formula xml:id="formula_0" coords="1,415.45,330.40,140.46,9.65">R = n G n<label>(1)</label></formula><p>while the expected numbers of relevant and non-relevant documents with scores greater than s are</p><formula xml:id="formula_1" coords="1,372.17,386.13,183.75,24.60">R + (s) = R (1 -F (s|1)) (2) N + (s) = (n -R) (1 -F (s|0))<label>(3)</label></formula><p>respectively. The expected numbers of the relevant and nonrelevant documents with scores ≤ s respectively are</p><formula xml:id="formula_2" coords="1,378.94,456.79,176.98,24.60">R -(s) = R -R + (s) (4) N -(s) = (n -R) -N + (s)<label>(5)</label></formula><p>Let us now assume an effectiveness measure M of the form of a linear combination the document counts of the categories defined by the four combinations of relevance and retrieval status, for example a linear utility <ref type="bibr" coords="1,510.28,529.81,15.27,8.64" target="#b17">[18]</ref>. From the property of expectation linearity, the expected value of such a measure would be the same linear combination of the above four expected document numbers. Assuming that the larger the M the better the effectiveness, the optimal score threshold s θ which maximizes the expected M is</p><formula xml:id="formula_3" coords="1,326.77,611.15,229.14,16.07">s θ = arg max s {M (R + (s), N + (s), R -(s), N -(s))} (6)</formula><p>Given n, the only unknowns which have to be estimated are the densities P (s|1) and P (s|0) (or their cdfs), and the generality G n .</p><p>So far, this is a clear theoretical answer to predicting s θ for linear effectiveness measures. In Section 2.3 we will see how to deal with non-linear measures, as well as, how to predict rank (rather than score) cut-offs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Probability Thresholds</head><p>Given the two densities and the generality defined earlier, scores can be normalized to probabilities of relevance straightforwardly <ref type="bibr" coords="2,125.36,97.43,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="2,138.64,97.43,13.28,8.64" target="#b13">14]</ref> by using the Bayes' rule.</p><p>Normalizing to probabilities is very important in tasks where several rankings need to be fused or merged such as in meta-search/fusion or distributed retrieval. This may also be important for thresholding when documents arrive one by one and decisions have to be made on the spot, depending on the measure under optimization. Nevertheless, it is unnecessary for thresholding rankings since optimal thresholds can be found on their scores directly, and it is furthermore unsuitable given F 1 as the evaluation measure.</p><p>While for some measures there exists an optimal fixed probability threshold, for others it does not. Lewis <ref type="bibr" coords="2,258.87,228.94,16.60,8.64" target="#b12">[13]</ref> formulates this in terms of whether or not a measure satisfies the probability thresholding principle, and proves that the F measure does not satisfy it. In other words, how a system should treat documents with, e.g., 50% chance of being relevant depends on how many documents with higher probabilities are available.</p><p>The last-cited study also questions whether, for a given measure, an optimal threshold (not necessarily a probability one) exists, and goes on to re-formulate the probability ranking principle for binary classification. A theoretical proof is provided about the F measure satisfying the principle, so such an optimal threshold does exist. It is just a different rank or score threshold for each ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The S-D Rank Optimization</head><p>The s-d threshold optimization method is based on the assumption that the measure M is a linear combination of the document counts of the four categories defined by the user and system decisions about relevance and retrieval status. However, measure linearity is not always the case, e.g. the F measure is non-linear.</p><p>Non-linearity complicates the matters in the sense that the expected value of M cannot be easily calculated. Given a ranked list, some approximations can be made simplifying the issue. If G n , F (s|1), and F (s|0) are estimated on a given ranking, then Equations 2-5 are good approximations of the actual document counts. Plugging those counts into M , we can now talk of actual M values rather than expected. The score threshold which maximizes M is given by Equation <ref type="formula" coords="2,285.43,572.24,3.74,8.64">6</ref>.</p><p>While M can be optimal anywhere in the score range, with respect to optimizing rank cutoffs we only have to check its value at the scores corresponding to the ranked documents, plus one extra point to allow for the possibility of an empty optimal retrieved set. Let s k be the score of the kth ranked document, and define M k as follows:</p><formula xml:id="formula_4" coords="2,53.80,665.18,239.10,21.01">M k = M (R+(s k ), N+(s k ), R-(s k ), N-(s k )) k = 1, . . . , n M (0, 0, R, n -R) k = 0</formula><p>The optimal rank K is arg max k M k . This allows for K to become 0, meaning that no document should be retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Score Distributions</head><p>Let us now elaborate on the form of the two densities P (s|1) and P (s|0) of Section 2.1 and their estimation. <ref type="foot" coords="2,506.96,83.80,3.49,6.05" target="#foot_0">2</ref>Score distributions have been modeled since the early years of IR with various known distributions <ref type="bibr" coords="2,500.16,109.39,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="2,514.04,109.39,7.47,8.64" target="#b6">7,</ref><ref type="bibr" coords="2,524.60,109.39,12.45,8.64" target="#b19">20,</ref><ref type="bibr" coords="2,540.15,109.39,11.83,8.64" target="#b20">21]</ref>. However, the trend during the last few years, which has started in <ref type="bibr" coords="2,360.45,133.30,11.62,8.64" target="#b2">[3]</ref> and followed up in <ref type="bibr" coords="2,462.65,133.30,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="2,478.64,133.30,7.47,8.64" target="#b1">2,</ref><ref type="bibr" coords="2,491.32,133.30,7.47,8.64" target="#b7">8,</ref><ref type="bibr" coords="2,504.00,133.30,12.45,8.64" target="#b13">14,</ref><ref type="bibr" coords="2,521.66,133.30,11.83,8.64" target="#b21">22]</ref>, has been to model score distributions by a mixture of normalexponential densities: normal for relevant, exponential for non-relevant.</p><p>Despite its popularity, it was pointed out recently that, under a hypothesis of how systems should score and rank documents, this particular mixture of normal-exponential presents a theoretical anomaly <ref type="bibr" coords="2,444.10,216.98,15.27,8.64" target="#b16">[17]</ref>. In practice, nevertheless, it has stand the test of time in the light of • its (relative) ease to calculate,</p><p>• good experimental results, and</p><p>• lack of a proven alternative.</p><p>The reader should keep in mind that the normal-exponential mixture fits some retrieval models better than others, or it may not fit some data at all. As a rule of thumb, candidates for good fits are scoring functions in the form of a linear combination of query-term weights, e.g. tf.idf, cosine similarity, and some probabilistic models <ref type="bibr" coords="2,466.01,365.56,10.58,8.64" target="#b1">[2]</ref>. Also, long queries <ref type="bibr" coords="2,316.81,377.52,11.62,8.64" target="#b1">[2]</ref> or good queries/systems <ref type="bibr" coords="2,429.71,377.52,16.59,8.64" target="#b13">[14]</ref> seem to help.</p><p>In this paper, we do not set out to investigate alternative mixtures. We theoretically extend and refine the current model in order to account for practical situations, deal with its theoretical anomaly, and improve its computation. We also check its goodness-of-fit to empirical data using a statistical test; a check that has not been done before as far as we are concerned. At the same time, we explicitly state all parameters involved, try to minimize their number, and find for them a robust set of values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Normal-Exponential Model</head><p>Let us consider a general retrieval model which in theory produces scores in [s min , s max ], where s min ∈ R ∪ {-∞} and s max ∈ R ∪ {+∞}. By using an exponential distribution, which has semi-infinite support, the applicability of the s-d model is restricted to those retrieval models for which s min ∈ R. The two densities are given by</p><formula xml:id="formula_5" coords="2,341.96,597.63,213.95,49.08">P (s|1) = 1 σ φ s -µ σ σ &gt; 0, µ, s ∈ R (7) P (s|0) = ψ(s -s min ; λ) λ &gt; 0, s ≥ s min (8)</formula><p>where φ(.) is the density function of the standard normal distribution, i.e. with a mean of 0 and standard deviation of 1, and ψ(.) is the standard exponential density (Equations 18-19 in Appendix B). The corresponding cdfs are given by Equations 20 and 22. The total score distribution is written as</p><formula xml:id="formula_6" coords="3,96.03,107.17,154.63,9.65">P (s) = (1 -G n ) P (s|0) + G n P (s|1)</formula><p>where G n ∈ [0, 1]. Hence, there are 4 parameters to estimate, λ, µ, σ, and G n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problems of the Normal-Exponential Model</head><p>Over the years, two main problems of the normalexponential model have been identified. We describe each one of them, and then introduce new models which eliminate the first problem and deal partly with the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Support Incompatibility</head><p>Although we already generalized somewhat above by introducing a shifted exponential, the mix, as it has been used in all related literature so far, has a support incompatibility problem: while the exponential is defined at or above some s min , the normal has a full real axis support. This is a theoretical problem which is solved by the new models we will introduce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Recall-Fallout non-Convexity</head><p>From the point of view of how scores or rankings of IR systems should be, Robertson <ref type="bibr" coords="3,162.40,365.71,16.60,8.64" target="#b16">[17]</ref> formulates the recall-fallout convexity hypothesis:</p><p>For all good systems, the recall-fallout curve (as seen from [. . . ] recall=1, fallout=0) is convex.</p><p>Similar hypotheses can be formulated as a conditions on other measures, e.g., the probability of relevance should be monotonically increasing with the score; the same should hold for smoothed precision. Although, in reality, these conditions may not always be satisfied, they are expected to hold for good systems, i.e. those producing rankings satisfying the probability ranking principle (PRP), because their failure implies that systems can be easily improved.</p><p>As an example, let us consider smoothed precision. If it declines as score increases for a part of the score range, that part of the ranking can be improved by a simple random reordering <ref type="bibr" coords="3,89.94,566.56,15.27,8.64" target="#b18">[19]</ref>. This is equivalent of "forcing" the two underlying distributions to be uniform (i.e. have linearly increasing cdfs) in that score range. This will replace the offending part of the precision curve with a flat one-the least that can be done-improving the overall effectiveness of the system.</p><p>Such hypotheses put restrictions on the relative forms of the two underlying distributions. The normal-exponential mixture violates such conditions, only (and always) at both ends of the score range. Although the low-end scores are of insignificant importance, the top of the ranking is very significant, especially for low R topics. The problem is a manifestation of the fact that an exponential tail extends further than a normal one.</p><p>To complicate matters further, our data suggest that such conditions are violated at a different score s c for the probability of relevance and for precision. Since the F -measure we are interested in is a combination of recall and precision (and recall by definition cannot have a similar problem), we find s c for precision. We force the distributions to comply with the hypothesis only when s c &lt; s 1 , where s 1 the score of the top document; otherwise, the theoretical anomaly does not affect the score range. If s max is finite, then two uniform distributions can be used in [s c , s max ] as mentioned earlier. Alternatively, preserving a theoretical support in [s min , +∞), the relevant documents distribution can be forced to an exponential in [s c , +∞) with the same λ as this of the non-relevant. We apply the alternative.</p><p>In fact, rankings can be further improved by reversing the offending sub-rankings; this will force the precision to increase with an increasing score, leading to better effectiveness than randomly re-ordering the sub-ranking. However, the big question here is whether the initial ranking satisfies the PRP or not. If it does, then the problem is an artifact of the normal-exponential model and reversing the sub-ranking may actually be dangerous to performance. If it does not, then the problem is inherent in the scoring formula producing the ranking. In the latter case, the normal-exponential model cannot be theoretically rejected, and it may even be used to detect the anomaly and improve rankings.</p><p>It is difficult, however, to determine whether a single ranking satisfies the PRP or not; it is well-known since the early IR years that precision for single queries is erratic, especially at early ranks, justifying the use of interpolated precision. On the one hand, according to interpolated precision all rankings satisfy the PRP, but this is forced by the interpolation. On the other hand, according to simple precision some of our rankings do not seem to satisfy the PRP, but we cannot determine this for sure. We would expect, however, that using precision averaged over all topics should produce a-more or less-declining curve with an increasing rank. Figure <ref type="figure" coords="3,345.63,515.56,4.98,8.64" target="#fig_0">1</ref> suggests that the off-the-shelf system we currently use produces rankings that may not satisfy the PRP for ranks 5,000 to 10,000, on average. Consequently, we rather leave open the question of whether the problem is inherent in some scoring functions or introduced by the combined use of normal and exponential distributions. Being conservative, we just randomize the offending sub-rankings rather than reversing them. The impact of this on thresholding is that the s-d method turns "blind" inside the upper offending range; as one goes down the corresponding ranks, precision would be flat, recall naturally rising, so the optimal F 1 threshold can only be below the range.</p><p>We will use new models that, although they do not eliminate the problem, also do not always violate such conditions imposed by the PRP (irrespective of whether it holds or not). . By rank 100,000, precision is still flat rather than declining, recall is still rising, so F1 has not yet peaked; this suggests that there are optimal K's larger than 100,000. Systems correctly predicting K's larger than 100,000 do not get credit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Truncated Normal-Exponential Model</head><p>In order to enforce support compatibility, Arampatzis et al. <ref type="bibr" coords="4,53.80,360.70,11.62,8.64" target="#b4">[5]</ref> introduced truncated models which we will discuss in this and the next section. They introduced a left-truncated at s min normal distribution for P (s|1). With this modification, we reach a new mixture model for score distributions with a semi-infinite support in [s min , +∞), s min ∈ R.</p><p>In practice, however, scores may be naturally bounded (by the retrieval model) or truncated to the upside as well. For example, cosine similarity scores are naturally bounded at 1. Scores from probabilistic models with a (theoretical) support in (-∞, +∞) are usually mapped to the bounded (0, 1) via a logistic function. Other retrieval models may just truncate at some maximum number for practical reasons. Consequently, it makes sense to introduce a right-truncation as well, for both the normal and exponential densities.</p><p>Depending on how one wants to treat the leftovers due to the truncations, two new models may be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Theoretical Truncation</head><p>There are no leftovers (Figure <ref type="figure" coords="4,174.02,572.41,3.60,8.64">2</ref>). The underlying theoretical densities are assumed to be the truncated ones, normalized accordingly to integrate to one: Φ(.) and Ψ(.) are the cdfs of φ(.) and ψ(.) respectively (Equations <ref type="table" coords="4,363.46,508.78,9.96,8.64" target="#tab_4">20</ref> and<ref type="table" coords="4,394.78,508.78,7.89,8.64" target="#tab_4">22</ref>). The cdfs of the above P (s|1) and P (s|0) are given by Equations 21 and 23, respectively.</p><formula xml:id="formula_7" coords="4,81.74,614.36,211.17,25.35">P (s|1) = 1 σ φ s-µ σ Φ(β) -Φ(α) s ∈ [s min , s max ]<label>(9)</label></formula><formula xml:id="formula_8" coords="4,53.80,661.26,239.10,62.96">P (s|0) = ψ(s -s min ; λ) Ψ(s max -s min ; λ) s ∈ [s min , s max ] (10) where α = s min -µ σ β = s max -µ σ<label>(11)</label></formula><p>Let S rel and S nrel be the random variables corresponding to the relevant and non-relevant document scores respectively. The expected value and variance of S rel are given by Equations 24 and 25 in Appendix B.3. For S nrel , the corresponding Equations are 26 and 27 in Appendix B.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Technical Truncation</head><p>The underlying theoretical densities are not truncated, but the truncation is of a "technical" nature. The leftovers are accumulated at the two truncation points introducing discontinuities (Figure <ref type="figure" coords="4,383.85,648.86,3.60,8.64">3</ref>). For the normal, the leftovers can easily be calculated:</p><formula xml:id="formula_9" coords="4,322.81,679.45,225.91,41.38">P (s|1) =      Φ(α) δ(s -s min ) s = s min 1 σ φ s-µ σ s ∈ (s min , s max ) (1 -Φ(β)) δ(s -s max ) s = s max</formula><p>where δ(.) is Dirac's delta function. For the exponential, while the leftovers at the right side are determined by the right truncation, in order to calculate the ones at the left side requires to assume that the exponential extends below s min to some new minimum score s min :</p><formula xml:id="formula_10" coords="5,53.80,121.28,257.48,37.89">P (s|0) = 8 &gt; &lt; &gt; : Ψ(smin -s min ; λ) δ(s -smin) s = smin ψ(s -s min ; λ) s ∈ (smin, smax) (1 -Ψ(smax -s min ; λ)) δ(s -smax) s = smax</formula><p>The cdfs corresponding to the above densities are:</p><formula xml:id="formula_11" coords="5,79.58,193.08,186.34,68.30">F (s|1) = Φ( s-µ σ ) s ∈ [s min , s max ) 1 s = s max F (s|0) = Ψ(s -s min ; λ) s ∈ [s min , s max ) 1 s = s max</formula><p>The equations in this section simplify somewhat when estimating their parameters from down-truncated ranked lists, as we will see in Section 4.1. We do not need to calculate s min . If, for some measure, the number of non-relevant documents is required, it can simply be estimated as n -R.</p><p>The expected values and variances of S rel and S nrel , if needed, have to be calculated starting from Equations 24-27 and taking into account the contribution of the discontinuities. We do not give the formulas in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">The Relation Between the Truncated Models</head><p>For both models the right truncation is optional. For s max = +∞, we get Φ(β) = Ψ(s max -s min ; λ) = 1, leading to lefttruncated models; this accommodates retrieval models with scoring support in [s min , +∞), s min ∈ R. This is the maximum range that can be achieved with the current mixture, since the restriction of a finite s min is imposed by the use of the exponential.</p><p>When s min µ s max then Φ(α) ≈ 0 and Φ(β) ≈ 1. If additionally s min = s min , then Ψ(s min -s min ; λ) = 0 and Ψ(s max -s min ; λ) ≈ 1. Thus we can well-approximate the standard normal-exponential model. Consequently, using a truncated model is a valid choice even when truncations are insignificant.</p><p>From a theoretical point of view, it may be difficult to imagine a process producing a truncated normal directly. Truncated normal distributions are usually the results of censoring, meaning that the out-truncated data do actually exist. In this view, the technically truncated model may correspond better to the IR reality. This is also in line with the theoretical arguments for the existence of a full normal distribution <ref type="bibr" coords="5,53.80,639.08,10.58,8.64" target="#b1">[2]</ref>.</p><p>Concerning convexity, both truncated models do not always violate such conditions. Consider the problem at the top score range (s c , +∞). In the cases of s c ≥ s max , the problem is out-truncated in both models, while-in theoryit still always exists in the original model. The improvement so far is of a rather theoretical nature. In practise, we should be interested in what happens when s c &lt; s 1 . Our extended experiments (not reported in this paper) suggest that truncation helps estimation in producing higher numbers of convex fits within the observed score range. Consequently, the benefits are also practical.</p><p>These improvements make the original model more general, and it indeed produces better fits on our data. In fact, the truncated distributions should have been used in the past during parameter estimation even for the original normalexponential model due to down-truncated rankings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parameter Estimation</head><p>The normal-exponential mixture has worked best under the availability of some relevance judgments which serve as an indication about the form of the component densities <ref type="bibr" coords="5,316.81,238.11,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="5,329.95,238.11,7.47,8.64" target="#b7">8,</ref><ref type="bibr" coords="5,339.76,238.11,11.83,8.64" target="#b21">22]</ref>. In filtering or classification, usually some training data-although often biased-are available. In the current task, however, no relevance information is available.</p><p>A method was introduced in the context of fusion which recovers the component densities without any relevance judgments using the Expectation Maximization (EM) algorithm <ref type="bibr" coords="5,341.36,310.45,15.27,8.64" target="#b13">[14]</ref>. In order to deal with the biased training data in filtering, the EM method was also later adapted and applied for thresholding tasks <ref type="bibr" coords="5,410.34,334.36,10.58,8.64" target="#b0">[1]</ref>. <ref type="foot" coords="5,424.45,332.69,3.49,6.05" target="#foot_1">3</ref> Nevertheless, EM was found to be "messy" and sensitive to its initial parameter settings <ref type="bibr" coords="5,316.81,358.27,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="5,331.72,358.27,11.83,8.64" target="#b13">14]</ref>. We will improve upon this estimation method in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Down-truncated Rankings</head><p>For practical reasons, rankings are usually truncated at some rank t &lt; n. Even what is usually considered a full ranking is in fact a collection's subset of those documents with at least one matching term with the query.</p><p>This fact has been largely ignored in all previous research using the standard model, despite that it may affect greatly the estimation. For example, in TREC Legal 2007 and 2008, t was 25, 000 and 100, 000 respectively. This results to a lefttruncation of P (s|1) which at least in the case of the 2007 data is significant. For 2007 it was estimated that there were more than 25, 000 relevant documents for 13 of the 43 Ad Hoc topics (to a high of more than 77, 000) and the median system was still achieving 0.1 precision at ranks of 20, 000 to 25, 000.</p><p>Additionally, considering that the exponential may not be a good model for the whole distribution of the non-relevant scores but only for their high end, some imposed truncation may help achieve better fits. Consequently, all estimations should take place at the top of the ranking, and then get extrapolated to the whole collection. The truncated models of <ref type="bibr" coords="5,327.60,645.32,11.62,8.64" target="#b4">[5]</ref> require changes in the estimation formulas.</p><p>Let us assume that the truncation score is s t . For both truncated models, we we need to estimate a two-side truncated normal at s t and s max , and a shifted exponential by s t right-truncated at s max , with s max possibly be +∞. Thus, the formulas that should be used are Equations 9 and 10 but for α t instead of α α t = s t -µ σ and for s t instead of s min . Beyond this, the models differentiate in the way R is calculated. If G t is the fraction of relevant documents in the truncated ranking, extrapolating the truncated normal outside its estimation range and appropriately per model in order to account for the remaining relevant documents, the R is calculated as:</p><formula xml:id="formula_12" coords="6,63.76,227.97,179.69,45.22">• theoretically truncated normal-exponential R = t G t Φ(β) -Φ(α) Φ(β) -Φ(α t )</formula><p>• technically truncated normal-exponential</p><formula xml:id="formula_13" coords="6,133.47,310.55,98.49,23.23">R = t G t 1 Φ(β) -Φ(α t )</formula><p>Consequently, Equation 1 must be replaced by one of the above depending on the model in use, Equations 2 and 3 must be re-written as</p><formula xml:id="formula_14" coords="6,104.34,396.42,138.01,32.61">R + (s) = t G t (1 -F (s|1)) N + (s) = t (1 -G t ) (1 -F (s|0))</formula><p>while Equations 4 and 5 remain the same. F (s|1) and F (s|0) are now the cdfs either of Section 3.3.1 or 3.3.2, depending on which model is used.</p><p>In estimating the technically truncated model, if there are any scores equal to s max or s min they should be removed from the data-set; these belong to the discontinuous legs of the densities given in Section 3.3.2. In this case, t should be decremented accordingly. In practise, while scores equal to s min should not exist in the top-t due to the down-truncation, some s max scores may very well be in the data. Removing these during estimation is a simplifing approximation with an insignificant impact when the relevant documents are many and the bulk of their score distribution is below s max , as it is the case in current experimental setup. As we will see next, while we do not use the s max scores during fitting, we take them into account during goodness-of-fit testing; using multiple such fitting/testing rounds, this reduces the impact of the approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Score Preprocessing</head><p>Our scores have a resolution of 10 -6 . Obviously, LUCENE rounds or truncates the output scores, destroying information. In order to smooth out the effect of rounding in the data, we add ∆s = rand(10 -6 ) -0.5 * 10 -6 to each datum point, where rand(x) returns a uniformly-distributed real random number in [0, x).</p><p>Beyond using all scores available and in order to speed up the calculations, we also tried stratified down-sampling to keep only 1 out of 2, 3, or 10 scores. <ref type="foot" coords="6,475.76,103.43,3.49,6.05" target="#foot_2">4</ref> Before any downsampling, all datum points were smoothed by replacing them with their average value in a surrounding window of 2, 3, or 10 points, respectively.</p><p>In order to obtain better exponential fits we may further left-truncate the rankings at the mode of the observed distribution. We bin the scores (as described in Section A.1), find the bin with the most scores, and if that is not the leftmost bin then we remove all scores in previous bins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Expectation Maximization</head><p>EM is an iterative procedure which converges locally <ref type="bibr" coords="6,541.81,233.19,10.58,8.64" target="#b8">[9]</ref>. Finding a global fit depends largely on the initial settings of the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Initialization</head><p>We tried numerous initial settings, but no setting seemed universal. While some settings helped a lot some fits, they had a negative impact on others. Without any indication of the form, location, and weighting of the component densities, the best fits overall were obtained for randomized initial values, preserving also the generality of the approach:<ref type="foot" coords="6,519.89,347.66,3.49,6.05" target="#foot_3">5</ref> </p><formula xml:id="formula_15" coords="6,324.79,368.14,222.64,51.79">G t,init = rand(1) , λ init = max( , rand(µ s -s t )) -1 µ init = s min + rand(s 1 -s min ) σ 2 init = max( 2 , (1 + c 1 rand(1)) 2 σ 2 s -λ -2 init )</formula><p>where s 1 is the maximum score datum, µ s and σ 2 s are respectively the mean and variance of the score data, is an arbitrary small constant which we set equal to the width of the bins (see Appendix A.1), and c 1 ∈ (0, +∞) is another constant which we explain below.</p><p>Assuming that no information is available about the expected R, not much can be done for G t,init , so it is randomized using its whole supported range. Next we assume that right-truncation of the exponential is insignificant, which seems to be the case in our current experimental set-up.</p><p>If there are no relevant documents, then µ s -(s t -s min ) ≈ λ -1 + s min . From the last equation we deduce the minimum λ init . Although in general, there is no reason why the exponential cannot fall slower that this, from an IR perspective it should not, or E(S nrel ) would get higher than E(S rel ).</p><p>The µ init given is suitable for a full normal, and its range should be expanded in both sides for a truncated one because the mean of the corresponding full normal can be below s min or above s 1 . Further, µ init can be restricted based on the hypothesis that for good systems should hold that E(S rel ) &gt; E(S nrel ). We have not worked out these improvements.</p><p>The variance of the initial exponential is λ -2 init . Assuming that the random variables corresponding to the normal and exponential are uncorrelated, the variance of the normal is ≥ σ 2 s -λ -2 init which, depending on how λ is initialized, could take values ≤ 0. To avoid this, we take the max with the constant. For an insignificantly truncated normal, c 1 ≈ 0, while in general c 1 &gt; 0, because the variance of the corresponding full normal is larger than what is observed in the truncated data. We set c 1 = 2, however, we found its usable range to be [0.25, 5].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Update Equations</head><p>For t ≤ n observed scores s 1 . . . s t , and neither truncated nor shifted normal and exponential densities (i.e. for the original model), the update equations are P (j|s) is given by Bayes' rule P (j|s) = P (s|j)P (j)/P (s), P</p><p>= G t , P (0) = 1 -G t , and P (s) by Equation <ref type="formula" coords="7,261.67,369.64,3.74,8.64" target="#formula_1">3</ref>.1.</p><p>We initialize those equations as described above, and iterate them until the absolute differences between the old and new values for µ, λ -1 , and √ σ are all less than .001 (s 1s min ), and |G t,new -G t,old | &lt; .001. Like this we target an accuracy of 0.1% for scores and 1 in a 1,000 for documents. We also tried a target accuracy of 0.5% and 5 in 1,000, but it did not seem sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Correcting for Truncation</head><p>If we use the truncated densities (Equations 9 and 10) in the above update equations, the µ new and σ 2 new calculated at each iteration would be the expected value and variance of the truncated normal, not the µ and σ 2 we are looking for. Similarly, 1/λ new + s t would be equal to the expected value of the shifted truncated exponential. Instead of looking for new EM equations, we rather correct to the right values using simple approximations.</p><p>Using Equation <ref type="formula" coords="7,127.56,584.50,8.30,8.64">26</ref>, at the end of each iteration we correct the calculated λ new as</p><formula xml:id="formula_17" coords="7,54.92,615.79,237.98,33.18">λnew ← " 1 λnew + st + smax exp(-λ old (smax -st)) -st Ψ(smax -st; λ old ) « -1<label>(12)</label></formula><p>using the λ old from the previous iteration as an approximation. Similarly, based on Equations 24 and 25, we correct the calculated µ new and σ 2 new as</p><formula xml:id="formula_18" coords="7,99.56,699.42,193.34,22.31">µ new ← µ new - φ(α ) -φ(β ) Φ(β ) -Φ(α ) σ old<label>(13)</label></formula><formula xml:id="formula_19" coords="7,316.81,71.51,251.79,38.56">σ 2 new ← σ 2 new " 1 + α φ(α ) -β φ(β ) Φ(β ) -Φ(α ) - " φ(α ) -φ(β ) Φ(β ) -Φ(α ) « 2 # -1<label>(14)</label></formula><p>where α = s t -µ old σ 2 old β = s max -µ old σ 2 old again using the values from the previous iteration. These simple approximations work, but sometimes they seem to increase the number of iterations needed for convergence, depending on the accuracy targeted. Rarely, and for high accuracies only, the approximations possibly handicap EM convergence; the intended accuracy is not reached for up to 1,000 iterations. Generally, convergence happens in 10 to 50 iterations depending on the number of scores (more data, slower convergence), and even with the approximation EM produces considerably better fits than when using the non-truncated densities. To avoid getting locked in a non-converging loop, despite its rarity, we cap the number of iterations to 100. The end-differences we have seen between the observed and expected numbers of documents due to these approximations have always been less than 4 in 100,000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Multiple Runs</head><p>We initialize and run EM as described above. After EM stops, we apply the χ 2 goodness-of-fit test for the observed data and the recovered mixture (see Appendix A). If the null hypothesis H 0 is rejected, we randomize again the initial values and repeat EM for up to 100 times or until H 0 cannot be rejected. If H 0 is rejected in all 100 runs, we just keep the best fit found. We run EM at least 10 times, even if we cannot reject H 0 earlier. Perhaps a maximum of 100 EM runs is an overkill, but we found that there is significant sensitivity to initial conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5">Rejecting Fits on IR Grounds</head><p>Some fits, irrespective of their quality, can be rejected on IR grounds. Firstly, it should hold that R ≤ n, however, since each fit corresponds to t (1 -G t ) non-relevant documents, we can tighten the inequality somewhat to:</p><formula xml:id="formula_20" coords="7,395.24,558.40,160.68,9.65">R ≤ n -t (1 -G t )<label>(15)</label></formula><p>This is a very light condition, which should handle a few extremities. Secondly, concerning the random variables S rel and S nrel , one would expect:</p><formula xml:id="formula_21" coords="7,397.48,619.95,158.44,9.65">E(S rel ) &gt; E(S nrel )<label>(16)</label></formula><p>This is rather only a hypothesis-not a requirement-that good systems should satisfy and there are no guarantees. We have not been able so far to motivate any inequality on score variances.</p><p>We are still experimenting with such conditions, and we have not applied them for producing any of the end-results reported in this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Fitting Results and Analysis</head><p>While the s-d method is non-parametric, there are several parameters in recovering the mixture of the densities: smoothing and sampling (both optional), binning, EM initialization and targeted accuracy, rejection conditions, and maybe others. Table <ref type="table" coords="8,95.06,252.93,4.98,8.64" target="#tab_1">1</ref> provides some data on the fits resulting from the above procedure. The default and A runs use the theoretical truncation of Section 3.3.1; the B runs use the technical truncation of Section 3.3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Sampling, Binning, and Quality of the Fits</head><p>Down-sampling has the effect of eliminating some of the right tails, leading to fewer bins when binning the data. Moreover, the fewer the scores, the less EM iterations and runs are needed for a good fit (data not shown). Downsampling the scores helps supporting the H 0 . At 1 out of 3 stratified sampling, the H 0 cannot be rejected at a significance level of 0.05 for 60-64% of the 2007 topics and for 20% for the 2008 topics. Non-stratified down-sampling with 0.1 probability raises this to 42% for the 2008 topics. Extreme down-sampling to keep only around 1,000 to 5,000 scores supports the H 0 in almost all fits. Consequently, the number of scores and bins plays a big role in the quality of the fits according to the χ 2 test; there is a positive correlation between the median number of bins M and the percentage of rejected H 0 . This effect does not seem to be the result of information loss due to down-sampling; we still get more support for the H 0 when reducing the number of scores by down-truncating the rankings instead of down-sampling them. This is an unexpected result; we rather expected that the increased number of scores and bins is dealt with by the increased degrees of freedom parameter of the corresponding χ 2 distributions. Irrespective of sampling and binning, however, all fits look reasonably well to the eye.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">A Score Continuity Problem?</head><p>In all runs, for a small fraction of topics (2-13%) the optimum number of bins M is near (&lt; 5% difference) to our capped value of 200. For most of these topics, when looking for the optimal number of bins in the range <ref type="bibr" coords="8,230.86,674.64,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="8,243.04,674.64,22.70,8.74">1000]</ref> (numbers are tried with a step of 5%) the binning method does not converge. This means there is no optimal binning as the algorithm identifies the discrete structure of data as being  a more salient feature than the overall shape of the density function. Figure <ref type="figure" coords="8,384.10,487.69,4.98,8.64" target="#fig_2">4</ref> demonstrates this. Since the scores are already randomized to account for rounding (Section 4.2), the discrete structure of the data is not a result of rounding but it rather comes from the retrieval model itself. Internal statistics are usually based on document and word counts; when these are low, statistics are "rough", introducing the discretization effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Convexity of Fits</head><p>Concerning the theoretical anomaly of the normalexponential mixture, we investigate the number of fits presenting the anomaly within the observed score range, i.e. at a rank below rank-1 (k c &gt; 1). 6 We see that the anomaly shows up in a large number of topics (64-80%). The impact of non-convexity on the s-d method is that the method turns "blind" at rank numbers &lt; k c restricting the estimated op- 6 In our context we re-formulated the recall-fallout convexity hypothesis as a condition on smoothed precision. So there is no issue of convexity but rather the issue of the precision monotonically declining with the score. However, we stick to using the term "convexity" in describing the problem. Figure <ref type="figure" coords="9,82.38,412.95,3.88,8.64">5</ref>: For topic 91 (top plot), the fit looks good but has a convexity problem in the whole ranking (kc ≥ 25, 000), indicated by having to flatten its precision in the whole range. Alternatively, the fit could have been rejected on IR grounds. By enabling the condition of Equation <ref type="formula" coords="9,124.61,457.43,7.47,7.77" target="#formula_21">16</ref>, i.e. the expected relevant score should be larger than the expected non-relevant, the method would have rejected the fit and produce another one (bottom plot) with a slightly larger χ 2 but no convexity problem. (Both datasets are downsampled; the slight variation of the observed data across the plots are due to different samples used.) timal thresholds wtih K ≥ k c . However, the median rank number k c down to which the problem exists is very low compared to the median estimated number of relevant documents R (7,484 or 32,233), so K &lt; k c is unlikely on average anyway and thresholding should not be affected. Consequently, the data suggest that the non-convexity should have an insignificant impact on s-d thresholding.</p><p>For a small number of topics (0-10%), the problem appears for k c &gt; R and non-convexity should have a significant impact. Still, we argue that for a good fraction of such topics, a large k c indicates a fitting problem rather than a theoretical one. Figure <ref type="figure" coords="9,146.81,710.82,4.98,8.64">5</ref> explains this further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">Ranking-length Bias</head><p>Since there are more data at lower scores, EM results in parameter estimates that fit the low scores better than the high scores. This is exactly the opposite of what is needed for IR purposes, where the top of rankings is more important. It also introduces a weak but undesirable bias: the longer the input ranked list, the lower the estimates of the means of the normal and exponential; this usually results in larger estimations of R and K.</p><p>Trying to neutralize the bias without actually removing it, input ranking lengths can better be chosen according to the expected R. This also makes sense for the estimation method irrespective of biases: we should not expect much when trying to estimate, e.g., an R of 100,000 from only the top-1000. As a rule-of-thumb, we recommend input ranking lengths of around 1.5 times the expected R with a minimum of 200. According to this recommendation, the 2007 rankings truncated at 25,000 are spot on, but the 100,000 rankings of 2008 are falling short by 20%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Summary and Future Improvements</head><p>Recovering the mixture with EM has been proven to be "tricky". However, with the improvements presented in this paper, we have reached a rather stable behavior which produces usable fits.</p><p>EM's initial parameter settings can further be tightened resulting in better estimates in less iterations and runs, but we have rather been conservative in order to preserve the generality.</p><p>As a result of how EM works-giving all data equal importance-a weak but undesirable ranking-length bias is present: the longer the input ranking, the larger the R estimates. Although the problem can for now be neutralized by choosing the input lengths in accordance with the expected R, any future improvements of the estimation method should take into account that score data are of unequal importance: data should be fitted better at their high end.</p><p>Whatever the estimation method, conditions for rejecting fits on IR grounds such as those investigated in Section 4.3.5, seem to have a potential for further considerable improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we will conduct a range of experiments with the truncated models of <ref type="bibr" coords="9,412.79,591.48,10.58,8.64" target="#b4">[5]</ref>, which we discussed in great detail above. Since our focus is the thresholding problem, we use an off-the-shelf retrieval system: the vector-space model of Apache's Lucene.</p><p>More information about the collection, topics, and evaluation measures can be found in the overview paper in this volume, and at the TREC Legal web-site.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Runs</head><p>For TREC Legal 2007 and 2008 we created the following runs:</p><p>Legal07 Off-the-shelf LUCENE using the RequestText as query, on a stemmed index, using the generic SMART stoplist. The 2007 rankings are truncated at 25k results.</p><p>This run is the run labeled catchup0701t in <ref type="bibr" coords="10,256.03,98.30,10.58,8.64" target="#b3">[4]</ref>.</p><p>Legal08 Same as above, but in pre-processing this year's topics, we used the RequestText field stop-listed by an extended list in which we manually included lowcontent words based on the topics of 2006 and 2007. All 2008 rankings are truncated at 100k items.</p><p>This runs is the basis for the official submissions labeled uva-xcons, uva-xb, and uva-xk.</p><p>For the threshold optimization, we first apply the original version of the score-distributional threshold optimization as it has been used, for example, in the Filtering track <ref type="bibr" coords="10,258.96,243.04,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="10,272.24,243.04,7.38,8.64" target="#b2">3]</ref>:</p><p>sd original First fitting a mixture of normal (for relevant) and exponential (for non-relevant) to the score distribution, and then calculate the rank that maximizes the F 1 measure. Note that the fit may indicate an optimal rank threshold beyond the run's length (25k in 2007 and 100k in 2008), in which case we simply select the final rank.</p><p>This run corresponds to our official submission labeled uva-xk.</p><p>In this paper, we presented an improved version of the sd method in Section 3. The improvements that have the greatest impact on end-user effectiveness are:</p><p>1. Use of truncated distributions <ref type="bibr" coords="10,193.74,432.78,11.62,8.64" target="#b4">[5]</ref> to account for natural score bounds or truncations.</p><p>2. EM is run with different initial parameters, and better termination methods. We also now run it up to 100 times instead of 10.</p><p>3. We used the square error before to select the best fit; we replaced this with the χ 2 which is more suitable for distributions.</p><p>4. Optimal binning. Before, we used a fixed number of max(5, t/200) bins, which gave 500 bins (or a bit less after a left-truncation of the data) for the 2008 rankings.</p><p>Consequently, we provide here additional runs:</p><p>Theoretical Truncation Runs using the theoretical truncation of Section 3.3.1. The B runs is down-sampled (a stratified sample of 1/3).</p><p>Theoretical Truncation Runs using the technical truncation of Section 3.3.2. The A runs are down-sampled (a stratified sample of 1/3). Details of the effect of sampling and binning on the fits are in Table <ref type="table" coords="10,237.58,708.67,3.74,8.64" target="#tab_1">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussion</head><p>We first discuss the overall quality of the rankings, and then the main topic of this paper-estimating the cut-off K.</p><p>The top half of Table <ref type="table" coords="10,410.92,420.57,4.98,8.64" target="#tab_4">2</ref> shows several measures on the two underlying rankings, Legal07 and Legal08. We show precision at 5 (all top-5 results were judged by TREC); estimated recall at B; and the F 1 of the estimated precision and recall at R (i.e. the estimated number of relevant documents).</p><p>To determine the quality of our rankings in comparison to other systems, we show the highest, lowest, and median performance of all submissions in the bottom half of Table 2. As it turns out, Legal08 obtains exactly the median performance for Recall@B and F 1 @R when using all relevant documents in evaluation. Both rankings fare somewhat better than the median at P rec@5 and in evaluating with the highly relevant documents only. It is clear that our rankings are far from optimal in comparison with the other submissions. On the negative side, this limits the performance of the s-d method. On the plus side, it makes our rankings good representatives of the median-quality ranking.</p><p>Table <ref type="table" coords="10,352.38,626.03,4.98,8.64" target="#tab_5">3</ref> shows the results for the various thresholding methods. We see that the original s-d method stays well behind the F 1 @R in Table <ref type="table" coords="10,423.86,649.94,3.74,8.64" target="#tab_4">2</ref>. Although this comparison is unfair, the mean estimated number of relevant items is generally not known, we expected the original s-d method to do better.</p><p>All runs with the improved version of the s-d method lead to significantly better results. The B run use the theoretical We also show the highest, lowest, and median performance over the 23 submissions to TREC Legal 2008 (recall that the thresholding task is new at TREC 2008, so there is no comparable data for 2007). Note that the actual value of F 1 @K is a result of both the quality of the underlying ranking and choosing the right threshold. As seen earlier, our ranking has the median Recall@B and F 1 @R. With the estimated threshold of the s-d model, the F 1 @K is 0.1374, well above the median score of 0.0974.</p><p>There is still amble room for improvement. The F 1 @R in Table <ref type="table" coords="11,89.59,505.77,4.98,8.64" target="#tab_4">2</ref> is 0.1328 for 2007 and 0.1709 for 2008, and we obtain 75-80% of these scores. Obviously, R is not known in an operational system, and F 1 @R serves as a soft upperbound on performance.  Before discussing each of the topics in detail, an immediate observation is that the estimated (non-interpolated) precision is strikingly different from monotonically declining "ideal" precision curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Further Analysis</head><p>For Topic 73 (Legal 2007), the estimated R exceeds the length of the ranking, and the K opt corresponds to the last found relevant document at rank 22,091. The s-d model is clearly aiming too low and estimates R at 2,720 and K at 2,593.</p><p>Topic 105 (Legal 2008) has an R of 34,424, well within the length of the ranking, and the s-d model estimates an R of 36,503, near to the real R, and an estimated K of 28,952. The divergence in the prediction of K may be explained, in part, by the fact that K opt always corresponds to a point where a relevant document is retrieved, and judged documents are very sparse down at this rank.</p><p>Topic 124 (Legal 2008) has an R of 20,083 and the s-d model predicts an R of 51,231 and a K of 43,597. Here, the R is overestimated but the K is very close to the K opt . Topic 145 (Legal 2008) has an R of 91,790, very close to the length of the ranking. The s-d model predict an R of 87,060 and a K of 91,590, both relatively close to the official evaluation especially when bearing in mind that the K opt is again at the last relevant document in the whole ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We studied the problem of finding an "optimal" point to stop reading a ranked list, by selecting thresholds that optimize the F 1 -measure. The approach taken employs the scoredistributional threshold optimization (s-d), a non-parametric method proven effective for binary classification in earlier years. We made significant theoretical and computational improvements over the original method, and identified room for further improvements.</p><p>The method uses no other input than the document scores of a standard retrieval run, fit a mixture of (possibly truncated) normal and exponential distributions (normal for relevant, and exponential for non-relevant document scores), and calculate the optimal score threshold given the estimated distributions and their contributing weight. The experiments confirm that the s-d method is effective for determining thresholds, although there is still clear room for improvement: the effectiveness varies considerably per topic, with an average performance of 75-80% of F 1 @R.</p><p>Assuming that a normal-exponential mixture is a good approximation for score distributions and that no relevance information is available, we believe that the improved methods described in this paper are a) as general as possible, b) they deal with most known theoretical anomalies and practical difficulties, and consequently, c) they bring us closer to the performance ceiling of s-d thresholding. If the effectiveness is deemed unsatisfactory, further improvements of s-d thresholding should come from using alternative mixtures or training data. Nevertheless, some other mixtures may be more difficult-or even impossible-to estimate.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Chi-Square Goodness of Fit</head><p>To determine the quality of the fits, we bin the scores and calculate the χ 2 statistic</p><formula xml:id="formula_22" coords="13,133.31,442.04,155.85,25.25">χ 2 = X i |Oi -Ei| 2 Ei (<label>17</label></formula><formula xml:id="formula_23" coords="13,289.17,449.90,3.73,7.77">)</formula><p>where Oi and Ei are the observed and expected frequencies respectively for bin i. The expected frequency is calculated by</p><formula xml:id="formula_24" coords="13,122.88,504.38,100.95,8.35">Ei = t (F (si,a) -F (s i,b ))</formula><p>where si,a and s i,b are respectively the lower and upper score limits of bin i, and F (s) = (1-Gt)F (s|0)+GtF (s|1) is the cumulative distribution function of the mixture under estimation. The statistic follows, approximately, a χ 2 distribution with M -4 -1 degrees of freedom, where M is the number of bins and 4 is the number of parameters we estimate. The null hypothesis H0 is that the observed data follow the estimated mixture. H0 is rejected if the χ 2 of the fit is above the critical value of the corresponding χ 2 distribution at a significance level of 0.05 <ref type="bibr" coords="13,216.31,612.49,13.75,7.77" target="#b14">[15]</ref>.</p><p>For the χ 2 approximation to be valid, Ei should be at least 5, thus we may combine bins in the right tail when Ei &lt; 5. When the last Ei does not reach 5 even for b = +∞, we only then apply the Yates' correction, i.e. subtract 0.5 from the absolute difference of the frequencies in Equation 17 before squaring.</p><p>Different fits on the same data can result to slightly different degrees of freedom due to combining bins. To compare the quality of different fits, so we can keep track of the best one irrespective its H0 status, we use the χ 2 upper-probability; the higher the probability, the better the fit. As an initial upper-probability reference, we use the one of an exponential-only fit, produced by setting λ = 1/(µs -st).</p><p>The χ 2 statistic is sensitive to the choice of bins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Score Binning</head><p>For binning, we use the optimal number of bins as this is given by the method described in <ref type="bibr" coords="13,405.15,133.12,13.75,7.77" target="#b11">[12]</ref>. The method considers the histogram to be a piecewise-constant model of the underlying probability density. Then, it computes the posterior probability of the number of bins for a given data set. This enables one to objectively select an optimal piecewise-constant model describing the density function from which the data were sampled. For practical reasons, we cap the number of bins to a maximum of 200.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Formulas and Derivations</head><p>For completeness, we give here the rest of the formulas not given throughout the paper, and the derivations of those not found in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Density Functions</head><p>• standard normal distribution <ref type="bibr" coords="13,440.41,285.51,13.95,7.77" target="#b15">[16]</ref>:</p><formula xml:id="formula_25" coords="13,386.09,300.93,169.83,16.84">φ(s) = exp `-s 2 /2 √2π s ∈ R<label>(18)</label></formula><p>• exponential distribution <ref type="bibr" coords="13,424.09,334.13,14.94,7.77" target="#b15">[16]</ref> ψ(s; λ) = λ exp(-λs) λ &gt; 0, s ≥ 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Cumulative Distribution Functions</head><p>• standard normal <ref type="bibr" coords="13,397.00,386.62,13.95,7.77" target="#b15">[16]</ref>:</p><formula xml:id="formula_27" coords="13,372.81,402.27,183.11,22.00">Φ(s) = 1 2 » 1 + erf " s √ 2 «- s ∈ R<label>(20)</label></formula><p>where erf(.) is the error function.</p><p>• two-side truncated normal <ref type="bibr" coords="13,433.01,447.01,60.50,7.77">[10, pp.156-162]</ref>:</p><formula xml:id="formula_28" coords="13,352.28,463.38,203.63,22.15">F (s|1) = Φ `s-µ σ ´-Φ(α) Φ(β) -Φ(α) s ∈ [smin, smax]<label>(21)</label></formula><p>where α and β are given by Equation <ref type="formula" coords="13,472.95,494.83,7.47,7.77" target="#formula_8">11</ref>.</p><p>• exponential <ref type="bibr" coords="13,380.68,508.75,13.95,7.77" target="#b15">[16]</ref>:</p><formula xml:id="formula_29" coords="13,379.59,525.84,176.32,8.06">Ψ(s; λ) = 1 -exp(-λs) s ≥ 0<label>(22)</label></formula><p>• shifted and right-truncated exponential:</p><formula xml:id="formula_30" coords="13,349.04,561.79,206.88,19.75">F (s|0) = Ψ(s -smin; λ) Ψ(smax -smin; λ) s ∈ [smin, smax]<label>(23)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Moments of a Truncated Normal</head><p>These can be found in the literature, e.g. in <ref type="bibr" coords="13,488.47,609.72,13.74,7.77" target="#b9">[10]</ref>. Let S be a normally-distributed random variable with mean µ and variance σ 2 , which we left-truncate at smin and right-truncate at smax.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.1 Expected Value</head><p>E(S|smin ≤ S &lt; smax) = µ + φ(α) -φ(β) Φ(β) -Φ(α) σ (24)</p><p>We do not us the ≤ sign at the upper limit of S here (and in the equations below) to denote that the right-truncation is an option (i.e. smax can be +∞) in the context of this paper. We have not found those in the literature. Let S be an exponentially distributed random variable with rate parameter λ, which we shift by smin and right-truncate at smax.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4.1 Expected Value</head><p>From the definition of the expected value of a truncated distribution 7 and Equation <ref type="formula" coords="14,123.29,233.82,8.97,7.77" target="#formula_26">19</ref>E(S|smin ≤ S &lt; smax) = as expected; the shift does not affect the variance <ref type="bibr" coords="14,494.76,188.89,13.74,7.77" target="#b15">[16]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,53.80,239.60,239.11,8.64;4,53.80,251.20,239.10,7.77;4,53.80,262.16,239.10,7.77;4,53.80,272.83,239.10,8.06;4,53.80,283.79,239.11,8.06;4,53.80,294.75,222.19,8.06"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Precision, Recall, and F1-as these are estimated by TREC's deep-sampling method-averaged over all 26 topics of TREC Legal 2008. By rank 100,000, precision is still flat rather than declining, recall is still rising, so F1 has not yet peaked; this suggests that there are optimal K's larger than 100,000. Systems correctly predicting K's larger than 100,000 do not get credit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,375.86,240.59,121.01,8.64"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Theoretical truncation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,316.81,369.80,239.10,8.64;8,316.81,381.41,239.11,7.77;8,316.81,392.08,80.16,8.06;8,396.97,390.31,3.65,5.24;8,404.11,392.08,151.80,8.06;8,316.81,403.04,239.10,8.06;8,316.81,414.00,140.08,8.06;8,456.89,412.23,3.65,5.24;8,464.01,414.29,91.91,7.77;8,316.81,424.96,239.10,8.06;8,316.81,436.20,230.35,7.77"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: The optimal number of bins does not seem to converge, so it is capped at 200. Due to the high number of bins, the best fit found has a large χ 2 = 2231.4. Combining bins with expected frequency &lt; 5 on the right tail, minus 4 the parameters we estimate, gives 84 degrees of freedom for the χ 2 distribution and a critical value of 106.4 at .05 significance. The upper-probability of the fit is practically 0, nevertheless, it looks reasonably well to the eye.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,53.80,239.60,239.10,8.64;11,53.80,251.20,123.60,7.77"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: F1@R versus F1@K as estimated by s-d method for all 26 topics of TREC Legal 2008.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,53.80,573.94,239.10,9.72;11,53.80,586.29,239.11,9.33;11,53.80,597.85,232.45,9.03;11,53.80,617.94,214.28,9.72;11,53.80,638.09,224.24,9.72;11,53.80,658.24,224.24,9.72;11,53.80,678.39,224.24,9.72"><head>Figure 6</head><label>6</label><figDesc>Figure 6 show the F 1 scores of the Legal 2008 B run, plotted against the "ceiling" of F 1 at the estimated R. We will look in detail at some of the topics from 2007 and 2008 B runs: Topic 73 B = 4,085; est.R = 31,894; K opt = 22,091. Topic 105 B = 36,549; est.R = 34,424; K opt = 49,439. Topic 124 B = 86,075; est.R = 20,083; K opt = 44,524. Topic 145 B = 40,315; est.R = 91,790; K opt = 82,806.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,62.77,698.87,230.13,8.64;11,53.80,710.82,239.10,9.33"><head>Figure 7</head><label>7</label><figDesc>Figure 7 compares the prediction of the s-d model with the official evaluation's estimated precision, recall, and F 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="12,143.36,448.24,320.21,8.64"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: S-D model predictions (top plots) versus the official evaluation (bottom plots).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="14,53.80,56.89,69.37,8.96;14,124.15,73.25,98.39,7.86;14,68.55,114.88,15.00,7.86;14,83.87,112.62,3.65,5.24;14,89.56,105.32,5.38,5.76;14,94.93,114.88,13.82,7.86;14,112.00,109.07,62.79,7.86;14,118.15,120.96,50.49,7.86;14,178.03,114.88,7.16,7.86;14,187.24,108.01,57.29,8.93;14,195.22,120.96,50.49,7.86;14,246.90,105.32,16.31,8.45;14,277.96,115.17,14.94,7.77;14,53.80,152.61,215.68,8.96"><head>B. 4</head><label>4</label><figDesc>Moments of a Shifted Truncated Exponential</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="14,170.24,250.87,22.06,7.00;14,174.59,258.86,14.70,6.38;14,194.83,253.58,72.22,7.86;14,183.52,267.80,70.25,7.86;14,270.80,261.72,7.16,7.86;14,94.99,298.80,7.16,7.86;14,115.82,292.99,50.45,7.86;14,105.92,304.88,70.25,7.86;14,180.95,286.64,15.91,5.24;14,182.50,292.34,5.12,5.76;14,177.45,313.99,14.70,6.38;14,196.84,298.80,54.86,7.86;14,53.80,326.58,239.11,8.06;14,53.80,337.82,201.00,7.77;14,254.80,335.96,2.99,5.18;14,76.50,355.87,15.91,5.24;14,78.05,361.57,5.12,5.76;14,73.01,383.21,14.70,6.38;14,92.40,368.02,64.59,7.86;14,159.55,361.15,44.15,8.93;14,178.38,374.10,12.55,7.86;14,206.42,361.15,6.79,5.76;14,213.21,368.02,13.50,7.86;14,233.93,362.22,4.61,7.86;14,229.96,374.10,12.55,7.86;14,243.70,359.53,27.56,7.38;14,255.34,379.08,14.70,6.38;14,53.80,400.67,239.10,7.77;14,53.80,411.63,27.64,7.77;14,53.80,434.76,97.75,7.86;14,155.70,428.96,4.61,7.86;14,155.31,440.85,5.38,7.86;14,161.88,434.76,7.16,7.86;14,170.25,428.96,134.89,7.86;14,202.81,440.85,70.25,7.86;14,277.96,451.48,14.94,7.77;14,57.88,462.15,235.02,8.06;14,53.80,473.11,239.10,8.06;14,53.80,484.36,58.77,7.77;14,120.50,506.55,67.20,7.86;14,191.84,500.76,4.61,7.86;14,191.46,512.64,5.38,7.86;14,200.08,506.55,25.63,7.86;14,53.80,530.14,239.10,8.06;14,53.80,541.39,51.15,7.77;14,53.80,556.84,69.37,8.96;14,53.80,572.99,239.10,8.06;14,53.80,583.95,239.10,8.06;14,53.80,595.20,225.04,7.77;14,53.80,625.72,75.29,7.86;14,129.08,623.46,3.65,5.24;14,133.23,625.72,99.78,7.86;14,233.02,623.46,3.65,5.24;14,237.17,625.72,59.47,7.86;14,53.80,661.14,110.17,7.86;14,167.73,655.34,64.62,7.86;14,232.36,653.57,3.65,5.24;14,236.51,655.34,59.47,7.86;14,227.34,666.69,8.53,8.40;14,64.66,681.95,185.20,7.88;14,53.80,693.67,57.38,5.62;14,64.66,701.14,219.64,7.88;14,53.80,712.86,110.94,5.62;14,322.12,57.64,233.79,8.06;14,316.81,68.60,86.35,7.86;14,403.16,66.83,3.65,5.24;14,407.31,68.60,148.60,8.06;14,316.81,79.84,6.98,7.77;14,316.81,103.12,98.39,7.86;14,421.43,97.32,4.61,7.86;14,418.97,108.67,9.03,8.40;14,431.22,96.24,6.79,5.76;14,484.95,97.32,4.61,7.86;14,439.20,109.20,96.11,7.86;14,538.55,103.12,13.82,7.86;14,552.38,96.24,6.79,5.76;14,540.98,120.03,14.94,7.77;14,320.89,130.70,235.02,8.06;14,316.81,141.66,194.83,8.06;14,378.95,165.94,67.84,7.86;14,453.01,160.14,4.61,7.86;14,450.55,171.49,9.03,8.40;14,463.83,165.94,29.95,7.86"><head>2 7λ 2 " 2 1 - 1 «</head><label>22211</label><figDesc>s -smin; λ) ds Ψ(smax -smin; λ) = = λ exp(λsmin) Ψ(smax -smin; λ) smax Z s min s exp(-λs) dswhere the shift of the exponential by smin is already taken into account. From lists of integrals of exponential functions8   Putting the last 2 equations together and working out the calculation leads toE(S|smin ≤ S &lt; smax) = 1 λ -smax exp(-λ(smax -smin)) -smin Ψ(smax -smin; λ)(26) For only shift but no truncation (smin = 0, smax = +∞), ψ(smax -smin; λ) = 0 and Ψ(smax -smin; λ) = 1, so Equation 26 becomesE(S|smin ≤ S) = 1 λ + sminwhich for a zero shift (smin = 0) it becomes E(S) = 1/λ, as expected<ref type="bibr" coords="14,87.77,541.39,13.74,7.77" target="#b15">[16]</ref>.B.4.2 VarianceWe can break down a shifted S to a mixture of its right-truncated and left-truncated parts weighted by a and b where a + b = 1. The two parts are non-correlated, so for their variances it holds thatV(S|smin ≤ S) = a 2 V(S|smin ≤ S &lt; smax)+b 2 V(S|smax ≤ S) ⇒ V(S|smin ≤ S &lt; smax) = V(smin ≤ S) -b 2 V(S|smax ≤ S)a http://en.wikipedia.org/wiki/Truncated distribution 8 http://en.wikipedia.org/wiki/List of integrals of exponential functions Since shifts do not affect variances, V(S|smin ≤ S) = V(S|smax ≤ S) = 1/λ 2 . Moreover, a = Ψ(smax-smin), leading toV(S|smin ≤ S &lt; smax) = 1 exp(λ(smin -smax)) -(27) For only shift but no truncation (smin = 0, smax = +∞), exp (λ (smin -smax)) = 0 and Equation 27 becomesV(S|smin ≤ S) = 1 λ 2 = V(S)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,109.95,64.07,389.81,100.25"><head>Table 1 :</head><label>1</label><figDesc>The effects of sampling and binning on fitting quality, and convexity of fits.</figDesc><table coords="8,109.95,89.71,389.81,74.61"><row><cell>run</cell><cell cols="3">f M M &gt; 190 H0 no reject</cell><cell>kc &gt; 1</cell><cell>e kc</cell><cell>kc &gt; e R comments</cell></row><row><cell cols="2">2007-default 56.5</cell><cell>4 (8%)</cell><cell cols="2">2 (4%) 33 (66%)</cell><cell cols="2">29 5 (10%) no smth or sampling</cell></row><row><cell>2007-A</cell><cell>37</cell><cell>1 (2%)</cell><cell cols="2">32 (64%) 40 (80%)</cell><cell cols="2">34 5 (10%) smth + 1/3 strat. sampl.</cell></row><row><cell>2007-B</cell><cell>36</cell><cell>1 (2%)</cell><cell cols="3">30 (60%) 32 (64%) 61.5</cell><cell>1 (2%) smth + 1/3 strat. sampl.</cell></row><row><cell>2008-default</cell><cell>93</cell><cell>6 (13%)</cell><cell cols="2">0 (0%) 29 (64%)</cell><cell>89</cell><cell>0 (0%) no smth or sampling</cell></row><row><cell>2008-A</cell><cell>63</cell><cell>1 (2%)</cell><cell cols="2">5 (11%) 30 (67%)</cell><cell>98</cell><cell>0 (0%) smth + 1/3 strat. sampl.</cell></row><row><cell>2008-B</cell><cell>66</cell><cell>4 (9%)</cell><cell cols="2">9 (20%) 31 (69%)</cell><cell>45</cell><cell>1 (2%) smth +1/3 strat. sampl.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,316.81,64.07,239.10,113.84"><head>Table 2 :</head><label>2</label><figDesc>Ranking quality for the Legal 2007 &amp; 2008. The highest, lowest, and median are of the 23 submissions in 2008 using the RequestText field only.</figDesc><table coords="10,348.54,108.38,175.66,69.53"><row><cell>Run</cell><cell cols="3">P rec@5 Recall@B F 1 @R</cell></row><row><cell>Legal07</cell><cell>0.3302</cell><cell>0.1548</cell><cell>0.1328</cell></row><row><cell>Legal08</cell><cell>0.4846</cell><cell>0.2036</cell><cell>0.1709</cell></row><row><cell>highest</cell><cell>0.5923</cell><cell>0.2779</cell><cell>0.2173</cell></row><row><cell>median</cell><cell>0.4154</cell><cell>0.2036</cell><cell>0.1709</cell></row><row><cell>lowest</cell><cell>0.0538</cell><cell>0.0729</cell><cell>0.0694</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,316.81,203.20,239.10,149.06"><head>Table 3 :</head><label>3</label><figDesc>Estimating cut-off K for the Legal 2007 &amp; 2008. The highest, lowest, and median are of the 23 submissions using the RequestText field. Statistical significance (t-test, one-tailed) at 95% ( • ) and 99% ( • ) against the original sd method.</figDesc><table coords="10,461.19,258.74,62.62,8.64"><row><cell>2007</cell><cell>2008</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,331.16,683.73,224.75,6.91;2,316.81,693.19,239.10,6.91;2,316.81,702.66,239.10,6.91;2,316.81,712.12,192.91,6.91"><p>Probabilistic foundations necessary to follow the discussion can be found in several sources, [e.g.,<ref type="bibr" coords="2,417.95,693.19,9.96,6.91" target="#b9">10,</ref><ref type="bibr" coords="2,430.39,693.19,9.96,6.91" target="#b10">11,</ref><ref type="bibr" coords="2,442.84,693.19,9.46,6.91" target="#b15">16]</ref>. Where the derivation of a formula is obvious or it can easily be found in the literature, we give directly the result. Otherwise, we show its derivation in Appendix B.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="5,331.16,702.66,224.75,6.91;5,316.81,712.12,163.02,6.91"><p>Another method for producing unbiased estimators in filtering can be found in<ref type="bibr" coords="5,345.59,712.12,12.22,6.91" target="#b21">[22]</ref>, but it requires relevance judgements.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="6,331.16,636.14,224.75,6.91;6,316.81,645.61,239.10,6.91;6,316.81,655.07,223.74,6.91"><p>In order not to complicate things further, we do not include the downsampling into the formulas in this paper; it is not difficult to see where things should be weighted inversely proportional to the sampling probability.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="6,327.67,663.28,228.24,8.43;6,316.81,674.26,239.10,6.91;6,316.81,683.47,239.10,7.16;6,316.81,693.19,239.11,6.91;6,316.81,702.40,239.10,7.16;6,316.81,711.87,38.93,7.16"><p><ref type="bibr" coords="6,327.67,663.28,2.99,5.18" target="#b4">5</ref> With some (even biased) training data, suitable initial parameter settings are given in<ref type="bibr" coords="6,373.68,674.26,8.47,6.91" target="#b0">[1]</ref>. Without any training data, assuming that the relevant documents are much fewer than non-relevant by rank t, initial parameters can be estimated as described in<ref type="bibr" coords="6,420.76,693.19,12.39,6.91" target="#b13">[14]</ref>; unfortunately this assumption cannot be made in TREC Legal due to the large variance of estimated R and topics with R &gt; t.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>We thank <rs type="person">Nir Nussbaum</rs> for producing the rankings and submitting the official runs. We also benefited from discussions with <rs type="person">Stephen Robertson</rs>.</p><p>This research was supported by the <rs type="funder">Netherlands Organization for Scientific Research (NWO</rs>, grant # <rs type="grantNumber">612.066.513</rs>, <rs type="grantNumber">639.072.601</rs>, and <rs type="grantNumber">640.001.501</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_g7KHjMS">
					<idno type="grant-number">612.066.513</idno>
				</org>
				<org type="funding" xml:id="_4xDuww2">
					<idno type="grant-number">639.072.601</idno>
				</org>
				<org type="funding" xml:id="_MEF7v56">
					<idno type="grant-number">640.001.501</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,73.72,586.14,219.18,7.77;12,73.72,597.10,219.18,7.77;12,73.72,607.91,127.76,7.93" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,134.35,586.14,158.55,7.77;12,73.72,597.10,219.18,7.77;12,73.72,608.06,65.18,7.77">Unbiased s-d threshold optimization, initial query degradation, decay, and incrementality, for adaptive document filtering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,154.90,607.91,19.33,7.72">TREC</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,73.72,620.61,219.18,7.77;12,73.72,631.57,219.18,7.77;12,73.72,642.38,197.31,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,207.23,620.61,85.67,7.77;12,73.72,631.57,219.18,7.77;12,73.72,642.53,16.81,7.77">The score-distributional threshold optimization for adaptive binary classification tasks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Van Hameren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,106.83,642.38,79.19,7.72">Proceedings SIGIR&apos;01</title>
		<meeting>SIGIR&apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,73.72,655.09,219.18,7.77;12,73.72,666.04,219.18,7.77;12,73.72,676.85,172.72,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,104.09,666.04,188.81,7.77;12,73.72,677.00,110.13,7.77">Incrementality, half-life, and threshold optimization for adaptive document filtering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H A</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">P</forename><surname>Van Der Weide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,199.86,676.85,19.33,7.72">TREC</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,73.72,689.56,219.18,7.77;12,73.72,700.51,219.18,7.77;12,73.72,711.32,118.38,7.93" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="12,279.46,689.56,13.44,7.77;12,73.72,700.51,219.18,7.77;12,73.72,711.47,31.61,7.77">Access to legal documents: Exact match, best match, and combinations</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koolen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nussbaum</surname></persName>
		</author>
		<editor>TREC. NIST</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,336.73,488.90,219.18,7.77;12,336.73,499.71,219.18,7.93;12,336.73,510.82,20.17,7.77" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,504.71,488.90,51.20,7.77;12,336.73,499.86,162.79,7.77">Threshold optimization using truncated score distributions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Unpublished</note>
</biblStruct>

<biblStruct coords="12,336.73,523.37,219.18,7.77;12,336.73,534.18,219.18,7.93;12,336.73,545.14,199.12,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,396.68,523.37,159.24,7.77;12,336.73,534.33,183.60,7.77">A probabilitstic solution to the selection and fusion problem in distributed information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Baumgarten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,539.88,534.18,16.03,7.72;12,336.73,545.14,68.91,7.72">Proceedings SIGIR &apos;99</title>
		<meeting>SIGIR &apos;99</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,336.73,557.84,219.18,7.77;12,336.73,568.65,219.18,7.93;12,336.73,579.61,186.44,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,392.38,557.84,163.53,7.77;12,336.73,568.80,169.94,7.77">When the most &quot;pertinent&quot; document should not be retrieved -an analysis of the Swets model</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bookstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,513.07,568.65,42.84,7.72;12,336.73,579.61,101.81,7.72">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="377" to="383" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,336.73,592.31,219.18,7.77;12,336.73,603.27,219.18,7.77;12,336.73,614.08,73.22,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,545.46,592.31,10.45,7.77;12,336.73,603.27,219.18,7.77;12,336.73,614.23,10.27,7.77">Information filtering, novelty detection, and named-page finding</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,363.37,614.08,19.33,7.72">TREC</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,336.73,626.78,219.18,7.77;12,336.73,637.59,219.19,7.93;12,336.73,648.55,156.15,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,479.57,626.78,76.35,7.77;12,336.73,637.74,157.41,7.77">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,504.00,637.59,51.91,7.72;12,336.73,648.55,85.89,7.72">Journal of the Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,336.73,661.10,219.18,7.93;12,336.73,672.06,219.19,7.93" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Balakrishnan</surname></persName>
		</author>
		<title level="m" coord="12,514.56,661.10,41.35,7.72;12,336.73,672.06,86.56,7.72">Continuous Univariate Distributions</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct coords="12,336.73,684.61,219.18,7.93;12,336.73,695.57,219.19,7.93" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Balakrishnan</surname></persName>
		</author>
		<title level="m" coord="12,514.56,684.61,41.35,7.72;12,336.73,695.57,86.56,7.72">Continuous Univariate Distributions</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct coords="12,336.73,708.28,219.18,7.77;13,73.72,57.92,20.17,7.77;13,112.06,57.92,180.85,7.77;13,73.72,69.72,50.66,6.32" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">H</forename><surname>Knuth</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/physics/0605197v1" />
		<title level="m" coord="12,394.01,708.28,158.12,7.77">Optimal data-based binning for histograms</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,81.44,219.18,7.77;13,73.72,92.24,219.19,7.93;13,73.72,103.35,83.82,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,130.45,81.44,162.45,7.77;13,73.72,92.40,75.92,7.77">Evaluating and optimizing autonomous text classification systems</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,166.64,92.24,79.25,7.72">Proceedings SIGIR&apos;95</title>
		<meeting>SIGIR&apos;95</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="246" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,115.91,219.18,7.77;13,73.72,126.87,219.18,7.77;13,73.72,137.67,164.20,7.93" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,220.61,115.91,72.29,7.77;13,73.72,126.87,200.88,7.77">Modeling score distributions for combining the outputs of search engines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Rath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,73.72,137.67,79.19,7.72">Proceedings SIGIR&apos;01</title>
		<meeting>SIGIR&apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="267" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,150.38,219.18,7.77;13,73.72,162.17,217.43,6.32" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><surname>Nist/Sematech</surname></persName>
		</author>
		<ptr target="http://www.itl.nist.gov/div898/handbook/" />
		<title level="m" coord="13,156.86,150.38,109.74,7.77">handbook of statistical methods</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,173.74,219.19,7.93;13,73.72,184.70,159.33,7.93" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="13,123.15,173.74,169.75,7.72;13,73.72,184.70,33.93,7.72">Probability, Random Variables, and Stochastic Processes</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Papoulis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct coords="13,73.72,197.40,219.18,7.77;13,73.72,208.21,219.18,7.72;13,73.72,219.17,167.99,7.93" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,134.39,197.40,137.44,7.77">On score distributions and relevance</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,73.72,208.21,219.18,7.72;13,73.72,219.17,29.85,7.72">Proceedings of 29th European Conference on IR Research, ECIR&apos;07</title>
		<meeting>29th European Conference on IR Research, ECIR&apos;07<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,231.87,219.18,7.77;13,73.72,242.68,219.19,7.93;13,73.72,253.64,219.18,7.93;13,73.72,264.75,123.27,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,178.57,231.87,75.08,7.77">Routing and filtering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,208.68,242.68,84.23,7.72;13,73.72,253.64,162.69,7.93">TREC: Experiment and Evaluation in Information Retrieval, chapter 5</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="99" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,277.30,219.18,7.77;13,73.72,288.11,219.18,7.93;13,73.72,299.22,55.53,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,135.03,277.30,157.87,7.77;13,73.72,288.26,102.22,7.77">The parametric description of retrieval tests. part 1: The basic parameters</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,183.98,288.11,93.20,7.72">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,311.62,219.19,7.93;13,73.72,322.73,82.43,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,127.32,311.77,106.54,7.77">Information retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,245.71,311.62,25.92,7.72">Science</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">3577</biblScope>
			<biblScope unit="page" from="245" to="250" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,335.28,219.18,7.77;13,73.72,346.09,155.40,7.93" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="13,122.26,335.28,166.56,7.77">Effectiveness of information retrieval methods</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>American Documentation</publisher>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="72" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,73.72,358.80,219.18,7.77;13,73.72,369.60,219.18,7.93;13,73.72,380.71,83.82,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,163.54,358.80,129.36,7.77;13,73.72,369.75,67.42,7.77">Maximum likelihood estimation for filtering thresholds</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,162.80,369.60,80.43,7.72">Proceedings SIGIR&apos;01</title>
		<meeting>SIGIR&apos;01</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="294" to="302" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
