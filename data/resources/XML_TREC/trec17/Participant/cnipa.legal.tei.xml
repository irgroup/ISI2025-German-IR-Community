<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.56,115.96,320.32,12.91;1,234.84,133.96,165.72,12.91">CNIPA, FUB and University of Rome &quot;Tor Vergata&quot; at TREC 2008 Legal Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,203.76,174.40,78.37,8.97"><forename type="first">Giambattista</forename><surname>Amati</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Fondazione Ugo Bordoni (FUB)</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.60,174.40,59.53,8.97"><forename type="first">Marco</forename><surname>Bianchi</surname></persName>
							<email>marco.bianchi@cnipa.it</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Italian National Centre for ICT in the Public Administrations (CNIPA)</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.48,174.40,63.86,8.97"><forename type="first">Alessandro</forename><surname>Celi</surname></persName>
							<email>alessandro.celi@di.univaq.it</email>
							<affiliation key="aff2">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of L&apos;Aquila, L&apos;Aquila</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,204.36,186.40,54.49,8.97"><forename type="first">Mauro</forename><surname>Draoli</surname></persName>
							<email>draoli@cnipa.it</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Italian National Centre for ICT in the Public Administrations (CNIPA)</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.32,186.40,69.26,8.97"><forename type="first">Giorgio</forename><surname>Gambosi</surname></persName>
							<email>gambosi@mat.uniroma2.it</email>
						</author>
						<author>
							<persName coords="1,368.40,186.40,57.90,8.97"><forename type="first">Giovanni</forename><surname>Stilo</surname></persName>
							<email>stilo@nestor.uniroma2.it</email>
							<affiliation key="aff4">
								<orgName type="laboratory">NESTOR -Laboratory</orgName>
								<orgName type="institution">University of Rome &quot;Tor Vergata&quot;</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Matematics Department</orgName>
								<orgName type="institution">University of Rome &quot;Tor Vergata&quot;</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.56,115.96,320.32,12.91;1,234.84,133.96,165.72,12.91">CNIPA, FUB and University of Rome &quot;Tor Vergata&quot; at TREC 2008 Legal Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">97EC8C1AF1B24D1ACD4B9089878413E5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC Legal track was introduced in TREC 2006 with the claimed purpose of to evaluate the efficacy of automated support for review and production of electronic records in the context of litigation, regulation and legislation. The TREC Legal track 2008 runs three tasks: <ref type="bibr" coords="1,134.76,405.28,11.72,8.97" target="#b0">(1)</ref> an automatic ad hoc task, <ref type="bibr" coords="1,250.80,405.28,11.72,8.97" target="#b1">(2)</ref> an automatic relevance feedback task, and (3) an interactive task. We have only taken part in the automatic ad hoc task of the TREC Legal track 2008, and focused on the following issues:</p><p>1. Indexing. The CDIP test collection is characterized by an large number of unique terms due to OCR mistakes. We have defined a term selection strategy to reduce the number of terms, as described in Section 2. 2. Querying. The analysis of the past TREC results for the Legal track showed that the best retrieval strategy basically returned a ranked list of the boolean retrieved documents. As a consequence, we have defined a strategy aimed to boost the score of documents satisfying the final negotiated boolean query. Furthermore, we defined a method for automatic construction of a weighted query from the request text, as reported in Section 3. 3. Estimation of the K value. We have used a query performance prediction approach to try to estimate K values. The query weighting model that we have adopted is described in Section 4.</p><p>Submitted runs and their evaluation are reported in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Indexing</head><p>The IIT Complex Document Information Processing (CDIP) test collection is based on a snapshot of the Tobacco Master Settlement Agreement (MSA) sub-collection of the LTDL.</p><p>The CDIP collection presents a large number of unique terms due to OCR mistakes. For example, GOV2, one of the biggest test collections (426GB), contains about 50ML unique terms for 25ML of documents, whereas CDIP (57GB of text) contains almost twice as much: 95ML unique terms for 7ML documents.</p><p>We have used the Terrier (TERabyte RetrIEveR) Information Retrieval platform <ref type="bibr" coords="2,450.48,169.60,11.60,8.97" target="#b0">[1]</ref> using the following indexing configuration:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TrecDocTags.doctag=record TrecDocTags.idtag=tid TrecDocTags.process=ot TrecDocTags.casesensitive=false Termpipelines = Stopwords, PorterStemmer</head><p>With this configuration all meta-data were ignored. In addition, words containing more than 20 characters were excluded.</p><p>With such settings the generated index would have had 95ML terms with 14GB of index structures (direct, inverted and lexicon files). Therefore, we have removed from index all terms having a very low frequency (i.e. ≤ 25) producing a lexicon with "only" 9ML terms.</p><p>We have noticed that the presence of OCR errors, by altering both global and local statistics, affects the retrieval quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Retrieval</head><p>We have used a variation of the DFRee model, a parameter free IR model offered by the Terrier platform. With this model we have not had to tune any parameters, and we have focused only on the proposed methodology, by evaluating the gain in performance with respect to the baseline. We have extracted the most informative terms from the top-returned documents as performed in query expansion. In this expansion process, terms in the topreturned documents are weighted using a particular DFR term weighting model. During our experiment we have found that Bo1 (Bose-Einstein statistics) term weighting models best fit with this collection. We have also made tuning on the number of top-returned documents and number of expanded term; we have obtained the best performance considering 5 documents and 10 terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Boolean re-rank</head><p>We have boosted the scores of all documents d i ∈ B, where B is the set of documents satisfying the final negotiated boolean query. The score s i of a document d i ∈ B was augmented by a value s: s </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Topic processing</head><p>According to TREC Legal Track 2008 guideline each topic is composed by 4 fields: Request-Text, ProposalByDefendant, RejoinderByPlaintiff, andFinalQuery. The union of all these fields would have produced a very long query. We have thus indexed all topics to obtain a query lexicon with the aim to remove all query-terms that are non informative. Then for each topic we weighted the remaining query-terms by the number of occurrences in the four fields of the topic. We show here an example of a produced query (topic n.52):</p><formula xml:id="formula_0" coords="3,134.76,292.49,365.21,80.00">affect 1 agricultur 2 fertil 2 commerci 2 yield 4 rai 1 output 2 hpf 3 phosphoru 2 crop 6 greater 1 multipl 1 augment 1 increa 1 introduc 1 boost 3 fertiliz 3 soil 1 phosphat 5 doubl 1 high 4 purpos 1 tripl 1 4 Estimating K values 4.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Query performance prediction</head><p>Robustness is an important measure reflecting the retrieval performance of an Information Retrieval (IR) system. It particularly refers to how an IR system deals with poorlyperforming queries. As stressed by Cronen-Townsend et. al. <ref type="bibr" coords="3,377.88,408.52,10.60,8.97" target="#b1">[2]</ref>, poorly-performing queries considerably hurt the effectiveness of an IR system. Indeed, this issue has become important in IR research. Moreover, the use of reliable query performance predictors is a step towards determining for each query the most optimal corresponding retrieval strategy. For example, in <ref type="bibr" coords="3,144.48,456.28,10.60,8.97" target="#b2">[3]</ref>, the use of query performance predictors allowed to devise a selective decision methodology avoiding the failure of query expansion. In order to predict the performance of a query, the first step is to differentiate the highly-performing queries from the poorly-performing queries. This problem has recently been the focus of an increasing research attention. In <ref type="bibr" coords="3,486.18,492.16,10.60,8.97" target="#b1">[2]</ref>, Cronen-Townsend et. al. suggested that query performance is correlated with the clarity of a query. Following this idea, they used a clarity score as the predictor of query performance.</p><p>In their work, the clarity score is defined as the Kullback-Leibler divergence of the query model from the collection model. In <ref type="bibr" coords="3,279.41,540.04,10.69,8.97" target="#b2">[3]</ref>, Amati et. al. proposed the notion of query-difficulty to predict query performance. Their basic idea is that the term weight, as obtained in query expansion, provides evidence of the query performance. We use a query performance prediction approach to try to estimate a correct K measure. The basic idea is quite simple: with an "easy" query we doesn't need to go deep in the retrieval because all relevant documents are on top; otherwise if we try with an "hard" one, we need to goo much deeper to find all relevant documents:</p><p>′′ easy ′′ query =⇒ ′′ small ′′ K value ′′ hard ′′ query =⇒ ′′ large ′′ K value</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Query weighting model</head><p>Since we had not time to extract expanded query weights we simply used the inverse document frequency:</p><formula xml:id="formula_1" coords="4,272.88,172.24,81.85,26.47">D i = t∈qi -log n t N</formula><p>Where t is a term of a query q i , n t is the number of relevant documents where the term t appears, N is the number of all the documents in the collection. The correlation factor between D i and K i , with K i the optimal value for the F 1 @K, was about 30% with TREC data of 2007, whereas an higher correlation there was between D i and the estimated number of relevant documents (37%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Normalization's variants</head><p>To turn the coefficient D i into an estimated K value we used the Z-Score <ref type="bibr" coords="4,435.25,308.68,10.60,8.97" target="#b3">[4]</ref>. For the new queries we have formulated three different models:</p><formula xml:id="formula_2" coords="4,139.20,340.36,155.07,23.23">1. K O = 1 - D -µ idf σ idf • µ k</formula><p>where µ idf and σ idf are the mean and the standard deviation of all D i respectively and µ k is the mean of the optimal K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">K</head><formula xml:id="formula_3" coords="4,185.16,386.68,110.64,23.23">R = 1 - D -µ idf σ idf • µ R</formula><p>where µ R is the mean of the cardinalities of relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">K</head><formula xml:id="formula_4" coords="4,185.16,420.88,111.02,23.23">B = 1 - D -µ idf σ idf • µ B</formula><p>where µ B is the mean of the cardinalities of B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Submitted runs and results</head><p>For the participation to the ad hoc task we have submitted the following runs:</p><p>-The run labeled as CTFrtSk represents the compulsory baseline. It is computed just using the request text field as query. The K values are computed using the first model described in Section 4.3. -The run labeled as CTFrtSkBr0 is computed just using the (typically one-sentence) request text field as query. The boolean re-rank strategy is applied with α = 0.0. The K values are computed using the first model described in Section 4.3. -The run labeled as CTFggeSkBr0 computed using the query elaboration method described in Section 3. The boolean re-rank strategy is applied with α = 0.0. The K values are computed using the first model described in Section 4.3. -The run labeled as CTFgge4kBr0 is computed using the query elaboration method described in Section 3. The boolean re-rank strategy is applied with α = 0.0. The K values are equal to 40,000 for each topic.</p><p>-The run labeled as CTFgge10kBr0 is computed using the query elaboration method described in Section 3. The boolean re-rank strategy is applied with α = 0.0. The K values are equal to 100,000 for each topic. -The run labeled as CTFggeBkBr0 is computed using the query elaboration method described in Section 3. The boolean re-rank strategy is applied with α = 0.0. The K values are computed using the third model described in Section 4.3. -The run labeled as CTFggeBkBr1 computed using the query elaboration method described in Section 3. The boolean re-rank strategy is applied with α = 1.0. The K values are computed using the third model described in Section 4.3. -The run labeled as CTFggeRkBr0 computed using the query elaboration method described in Section 3. The boolean re-rank strategy is applied with α = 0.0. The K values are computed using the second model described in Section 4.3.</p><p>Results of submitted runs are shown in Table <ref type="table" coords="5,316.15,280.36,3.77,8.97">1</ref>.</p><p>Table <ref type="table" coords="5,248.40,311.80,3.77,8.97">1</ref>. Summary of the CTF Legal track runs. Applying the boolean re-rank to the baseline (CTFrtSkBr0) we improve our performance of +4.99%. The introduction of the the query elaboration method (CTFggeSkBr0) allows to improve our performance of +20.43% with respect to the baseline. If we consider only those runs in which the K value is computed on basis of the query complexity, the best improvement with respect to the baseline is 44.77% (CTFggeBkBr1). This is not our best result. In fact the best run is CTFgge10kBr0. It improves the baseline performance of 68.48% considering K=10000 for each topic. CTFgge10kBr0 differs only -2.03% from the best run among all 64 runs submitted to the ad hoc task of Legal track 2008.</p><formula xml:id="formula_5" coords="5,149.76,333.64,322.92,22.03">F 1 HF 1 Run label est F 1 @K est F 1 @R est HF 1 @K h est F 1 @</formula><p>With respect to the estimated HF 1 @K h metric the baseline is evaluated 0.0481. Seven of the eight submitted runs are over the median of the ad hoc task of Legal track 2008. Our best run is CTFggeRkBr0 with an evaluation of 0.0947 and an improvement of 96.88% over the baseline. CTFggeRkBr0 differs 12.35% from the best run among all 64 runs submitted for the ad hoc task of Legal track 2008.</p><p>We have already started a experimentation aimed to better analyze the relationship between the D i values, introduced in Section 4.2, and the retrieval performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,299.28,610.66,2.20,4.03;2,299.28,618.14,2.82,6.33;2,305.28,613.62,35.39,9.89;2,134.76,634.26,204.90,9.89;2,298.20,655.86,38.83,9.18;3,134.76,118.96,365.63,9.67;3,134.76,130.74,365.74,9.19;3,134.76,142.96,365.73,8.97;3,134.76,154.84,365.93,8.97;3,134.76,166.84,104.63,8.97;3,239.40,164.26,2.20,4.03;3,239.40,166.84,27.09,10.75"><head>′i</head><label></label><figDesc>= s i + s where s = s k is the score of the k-th document and k = α * b b is the number of documents in B and α a parameter. Notice that s k varies on each topic because b depends on the final negotiated boolean query. If α = 0 then the score s 0 of the top-rank document is added to all d ∈ B, and all these documents are shifted up in all topmost positions. Documents also keep the order computed by the DFR model. On the other hand when α → ∞ then s ′ i ∼ s i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.76,345.78,365.83,205.99"><head></head><label></label><figDesc>Six of the eight submitted runs are over the median of the ad hoc task of Legal track 2008.</figDesc><table coords="5,134.76,345.78,365.83,194.11"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>R h</cell></row><row><cell>Best run of the ad hoc task '08</cell><cell>0.2204</cell><cell>0.2458</cell><cell>0.1064</cell><cell>0.1770</cell></row><row><cell cols="2">Median run of the ad hoc task '08 0.1429</cell><cell>0.1823</cell><cell>0.0702</cell><cell>0.1109</cell></row><row><cell>CTFrtSk (baseline)</cell><cell>0.1282</cell><cell>0.1736</cell><cell>0.0481</cell><cell>0.0844</cell></row><row><cell>CTFrtSkBr0</cell><cell>0.1346</cell><cell>0.1822</cell><cell>0.0723</cell><cell>0.1113</cell></row><row><cell>CTFggeSkBr0</cell><cell>0.1544</cell><cell>0.2152</cell><cell>0.0811</cell><cell>0.1008</cell></row><row><cell>CTFgge4kBr0</cell><cell>0.1849</cell><cell>0.2152</cell><cell>0.0818</cell><cell>0.1008</cell></row><row><cell>CTFgge10kBr0</cell><cell>0.2160</cell><cell>0.2152</cell><cell>0.0788</cell><cell>0.1008</cell></row><row><cell>CTFggeBkBr0</cell><cell>0.1800</cell><cell>0.2152</cell><cell>0.0799</cell><cell>0.1008</cell></row><row><cell>CTFggeBkBr1</cell><cell>0.1856</cell><cell>0.2196</cell><cell>0.0824</cell><cell>0.1016</cell></row><row><cell>CTFggeRkBr0</cell><cell>0.1785</cell><cell>0.2152</cell><cell>0.0947</cell><cell>0.1008</cell></row><row><cell cols="5">With respect to the main metric (i.e. estimated F 1 @K) the evaluation of our baseline (CT-</cell></row><row><cell>FrtSk) is 0.1282.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.10,251.88,362.01,8.07;6,146.52,262.80,353.65,8.07;6,146.52,273.84,209.72,8.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,415.56,251.88,84.55,8.07;6,146.52,262.80,184.93,8.07">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,349.92,262.80,150.25,8.07;6,146.52,273.84,183.42,8.07">Proceedings of ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval (OSIR 2006)</title>
		<meeting>ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval (OSIR 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.10,284.76,362.00,8.07;6,146.52,295.68,353.78,8.07;6,146.52,306.72,182.69,8.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,314.97,284.76,104.01,8.07">Predicting query performance</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,434.50,284.76,65.60,8.07;6,146.52,295.68,353.78,8.07;6,146.52,306.72,31.13,8.07">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.10,317.64,362.29,8.07;6,146.52,328.56,353.67,8.07;6,146.52,339.60,262.52,8.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,298.03,317.64,202.36,8.07;6,146.52,328.56,56.88,8.07">Query difficulty, robustness, and selective application of query expansion</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,220.38,328.56,279.81,8.07;6,146.52,339.60,72.19,8.07">Advances in Information Retrieval, Proceedings of the 26th European Conference on IR Research</title>
		<meeting><address><addrLine>Sunderland UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.10,350.52,361.79,8.07;6,146.52,361.44,75.68,8.07" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Altman</surname></persName>
		</author>
		<title level="m" coord="6,188.04,350.52,311.85,8.07;6,146.52,361.44,49.54,8.07">Financial ratios, discriminant analysis and the prediction of corporate bankruptcy. Journal of Finance</title>
		<imprint>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
