<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,104.52,75.94,402.98,14.42;1,133.62,103.54,344.73,14.42">Evaluating a novel kind of retrieval models based on relevance decision making in a relevance feedback environment</title>
				<funder ref="#_8dy3yEu">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,90.66,150.74,39.22,10.80"><forename type="first">H</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName coords="1,139.66,150.74,47.52,10.80"><forename type="first">K</forename><forename type="middle">F</forename><surname>Dang</surname></persName>
						</author>
						<author>
							<persName coords="1,195.98,150.74,54.78,10.80"><forename type="first">R</forename><forename type="middle">W P</forename><surname>Luk</surname></persName>
						</author>
						<author>
							<persName coords="1,259.35,150.74,37.35,10.80"><forename type="first">J</forename><surname>Allan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.71,150.74,54.27,10.80"><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">City University of New York</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,371.02,150.74,53.64,10.80"><forename type="first">K</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,434.64,150.74,38.00,10.80"><forename type="first">G</forename><surname>Ngai</surname></persName>
						</author>
						<author>
							<persName coords="1,495.98,150.74,25.34,10.80"><forename type="first">Y</forename><surname>Li</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,104.52,75.94,402.98,14.42;1,133.62,103.54,344.73,14.42">Evaluating a novel kind of retrieval models based on relevance decision making in a relevance feedback environment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E3F35C0A368833D0132ECBFA4B2214CA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the results of our participation in the relevance feedback track using our novel retrieval models. These models simulate human relevance decision-making. For each document location of a query term, information from its document-context at that location determines the relevance decision outcomes there. The relevance values for all documents locations of all query terms in the same document are combined to form the final relevance value for that document. Two probabilistic models are developed, and one of them is directly related to the TF-IDF term weights. Our initial retrieval is a passage-based retrieval.</p><p>Passage scores of the same document are combined by the Dombi fuzzy disjunction operator. Later, we found that the Markov random field (MRF) model produces better results than our initial retrieval system (without relevance information). If we apply our novel retrieval models using the initial retrieval list of the MRF model, the retrieval effectiveness of our models will be improved. These informal run results using the MRF model used in conjunction with our novel models are also presented.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this participation, we are interested in an alternative RF approach. Previously, we developed various document-context dependent retrieval models <ref type="bibr" coords="2,281.46,126.06,11.72,9.02" target="#b0">[1]</ref> that operate in a RF environment. In here, we further developed and used a fully probabilistic retrieval model. Our approach uses the relevance judgment of the feedback documents to estimate the parameters of our probabilistic models. These models are descriptive ones because they do not adjust their parameters according to their performance, unlike normative models (e.g., support vector machine <ref type="bibr" coords="2,216.86,195.06,11.23,9.02" target="#b1">[2]</ref>) that optimize their performance using training data. In addition, we extended the common TF-IDF term weights so that they become document-context dependent.</p><p>The rest of this paper is organized as follows. Section 2 presents our models. Section 3 describes the set up of our experiments. Section 4 analyze and discusses our results of our formal runs. Section 5 looks at the results of the informal runs. Finally, Section 6 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Our Approach</head><p>Our models are based on the premise that local relevance at a particular document location is determined by the information in the context of that location. The general equation of making relevance decision <ref type="bibr" coords="2,490.31,367.56,11.62,9.02" target="#b2">[3]</ref> may be captured by the following formula: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model 1</head><p>In this model, we use the document-context based model which is similar to <ref type="bibr" coords="2,400.02,589.14,10.64,9.02" target="#b2">[3]</ref>. c(d, k) starts at position kn to k+n such that it has 2n+1 terms (i.e., the context size is 2n+1 and n=25 in the experiments). In the document-context based model, we give scores to the contexts and the scores are summed together to produce the document score. By the query centric assumption <ref type="bibr" coords="2,345.70,640.92,10.61,9.02" target="#b2">[3]</ref>, we only consider the contexts of query terms. In the experiments of the relevance feedback track, besides the contexts of query terms, we also consider the contexts of expansion terms. The set of expansion terms is denoted by Q e . We will discuss how expansion terms are found after presenting the ranking formula.  </p><formula xml:id="formula_0" coords="3,176.94,150.23,256.88,53.05">(i.e., ) , ], [ | ) , ( ( r R Q k d k d c p = ). ∑ ∈ ∧ ∈ ∋ = = = e Q k d Q k d k r R Q k d k d c p r R Q k d k d c p d Score ] [ ] [ ) , ], [ | ) , ( ( ) , ], [ | ) , (<label>( log )</label></formula><formula xml:id="formula_1" coords="3,166.32,282.55,281.02,64.87">+ = = = n n p n n p r R Q k d p k d p r R Q k d p k d p r R Q k d k d c p r R Q k d k d c p ) , ], [ | ] [ ( ) , ], [ | ] [ ( ) , ], [ | ) , ( ( ) , ], [ | ) , ( (</formula><p>The probability of seeing the term t in the relevance model of q i is given by the ratio between the occurrence frequency of the term t in those contexts and the total occurrence frequencies of all the terms in those contexts. Similarly for the irrelevance model of q i which considers the contexts of q i in the irrelevant documents. For the collection model of q i , it considers all the contexts of q i in the documents from the initial retrieval list which is the result of Set A. The probabilities from the relevance model and the irrelevance model are smoothed by the probability from the collection model using linear interpolation with the weight of the relevance/irrelevance model set to 0.1. This is because some of the terms may not occur in the relevance/irrelevance model and they receive zero probabilities which will give undefined result in calculation of the context score. After smoothing with the collection model, all probabilities are larger then zero.</p><p>In finding the expansion terms (in Q e ), a relevance model and an irrelevance model for the query Q are constructed similar to those constructed for each query term q i described in the previous paragraph. The difference is that instead of considering the contexts of a particular query term, we consider the contexts of all query terms (i.e., combining the relevance/irrelevance models of individual query terms to form a relevance/irrelevance model for the query). The terms in the relevance model are ranked by the difference between the probability given by the relevance model and the probability given by the irrelevance model.</p><p>Those terms with the difference smaller than zero are discarded. In our experiments, top 500 terms from the ranked term list are considered as expansion terms. For each expansion, similar to each query term, a relevance model, an irrelevance model and a collection model are constructed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model 2</head><p>Based on the judged N documents (N=1 for RF08.B and N=6 for RF08.C) we apply (1) query expansion (QE) followed by (2) boost and discount, as described below.</p><p>(a) QE Stage: We select query expansion terms from document-contexts within each judged documents. Document-contexts are text windows centered on query terms. The context size is fixed to be 41. We then obtain the vectors rel q and irr q whose elements represent the terms contained in the judged relevant and judged irrelevant documents respectively. The value of a term t is given by</p><formula xml:id="formula_2" coords="4,158.52,254.94,294.59,34.67">⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ + + × × × + = ) ( 1 ) ( 1 ) ( ) ( ) ( 1 ) ( ) ( t tmprf t tmprf t idf t NoDoc t Freq t Freq t Score</formula><p>where Freq(t) = total term frequency of t in the judged relevant / irrelevant document-contexts, NoDoc(t) = number of judged relevant / irrelevant document-contexts that contain t, idf(t) = inverse document frequency of t in the whole collection, and tmprf(t)=df(t)-NoDoc(t)+1, with df(t)= document frequency of t in the collection. For each of rel q and irr q , we include a fixed number of terms (N QE ) with the highest scores. We set N QE =80. The relative weights of the judged relevant and judged irrelevant documents may be specified by a parameter β , so that the query expansion vector is</p><formula xml:id="formula_3" coords="4,235.50,420.03,142.73,30.05">| | ) 1 ( | | irr irr rel rel QE q q q q q β β - - = .</formula><p>Finally, we obtain an expanded query by mixing the original query q and QE q</p><formula xml:id="formula_4" coords="4,258.06,465.06,156.15,57.56">: | | ) 1 ( | | QE QE RF q q q q q α α - + = .</formula><p>We have used the values on a vector space model using BM25 term weights. For the terms that appear in the original query q , we directly modify the tf component of the BM25 term weight, utilizing evidence from the judged documents.</p><p>Generally the specific usage of a query term can be deduced by examining the words in its vicinity. Hence the 'collocation terms', defined as the terms that appear within a document-context centred on a query term in a judged relevant / irrelevant document can provide evidence for / against the relevance of a non-judged document. Hence, in a non-judged document, if the words within a document-context of a query term are similar to the collocation terms found form judged relevant documents, this would support the document as likely to be relevant too. In our algorithm, we implement this effect by giving a 'boost' to the tf component of the BM25 term-weight of the query term. Similarly, if the words lying in the document-context of a query term match the collocation terms extracted from judged irrelevant documents, we 'discount' a certain amount of the tf value. Suppose q ={q 1 , q 2 , …, q n }. In the B&amp;D algorithm, we adjust tf(q i ) according to the matching of words appearing in the context-windows centred on q i with 'boost' or 'discount' collocation terms. Let B B and B D denote the sets of 'boost' and 'discount' collocation terms respectively. These are the context terms extracted from judged relevant and irrelevant documents. In general, the size of the context windows for extracting B B and B D terms may be denoted by consize B and consize D respectively. We introduce the variables c b and c d as matching counts of the 'boost' and 'discount' collocation terms, defined as follows.</p><formula xml:id="formula_5" coords="5,163.62,267.87,132.64,22.03">∑ = w B i b w increment q c ) ( ) (</formula><p>where the sum is over all terms occurring in a document-context centred on q i , and</p><formula xml:id="formula_6" coords="5,163.44,315.18,206.02,34.67">⎩ ⎨ ⎧ ∈ = otherwise 0 if / ) ( ) ( 0 B B B w idf w idf w increment .</formula><p>In the above equation, We directly adjust the tf factor of query term q:</p><formula xml:id="formula_7" coords="5,230.70,470.13,147.52,28.31">∑ + ← k i BD i i k q tf q tf q tf ) , ( ) ( ) (</formula><p>, where the sum is over all locations k of the occurrences of q i in the document, and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Set Up and Calibration</head><p>We used a PC-cluster (called MATRIX) to perform the indexing and retrieval. The GOV2 document collection is distributed to 40 nodes. Each node holds about 10+G bytes documents which are indexed in about 10 hours when there are other jobs running at the time. Note that each node has one CPU that has only one core. On average, the size of each index plus other auxiliary files (e.g., dictionary) in a node is about 500M bytes.</p><p>For the initial retrieval without any RF (i.e., Set A), we calibrated our retrieval system using the 2005-2007 Terabyte track collections. Passages of at most 300 terms are used as the basic unit of retrieval. The passage scores are based on our version of the BM25 term weights <ref type="bibr" coords="6,394.14,212.34,10.63,9.02" target="#b3">[4]</ref>. These passage scores are normalised between zero and one, and their normalised values are treated as membership values that are fed into the fuzzy disjunction Dombi operator <ref type="bibr" coords="6,261.21,246.84,10.62,9.02" target="#b4">[5]</ref>. Pseudo-relevance feedback (PRF) is used. It reads the top 15 passages in the initial retrieval list in order to expand the original title query by adding 80 expansion terms.</p><p>The mean average precision (MAP) of the initial retrieval was around 23%. The top 3000 documents of this retrieval list are re-ranked by our model 1 and 2 for feedback sets B-E, which contain different number of relevance documents and nonrelevant documents in different sets. Set B contains one relevant feedback document for each query. Set C contains 3 relevant and 3 non-relevant feedback documents for each query.</p><p>Set D contains 10 judged feedback documents for each query. Finally, Set E contains many judged relevant and nonrelevant feedback documents.</p><p>For our calibration, we compared the performance of our model 1 with SVM that is trained using the feedback documents. Our model 1 and SVM re-ranked the same initial retrieval list produced by our retrieval system with PRF. Results are shown in Table <ref type="table" coords="6,320.67,436.56,3.76,9.02" target="#tab_0">1</ref>. The MAPs of our model 1 are better than the corresponding MAPs of the SVM for feedback sets C and D. The statistical significance of their MAP differences is at the 95% confidence level. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Formal Runs</head><p>The formal runs report results for two subsets of queries. One subset is the terabyte queries and the other subset is the million query track queries. We obtain the relevance feedback results for feedback set B-E for model 1 but only set B-C for model 2 due to lack of time.  Table <ref type="table" coords="7,115.84,654.30,5.01,9.02" target="#tab_1">2</ref> shows the performance of our models, and the averages of best and of the median performance of all participants for 31 Terabyte track queries. Interestingly, the performance of our ad hoc retrieval without any RF is better than any of our own models with RF. The performance of our models is similar to the average of the median performance of each query. Figure <ref type="figure" coords="8,325.55,74.34,5.01,9.02" target="#fig_6">1</ref> shows the MAP difference between our model 1 and the median performance of each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Terabyte Track Subset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Million Query Track Subset</head><p>Table <ref type="table" coords="8,115.44,160.56,5.01,9.02" target="#tab_2">3</ref> shows the performance of our formal runs for million query track queries used in this RF track. For this subset of queries, the StatAP and MTC AP estimates are reported. The performance of our model 1 using feedback set E is similar to the median performance of the participants. Figures <ref type="figure" coords="8,449.87,195.06,5.01,9.02">2</ref> and<ref type="figure" coords="8,476.54,195.06,5.01,9.02" target="#fig_7">3</ref> show the MTC AP estimate and StateAP differences between our model 1 and median performance, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Informal Runs</head><p>For the informal runs, we tested whether better performance may be obtained when the initial retrieval containing more relevant documents is used for re-ranking. In this case, we used the MRF <ref type="bibr" coords="9,481.07,373.56,11.68,9.02" target="#b5">[6]</ref> model provided by the Lemur package <ref type="bibr" coords="9,221.23,390.84,11.69,9.02" target="#b6">[7]</ref> to generate the initial retrieval list. Stop word removal is not used. The porter stemmer [8] is used. The setting of the μ parameter for individual terms is 1500 and 4000 for the windows of the MRF model. The size of the index is 210G bytes. This index is created by a dedicated machine for 19 hours. The retrieval time is 2-3 hours for all title queries of this RF track. No PRF is used because the results using PRF are worst than those without PRF. Table <ref type="table" coords="9,411.35,460.92,5.01,9.02" target="#tab_3">4</ref> shows that the retrieval performance improves (c.f. Table <ref type="table" coords="9,227.83,478.20,4.17,9.02" target="#tab_0">1</ref>) when the performance of the initial retrieval list used for re-ranking is improved apart from feedback set B which contains only one relevant document for each query. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We developed two novel models for RF. The performance of this model is similar to the median performance of all the runs by all participants. If better performing initial retrieval is used, then we expect that the retrieval using the judged documents in the feedback set performs better than the original retrieval using the same set of feedback documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,438.78,421.78,5.01,13.54;2,432.48,421.78,7.52,13.54;2,428.76,421.78,5.01,13.54;2,399.66,421.78,15.24,13.54;2,382.50,421.78,3.01,13.54;2,343.02,421.78,7.52,13.54;2,338.16,421.78,4.18,13.54;2,330.96,421.78,5.01,13.54;2,312.60,421.78,8.77,13.54;2,299.10,421.78,3.76,13.54;2,284.94,421.78,5.01,13.54;2,272.88,421.78,5.01,13.54;2,238.80,421.78,12.23,13.54;2,213.30,421.78,4.18,13.54;2,206.10,421.78,5.01,13.54;2,192.60,421.78,3.76,13.54;2,178.44,421.78,5.01,13.54;2,264.24,429.79,2.19,7.90;2,388.32,421.78,7.52,13.54;2,363.96,421.78,6.68,13.54;2,323.04,421.78,7.52,13.54;2,304.68,421.78,6.68,13.54;2,290.28,421.78,7.52,13.54;2,277.98,421.78,6.68,13.54;2,227.88,421.78,10.03,13.54;2,198.18,421.78,7.52,13.54;2,183.78,421.78,7.52,13.54;2,266.58,429.79,3.90,7.90;2,258.66,429.79,4.39,7.90;2,374.88,420.78,8.26,15.04;2,352.32,420.78,8.26,15.04;2,250.14,420.78,7.43,15.04;2,216.78,420.78,8.26,15.04;2,167.58,420.78,10.73,15.04;2,90.00,466.24,222.51,10.02;2,312.48,466.92,209.56,9.75;2,90.00,484.56,432.07,9.02;2,90.00,502.56,432.04,9.02;2,90.00,520.14,64.99,9.02"><head></head><label></label><figDesc>∇(•) is the document-wide relevance decision, ∂ d,k (•) is the local relevance decision at location k for document d, c(d, k) is the document context, which is a sequence of a fixed number of terms, at location k in document d, and C(•) is a function that combines the local relevance values into a document-wide relevance value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,90.00,76.02,252.09,9.02;3,368.52,74.55,4.70,10.87;3,348.06,73.74,112.16,12.07;3,486.66,74.55,4.70,10.87;3,466.26,73.74,55.74,12.07;3,90.00,93.24,432.03,9.02;3,90.00,110.63,432.04,10.42;3,90.00,130.68,180.05,9.02;3,390.54,129.31,4.00,10.81;3,359.82,129.31,3.00,10.81;3,342.96,129.31,7.00,10.81;3,332.28,129.31,4.00,10.81;3,320.64,129.31,2.40,10.81;3,314.22,129.31,4.00,10.81;3,303.36,129.31,3.00,10.81;3,291.90,129.31,4.00,10.81;3,282.18,129.31,4.00,10.81;3,385.14,129.31,4.67,10.81;3,364.68,129.31,7.34,10.81;3,351.00,129.31,8.67,10.81;3,336.54,129.31,5.33,10.81;3,325.68,129.31,6.01,10.81;3,307.86,129.31,5.33,10.81;3,296.22,129.31,6.01,10.81;3,286.26,129.31,5.33,10.81;3,275.76,129.31,6.01,10.81;3,375.36,128.51,146.72,12.02;3,90.00,152.40,173.08,9.02"><head>Let</head><label></label><figDesc>R be the binary random variable for relevance where r R = means relevant and r R = means irrelevant. The score of a document d is calculated by summing the scores of the contexts c(d, k) where d[k] is a term in Q ∪ Q e . The score of a context is the log of the ratio between the probability of seeing the context in the relevance model of d[k] (i.e., the probability of seeing the context in the irrelevance model of d[k]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,204.36,180.82,3.99,10.78;3,90.00,230.40,432.04,9.02;3,90.00,247.62,432.10,9.02;3,90.00,264.90,108.03,9.02;3,301.74,323.68,14.83,18.02;3,302.10,289.06,14.83,18.02;3,309.84,340.64,3.85,7.01;3,305.58,340.64,3.85,7.01;3,310.20,306.02,3.85,7.01;3,305.94,306.02,3.85,7.01;3,427.50,325.25,6.60,12.01;3,349.86,325.25,6.60,12.01;3,427.80,290.69,6.60,12.01"><head>(</head><label></label><figDesc>The probabilities of seeing the context c(d, k) in the relevance model and irrelevance model of d[k] are given by multiplying the probabilities by seeing the terms in c(d, k) in the relevance model and irrelevance model of d[k] respectively:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,222.72,533.26,5.99,10.78;4,219.72,533.26,3.00,10.78;4,213.72,533.26,5.99,10.78;4,204.18,532.45,6.58,11.98;4,192.24,531.94,7.56,12.66;4,232.86,534.60,14.46,9.02;4,281.64,533.24,6.00,10.81;4,278.58,533.24,3.00,10.81;4,272.58,533.24,6.00,10.81;4,263.04,532.44,6.59,12.01;4,251.76,531.92,6.59,12.69;4,289.80,534.60,2.51,9.02;4,90.00,577.62,385.84,9.02;4,486.72,582.68,8.55,6.29;4,480.00,576.27,42.03,10.79"><head></head><label></label><figDesc>Boost and discount (B&amp;D) stage: We perform a second retrieval with the expanded query RF q based</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,367.98,359.72,4.00,10.81;5,362.16,359.72,6.00,10.81;5,359.16,359.72,3.00,10.81;5,353.16,359.72,6.00,10.81;5,337.80,359.72,4.00,10.81;5,325.44,359.72,4.00,10.81;5,307.80,359.72,3.34,10.81;5,300.30,359.72,6.00,10.81;5,297.30,359.72,3.00,10.81;5,291.30,359.72,6.00,10.81;5,265.86,359.72,4.00,10.81;5,241.92,359.72,15.34,10.81;5,225.24,359.72,4.00,10.81;5,212.82,359.72,4.00,10.81;5,257.52,366.14,7.00,6.30;5,344.22,358.92,6.59,12.01;5,282.36,358.92,6.59,12.01;5,232.32,358.92,6.59,12.01;5,329.94,359.72,8.01,10.81;5,313.26,359.72,9.34,10.81;5,270.72,359.72,8.01,10.81;5,217.32,359.72,8.01,10.81;5,197.28,359.72,12.68,10.81;5,376.38,361.08,145.64,9.02;5,90.00,384.84,294.10,9.02;5,513.90,383.48,4.00,10.81;5,508.08,383.48,6.00,10.81;5,505.08,383.48,3.00,10.81;5,499.08,383.48,6.00,10.81;5,493.86,383.48,3.34,10.81;5,488.04,383.48,4.00,10.81;5,482.22,383.48,6.00,10.81;5,479.22,383.48,3.00,10.81;5,473.22,383.48,6.00,10.81;5,443.82,383.48,8.00,10.81;5,419.52,383.48,15.34,10.81;5,435.12,389.90,7.00,6.30;5,401.76,389.90,3.50,6.30;5,464.22,382.68,6.59,12.01;5,409.92,382.68,6.59,12.01;5,452.64,383.48,8.01,10.81;5,388.02,383.48,12.68,10.81;5,519.54,384.84,2.51,9.02;5,90.00,405.84,431.95,9.75;5,90.00,423.06,90.77,9.75"><head></head><label></label><figDesc>where N is the total number of documents in the collection, df(w) is the document frequency of w, c d (q) are defined similarly by matching the words with those in the set of 'discount collocation terms', B D .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,433.02,526.22,4.00,10.81;5,382.02,526.22,4.00,10.81;5,288.60,526.22,4.00,10.81;5,277.74,526.22,3.00,10.81;5,263.40,526.22,4.00,10.81;5,427.02,532.64,3.50,6.29;5,404.82,532.64,3.50,6.29;5,274.02,532.64,1.94,6.29;5,252.18,532.64,9.32,6.29;5,421.20,526.22,5.33,10.81;5,399.24,526.22,5.33,10.81;5,356.52,526.22,24.68,10.81;5,305.88,526.22,40.02,10.81;5,282.24,526.22,5.33,10.81;5,267.72,526.22,6.00,10.81;5,244.14,526.22,6.68,10.81;5,412.38,525.42,6.59,12.01;5,394.56,525.42,3.00,12.01;5,348.24,525.42,6.00,12.01;5,295.74,525.42,6.59,12.01;5,385.74,524.91,4.93,12.68;5,438.72,527.58,2.51,9.02;5,90.00,551.40,322.72,9.02;5,479.52,556.42,5.80,6.27;5,443.82,550.02,35.16,10.75;5,418.50,549.22,24.92,11.94;5,427.08,549.22,6.56,11.94;5,490.08,551.40,31.92,9.02;5,90.00,574.14,298.53,9.75;5,497.70,572.82,5.97,10.75;5,474.24,572.82,3.98,10.75;5,418.74,572.82,3.98,10.75;5,491.10,572.02,6.56,11.94;5,481.38,572.02,6.56,11.94;5,423.06,572.02,6.56,11.94;5,465.54,579.22,5.80,6.27;5,429.84,572.82,35.16,10.75;5,393.24,572.82,24.56,10.75;5,507.60,574.14,14.44,9.02;5,181.80,595.53,5.99,10.79;5,166.20,595.53,3.99,10.79;5,117.66,595.53,3.99,10.79;5,173.34,594.73,6.58,11.99;5,157.50,601.94,5.82,6.29;5,121.80,595.53,35.29,10.79;5,92.16,595.53,24.64,10.79;5,189.00,594.19,333.12,12.70;5,90.00,616.80,432.04,9.02;5,146.40,635.49,11.99,10.79;5,136.62,634.69,6.58,11.99;5,127.38,641.90,4.27,6.29;5,91.62,635.49,35.29,10.79;5,159.00,636.90,2.51,9.02;5,219.78,635.49,11.99,10.79;5,211.38,634.69,6.58,11.99;5,201.36,641.90,5.05,6.29;5,165.60,635.49,35.29,10.79;5,232.98,636.90,2.51,9.02;5,297.96,635.49,11.99,10.79;5,289.50,634.69,6.58,11.99;5,277.80,641.90,5.82,6.29;5,242.10,635.49,35.29,10.79;5,310.50,636.90,78.45,9.02;5,418.56,635.54,3.00,10.81;5,412.56,635.54,6.00,10.81;5,402.84,634.74,6.59,12.01;5,392.70,634.21,4.94,12.70"><head>.</head><label></label><figDesc>above, BCnt(x) is a linear function with BCnt(0)=0 and saturates at BFactor is a constant that controls the effect of B&amp;D, and γ is a constant that adjusts the relative weighting of boost and discount. We have chosen the following set of parameters:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,90.00,619.80,424.59,9.02"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: MAP difference between our model 1 and the median performance of 31 Terabyte track queries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="9,90.00,270.06,432.09,9.02;9,90.00,287.34,31.44,9.02"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: StatAP difference between our model 1 and the median performance of million query track queries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,90.00,505.56,434.22,184.99"><head>Table 1 :</head><label>1</label><figDesc>TREC RF Track: Comparison with Support Vector Machine (Model 1 is not calibrated by any RF</figDesc><table coords="6,90.00,522.78,425.30,133.27"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">track queries)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>P@10</cell><cell></cell><cell>P@30</cell><cell></cell><cell>MAP</cell><cell></cell><cell cols="2">R-Precision</cell></row><row><cell>Set</cell><cell>Model 1</cell><cell>SVM</cell><cell>Model 1</cell><cell>SVM</cell><cell>Model 1</cell><cell>SVM</cell><cell>Model 1</cell><cell>SVM</cell></row><row><cell>B</cell><cell>.3144</cell><cell>.3330</cell><cell>.1977</cell><cell>.2090</cell><cell>.2601</cell><cell>.2503</cell><cell>.2643</cell><cell>.2585</cell></row><row><cell>C</cell><cell>.4367</cell><cell>.4455</cell><cell>.2345</cell><cell>.2535</cell><cell>.3719*</cell><cell>.3573</cell><cell>.3684</cell><cell>.3630</cell></row><row><cell>D</cell><cell>.5205</cell><cell>.5064</cell><cell>.2684</cell><cell>.2818</cell><cell>.4225*</cell><cell>.4041</cell><cell>.4222</cell><cell>.4042</cell></row><row><cell>E</cell><cell>.6394</cell><cell>.6428</cell><cell>.4129</cell><cell>.4138</cell><cell>.6195</cell><cell>.6189</cell><cell>.6045</cell><cell>.6011</cell></row><row><cell cols="9">Key: * means statistical significance at 95% confidence level (or p-value &lt; 0.05). Sets B, C, D and E have</cell></row></table><note coords="6,90.00,664.26,389.18,9.02;6,90.00,681.54,205.22,9.02"><p>different numbers of relevant documents (i.e., 1 relevant, 3 relevant and 3 nonrelevant, 10 judged documents, many judged documents, respectively).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,90.00,212.34,416.95,391.83"><head>Table 2 :</head><label>2</label><figDesc>Formal runs for (31) Terabyte track queries.</figDesc><table coords="7,109.80,230.04,397.15,374.13"><row><cell>Initial Retrieval</cell><cell></cell><cell cols="2">P@10</cell><cell></cell><cell></cell><cell cols="2">MAP</cell><cell></cell><cell cols="2">R-Prec</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Set A</cell><cell></cell><cell></cell><cell>.3419</cell><cell></cell><cell></cell><cell cols="2">.1670</cell><cell></cell><cell cols="2">.1892</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Model 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Model 2</cell></row><row><cell>Sets</cell><cell></cell><cell cols="2">P@10</cell><cell></cell><cell></cell><cell cols="2">MAP</cell><cell></cell><cell cols="2">R-Prec</cell><cell></cell><cell cols="2">P@10</cell><cell></cell><cell></cell><cell>MAP</cell><cell>R-Prec</cell></row><row><cell>B</cell><cell></cell><cell></cell><cell>.2387</cell><cell></cell><cell></cell><cell cols="2">.1224</cell><cell></cell><cell cols="2">.1504</cell><cell></cell><cell cols="2">.2645</cell><cell></cell><cell cols="2">.1239</cell><cell>.1649</cell></row><row><cell>C</cell><cell></cell><cell></cell><cell>.2839</cell><cell></cell><cell></cell><cell cols="2">.1423</cell><cell></cell><cell cols="2">.1666</cell><cell></cell><cell cols="2">.3032</cell><cell></cell><cell cols="2">.1314</cell><cell>.1629</cell></row><row><cell>D</cell><cell></cell><cell></cell><cell>.2548</cell><cell></cell><cell></cell><cell cols="2">.1356</cell><cell></cell><cell cols="2">.1610</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>E</cell><cell></cell><cell></cell><cell>.2839</cell><cell></cell><cell></cell><cell cols="2">.1599</cell><cell></cell><cell cols="2">.1857</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TREC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Best</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Median</cell></row><row><cell>Measures</cell><cell></cell><cell cols="2">P@10</cell><cell></cell><cell></cell><cell cols="2">MAP</cell><cell></cell><cell cols="2">R-Prec</cell><cell></cell><cell cols="2">P@10</cell><cell></cell><cell></cell><cell>MAP</cell><cell>R-Prec</cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell>.7129</cell><cell></cell><cell></cell><cell cols="2">.4215</cell><cell></cell><cell cols="2">.4530</cell><cell></cell><cell cols="2">.2839</cell><cell></cell><cell cols="2">.1427</cell><cell>.1801</cell></row><row><cell>0.5</cell><cell></cell><cell></cell><cell cols="10">Difference betw een our set E1 and median</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.1</cell><cell>704</cell><cell>708</cell><cell>722</cell><cell>738</cell><cell>746</cell><cell>764</cell><cell>768</cell><cell>776</cell><cell>788</cell><cell>792</cell><cell>800</cell><cell>806</cell><cell>814</cell><cell>828</cell><cell>840</cell><cell>850</cell></row><row><cell>-0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,90.00,246.84,432.12,414.68"><head>Table 3 :</head><label>3</label><figDesc>Performance of formal runs for million query track queries.</figDesc><table coords="8,90.00,264.54,432.12,396.98"><row><cell>Initial Retrieval</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">StatAP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">MTC AP Estimate</cell></row><row><cell>Set A</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.2413</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">.0443</cell></row><row><cell>Ours</cell><cell></cell><cell></cell><cell cols="2">Model 1</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Model 2</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Model 1</cell><cell></cell><cell>Model 2</cell></row><row><cell>B</cell><cell></cell><cell></cell><cell cols="2">.2077</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.2170</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.0440</cell><cell></cell><cell></cell><cell>.0441</cell></row><row><cell>C</cell><cell></cell><cell></cell><cell cols="2">.2348</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.1754</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.0502</cell><cell></cell><cell></cell><cell>.0443</cell></row><row><cell>D</cell><cell></cell><cell></cell><cell cols="2">.2453</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">.0510</cell><cell></cell><cell></cell><cell></cell></row><row><cell>E</cell><cell></cell><cell></cell><cell cols="2">.2414</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">.0536</cell><cell></cell><cell></cell><cell></cell></row><row><cell>TREC</cell><cell></cell><cell></cell><cell cols="2">Best</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Median</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Best</cell><cell></cell><cell></cell><cell>Median</cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell cols="2">.8109</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.1946</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.0868</cell><cell></cell><cell></cell><cell>.0564</cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell cols="10">Difference between our set E and median</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.05</cell><cell>704</cell><cell>796</cell><cell>2126</cell><cell>2562</cell><cell>3210</cell><cell>3618</cell><cell>4358</cell><cell>4946</cell><cell>5590</cell><cell>6042</cell><cell>6450</cell><cell>6786</cell><cell>7322</cell><cell>7858</cell><cell>8602</cell><cell>9086</cell><cell>9570</cell></row><row><cell>-0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="18">Figure 2: MTC AP estimate difference between our model 1 and the median performance of million query</cell></row><row><cell>track queries.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,101.16,529.92,409.61,132.74"><head>Table 4 :</head><label>4</label><figDesc>Informal runs using the initial retrieval list generated by Lemur and re-ranked by our model 1 for feedback sets B-E.</figDesc><table coords="9,128.58,564.90,375.16,97.76"><row><cell>Set</cell><cell>P@10</cell><cell>P@30</cell><cell>MAP</cell><cell>R-precision</cell></row><row><cell>A</cell><cell>.3977</cell><cell>.2750</cell><cell>.3339</cell><cell>.3389</cell></row><row><cell>B</cell><cell>.3654</cell><cell>.2317</cell><cell>.3148</cell><cell>.3042</cell></row><row><cell>C</cell><cell>.4859</cell><cell>.2728</cell><cell>.4380</cell><cell>.4234</cell></row><row><cell>D</cell><cell>.5837</cell><cell>.3048</cell><cell>.4970</cell><cell>.4834</cell></row><row><cell>E</cell><cell>.7175</cell><cell>.4677</cell><cell>.7309</cell><cell>.6962</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work is supported by <rs type="projectName">HKPU</rs> Project # <rs type="grantNumber">G-YG29</rs>. Robert thanks the <rs type="institution">Center for Intelligent Information Retrieval, University of Massachusetts (UMASS)</rs> for facilitating him to develop in part the basic IR system, when he was on leave at <rs type="institution">UMASS</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_8dy3yEu">
					<idno type="grant-number">G-YG29</idno>
					<orgName type="project" subtype="full">HKPU</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,93.77,333.06,428.24,9.02;10,108.00,350.34,357.42,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,416.51,333.06,105.51,9.02;10,108.00,350.34,142.83,9.02">A retrospective study of probabilistic context-based retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W P</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,267.72,350.34,140.39,9.02">Proceedings of the ACM SIGIR &apos;05</title>
		<meeting>the ACM SIGIR &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="663" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,93.77,367.56,428.15,9.02;10,108.00,384.84,313.13,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,320.45,367.56,201.48,9.02;10,108.00,384.84,82.00,9.02">Support vector machines: relevance feedback and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Shahrary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C</forename><surname>Gibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,196.02,384.84,159.78,9.02">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="305" to="323" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,93.77,402.06,428.29,9.02;10,108.00,419.34,315.04,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,367.15,402.06,154.91,9.02;10,108.00,419.34,109.12,9.02">Interpreting TF-IDF term weights as making relevance decisions</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W P</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,223.56,419.34,172.79,9.02">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,93.77,436.56,428.29,9.02;10,108.00,453.78,338.61,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,279.32,436.56,242.75,9.02;10,108.00,453.78,123.93,9.02">Some simple approximations to the 2-Poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,248.82,453.78,140.45,9.02">Proceedings of the ACM SIGIR &apos;94</title>
		<meeting>the ACM SIGIR &apos;94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,93.77,471.06,428.27,9.02;10,108.00,488.28,335.26,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,184.79,471.06,337.25,9.02;10,108.00,488.28,186.43,9.02">A general class of fuzzy operators, the DeMorgan class of fuzzy operators and fuzziness measures induced by fuzzy operators</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dombi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,301.02,488.28,93.57,9.02">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="149" to="163" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,93.77,505.56,428.15,9.02;10,108.00,522.78,197.73,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,270.24,505.56,233.48,9.02">A Markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,108.00,522.78,140.46,9.02">Proceedings of the ACM SIGIR &apos;05</title>
		<meeting>the ACM SIGIR &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,93.77,540.06,428.25,9.02;10,108.00,557.28,218.64,9.02" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,249.91,540.06,151.32,9.02">Experiments using the Lemur toolkit</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,420.66,540.06,101.36,9.02;10,108.00,557.28,106.70,9.02">Proceedings of the 2001 Text REtrieval Conference</title>
		<meeting>the 2001 Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2001">2002. 2001</date>
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
