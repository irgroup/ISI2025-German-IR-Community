<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,118.17,76.50,375.46,15.95">University of Waterloo at TREC 2008 Blog track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,263.89,122.12,83.89,9.57"><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
							<email>ovechtom@engmail.uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Sciences Faculty of Engineering</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,118.17,76.50,375.46,15.95">University of Waterloo at TREC 2008 Blog track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">81B371EDFCEC9E51E17F47F1D972F201</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper reports the University of Waterloo participation in the opinion and polarity tasks of the Blog track. The proposed method uses a lexicon built from several linguistic resources. The opinion discriminating ability of each subjective lexical unit was estimated using the Kullback-Leibler divergence. The KLD scores of subjective words occurring within fixed-size windows around instances of query terms were used in calculating document scores. The described system also used a method of identifying phrases in topic titles by matching them to Wikipedia titles. The results show that both KLD-based scores of subjective lexical units and Wikipedia-matched phrases are useful techniques that help improve opinion retrieval performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This year the University of Waterloo participated in the opinion finding and polarity tasks of the Blog track. Our approach relies on the use of a lexicon of subjective words and phrases, gathered from a variety of sources, such as FrameNet <ref type="bibr" coords="1,114.99,382.69,10.59,8.72" target="#b0">[1]</ref>, Levin's verb classes <ref type="bibr" coords="1,222.07,382.69,10.59,8.72" target="#b1">[2]</ref>, Hatzivassilouglou and McKeown's list of subjective adjectives <ref type="bibr" coords="1,507.08,382.69,10.59,8.72" target="#b2">[3]</ref>. The developed methods use the Kullback-Leibler divergence (KLD) <ref type="bibr" coords="1,337.96,394.21,11.60,8.72" target="#b3">[4]</ref> to weight subjective words, and factors these weights into the document score.</p><p>The opinion finding task of the Blog track of TREC began in 2006. Blog tracks 06-08 use the same document collection, but different sets of topics. The document collection includes 3.2 million permalink documents (88.8Gb), i.e. blog posts. Each topic consists of the standard TREC components: title, description and narrative, and describes the entity (e.g., a person, product, event or abstract entity) about which the searcher wants to find opinions. The objective of the opinion task is to retrieve a ranked list of blog posts, which express opinions about the entity described in the topic. The objective of the polarity task is to retrieve two separate ranked lists of documents with positive and negative opinions. Relevance judgements were performed on a 5-point scale: 0 -document is nonrelevant; 1 -document is relevant, but contains no opinion on the target entity; 2 -document is relevant and contains negative opinion(s) on the target entity; 3 -document is relevant and contains mixed (both positive and negative) opinions on the target entity; 4 -document is relevant and contains positive opinion(s) on the target entity. Two types of relevance were defined in the task: topic relevance, where a document judged as 1-4 is considered relevant, and opinion relevance, where a document is considered relevant if judged as &gt;1 in opinion task, and 2 (4) in negative (positive) polarity finding subtasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>Our approach to finding blogs containing opinions about the concept expressed in the query is a two-stage process. In the first stage, a set of documents is retrieved in response to the query using a topic-relevance ranking method, while in the second stage, this document set is re-ranked using an opinion-finding method. In the experiments reported in this paper, for the first stage we used BM25 <ref type="bibr" coords="1,294.64,627.01,11.60,8.72" target="#b4">[5]</ref> implemented in the Wumpus search engine <ref type="bibr" coords="1,484.31,627.01,10.59,8.72" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Identifying phrases in queries</head><p>Our earlier work on retrieval of opinions from blogs <ref type="bibr" coords="1,295.65,670.69,11.60,8.72" target="#b6">[7]</ref> suggested that the use of phrases in the first stage, i.e. retrieval of the documents using a topic-relevance ranking method, yields better results than the use of single terms. In that approach we simply used user-defined phrases, i.e. the text enclosed in quotes by the user was treated as a phrase. Clearly, this cannot be always relied upon, since not all users explicitly delimit phrases in their queries. In the present work we used a method of identifying phrases by matching them to Wikipedia titles, as described below, and which is similar to the method used in <ref type="bibr" coords="2,225.78,86.05,10.59,8.72" target="#b7">[8]</ref>.</p><p>Any part of the query that matched a Wikipedia title was treated as a phrase. First, we attempted to match the entire query of n words, then, if unsuccessful, every subphrase of size n-1, then every subphrase of size n-2 in the unmatched part of the query, and so on until we reached unigrams. The unmatched unigrams were always kept in the query. Stopwords were filtered out only from the single terms in the query. If a phrase that matched a Wikipedia title contained stopwords, they were not removed, such as in "March of the penguins" (Topic 851).</p><p>To illustrate the process of identifying phrases in the query, consider the following example: the query "business intelligence resources" (Topic 898) was split into "business intelligence" and "resources", because Wikipedia has an article with the title "business intelligence". Similarly, the query "opera software OR opera browser OR opera mobile OR opera mini" (Topic 944) was split into "opera software", "opera browser", "opera mobile" and "opera mini". The Boolean operator OR was removed because it is a stopword.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Building the subjective lexicon</head><p>The subjective lexicon used in the proposed methods was adapted from the resources described below. Wilson et al. used a similar set of subjective lexical units in classifying opinions by intensity <ref type="bibr" coords="2,389.93,264.13,10.59,8.72" target="#b8">[9]</ref>. <ref type="bibr" coords="2,191.34,282.20,13.92,9.57" target="#b1">[2]</ref> Beth Levin has categorized English verbs into semantic classes. Verbs from the following classes were used in our method:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Levin's verb classes</head><p>• Verbs of psychological state (e.g., amaze, fascinate, bother, impress); • Verbs of desire (e.g., crave, yearn, need); • Judgment verbs (e.g., acclaim, criticize, reproach).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">FrameNet [1]</head><p>Lexical units (verbs, phrasal verbs, adjectives, etc.) from the following frames were used:</p><p>• Emotion_active (e.g., fret, fuss, lose sleep); • Emotion_directed (e.g., affronted, delighted, resentful); • Experiencer_object (e.g., enthrall, puzzle, trouble); • Experiencer_subject (e.g., dissatisfied, jubilant, fed up).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Ballmer and Brennenstuhl speech act verbs [10]</head><p>A few verbs and expressions were manually selected from the Emotion Model (e.g., blow up, burst out laughing, grumble about).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Hatzivassilouglou and McKeown's subjective adjectives [3]</head><p>A list of 1336 subjective adjectives manually composed by <ref type="bibr" coords="2,337.71,496.21,87.19,8.72">Hatzivassiloglou and</ref> McKeown (e.g., amusing, impressive, unreliable) was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5">Subjective lexicon processing</head><p>After the removal of duplicates, the overall subjective lexicon gathered consisted of 1828 lexical units. For each verb and most of the phrasal verbs, whenever it made sense, we have also added past tense, gerund ("-ing" form) and third person forms. With all the grammatical word forms added, the total size of the subjective lexicon was 3182.</p><p>In the polarity subtask, we used the original polarity tags when they were provided by the lexicon authors. For example, Hatzivassiloglou and McKeown's adjectives have polarity tags. Some of Levin's verb classes are also divided into positive and negative. We also manually added polarity tags to some of the words in other resources. Some words have no clear polarity and can be used in positive or negative sense depending on the context, such as "feel", "overwhelm", "surprised" . We did not tag such words, and hence did not use them in the polarity subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Window-based co-occurrence</head><p>Our approach to opinion-based reranking consists in adjusting the tf weights of query terms on the basis of their cooccurrence with subjective lexical units in fixed-size windows centered around the query term occurrences. The motivation for this is that if a subjective word or phrase occurs close to a query term, it may indicate that the author expresses an opinion about the topic related to the query term. The reason, why we chose to use a fixed-size window instead of a natural language unit, such as a sentence, is two-fold: first, a subjective word may not actually "target" the query term occurrence in a sentence, but another word in a different sentence. For instance, a subjective adjective may modify a pronoun in a different sentence, e.g., "He saw an oil painting near the window. It was beautiful." Alternatively, it may modify a noun related to the query term, for instance, when expressing an opinion about a photo camera, a person may talk about the picture quality, rather than the camera directly: "I bought a new camera. The picture quality is excellent." The second reason is practical: it is faster and less error-prone to identify windows than split the text into sentences. In the case of blogs, sentence boundary detection is a more difficult task than with, say, a newswire article: the former may use non-standard and ill-formed syntactic constructions without proper punctuation marks, and are typically in HTML format, which may not be always possible to convert to plain text correctly.</p><p>The window is defined as n words to the left and right of the query term occurrence in text. In cases where the distance between two instances of query term(s) in a document is less than n, the text span between these two query term instances is split in the middle, such that one half is attributed to the query term on the left, and the other halfto the query term on the right. This is done in order to avoid counting the same subjective word occurrence twice. In our experiments window size was set to 30, as this proved optimal on the training datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Term weighting 2.4.1 Calculating KLD scores of subjective lexical units</head><p>Intuitively, subjective words that occur relatively more frequently in the known relevant and opinionated documents than in the non-relevant or relevant but non-opinionated ones are more useful in predicting opinions. Based on this intuition, we calculated scores for the units in our subjective lexicon using the Kullback-Leibler divergence (KLD).</p><p>The Kullback-Leibler divergence measures the relative entropy between two probability distributions. It has been defined in information theory <ref type="bibr" coords="3,192.73,349.81,11.60,8.72" target="#b3">[4]</ref> and was used in many information retrieval and natural language processing tasks, for example, in query expansion following pseudo-relevance feedback <ref type="bibr" coords="3,354.87,361.33,15.30,8.72" target="#b10">[11]</ref>.</p><p>The KLD score of a subjective lexical unit was calculated according to Eq. 1.</p><p>Where: P R (t) -probability of the subjective lexical unit t occurring in the relevant documents, and calculated as f R (t)/R, where f R (t) -frequency of occurrence of t in the relevant set, R -number of terms in the relevant set; P N (t)probability of the subjective lexical unit t occurring in the non-relevant documents, and calculated as f N (t)/N, where f N (t) -frequency of occurrence of t in the non-relevant set, N -number of terms in the non-relevant set.</p><p>The BLOG track 2006 and 2007 data was used for calculating KLD scores of the subjective lexicon. In the opinion finding task, the relevant set consisted of all the documents for the 100 topics with the relevance judgments of 2 (negative opinion), 3 (mixed opinion) and 4 (positive opinion). The non-relevant set consisted of all the documents with the judgments of 0 (non-relevant) and 1 (relevant, but not opinionated). In the polarity task, KLD scores were calculated separately for positive and negative subjective words. When calculating KLD scores for positive (or negative) words, the relevant set consisted of all documents with relevance judgment level 4 (or 2 for negative), while the nonrelevant consisted of documents with all other relevance judgment levels.</p><p>A KLD score was calculated for each lexical unit, not each of its grammatical word forms separately. Thus, in calculating KLD for "fascinate", the frequencies of occurrences of "fascinate", "fascinated", "fascinating" and "fascinates" were added. In total, KLD scores for 1828 lexical units were calculated. Lexical units with negative KLD scores were discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Calculating document matching score</head><p>Our approach to the weighting of query term occurrences in the document consists of modifying the term frequency (tf) calculation in BM25. Instead of counting the actual frequency of a term's occurrence in the document to get tf, we calculate a pseudo-frequency (pf) value (Eqs. 2 and 3). If the query term t i co-occurs with a subjective word within a window of n words either side of it, then we add the normalized KLD score of the subjective word to c(t i ) (Eq. 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! KLD(t)</head><formula xml:id="formula_0" coords="3,208.52,407.21,201.03,25.49">= P R (t) " log P R (t) P N (t)<label>(1)</label></formula><p>The idea of using pseudo-frequency weights was also used in a proximity-based document ranking method proposed in <ref type="bibr" coords="4,81.08,86.05,15.30,8.72" target="#b11">[12]</ref>, which proved to be effective in an ad-hoc IR task.</p><p>Where: c(t i ) -contribution of the i th instance of the query term t to pf, KLD(s j ) -KLD score of the subjective lexical unit s j , |J| -the number of subjective lexical units occurring in the window of 30 words around t i , maxKLD -the maximum KLD score for all 1828 subjective lexical units.</p><p>Where: N -number of instances of the query term t in the document.</p><p>After pf is calculated for a query term, its Term Weight (TW) in the document is calculated in the same way as in the BM25 formula <ref type="bibr" coords="4,133.02,291.01,10.59,8.72" target="#b4">[5]</ref>, with pf used instead of tf (Eq. 4):</p><p>Where: k 1 is the term frequency normalisation factor, which moderates the contribution of the weight of frequent terms. If k 1 =0, pf has no effect on the term weight, while the higher the value of k 1 the more effect pf has on the term weight. NF is the document length normalisation factor, and is calculated in the same way as in the BM25 document ranking function, as expressed in Eq. 5.</p><p>Where: b is a tuning constant, DL is the document length in word counts; AVDL is the average document length in the document collection.</p><p>The Document Matching Score is calculated as the sum of weights of all query terms found in the document (Eq. 6).</p><p>€</p><formula xml:id="formula_1" coords="4,204.47,504.61,204.66,29.34">MS = TW t t=1 |Q| ∑<label>(6)</label></formula><p>Where: |Q| is the number of terms in the query.</p><p>In the runs that used Wikipedia-based phrases (see Section 3.1) in Stage 2 (opinion based reranking), we used both phrases and single terms in calculating a document matching score, i.e. we counted the occurrences of the whole phrases in the document, plus any of their component terms that occur separately. For instance, if a document contains instances of the query phrase "March of the Penguins" and instances of "penguin", the document matching score will be TW("March of the Penguins")+TW("penguin").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Opinion finding task</head><p>For the baseline runs, we used BM25 implemented in Wumpus, which, as described earlier, was also used for Stage 1 (initial document retrieval) of our opinion retrieval algorithm. We have evaluated different values for b and k 1 parameters of BM25 on Blog 06 dataset. The values of 0.1 and 0.75 for b and k 1 respectively yielded good</p><formula xml:id="formula_2" coords="4,132.52,110.87,277.34,88.86">! c(t i ) = 1+ KLD(s j ) maxKLD if | J | &gt; 0 j=1 |J | " 0 otherwise. # $ % &amp; %<label>(2)</label></formula><formula xml:id="formula_3" coords="4,132.92,218.70,275.03,272.55">! pf t = c(t i ) (3) i=1 N " ! TW t = (k 1 + 1) " pf t k 1 " NF + pf t " idf t (4) ! NF = (1" b) + b # DL AVDL (<label>5</label></formula><formula xml:id="formula_4" coords="4,404.94,427.96,4.09,9.87">)</formula><p>performance and were therefore used in all the baseline and experimental runs reported in the paper. Two baseline runs were performed (UWbase1 and UWbase2), both of which used the title section of the topics. UWbase1 used single terms, while UWbase2 -phrases identified by matching topic titles to Wikipedia titles as outlined in 2.1 above. Two opinion runs (UWopinion1 and UWopinion2) were conducted by re-ranking UWbase1 and UWbase2 respectively using the method described in Section 2.</p><p>Blog track participants were required to submit their runs on 150 topics: 100 topics from Blog-06 and 07, and 50 new topics that were developed this year. We report the results for all 150 topics in Table <ref type="table" coords="5,425.48,163.09,3.73,8.72" target="#tab_0">1</ref>, as well as for the new 50 topics separately in Table <ref type="table" coords="5,175.91,174.61,3.73,8.72" target="#tab_1">2</ref>. Our performance analysis, however, is focused on the new topics. To facilitate cross-site comparison, following the baseline retrieval stage the track organisers released 5 baselines (runs NISTbaseline1-5 in Tables <ref type="table" coords="5,100.01,197.41,4.92,8.72" target="#tab_0">1</ref> and<ref type="table" coords="5,124.56,197.41,3.59,8.72" target="#tab_1">2</ref>), randomly selected from the submitted baseline runs. Participants were encouraged to submit opinion runs based on as many of these baselines as possible. We submitted opinion runs based on all of these baselines (runs UWnb1Op through UWnb5Op in Tables <ref type="table" coords="5,243.33,220.45,4.92,8.72" target="#tab_0">1</ref> and<ref type="table" coords="5,270.46,220.45,3.59,8.72" target="#tab_1">2</ref>). To facilitate reading of Tables <ref type="table" coords="5,415.39,220.45,4.92,8.72" target="#tab_0">1</ref> and<ref type="table" coords="5,442.52,220.45,3.73,8.72" target="#tab_1">2</ref>, all baseline runs (i.e. without opinion features) are shaded in grey and each opinion run is placed immediately below its corresponding baseline. As can be seen from Table <ref type="table" coords="5,187.98,463.57,3.73,8.72" target="#tab_1">2</ref>, the use of opinion features in UWopinion2 was useful and led to improved average performance on 50 new topics over the corresponding baseline (UWbase2) by 5% in MAP and 13% in P10 (opinion relevance). Average improvements on 150 topics (Table <ref type="table" coords="5,302.43,486.61,4.14,8.72" target="#tab_0">1</ref>) were more substantial: 19.4% in MAP, 25% in P10 and 6.3 in R-Prec (all statistically significant, t-test, p&lt;.02). Analysis of differences in average precision values by topic between UWopinion2 and UWbase2 (Figure <ref type="figure" coords="5,257.30,509.65,4.14,8.72" target="#fig_0">1</ref>) shows that the majority of topics benefited from the use of KLDweighted subjective words in document re-ranking. A notable outlier, topic 1013 (European Union, Iceland), dropped from 0.8615 to 0.1018, causing substantial average drop in performance. A likely explanation for such poor performance is different use of phrases: in the baseline run, Wikipedia-matched title phrases were searched as fixed phrases, i.e. no partial matches were allowed. In the opinion re-ranking stage, partial matches were allowed, i.e. "European Union" would match "European", "Union" and "European Union". Thus, documents, containing many instances of "European" co-occurred with subjective vocabulary, were promoted in the ranked list, hurting performance.  To determine the effect of KLD-based weighting on performance, we conducted a run without KLD (UWopinion2-noKLD in Tables <ref type="table" coords="6,144.21,554.77,4.92,8.72" target="#tab_2">3</ref> and<ref type="table" coords="6,169.28,554.77,3.61,8.72" target="#tab_3">4</ref>). In this run, instead of using pseudo-frequency pf (Eqs. 2 and 3), we used term frequency tf, whereby each instance of the query term t occurring within the window of +/-30 words of a subjective lexical unit, contributed 1 towards the tf of this term. As in UWopinion2, those query term instances that did not co-occur with a subjective word in a window, were not counted towards tf.  As can be seen from Tables <ref type="table" coords="7,188.55,160.45,4.92,8.72" target="#tab_2">3</ref> and<ref type="table" coords="7,214.47,160.45,3.73,8.72" target="#tab_3">4</ref>, there is a substantial improvement from using KLD in run UWopinion2 over UWopinion2-noKLD. Based on opinion relevance judgements on the new 50 topics, there is 5.9% improvement in MAP (statistically significant, t-test, p&lt;.01), 2.8% improvement in P10 (not significant) and 4.6% improvement in Rprec (significant, t-test, p&lt;.05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Polarity task</head><p>For the polarity task we used the same method as in the opinion task, with the weights for positive/negative lexical units calculated respectively on positive/negative opinion training datasets. UWpolarity1 is based on UWbase1 run, while UWpolarity2 -on UWbase2. The results for 150 topics are presented in Tables <ref type="table" coords="7,431.36,280.21,4.92,8.72" target="#tab_4">5</ref> and<ref type="table" coords="7,458.16,280.21,3.77,8.72">6</ref>, while for 50 new topics -in Tables <ref type="table" coords="7,144.11,291.73,4.92,8.72" target="#tab_5">7</ref> and<ref type="table" coords="7,168.54,291.73,3.74,8.72">8</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions</head><p>In this paper we presented a new method of opinion retrieval from blogs. We used a subjective lexicon gathered from a number of linguistic resources, such as FrameNet, Levin's verb classes, Ballmer and Brennestuhl speech act verbs, etc. The Kullback-Leibler divergence measure was used to weight subjective words. We also experimented with different types of queries for the first stage (document retrieval) and the second stage (opinion-based reranking). Specifically, we identified phrases in the TREC topic titles by matching them to Wikipedia titles.</p><p>The method that achieved the best overall performance (UWopinion2) used Wikipedia-based phrases in both stages and the KLD-based document reranking method. The improvement over the baseline (UWbase2) on the 50 new topics is 5%, whereas the improvement on all 150 topics is 19.4% (statistically significant, t-test, p&lt;.01). Further analysis demonstrates that KLD-based weighting of subjective words is a useful factor in the ranking of opinionated documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,132.76,513.49,346.20,8.72;6,168.24,332.64,302.64,136.08"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Difference in average precision of UWopinion2 from the baseline UWbase2.</figDesc><graphic coords="6,168.24,332.64,302.64,136.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,172.32,259.09,267.10,187.13"><head>Table 1 .</head><label>1</label><figDesc>Results based on 150 topics</figDesc><table coords="5,172.32,274.62,267.10,171.60"><row><cell>Run</cell><cell cols="3">Opinion relevance</cell><cell cols="3">Topic relevance</cell></row><row><cell></cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell></row><row><cell>UWbase1</cell><cell cols="6">0.2314 0.4740 0.2859 0.2997 0.6060 0.3524</cell></row><row><cell>UWopinion1</cell><cell cols="6">0.2508 0.5707 0.2958 0.2923 0.6347 0.3416</cell></row><row><cell>UWbase2</cell><cell cols="6">0.2476 0.4647 0.3095 0.3313 0.6327 0.3890</cell></row><row><cell>Uwopinion2</cell><cell cols="6">0.2956 0.5813 0.3493 0.3589 0.7027 0.4136</cell></row><row><cell cols="7">NISTbaseline1 0.2639 0.4753 0.3189 0.3701 0.7307 0.4156</cell></row><row><cell>UWnb1Op</cell><cell cols="6">0.3148 0.6107 0.3613 0.3812 0.7407 0.4264</cell></row><row><cell cols="7">NISTbaseline2 0.2657 0.5287 0.3189 0.3382 0.7000 0.3831</cell></row><row><cell>UWnb2Op</cell><cell cols="6">0.2940 0.5933 0.3468 0.3361 0.7167 0.3835</cell></row><row><cell cols="7">NISTbaseline3 0.3201 0.5387 0.3647 0.4244 0.7220 0.4573</cell></row><row><cell>UWnb3Op</cell><cell cols="6">0.3202 0.5960 0.3613 0.3768 0.7173 0.4181</cell></row><row><cell cols="7">NISTbaseline4 0.3543 0.5580 0.3979 0.4776 0.7867 0.5092</cell></row><row><cell>UWnb4Op</cell><cell cols="6">0.3403 0.6000 0.3807 0.4057 0.7280 0.4484</cell></row><row><cell cols="7">NISTbaseline5 0.3147 0.5307 0.3709 0.4424 0.7793 0.4868</cell></row><row><cell>UWnb5Op</cell><cell cols="6">0.3298 0.6133 0.3772 0.3978 0.7427 0.4504</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,172.32,74.53,267.10,187.13"><head>Table 2 .</head><label>2</label><figDesc>Results based on 50 new topics</figDesc><table coords="6,172.32,90.30,267.10,171.36"><row><cell>Run</cell><cell cols="3">Opinion relevance</cell><cell cols="3">Topic relevance</cell></row><row><cell></cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell></row><row><cell>UWbase1</cell><cell cols="6">0.2485 0.5160 0.3014 0.2897 0.5840 0.3359</cell></row><row><cell>UWopinion1</cell><cell cols="6">0.2398 0.5100 0.2820 0.2571 0.5440 0.2934</cell></row><row><cell>UWbase2</cell><cell cols="6">0.2753 0.5160 0.3391 0.3309 0.6380 0.3824</cell></row><row><cell>Uwopinion2</cell><cell cols="6">0.2892 0.5840 0.3361 0.3335 0.6580 0.3789</cell></row><row><cell cols="7">NISTbaseline1 0.3239 0.5800 0.3682 0.4031 0.7320 0.4345</cell></row><row><cell>UWnb1Op</cell><cell cols="6">0.3365 0.6160 0.3706 0.3841 0.6980 0.4229</cell></row><row><cell cols="7">NISTbaseline2 0.2640 0.5500 0.3145 0.3107 0.6480 0.3493</cell></row><row><cell>UWnb2Op</cell><cell cols="6">0.2838 0.5840 0.3247 0.3057 0.6460 0.3387</cell></row><row><cell cols="7">NISTbaseline3 0.3565 0.5540 0.3887 0.4344 0.6440 0.4608</cell></row><row><cell>UWnb3Op</cell><cell cols="6">0.3298 0.6060 0.3563 0.3613 0.6680 0.3884</cell></row><row><cell cols="7">NISTbaseline4 0.3822 0.6160 0.4284 0.4724 0.7440 0.4993</cell></row><row><cell>UWnb4Op</cell><cell cols="6">0.3381 0.6060 0.3718 0.3793 0.6700 0.4131</cell></row><row><cell cols="7">NISTbaseline5 0.2988 0.5300 0.3524 0.3745 0.7040 0.4170</cell></row><row><cell>UWnb5Op</cell><cell cols="6">0.3196 0.6220 0.3623 0.3549 0.6920 0.4033</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,144.00,302.43,309.22,385.23"><head>Table 3 .</head><label>3</label><figDesc>The effect of KLD on performance (150 topics)</figDesc><table coords="6,144.00,302.43,309.22,385.23"><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.2</cell><cell>1001</cell><cell>1003</cell><cell>1005</cell><cell>1007</cell><cell>1009</cell><cell>1011</cell><cell>1013</cell><cell>1015</cell><cell>1017</cell><cell>1019</cell><cell>1021</cell><cell>1023</cell><cell>1025</cell><cell>1027</cell><cell>1029</cell><cell>1031</cell><cell>1033</cell><cell>1035</cell><cell>1037</cell><cell>1039</cell><cell>1041</cell><cell>1043</cell><cell>1045</cell><cell>1047</cell></row><row><cell>-0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Run</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Opinion relevance</cell><cell></cell><cell></cell><cell></cell><cell cols="5">Topic relevance</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MAP</cell><cell></cell><cell cols="2">P10</cell><cell cols="3">Rprec</cell><cell></cell><cell cols="2">MAP</cell><cell></cell><cell cols="2">P10</cell><cell cols="3">Rprec</cell></row><row><cell cols="4">UWbase2</cell><cell></cell><cell></cell><cell></cell><cell cols="18">0.2476 0.4647 0.3095 0.3313 0.6327 0.3890</cell></row><row><cell cols="5">UWopinion2</cell><cell></cell><cell></cell><cell cols="18">0.2956 0.5813 0.3493 0.3589 0.7027 0.4136</cell></row><row><cell cols="25">UWopinion2-noKLD 0.2733 0.5560 0.3298 0.3476 0.6907 0.3979</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,160.56,74.53,290.61,67.37"><head>Table 4 .</head><label>4</label><figDesc>The effect of KLD on performance (50 new topics)</figDesc><table coords="7,160.56,90.30,290.61,51.60"><row><cell>Run</cell><cell cols="3">Opinion relevance</cell><cell cols="3">Topic relevance</cell></row><row><cell></cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell></row><row><cell>UWbase2</cell><cell cols="6">0.2753 0.5160 0.3391 0.3309 0.6380 0.3824</cell></row><row><cell>UWopinion2</cell><cell cols="6">0.2892 0.5840 0.3361 0.3335 0.6580 0.3789</cell></row><row><cell cols="7">UWopinion2-noKLD 0.2732 0.5680 0.3212 0.3233 0.6620 0.3638</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,91.22,321.73,429.31,46.01"><head>Table 5 .</head><label>5</label><figDesc>Negative polarity results (150 topics) Table6. Positive polarity results (150 topics)</figDesc><table coords="7,97.68,337.26,416.38,30.48"><row><cell>Run</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell><cell>Run</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell></row><row><cell>UWpolarity1</cell><cell cols="3">0.0686 0.1239 0.0935</cell><cell>UWpolarity1</cell><cell cols="3">0.1033 0.1651 0.1384</cell></row><row><cell>UWpolarity2</cell><cell cols="3">0.0925 0.1542 0.1257</cell><cell>UWpolarity2</cell><cell cols="3">0.1280 0.1933 0.1701</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,85.81,385.09,440.13,46.01"><head>Table 7 .</head><label>7</label><figDesc>Negative polarity results (50 new topics) Table 8. Positive polarity results (50 new topics)</figDesc><table coords="7,97.68,400.62,416.38,30.48"><row><cell>Run</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell><cell>Run</cell><cell>MAP</cell><cell>P10</cell><cell>Rprec</cell></row><row><cell>UWpolarity1</cell><cell cols="3">0.0669 0.1104 0.0896</cell><cell>UWpolarity1</cell><cell cols="3">0.0893 0.1408 0.1284</cell></row><row><cell>UWpolarity2</cell><cell cols="3">0.0968 0.1396 0.1200</cell><cell>UWpolarity2</cell><cell cols="3">0.1239 0.2041 0.1662</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,88.80,648.37,434.06,8.72;7,88.80,659.89,99.09,8.72" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,267.68,648.37,125.57,8.72">The Berkeley FrameNet project</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">F</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,410.39,648.37,106.68,8.72">Proc. of the COLING-ACL</title>
		<meeting>of the COLING-ACL<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.80,675.49,395.73,8.72" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,128.79,675.49,152.82,8.72">English Verb Classes and Alternations</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>The University of Chicago Press</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.80,690.85,452.12,8.72;7,88.80,702.37,409.36,8.72" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,266.02,690.85,195.50,8.72">Predicting the semantic orientation of adjectives</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,480.33,690.85,60.59,8.72;7,88.80,702.37,327.01,8.72">Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,74.53,451.95,8.72;8,88.80,86.05,70.78,8.72" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,148.96,74.53,249.29,8.72">The science of information: Measurements and applications</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Losee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Academic Press Prof., Inc</publisher>
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,101.41,451.99,8.72;8,88.80,112.93,452.16,8.72;8,88.80,124.45,35.79,8.72" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,295.19,101.41,245.60,8.72;8,88.80,112.93,353.67,8.72">A probabilistic model of information retrieval: development and comparative experiments. Parts 1 and 2. Information Processing and Management</title>
		<author>
			<persName coords=""><forename type="first">Spärck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="809" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,140.05,452.11,8.72;8,88.80,151.57,452.16,8.72;8,88.80,163.09,145.99,8.72" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,223.08,140.05,317.84,8.72;8,88.80,151.57,31.31,8.72">Indexing Time vs. Query Time Trade-offs in Dynamic Information Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,140.07,151.57,395.84,8.72">Proceedings of the 14th ACM Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the 14th ACM Conference on Information and Knowledge Management (CIKM)<address><addrLine>Bremen, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-11">November 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,178.45,452.14,8.72;8,88.80,189.97,254.06,8.72" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,155.77,178.45,248.50,8.72">Using Subjective Adjectives in Opinion Retrieval from Blogs</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vechtomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,423.16,178.45,117.78,8.72;8,88.80,189.97,83.26,8.72">Proceedings of the 16th Text Retrieval Conference</title>
		<meeting>the 16th Text Retrieval Conference<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">November 6-9, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,205.57,452.00,8.72;8,88.80,217.09,452.15,8.72;8,88.80,228.61,136.59,8.72" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,248.70,205.57,292.10,8.72;8,88.80,217.09,50.32,8.72">Improving Complex Interactive Question Answering with Wikipedia Anchor Text</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mackinnon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vechtomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,159.06,217.09,326.75,8.72">Proceedings of the 30th European Conference on Information Retrieval (ECIR)</title>
		<meeting>the 30th European Conference on Information Retrieval (ECIR)<address><addrLine>Glasgow, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-04-03">March 30 -April 3, 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,243.97,452.06,8.72;8,88.80,255.49,77.45,8.72" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,230.89,243.97,191.08,8.72">Recognizing Strong and Weak Opinion Clauses</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,429.01,243.97,108.03,8.72">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="73" to="99" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,271.09,452.08,8.72;8,88.80,282.61,196.85,8.72" xml:id="b9">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Th</forename><surname>Ballmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Brennenstuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,232.17,271.09,102.08,8.72">Speech Act Classification</title>
		<title level="s" coord="8,340.69,271.09,195.41,8.72">Springer Series in Language and Communication</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,297.97,452.06,8.72;8,88.80,309.49,301.32,8.72" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,309.20,297.97,231.66,8.72;8,88.80,309.49,40.20,8.72">An Information-Theoretic Approach to Automatic Query Expansion</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>De Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bigi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,136.00,309.49,172.91,8.72">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,88.80,325.09,452.06,8.72;8,88.80,336.61,267.68,8.72" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,267.70,325.09,268.62,8.72">Lexical Cohesion and Term Proximity in Document Ranking</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vechtomova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Karamuftuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,88.80,336.61,162.67,8.72">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1485" to="1502" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
