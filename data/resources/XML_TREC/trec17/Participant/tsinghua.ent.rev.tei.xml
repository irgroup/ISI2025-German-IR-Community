<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.06,76.31,243.40,12.58;1,423.54,78.76,3.00,5.40">THUIR at TREC2008: Enterprise Track 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,153.36,99.90,39.65,9.02"><forename type="first">Yufei</forename><surname>Xue</surname></persName>
						</author>
						<author>
							<persName coords="1,200.34,99.90,37.51,9.02"><forename type="first">Tong</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName coords="1,244.98,99.90,51.35,9.02"><forename type="first">Guichun</forename><surname>Hua</surname></persName>
						</author>
						<author>
							<persName coords="1,303.61,99.90,42.59,9.02"><forename type="first">Min</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,353.36,99.90,39.78,9.02"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName coords="1,399.72,99.90,53.58,9.02"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.06,76.31,243.40,12.58;1,423.54,78.76,3.00,5.40">THUIR at TREC2008: Enterprise Track 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5E30030BED2B2B636B723A4CDC72A731</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participate in document search and expert search of Enterprise Track in TREC2008. The corpus and tasks are same as the year before. Different from TREC 2007, the topics come from CSIRO Enquiries, and the topic statements are richer and more colloquial.. In document search, we look into the key resource page pre-selection, the use of anchor text, query classification, and multi-field search. In expert search, we develop methods to detect expert identifiers and experimented based on our previous PDD (personal description documents) model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is the fourth year that the IR groups of Tsinghua University participated in TREC Enterprise Track. Different from TREC 2007, the topics come from CSIRO Enquiries, and the topic statements are richer and more colloquial. The approaches we've studied this year include the use of anchor text, person entity identification, topic distillation with key resource pre-selection, query classification and multi-field search.</p><p>For document search task, we mainly investigate the effects of key source pre-selection and the use of anchor text. We first observe the high quality resource distribution. Some features are studied to find overview pages. We also do some link analysis: both HITS and PageRank algorithms are employed to evaluate the page quality. Besides, we attempted a novel link analysis method which involved the document similarity.</p><p>For expert finding task, a lot of efforts have been made on name identification. We built personal description documents (PDD) for each candidate from various types of resources. We obtain retrieved results from each description document collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Document Search</head><p>The document search task is to help the science communicator to find specific information in the web site. We build a query independent classifier that selects key resources to find high quality pages. The other one is to adapt link analysis to predict those authoritative pages. Both approaches were adopted in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Key pages pre-selection using query independent features</head><p>First we try to do some data cleansing work to pick those key pages out according to some query independent features. Figure <ref type="figure" coords="1,131.06,574.95,5.25,9.45">1</ref> shows that the distribution of the amount of out-links in overview pages provided by TREC. From the distribution we notice that most overview pages contain a lot of out-links from 115 to 180, contrast to the fact that among the whole corpus more than ninety percent of pages are with out-links less than 100. We conduct an experiment that only retrieve from those documents which have number of out-links more than 100 and build a training set which is not overlapped with the Enterprise 2008 topics. The results show that the performance is 10% higher than retrieving from the whole corpus while the size of the selected corpus is only 10% of the whole one.</p><p>Figure <ref type="figure" coords="2,180.05,232.35,3.95,9.45">1</ref>. The distribution of the amount of out-links in example pages Similarly, the in-link anchor text are also studied. We merge the distillation of the page A and all its anchor texts whose links leads to the page A. The new page B replaces the page A in the whole process of the information retrieval. The experiments results in our training set validate our supposition that the anchor text based retrieval outperform the full text retrieval by more than 20% in MAP.</p><p>Some other features are also attempted to identify high quality pages, such the length of page URLs, the amount of in-link. We also implement a decision tree to combine these features to better construct the high quality pages set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Adapting link analysis for finding authoritative pages</head><p>We first used Page Rank <ref type="bibr" coords="2,167.52,384.75,12.26,9.45" target="#b0">[1]</ref> to estimate the quality of the web pages. However, the link structure of the web site CSIRO is quite different from the environment that the algorithm applies to. So after executing the Page Rank process, we get some pages with very large scores like the homepage and index pages. However, it is difficult to use these importance scores in conjunction with query-specific IR scores to rank the query results. Several known approaches are attempted but all failed to improve the performance.</p><p>Assume that if one page provides necessary authoritative information to one topic, then its linked neighbors will have higher probabilities to present some detailed or relevant information. Therefore for a given page, we add the similarities of those pages which the link to the page as the new score. This reflects the idea that considering the similarity of pages instead of merely analyzing the link relation. For example, if a hub points to an authoritative page and the hub page is a good one, then the authoritative may get a lot of reinforcement. However, if only a little part of the hub page is relevant to the page it links to, the authoritative page may get too much. Plus the strength of the link relation is more or less reflected by the anchor text. Therefore involving the similarity of anchor text to the algorithm may better quantitatively determine the strength of reinforcement. The experiments results show that the improvement achieved by the content-based link analysis is consistent and significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Submitted results</head><p>We list the four results we submit and their descriptions in the following table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Brief Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THUFmfS</head><p>short query, result combination on fulltext and selected key pages set.</p><p>THUFS short query search on full text.</p><p>THUFaAS short query search on full text + anchor text + selected key pages.</p><p>THUFsimAncL long query, result reranking with inlink similarity, then reranking with anchor evidence</p><p>We adapted short queries and rank the combination with probabilistic relevance model on original full text and the pre-selected key pages set on THUFmfS. The result of THUFS is the baseline result. We extract and integrate inlink anchor text for each document, combine them into original documents, and rank the documents with probabilistic relevance model on the new collection in THUFaAS. In the last result of THUFsimAncL, we use the probabilistic relevance model to rank the linear combination of the relevance between the long queries and the documents, and the similarity propagation with in-link docs. After that we re-rank the result with the anchor text similarity evidence.</p><p>3 Expert Search</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Expert identifiers detection</head><p>Because there is no master list of candidates, we should automatically detect expert identifiers. According to the guideline that among CSIRO the pattern of the emails is firstname.lastname@csiro.au, we extract all the email addresses from the corpus, including some variation such as that the @ symbol may be HTML-encoded. After eliminating the typo in name and name variations in addresses, we got 3161 candidate. There are some variations for English names. Given a name "firstname.lastname", at least five variations are possible: Firstname Lastname, Firstname.Lastname, Firstname Middlename Lastname, F. Lastname, F. M. Lastname. For the first three pattern of variation, we use Aho-Corasick algorithm to label. It takes O(m+n) time, where m is the length of the name and n is the length of the document. Labeling F.Lastname is a problem that a bit hard to tackle. Because it is possible that more than one person shares one abbreviation. For example, T. Thomas may represent Tom Thomas or Tim Thomas. We tried to eliminate the ambiguity according the co-occurrence of other labeled names. However, there are still some ambiguous abbreviations hard to eliminate. Some other technologies such as pronouns eliminating are also integrated in our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Constructing PDD and merging results</head><p>As we did in previous expert finding task, we build person description document (PDD) for each candidate <ref type="bibr" coords="3,518.91,434.37,11.17,9.45" target="#b3">[4]</ref>. We extract some candidate relevant information from the document as expertise, for example, the context around the expert identifier.</p><p>Besides, we also extract information from candidate's homepages. In total we find 477 homepages, which are about 15.2% of the amount of candidates. We name the PDD constructed from the homepages as detailed PDD (DPDD). We also construct another PDD using a collection of high-quality documents. The documents in the collection are selected by analyzing the link graph of the corpus.</p><p>For job hunting requests, we filtered out all the documents in the domain name of recruitment, and build a recruitment-PDD to improve the performance on the topics about job hunting. And the corresponding automatic query classification approach is used to identify such tasks. But due to the free expressions on find a job in human language, the recall of query classification result is not very high.</p><p>To merge the ranking results retrieved from each PDD collection, we adopted EM algorithm to assign the weight to each ranking similarity, because some previous work shows that when the ratio of the weights is parallel to the ratio of the MAP achieved by each ranking list, the merged list achieves the best performance <ref type="bibr" coords="3,517.59,637.16,11.18,9.45" target="#b4">[5]</ref>.</p><p>To compare the performances of two branches of work: PDD-based search (first extract information, then search on re-constructed documents) and document-based search (first search on original documents, then extract expert information from top-returned results), besides runs with PDDs, one run of experiments on document-based search was also submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Submitted results</head><p>The results of our 4 runs are listed below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Future Work</head><p>In document search task, we attempted a promising content-based link analysis algorithm. We find the link structure of intranet and a website is totally different from the Internet. Therefore we will try to investigate the link analysis algorithms applying in intranet. A bigger ambition is that we would like to experiment our content-based link analysis algorithm on bigger data sets and to propose an algorithm integrating the link analysis and similarity ranking. The automatic query type identification is also important in Intranet search to meet different information request. Further study will be made on the analysis the intention of the query.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,69.42,743.61,464.47,8.10;1,70.02,759.21,395.48,8.10"><p>Supported by the Chinese National Key Foundation Research &amp; Development Plan (2004CB318108)，Natural Science Foundation (60621062, 60503064，60736044) and National 863 High Technology Project (2006AA01Z141)</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,65.27,384.96,468.60,9.02;4,71.52,399.96,209.11,9.02" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,296.73,384.96,232.34,9.02">The PageRank citation ranking: Bringing order to the web</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="4,65.27,414.96,468.60,9.02;4,71.52,429.96,199.74,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,175.82,414.96,211.93,9.02">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,396.19,414.96,137.68,9.02;4,71.52,429.96,195.37,9.02">Proceedings of the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,65.27,444.96,468.61,9.02;4,71.52,459.96,145.79,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,256.11,444.96,263.77,9.02">Maximum-likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,527.46,444.96,6.42,9.02;4,71.52,459.96,101.92,9.02">J. Royal Statist. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,65.27,474.96,468.55,9.02;4,71.52,489.96,244.75,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,145.28,474.96,163.58,9.02">THUIR at TREC 2005: Enterprise Track</title>
		<author>
			<persName coords=""><forename type="first">Yupeng</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,157.14,489.96,104.74,9.02">Proceedings of TREC2005</title>
		<meeting>TREC2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>CST Dept, Tsinghua University</orgName>
		</respStmt>
	</monogr>
	<note>NIST</note>
</biblStruct>

<biblStruct coords="4,65.27,504.96,468.61,9.02;4,71.52,519.96,447.02,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,207.30,504.96,326.58,9.02;4,71.52,519.96,73.40,9.02">Probabilistic Model Supported Rank Aggregation for the Semantic Concept Detection in Video</title>
		<author>
			<persName coords=""><forename type="first">Dayong</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,151.22,519.96,300.94,9.02">ACM International Conference on Image and Video Retrieval (CIVR 2007)</title>
		<imprint>
			<date type="published" when="2007-11">July 9-11 2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
