<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,66.76,72.36,476.21,16.84;1,72.73,92.29,464.26,16.84">University of Twente at the TREC 2008 Enterprise Track: Using the Global Web as an expertise evidence source</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,186.46,138.01,84.79,11.06"><forename type="first">Pavel</forename><surname>Serdyukov</surname></persName>
							<email>serdyukovpv@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>PO Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.42,138.01,48.60,11.06"><forename type="first">Robin</forename><surname>Aly</surname></persName>
							<email>alyr@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>PO Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.02,138.01,86.23,11.06"><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
							<email>hiemstra@cs.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>PO Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,66.76,72.36,476.21,16.84;1,72.73,92.29,464.26,16.84">University of Twente at the TREC 2008 Enterprise Track: Using the Global Web as an expertise evidence source</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BEC63BDEC3FD85AA1F6425FF36D47A36</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the details of our participation in expert search task of the TREC 2007 Enterprise track.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This is the fourth (and the last) year of TREC 2007 Enterprise Track and the second year the University of Twente (Database group) submitted runs for the expert finding task. In the methods that were used to produce these runs, we mostly rely on the predicting potential of those expertise evidence sources that are publicly available on the Global Web, but not hosted at the website of the organization under study (CSIRO). This paper describes the follow-up studies complimentary to our recent research <ref type="bibr" coords="1,205.93,353.65,9.73,7.86" target="#b8">[8]</ref> that demonstrated how taking the web factor seriously significantly improves the performance of expert finding in the enterprise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EXPERTISE EVIDENCE ACQUISITION FROM THE GLOBAL WEB</head><p>One could imagine an expert finder that is equipped with a web crawler focusing on retrieval of employee-specific information from the Web. Such a spider would provide us with a plenty of information about how the organization is positioned at the world or regional markets, how influential and wide-spread its organizational knowledge. However, in case when an expert finder should be made cheap but good, the enterprise may rely on powerful mediators between people and the Web: leading search engines and their public search APIs.</p><p>In our latest studies <ref type="bibr" coords="1,149.86,528.11,9.73,7.86" target="#b8">[8]</ref> we found that extracting topicand person-specific information with Yahoo! and Google Search APIs is a universal way to expand the search scope of expert finders. We used as many expertise evidence sources as possible to finally aggregate ranks from several sourcespecific rankings per each candidate. We relied on the hypothesis that real experts should be popular not only locally, in the enterprise, but also in the other web spaces available for search: news, blogs, academic libraries etc. We extracted expertise evidence from search engines by issuing queries for each candidate containing:</p><p>• the quoted full person name: e.g. "tj higgins",</p><p>• the name of the organization: csiro,</p><p>• query terms without any quotes: e.g. genetic modification,</p><p>• the directive prohibiting the search at the organizational web site: -inurl:csiro.au.</p><p>Adding the organization's name was important for the resolution of an employee's name, the clause restricting the search to URLs that do not contain the domain of the organization separated organizational data from the rest of available information (one could also enlist all organizational domains, each in separate -inurl clause). As the second step of acquiring the evidence of a certain type, we send the query to a web search service and regard the number of returned results as a measure of personal expertness. Due to the limits of the Search Engine API technology we used, we had to restrict the number of persons for which we extracted global expertise evidence: it was unrealistic and unnecessary to issue thousands of queries containing each person for each query provided by a user. So, making an initial expert finding run on enterprise data was a requirement. As a result of that run, we used 100 most promising candidate experts (actually, the maximum number of candidates per query allowed for a single TREC submission) for the further analysis. Apart from the ranking built on fully indexed organizational data, we built rankings using 6 different sources of expertise evidence from the Global Web: Global Web Search, Regional Web Search, Document-specific Web search, News Search (all via Yahoo! Web search API), Blogs Search and Books Search (via Google Blog and Book Search APIs). Our experiments demonstrated a substantial increase in performance when we used combinations of up to three rankings. The best combination was comprised of the Enterprise, Global Web and News based rankings.</p><p>Despite that the main idea was to combine various rankings, we used obviously naive measure of expertness. That is why in the present work, we focus on combination of only two rankings, Enterprise and Global Web based, but use various measures of quality of web results returned by Yahoo Global Web Search API in response to the above described queries. Some of statistics per URL (the domain size and the number of inlinks) are still extracted by means of Google Web Search API, since it has no limit on the number of queries per user IP and it was a decisive factor to complete our experiments in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MEASURING THE QUALITY OF A WEB SEARCH RESULT</head><p>After all the majority of expert finding approaches is based on measuring the quality of a person-specific result set returned by the search engine in response to a query. Personspecific means that it contains only those documents that have at least one mention of the certain person and its quality may be represented by various features: the number of documents it contains or the sum of their relevance probabilities. A result set returned by a typical web search engine consists of a list of result items described by their URLs, titles and summaries (snippets). To measure the overall quality of a web search result, we should aggregate calculated quality measures for all or top-k result items:</p><formula xml:id="formula_0" coords="2,69.87,136.07,223.03,17.86">Expertise(e) = Item∈W ebResultSet Quality(Item)<label>(1)</label></formula><p>Certainly, downloading web pages using URLs of web result items for the deeper analysis of web result quality may lead to the better perfomance, but in our experiments we restrict ourselves to quality measures calcualted just from the search result pages or using such page statistics that can be quickly acquired from a search engine without downloading the full content of a page. All measures that we considered in this paper could be classified into two types: query-dependent and query-independent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query independent quality measures</head><p>In our experiments we focused on four kinds of query independent quality measures of a result item (web page).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">URL length</head><p>Previous studies indicated that URL length is inversely proportional to the usefulness of the page it refers to <ref type="bibr" coords="2,270.35,326.44,9.73,7.86" target="#b5">[5,</ref><ref type="bibr" coords="2,283.18,326.44,6.49,7.86" target="#b3">3]</ref>. We apply simple quality measure based on this assumption: Quality(Item) = 1/ Length(ItemURL). The URL length is expressed in levels: the number of backslashes in the URL after its domain part. It should be mentioned that expressing the URL length in symbols performed much worse in our preliminary experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Inlinks for domain</head><p>Another quality estimate we used is an approximation of the result item's authority. Since it was impossible to calculate sophisticated web graph centrality measures and since pages themselves are not often linked by pages outside of their domain, we used a simple inlink authority measure for the domain of the result item, considering that in many other authority measures (e.g. Pagerank) this value anyway propagates to all pages hosted at the result item's domain: Quality(Item) = Inlinks(Domain(Item)). The authority estimate was acquired using the link: clause plus the domain name to query Google Web Search API that returned the number of pages citing the given domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Domain size</head><p>We also supposed that the importance of the domain which hosts the returned result page should also be expressed by its size: Quality(Item) = Size(Domain(Item)) The main intuition was that large domains usually become so only due to the time and money spent on their maintenance what in turn demonstrates their respectability. The size estimate was acquired using site: clause plus the domain name to query Google Web Search API that returned the number of pages indexed by Google at the given domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Freshness</head><p>We supposed that a page's last date of modification shows how much trust we should put in expertise evidence found in it. Obviously, the freshness of expertise evidence implicitly indicates the freshness of candidate's expert knowledge.</p><p>In our preliminary experiments it appeared that considering only those results that where at least once modified (or created) after 2006 was better than just treating all of them equally useful:</p><formula xml:id="formula_1" coords="2,348.01,112.94,171.03,18.32">Quality(Item) = 1, Y ear(Item) ≥ 2006 0, Y ear(Item) &lt; 2006</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query dependent quality measures</head><p>The state-of-the-art methods, including one that we use to get Enterprise based ranking <ref type="bibr" coords="2,443.45,167.08,9.22,7.86" target="#b2">[2]</ref>, often rank candidates by the sum of relevance probabilities of pages that contain their mentions. Since it is very time-and broadband-consuming to download all pages in the result list in order to measure their relevance, we use a very simple measure of an Item's (URL, Title or Summary) relevance which we sum over the result list:</p><formula xml:id="formula_2" coords="2,352.66,252.87,203.26,19.75">Quality(Item) = N (q, q ∈ Item ∧ q ∈ Q) N (q, q ∈ Q) (2)</formula><p>what is the number of query terms q appearing in the result Item divided by the number of terms in the query Q. Since it is hard to tokenize URLs, we just search for a query term as for a substring in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RANK AGGREGATION</head><p>The problem of rank aggregation is well known in research on metasearch <ref type="bibr" coords="2,378.17,357.02,9.22,7.86" target="#b6">[6]</ref>. Since our task may be viewed as people metasearch, we adopt solutions from that area. In our previous experiments with different rank aggregation methods we found that the simplest approach is also the best performing <ref type="bibr" coords="2,316.81,398.86,9.22,7.86" target="#b8">[8]</ref>. To get the final score we just summed the negatives of ranks for a person from each source to sort them in descending order:</p><formula xml:id="formula_3" coords="2,374.59,443.21,181.32,26.84">Expertise(e) = K i=1 -Ranki(e)<label>(3)</label></formula><p>This approach is often referred as Borda count <ref type="bibr" coords="2,515.07,476.32,9.22,7.86" target="#b1">[1]</ref>. In our previous work we just sorted all candidates' expertise estimates for each evidence source to get their source-specific ranks. In this work we assigned these ranks more smoothly. First, we considered that all candidates with zero expertise estimates are always assigned with the lowest negative rank possible in the system (-100 in our experiments, since we always start by taking top-100 candidates from the Enterprise based ranking). Second, we assigned equal ranks to the candidates with equal expertise estimates, since before they were given arbitrary ranks by the sorting algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head><p>The CERC collection was indexed by Lucene retrieval engine using Snowball stemmer at the text parsing stage. For the purpose of finding candidate experts, we extracted all email addresses from the collection with csiro.au domain and firstname.lastname-like first part. We also had a list of email addresses to be banned which were not personal, but organizational addresses (e.g. publishing.photos@csiro.au). After all, we had 3500 candidate experts in total. Later, in order to find an association between a candidate and a document, we searched for the candidate's full email address or full name in the document's text. For each TREC title query we retrieved 50 documents (using a language model based retrieval model <ref type="bibr" coords="3,119.54,220.19,9.98,7.86" target="#b2">[2]</ref>) that contained at least one candidate expert mentioned. Then we analyzed these documents with the state-of-the-art Enterprise based expert finding method (Balog's candidate-centric Model 2 described in <ref type="bibr" coords="3,245.38,251.57,9.73,7.86" target="#b2">[2]</ref> and used in our previous experiments with web expertise evidence <ref type="bibr" coords="3,277.03,262.03,9.52,7.86" target="#b8">[8]</ref>). Finally, we considered only top 100 candidates from the Enterprise based ranking and built Web based rankings only for those.</p><p>The results analysis is based on calculating popular IR performance measures also used in official TREC evaluations: Mean Average Precision (MAP), precision at top 5 ranked candidate experts (P@5) and Mean Reciprocal Rank (MRR). We analyzed the performance of the Enterprise based ranking combined with one of the following rankings:</p><p>• WebNumOfResults: based on the number of web result items returned,</p><p>• WebURLLenInLevels: based on the sum of URL Length based quality estimates for web result items,</p><p>• WebInlinksForDomain: based on the sum of inlinks of domains of web result items,</p><p>• WebSizeForDomain: based on the sum of sizes of domains of web result items,</p><p>• WebAfter2006: based on the number of web result items modified or created after 2006,</p><p>• WebRelevURL: based on the sum of URL relevance probabilities for web result items,</p><p>• WebRelevTitle: based on the sum of title relevance probabilities for web result items,</p><p>• WebRelevSummary: based on the sum of summary relevance probabilities for web result items, Our initial intention was to improve the combination of the Enterprise and the Enterprise+WebNumOfResults rankings that we regarded as our baseline (see Table <ref type="table" coords="3,282.15,617.04,3.58,7.86" target="#tab_0">1</ref>). Only the WebURLLenInLevels ranking showed significantly degraded performance, the others were equally or better performing. Three rankings appeared to have slightly better performance in combination with the Enterprise rankings: WebAfter2006, WebRelevTitle, WebRele-vURL. We also tried to further combine different rankings from the above list. However, we did not succeed to beat the WebRelevURL's ranking performance with any of these combinations.  We finally submitted combinations of the Enterprise ranking with WebNumOfResults, WebAfter2006, WebRe-levTitle, and WebRelevURL rankings as runs to TREC 2008 (see Table <ref type="table" coords="3,384.87,183.42,3.58,7.86" target="#tab_2">2</ref>). The only difference with experiments with TREC 2007 queries is that we used our own infinite random walk based expert finding method <ref type="bibr" coords="3,493.91,204.35,9.73,7.86">[9]</ref> to build the Enterprise ranking. In this case all methods were equally effective according to MAP measure, but according to MRR and P@5 measures, considering relevance of URLs was indeed beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>The usefullness of query-independent document quality measures for expert finding was recently studied. MacDonald et. al. <ref type="bibr" coords="3,360.26,303.55,9.73,7.86" target="#b7">[7]</ref> reported a bit different findings for the enterprise data only (e.g. all inlinks are only from pages of the same domain): they used similar expert finding method as a baseline and using Inlinks and URL length improved its MAP by a few percents. Similar document quality measures for document retrieval task can be found in some groups' reports on TREC Enterprise Track 2007 <ref type="bibr" coords="3,476.09,366.32,14.34,7.86" target="#b12">[12,</ref><ref type="bibr" coords="3,493.76,366.32,7.17,7.86" target="#b4">4,</ref><ref type="bibr" coords="3,504.26,366.32,10.75,7.86" target="#b11">11]</ref>. Measuring the quality of web result set to predict users' satisfaction with a search engine was just proposed by White et. al. <ref type="bibr" coords="3,539.02,387.24,13.52,7.86" target="#b10">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>The presented study demonstrates the predicting potential of the expertise evidence that can be found outside of the organization. We discovered that combining the ranking built solely on the Enterprise data with the Global Web based ranking may produce significant increases in performance. However, our main goal was to explore whether this result can be further improved by using various quality measures to distinguish among web result items. While, indeed, it was beneficial to use some of these measures, especially those measuring relevance of URL strings and titles, it stayed unclear whether they are decisively important.</p><p>There still stays a number of parallel directions to follow. First, various normalization and smoothing techniques could be applied to the URL quality measures we used. However, it seems more promising to apply machine learning mechanisms to find out which quality features of a web result item are the most important and how to combine them into a powerful expertise prediction model. Other sources of web expertise evidence besides Global Web should also not be overlooked: blog features (e.g. number of subscribers) when using Blog search based evidence or publication features (e.g. publisher's authority or a citation index) when using academic search services.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,59.35,55.01,228.00,122.92"><head>Table 1 :</head><label>1</label><figDesc>The performance of TREC 2007 queries</figDesc><table coords="3,79.69,55.01,187.32,100.66"><row><cell>Ranking</cell><cell>MAP MRR</cell><cell>P@5</cell></row><row><cell>Enterprise</cell><cell cols="2">0.362 0.508 0.220</cell></row><row><cell>Enterprise +</cell><cell></cell><cell></cell></row><row><cell>WebNumOfResults</cell><cell cols="2">0.485 0.627 0.256</cell></row><row><cell>WebURLLenInLevels</cell><cell cols="2">0.386 0.532 0.216</cell></row><row><cell cols="3">WebInlinksForDomain 0.477 0.632 0.252</cell></row><row><cell>WebSizeForDomain</cell><cell cols="2">0.477 0.604 0.248</cell></row><row><cell>WebAfter2006</cell><cell cols="2">0.491 0.620 0.256</cell></row><row><cell>WebRelevURL</cell><cell>0.501 0.650</cell><cell>0.26</cell></row><row><cell>WebRelevTitle</cell><cell>0.488 0.634</cell><cell>0.26</cell></row><row><cell>WebRelevSummary</cell><cell cols="2">0.485 0.627 0.252</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,322.37,123.21,228.00,7.89"><head>Table 2 :</head><label>2</label><figDesc>The performance of TREC 2008 queries</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">ACKNOWLEDGEMENTS</head><p>We want to sincerely thank <rs type="person">Henning Rode</rs> for the help with the collection preprocessing and series of exciting discussions.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="4,58.28,55.51,96.81,10.75" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,70.79,171.76,7.86;4,72.62,81.25,203.17,7.86;4,72.62,91.71,194.34,7.86;4,72.62,102.17,206.16,7.86;4,72.62,112.63,201.01,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,201.56,70.79,42.82,7.86;4,72.62,81.25,43.12,7.86">Models for metasearch</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,134.64,81.25,141.14,7.86;4,72.62,91.71,194.34,7.86;4,72.62,102.17,202.61,7.86">SIGIR &apos;01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="276" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,124.09,198.17,7.86;4,72.62,134.55,202.22,7.86;4,72.62,145.01,122.07,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,242.48,124.09,28.30,7.86;4,72.62,134.55,186.56,7.86">Formal models for expert finding in enterprise corpora</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,72.62,145.01,40.49,7.86">SIGIR &apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,156.47,179.48,7.86;4,72.62,166.93,218.83,7.86;4,72.62,177.39,192.35,7.86;4,72.62,187.85,194.34,7.86;4,72.62,198.31,206.16,7.86;4,72.62,208.77,201.01,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,118.20,166.93,173.24,7.86;4,72.62,177.39,32.55,7.86">Relevance weighting for query independent evidence</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,123.82,177.39,141.14,7.86;4,72.62,187.85,194.34,7.86;4,72.62,198.31,202.61,7.86">SIGIR &apos;05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,220.23,218.61,7.86;4,72.62,230.69,205.65,7.86;4,72.62,241.15,187.56,7.86;4,72.62,251.61,171.57,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,102.05,230.69,176.22,7.86;4,72.62,241.15,51.38,7.86">Research on enterprise track of trec 2007 at sjtu apex lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,142.30,241.15,117.87,7.86;4,72.62,251.61,143.31,7.86">Proceeddings of the 15th Text REtrieval Conference (TREC 2007)</title>
		<meeting>eeddings of the 15th Text REtrieval Conference (TREC 2007)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,263.07,196.89,7.86;4,72.62,273.53,220.29,7.86;4,72.62,283.99,183.00,7.86;4,72.62,294.45,220.22,7.86;4,72.62,304.91,203.74,7.86;4,72.62,315.37,137.98,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,253.64,263.07,15.87,7.86;4,72.62,273.53,216.36,7.86">The importance of prior probabilities for entry page search</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,84.13,283.99,171.49,7.86;4,72.62,294.45,220.22,7.86;4,72.62,304.91,146.38,7.86">SIGIR &apos;02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,326.83,205.93,7.86;4,72.62,337.29,177.62,7.86;4,72.62,347.75,205.60,7.86;4,72.62,358.21,200.66,7.86;4,72.62,368.67,72.95,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,72.62,337.29,113.01,7.86">Supervised rank aggregation</title>
		<author>
			<persName coords=""><forename type="first">Y.-T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z.-M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,204.31,337.29,45.92,7.86;4,72.62,347.75,205.60,7.86;4,72.62,358.21,67.54,7.86">WWW &apos;07: Proceedings of the 16th international conference on World Wide Web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="481" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,380.13,220.29,7.86;4,72.62,390.59,217.67,7.86;4,72.62,401.05,208.92,7.86;4,72.62,411.51,66.65,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,242.80,380.13,50.10,7.86;4,72.62,390.59,142.46,7.86">High quality expertise evidence for expert search</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hannah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,233.59,390.59,56.70,7.86;4,72.62,401.05,208.92,7.86;4,72.62,411.51,37.86,7.86">Proceedings of 30th European Conference on Information Retrieval (ECIR08)</title>
		<meeting>30th European Conference on Information Retrieval (ECIR08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,422.97,215.07,7.86;4,72.62,433.43,190.74,7.86;4,72.62,443.89,181.57,7.86;4,72.62,454.35,208.25,7.86;4,72.62,464.81,202.15,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,201.47,422.97,86.22,7.86;4,72.62,433.43,190.74,7.86;4,72.62,443.89,166.28,7.86">Being omnipresent to be almighty: The importance of the global web evidence for organizational expert finding</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Serdyukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,72.62,454.35,208.25,7.86;4,72.62,464.81,174.25,7.86">FCHER&apos;08: Proceedings of the SIGIR&apos;08 Workshop on Future Challenges in Expertise Retrieval</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,476.27,207.83,7.86;4,72.62,486.73,219.28,7.86;4,72.62,497.19,146.20,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,243.08,476.27,37.37,7.86;4,72.62,486.73,203.98,7.86">Modeling multi-step relevance propagation for expert finding</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Serdyukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rode</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,72.62,497.19,39.85,7.86">CIKM &apos;08</title>
		<meeting><address><addrLine>Napa Valley, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,508.65,211.00,7.86;4,72.62,519.11,212.70,7.86;4,72.62,529.57,207.34,7.86;4,72.62,540.03,213.86,7.86;4,72.62,550.49,206.16,7.86;4,72.62,560.95,191.80,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,102.57,519.11,182.74,7.86;4,72.62,529.57,68.21,7.86">Enhancing web search by promoting multiple search engine use</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Heath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,159.27,529.57,120.68,7.86;4,72.62,540.03,213.86,7.86;4,72.62,550.49,202.61,7.86">SIGIR &apos;08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,572.41,194.87,7.86;4,72.62,582.87,202.82,7.86;4,72.62,593.33,197.06,7.86;4,72.62,603.79,130.03,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="4,102.82,582.87,172.61,7.86;4,72.62,593.33,19.21,7.86">Rmit university at the trec 2007 enterprise track</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shokouhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Puglisi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,110.27,593.33,159.41,7.86;4,72.62,603.79,101.77,7.86">Proceeddings of the 15th Text REtrieval Conference (TREC 2007)</title>
		<meeting>eeddings of the 15th Text REtrieval Conference (TREC 2007)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,72.62,615.25,214.74,7.86;4,72.62,625.71,217.10,7.86;4,72.62,636.17,192.28,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="4,195.38,615.25,91.98,7.86;4,72.62,625.71,101.51,7.86">The open university at trec 2007 enterprise track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,192.56,625.71,97.16,7.86;4,72.62,636.17,164.02,7.86">Proceeddings of the 15th Text REtrieval Conference (TREC 2007)</title>
		<meeting>eeddings of the 15th Text REtrieval Conference (TREC 2007)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
