<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,94.35,102.09,423.30,15.11">Document and Query Expansion Models for Blog Distillation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,85.44,134.57,75.30,10.48"><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,169.82,134.57,90.63,10.48"><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Elsas</surname></persName>
							<email>jelsas@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.28,134.57,73.24,10.48"><forename type="first">Changkuk</forename><surname>Yoo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.19,134.57,65.19,10.48"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
							<email>callan@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,426.50,134.57,100.06,10.48"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,94.35,102.09,423.30,15.11">Document and Query Expansion Models for Blog Distillation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C604173ECD4E79FDDD0D24E300EEFA1E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the CMU submission to the 2008 TREC blog distillation track. Similar to last year's experiments, we evaluate different retrieval models and apply a query expansion method that leverages the link structure in Wikipedia. We also explore using a corpus that combines several different representations of the documents, using both the feed XML and permalink HTML, and apply initial experiments with spam filtering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CMU submission to the 2008 blog distillation track explored document representation, retrieval models, query expansion, and spam filtering. CMU's retrieval system, based on the Indri search engine <ref type="foot" coords="1,293.78,423.68,3.97,6.12" target="#foot_0">1</ref> , used a combined index of the permalink and feed documents, differentially weighting text from various parts of the HTML and XML. Two retrieval models were applied: the large document model, where each feed is viewed as a single document; and the small document model, where a feed is represented as a collection of individual entry documents. Similarly to last year's submission, our query expansion method leverages the link structure in Wikipedia. A spam filtering component was also integrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Document Representation</head><p>Although our system last year successfully made use of only the feed (XML) documents, subsequent testing indicated that using the permalink (HTML) documents could provide some performance improvements. In order to leverage both representations of the blog feeds, this year's submission used a combined index in which each indexed blog contains the text from both the permalink and feed documents. These separate representations of the blogs are indexed as fields in Indri, allowing flexible access to the different document representations at query time.</p><p>The fields represented in our index, given in Table 1, include the full text of the HTML pages (permtext), as well as several structural elements of the feed XML documents.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Retrieval Models</head><p>We applied two retrieval models to the task of blog distillation: the large document model, which treats each blog or feed as a single (large) document, and the small document model, which retrieves blog entries individually and aggregates an entry ranking into an overall feed ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Large Document Model</head><p>The large document model treats each feed as a concatenation of all its entries. In this model, documents are ranked by the posterior probability of observing the feed given the query,</p><formula xml:id="formula_0" coords="1,346.46,584.55,153.63,57.10">P LD (F |Q) = P LD (Q, F )/P (Q) rank = P (F ) Document Prior P LD (Q|F ) Query Likelihood</formula><p>.</p><p>(</p><formula xml:id="formula_1" coords="1,531.51,604.69,8.49,8.74">)<label>1</label></formula><p>The query likelihood component is estimated as a weighted combination of query likelihoods from the different document representations: permalink text, feed title, entry titles and entry content,</p><formula xml:id="formula_2" coords="1,348.49,702.00,191.51,21.98">P LD (Q|F ) = j P LD (Q|F (j) ) vj ,<label>(2)</label></formula><p>where the j denotes different representations and v j are learned weights for each of those representations. This representation-specific query likelihood component is estimated with Metzler &amp; Croft's full dependence model <ref type="bibr" coords="2,131.45,122.98,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,147.20,122.98,7.75,8.74" target="#b1">2]</ref> using Dirichlet-smoothed maximum likelihood estimates <ref type="bibr" coords="2,186.41,134.93,9.96,8.74" target="#b6">[7]</ref>,</p><formula xml:id="formula_3" coords="2,72.00,164.12,242.13,69.93">P LD (Q|F (j) ) = ψi∈Ψ(Q) P LD (ψ i |F (j) ) wi = ψi∈Ψ(Q) tf ψi;F (j) + µP M LE (ψ i |C) |F (j) | + µ wi .<label>(3)</label></formula><p>The ψ i are query unigram and term window query features, and the dependence model weights w i are taken from previous literature. This complex query formulation can be expressed in the following Indri query template shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Small Document Model</head><p>The small document model scores each entry individually, and then combines those scores into an overall feed score. Again, ranking by the posterior probabil-ity of observing the feed given the query, we have,</p><formula xml:id="formula_4" coords="2,321.15,94.44,218.86,115.86">P SD (F |Q) = 1 P (Q) E∈F P SD (Q, E, F ) rank = P (F ) E∈F P (Q|E, F )P (E|F ) rank = P (F ) Feed Prior E∈F P (Q|E) Query Likelihood P (E|F ) Entry Centrality ,<label>(4)</label></formula><p>where the last line holds if we assume queries are conditionally independent of feeds given the entry. As in the large document model, Equation <ref type="formula" coords="2,486.89,246.60,3.88,8.74" target="#formula_2">2</ref>, the query likelihood is calculated via a combination of different document representations</p><formula xml:id="formula_5" coords="2,348.54,291.76,191.46,21.98">P SD (Q|E) = j P SD (Q|E (j) ) vj ,<label>(5)</label></formula><p>and these query likelihood components are estimated with a full dependence model using Jelinek-Mercer smoothing <ref type="bibr" coords="2,359.57,349.69,10.51,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,373.50,349.69,7.75,8.74" target="#b6">7]</ref> to combine both the entry and feed language models,</p><formula xml:id="formula_6" coords="2,323.53,382.89,216.47,90.28">P SD (Q|E (j) ) = ψi∈Ψ(Q) P JM (ψ i |E (j) ) wi = ψi∈Ψ(Q) λ E P M LE (ψ i |E (j) ) + λ F P M LE (ψ i |F (j) ) + λ C P M LE (ψ i |C) wi<label>(6)</label></formula><p>The centrality component of this model is given by,</p><formula xml:id="formula_7" coords="2,364.39,508.17,171.37,24.72">P (E|F ) = φ(E, F ) Ei∈F φ(E i , F ) . (<label>7</label></formula><formula xml:id="formula_8" coords="2,535.76,514.91,4.24,8.74">)</formula><p>where φ is defined as,</p><formula xml:id="formula_9" coords="2,354.20,566.90,185.81,27.02">φ(E, F ) = ti∈E P (t i |F ) tf t i ;E |E| .<label>(8)</label></formula><p>This centrality scoring favors entries that share a language more closely with the language of the feed as a whole. In practice, the product in Equation 8 is only taken over the query terms, providing a queryconditioned centrality measure. The feed prior component of this model is used to correct for the overly optimistic centrality scoring, and is proportional to the log of the feed length: P (F ) ∝ log(|F |). See <ref type="bibr" coords="2,310.98,701.24,10.52,8.74" target="#b1">[2]</ref> for a more thorough description of this retrieval model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><p>The above models have several free parameters for smoothing and model combination that must be set. All of these parameters were set via a simple grid search with a step size of 0.1 using last year's queries and relevance judgements <ref type="bibr" coords="3,184.07,141.37,9.97,8.74" target="#b4">[5]</ref>. The parameter settings were used in Equations 5 and 2 are shown in Table <ref type="table" coords="3,293.27,153.32,3.88,8.74">3</ref>.</p><formula xml:id="formula_10" coords="3,72.00,174.58,229.52,75.01">Model permtext title entrytitle entrybody (v1) (v2) (v3) (v4) LD 0.3 0.5 0.1 0.1 SD 0.6 - 0.1 0.3 Table 3: Weight settings (v i ) for different document representations.</formula><p>The smoothing parameters used were µ = 2500 for the large document model and λ E = 0.4, λ F = 0.3 and λ C = 0.3 for the small document model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Wikipedia Link-based Expansion</head><p>As demonstrated at last year's TREC submission, blog retrieval can greatly benefit from specifically designed query expansion methods. In this year's submission, we apply the same query expansion method that utilizes the link structure in Wikipedia to discover topics related to the query. The original Wikipedia markup includes crossarticle links. Each link is specified by its target Wikipedia article and its anchor text or anchor phrase, which may differ from the target article's title. Our Wikipedia link-based expansion method expands the query with related anchor phrases from Wikipedia, scoring each proportional to how often it occurs in links to documents relevant to the query.</p><p>The unexpanded query is issued as a dependence model query to our Wikipedia index, comprised of 2, 471, 311 articles, excluding date and category pages, from the English Wikipedia. From the resulting ranking, two document sets are defined: the top R documents are defined as the relevant set, S R , and the top W documents are defined as the working set, S W . Because R &lt; W , it follows that S R ⊂ S W . The method focuses on anchor phrases appearing in articles in S W that link to an article in S R . Anchor phrase a i is scored according to,</p><formula xml:id="formula_11" coords="3,107.05,674.81,193.97,41.56">λ i = ai j ∈S W I target(a ij ) ∈ S R × R -rank target(a ij ) ,<label>(9)</label></formula><p>where a ij denotes an occurrence of anchor phrase a i , target(a ij ) is the article linked to by anchor phrase occurrence a ij , rank target(a ij ) denotes the rank of target(a ij ), and I is the identity function. The unexpanded query was augmented with the most highly scoring 20 expansion phrases.</p><p>The method aims to fulfill two desired properties of expansion phrases -that they relate to the query and that they are popular terms, likely to appear in other documents. If two candidate expansion phrases appear equal number of times in S W , the one appearing in links to the most highly ranked documents will score higher. If two candidate expansion terms appear in links to the same document, the most frequent one will score higher. Prior work shows this method resulting in higher retrieval performance than pseudo-relevance feedback (PRF) on the same external resource, the Wikipedia <ref type="bibr" coords="3,441.51,278.42,9.97,8.74" target="#b1">[2]</ref>. An evaluation of the sensitivity of this query expansion method to the parameters R and W is presented in previous work <ref type="bibr" coords="3,310.98,314.29,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="3,324.33,314.29,7.01,8.74" target="#b0">1]</ref>, and the parameter settings used here are taken from that work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Splog Detection</head><p>Our method for splog detection combined four distinct classifiers. Three were rule-based classifiers based on potentially high precision, low coverage heuristics. The fourth classifier is a maximum-margin classifier based on bag-of-word features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Post Time Interval</head><p>Some splogs are machine-generated, containing nonsense text or even snippets of text weaved together from other blogs or websites <ref type="bibr" coords="3,439.25,499.37,9.96,8.74" target="#b3">[4]</ref>. Machine-generated splogs may be characterized by an unusually consistent time interval between consecutive posts. Our post time-interval classifier (TI) classifies a blog as spam if its time interval between consecutive posts varies by no more than 10 seconds. This classifier labeled 366 blogs as spam, of which 333 (91%) were not labeled as spam by any other classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Term Compression</head><p>Many splogs exist to promote and advertise affiliated sites <ref type="bibr" coords="3,332.38,641.46,9.96,8.74" target="#b2">[3]</ref>. These splogs may be characterized by an unusually small ratio of vocabulary size to term count. Our term compression classifier (TC) classifies a blog as spam if X ≤ 6.5% of its unique terms account for Y ≥ 50% of its total term count. We set Y = 50% and tuned X to maximize MAP on last year's queries and relevance judgements <ref type="bibr" coords="3,427.01,713.20,9.96,8.74" target="#b4">[5]</ref>. This classifier labeled 4523 blogs as spam, of which 1687 (41%) were not labeled as spam by any other classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Link Compression</head><p>Some splogs exist to artificially inflate the PageRank of affiliated sites <ref type="bibr" coords="4,146.48,144.79,9.96,8.74" target="#b2">[3]</ref>. These splogs may be characterized by an unusually high percentage of hyperlinks linking to the same URL(s). Our link compression classifier (LC) classifies a blog as spam if X ≤ 1% of its unique link-to URLs account for Y ≥ 70% of its total hyperlink count. We set Y = 70% and tuned X to maximize MAP on last year's queries and relevance judgements <ref type="bibr" coords="4,150.15,228.48,9.97,8.74" target="#b4">[5]</ref>. This classifier labeled 640 blogs as spam, of which 602 (94%) were not labeled as spam by any other classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">SVM classifier</head><p>The lexical features of a blog may provide evidence that it is spam (e.g., pornographic content). An SVM bag-of-words model was trained using a publicly available ham/spam blog data set 23 . Terms were weighted by P M LE (w|F ). This classifier labeled 10839 blogs as spam, of which 8365 (77%) were not labeled as spam by any other classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Combining Classifiers</head><p>These four spam classifiers were combined log-linearly and integrated into the large document model in the form of query-independent document priors (Formula 1) as,</p><formula xml:id="formula_12" coords="4,89.09,472.11,207.50,9.65">log P (F ) ∝ log P (ham|F ) = f i log α i (<label>10</label></formula><formula xml:id="formula_13" coords="4,296.59,472.11,4.43,8.74">)</formula><p>where f i denotes the binary output of the above classifiers and each α i denotes the weight associated with each classifier. We set log α T I = -100 manually based on our hypothesis that its precision is high. Holding this value constant, log α T C = -3, log α LC = -1,and log α SV M = -1 were set by doing a grid search to maximize MAP on last year's queries and relevance judgements <ref type="bibr" coords="4,186.93,575.92,9.96,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Our 4 submitted runs (cmuSD = SD model, cmuSDWiki = SD + Wiki expansion, cmuLDWiki = LD + Wiki expansion, and cmuLDwikiSP = LD + Wiki expansion + splog detection) used only the TREC topic title field. Results are given in Table <ref type="table" coords="4,292.01,677.95,3.88,8.74" target="#tab_4">4</ref>. Figures <ref type="figure" coords="4,358.32,168.48,13.28,8.74" target="#fig_1">1(a</ref>) and 1(b) show cmuLDWikiSP's perquery performance in terms of average precision (AP) and R-Precision (R-Prec), respectively, alongside the per-query median and best performance. Queries are sorted along the x axis in descending order of cmuLDWikiSP performance. Dots indicate the queries for which cmuLDWikiSP obtained the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Wikipedia Link-based Expansion Error Analysis</head><p>Here, we focus on the queries that were helped or hindered the most by Wikipedia link-based expansion. Comparing cmuSD vs. cmuSDwiki, Wikipedia link-based expansion improved MAP for 33/50 (66%) queries. The ones with the largest MAP increase were "road cycling" (372%), "U.S. national park" (266%) and "theater" (138%). Wikipedia link-based expansion found valuable expansion terms for these queries because most documents in the relevant set, S R , were in fact relevant. These were queries with many relevant articles in the Wikipedia (more than R = 100) in the form of relevant named entities (e.g., names of cyclists and cycling events, and names of parks and organizations dealing with parks).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>cmuLDwikiSP R-Precision</head><p>Query R-Precision q q q q q q q q q cmuLDwikiSP best median cmu=best (b) Per-query R-Prec The query with the largest drop in MAP (70%) was "food in Singapore". The top 5 expansion terms and scores were, singapore 0.596 lee kuan yew 0.053 orchard road 0.039 national university of singapore 0.033 singapore airlines 0.030</p><p>These non-relevant expansion phrases originated from links to non-relevant documents. Interestingly, the unexpanded query successfully ranked article "Cuisine in Singapore" above those linked to by these expansion phrases. However, "Cuisine in Singapore" had a total of 21 in-links. Each of the articles associated with these non-relevant anchor phrases had more than 100 in-links. Article "Singapore" had about 8000. The high number of in-links associated with these non-relevant articles in S R produced these poor expansion phrases. This same error type caused the third largest drop in MAP (30%), for the query "3D cities globes". The top 5 expansion terms and scores were, golden globe award 0.228 golden globes 0.150 duke nukem 3d 0.084 globe 0.082 golden globe 0.066</p><p>Here, again, the top ranked documents in S R were all relevant ("Live Search Maps", "Virtual Globe", "Google Earth", and "Polygonal Modeling"). However, all had fewer than 10 in-links. The non-relevant article "golden globe award", which contributed three non-relevant expansion phrases, was ranked 15th and had 739 in-links. The non-relevant article "Duke Nukem 3D", which contributed the third top anchor phrase, was ranked 58th and had 133 in-links. This analysis shows that non-relevant articles in S R , even if not at the top of the ranking, are specially damaging when they have many in-links. These potentially damaging non-relevant articles are more likely to be introduced into S R when there are less than R relevant articles for the query. This analysis is compatible with prior results showing that Wikipedia link-based expansion is particularly successful when the query describes a broad, general topic, likely to have many (&gt; R) relevant articles in Wikipedia <ref type="bibr" coords="5,521.86,634.55,9.97,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This year we continued our evaluation of retrieval models for blog feed search, applying extensions to the previous year's models. We also experimented with query expansion for this task, as well as an expanded document representation and spam filtering. The best performing retrieval model from last year's submission continued to perform well this year, but the extensions to last year's small document model did not. Query expansion also showed promising improvements on this year's query set, and spam filtering provided a slight performance boost.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,174.15,321.96,263.71,9.02"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Per-query results: median, best, and cmuSDwikiDP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="1,375.79,360.20,99.40,8.74"><head>Table 1 :</head><label>1</label><figDesc>Indexed fields</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="2,72.00,301.94,240.07,200.92"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="2,72.00,301.94,240.07,200.92"><row><cell>, where &lt;unigrams&gt;</cell></row><row><cell>#weight( v1 #weight(</cell></row><row><cell>0.8 #combine(&lt;unigrams&gt;.(permtext))</cell></row><row><cell>0.1 #combine(&lt;ordered windows&gt;.(permtext))</cell></row><row><cell>0.1 #combine(&lt;unordered windows&gt;.(permtext)))</cell></row><row><cell>v2 #weight(</cell></row><row><cell>0.8 #combine(&lt;unigrams&gt;.(title))</cell></row><row><cell>0.1 #combine(&lt;ordered windows&gt;.(title))</cell></row><row><cell>0.1 #combine(&lt;unordered windows&gt;.(title)))</cell></row><row><cell>v3 #weight(</cell></row><row><cell>0.8 #combine(&lt;unigrams&gt;.(entrytitle))</cell></row><row><cell>0.1 #combine(&lt;ordered windows&gt;.(entrytitle))</cell></row><row><cell>0.1 #combine(&lt;unordered windows&gt;.(entrytitle)))</cell></row><row><cell>v4 #weight(</cell></row><row><cell>0.8 #combine(&lt;unigrams&gt;.(entrybody))</cell></row><row><cell>0.1 #combine(&lt;ordered windows&gt;.(entrybody))</cell></row><row><cell>0.1 #combine(&lt;unordered windows&gt;.(entrybody))))</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="2,72.00,525.94,229.02,99.49"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="2,72.00,525.94,229.02,99.49"><row><cell>: Large Document Indri Query Template</cell></row><row><cell>is a simple unigram query, &lt;unordered windows&gt; is a</cell></row><row><cell>group of #uw query operators, each with a window size</cell></row><row><cell>set to twice the number of query terms considered,</cell></row><row><cell>and &lt;ordered windows&gt; is a group of #1 query op-</cell></row><row><cell>erators. Parameters v1-v4 were trained on last year's</cell></row><row><cell>queries and will be discussed in Section 3.3.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,341.23,73.55,165.46,73.46"><head>Table 4 :</head><label>4</label><figDesc>Results</figDesc><table coords="4,341.23,73.55,165.46,52.35"><row><cell>run</cell><cell>MAP</cell><cell>P@10</cell><cell>R-Prec</cell></row><row><cell>cmuSD</cell><cell>0.246</cell><cell>0.372</cell><cell>0.3086</cell></row><row><cell>cmuSDwiki</cell><cell>0.259</cell><cell>0.372</cell><cell>0.3178</cell></row><row><cell>cmuLDwiki</cell><cell>0.302</cell><cell>0.422</cell><cell>0.3534</cell></row><row><cell cols="4">cmuLDwikiSP 0.306 0.434 0.3646</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.24,714.56,130.11,6.99"><p>http://www.lemurproject.org/indri</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,87.24,695.59,110.89,6.99"><p>http://svmlight.joachims.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,87.24,705.09,205.18,6.99;4,72.00,714.56,48.26,6.99"><p>http://ebiquity.umbc.edu/resource/html/id/212/Splog-Blog-Dataset</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,87.50,213.61,213.53,8.74;6,87.50,225.57,213.53,8.74;6,87.50,237.52,213.53,8.74;6,87.50,249.48,213.53,8.74;6,87.50,261.43,205.65,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,87.50,225.57,213.53,8.74;6,87.50,237.52,138.40,8.74">Document representation and query expansion models for blog recommendation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Elsas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,246.24,237.52,54.79,8.74;6,87.50,249.48,213.53,8.74;6,87.50,261.43,174.80,8.74">ICWSM &apos;08: Proceedings of the 2nd annual international AAAI Conference in Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,281.36,213.52,8.74;6,87.50,293.31,213.53,8.74;6,87.50,305.27,213.52,8.74;6,87.50,317.22,213.52,8.74;6,87.50,329.18,213.53,8.74;6,87.50,341.13,56.15,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,281.62,281.36,19.40,8.74;6,87.50,293.31,213.53,8.74;6,87.50,305.27,47.83,8.74">Carbonell. Retrieval and feedback models for blog feed search</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Elsas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,162.92,305.27,138.10,8.74;6,87.50,317.22,213.52,8.74;6,87.50,329.18,213.53,8.74;6,87.50,341.13,26.37,8.74">SIGIR &apos;08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,361.06,213.53,8.74;6,87.50,373.01,213.52,8.74;6,87.50,384.97,213.53,8.74;6,87.50,396.92,213.52,8.74;6,87.50,408.88,156.15,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,237.31,361.06,63.71,8.74;6,87.50,373.01,71.13,8.74">Characterizing the splogosphere</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kolari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,182.75,373.01,118.27,8.74;6,87.50,384.97,213.53,8.74;6,87.50,396.92,213.52,8.74;6,87.50,408.88,125.52,8.74">WWW &apos;06: Proceedings of the 3rd Annual Workshop on Weblogging Ecosystem: Aggregation, Analysis and Dynamics, 15th World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,428.80,213.53,8.74;6,87.50,440.76,213.52,8.74;6,87.50,452.71,213.53,8.74;6,87.50,464.67,213.53,8.74;6,87.50,476.62,213.52,8.74;6,87.50,488.58,61.12,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,179.95,440.76,121.06,8.74;6,87.50,452.71,195.92,8.74">Splog detection using selfsimilarity analysis on blog temporal dynamics</title>
		<author>
			<persName coords=""><forename type="first">Y.-R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tatemura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,87.50,464.67,213.53,8.74;6,87.50,476.62,213.52,8.74;6,87.50,488.58,30.47,8.74">AIRWeb &apos;07: Proceedings of the 3rd international workshop on Adversarial information retrieval on the web</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,508.51,213.52,8.74;6,87.50,520.46,213.52,8.74;6,87.50,532.42,194.17,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,260.32,508.51,40.70,8.74;6,87.50,520.46,116.53,8.74">Overview of the trec-2007 blog track</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>In TREC &apos;07: Proceedings of the 16th TREC conference</note>
</biblStruct>

<biblStruct coords="6,87.50,552.34,213.52,8.74;6,87.50,564.30,213.52,8.74;6,87.50,576.25,213.53,8.74;6,87.50,588.21,78.60,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,220.53,552.34,80.48,8.74;6,87.50,564.30,152.22,8.74">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,268.09,564.30,32.93,8.74;6,87.50,576.25,40.91,8.74">Proc of SIGIR 05</title>
		<meeting>of SIGIR 05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,87.50,608.13,213.53,8.74;6,87.50,620.09,213.52,8.74;6,87.50,632.04,213.52,8.74;6,87.50,644.00,165.74,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,202.76,608.13,98.27,8.74;6,87.50,620.09,213.52,8.74;6,87.50,632.04,54.74,8.74">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,149.84,632.04,151.18,8.74;6,87.50,644.00,68.30,8.74">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
