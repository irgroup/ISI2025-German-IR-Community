<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.82,116.71,289.78,12.24">DUTIR at TREC 2008 Relevance Feedback Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,183.18,140.52,49.50,8.77"><forename type="first">Xiaoling</forename><surname>Sun</surname></persName>
							<email>sunxiaoling1234@126.com</email>
						</author>
						<author>
							<persName coords="1,239.19,140.52,34.36,8.77"><forename type="first">Yuan</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName coords="1,280.00,140.52,46.30,8.77"><forename type="first">Hongfei</forename><surname>Lin</surname></persName>
							<email>hflin@dlut.edu.cn</email>
						</author>
						<author>
							<persName coords="1,332.74,140.52,49.72,8.77"><forename type="first">Zhihao</forename><surname>Yang</surname></persName>
							<email>yangzh@dlut.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">LingGong Road Shahekou District</orgName>
								<address>
									<postCode>116023</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.82,116.71,289.78,12.24">DUTIR at TREC 2008 Relevance Feedback Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E3D5CA4734B3EE4062B9814C583AE682</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper details our experiments carried out at TREC 2008 Relevance Feedback Track. We focused on the analysis of feedback documents, both relevant and non-relevant, to explore more useful information to improve retrieval performance. In our experiments, local co-occurrence model and a Rocchio formula were used to select good expansion terms. Five runs were submitted. These runs used different amount of relevance info for analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1、 Introduction</head><p>Relevance feedback, which traditionally uses the terms in the relevance documents to enrich the user's initial query, is an effective method for improving retrieval performance. However, there has been comparatively few research advances in RF in recent years. There is no general agreement of what the best RF approach is, or what relative benefits and costs of the various approaches are <ref type="bibr" coords="1,402.79,383.22,10.38,8.77" target="#b0">[1]</ref>.</p><p>Setting up a framework to look at these separate effects for future research will be an important goal for this track. It is anticipated that this will be at least a 2 year effort. The first year will investigate aspects of relevance feedback that can be looked at without user involvement and will use one round of batch relevance judgments. There are plenty of issues to look at even with this simple setup. The second year will start to loosen this up and examine more realistic decision procedures for determination of documents to be looked at (e.g., arbitrary rounds of judgments based on results of previous judgments.) User interfaces will not be looked at during the first two years.</p><p>Indri search engine which combines the language modeling and inference network approaches were used in our experiments. Many studies have found that the terms that co-occur with the query terms frequently are often related to the query <ref type="bibr" coords="1,247.05,534.96,10.33,8.77" target="#b1">[2]</ref>. So our algorithm is based on local co-occurrence method, and uses a Rocchio formula to filter out bad expansion terms.</p><p>The other sections are organized as follow: Section 2 describes the collection used in the RF track and preprocess. Section 3 is our index environment. Section 4 explains the methods and official runs. Section 5 details the results and discussion on them. Section 6 draws some conclusions form the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2、 Collection and Preprocess</head><p>The Terabyte document collection is used for RF track. The GOV2 corpus, which contains a large proportion of the pages in .gov domain, is used as the collection. It is made up of about 25 million documents comprising about 426GB of document source. Topics are a subset of those used for either the 2007 Million Query track or the 2005, 2006 Terabyte tracks. In particular, the Million Query track topics furnish a source of ranked judgments that are system independent (i.e., ordered by the algorithms that chose which documents to judge).</p><p>The html format pages are preprocessed in the corpus, and the others are unchanged. The basic idea of relevance feedback is to extract expansion terms from the relevance documents to formulate a new query for a second round retrieval <ref type="bibr" coords="2,203.77,140.52,10.38,8.77" target="#b2">[3]</ref>. If the words added to the original query are unrelated to the topic, the quality of the retrieval is likely to be degraded. Since the web is a highly volatile and heterogeneous information source and usually contains various types of materials that are not related to the topic of the web-page, such as navigation, decoration, interaction and the others. These are considered noises and harmful to retrieval performance. Therefore, it is necessary to filter out the noisy information.</p><p>DOM based method is used in our experiment. First, the page is passed through an HTML parser that creates a DOM tree representation of the web page. We use Htmlparser as our HTML parser, which takes care of correcting the HTML, therefore we do not have to deal with error resiliency. Once processed, the resulting DOM document can be seamlessly shown as a webpage to the end-user as if it was HTML. The DOM tree is hierarchically arranged and can be analyzed in sections or as a whole. We navigate the DOM tree recursively, using a series of different filtering techniques to remove and modify specific nodes and leave only the content behind. In the experiment, we just remove some specific nodes, such as &lt;script&gt;, &lt;img&gt;, &lt;style&gt; and so on, to filter out the noisy information. A further work can be done to extract the useful content of the webpage. Then, the tags of the html pages are removed. At last, all the pages in the corpus are converted to trectext format files.</p><p>In order to increase retrieval speed, we split the documents into 4 pieces, and build each index on a different machine. So we use 4 PCs for both indexing and retrieval all the GOV2 corpus documents. The PC has 2.19GHz CPU with 2GB RAM running Windows XP.</p><p>First, we index the whole GOV2 collection with no special document or link structure indexed.</p><p>Second, we stem all documents by using the Porter stemmer. Third, we delete noise words using the stopword list provided by Indri. After all the documents are indexed, the size of full-text index is about 135GB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3、 Methods and Official Runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Local co-occurrence model</head><p>Xu and Croft's experiment had showed that local context analysis, using the co-occurrence information between terms, can perform very well <ref type="bibr" coords="2,251.83,542.52,11.40,8.77" target="#b3">[4]</ref> on query expansion. So, in our experiment, we use local co-occurrence method to select good terms. The sentence-level window is set for the co-occurrence of query and candidate terms. In the past, document-level window was often used for statistic co-occurrence information, but the size might be too rough to reflect the degree of correlation between two terms. In addition, when the document is very long, it maybe involves many various themes, if the size of window is large, "Theme offsets" problem will occur. That is why we select such a small size.</p><p>The method is similar to <ref type="bibr" coords="2,206.73,633.54,10.28,8.77" target="#b4">[5]</ref>, but the size of window is a sentence. The co-occurrence between term t and query term q is defined as follows:</p><formula xml:id="formula_0" coords="2,166.20,665.84,324.96,14.38">( , | ) min(1, ( | )* ( | )) Cooc t q S tf t S tf q S = (1)</formula><p>If t and q occurrence in a sentence, no matter how many times, we define it as 1. Then the degree of co-occurrence between t and q in the relevance document sets RE is:</p><formula xml:id="formula_1" coords="3,166.62,106.41,324.00,42.04">( , | ) ( , | ) D RE S D Cooc t q S Cood t q RE n ∈ ∈ = ∑ ∑ (2)</formula><p>At last, the cohesion degree between term t and query Q is:</p><formula xml:id="formula_2" coords="3,180.72,165.45,309.48,27.43">( , | ) ( , | ) q Q Cohd t Q RE Cood t q RE ∈ = ∏<label>(3)</label></formula><p>Then the top K terms can be selected as expansion terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A Rocchio formula</head><p>The co-occurrence model only considers the relevance documents, but non-relevance documents also help to improve the retrieval accuracy by lowering the rank of the documents similar to the non-relevant feedback documents. The expansion terms should make the largest difference between the relevance feedback documents and the non-relevance documents. So the non-relevance documents should be involved to select good expansion terms.</p><p>The term weight is assigned using the Rocchio formula applied to INQUERY's version 2.1 weighting scheme <ref type="bibr" coords="3,119.53,337.74,10.33,8.77" target="#b5">[6]</ref>. The top-K non-query terms in the following order are chosen and weighted using a Rocchio formula, β=0.75，γ=0.25:</p><formula xml:id="formula_3" coords="3,170.28,373.06,318.96,29.03">1 1 ( ) rel nonrel r n r Weight t belief belief n n β γ = ⋅ -⋅ ∑ ∑<label>(4)</label></formula><p>And the belief for term t in doc d is calculated by the formula:</p><p>, log( 0.5) log( 0. (5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Official runs</head><p>Because of the different advantages of the two methods mentioned above, we merge the two methods. The candidate terms are re-ranked by the scores obtained by the two methods, and then the top-K terms are selected.</p><p>We remove the stop words using a stop words list provided by Indri Search Engine from the original query, and combine the residual words by Indri operator #combine.</p><p>In the other runs, we also remove stop words. The original query and expansion terms are combined into a new query of the form:</p><p>#combine (0.8 original-query 0.2 expansion terms)</p><p>We submitted 5 runs for Relevance Feedback Track:</p><p>A: Our baseline, we used the Indri retrieval system. This run is only a simple query likelihood run. We don't make any change to the topics, just remove the stop words.</p><p>B: 1 rel doc. We use the local co-occurrence model in the relevance documents. The window of co-occurrence is a sentence. Top 20 terms are selected to extend the original topics. The proportion of original topic terms to extended terms is 0.8:0.2; the other runs are the same proportion.</p><p>C: 3 rel docs and 3 nonrel docs. The two methods are used to select good expansion terms, because the non-relevant documents are available. 30 terms are selected. D: 10 judged docs (superset of C, so at least 3 rel and 3 nonrel docs). The same to C methods.</p><p>E: Large amounts of judged docs (40 to 800). The same to C methods, but number of the expansion terms is larger. We select 70 terms because more feedback information can be used. This run examines the amount of improvement possible with more relevance info.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4、 Results</head><p>All 5 runs are summarized in table1. From the results we can see, with the feedback information increases, the results also increase at the same time. DUTIRRF08.D1 is a little better than the other runs. But the runs performed not very well on the whole. The reasons maybe include: the simple algorithm, the number and quality of expansion terms and so on. DUTIRRF08.E1 uses more information, but the result is not improved. Therefore, good performance can be obtained "on the cheap", by using just a relatively low number of positive judgments.</p><p>When the number of expansion terms is increased, the terms selected are either unrelated to the query or is harmful, instead of helpful, to retrieval effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5、 Conclusion</head><p>In the RF track, we use local co-occurrence model and a Rocchhio formula to select good expansion terms, but the results are not very well. The reason maybe, the sizes of the optimal query of different topics are different. It means that we cannot use the same query size for all the topics. In the future, we are interested in exploring the best query size and using the best methods for each different topic. In addition, expansion-based feedback maybe creates an inconsistent interpretation of the original and the expanded query, model-based feedback should be mainly considered.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,87.42,231.54,420.53,155.61"><head>Table 1</head><label>1</label><figDesc>Table 1 is based on judging a pool of the top 10 ranked documents from each run for a subset of 31 of the terabyte-track topics. The results of MTC and statAP algorithm are not listed here. Run submitted for top 10 ranked documents for a subset of 31 of the terabyte-track topics</figDesc><table coords="4,87.42,285.38,386.68,86.18"><row><cell>Run</cell><cell>P@5</cell><cell>P@10</cell><cell>MAP</cell><cell>R-Precision</cell><cell>bpref</cell></row><row><cell>DUTIRRF08.A1</cell><cell>0.2387</cell><cell>0.2290</cell><cell>0.1326</cell><cell>0.1633</cell><cell>0.2033</cell></row><row><cell>DUTIRRF08.B1</cell><cell>0.2774</cell><cell>0.2774</cell><cell>0.1523</cell><cell>0.1825</cell><cell>0.2213</cell></row><row><cell>DUTIRRF08.C1</cell><cell>0.3226</cell><cell>0.3000</cell><cell>0.1613</cell><cell>0.1956</cell><cell>0.2283</cell></row><row><cell>DUTIRRF08.D1</cell><cell>0.2968</cell><cell>0.2903</cell><cell>0.1675</cell><cell>0.2056</cell><cell>0.2349</cell></row><row><cell>DUTIRRF08.E1</cell><cell>0.3290</cell><cell>0.3258</cell><cell>0.1664</cell><cell>0.1890</cell><cell>0.2376</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,101.22,659.70,210.77,8.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,101.22,659.70,81.79,8.77">Proposal for a TREC</title>
	</analytic>
	<monogr>
		<title level="j" coord="4,207.24,659.70,104.75,8.77">Relevance Feedback Track</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,101.28,682.44,406.60,8.77;4,87.42,697.62,311.70,8.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,363.54,682.44,144.35,8.77;4,87.42,697.62,109.57,8.77">Selecting Good Expansion Terms for Pseudo-Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,214.42,697.62,109.31,8.77">Proceedings of SIGIR &apos;2008</title>
		<meeting>SIGIR &apos;2008</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,101.40,720.37,406.57,8.77;5,87.42,110.16,330.83,8.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,322.25,720.37,185.71,8.77;5,87.42,110.16,205.31,8.77">Improving Pseudo-Relevance Feedback in Web Information Retrieval Using Web Page Segmentation</title>
		<author>
			<persName coords=""><forename type="first">Shipeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,310.04,110.16,84.13,8.77">Proceeding of WWW</title>
		<meeting>eeding of WWW</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,102.71,132.90,405.23,8.77;5,87.42,148.08,301.96,8.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,211.47,132.90,296.47,8.77;5,87.42,148.08,46.04,8.77">Improving the Effectiveness of Information Retrieval with Local Context Analysis [J]</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,138.55,148.08,163.90,8.77">ACM Transaction on Information Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,101.52,170.83,406.46,8.77;5,87.42,186.00,287.50,8.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,265.22,170.83,242.76,8.77;5,87.42,186.00,34.25,8.77">Local Co-occurrence Based Query Expansion for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ding</forename><surname>Guodong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bai</forename><surname>Shuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wang</forename><surname>Bin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,127.93,186.00,164.73,8.77">Journal of Chinese Information Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="84" to="91" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,102.36,208.75,405.61,8.77;5,87.42,223.93,278.05,8.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,431.97,208.75,76.00,8.77;5,87.42,223.93,58.57,8.77">Recent Experiment with INQUERY</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lisa</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhihong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,164.50,223.93,172.01,8.77">Fourth Text REtrieval Conference (TREC-4)</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
