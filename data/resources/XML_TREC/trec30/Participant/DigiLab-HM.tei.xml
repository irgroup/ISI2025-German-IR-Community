<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.75,70.85,407.78,12.90;1,119.12,86.79,357.03,12.90">DS4DH at TREC Health Misinformation 2021: Multi-Dimensional Ranking Models with Transfer Learning and Rank Fusion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,98.24,109.66,58.65,10.37"><forename type="first">Boya</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Medical Informatics</orgName>
								<orgName type="institution">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.35,109.66,61.41,10.37"><forename type="first">Nona</forename><surname>Naderi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Sciences and Arts of Western</orgName>
								<orgName type="institution">HES-SO University of Applied</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Swiss Institute of Bioinformatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.20,109.66,119.19,10.37"><forename type="first">Fernando</forename><surname>Jaume-Santero</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Medical Informatics</orgName>
								<orgName type="institution">University of Geneva</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Sciences and Arts of Western</orgName>
								<orgName type="institution">HES-SO University of Applied</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,401.09,109.66,82.50,10.37"><forename type="first">Douglas</forename><surname>Teodoro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Medical Informatics</orgName>
								<orgName type="institution">University of Geneva</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Sciences and Arts of Western</orgName>
								<orgName type="institution">HES-SO University of Applied</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Swiss Institute of Bioinformatics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.75,70.85,407.78,12.90;1,119.12,86.79,357.03,12.90">DS4DH at TREC Health Misinformation 2021: Multi-Dimensional Ranking Models with Transfer Learning and Rank Fusion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ADC6C185D91CEEFCFC60C84FE317030D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the work of the Data Science for Digital Health (DS4DH) group at the TREC Health Misinformation Track 2021. The TREC Health Misinformation track focused on the development of retrieval methods that provide relevant, correct and credible information for health related searches on the Web. In our methodology, we used a two-step ranking approach that includes i) a standard retrieval phase, based on BM25 model, and ii) a reranking phase, with a pipeline of models focused on the usefulness, supportiveness and credibility dimensions of the retrieved documents. To estimate the usefulness, we classified the initial rank list using pre-trained language models based on the transformers architecture fine-tuned on the MS MARCO corpus. To assess the supportiveness, we utilized BERT-based models fine-tuned on scientific and Wikipedia corpora. Finally, to evaluated the credibility of the documents, we employed a random forest model trained on the Microsoft Credibility dataset combined with a list of credible sites. The resulting ranked lists were then combined using the Reciprocal Rank Fusion algorithm to obtain the final list of useful, supporting and credible documents. Our approach achieved competitive results, being top-2 in the compatibility measurement for the automatic runs. Our findings suggest that integrating automatic ranking models created for each information quality dimension with transfer learning can increase the effectiveness of health-related information retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The purpose of the TREC Health Misinformation Track<ref type="foot" coords="1,95.61,691.34,3.99,6.91" target="#foot_0">1</ref> is to develop retrieval systems that provide relevant and correct information for health-related Web searches. The challenge provides 50 healthrelated topics, among which only 35 topics are evaluated. As illustrated in Table <ref type="table" coords="1,464.88,216.46,4.17,9.46" target="#tab_1">1</ref>, each topic contains a query, a description, a narrative, a stance and an evidence . For automatic runs, only the query and the description are used. The TREC Health Misinformation corpus contains one billion English documents extracted from the April 2019 snapshot of Common Crawl <ref type="bibr" coords="1,431.43,297.75,83.49,9.46" target="#b10">(Raffel et al., 2020)</ref>.</p><p>For a document to be relevant and correct, the TREC Health Misinformation challenge considers three levels of information quality: (1) usefulness, that is, whether a document contains relevant information to answer a topic's question; (2) supportiveness, that is, whether a document contains supportive information for the descriptions marked as helpful or dissuasive information for the descriptions marked as unhelpful; and (3) credibility, that is, whether an information source document is considered credible in the field of knowledge. This paper describes submissions of DS4DH to the TREC Health Misinformation 2021, which achieved top-2 performance in the compatibility assessment for the automatic runs. Section 2 introduces our methodology based on a twostep approach of document retrieval for the multidimensional retrieval task and the specific evaluation criteria used to assess these dimensions with a single ranked list. Section 3 presents and discusses our results. Finally, Section 4 concludes this paper and proposes future studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The overview of our pipeline is presented in Figure 1. First, in the retrieval phase, we extracted 10,000 documents using a BM25 model <ref type="bibr" coords="1,488.52,696.18,32.99,9.46;1,306.14,709.73,103.00,9.46" target="#b11">(Robertson and Zaragoza, 2009)</ref>. Second, in the re-ranking phase, we estimated relevance of the documents according to the usefulness, supportiveness and credibility scores. At the end, 7 runs with different model combinations were submitted.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Retrieval Phase</head><p>We extracted 10,000 documents using a BM25 model with standard <ref type="bibr" coords="2,170.94,542.39,119.55,9.46;2,70.87,555.94,25.96,9.46" target="#b11">(Robertson and Zaragoza, 2009)</ref> and fine-tuned parameters. For the finetuning version, as the query relevance was not available, we created topics, that is, query + description, for a set of indexed documents using the a key-word2query and doc2query approaches proposed by Bennani-Smires et al. <ref type="bibr" coords="2,187.19,623.68,103.32,9.46;2,70.87,637.23,25.09,9.46" target="#b1">(Bennani-Smires et al., 2018)</ref> and <ref type="bibr" coords="2,116.95,637.04,168.82,9.66">Nogueira et al. (Nogueira et al., 2019b)</ref>, respectively. Then, a known-item search approach was applied using the silver topics and the BM25 parameters was fine-tuned using a grid search. This resulted in two initial ranking lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Re-Ranking Phase</head><p>For re-ranking the retrieved documents, we use a set of machine learning models trained to classify documents according to the usefulness, supportive-ness, and credibility criteria.</p><p>Usefulness To improve the usefulness dimension of the retrieved documents, we implemented reranking models based pre-trained language models fine-tuned on the MS MARCO dataset: BERT-base <ref type="bibr" coords="2,305.78,614.88,63.71,9.46" target="#b6">(Li et al., 2020)</ref>, mono-BERT-large (Nogueira et al., 2019a) and ELECTRA <ref type="bibr" coords="2,409.20,628.43,80.55,9.46" target="#b2">(Clark et al., 2020)</ref>. While BM25 provides a strong baseline for usefulness, it does not consider the relation and context of words. Thus, the pre-trained language models are used to enhance the quality of the original ranking <ref type="bibr" coords="2,324.06,696.18,99.31,9.46" target="#b14">(Teodoro et al., 2021)</ref> as similarly shown to improve other natural language processing tasks like named entity recognition <ref type="bibr" coords="2,436.05,723.27,85.61,9.46" target="#b8">(Naderi et al., 2021)</ref>. Given a topic and a document, the language model infers whether the document is relevant or not to the topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supportiveness</head><p>In this information quality dimension, documents are identified under three levels: 1) supportive -the document supports the treatment; 2) dissuades -the document refutes the treatment; 3) neutral -the document does not contain enough information to make the decision. We want documents that are either supportive or dissuasive on the top of the ranking list, which means that correct or factual documents are boosted and misinforming documents should be downgraded.</p><p>The supportiveness dimension shares similarities with claim-checking models, which take a claim and a document as the information source, and validate or refute the claim based on document content <ref type="bibr" coords="3,70.51,264.41,111.44,9.46" target="#b13">(Stammbach et al., 2021)</ref>. Their main difference is that for claim-checking models, we assume that the information source is always correct. Thus, for the supportiveness criterion, we add a further classification step, which evaluates the documents as correct or incorrect. To do so, we used a k-nearest neighbors algorithm <ref type="bibr" coords="3,163.87,345.71,97.01,9.46" target="#b15">(Teodoro et al., 2010)</ref> based on the top-k assignments provided by the claimchecking models, that is, a majority vote is used to decide whether the treatment should be supported or dissuaded. Then, higher rank is given to the correct supportive/dissuasive documents, medium rank is given to the neutral documents and lower rank is given to the incorrect supportive/dissuasive documents. The details are shown in Figure <ref type="figure" coords="3,265.13,454.10,5.47,9.46">2</ref> and Table <ref type="table" coords="3,97.22,467.65,4.09,9.46">2</ref>.</p><p>We used three models from the Scientific Claim Verification task <ref type="bibr" coords="3,145.78,494.75,95.65,9.46" target="#b17">(Wadden et al., 2020)</ref> to classify the treatments: RoBERTa-Large <ref type="bibr" coords="3,214.20,508.30,71.61,9.46" target="#b7">(Liu et al., 2019)</ref>, BioMedRoBERTa-base <ref type="bibr" coords="3,177.85,521.85,112.01,9.46" target="#b5">(Gururangan et al., 2020)</ref> and SciBERT-base <ref type="bibr" coords="3,158.23,535.40,94.13,9.46" target="#b0">(Beltagy et al., 2019)</ref>. These models were trained on either scientific or large English corpora and fine-tuned on the FEVER <ref type="bibr" coords="3,70.51,576.04,93.08,9.46" target="#b16">(Thorne et al., 2018)</ref> and SciFact <ref type="bibr" coords="3,222.53,576.04,67.97,9.46;3,70.87,589.59,25.43,9.46" target="#b17">(Wadden et al., 2020)</ref> datasets. The information that these models learned from previous corpora benefits our ranking task through transfer learning.</p><p>Credibility For estimating credibility, we develop a random forest classifier trained on the Microsoft Credibility dataset <ref type="bibr" coords="3,192.03,664.29,98.47,9.46;3,70.87,677.83,25.96,9.46" target="#b12">(Schwarz and Morris, 2011)</ref> with a set of features, such as readability, openpage rank 2 and number of CSS style sheets. The dataset consists of 1,000 Web pages on five topics of Health, Politics, Finance, Environmental Science, and Celebrity News. The Web pages are manually rated with credibility scores between 1 2 https://www.domcop.com/openpagerank/documentation ("very non-credible") and 5 ("very credible"). <ref type="foot" coords="3,519.93,72.68,3.99,6.91" target="#foot_1">3</ref>We convert these scores for a binary classification setting -that is, the scores of 4 and 5 are considered as 1 or credible and scores of 1, 2, and 3 are considered as 0 or non-credible. For the readability score, we rely on SMOG index, which estimates the years of education an average person needs to understand a piece of writing. Following <ref type="bibr" coords="3,483.98,169.57,40.43,9.46;3,306.14,183.12,74.67,9.46" target="#b12">(Schwarz and Morris, 2011)</ref>, we retrieve a Web page's PageRank and use it as a feature to train the classifier. We further use the number of CSS style definitions for estimating the effort for the design of a Web page <ref type="bibr" coords="3,305.78,237.31,94.82,9.46" target="#b9">(Olteanu et al. (2013)</ref> showed the effectiveness of this feature). Furthermore, a list of credible websites scrapped from the Health On the Net search engine 4 for the challenge's queries is combined with the baseline model to explore better performance. The result of the classifier was added with a unitary value for the Health on the Net credible sites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Submitted Runs</head><p>Run 1: Baseline run. A combination of M1, M5 and M7 in Figure <ref type="figure" coords="3,381.52,386.38,4.01,9.46" target="#fig_0">1</ref>. This automatic run was created using a model based on Reciprocal Rank Fusion (RRF) <ref type="bibr" coords="3,337.26,413.48,101.20,9.46" target="#b4">(Cormack et al., 2009)</ref> of three models: i) usefulness, created using a default BM25, ii) supportiveness, created using a RoBERTa large model fine-tuned on the FEVER and SciFact corpus, and iii) credibility, created using a credibility random forest classifier as described in Section2.</p><p>Run 2: A combination of M2, M6 and M9 in Figure <ref type="figure" coords="3,338.95,516.20,4.17,9.46" target="#fig_0">1</ref>. This automatic run was created using a rank fusion based on RRF of three models: i) usefulness, created using a combined default BM25 with a fine-tuned BM25 model using known item search with query and description been generated using transfer learning from language models, ii) supportiveness, created using a combined rank of three transformer-based models fine-tuned on the FEVER and SciFact corpus, and iii) credibility, created using a random forest classifier trained on the Microsoft Credibility dataset combined with a list of credible sites.</p><p>Run 3: A combination of M3, M6 and M9 in Figure <ref type="figure" coords="3,338.95,700.22,4.17,9.46" target="#fig_0">1</ref>. This automatic run was created using a rank fusion based on RRF of three models: i) Figure <ref type="figure" coords="4,98.80,280.17,3.80,8.64">2</ref>: Re-Ranking Pipeline for Supportiveness. When the supportive and dissuasive documents are for one topic, we use the majority vote to decide the correct label. The document ranking score of the incorrect side becomes negative. We bring in the credibility sites when tie. </p><formula xml:id="formula_0" coords="4,322.40,363.49,120.68,43.78">S max or -S max 1 -1 N N i=1 S i 1 -1 N N i=1 S i -3 -3 -2 -2</formula><p>Table <ref type="table" coords="4,95.74,420.81,3.95,8.64">2</ref>: Ranking Score for Supportiveness. When the document only includes neutral evidence, the document confidence score is 1 -1 N N i=1 S i , where S 1 , S 2 , ..., S i is the confidence score of each evidence in the document. When the document contains both supports and dissuades evidences without considering the neutral cases, the document confidence score is -2. When evidences are either support or dissuades without considering the neutral cases, the document confidence score is S max , where S max is highest among the confidence score of each evidence in the document. When the qualified evidence is void, the document confidence score is -3. usefulness, created using a combination of three transformed-based language models trained on the MS MARCO corpus 5 , ii) supportiveness, created using a combined rank of three transformer-based models fine-tuned on the FEVER and SciFact corpus, and iii) credibility, created using a random forest model trained on the Microsoft Credibility dataset combined with a list of credible sites.</p><p>Run 4: A combination of <ref type="bibr" coords="4,190.02,633.05,17.52,9.46">M4,</ref><ref type="bibr" coords="4,210.02,633.05,76.46,9.46;4,70.87,646.60,13.79,9.46">M5 and M9 in Figure</ref> 1. This automatic run was created using a rank fusion based on RRF of three models: i) usefulness, created using a combined BoW model with three transformed-based language models trained on the MS MARCO corpus, ii) supportiveness, created using a RoBERTa large model fine-tuned on the FEVER and SciFact corpus, and iii) credibility, created using a random forest model trained on the 5 https://microsoft.github.io/msmarco/ Microsoft Credibility dataset combined with a list of credible sites.</p><p>Run 5: A combination of M4, M6 and M7 in Figure <ref type="figure" coords="4,338.08,564.66,4.17,9.46" target="#fig_0">1</ref>. This automatic run was created using a rank fusion based on RRF of three models: i) usefulness, created using a combined BoW model with three transformed-based language models trained on the MS MARCO corpus, ii) supportiveness, created using a combined rank of three transformerbased models fine-tuned on the FEVER and SciFact corpus, and iii) credibility, create using a random forest model trained on the Microsoft Credibility dataset.</p><p>Run 6: A combination of M4, M6 and M9 in Figure 1. This automatic run was created using a rank fusion based on RRF of three models: i) usefulness, created using a combined BoW model with three transformed-based language models trained on the MS MARCO corpus, ii) supportiveness, created using a combined rank of three transformer-based models fine-tuned on the FEVER and SciFact corpus, and iii) credibility, created using a random forest classifier combined with a list of credible sites.</p><p>Run 7: A combination of all the individual models in Figure <ref type="figure" coords="5,131.99,177.16,4.17,9.46" target="#fig_0">1</ref>. This automatic run was created using a rank fusion based on RRF of the individual models used to create the i) usefulness (5 individual models), ii) supportiveness (3 individual models), and iii) credibility (2 individual models).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Evaluation Methods</head><p>The assessments of this year's TREC Health Misinformation were divided into "compatibility with helpful" (help) and "compatibility with harmful" (harm) metrics. In order to evaluate the system's ability to have higher levels for helpful information and lower levels for harmful information, the "compatibility with harmful" results were subtracted from the "compatibility with helpful" results, which is marked as "help-harm". This orders systems correctly with similar helpful compatibility and lower harmful compatibility. For more details, please see <ref type="bibr" coords="5,117.51,420.63,85.48,9.46" target="#b3">(Clarke et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>The official challenge results are shown in Table <ref type="table" coords="5,283.69,465.71,5.44,9.46" target="#tab_4">3</ref> and Figure <ref type="figure" coords="5,122.39,479.26,4.17,9.46" target="#fig_1">3</ref>. The 'Best Help', 'Best Harm' and 'Best Hp-Hm' are are the highest "compatibility with helpful" (help), lowest "compatibility with harmful" (harm) and highest "help-harm" from the list of top-3 automatic runs from each group. Note that 'Run 1' to 'Run 7' are runs submitted by the DS4DH group. 'BM25 Baseline' is the baseline model by the TREC Health Misinformation.</p><p>In our submitted runs, the best harm is in 'Run 4', the best help and help-harm are both in 'Run 7'. This is as expected since Run 7 combines all the individual models to maximize the system ranking ability. The helpful compatibility is 0.136 which is comparable to the 'Best Help', and the harmful compatibility 0.095 is significantly low, which is similar to the 'Best Harm'. Therefore, we obtained help-harm at 0.041, which is right after the overall 'Best Hp-Hm', together with superior performance on lower ranking harmful information.</p><p>The 'Best Help' run achieved in the challenge gives the helpful compatibility at 0.203. However, for this run, the harmful compatibility is also as   high as 0.168. Therefore, the help-harm is 0.034, which can distinguish the helpful and harmful information but needs improvement by lower ranking the harmful one. The 'Best Harm' gives the harmful compatibility at 0.022, which is significantly lower than other runs. However, the helpful compatibility for this run is only 0.006, resulting in a help-harm of -0.016, in a sense that neither helpful nor harmful information is retrieved. On the other hand, the 'Best Hp-Hm' gives relatively higher helpful compatibility at 0.195 and relatively lower compatibility at 0.153. In the end, the best help-harm 0.043 is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Models Analysis</head><p>To understand the performance of each component, we study the compatibility of individual models. The results are depicted in  ity with 0.143. This is beneficial since at this phase, overall compatibility is more critical. The monoBERT model for usefulness in the re-ranking phase gives highest help-harm compatibility at 0.053, which is the top-1 result compared to the automatic runs submitted by the participants. This indicates that the model can effectively differentiate between helpful and harmful information. The SciBERT-base model for supportiveness gives lowest harmful compatibility at 0.009 with satisfactory helpful compatibility. This demonstrates the model's ability to identify misinformation. As a result of the foregoing analysis, further experiments could be explored: 1) in the document retrieval phase, BM25 should be the prior model. 2) in the re-rankning phase: prioritising the monoBERT for usefulness, the SciBERT-base model for supportiveness, the 'Random Forest with Credibility Sites' model for credibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In the average compatibility measurement of automatic runs, our contributions came out on top-2. Our findings imply that combining automatic ranking models for each information quality dimension with transfer learning can improve the quality of health-related information retrieval by allowing the proper documents to be retrieved while discarding the incorrect ones. The RRF algorithm is a robust alternative for combining ranks when no trained set is available. Further empirical approaches could be to fine-tune our models based on topic content and generate manual runs and to re-rank the top 10% of the retrieved documents to reduce the possibility of bringing the harmful documents from the bottom of the ranking list to the top.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,70.87,391.81,453.72,8.64;2,70.87,403.76,453.54,8.64;2,70.87,415.72,453.55,8.64;2,70.87,427.67,455.29,8.64;2,70.87,439.63,453.54,8.64;2,70.87,451.58,453.72,8.64;2,70.87,463.54,454.78,8.64;2,70.87,475.49,447.68,8.64;2,70.87,258.72,454.86,121.24"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Retrieval Pipeline. M1: BM25 baseline. M2: M1 combined with a fine-tuned index using a silver standard query relevance. M3: a re-ranked list using masked language models (MLMs) fine-tuned on the MS MARCO dataset. M4: a combination BM25 and MLMs. M5: a RoBERTa model fine-tuned on the FEVER+SciFact fact-checking datasets. M6: A combination of three MLMs trained on the FEVER+SciFact fact-checking corpora. M7: a random forest model trained on the Microsoft Credibility dataset to predict a site's credibility. M8: a list of credible websites scrapped from the Health-on-Net search engine for the challenge's queries. M9: a linear combination of M7 and M8 models. M10: a combination of model M4, M6 and M9. All ranking combinations, apart from M9, were created using the reciprocal ranking fusion (RRF) algorithm with the k parameter set to 60.</figDesc><graphic coords="2,70.87,258.72,454.86,121.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,306.14,454.28,218.44,8.64;5,306.14,466.23,66.43,8.64;5,313.23,238.34,204.09,204.09"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Relations between 'Help' and 'Harm' for Submitted Runs.</figDesc><graphic coords="5,313.23,238.34,204.09,204.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,70.87,286.81,218.44,8.64;6,70.87,298.76,218.27,8.64;6,70.87,310.72,219.65,8.64;6,70.87,322.67,219.65,8.64;6,70.87,334.63,218.27,8.64;6,70.87,346.58,218.27,8.64;6,70.87,358.54,132.00,8.64;6,77.95,70.87,204.09,204.09"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Relations between 'Help' and 'Harm' for Individual Models. ELE: ELECTRA. RwC: Random Forest with Credibility Sites. mnBT: monoBERT. RF: Random Forest. BioB: BioMedRoBERTa-base. RBL: RoBERTa-Large. SciBT: SciBERT. BM25: Standard BM25. Ft: Fine-tuned BM25. BM25-B: BM25 Baseline by TREC Health Misinformation</figDesc><graphic coords="6,77.95,70.87,204.09,204.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="4,70.87,70.87,459.00,197.46"><head></head><label></label><figDesc></figDesc><graphic coords="4,70.87,70.87,459.00,197.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="8,147.64,103.57,300.00,185.50"><head></head><label></label><figDesc></figDesc><graphic coords="8,147.64,103.57,300.00,185.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="8,70.87,334.90,464.94,287.70"><head></head><label></label><figDesc></figDesc><graphic coords="8,70.87,334.90,464.94,287.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,248.45,236.70,98.06,8.64"><head>Table 1 :</head><label>1</label><figDesc>Topic Example.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,309.81,214.38,210.62,8.64"><head>Table 3 :</head><label>3</label><figDesc>Averaged Compatibility of Submitted Runs.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.01,756.07,189.29,6.31;1,70.87,766.03,16.14,6.31"><p>https://trec-health-misinfo.github. io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,322.28,734.41,203.61,7.77;3,306.14,744.37,218.49,7.77;3,306.14,754.34,41.52,7.77"><p>A credibile Web page is defined as "a page whose information one can accept as the truth without needing to look elsewhere."</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Illustration for Compatibility Measurement</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,306.14,225.55,219.65,8.64;6,316.69,236.51,207.72,8.64;6,316.74,247.29,207.67,8.59;6,316.63,258.25,207.77,8.59;6,316.88,269.21,207.52,8.59;6,316.74,280.17,199.06,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,494.58,225.55,31.21,8.64;6,316.69,236.51,190.78,8.64">Scibert: A pretrained language model for scientific text</title>
		<author>
			<persName coords=""><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,316.74,247.29,207.67,8.59;6,316.63,258.25,207.77,8.59;6,316.88,269.21,207.52,8.59;6,316.74,280.17,118.89,8.59">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3615" to="3620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,306.14,301.15,219.92,8.64;6,317.05,312.10,209.10,8.64;6,317.05,323.06,209.01,8.64;6,317.05,333.84,209.01,8.82;6,317.05,344.80,209.01,8.59;6,317.05,355.76,80.25,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,317.05,323.06,209.01,8.64;6,317.05,334.02,70.02,8.64">Simple unsupervised keyphrase extraction using sentence embeddings</title>
		<author>
			<persName coords=""><forename type="first">Kamil</forename><surname>Bennani-Smires</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreea</forename><surname>Hossmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Baeriswyl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,406.18,333.84,119.89,8.59;6,317.05,344.80,209.01,8.59;6,317.05,355.76,11.42,8.59">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="221" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,306.14,376.74,218.27,8.64;6,317.05,387.70,207.36,8.64;6,317.05,398.66,209.10,8.64;6,317.05,409.44,134.67,8.59" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="6,443.93,387.70,80.49,8.64;6,317.05,398.66,205.18,8.64">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,306.14,430.41,218.27,8.64;6,317.05,441.19,207.36,8.82;6,316.49,452.15,210.08,8.82;6,317.05,463.29,12.45,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,387.40,441.37,105.58,8.64">Assessing top-preferences</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandra</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Vtyurina</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Smucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,503.26,441.19,21.16,8.59;6,316.49,452.15,170.37,8.59">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,306.14,484.09,218.27,8.64;6,317.05,495.05,207.36,8.64;6,317.05,506.00,207.35,8.64;6,316.74,516.78,207.67,8.59;6,317.05,527.74,209.01,8.59;6,317.05,538.70,119.30,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,385.02,495.05,139.39,8.64;6,317.05,506.00,190.76,8.64">Reciprocal rank fusion outperforms condorcet and individual rank learning methods</title>
		<author>
			<persName coords=""><surname>Gordon V Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Buettcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,316.74,516.78,207.67,8.59;6,317.05,527.74,209.01,8.59;6,317.05,538.70,50.65,8.59">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,306.14,559.68,218.27,8.64;6,317.05,570.64,208.60,8.64;6,317.05,581.60,208.74,8.64;6,316.69,592.56,207.72,8.64;6,316.74,603.34,82.55,8.59" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,431.61,581.60,94.19,8.64;6,316.69,592.56,188.39,8.64">Don&apos;t stop pretraining: Adapt language models to domains and tasks</title>
		<author>
			<persName coords=""><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,316.74,603.34,77.43,8.59">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,306.14,624.31,218.27,8.64;6,316.47,635.27,207.93,8.64;6,317.05,646.05,207.36,8.82;6,317.05,657.01,75.27,8.59" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Canjia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yingfei</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09093</idno>
		<title level="m" coord="6,398.12,635.27,126.28,8.64;6,317.05,646.23,142.49,8.64">Parade: Passage representation aggregation for document reranking</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,306.14,677.99,219.92,8.64;6,317.05,688.95,208.60,8.64;6,317.05,699.90,209.10,8.64;6,317.05,710.86,209.01,8.64;6,317.05,721.64,167.86,8.82" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="6,317.05,710.86,209.01,8.64;6,317.05,721.82,25.37,8.64">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,306.14,742.62,218.52,8.64;6,317.05,753.58,207.35,8.64;6,317.05,764.54,207.71,8.64;7,70.87,332.28,218.27,8.64;7,81.78,343.24,207.71,8.64;7,81.78,354.02,207.26,8.82" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,455.32,753.58,69.09,8.64;6,317.05,764.54,207.71,8.64;7,70.87,332.28,76.26,8.64">Ensemble of deep masked language models for effective named entity Rodrigo Nogueira</title>
		<author>
			<persName coords=""><forename type="first">Nona</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Knafou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jenny</forename><surname>Copara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas Teodoro ; Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2021. 2019</date>
			<biblScope unit="page">1904</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct coords="7,70.87,373.68,218.27,8.64;7,81.78,384.64,209.01,8.64;7,81.78,395.42,207.36,8.82;7,81.78,406.38,209.10,8.82;7,81.78,417.52,36.25,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,167.68,384.64,123.10,8.64;7,81.78,395.60,144.06,8.64">Web credibility: Features exploration and credibility prediction</title>
		<author>
			<persName coords=""><forename type="first">Alexandra</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stanislav</forename><surname>Peshterliev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,249.50,395.42,39.63,8.59;7,81.78,406.38,140.46,8.59">European conference on information retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="557" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.87,437.00,219.92,8.64;7,81.78,447.96,207.36,8.64;7,81.78,458.92,207.36,8.64;7,81.78,469.88,207.36,8.64;7,81.78,480.66,208.60,8.82;7,81.78,491.79,56.73,8.64" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,234.30,458.92,54.84,8.64;7,81.78,469.88,207.36,8.64;7,81.78,480.83,44.26,8.64">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,133.68,480.66,152.42,8.59">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.87,511.09,219.92,8.82;7,81.78,522.05,209.10,8.59;7,81.78,533.19,80.83,8.64" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<title level="m" coord="7,252.85,511.09,37.93,8.59;7,81.78,522.05,204.59,8.59">The probabilistic relevance framework: BM25 and beyond</title>
		<imprint>
			<publisher>Now Publishers Inc</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.87,552.67,218.27,8.64;7,81.42,563.63,208.06,8.64;7,81.78,574.41,209.01,8.82;7,81.78,585.37,207.35,8.82;7,81.03,596.51,47.32,8.64" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,240.17,552.67,48.97,8.64;7,81.42,563.63,208.06,8.64;7,81.78,574.59,43.36,8.64">Augmenting web pages and search results to support credibility assessment</title>
		<author>
			<persName coords=""><forename type="first">Julia</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Meredith</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,145.91,574.41,144.88,8.59;7,81.78,585.37,177.84,8.59">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1245" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.87,615.99,220.01,8.64;7,81.78,626.95,207.36,8.64;7,81.78,637.73,171.27,8.82" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="7,109.11,626.95,180.03,8.64;7,81.78,637.91,58.81,8.64">The choice of knowledge base in automated claim checking</title>
		<author>
			<persName coords=""><forename type="first">Dominik</forename><surname>Stammbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Boya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elliott</forename><surname>Ash</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2111" to="07795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.87,657.39,219.51,8.64;7,81.78,668.35,209.01,8.64;7,81.78,679.30,208.60,8.64;7,81.78,690.26,208.74,8.64;7,81.78,701.04,207.35,8.82;7,81.61,712.00,129.15,8.82" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,134.21,690.26,156.31,8.64;7,81.78,701.22,126.74,8.64">Information retrieval in an infodemic: the case of covid-19 publications</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sohrab</forename><surname>Ferdowsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikolay</forename><surname>Borissov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elham</forename><surname>Kashani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Vicente Alvarez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jenny</forename><surname>Copara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Racha</forename><surname>Gouareb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nona</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Poorya</forename><surname>Amini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,216.00,701.04,73.13,8.59;7,81.61,712.00,66.44,8.59">Journal of medical Internet research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">30161</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.87,731.66,219.52,8.64;7,81.78,742.62,209.10,8.64;7,81.42,753.58,209.37,8.64;7,81.78,764.36,207.36,8.82;7,316.63,249.31,209.43,8.59;7,317.05,260.27,209.10,8.59;7,317.05,271.23,156.74,8.59" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,81.42,753.58,209.37,8.64;7,81.78,764.54,83.78,8.64">Automatic ipc encoding and novelty tracking for effective patent mining</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emilie</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vishnyakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Lovis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,184.54,764.36,104.59,8.59;7,316.63,249.31,209.43,8.59;7,317.05,260.27,209.10,8.59;7,317.05,271.23,152.51,8.59">The 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering, and Cross-Lingual Information Access</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,306.14,291.33,69.88,8.64;7,391.85,291.33,82.86,8.64;7,490.53,291.33,33.88,8.64;7,317.05,302.29,209.10,8.64;7,317.05,313.25,207.36,8.64;7,316.80,324.03,207.61,8.82;7,317.05,334.99,207.36,8.59;7,317.05,345.95,207.36,8.59;7,316.49,356.90,207.92,8.82;7,317.05,368.04,37.36,8.64" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,317.05,313.25,207.36,8.64;7,316.80,324.21,44.23,8.64">Fever: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,379.13,324.03,145.28,8.59;7,317.05,334.99,129.86,8.59">Proceedings of the 2018 Conference of the North American Chapter</title>
		<title level="s" coord="7,433.38,356.90,51.57,8.59">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,306.14,387.97,218.27,8.64;7,316.58,398.93,207.83,8.64;7,317.05,409.89,207.35,8.64;7,317.05,420.67,209.01,8.82;7,317.05,431.62,207.36,8.59;7,316.74,442.58,163.09,8.82" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,427.65,409.89,96.75,8.64;7,317.05,420.84,64.64,8.64">Fact or fiction: Verifying scientific claims</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,402.64,420.67,123.43,8.59;7,317.05,431.62,207.36,8.59;7,316.74,442.58,82.88,8.59">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7534" to="7550" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
