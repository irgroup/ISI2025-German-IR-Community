<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.81,115.96,309.73,12.62;1,151.47,133.89,312.43,12.62;1,278.23,151.82,58.89,12.62">PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for Multi-stage Ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.05,189.49,55.35,8.74"><forename type="first">Yixuan</forename><surname>Qiao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.40,189.49,43.45,8.74"><forename type="first">Hao</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.41,189.49,54.66,8.74"><forename type="first">Tuozhen</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Central University of Finance and Economics</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.62,189.49,48.70,8.74"><forename type="first">Xianbin</forename><surname>Ye</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Jinan University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,394.88,189.49,44.42,8.74"><forename type="first">Jun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,449.86,189.49,21.46,8.74;1,244.18,201.45,17.78,8.74"><forename type="first">Peng</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.89,201.45,55.69,8.74"><forename type="first">Guotong</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Ping An Health Cloud Company Limited</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Ping An International Smart City Technology Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.81,115.96,309.73,12.62;1,151.47,133.89,312.43,12.62;1,278.23,151.82,58.89,12.62">PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for Multi-stage Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F5D5D02AB5895F29E7794321B96C2123</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>expansion method</term>
					<term>dense retrieval</term>
					<term>transfer learning</term>
					<term>multi-stage ranking</term>
					<term>model parallel</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the PASH participation in TREC 2021 Deep Learning Track. In the recall stage, we adopt a scheme combining sparse and dense retrieval method. In the multi-stage ranking phase, point-wise and pair-wise ranking strategies are used one after another based on model continual pre-trained on general knowledge and documentlevel data. Compared to TREC 2020 Deep Learning Track, we have additionally introduced the generative model T5 to further enhance the performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Methodology</head><p>In this section, we briefly describe the components in the multi-stage ranking pipeline. Details of some methods can be found in TREC 2020 notebook paper. The passage ranking task contains 285,328 queries on a collection of 138,364,198 passages, totally 296,419 query passage pairs annotated as positive for relevance. Few queries are matched with multiple relevant passages. The document ranking task contains 331,748 queries on a collection of 11,959,635 documents, totally 341,836 query document pairs annotated as positive for relevance. Few queries are matched with multiple relevant documents. NDCG is the main official evaluation index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Multi-way Matching</head><p>Sparse retrieval We use the docTTTTTquery <ref type="bibr" coords="1,340.81,625.15,16.14,8.74" target="#b0">[1]</ref> (also known as docT5query or doc2query-T5) to generate queries for which the passage might be relevant.</p><p>For passage, We sample 40 queries per passage with T5-base. For document, we first segment each document into passages by applying a sliding window of ten sentences with a stride of five. Each passage is then prepended with the url and title of the document. Finally, we generate ten queries per passage. Each document prepended with the url and title info was appended with all its predicted queries are indexed by BM25 <ref type="bibr" coords="2,300.32,178.77,15.71,8.74" target="#b1">[2]</ref> as before.</p><p>Dense retrieval Dense retrieval methods have shown great promise over sparse retreval methods in a range of NLP problems. We choose ColBERT <ref type="bibr" coords="2,433.07,225.00,15.90,8.74" target="#b2">[3]</ref> as our Dense Retriever due to the effectiveness/efficiency tradeoffs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Multi-stage Ranking</head><p>We inherit the model from TREC 2020 Deep Learning Track including BERT-Large <ref type="bibr" coords="2,155.77,307.49,12.60,8.74" target="#b3">[4]</ref>, ALBERT-XXLarge <ref type="bibr" coords="2,250.46,307.49,16.22,8.74" target="#b4">[5]</ref>, ELECTRA-Large <ref type="bibr" coords="2,345.26,307.49,16.38,8.74" target="#b5">[6]</ref> and XLNet-Large <ref type="bibr" coords="2,435.41,307.49,14.54,8.74" target="#b6">[7]</ref> model. In particular, BERT-Large uses the same pre-training and fine-tuning strategies as last year but using this year's data set. Compared with last year, we have made the following further improvements: amazing fact is that the zero-shot NDCG@5 of the T5-11B is already 0.3651.</p><formula xml:id="formula_0" coords="2,140.99,369.63,5.73,8.77">-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Ensemble</head><p>Benefited from multi-way matching, we just sequentially train different re-rankers with different random seeds for ensemble learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Results</head><p>We submitted six official runs in each passage and document ranking subtask. Table <ref type="table" coords="2,162.64,632.21,4.98,8.74">1</ref> and 2 present the results of our runs in passage ranking task. Table <ref type="table" coords="2,475.61,632.21,4.98,8.74">3</ref> and 4 present the results of our runs in document ranking task. We use r * to denote the runs for re-ranking, f * for full ranking.</p><p>Table <ref type="table" coords="3,218.08,146.72,4.13,7.89">1</ref>. Results on the TREC 2021 passage re-rank task.</p><p>RUN MAP@100 NDCG@5 NDCG@10 R@100 pash r1 0.2362 0.7190 0.6951 0.3261 pash r2 0.2389 0.7390 0.7076 0.3261 pash r3 0.2385 0.7390 0.7072 0.3261 Table <ref type="table" coords="3,215.40,286.35,4.13,7.89">2</ref>. Results on the TREC 2021 passage full rank task.</p><p>RUN MAP@100 NDCG@5 NDCG@10 R@100 pash f1 0.3193 0.7596 0.7494 0.4868 pash f2 0.3318 0.7596 0.7494 0.5300 pash f3 0.3378 0.7596 0.7494 0.5500 Table <ref type="table" coords="3,213.52,425.99,4.13,7.89">3</ref>. Results on the TREC 2021 document re-rank task.</p><p>RUN MAP@100 NDCG@5 NDCG@10 R@100 pash doc r1 0.2665 0.7452 0.7150 0.3195 pash doc r2 0.2640 0.7308 0.7076 0.3195 pash doc r3 0.2672 0.7383 0.7164 0.3195 Table <ref type="table" coords="3,210.85,563.88,4.13,7.89">4</ref>. Results on the TREC 2021 document full rank task.</p><p>RUN MAP@100 NDCG@5 NDCG@10 R@100 pash doc f1 0.3111 0.6745 0.5832 0.3683 pash doc f4 0.3498 0.7516 0.7404 0.4412 pash doc f5 0.3521 0.7508 0.7368 0.4419</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusion</head><p>The experiments demonstrate that the expressiveness of ColBERT is well integrated with BM25+docTTTTTquery. Compared with the transformer-based model, the generative model T5 has a higher NDCG@5 and a lower NDCG@10, which means that relevant passages are already in top5. This phenomenon largely hints at the thirst for multi-stage ranking in generative models, which can be expected to show powerful effects with the pair-wise or list-wise training. We believe that the interweaving sequence of different methods will be a focus point of future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,151.70,369.66,328.89,8.74;2,151.70,381.62,230.22,8.74;2,140.99,394.42,331.47,8.77;2,154.80,409.04,247.46,8.74;2,154.25,421.87,147.67,8.74;2,155.35,434.70,325.24,8.74;2,168.64,446.65,188.05,8.74;2,154.25,459.49,326.35,8.74"><head></head><label></label><figDesc>We use pair-wise loss as the goal of the second stage of ranking. So we can use more data instead of TREC labeled 4-class data. -Generative model T5[8] is introduced to further enhance the performance a) Implementation based on Megatron-LM[9] repository. b) Same training strategy as [10]. c) Training the T5-3B model takes approximately 12 days on 32 V100 GPUs consuming about 12.8M training examples. d) The T5-11B model takes about 30 days under the same situation. An</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,146.00,655.03,2.55,5.24;1,149.04,656.80,309.22,7.86"><p>* Corresponding Author. Email: {qiaoyixuan528, xieguotong}@pingan.com.cn.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,142.96,282.06,337.63,7.86;4,151.52,293.02,186.49,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,327.35,282.06,153.24,7.86;4,151.52,293.02,14.75,7.86">Document expansion by query prediction</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08375</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,142.96,303.98,337.63,7.86;4,151.52,314.94,188.81,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,243.02,303.98,237.57,7.86;4,151.52,314.94,37.53,7.86">Bm25 pseudo relevance feedback using anserini at waseda university</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,208.41,314.94,69.80,7.86">OSIRRC@ SIGIR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.96,325.90,337.63,7.86;4,151.52,336.86,329.07,7.86;4,151.52,347.82,329.07,7.86;4,151.52,358.78,54.26,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,311.34,325.90,169.25,7.86;4,151.52,336.86,160.53,7.86">Efficient and effective passage search via contextualized late interaction over bert</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Colbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,331.71,336.86,148.88,7.86;4,151.52,347.82,325.24,7.86">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.96,369.74,337.63,7.86;4,151.52,380.69,329.07,7.86;4,151.52,391.65,329.07,7.86;4,151.52,402.61,329.07,7.86;4,151.52,413.57,72.70,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,398.03,369.74,82.56,7.86;4,151.52,380.69,215.11,7.86">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,386.50,380.69,94.09,7.86;4,151.52,391.65,175.31,7.86">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s" coord="4,380.58,402.61,91.67,7.86">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.96,424.53,337.63,7.86;4,151.52,435.49,296.16,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,207.99,424.53,272.60,7.86;4,151.52,435.49,26.48,7.86">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,197.38,435.49,218.33,7.86">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.96,446.45,337.63,7.86;4,151.52,457.41,329.07,7.86;4,151.52,468.37,28.16,7.86" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Electra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="4,398.59,446.45,82.00,7.86;4,151.52,457.41,189.30,7.86">Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,142.96,479.33,337.64,7.86;4,151.52,490.26,290.96,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,215.00,479.33,265.59,7.86;4,151.52,490.28,32.81,7.86">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,192.52,490.28,204.31,7.86">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.96,501.24,337.64,7.86;4,151.52,512.18,278.83,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,215.34,501.24,265.26,7.86;4,151.52,512.20,45.40,7.86">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,205.13,512.20,155.54,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.96,523.16,337.63,7.86;4,151.52,534.12,329.07,7.86;4,151.52,545.08,295.40,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,243.40,523.16,237.19,7.86;4,151.52,534.12,92.36,7.86">Efficient large-scale language model training on gpu clusters using megatron-lm</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,265.86,534.12,214.73,7.86;4,151.52,545.08,238.64,7.86">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</title>
		<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,142.61,556.04,337.98,7.86;4,151.52,567.00,329.07,7.86;4,151.52,577.96,102.91,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="4,318.04,556.04,162.56,7.86;4,151.52,567.00,256.32,7.86">The expando-mono-duo design pattern for text ranking with pretrained sequence-to-sequence models</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.05667</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
