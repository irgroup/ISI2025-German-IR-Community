<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.08,94.56,451.11,22.70">Method Comparison for Crisis Pipelines</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,125.61,157.04,109.39,14.30"><forename type="first">Shivam</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">New Jersey Institute of Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,367.10,157.04,95.74,14.30"><forename type="first">Cody</forename><surname>Buntain</surname></persName>
							<email>cbuntain@njit.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">New Jersey Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.08,94.56,451.11,22.70">Method Comparison for Crisis Pipelines</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ECFD507CDDEDE72A36E01187C2DFA950</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Incident Streams</term>
					<term>TREC</term>
					<term>TRECIS</term>
					<term>crisis informatics</term>
				</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>In crisis informatics, data sparsity remains a crucial bottleneck for learning, and while numerous approaches exist to alleviate this issue, little domain-specific guidance exists for choosing or prioritizing these approaches. When developing a crisis informatics pipeline, there are majorly four areas to take into consideration, namely, augmentation, counter data imbalance, class selection for data augmentation, to consider which classes to augment, language model selection, and training methods. When considering these different sections of a crisis informatics pipeline, there is a lack of guidance regarding prioritization of these sections for optimization. For example, using an off-the-shelf, state-of-the-art pre-trained language model may give us some performance boost, but will an older model with better class-balanced dataset show better or similar performance, and if so, then should data augmentation be prioritized over model selection? Will a pipeline with multi-task learning give similar performance on a not so well-balanced dataset, and if so, should using better training methods be prioritized over selecting the best augmentation technique? These are some of the questions we aim to consider through our work. This paper provides this much needed domain-specific guidance by evaluating performance improvements across a series of data augmentations, model improvements, and learning designs.</p><p>Since its inception in 2018, the Incident Streams track at the annual Text Retrieval Conference(TREC-IS) has received various submissions for the information classification and priority scoring tasks. These submissions are generated from pipelines that utilize state-of-the-art language models for result generation, various augmentation techniques to counter imbalance in the data, and various other methods which might help elevate the efficiency of their pipelines. However, there is a need for a comparison between different methods that can be used within different sections of a pipeline. This work aims to fill this gap by comparing different methods in three major sections of a pipeline, namely, data augmentation, model selection, and model training.</p><p>In particular, this paper describes our research around TREC-IS and aims to answer the following research questions: RQ1: Across several augmentation techniques and libraries, how much performance increase is observed, on average as well as for each technique or library, when applied to crisis informatics data?</p><p>RQ2: What is the change in performance when we augment high priority classes, as opposed to all classes? RQ3: By how much might one expect performance to increase by using increasingly sophisticated off-the-shelf, pre-trained models?</p><p>RQ4: How much performance increase is observed upon using single multi-task learning pipeline, as compared to different task-specific pipelines?</p><p>RQ5: Across the various sections of a crisis informatics pipeline, namely, data augmentation, langauge model selection, and training methodology, which section should be prioritized for optimization for maximum performance boost?</p><p>To answer these question, this paper presents a systematic comparison of test results showcased by different pipelines.</p><p>We outline a basic pipeline architecture and make changes in the sections we aim to compare, leaving the rest same.</p><p>We define a single baseline model, which will aid us to compare across different research questions and also help Our results show that, amongst the three different augmentation strategies used, even though there is meaning in using augmentation, there is no clear winner. However, augmenting only high priority classes under a certain threshold does seem to provide more performance boost as compared to augmenting all classes which are bellow the aforementioned threshold. Our results also showcase that using off-the-shelf pre-trained models does improve the performance by a degree in tasks, however, there is more evidence in prioritizing optimization of learning methods over selecting the best pre-trained language model. Primary contribution of this work will be of interest to those studying crisis-informatics and methods to improve the performance of their pipelines by giving an insight into which section to prioritize for optimization. Crisis Informatics researchers in particular can benefit from the comparison of different learning methods and different language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESEARCH QUESTION</head><p>In this section, we dive deeper into the various research questions and outline the methods used to answer these questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Augmentation Comparison</head><p>Like many other real-world data, the crisis tweets collected by TREC-IS are imbalanced in the distribution across different information as well as priority labels. This is expected as there is would be a higher number of people posting a tweet showing support or giving condolences to the victims of some crisis events as opposed to the number of people requesting aid for the same crisis. To counter this imbalance various augmentation strategies can be applied to the dataset.</p><p>In this experiment, we aim to answer the following research question:</p><p>RQ: Across several augmentation techniques and libraries, how much performance increase is observed, on average as well as for each technique or library, when applied to crisis informatics data?</p><p>We answer the above mentioned research question by observing the performance improvement across the following augmentation strategies for the textual data present in the tweets:</p><p>1. Synonym-Augmentation: In this method, we list all the verbs in the given tweet text and replace them with their synonyms, thus "generating" new tweet text. If a text has more than one verb in it, then we replace one verb with its respective synonyms at a time, keeping the rest of the verbs the same. For all of these three augmentation strategies, we define a multiplication factor, which is the number of times a tweet text gets augmented. We also augment only the "actionable" classes, which means, we augment classes which has high average priority. We use DeBERTa as the core language model for all three use cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Easy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Selection for Augmentation</head><p>An important factor in evaluation for TREC-IS is evaluation scores for "actionable" information classes. These are the top six information classes that have the highest average priority score. This raises an important question of whether we would want to augment all the classes or only those classes which are "actionable", as these are the high priority classes that are more important for emergency responders.</p><p>In this experiment, we aim to answer the following research question:</p><p>RQ: What is the change in performance when we augment high priority classes, as opposed to all classes?</p><p>To answer the above research question, we compare the performance increase between two pipelines, one with augmentation on only actionable classes, and the other with augmentation for all classes. Since augmenting all the classes will keep the overall ratio of information classes the same, thus overlooking the main motive for using augmentation, we use the minimum count method used by <ref type="bibr" coords="3,305.31,243.34,64.91,8.81">Wang et al. 2021</ref>. In this method, Wang augments only those classes which are below a certain threshold and calculates a multiplication factor based on the difference between the threshold and the count of tweets in that class. This multiplication factor is the number of tweet text we "generate" from a single tweet. Thus, in this experiment, we compare two pipelines, one with augmentations on all the classes with class count lower than 500 and one with augmentations on "actionable" class with class count lower than 500. For this experiment, we use EDA as the base augmentation strategy and DeBERTa as the base model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Selection</head><p>Model selection is another important aspect to consider when formulating a pipeline. There are various pre-trained language models available which are trained on a high amount of data, like BERT, RoBERTa, XLM, DeBERTa, etc. The state-of-the-art limits are frequently pushed with better models, which are either trained on a greater amount of data or use a denser or more refined base architecture. This raises the question of whether constantly updating our crisis informatics pipelines with these new, off-the-shelf pre-trained language model guarantee performance improvement.</p><p>Through this experiment, we aim to answer the following research question:</p><p>RQ: By how much might one expect performance to increase by using increasingly sophisticated off-the-shelf, pre-trained models?</p><p>We answer the above mentoined question by comparing three different language models, namely, BERT, RoBERTa, and DeBERTa, to check whether using state-of-the-art models like DeBERTa showcases improved results as compared to the base models like BERT and RoBERTa. In this experiment, we change the pre-trained language model in our base pipeline. We use AugLy with multiplication factor for actionable classes only to get the augmentations in the textual data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Task Learning</head><p>Wang et al. 2021 in their work use multi-task learning, using a combined loss from priority scoring task model and information classification model. This was in turn motivated by Zhang and Yang 2017, whose work shows evidence that parameter sharing between multiple tasks is likely to enable one task to share its learned knowledge with another. Wang, in their work, defines a parameter lambda, ùúÜ, as a loss parameter which they use as a weight for adjusting the loss of priority scoring task and information labels classification to calculate the final loss. The following equation describes the calculation for the final loss function, where L it is the loss for information type classification task and L pri is the loss for priority scoring task.</p><formula xml:id="formula_0" coords="3,242.18,696.98,110.59,8.81">ùêø ùë°ùëúùë° ùëéùëô = ùúÜùêø ùëñùë° + (1 -ùúÜ)ùêø ùëùùëü ùëñ</formula><p>Through this experiment we aim to answer the following research question:</p><p>RQ: How much performance increase is observed upon using single multi-task learning pipeline, as compared to different task-specific pipelines?  To answer this, we compare two different pipelines, one with multi-task learning, and one with two task-specific models, one for each, information type classification task and priority scoring task. We can get a model for priority scoring task only and information classification task only, if we set ùúÜ as 0 and 1, respectively. We use the ùúÜ parameter to train two different models, one for each task, and combine their results to form the final result. We compare this result with the multi-task learning using the equation described above with ùúÜ as 0.5. We use AugLy with multiplication factor for actionable classes only to get the augmentations in the textual data and use DeBERTa as the base neural language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODOLOGY</head><p>This sections defines the method we used to evaluate the four research questions discussed above. We outline the basic architecture of the pipeline, modifying different sections of which would generate the pipelines which we use to answer the research questions. We also discuss in brief the dataset used for training and testing, and also the evaluations metrics used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Description</head><p>Since its inception in 2018, TREC-IS has accumulated a total labeled corpus of more than 60k labeled crisis tweets made during 75 different crisis events. These labeled tweets can be distributed into 5 different subsets, based on their editions, namely, 2018, 2019-A, 2019-B, 2020-A, and 2020-B. For our experiments in this work, we use the whole dataset for training and use the first labeled dataset released for the 2021 edition as the testing dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>TREC-IS releases an evaluation notebook for every edition. These notebooks include, an nDCG metric for ranking content by priority, F1 score divided into two sets, one restricted to "actionable" information types, and the other containing all possible labels, and R score for priority score comparison which, similar to the F1 score, is also divided into two sets, one for "actionable" information type and one for all possible labels. This "actionable" set is restricted to the top six information types with the highest average priority score, making them the most "important" types to classify correctly in a qualitative sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Description</head><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>This section presents the results for the various experiments outlined above. We compare the various pipelines based on the evaluation scores as well as across individual information type scores. We also the compare the net percent improvement from our baseline. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Augmentation Comparison</head><p>Table <ref type="table" coords="5,95.13,471.51,4.88,8.81" target="#tab_4">1</ref> shows the results from the various augmentation methods. As evident, there is clearly no "best" augmentation strategy. AugLy outperforms the rest of the strategies in all of the priority scores, except for priority F1 for all, where it is still competitive to the best and the difference can be attributed to the randomness. EDA, on the other hand, outperforms the other strategies in information type classification scores, except for the information type accuracy, which is competitive to Synonym-Augmentation and the difference is low enough that it can be attributed to randomness.</p><p>Table <ref type="table" coords="5,95.71,549.07,4.89,8.81" target="#tab_5">2</ref> shows the results for individual information label for the three augmentation pipelines and also the baseline.</p><p>For the F1 score for actionable classes, EDA pipeline outperforms the other pipelines in majority classes and apart from the poor performance in "NewSubEvent", it is competitive to the best score in "SearchAndRescue" label. However, for non-actionable classes, pipeline with synonym-augmentation shows better results than pipeline using EDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Selection for Augmentation</head><p>This section discusses the results for the comparison between augmentation on actionable classes only and on all classes. The "Actionable" pipeline is the pipeline with augmentations done on classes which are actionable as well as bellow a threshold of 500 tweet text, per information class. The "All" pipeline is the pipeline with augmentations done on all the classes which are bellow the threshold of 500 tweets text, per class, irrespective of whether or not those classes are actionable or not.</p><p>As evident from the table 3, the "Actionable" pipeline outperforms in all of the major evaluation scores, and is competitive in the rest. The two pipelines are outperformed by the Baseline in the nDCG score, but the difference is close enough that this may be attributed to the randomness of the model. The "All" pipeline outperforms the rest in information type accuracy score and the Priority F1 for all classes, but the difference between the "Actionable" and "All" pipelines for these score is near enough that this may also be attributed to randomness of the model.</p><p>Table <ref type="table" coords="6,96.45,563.62,5.06,8.81" target="#tab_7">4</ref> showcases evaluation scores for individual information type labels. As evident from the table, for the F1 score for actionable classes, the "Actionable" pipeline outperforms the "All" pipeline in majority of the classes, with an exception for "EmergingThreats" and "ServiceAvailable". We can observe similar results for the F1 score of non-actionable classes as well, with the "Actionable" pipeline outperforming the "All" pipeline in more than 50% of the information classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Selection</head><p>Table <ref type="table" coords="6,97.56,660.59,5.08,8.81" target="#tab_8">5</ref> compares the evaluation results for the three pre-trained model runs, namely, BERT, RoBERTa, and DeBERTa. As evident from the table, RoBERTa outperforms the rest in the information type classification task but shows competitive results in the priority scoring task, with the best scores for Priority R for actionable classes.</p><p>Similarly, DeBERTa outperformed the rest in the priority scoring task, except for Priority R for actionable classes.</p><p>It is important to note that the Baseline pipeline is performing better than the BERT pipeline, and shows competitive results against the DeBERTa model, in all three evaluation scores information label classification task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Task Learning</head><p>This section shows the results obtained for the experiment between a single multi-task pipeline, and two separate task-specific pipelines, one for each information label classification task and as well as one for priority scoring task.</p><p>In the tables 7 and 8, we discuss these two pipelines, with "Separate Task" representing the pipeline using two separate task-specific models, and "Multi-Task" representing the multi-task learning pipeline.</p><p>As evident from table 7, the multi-task learning outperforms the separate task pipelines in almost all of the evaluation scores, with an exception for actionable information type F1 score and the information type accuracy. As compared to the Baseline, the "Multi-Task" pipeline has a noticeable improvement in most of the scores, with an exception for information type accuracy. For the evaluation scores regarding information label classification task, we observe that the results by "Separate Task" pipeline is competitive to the results showcased by the "Multi-Task" pipeline, however, multi-task learning outperforms the separate task pipeline by a wide margin.</p><p>Table <ref type="table" coords="7,96.11,626.28,4.98,8.81" target="#tab_12">8</ref> shows the evaluation results for individual information labels for the two mentioned pipelines. As evident from the table, the "Multi-Task" pipeline does not show a significant performance boost as compared to the "Separate Task" pipeline. The "Multi-Task" pipeline performs poorly for the actionable information classes, and showcases the best results in less than half of the non-actionable information classes. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,228.01,154.86,139.26,8.02;4,72.00,72.00,467.25,71.40"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Base Pipeline Architecture</figDesc><graphic coords="4,72.00,72.00,467.25,71.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,87.94,602.95,435.33,8.81;4,72.00,614.90,452.52,8.81;4,72.00,626.86,451.27,8.81;4,72.00,638.81,451.28,8.81;4,72.00,650.77,452.52,8.81;4,71.64,662.72,452.88,8.81;4,72.00,674.68,452.52,8.81;4,72.00,686.63,255.04,8.81"><head></head><label></label><figDesc>keep a consistent model architecture across all the experiments described in this work. This works aim to compare the results between three different sections of a neural pipeline, namely, augmentation, pre-trained model, and training method. We change the specific sections of the basic neural pipeline architecture and keep everything else the same for a clear and consistent comparison. Our model architecture is heavily inspired by the model architecture used by the model described by Wang et al. 2021. Figure 1 describes our basic pipeline architecture, which can be split into five major sections, namely, textual data extraction, data augmentation, model selection, model training, and prediction. Of these five, in this work, we change the data augmentation, the model selection, and the model training sections for their respective experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,184.68,785.65,226.36,29.84"><head></head><label></label><figDesc>of pipeline which gives us the most improvements. This work spans TREC-IS 2021-A and 2021-B, with the results being compared on the 2021-A test dataset.</figDesc><table /><note coords="1,268.88,785.65,57.66,7.93;1,184.68,796.70,226.36,7.73;1,203.99,807.57,187.29,7.93;2,72.00,75.33,78.29,8.81"><p>Notebook Paper Incident Streams Track at Text Retrieval Conference (TREC-IS) Richard McCreadie, Cody Buntain and Ian Soboroff identify the section</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,84.45,605.59,440.06,105.96"><head>Data Augmentation: Easy</head><label></label><figDesc></figDesc><table coords="2,84.45,605.82,440.06,105.74"><row><cell>Data Augmentation, or EDA, is the work presented by Wei and Zou</cell></row><row><cell>[cite paper]. This method includes four different text processing methods, namely, synonym-replacement,</cell></row><row><cell>random insertion, random swap, and random deletion. This method is a more advanced version of our</cell></row><row><cell>synonym-augmentation method, with synonym-replacement in any random word instead of just the verb.</cell></row><row><cell>3. AugLy: AugLy is a data augmentation library recently developed by Facebook Research. It contains over</cell></row><row><cell>100 different augmentation methods across multi-modalities like image, text, video, and audio. For textual</cell></row><row><cell>data augmentation, AugLy introduces 11 different augmentation functions, of which we have used three for</cell></row><row><cell>this experiment, namely, word splitting, similar character replacement, and "typos" simulation.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,184.68,785.65,226.36,29.84"><head>Table 1 . Evaluation results on test dataset by pipelines with different augmentation techniques.</head><label>1</label><figDesc></figDesc><table coords="5,78.38,97.77,447.72,55.75"><row><cell>Augmentation Statergies</cell><cell>nDCG@100</cell><cell cols="2">Info Type F1</cell><cell>Info Accuracy</cell><cell cols="2">Priority F1</cell><cell cols="2">Priority R</cell></row><row><cell></cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell>Actionable</cell><cell>All</cell></row><row><cell>Baseline</cell><cell>0.492</cell><cell>0.2062</cell><cell>0.2837</cell><cell>0.8896</cell><cell>0.215</cell><cell>0.1737</cell><cell>0.0643</cell><cell>0.155</cell></row><row><cell>Augly</cell><cell>0.5112</cell><cell>0.2132</cell><cell>0.2927</cell><cell>0.8883</cell><cell>0.257</cell><cell>0.2012</cell><cell>0.1661</cell><cell>0.2126</cell></row><row><cell>EDA</cell><cell>0.4538</cell><cell>0.3008</cell><cell>0.3239</cell><cell>0.8817</cell><cell>0.2434</cell><cell>0.1855</cell><cell>0.1046</cell><cell>0.1881</cell></row><row><cell>Synonym Augmentation</cell><cell>0.4831</cell><cell>0.285</cell><cell>0.3189</cell><cell>0.891</cell><cell>0.2507</cell><cell>0.2045</cell><cell>0.1342</cell><cell>0.1924</cell></row></table><note coords="4,268.88,785.65,57.66,7.93;4,184.68,796.70,226.36,7.73;4,203.99,807.57,187.29,7.93"><p>Notebook Paper Incident Streams Track at Text Retrieval Conference (TREC-IS) Richard McCreadie, Cody Buntain and Ian Soboroff</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,78.38,170.53,491.45,255.39"><head>Table 2 . Per-information label score distribution for various augmentation pipelines</head><label>2</label><figDesc></figDesc><table coords="5,78.38,194.44,491.45,231.48"><row><cell>Information Classes</cell><cell></cell><cell cols="2">Precision</cell><cell></cell><cell></cell><cell cols="2">Recall</cell><cell></cell><cell></cell><cell cols="2">F1 Score</cell><cell></cell></row><row><cell></cell><cell>Baseline</cell><cell>EDA</cell><cell>AugLy</cell><cell>Syn-Aug</cell><cell>Baseline</cell><cell>EDA</cell><cell>AugLy</cell><cell>Syn-Aug</cell><cell>Baseline</cell><cell>EDA</cell><cell>AugLy</cell><cell>Syn-Aug</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EmergingThreats</cell><cell>0.14</cell><cell>0.14</cell><cell>0.15</cell><cell>0.16</cell><cell>0.3</cell><cell>0.36</cell><cell>0.24</cell><cell>0.26</cell><cell>0.19</cell><cell>0.2</cell><cell>0.18</cell><cell>0.2</cell></row><row><cell>GoodsServices</cell><cell>0</cell><cell>0.61</cell><cell>0.61</cell><cell>0.65</cell><cell>0</cell><cell>0.38</cell><cell>0.13</cell><cell>0.26</cell><cell>0</cell><cell>0.46</cell><cell>0.22</cell><cell>0.37</cell></row><row><cell>MovePeople</cell><cell>0.63</cell><cell>0.5</cell><cell>0.51</cell><cell>0.56</cell><cell>0.32</cell><cell>0.53</cell><cell>0.27</cell><cell>0.4</cell><cell>0.43</cell><cell>0.52</cell><cell>0.35</cell><cell>0.47</cell></row><row><cell>NewSubEvent</cell><cell>0.12</cell><cell>0.02</cell><cell>0.15</cell><cell>0.09</cell><cell>0.14</cell><cell>0.04</cell><cell>0.1</cell><cell>0.06</cell><cell>0.13</cell><cell>0.02</cell><cell>0.12</cell><cell>0.07</cell></row><row><cell>SearchAndRescue</cell><cell>0.22</cell><cell>0.13</cell><cell>0.04</cell><cell>0.19</cell><cell>0.06</cell><cell>0.21</cell><cell>0.03</cell><cell>0.24</cell><cell>0.09</cell><cell>0.16</cell><cell>0.03</cell><cell>0.21</cell></row><row><cell>ServiceAvailable</cell><cell>0.46</cell><cell>0.43</cell><cell>0.44</cell><cell>0.51</cell><cell>0.34</cell><cell>0.45</cell><cell>0.32</cell><cell>0.32</cell><cell>0.39</cell><cell>0.44</cell><cell>0.37</cell><cell>0.39</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Non-Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Advice</cell><cell>0.51</cell><cell>0.39</cell><cell>0.44</cell><cell>0.46</cell><cell>0.24</cell><cell>0.29</cell><cell>0.23</cell><cell>0.37</cell><cell>0.33</cell><cell>0.33</cell><cell>0.31</cell><cell>0.41</cell></row><row><cell>CleanUp</cell><cell>0.19</cell><cell>0.25</cell><cell>0.23</cell><cell>0.27</cell><cell>0.5</cell><cell>0.58</cell><cell>0.54</cell><cell>0.54</cell><cell>0.28</cell><cell>0.35</cell><cell>0.33</cell><cell>0.36</cell></row><row><cell>ContextualInformation</cell><cell>0.12</cell><cell>0.09</cell><cell>0.11</cell><cell>0.11</cell><cell>0.11</cell><cell>0.04</cell><cell>0.07</cell><cell>0.07</cell><cell>0.11</cell><cell>0.06</cell><cell>0.09</cell><cell>0.09</cell></row><row><cell>Discussion</cell><cell>0.03</cell><cell>0.03</cell><cell>0.02</cell><cell>0.02</cell><cell>0.1</cell><cell>0.17</cell><cell>0.15</cell><cell>0.15</cell><cell>0.05</cell><cell>0.05</cell><cell>0.04</cell><cell>0.04</cell></row><row><cell>Donations</cell><cell>0.32</cell><cell>0.44</cell><cell>0.3</cell><cell>0.4</cell><cell>0.56</cell><cell>0.65</cell><cell>0.57</cell><cell>0.68</cell><cell>0.41</cell><cell>0.53</cell><cell>0.4</cell><cell>0.5</cell></row><row><cell>Factoid</cell><cell>0.54</cell><cell>0.45</cell><cell>0.48</cell><cell>0.5</cell><cell>0.49</cell><cell>0.56</cell><cell>0.49</cell><cell>0.5</cell><cell>0.52</cell><cell>0.5</cell><cell>0.49</cell><cell>0.5</cell></row><row><cell>FirstPartyObservation</cell><cell>0.14</cell><cell>0.13</cell><cell>0.17</cell><cell>0.16</cell><cell>0.18</cell><cell>0.17</cell><cell>0.27</cell><cell>0.32</cell><cell>0.16</cell><cell>0.14</cell><cell>0.21</cell><cell>0.21</cell></row><row><cell>Hashtags</cell><cell>0.47</cell><cell>0.38</cell><cell>0.41</cell><cell>0.39</cell><cell>0.49</cell><cell>0.55</cell><cell>0.56</cell><cell>0.46</cell><cell>0.48</cell><cell>0.45</cell><cell>0.47</cell><cell>0.42</cell></row><row><cell>InformationWanted</cell><cell>0.4</cell><cell>0.49</cell><cell>0.45</cell><cell>0.5</cell><cell>0.18</cell><cell>0.49</cell><cell>0.39</cell><cell>0.51</cell><cell>0.25</cell><cell>0.49</cell><cell>0.42</cell><cell>0.5</cell></row><row><cell>Irrelevant</cell><cell>0.62</cell><cell>0.71</cell><cell>0.68</cell><cell>0.73</cell><cell>0.47</cell><cell>0.42</cell><cell>0.47</cell><cell>0.48</cell><cell>0.53</cell><cell>0.43</cell><cell>0.55</cell><cell>0.58</cell></row><row><cell>Location</cell><cell>0.6</cell><cell>0.56</cell><cell>0.59</cell><cell>0.59</cell><cell>0.66</cell><cell>0.7</cell><cell>0.61</cell><cell>0.63</cell><cell>0.63</cell><cell>0.62</cell><cell>0.6</cell><cell>0.61</cell></row><row><cell>MultimediaShare</cell><cell>0.28</cell><cell>0.3</cell><cell>0.31</cell><cell>0.31</cell><cell>0.4</cell><cell>0.46</cell><cell>0.51</cell><cell>0.44</cell><cell>0.33</cell><cell>0.36</cell><cell>0.38</cell><cell>0.36</cell></row><row><cell>News</cell><cell>0.27</cell><cell>0.26</cell><cell>0.26</cell><cell>0.25</cell><cell>0.33</cell><cell>0.36</cell><cell>0.24</cell><cell>0.16</cell><cell>0.3</cell><cell>0.3</cell><cell>0.25</cell><cell>0.2</cell></row><row><cell>Official</cell><cell>0.11</cell><cell>0.13</cell><cell>0.16</cell><cell>0.11</cell><cell>0.11</cell><cell>0.12</cell><cell>0.04</cell><cell>0.03</cell><cell>0.11</cell><cell>0.12</cell><cell>0.07</cell><cell>0.05</cell></row><row><cell>OriginalEvent</cell><cell>0.03</cell><cell>0.04</cell><cell>0.06</cell><cell>0.04</cell><cell>0</cell><cell>0.01</cell><cell>0.01</cell><cell>0</cell><cell>0.01</cell><cell>0.01</cell><cell>0.02</cell><cell>0.01</cell></row><row><cell>Sentiment</cell><cell>0.33</cell><cell>0.33</cell><cell>0.33</cell><cell>0.35</cell><cell>0.36</cell><cell>0.35</cell><cell>0.41</cell><cell>0.45</cell><cell>0.35</cell><cell>0.34</cell><cell>0.37</cell><cell>0.39</cell></row><row><cell>ThirdPartyObservation</cell><cell>0.49</cell><cell>0.45</cell><cell>0.5</cell><cell>0.48</cell><cell>0.26</cell><cell>0.26</cell><cell>0.29</cell><cell>0.27</cell><cell>0.34</cell><cell>0.33</cell><cell>0.37</cell><cell>0.35</cell></row><row><cell>Volunteer</cell><cell>0.25</cell><cell>0.2</cell><cell>0.17</cell><cell>0.16</cell><cell>0.06</cell><cell>0.35</cell><cell>0.23</cell><cell>0.25</cell><cell>0.1</cell><cell>0.25</cell><cell>0.2</cell><cell>0.19</cell></row><row><cell>Weather</cell><cell>0.7</cell><cell>0.65</cell><cell>0.66</cell><cell>0.68</cell><cell>0.49</cell><cell>0.46</cell><cell>0.4</cell><cell>0.39</cell><cell>0.58</cell><cell>0.54</cell><cell>0.49</cell><cell>0.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,78.38,684.68,447.72,130.82"><head>Table 3 . Test Result comparison between pipeline augmenting only "Actionable" information classes and pipeline augmenting "All" information classes.</head><label>3</label><figDesc></figDesc><table coords="5,78.38,719.92,447.72,46.28"><row><cell>Augmentation Statergies</cell><cell>nDCG@100</cell><cell cols="2">Info Type F1</cell><cell>Info Accuracy</cell><cell cols="2">Priority F1</cell><cell cols="2">Priority R</cell></row><row><cell></cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell>Actionable</cell><cell>All</cell></row><row><cell>Baseline</cell><cell>0.492</cell><cell>0.2062</cell><cell>0.2837</cell><cell>0.8896</cell><cell>0.215</cell><cell>0.1737</cell><cell>0.0643</cell><cell>0.155</cell></row><row><cell>Actionable</cell><cell>0.4837</cell><cell>0.2988</cell><cell>0.3305</cell><cell>0.889</cell><cell>0.2437</cell><cell>0.191</cell><cell>0.1396</cell><cell>0.2087</cell></row><row><cell>All</cell><cell>0.4915</cell><cell>0.2754</cell><cell>0.3147</cell><cell>0.8897</cell><cell>0.2352</cell><cell>0.1922</cell><cell>0.1242</cell><cell>0.2087</cell></row></table><note coords="5,268.88,785.65,57.66,7.93;5,184.68,796.70,226.36,7.73;5,203.99,807.57,187.29,7.93"><p>Notebook Paper Incident Streams Track at Text Retrieval Conference (TREC-IS) Richard McCreadie, Cody Buntain and Ian Soboroff</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,94.17,73.49,406.94,255.39"><head>Table 4 . Per-information label score distribution for class selection pipelines.</head><label>4</label><figDesc></figDesc><table coords="6,94.17,97.41,406.94,231.48"><row><cell>Information Classes</cell><cell></cell><cell>Precision</cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell><cell></cell><cell>F1-Score</cell><cell></cell></row><row><cell></cell><cell>Baseline</cell><cell>Actionable</cell><cell>All</cell><cell>Baseline</cell><cell>Actionable</cell><cell>All</cell><cell>Baseline</cell><cell>Actionable</cell><cell>All</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EmergingThreats</cell><cell>0.14</cell><cell>0.14</cell><cell>0.16</cell><cell>0.3</cell><cell>0.24</cell><cell>0.26</cell><cell>0.19</cell><cell>0.18</cell><cell>0.2</cell></row><row><cell>GoodsServices</cell><cell>0</cell><cell>0.42</cell><cell>0.58</cell><cell>0</cell><cell>0.35</cell><cell>0.19</cell><cell>0</cell><cell>0.38</cell><cell>0.28</cell></row><row><cell>MovePeople</cell><cell>0.63</cell><cell>0.57</cell><cell>0.56</cell><cell>0.32</cell><cell>0.42</cell><cell>0.37</cell><cell>0.43</cell><cell>0.48</cell><cell>0.45</cell></row><row><cell>NewSubEvent</cell><cell>0.12</cell><cell>0.14</cell><cell>0.11</cell><cell>0.14</cell><cell>0.15</cell><cell>0.12</cell><cell>0.13</cell><cell>0.14</cell><cell>0.12</cell></row><row><cell>SearchAndRescue</cell><cell>0.22</cell><cell>0.15</cell><cell>0.11</cell><cell>0.06</cell><cell>0.41</cell><cell>0.21</cell><cell>0.09</cell><cell>0.22</cell><cell>0.14</cell></row><row><cell>ServiceAvailable</cell><cell>0.46</cell><cell>0.5</cell><cell>0.55</cell><cell>0.34</cell><cell>0.32</cell><cell>0.4</cell><cell>0.39</cell><cell>0.39</cell><cell>0.46</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Non-Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Advice</cell><cell>0.51</cell><cell>0.45</cell><cell>0.49</cell><cell>0.24</cell><cell>0.31</cell><cell>0.35</cell><cell>0.33</cell><cell>0.37</cell><cell>0.4</cell></row><row><cell>CleanUp</cell><cell>0.19</cell><cell>0.21</cell><cell>0.1</cell><cell>0.5</cell><cell>0.54</cell><cell>0.58</cell><cell>0.28</cell><cell>0.31</cell><cell>0.17</cell></row><row><cell>ContextualInformation</cell><cell>0.12</cell><cell>0.07</cell><cell>0.1</cell><cell>0.11</cell><cell>0.05</cell><cell>0.05</cell><cell>0.11</cell><cell>0.06</cell><cell>0.07</cell></row><row><cell>Discussion</cell><cell>0.03</cell><cell>0.03</cell><cell>0.03</cell><cell>0.1</cell><cell>0.2</cell><cell>0.15</cell><cell>0.05</cell><cell>0.05</cell><cell>0.05</cell></row><row><cell>Donations</cell><cell>0.32</cell><cell>0.31</cell><cell>0.35</cell><cell>0.56</cell><cell>0.62</cell><cell>0.59</cell><cell>0.41</cell><cell>0.42</cell><cell>0.44</cell></row><row><cell>Factoid</cell><cell>0.54</cell><cell>0.51</cell><cell>0.5</cell><cell>0.49</cell><cell>0.54</cell><cell>0.55</cell><cell>0.52</cell><cell>0.53</cell><cell>0.52</cell></row><row><cell>FirstPartyObservation</cell><cell>0.14</cell><cell>0.16</cell><cell>0.14</cell><cell>0.18</cell><cell>0.26</cell><cell>0.22</cell><cell>0.16</cell><cell>0.2</cell><cell>0.17</cell></row><row><cell>Hashtags</cell><cell>0.47</cell><cell>0.41</cell><cell>0.43</cell><cell>0.49</cell><cell>0.63</cell><cell>0.6</cell><cell>0.48</cell><cell>0.5</cell><cell>0.5</cell></row><row><cell>InformationWanted</cell><cell>0.4</cell><cell>0.47</cell><cell>0.46</cell><cell>0.18</cell><cell>0.52</cell><cell>0.66</cell><cell>0.25</cell><cell>0.49</cell><cell>0.54</cell></row><row><cell>Irrelevant</cell><cell>0.62</cell><cell>0.75</cell><cell>0.76</cell><cell>0.47</cell><cell>0.43</cell><cell>0.41</cell><cell>0.53</cell><cell>0.54</cell><cell>0.53</cell></row><row><cell>Location</cell><cell>0.6</cell><cell>0.58</cell><cell>0.58</cell><cell>0.66</cell><cell>0.66</cell><cell>0.59</cell><cell>0.63</cell><cell>0.62</cell><cell>0.58</cell></row><row><cell>MultimediaShare</cell><cell>0.28</cell><cell>0.32</cell><cell>0.29</cell><cell>0.4</cell><cell>0.54</cell><cell>0.43</cell><cell>0.33</cell><cell>0.4</cell><cell>0.35</cell></row><row><cell>News</cell><cell>0.27</cell><cell>0.28</cell><cell>0.28</cell><cell>0.33</cell><cell>0.24</cell><cell>0.27</cell><cell>0.3</cell><cell>0.26</cell><cell>0.28</cell></row><row><cell>Official</cell><cell>0.11</cell><cell>0.15</cell><cell>0.12</cell><cell>0.11</cell><cell>0.05</cell><cell>0.06</cell><cell>0.11</cell><cell>0.08</cell><cell>0.08</cell></row><row><cell>OriginalEvent</cell><cell>0.03</cell><cell>0.07</cell><cell>0.06</cell><cell>0</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell><cell>0.02</cell><cell>0.01</cell></row><row><cell>Sentiment</cell><cell>0.33</cell><cell>0.36</cell><cell>0.35</cell><cell>0.36</cell><cell>0.45</cell><cell>0.42</cell><cell>0.35</cell><cell>0.4</cell><cell>0.39</cell></row><row><cell>ThirdPartyObservation</cell><cell>0.49</cell><cell>0.47</cell><cell>0.49</cell><cell>0.26</cell><cell>0.36</cell><cell>0.34</cell><cell>0.34</cell><cell>0.41</cell><cell>0.4</cell></row><row><cell>Volunteer</cell><cell>0.25</cell><cell>0.25</cell><cell>0.17</cell><cell>0.06</cell><cell>0.33</cell><cell>0.4</cell><cell>0.1</cell><cell>0.29</cell><cell>0.24</cell></row><row><cell>Weather</cell><cell>0.7</cell><cell>0.66</cell><cell>0.66</cell><cell>0.49</cell><cell>0.46</cell><cell>0.39</cell><cell>0.58</cell><cell>0.54</cell><cell>0.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="6,78.38,346.38,447.72,80.02"><head>Table 5 . Test results comparision between pipelines using different language models.</head><label>5</label><figDesc></figDesc><table coords="6,78.38,370.65,447.72,55.75"><row><cell>Augmentation Statergies</cell><cell>nDCG@100</cell><cell cols="2">Info Type F1</cell><cell>Info Accuracy</cell><cell cols="2">Priority F1</cell><cell cols="2">Priority R</cell></row><row><cell></cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell>Actionable</cell><cell>All</cell></row><row><cell>Baseline</cell><cell>0.492</cell><cell>0.2062</cell><cell>0.2837</cell><cell>0.8896</cell><cell>0.215</cell><cell>0.1737</cell><cell>0.0643</cell><cell>0.155</cell></row><row><cell>BERT</cell><cell>0.4585</cell><cell>0.1617</cell><cell>0.2382</cell><cell>0.8872</cell><cell>0.2393</cell><cell>0.2004</cell><cell>0.1098</cell><cell>0.1522</cell></row><row><cell>RoBERTa</cell><cell>0.4987</cell><cell>0.2749</cell><cell>0.3153</cell><cell>0.8926</cell><cell>0.2238</cell><cell>0.1835</cell><cell>0.1966</cell><cell>0.2074</cell></row><row><cell>DeBERTa</cell><cell>0.5112</cell><cell>0.2132</cell><cell>0.2927</cell><cell>0.8883</cell><cell>0.257</cell><cell>0.2012</cell><cell>0.1661</cell><cell>0.2126</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="6,71.69,739.34,451.59,76.15"><head>Table 6</head><label>6</label><figDesc>compares the scores from individual information type labels. For F1 scores for Actionable classes, RoBERTa outperforms the rest of the pipelines in three of the six information classes. For the F1 score for non-actionable classes as well, RoBERTa outperforms the rest of the pipelines in more than 50% of the information labels. Through</figDesc><table coords="6,184.68,785.65,226.36,29.84"><row><cell>Notebook Paper</cell></row><row><cell>Incident Streams Track at Text Retrieval Conference (TREC-IS)</cell></row><row><cell>Richard McCreadie, Cody Buntain and Ian Soboroff</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="7,75.98,73.49,443.31,238.69"><head>Table 6 . Per-information label score distribution for model selection pipelines.</head><label>6</label><figDesc></figDesc><table coords="7,75.98,96.18,443.31,216.00"><row><cell>Information Classes</cell><cell></cell><cell>Precision</cell><cell></cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell><cell></cell><cell></cell><cell>F1 Score</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Baseline BERT RoBERTa DeBERTa</cell><cell cols="4">Baseline BERT RoBERTa DeBERTa</cell><cell cols="4">Baseline BERT RoBERTa DeBERTa</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EmergingThreats</cell><cell>0.14</cell><cell>0.11</cell><cell>0.13</cell><cell>0.15</cell><cell>0.3</cell><cell>0.17</cell><cell>0.26</cell><cell>0.24</cell><cell>0.19</cell><cell>0.13</cell><cell>0.17</cell><cell>0.18</cell></row><row><cell>GoodsServices</cell><cell>0</cell><cell>0.56</cell><cell>0.66</cell><cell>0.61</cell><cell>0</cell><cell>0.05</cell><cell>0.3</cell><cell>0.13</cell><cell>0</cell><cell>0.1</cell><cell>0.41</cell><cell>0.22</cell></row><row><cell>MovePeople</cell><cell>0.63</cell><cell>0.42</cell><cell>0.54</cell><cell>0.51</cell><cell>0.32</cell><cell>0.14</cell><cell>0.42</cell><cell>0.27</cell><cell>0.43</cell><cell>0.21</cell><cell>0.47</cell><cell>0.35</cell></row><row><cell>NewSubEvent</cell><cell>0.12</cell><cell>0.09</cell><cell>0.07</cell><cell>0.15</cell><cell>0.14</cell><cell>0.06</cell><cell>0.05</cell><cell>0.1</cell><cell>0.13</cell><cell>0.08</cell><cell>0.06</cell><cell>0.12</cell></row><row><cell>SearchAndRescue</cell><cell>0.22</cell><cell>0.18</cell><cell>0.09</cell><cell>0.04</cell><cell>0.06</cell><cell>0.09</cell><cell>0.09</cell><cell>0.03</cell><cell>0.09</cell><cell>0.12</cell><cell>0.09</cell><cell>0.03</cell></row><row><cell>ServiceAvailable</cell><cell>0.46</cell><cell>0.48</cell><cell>0.54</cell><cell>0.44</cell><cell>0.34</cell><cell>0.26</cell><cell>0.38</cell><cell>0.32</cell><cell>0.39</cell><cell>0.34</cell><cell>0.45</cell><cell>0.37</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Non-Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Advice</cell><cell>0.51</cell><cell>0.47</cell><cell>0.51</cell><cell>0.44</cell><cell>0.24</cell><cell>0.23</cell><cell>0.3</cell><cell>0.23</cell><cell>0.33</cell><cell>0.31</cell><cell>0.38</cell><cell>0.31</cell></row><row><cell>CleanUp</cell><cell>0.19</cell><cell>0.23</cell><cell>0.25</cell><cell>0.23</cell><cell>0.5</cell><cell>0.42</cell><cell>0.5</cell><cell>0.54</cell><cell>0.28</cell><cell>0.3</cell><cell>0.33</cell><cell>0.33</cell></row><row><cell>ContextualInformation</cell><cell>0.12</cell><cell>0.18</cell><cell>0.14</cell><cell>0.11</cell><cell>0.11</cell><cell>0.12</cell><cell>0.06</cell><cell>0.07</cell><cell>0.11</cell><cell>0.14</cell><cell>0.09</cell><cell>0.09</cell></row><row><cell>Discussion</cell><cell>0.03</cell><cell>0.01</cell><cell>0.02</cell><cell>0.02</cell><cell>0.1</cell><cell>0.05</cell><cell>0.1</cell><cell>0.15</cell><cell>0.05</cell><cell>0.02</cell><cell>0.04</cell><cell>0.04</cell></row><row><cell>Donations</cell><cell>0.32</cell><cell>0.31</cell><cell>0.3</cell><cell>0.3</cell><cell>0.56</cell><cell>0.37</cell><cell>0.61</cell><cell>0.57</cell><cell>0.41</cell><cell>0.34</cell><cell>0.4</cell><cell>0.4</cell></row><row><cell>Factoid</cell><cell>0.54</cell><cell>0.51</cell><cell>0.55</cell><cell>0.48</cell><cell>0.49</cell><cell>0.46</cell><cell>0.58</cell><cell>0.49</cell><cell>0.52</cell><cell>0.48</cell><cell>0.56</cell><cell>0.49</cell></row><row><cell>FirstPartyObservation</cell><cell>0.14</cell><cell>0.12</cell><cell>0.19</cell><cell>0.17</cell><cell>0.18</cell><cell>0.13</cell><cell>0.26</cell><cell>0.27</cell><cell>0.16</cell><cell>0.12</cell><cell>0.22</cell><cell>0.21</cell></row><row><cell>Hashtags</cell><cell>0.47</cell><cell>0.51</cell><cell>0.42</cell><cell>0.41</cell><cell>0.49</cell><cell>0.42</cell><cell>0.62</cell><cell>0.56</cell><cell>0.48</cell><cell>0.46</cell><cell>0.5</cell><cell>0.47</cell></row><row><cell>InformationWanted</cell><cell>0.4</cell><cell>0.11</cell><cell>0.59</cell><cell>0.45</cell><cell>0.18</cell><cell>0.01</cell><cell>0.3</cell><cell>0.39</cell><cell>0.25</cell><cell>0.02</cell><cell>0.4</cell><cell>0.42</cell></row><row><cell>Irrelevant</cell><cell>0.62</cell><cell>0.5</cell><cell>0.71</cell><cell>0.68</cell><cell>0.47</cell><cell>0.49</cell><cell>0.48</cell><cell>0.47</cell><cell>0.53</cell><cell>0.5</cell><cell>0.58</cell><cell>0.55</cell></row><row><cell>Location</cell><cell>0.6</cell><cell>0.6</cell><cell>0.62</cell><cell>0.59</cell><cell>0.66</cell><cell>0.59</cell><cell>0.59</cell><cell>0.61</cell><cell>0.63</cell><cell>0.59</cell><cell>0.61</cell><cell>0.6</cell></row><row><cell>MultimediaShare</cell><cell>0.28</cell><cell>0.26</cell><cell>0.34</cell><cell>0.31</cell><cell>0.4</cell><cell>0.34</cell><cell>0.52</cell><cell>0.51</cell><cell>0.33</cell><cell>0.3</cell><cell>0.41</cell><cell>0.38</cell></row><row><cell>News</cell><cell>0.27</cell><cell>0.25</cell><cell>0.25</cell><cell>0.26</cell><cell>0.33</cell><cell>0.29</cell><cell>0.23</cell><cell>0.24</cell><cell>0.3</cell><cell>0.27</cell><cell>0.24</cell><cell>0.25</cell></row><row><cell>Official</cell><cell>0.11</cell><cell>0.11</cell><cell>0.26</cell><cell>0.16</cell><cell>0.11</cell><cell>0.06</cell><cell>0.07</cell><cell>0.04</cell><cell>0.11</cell><cell>0.08</cell><cell>0.1</cell><cell>0.07</cell></row><row><cell>OriginalEvent</cell><cell>0.03</cell><cell>0.04</cell><cell>0.04</cell><cell>0.06</cell><cell>0</cell><cell>0</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell><cell>0.02</cell><cell>0.02</cell></row><row><cell>Sentiment</cell><cell>0.33</cell><cell>0.31</cell><cell>0.35</cell><cell>0.33</cell><cell>0.36</cell><cell>0.34</cell><cell>0.47</cell><cell>0.41</cell><cell>0.35</cell><cell>0.32</cell><cell>0.4</cell><cell>0.37</cell></row><row><cell>ThirdPartyObservation</cell><cell>0.49</cell><cell>0.48</cell><cell>0.54</cell><cell>0.5</cell><cell>0.26</cell><cell>0.23</cell><cell>0.28</cell><cell>0.29</cell><cell>0.34</cell><cell>0.31</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>Volunteer</cell><cell>0.25</cell><cell>0</cell><cell>0.25</cell><cell>0.17</cell><cell>0.06</cell><cell>0</cell><cell>0.04</cell><cell>0.23</cell><cell>0.1</cell><cell>0</cell><cell>0.07</cell><cell>0.2</cell></row><row><cell>Weather</cell><cell>0.7</cell><cell>0.6</cell><cell>0.66</cell><cell>0.66</cell><cell>0.49</cell><cell>0.33</cell><cell>0.43</cell><cell>0.4</cell><cell>0.58</cell><cell>0.43</cell><cell>0.52</cell><cell>0.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="7,72.00,328.13,454.10,129.22"><head>Table 7 . Test result comparison between pipeline using multi-task learning and pipeline using two different task-specific models.</head><label>7</label><figDesc></figDesc><table coords="7,78.38,363.36,447.72,46.28"><row><cell>Augmentation Statergies</cell><cell>nDCG@100</cell><cell cols="2">Info Type F1</cell><cell>Info Accuracy</cell><cell cols="2">Priority F1</cell><cell cols="2">Priority R</cell></row><row><cell></cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell></cell><cell>Actionable</cell><cell>All</cell><cell>Actionable</cell><cell>All</cell></row><row><cell>Baseline</cell><cell>0.492</cell><cell>0.2062</cell><cell>0.2837</cell><cell>0.8896</cell><cell>0.215</cell><cell>0.1737</cell><cell>0.0643</cell><cell>0.155</cell></row><row><cell>Separate Task</cell><cell>0.428</cell><cell>0.2256</cell><cell>0.2895</cell><cell>0.8876</cell><cell>0.1696</cell><cell>0.1336</cell><cell>0.1053</cell><cell>0.1875</cell></row><row><cell>Multi-Task</cell><cell>0.5112</cell><cell>0.2132</cell><cell>0.2927</cell><cell>0.8883</cell><cell>0.257</cell><cell>0.2012</cell><cell>0.1661</cell><cell>0.2126</cell></row></table><note coords="7,72.00,436.59,451.28,8.81;7,72.00,448.55,81.36,8.81"><p>this table, we can also observe the competitive results shown by the Baseline pipeline over the BERT and the DeBERTa pipelines.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="7,184.68,785.65,226.36,29.84"><head>Table 8 . Per-information label score distribution for different learning methods pipelines.</head><label>8</label><figDesc></figDesc><table coords="8,78.38,97.41,508.02,231.48"><row><cell>Information Classes</cell><cell></cell><cell>Precision</cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell><cell></cell><cell>F1 Score</cell><cell></cell></row><row><cell></cell><cell>Baseline</cell><cell>Separate Tasks</cell><cell>Multi-Task</cell><cell>Baseline</cell><cell>Separate Tasks</cell><cell>Multi-Task</cell><cell>Baseline</cell><cell>Separate Tasks</cell><cell>Multi-Task</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EmergingThreats</cell><cell>0.14</cell><cell>0.13</cell><cell>0.15</cell><cell>0.3</cell><cell>0.21</cell><cell>0.24</cell><cell>0.19</cell><cell>0.16</cell><cell>0.18</cell></row><row><cell>GoodsServices</cell><cell>0</cell><cell>0.58</cell><cell>0.61</cell><cell>0</cell><cell>0.16</cell><cell>0.13</cell><cell>0</cell><cell>0.25</cell><cell>0.22</cell></row><row><cell>MovePeople</cell><cell>0.63</cell><cell>0.54</cell><cell>0.51</cell><cell>0.32</cell><cell>0.29</cell><cell>0.27</cell><cell>0.43</cell><cell>0.38</cell><cell>0.35</cell></row><row><cell>NewSubEvent</cell><cell>0.12</cell><cell>0.06</cell><cell>0.15</cell><cell>0.14</cell><cell>0.05</cell><cell>0.1</cell><cell>0.13</cell><cell>0.06</cell><cell>0.12</cell></row><row><cell>SearchAndRescue</cell><cell>0.22</cell><cell>0.12</cell><cell>0.04</cell><cell>0.06</cell><cell>0.09</cell><cell>0.03</cell><cell>0.09</cell><cell>0.1</cell><cell>0.03</cell></row><row><cell>ServiceAvailable</cell><cell>0.46</cell><cell>0.46</cell><cell>0.44</cell><cell>0.34</cell><cell>0.38</cell><cell>0.32</cell><cell>0.39</cell><cell>0.41</cell><cell>0.37</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Non-Actionable Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Advice</cell><cell>0.51</cell><cell>0.4</cell><cell>0.44</cell><cell>0.24</cell><cell>0.2</cell><cell>0.23</cell><cell>0.33</cell><cell>0.27</cell><cell>0.31</cell></row><row><cell>CleanUp</cell><cell>0.19</cell><cell>0.28</cell><cell>0.23</cell><cell>0.5</cell><cell>0.54</cell><cell>0.54</cell><cell>0.28</cell><cell>0.37</cell><cell>0.33</cell></row><row><cell>ContextualInformation</cell><cell>0.12</cell><cell>0.09</cell><cell>0.11</cell><cell>0.11</cell><cell>0.08</cell><cell>0.07</cell><cell>0.11</cell><cell>0.09</cell><cell>0.09</cell></row><row><cell>Discussion</cell><cell>0.03</cell><cell>0.03</cell><cell>0.02</cell><cell>0.1</cell><cell>0.15</cell><cell>0.15</cell><cell>0.05</cell><cell>0.05</cell><cell>0.04</cell></row><row><cell>Donations</cell><cell>0.32</cell><cell>0.37</cell><cell>0.3</cell><cell>0.56</cell><cell>0.58</cell><cell>0.57</cell><cell>0.41</cell><cell>0.46</cell><cell>0.4</cell></row><row><cell>Factoid</cell><cell>0.54</cell><cell>0.5</cell><cell>0.48</cell><cell>0.49</cell><cell>0.5</cell><cell>0.49</cell><cell>0.52</cell><cell>0.5</cell><cell>0.49</cell></row><row><cell>FirstPartyObservation</cell><cell>0.14</cell><cell>0.14</cell><cell>0.17</cell><cell>0.18</cell><cell>0.26</cell><cell>0.27</cell><cell>0.16</cell><cell>0.18</cell><cell>0.21</cell></row><row><cell>Hashtags</cell><cell>0.47</cell><cell>0.4</cell><cell>0.41</cell><cell>0.49</cell><cell>0.54</cell><cell>0.56</cell><cell>0.48</cell><cell>0.46</cell><cell>0.47</cell></row><row><cell>InformationWanted</cell><cell>0.4</cell><cell>0.45</cell><cell>0.45</cell><cell>0.18</cell><cell>0.32</cell><cell>0.39</cell><cell>0.25</cell><cell>0.37</cell><cell>0.42</cell></row><row><cell>Irrelevant</cell><cell>0.62</cell><cell>0.69</cell><cell>0.68</cell><cell>0.47</cell><cell>0.45</cell><cell>0.47</cell><cell>0.53</cell><cell>0.54</cell><cell>0.55</cell></row><row><cell>Location</cell><cell>0.6</cell><cell>0.61</cell><cell>0.59</cell><cell>0.66</cell><cell>0.55</cell><cell>0.61</cell><cell>0.63</cell><cell>0.57</cell><cell>0.6</cell></row><row><cell>MultimediaShare</cell><cell>0.28</cell><cell>0.31</cell><cell>0.31</cell><cell>0.4</cell><cell>0.46</cell><cell>0.51</cell><cell>0.33</cell><cell>0.37</cell><cell>0.38</cell></row><row><cell>News</cell><cell>0.27</cell><cell>0.25</cell><cell>0.26</cell><cell>0.33</cell><cell>0.26</cell><cell>0.24</cell><cell>0.3</cell><cell>0.26</cell><cell>0.25</cell></row><row><cell>Official</cell><cell>0.11</cell><cell>0.16</cell><cell>0.16</cell><cell>0.11</cell><cell>0.05</cell><cell>0.04</cell><cell>0.11</cell><cell>0.08</cell><cell>0.07</cell></row><row><cell>OriginalEvent</cell><cell>0.03</cell><cell>0.06</cell><cell>0.06</cell><cell>0</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell><cell>0.02</cell><cell>0.02</cell></row><row><cell>Sentiment</cell><cell>0.33</cell><cell>0.3</cell><cell>0.33</cell><cell>0.36</cell><cell>0.4</cell><cell>0.41</cell><cell>0.35</cell><cell>0.34</cell><cell>0.37</cell></row><row><cell>ThirdPartyObservation</cell><cell>0.49</cell><cell>0.52</cell><cell>0.5</cell><cell>0.26</cell><cell>0.29</cell><cell>0.29</cell><cell>0.34</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>Volunteer</cell><cell>0.25</cell><cell>0.13</cell><cell>0.17</cell><cell>0.06</cell><cell>0.15</cell><cell>0.23</cell><cell>0.1</cell><cell>0.14</cell><cell>0.2</cell></row><row><cell>Weather</cell><cell>0.7</cell><cell>0.65</cell><cell>0.66</cell><cell>0.49</cell><cell>0.33</cell><cell>0.4</cell><cell>0.58</cell><cell>0.44</cell><cell>0.49</cell></row></table><note coords="7,268.88,785.65,57.66,7.93;7,184.68,796.70,226.36,7.73;7,203.99,807.57,187.29,7.93;8,72.00,355.69,61.60,8.51;8,72.00,374.88,453.02,8.81;8,81.96,386.83,295.36,8.81;8,72.00,403.27,415.84,8.81;8,268.88,785.65,57.66,7.93;8,184.68,796.70,226.36,7.73;8,203.99,807.57,187.29,7.93"><p>Notebook Paper Incident Streams Track at Text Retrieval Conference (TREC-IS) Richard McCreadie, Cody Buntain and Ian Soboroff REFERENCES Wang, C., Nulty, P., and Lillis, D. (2021). "Transformer-based Multi-task Learning for Disaster Tweet Categorisation". In: Proceedings of the International ISCRAM Conference 2021-May.May. Zhang, Y. and Yang, Q. (2017). "A survey on multi-task learning". In: arXiv preprint arXiv:1707.08114. Notebook Paper Incident Streams Track at Text Retrieval Conference (TREC-IS) Richard McCreadie, Cody Buntain and Ian Soboroff</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
