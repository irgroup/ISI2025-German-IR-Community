<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,211.70,85.16,171.88,12.62;1,225.87,103.09,143.54,12.62">UNIMIB at TREC 2021 Clinical Trials Track</title>
				<funder ref="#_B6en3fM">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_p5wdsfe">
					<orgName type="full">EU Horizon 2020 ITN/ETN on Domain Specific Systems for Information Extraction and Retrieval -DoSSIER</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,187.32,141.85,67.13,8.74"><forename type="first">Georgios</forename><surname>Peikos</surname></persName>
							<email>georgios.peikos@unimib.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems, and Communication (DISCo)</orgName>
								<orgName type="laboratory">Information and Knowledge Representation, Retrieval, and Reasoning (IKR3) Lab</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.10,141.85,57.54,8.74"><forename type="first">Oscar</forename><surname>Espitia</surname></persName>
							<email>oscar.espitiamendoza@unimib.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems, and Communication (DISCo)</orgName>
								<orgName type="laboratory">Information and Knowledge Representation, Retrieval, and Reasoning (IKR3) Lab</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.51,141.85,61.46,8.74"><forename type="first">Gabriella</forename><surname>Pasi</surname></persName>
							<email>gabriella.pasi@unimib.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems, and Communication (DISCo)</orgName>
								<orgName type="laboratory">Information and Knowledge Representation, Retrieval, and Reasoning (IKR3) Lab</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,211.70,85.16,171.88,12.62;1,225.87,103.09,143.54,12.62">UNIMIB at TREC 2021 Clinical Trials Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4D7E1668FC1380CA56C3C8687B726000</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This contribution summarizes the participation of the UNIMIB team to the TREC 2021 Clinical Trials Track. We have investigated the effect of different query representations combined with several retrieval models on the retrieval performance. First, we have implemented a neural re-ranking approach to study the effectiveness of dense text representations. Additionally, we have investigated the effectiveness of a novel decision-theoretic model for relevance estimation. Finally, both of the above relevance models have been compared with standard retrieval approaches. In particular, we combined a keyword extraction method with a standard retrieval process based on the BM25 model and a decision-theoretic relevance model that exploits the characteristics of this particular search task. The obtained results show that the proposed keyword extraction method improves 84% of the queries over the TREC's median NDCG@10 measure when combined with either traditional or decisiontheoretic relevance models. Moreover, regarding RPEC@10, the employed decision-theoretic model improves 85% of the queries over the reported TREC's median value.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2021 Clinical Trials Track<ref type="foot" coords="1,255.04,442.59,3.97,6.12" target="#foot_0">1</ref> focuses on the task of retrieving clinical trials that are eligible for a particular patient. Specifically, patient-related information is provided as a query consisting of a synthetic case in the form of an admission note. Each query describes a patient by means of certain conditions and observations, and, in general, queries are longer than those in traditional ad-hoc retrieval tasks. Moreover, clinical trials, i.e., the considered document collection, are multi-fielded documents, where a core aspect is constituted by the fields that specify the inclusion and exclusion criteria. Those are not all-inclusive statements about the trial to the point that other trial information can be ignored, but they are essential aspects for defining a trial's eligibility (relevance) to a given patient.</p><p>This report outlines our team's (UNIMIB) submission to TREC 2021 Clinical Trials Track, it discusses the experimental setup, and compares our results to the reported TREC's median performance. In particular, we examined the effect of different query representations for retrieving eligible clinical trials. Moreover, we combined those different query representations with several relevance models, one of which is a novel decision-theoretic model that leverages the peculiarities of this search task in the relevance estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>This section describes the three components of the submitted runs, i.e., the query and document representations, along with the employed relevance models. The first one is the BM25 model that leverages an ad-hoc query representation. In addition, the second relevance model is a decisiontheoretic model whose properties are based on the peculiarities of this particular search task; finally, a neural network-based model in a re-ranking setup has been employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query representation</head><p>The provided queries consist of synthetic patient cases created by medical experts in the form of admission notes. Previous studies <ref type="bibr" coords="2,229.88,118.55,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,242.05,118.55,7.75,8.74" target="#b1">2]</ref> have investigated the effect of different query representations on the system's performance. Their findings suggested that using the whole verbose query is not as effective as using its ad-hoc representation. Therefore, given a query that is a verbose representation of a synthetic patient case, we extracted keywords that better represent its content.</p><p>To this aim, we have employed EmbedRank++ proposed in <ref type="bibr" coords="2,365.13,166.37,9.96,8.74" target="#b2">[3]</ref>, which is a fast, unsupervised, and collection-independent method for extracting key phrases and keywords; these advantages make this method suitable for extracting keywords from verbose queries. Firstly, given a query, we estimated its embedding representation, and then we estimated the embedding representation of every of its tokens, both unigrams and bigrams. Having done that, we selected the keyword or key phrase that is most similar to the query by measuring their cosine similarity. Then, by employing the maximal marginal relevance (MMR) formula, as introduced in [3], we iteratively selected new keywords or key phrases similar to the query and different from the already extracted keywords. The employed keyword extraction approach requires the setting of two parameters; the total number of extracted keywords, and a parameter Î» that balances the trade-off between similarity to the query and diversity between the extracted keywords. Concluding, by using this tool, we were able to extract those keywords that better represent each query, and at the same time, avoid redundant terms.</p><p>For the submitted runs, we have used two different query representations, i.e., the original verbose query Qd, provided by the organizers, and an ad-hoc representation that contains the extracted keywords, Qk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Representation</head><p>In the context of this particular search task, as pointed out in Section1, several document sections have a different effect on the relevance of the whole document to the query. Specifically, without underestimating the contribution of the other document sections, the parts that refer to a trial's inclusion and exclusion criteria in the eligibility section are of great importance.</p><p>Besides the eligibility section, other important document sections are its title, description, summary, and studied condition. Consequently, three of our submitted runs leverage an index created by combining the eligibility section with all the document sections mentioned above; throughout this paper, this index will refer to as I comb. For the other two runs the index was created for only the title and summary with inclusion criteria when it is specified, and successfully extracted, this index will be referred to as I comb*.</p><p>Two additional indices have been created for each document, namely I in which indexes only the trial's inclusion criteria, and I ex which indexes only the trial's exclusion criteria. For their extraction, several regex rules that leverage their semi-structured nature have been used. In the cases where the extraction of the inclusion and exclusion criteria was not feasible, the whole eligibility section has been indexed for both indices, i.e., the I in and I ex. In addition to those two indices, a third one has been created. Here, the title, description, studied condition, and the summary sections were combined in a single text and indexed; this index will be referred to as I main.</p><p>In summary, the first, fourth and fifth submitted run uses the combined document representations I comb and I comb* to estimate the relevance of a clinical trial, while the relevance decision for the second and third submissions rely on the I in, the I ex and the I main indices, and will be further analyzed in section 2.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Retrieval Models</head><p>Given the various query and document representations, we have combined them with several relevance models. The considered models are the traditional BM25 model, a neural network-based model in a re-ranking setup, trained on previous clinical trials collections, and a decision-theoretic relevance model, which we have introduced for this particular search task. Specifically, the decisiontheoretic relevance model is based on the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) <ref type="bibr" coords="2,171.79,750.05,9.96,8.74" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Standard Approach</head><p>A traditional retrieval approach has been employed that leverages the Qk representation along with the I comb index and the BM25 model to estimate an overall relevance value and rank the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Decision-Theoretic Approach</head><p>As stated previously, the trial's inclusion and exclusion criteria have a significant role in the relevance (eligibility) of a trial to a particular patient. Specifically, we argue that the semantic similarity of a patient health record, in our case the query, to a trial's inclusion criteria contributes positively to the trial's overall relevance. In contrast, the semantic similarity to its exclusion criteria contributes negatively. In addition, we argue that the semantic similarity of a query to the remaining trial's sections, i.e., its title, description, summary, studied condition, also contributes positively to its overall relevance. These are task-specific characteristics that standard retrieval approaches usually do not consider, while a decision-theoretic model allows us to incorporate them in the relevance estimation.</p><p>In detail, to estimate the overall trial's relevance based on the previous assumptions, firstly, we have employed three different formal representations, namely the I in, the I ex and the I main, that have been introduced in Section 2.2. Then, given these three representations, we estimated, for each query, the topical relevance for each of them by using the BM25 model. By doing that, we ended up with three relevance scores that have a different contribution, either positive or negative, to the document's overall relevance. The final step was aggregating those scores by explicitly considering their independent contribution to relevance. That has been achieved by incorporating TOPSIS, a multi-criteria decision analysis method that can provide a final document ranking based on the task-specific characteristics.</p><p>Specifically, the implementation of TOPSIS requires several components to be considered:</p><p>-A set of alternatives that have to be ranked, in our case the documents.</p><p>-A set of considered criteria, with their related performance scores (in our case the three relevance scores), R in, R ex, R main calculated w.r.t. the different document representations using BM25. In order for TOPSIS to be applied, those scores must be monotonically increasing or decreasing and normalized. -A weighting vector associated with the importance of each criterion to the final relevance decision.</p><p>In addition to the components mentioned above, TOPSIS allows to specifically state the contribution, positive or negative, of a criterion to the final overall score. In this particular search task, the R in and R main criteria contribute positively, therefore they are benefit criteria, while the R ex contributes negatively, and, as a result, this criterion is a cost criterion.</p><p>TOPSIS is based on the concept that the chosen alternative, i.e., a document, should have the shortest geometric distance from a positive ideal solution and the longest from a negative ideal solution. In general, the positive ideal solution is a vector consisting of the maximum values of the benefit criteria and the minimum values of the cost criteria. In contrast, the negative ideal solution consists of the maximum values of the cost criteria and the minimum values of the benefit criteria.</p><p>Therefore, given the decision matrix related to a specific query containing the normalized performance (relevance) scores referred to the considered sections of each document, the weighted average of the matrix can be computed over the three considered criteria, to obtain the final relevance score. Moreover, the positive and negative ideal solutions can be generated s follows: the positive ideal solution is represented by a vector that contains the highest scores of the R in and R main criteria and the lowest score of the R ex criterion, present in the normalized decision matrix, i.e., across all the documents for a given query; the negative ideal solution is the exact opposite.</p><p>Finally, for each query-document pair, the euclidean distance of the document from the positive and negative ideal solutions is measured. The documents are then ranked based on the relative closeness of their overall relevance score to the ideal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Neural Approach</head><p>For two of the runs, namely UNM 4 and UNM 5, we implemented a re-ranking approach based on BM25 and Bert. BM25 employs the query representation Qd and the document representation I comb* ; on the re-ranking side, Bert for sentences classification was fine-tuned in a low data regime by using collections from previous TREC Biomedical tracks <ref type="foot" coords="4,355.15,144.21,3.97,6.12" target="#foot_1">2</ref> ; and also the collection indicated by the organizers <ref type="bibr" coords="4,162.79,157.74,9.96,8.74" target="#b1">[2]</ref>. Concerning the document representation, we also used I comb*. In this way, the combination of query and document does not exceed the limit of tokens of the transformer network. The training procedure was adopted by following previous approaches <ref type="bibr" coords="4,434.34,181.65,9.96,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Several steps of our methodology required some parameter selection. Therefore, this section presents a few details related to implementation aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Keyword Extraction Method</head><p>To begin with, the keyword extraction method applied to the queries has required the application of a specific model for obtaining both document and word embeddings. Due to its simplicity and speed, we have used the DistilBERT proposed in <ref type="bibr" coords="4,299.06,330.33,9.96,8.74" target="#b5">[6]</ref>. Moreover, the length of the provided queries, in terms of tokens, was smaller than the model's maximum input, and as a result, no action was needed.</p><p>In addition, we needed to set two more parameters related to the diversity between the selected keywords and the size of the new query. Due to the assumption that each query represents a different patient and that some conditions may be more complicated than others (therefore reflected in longer descriptions) we have modified the original implementation of the EmbedRank++ method. In particular, instead of extracting a constant number of key phrases from each query, we estimate the size of the new query dynamically. The length of the new query is equal to half the size of the initial query; stop-words have been removed. Regarding the second parameter, which is related to the diversity between the candidate keywords, it was set equal to 0.5 to capture many different aspects of each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Indexing &amp; Topical Relevance</head><p>To index the collection and estimate the topical relevance values with respect to each of different document representations (indices), we have employed PyTerrier <ref type="bibr" coords="4,376.16,527.56,10.52,8.74" target="#b6">[7]</ref> and its BM25 implementation, respectively. For preprocessing, we have used the standard PyTerrier's pipeline, i.e., porterstemming and stopwords removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">TOPSIS</head><p>As stated in Section 2.5, TOPSIS associates a weight with each considered criterion based on which each document is evaluated. These weights can be either learned from a portion of training data, manually set to specific values, or estimated with some weighting method. For the submitted runs R2 and R3, the weights have been set to fixed values equal to 0.33, the mean weight value of the three criteria, thus assuming a same importance for the three criteria. We refer to this model as TT MW model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Submitted Runs</head><p>Table <ref type="table" coords="4,113.54,718.08,4.98,8.74" target="#tab_0">1</ref> presents the submitted runs along with the corresponding components that have been analyzed in the previous sections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="5,113.79,246.08,4.98,8.74" target="#tab_1">2</ref> presents the results obtained from the five submitted runs, while Table <ref type="table" coords="5,451.24,246.08,4.98,8.74" target="#tab_2">3</ref> reports the number of queries that were improved compared to their reported TREC's median performance. Thus, it can be seen that the mean effectiveness of our runs is well-above the averaged TREC's median for three different measures, and also that the submitted runs improve the majority of the queries. Furthermore, one can observe that the highest PREC@10 value was obtained by the R3 run that involves the TOPSIS model and the Qk representation. Also, the R2 run that exploits the Qd query representation, that is usually more noisy, yields results relatively close to the runs that employ the Qk representation. Finally, the fact that the associated criteria weights were manually set, instead of learned using a training query set, may have underestimated the effectiveness of the employed decision-theoretic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper we have presented the results of our participation in the TREC 2021 Clinical Trials Track. Our objective was to investigate the effectiveness of several query representation combined with different retrieval models in this particular search task. The analysis of the results confirmed the effectiveness of the query representation approach (run R1). However, we also proved that a decision-theoretic model (run R2), yields similar results compared to a standard retrieval approach that is associated with an ad-hoc query representation (run R1). In addition, the decision-theoretic model was able to improve the system's precision when combined with a better query representation (run R3). Regarding the neural-based approaches, their performance was comparable to the reported TREC's median.</p><p>Concluding, it can be seen that using a decision-theoretic model is beneficial for this particular search task. The decision-theoretic model almost met the performance of a standard approach without leveraging the use of the query preprocessing method. At the same time, it outperformed the standard approach in terms of PREC@10 when combined with the employed query preprocessing method. However, the fact that the criteria weights were manually set may have underestimated the model's effectiveness; therefore, further research will be conducted in this direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,129.91,89.29,335.47,97.97"><head>Table 1 .</head><label>1</label><figDesc>A summary of the components employed in each submitted runs.</figDesc><table coords="5,129.91,89.29,335.47,81.09"><row><cell>Run ID</cell><cell>Run Name</cell><cell cols="3">Query Representation Document Index Relevance Model</cell></row><row><cell>R1</cell><cell>IKR3 BSL</cell><cell>Qk</cell><cell>I comb</cell><cell>BM25</cell></row><row><cell cols="2">R2 IKR3 TT MW d</cell><cell>Qd</cell><cell>I in, I ex, I main</cell><cell>TT MW</cell></row><row><cell cols="2">R3 IKR3 TT MW k</cell><cell>Qk</cell><cell>I in, I ex, I main</cell><cell>TT MW</cell></row><row><cell>R4</cell><cell>UNM 4</cell><cell>Qd</cell><cell>I comb*</cell><cell>BM25+BERT</cell></row><row><cell>R5</cell><cell>UNM 5</cell><cell>Qd</cell><cell>I comb*</cell><cell>BM25+BERT</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,85.04,330.44,425.19,92.69"><head>Table 2 .</head><label>2</label><figDesc>Overall comparison with the across query averaged median values, where R1-5 represent the effectiveness obtained by our runs.</figDesc><table coords="5,179.23,330.44,236.83,65.25"><row><cell>Measure</cell><cell cols="2">TREC's Median R1 R2 R3 R4 R5</cell></row><row><cell>NDCG@10</cell><cell>.304</cell><cell>.478 .431 .449 .252 .346</cell></row><row><cell>PREC@10</cell><cell>.161</cell><cell>.265 .255 .281 .152 .173</cell></row><row><cell>Reciprocal Rank</cell><cell>.294</cell><cell>.486 .452 .459 .289 .373</cell></row><row><cell>NDCG@5</cell><cell cols="2">Not Reported .504 .458 .468 .278 .380</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,166.97,520.40,261.34,56.63"><head>Table 3 .</head><label>3</label><figDesc>Number of improved queries over the TREC's Median.</figDesc><table coords="5,242.75,520.40,109.77,41.14"><row><cell>Runs</cell><cell>R1 R2 R3</cell></row><row><cell>NDCG@10</cell><cell>63 59 58</cell></row><row><cell>PREC@10</cell><cell>63 62 64</cell></row><row><cell cols="2">Reciprocal Rank 53 53 53</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,95.00,751.37,155.84,7.47"><p>http://www.trec-cds.org/2021.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,95.00,751.37,113.47,7.47"><p>http://www.trec-cds.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This work was supported by the <rs type="funder">EU Horizon 2020 ITN/ETN on Domain Specific Systems for Information Extraction and Retrieval -DoSSIER</rs> (<rs type="grantNumber">H2020-EU.1.3.1</rs>., ID: <rs type="grantNumber">860721</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_p5wdsfe">
					<idno type="grant-number">H2020-EU.1.3.1</idno>
				</org>
				<org type="funding" xml:id="_B6en3fM">
					<idno type="grant-number">860721</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,88.62,313.04,421.62,7.86;6,97.19,324.00,413.05,7.86;6,97.19,334.96,413.05,7.86;6,97.19,345.91,413.05,7.86;6,97.19,356.87,159.37,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,307.92,313.04,202.32,7.86;6,97.19,324.00,181.33,7.86">Generating clinical queries from patient narratives: A comparison between machines and humans</title>
		<author>
			<persName coords=""><forename type="first">Bevan</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liam</forename><surname>Cripwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,301.74,334.96,208.50,7.86;6,97.19,345.91,274.50,7.86">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">Noriko</forename><surname>Kando</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hideo</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</editor>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">August 7-11, 2017. 2017</date>
			<biblScope unit="page" from="853" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.62,367.83,421.62,7.86;6,97.19,378.79,413.05,7.86;6,97.19,389.75,413.04,7.86;6,97.19,400.71,286.20,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,244.83,367.83,215.92,7.86">A test collection for matching patients to clinical trials</title>
		<author>
			<persName coords=""><forename type="first">Bevan</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,452.85,378.79,57.38,7.86;6,97.19,389.75,413.04,7.86;6,97.19,400.71,46.71,7.86">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016</title>
		<editor>
			<persName><forename type="first">Raffaele</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Javed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ian</forename><surname>Aslam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Justin</forename><surname>Ruthven</surname></persName>
		</editor>
		<editor>
			<persName><surname>Zobel</surname></persName>
		</editor>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">July 17-21, 2016. 2016</date>
			<biblScope unit="page" from="669" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.62,411.67,421.61,7.86;6,97.19,422.63,413.05,7.86;6,97.19,433.59,413.04,7.86;6,97.19,444.54,413.04,7.86;6,97.19,455.50,95.97,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,491.80,411.67,18.43,7.86;6,97.19,422.63,262.75,7.86">Simple unsupervised keyphrase extraction using sentence embeddings</title>
		<author>
			<persName coords=""><forename type="first">Kamil</forename><surname>Bennani-Smires</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreea</forename><surname>Hossmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Baeriswyl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,131.43,433.59,340.35,7.86">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<editor>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</editor>
		<meeting>the 22nd Conference on Computational Natural Language Learning<address><addrLine>Brussels; Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10-31">2018. October 31 -November 1, 2018. 2018</date>
			<biblScope unit="page" from="221" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.62,466.46,421.61,7.86;6,97.19,477.42,413.05,7.86;6,97.19,488.38,60.45,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,259.79,466.46,250.44,7.86;6,97.19,477.42,111.37,7.86">Multiple Attribute Decision Making: Methods and Applications -A State-of-the-Art Survey</title>
		<author>
			<persName coords=""><forename type="first">Ching-Lai</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kwangsun</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,279.18,477.42,226.74,7.86">Lecture Notes in Economics and Mathematical Systems</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<date type="published" when="1981">1981</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.62,499.34,421.61,7.86;6,97.19,510.30,367.69,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,311.05,499.34,199.18,7.86;6,97.19,510.30,145.45,7.86">Clinical trial search: Using biomedical language understanding models for re-ranking</title>
		<author>
			<persName coords=""><forename type="first">Maciej</forename><surname>Rybinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jerry</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sarvnaz</forename><surname>Karimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,250.71,510.30,136.38,7.86">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page">103530</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.62,521.26,421.61,7.86;6,97.19,532.22,296.69,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,382.73,521.26,127.51,7.86;6,97.19,532.22,170.07,7.86">Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno>CoRR, abs/1910.01108</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.62,543.17,421.62,7.86;6,97.19,554.13,188.76,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,273.17,543.17,237.07,7.86;6,97.19,554.13,33.70,7.86">Declarative experimentation ininformation retrieval using pyterrier</title>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,150.23,554.13,107.37,7.86">Proceedings of ICTIR 2020</title>
		<meeting>ICTIR 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
