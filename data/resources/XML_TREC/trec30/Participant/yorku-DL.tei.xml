<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,69.31,68.24,456.65,16.23">York University at TREC 2021: Deep Learning Track</title>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,222.16,102.13,66.97,9.40"><forename type="first">Yizheng</forename><surname>Huang</surname></persName>
							<email>jhuang@yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Management Research Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.82,102.13,61.30,9.40"><forename type="first">Jimmy</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Knowledge Management Research Lab</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,69.31,68.24,456.65,16.23">York University at TREC 2021: Deep Learning Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0AAC6CDF3D8336B78B920E07A3DAB608</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>BM25</term>
					<term>Deep Learning</term>
					<term>Meta Search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is our first time to participate in TREC Deep Learning track. We submitted three BERT-based runs "YorkU21a", "YorkU21b" and "YorkU21c", where YorkU21a has the best performance. Our main goal is to explore the possibility of combining deep learning with traditional BM25 retrieval method. In this paper, we discuss the results of using the summation method to combine the above two approaches and provide some illustrative analyses on the impact of different retrieval strategies on the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information retrieval (IR) systems search for the relevant information from a collection of data based on various retrieval models such as probabilistic models, language models and deep learning models. The metasearch system <ref type="bibr" coords="1,120.42,381.63,10.51,9.40" target="#b0">[1]</ref> will access multiple IR systems simultaneously and gather their ranking results into a single ranked output. Since the IR systems retrieve different results, the metasearch system provides a way to combine the results of multiple systems to make the best match.</p><p>Deep learning models like Transformers <ref type="bibr" coords="1,248.05,417.50,10.51,9.40" target="#b1">[2]</ref> and Bert <ref type="bibr" coords="1,304.17,417.50,9.96,9.40" target="#b2">[3]</ref>, calculate the similarity between word embeddings by semantic search to rank passages, which is a semantic-based ambiguous matching. Although BM25 <ref type="bibr" coords="1,506.90,429.45,10.51,9.40" target="#b3">[4,</ref><ref type="bibr" coords="1,520.78,429.45,7.74,9.40" target="#b4">5]</ref> is keyword-based and cannot understand context and distinguish synonyms in the traditional way of retrieval, it is an exact match. IRLab at York University participated in the TREC 2021 Deep Learning Track for passage (full) ranking task. Our primary goal was to explore the results of combining the above two different search methods.</p><p>This paper is organized as follows: Section 2 presents our methods applied in passage ranking. Section 3 details our experimental results on different evaluation metrics. Finally, in Section 4, we discuss the conclude and present our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Methods</head><p>We have a three-stage framework. In the first stage, we did not use any dataset to train a new model because our focus is to combine deep learning and BM25. So, we utilized the Sentence-Bert trained by UKPLab <ref type="bibr" coords="1,507.16,579.86,9.96,9.40" target="#b5">[6]</ref>. We utilized msmarco-MiniLM-L-6-v3 for the normalized embedding and retrieving a candidate set because it has a faster computation speed. The candidate set was a submitted run as YorkU21b. We encoded each search query as a sentence embedding and used semantic search to calculate its relevance to the embeddings of the dataset. This would retrieve the most relevant 100 hits from each jsonl file, instead of retrieving them from the entire dataset. And we utilized two pre-trained cross-coder model ms-marco-MiniLM-L-12-v2 and ms-marco-MiniLM-L-6-v2 to re-rank the candidate set. The results of the above three rankings were voted, and the top 100 most relevant passages for each query were selected as the final result which was our submitted run of YorkU21a. For comparison, we also submitted the result YorkU21c, which was re-ranked only by ms-marco-MiniLM-L-6-v2.</p><p>During the second stage, we used the Anserini <ref type="bibr" coords="1,282.62,687.46,10.51,9.40" target="#b6">[7]</ref> with default parameters to obtain the result of BM25. Finally, we used a method to combine the result of YorkU21a and BM25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Combine Method</head><p>The way we considered combining BM25 and Deep Learning is straightforward, combining the two results in the simplest way. Some simple combination methods are introduced by Fox and Shaw <ref type="bibr" coords="1,440.72,757.64,9.96,9.40" target="#b7">[8]</ref>, such as CombMax, CombMin, CombSUM, and CombMed, and CombSUM is the best performing combination method. In this paper, we used CombSUM as a method to combine the results of BM25 and Deep Learning.</p><p>In this paper, we will use the summation method to combine the two retrieval results as follows:</p><formula xml:id="formula_0" coords="2,247.23,33.97,291.34,29.95">CombSU M = ! p∈P S(q)<label>(1)</label></formula><p>where P represents a set of retrieved passages and p represents each passage, q is a query and S(q) is the score of the passage retrieved by the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Normalization Method</head><p>Since the use of different retrieval systems will have different weighting methods and thus produce quite different ranges of similarity values, it is necessary to apply normalization methods to the different retrieval results. We used three different methods for normalization, which are Rescaling, Mean Normalization and Z-score Normalization.</p><p>Rescaling, also known as min-max normalization, is the simplest way to reduce the range of data to [0, 1] or [-1, 1], where the general formula for normalization of [0, 1] is as follows:</p><formula xml:id="formula_1" coords="2,249.99,210.17,284.34,30.05">s ′ = s -min(s) max(s) -min(s) (<label>2</label></formula><formula xml:id="formula_2" coords="2,534.33,216.91,4.24,9.40">)</formula><p>where s is an original score of ranking, s ′ is the normalized ranking score. Mean Normalization is another way to normalize data, it works by calculating and subtracting the mean value of each data. A common practice is to divide this value by the range or standard deviation, and the formula is as follows:</p><formula xml:id="formula_3" coords="2,249.99,295.08,284.34,30.05">s ′ = s - s max(s) -min(s) (<label>3</label></formula><formula xml:id="formula_4" coords="2,534.33,301.82,4.24,9.40">)</formula><p>where s is the mean of scores.</p><p>When the same process is done using standard deviations as denominators, the process is called Standardization, also known as Z-score Normalization. Z-score Normalization is widely used method for normalization in many machine learning algorithms. This method gives the mean and standard deviation of the original data to standardize the data. The processed data conforms to the standard normal distribution, that is, the mean is 0 and the standard deviation is 1, and the formula is as follows:</p><formula xml:id="formula_5" coords="2,274.64,403.33,259.69,22.98">s ′ = s -µ σ (<label>4</label></formula><formula xml:id="formula_6" coords="2,534.33,410.07,4.24,9.40">)</formula><p>where µ is the mean of all sample data and σ is the standard deviation of all sample data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Since YorkU21a achieves the best result for deep learning retrieval, we only use this run in combination with BM25. Our experiment runs are denoted as: YorkU21a, Anserini BM25, CombSUM rescal, CombSUM zscore, and CombSUM mean, where YorkU21a is our official submission and others are unofficial. Table <ref type="table" coords="2,478.41,509.15,4.98,9.40" target="#tab_0">1</ref> presents the detailed descriptions of these runs are as follows.   <ref type="table" coords="3,345.90,393.27,3.87,9.40" target="#tab_1">2</ref>. NIST evaluation provided a four-degree level: '0' irrelevant, '1' related, '2' highly relevant, and '3' perfectly relevant. For passages, a judgment level of '1' means the passage was related to the query but didn't actually answer it, so for measures that use binary relevance judgments a '1' is not relevant. Except for the calculation of NDCG which needs to use all the levels, the rest of the evaluation calculation should not consider level '1'.</p><p>We can clearly find that the deep learning model has the best result. And different normalization methods have an effect on the results, where Rescaling achieves the best performance. To better understand the differences between the deep learning, BM25 and combined methods, we compare them together as shown in the Figure <ref type="figure" coords="3,530.83,476.96,3.87,9.40" target="#fig_0">1</ref>. It can be seen that when the performance difference between deep learning and BM25 is large, the combined result becomes worse than deep learning, and conversely, if the performance of both is close, the result will be slightly better than deep learning. The interesting thing, however, is that in the overall case where deep learning is much stronger than BM25, BM25 still performs better in some queries. We analyzed one of the particular cases, as shown in Table <ref type="table" coords="3,165.95,536.73,3.87,9.40" target="#tab_2">3</ref>.</p><p>In Table <ref type="table" coords="3,111.99,548.69,3.87,9.40" target="#tab_2">3</ref>, we can find that the keyword-based BM25 model is more likely to find relevant passages when the query is a short sentence, while the semantic-based deep learning model will find passages that partially match the keywords rather than the exact matches. In other cases, we found that BM25 performs poorly when the query is a long sentence, as it is an exact match, and deep learning shows strong capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discusstions</head><p>The performance of deep learning-based retrieval is much better than that of BM25-based retrieval. If the performance gap between the two is too large for the query, combining the two results will instead yield a worse result. But when the performance of them is close, combining the two results will produce a better result.</p><p>From the retrieval results, the traditional BM25 is more suitable for retrieving queries with short sentences, while deep learning has better performance in retrieving long sentences based on semantics. However, the retrieval performance of deep learning under short sentences is sometimes far inferior to that of BM25. For example, when matching people's names, the deep learning model tends to match passages that contain partial information about the person's name, while BM25 will precisely match passages with the exact same person's name, which will lead to inaccuracy of deep learning.</p><p>For our future work, we will first focus on combining the advantages of traditional models for keyword-based exact matching with deep learning models to further improve the search performance. Second, we will apply our methods for more applications (such as biomedicine and Clinical IR) <ref type="bibr" coords="3,377.60,770.83,10.51,9.40" target="#b8">[9,</ref><ref type="bibr" coords="3,391.44,770.83,12.72,9.40" target="#b9">10,</ref><ref type="bibr" coords="3,407.49,770.83,11.62,9.40" target="#b10">11]</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,209.19,361.44,176.89,9.40;3,56.69,28.34,481.90,306.14"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison of Three Methods</figDesc><graphic coords="3,56.69,28.34,481.90,306.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,105.75,551.72,380.45,125.65"><head>Table 1 :</head><label>1</label><figDesc>Runs Description</figDesc><table coords="2,105.75,571.95,380.45,105.41"><row><cell>Runs</cell><cell>Description</cell></row><row><cell>Anserini BM25</cell><cell>Use BM25 algorithm to obtain a baseline run by Anserini.</cell></row><row><cell>YorkU21a</cell><cell>Use Sentence-Bert to obtain the best re-rank result.</cell></row><row><cell>CombSUM rescal</cell><cell>Use CombSUM method to combine the above two methods by</cell></row><row><cell></cell><cell>Rescaling.</cell></row><row><cell>CombSUM zscore</cell><cell>Use CombSUM method to combine the above two methods by</cell></row><row><cell></cell><cell>Z-score Normalization.</cell></row><row><cell>CombSUM mean</cell><cell>Use CombSUM method to combine the above two methods by</cell></row><row><cell></cell><cell>Mean Normalization.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,147.08,712.41,297.79,87.85"><head>Table 2 :</head><label>2</label><figDesc>Results with Different Method</figDesc><table coords="2,147.08,730.71,297.79,69.55"><row><cell>Runs</cell><cell cols="3">MAP P@10 NDCG@10 NDCG@100</cell></row><row><cell>Anserini BM25</cell><cell>0.1357 0.3547</cell><cell>0.4458</cell><cell>0.3913</cell></row><row><cell>YorkU21a</cell><cell>0.5308 0.6151</cell><cell>0.6965</cell><cell>0.5779</cell></row><row><cell cols="2">CombSUM rescal 0.2917 0.5491</cell><cell>0.6370</cell><cell>0.5654</cell></row><row><cell cols="2">CombSUM mean 0.2230 0.5283</cell><cell>0.6122</cell><cell>0.4691</cell></row><row><cell cols="2">CombSUM zscore 0.2602 0.4906</cell><cell>0.5875</cell><cell>0.5379</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,56.69,38.87,481.88,351.25"><head>Table 3 :</head><label>3</label><figDesc>Comparison of Deep Learning (NDCG@10: 0.2962) and BM25 (NDCG@10: 0.5815) in Query 190623: "for what is david w. taylor known" David W. Taylor. Rear Admiral David Watson Taylor, USN (March 4, 1864 -July 28, 1940) was a naval architect and engineer of the United States Navy. He served during World War I as Chief Constructor of the Navy, and Chief of the Bureau of Construction and Repair. Taylor is best known as the man who constructed the first experimental towing tank ever built in the The facility was previously known as the David W. Taylor Naval Ship Research and Development Center; it was renamed David Taylor Research Center (DTRC) in 1987 and later became the Carderock Division of the Naval Surface Warfare Center in 1992. Taylor, CEO of Procter and Gamble. David Taylor (Wisconsin judge), American jurist and legislator. David W. Taylor, U.S. Navy admiral and engineer. David Taylor (banker), banker. David W. Taylor. Rear Admiral David Watson Taylor, USN (March 4, 1864 -July 28, 1940) was a naval architect and engineer of the United States Navy. He served during World War I as Chief Constructor of the Navy, and Chief of the Bureau of Construction and Repair. Taylor is best known as the man who constructed the first experimental towing tank ever built in the United States.</figDesc><table coords="4,114.42,70.33,366.44,271.97"><row><cell>Runs</cell><cell>Rank</cell><cell>Related</cell><cell>Passage</cell></row><row><cell>YorkU21a</cell><cell>1</cell><cell>3</cell><cell>Rear Adm. United States.</cell></row><row><cell>YorkU21a</cell><cell>2</cell><cell>0</cell><cell>World Champ David taylor the magic man. World Champ. David</cell></row><row><cell></cell><cell></cell><cell></cell><cell>taylor the magic man. David Taylor, widely known as The Magic</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Man, is a 4x NCAA All-American, 4x BIG 10 Champion, and a 2x</cell></row><row><cell></cell><cell></cell><cell></cell><cell>NCAA Champion -and he just getting started. Having wrapped</cell></row><row><cell></cell><cell></cell><cell></cell><cell>up his NCAA career in March of 2014, David is just getting started</cell></row><row><cell></cell><cell></cell><cell></cell><cell>on his international career and ultimately, his quest for Gold in</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Tokyo, 2020.</cell></row><row><cell>YorkU21a</cell><cell>3</cell><cell>0</cell><cell>Taylor is best known for his contributions to microhistory, exem-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>plified in his William Cooper's Town: Power and Persuasion on</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the Frontier of the Early American Republic (1996). Using court</cell></row><row><cell></cell><cell></cell><cell></cell><cell>records, land records, letters and diaries, Taylor reconstructed the</cell></row><row><cell></cell><cell></cell><cell></cell><cell>background of founder William Cooper from Burlington, New Jer-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>sey, and the economic, political and social history related to the</cell></row><row><cell></cell><cell></cell><cell></cell><cell>land speculation, founding and settlement of Cooperstown, New</cell></row><row><cell></cell><cell></cell><cell></cell><cell>York, after the American Revolutionary War.</cell></row><row><cell cols="4">Anserini BM25 History. Anserini BM25 1 2 2 2 David S. David Taylor (veterinarian), television presenter on animal sub-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>jects.</cell></row><row><cell>Anserini BM25</cell><cell>3</cell><cell>3</cell><cell>Rear Adm.</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This research is supported by the <rs type="funder">Natural Sciences and Engineering Research Council (NSERC) of Canada</rs> and the <rs type="institution">York Research Chairs (YRC) program</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,74.13,493.32,464.45,6.58;4,74.13,501.29,149.54,6.58" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,196.42,493.32,255.99,6.58">Information retrieval on internet using meta-search engines : A review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manoj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elizabeth</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,462.99,493.32,75.59,6.58;4,74.13,501.29,67.87,6.58">Journal of Scientific Industrial Research</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="739" to="746" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,517.23,338.89,6.58;4,410.45,517.23,128.13,6.58;4,74.13,525.20,370.75,6.58" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,74.13,525.20,84.84,6.58">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">! Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,176.12,525.20,181.82,6.58">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,541.14,464.45,6.58;4,74.13,549.11,229.47,6.58" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,334.95,541.14,203.63,6.58;4,74.13,549.11,81.25,6.58">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,74.13,565.05,464.45,6.58;4,74.13,573.02,464.45,6.58;4,74.13,580.99,400.03,6.58" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,422.70,565.05,61.08,6.58">Okapi at TREC-4</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Gatford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Payne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,131.54,573.02,189.06,6.58">Proceedings of The Fourth Text REtrieval Conference</title>
		<editor>
			<persName><forename type="first">Donna</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>The Fourth Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-11-01">1995. November 1-3, 1995. 1995</date>
			<biblScope unit="volume">500</biblScope>
		</imprint>
		<respStmt>
			<orgName>NIST Special Publication. National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,596.93,464.45,6.58;4,74.13,604.90,87.16,6.58" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,256.54,596.93,243.61,6.58">Modeling term proximity for probabilistic information retrieval models</title>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><forename type="middle">Xiangji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaofeng</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,507.10,596.93,28.32,6.58">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="3017" to="3031" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,620.84,464.45,6.58;4,74.13,628.81,45.74,6.58" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m" coord="4,201.19,620.84,246.49,6.58">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<imprint>
			<date type="published" when="2019-08">August 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,644.75,464.45,6.58;4,74.13,652.72,444.28,6.58" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,214.62,644.75,242.72,6.58">Anserini: Enabling the use of lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,474.06,644.75,64.52,6.58;4,74.13,652.72,357.61,6.58">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,668.66,464.45,6.58;4,74.13,676.63,50.88,6.58" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,203.50,668.66,113.89,6.58">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,333.43,668.66,123.06,6.58">TREC-2: Text retrieval conference</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">500215</biblScope>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,692.57,464.45,6.58;4,74.13,700.54,240.61,6.58" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,400.44,692.57,138.13,6.58;4,74.13,700.54,121.00,6.58">Applying machine learning to text segmentation for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fuchun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Cercone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,201.78,700.54,32.91,6.58">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="333" to="362" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,716.48,464.45,6.58;4,74.13,724.45,464.45,6.58;4,74.13,732.42,400.03,6.58" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="4,218.04,716.48,163.59,6.58">York university at TREC 2005: Genomics track</title>
		<author>
			<persName coords=""><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,102.92,724.45,253.63,6.58">Proceedings of the Fourteenth Text REtrieval Conference, TREC 2005</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lori</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>the Fourteenth Text REtrieval Conference, TREC 2005<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">November 15-18, 2005. 2005</date>
			<biblScope unit="page" from="500" to="266" />
		</imprint>
		<respStmt>
			<orgName>NIST Special Publication. National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="4,74.13,748.36,464.45,6.58;4,74.13,756.33,464.45,6.58;4,74.13,764.30,464.45,6.58;4,74.13,772.27,161.03,6.58" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="4,187.82,748.36,347.67,6.58">A bayesian learning approach to promoting diversity in ranking for biomedical information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qinmin</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,422.13,756.33,116.45,6.58;4,74.13,764.30,388.71,6.58">Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Javed</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</editor>
		<meeting>the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">July 19-23, 2009. 2009</date>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
	<note>SIGIR 2009</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
