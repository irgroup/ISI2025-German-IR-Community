<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,74.85,79.85,445.58,12.90;1,231.47,95.79,132.33,12.90">IITD-DBAI: Multi-Stage Retrieval with Pseudo-Relevance Feedback and Query Reformulation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,249.26,133.82,99.75,10.75"><forename type="first">Shivani</forename><surname>Choudhary</surname></persName>
							<email>shivani@sire.iitd.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Delhi</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,74.85,79.85,445.58,12.90;1,231.47,95.79,132.33,12.90">IITD-DBAI: Multi-Stage Retrieval with Pseudo-Relevance Feedback and Query Reformulation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">046F771FC76E96DF0B2B299594A7A7AC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Conversational systems have acquired the center stage in NLP research. Compared to the conventional information retrieval task where we have to extract the passage or document from a vast collection of documents, the Conversational system requires extracting related information to respond to a series of questions. The turns in the conversation may follow the previous question. Complexity in this task arises due to the way we form the queries, which often have a reference to previous information using pronouns, co-reference. The presence of pronouns and unresolved co-references induces ambiguity in the query. Resolving the contextual dependency is one of the most challenging tasks in the Conversational system.</p><p>The Conversational assistance track (CAsT) has started in 2019. The long-term vision of the CAsT is "to support natural conversations between a person and a search engine to satisfy information needs and support complex information tasks". The task in both years of CAsT remained the same, to retrieve relevant passages depending upon the context evolution from the subsequent queries. raw_utterance CAsT-2019 had two tacks viz: automatic and manual track. Under Automatic track, response extraction was based on the raw utterances while the manual track has queries rewritten by humans. Co-reference and pronouns were resolved in the manually rewritten queries based on the historical context. Manually rewritten queries contain all of the information required to represent the single turn of the underlying information need. In CAsT-2019, additional information like description and title for the session was also provided <ref type="bibr" coords="1,232.27,687.30,58.23,9.46;1,70.87,700.85,23.01,9.46" target="#b1">(Dalton et al., 2020)</ref>. Three corpora, namely MSMARCO, TREC CAR (Wikipedia) paragraph Corpus V2.0 1 were used. Initially, it had also considered WaPo, but it was later dropped. CAsT-2020 had some changes, 1 http://trec-car.cs.unh.edu/datareleases/ title and description was removed from the query info, and document id as a canonical response to the query is added in the task. CAsT-2020 had three tracks -automatic, automatic-canonical, and manual. Under automatic, only raw utterance is to be used, while automatic-canonical can use the provided canonical response. The manual track was similar to last year based on the manually rewritten queries <ref type="bibr" coords="1,340.35,529.99,86.14,9.46" target="#b2">(Dalton et al., 2021)</ref>. The dataset was MS-MARCO and CAR <ref type="bibr" coords="1,390.06,543.54,77.80,9.46" target="#b3">(Dietz et al., 2018)</ref>. CAsT-2021 has three tracks similar to CAsT-2020, but with a modification that we need to extract a specific passage out of the extracted document. The idea of specific passage to be extracted from the document centered around the idea that responses should be crisp and could be used by automatic voice assistants like Alexa, Google, etc. CAsT-2021 used MSMARCO (2019/20 dump), WAPO-2020 and KILT <ref type="bibr" coords="1,332.71,665.48,88.02,9.46" target="#b6">(Petroni et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Description</head><p>In CAsT track, A conversation session S has a series of utterances {u 1 , u 2 , u 3 , u 4 . . .} called as turns. Our task is to predict a set of top-K passages from the collection for each turn.</p><p>Tracks: There are three tracks of submission Dataset: CAsT-2021 uses two dataset corpus for the task -MSMARCO, KILT <ref type="bibr" coords="2,200.49,321.98,89.38,9.46" target="#b6">(Petroni et al., 2021)</ref> and WAPO.</p><p>We have attempted the Automatic track. Each turn (Queries) in this session is raw in nature. The onus to resolve references and pronouns lies on the model itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Motivation and Method</head><p>We have gone through the CAsT-2020 submissions, and most of the models were multistage models. In the initial stage, a set of documents were retrieved from the collection, followed by re-ranking using neural model. Most of the models used query rewriting using generative model based on Transformer architecture <ref type="bibr" coords="2,162.03,521.98,99.45,9.46" target="#b7">(Vaswani et al., 2017)</ref>. For query rewriting, T5, BART, GPT-2 was used, and the re-ranker engine was based on BERT, ALBERT, and T5.</p><p>Our retrieval framework has three components: Query rewrite, document retrieval with pseudorelevance feedback, and neural engine-based reranker. The Query rewrite framework is based on chatty-goose 2 and re-ranker is based on pygaggle 3 . Core retrieval engine is based on the HQE <ref type="bibr" coords="2,263.51,644.83,25.63,9.46;2,70.87,658.38,52.11,9.46" target="#b8">(Yang et al., 2019)</ref> and PQE (Al-Thani et al.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Historical Query expansion (HQE)</head><p>This step is based on the submission from CAsT-2019 <ref type="bibr" coords="2,96.27,716.71,81.77,9.46" target="#b8">(Yang et al., 2019)</ref>. It is a three-stage algorithm. In the first step, it extracts the keyword for 2 https://github.com/castorini/chatty-goose 3 https://github.com/castorini/pygaggle the session and query level followed by measurement of ambiguity in query in second step, and in the last stage, query expansion with the session keyword and query level keyword is done.</p><p>A keyword is deemed important if it strongly relates with the documents in the index. HQE uses BM25 score between a keyword and its highestranked document in the index as its measure of importance. HQE computes this measure for each token in every utterance when presented with a topic. The most informative ones are then selected for query expansion. For a given topic, keywords can be locally important (i.e., it strongly relates to the topic being discussed in the current utterance) or globally important (i.e., it relates to the overall conversation theme). HQE thus creates two sets of expansion keywords, session and query, during the extraction phase. Whether the keyword is considered a session keyword or a query keyword is decided by two separate cutoffs, Q s , and Q t . If the importance score of a keyword is greater than either of the cutoff scores, it is added to corresponding expansion sets. Note that session keywords are always used for expansion, while query keywords are only used when current utterance is identified as ambiguous. An utterance is deemed ambiguous when BM25 score between it and its highest ranked document in index is low (i.e. by itself utterance is not important). If the ambiguity score is less than a certain threshold θ, then the query expansion will take place with query keywords.</p><p>The cutoff values for Q s , Q t , and θ determine the performance of HQE. We follow a greedy approach to find the optimal values of these cutoffs. Note that a query is always expanded with current session keywords and occasionally with preceding query keywords. Thus, we start by tuning Q s session cutoff. We set Q t and θ to arbitrarily high values allowing query expansion only via session keywords. Then we do a line search for Q s over the training set. Second, we set Q t to some fixed value (&gt; Q s ) and in similar fashion tune θ. Finally, we tune Q s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Passage Query Expansion (PQE)</head><p>Pseudo-relevance feedback enriches the query by incorporating features from top-k relevant documents. PQE uses a pseudo-relevance feedback mechanism as follows:</p><p>• The expanded query is from HQE is used to fetch an initial set of top-k documents. These Run Name K1 b NDCG@3 NDCG@5 P@5 AP@500 IITD-RAW_U_T5_1 0.9 0.4 documents combined together form the corpus of responses for the query.</p><p>• Individual tokens in the corpus are scored using TF-IDF. An IDF vector is pre-computed on complete MSMARCO documents.</p><p>• The topmost unique tokens are then considered for query expansion.</p><p>Note that PQE can be computationally prohibitive since it involves complete document retrieval. In order to avoid this, <ref type="bibr" coords="3,159.24,316.78,73.53,9.46">(Al-Thani et al.)</ref> proposes to use a simple rule to decide whether a query is to be expanded using PQE or not. (Al-Thani et al.) only perform PQE expansion when the query has at least one pronoun. This process has two HyperParameters, top-k documents, and top-k tokens from the document based on the TF-IDF score. The TF-IDF score helps the system to select the important terms. While selecting the term, we have also placed a criterion that it should have a DF between 0.001 and 0.2. In the PQE step, we noticed that some digits also appeared in top-k terms. Later, we filter out those instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">T5 query rewriter and reranker</head><p>In automatic track, query are presented in the bare format. In order to preserve the context of the query, we have used query rewriter. It uses T5 based model<ref type="foot" coords="3,127.92,576.29,3.99,6.91" target="#foot_0">4</ref> . The model is trained on CANARD dataset <ref type="bibr" coords="3,104.79,591.89,101.16,9.46" target="#b4">(Elgohary et al., 2019)</ref> that contains a set of rewritten queries based upon the history. To produce a n th rewitten utterance, we have supplied history of turns {u 1 , u 2 , u 3 , u 4 . . . , u n-1 } concatenated with u n . Reformulated queries were used for the final stage ranking of passages.</p><p>On the other hand T5 based ranking model <ref type="bibr" coords="3,70.51,687.49,90.24,9.46" target="#b5">(Nguyen et al., 2016)</ref> is trained on the MSMARCO, Robust04, Core17 and Core18. This model takes query Q and a list of passages {p 1 , p 2 , p 3 , ..p n }. It returns submitted passages according to the descending order of their relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Document Indexing</head><p>All three datasets were pre-processed and converted into jsonl format. We have use Pyserini<ref type="foot" coords="3,479.74,188.77,3.99,6.91" target="#foot_1">5</ref> to generate an index for faster retrieval of documents. Index was generated with an option to keep a copy of raw documents. We choose this option because the raw content was required at HQE and PQE stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Matrix</head><p>CAsT-2021 used following matrix to present the results of the participants NDCG@3, NDCG@5, NDCG@500 and AP@500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>Index for the cleaned document was generated using Pyserini<ref type="foot" coords="3,359.36,378.84,3.99,6.91" target="#foot_2">6</ref> with the default setting. Default setting did not restrict us to keeping K1 and b fixed. It can be changed during the retrieval of the documents. First, we performed our extraction and tuning on the 2019 training set. The best performance for HQE was obtained with Q s = 4, Q t = 4, θ = 10 and PQE with top-k = 5, top-k token = 3.</p><p>We have participated in automatic track and submitted two runs in the CAsT-2021. Two different set of parameters for BM25, K1 = 0.9, b = 0.4 and K1 = 1.2, b = 0.75 was selected for the retrieval of the document. The MAP is very low in both the results, and the main issue lies with the recall. Our retrieval engine extracted the top 100 documents from the corpus. Extracted documents were later chunked and re-ranked. In this process, lower retrieval numbers left the ranker with fewer relevant chunks, resulting in a lower than expected performance.</p><p>IITD-RAW_U_T5_2 has produced a mean NDCG@3 performance better than the median model. Model's performance on evaluation query has a noticeable variation in scores compared with median scores. Results for queries like -115 and 119 were better than the median; however, results on the evaluation queries like -111 and 117 were worse than the median benchmark for NDCG@3. Analysis of query expansion term for the first stage retrieval suggests that query expansion term has carried the intent of the conversation to higher depths. While the poor performing queries have expansion terms with less relevant keywords, generic keywords. Query expansion terms for query 119 have terms like swelling, shaking, infection, ear that carried the conversation context to higher depth led to better performance.</p><p>We have also analyzed the hqe and pqe keywords for query expansion. We can take evaluation number 106; the first few queries are listed in Table-1. For turn 3, query expansion terms were biopsy, breast, deadly, cancer, comment and cell. This turn has only one term, "deadly", that can explain the intent of the query. But, it is too generic in nature which has led to poor recall. On the flip side, turn five is expanded with terms carcinoma, wow, deadly, situ, lobular, deadliness, biopsy, breast which has specific terms related to cancer like "lobular, situ, carcinoma" has a good recall. Here the word "specific" means relevance to the topic.</p><p>Our submission to CAsT-2021 aimed to preserve the key terms and the context in all subsequent turns and use classical Information retrieval methods. It was aimed to pull as relevant documents as possible from the corpus. It appears that it can retain some of the keywords in subsequent turns. But, it fails when the key term itself is generic. The performance of this model can be improved further by including the context word vectors in the HQE and PQE stages. Context vector-based selection may help to keep top-k terms that are relevant to the conversation theme.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,102.47,231.21,155.06,8.64;2,70.87,70.87,218.26,148.50"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Multi-stage retrieval pipeline</figDesc><graphic coords="2,70.87,70.87,218.26,148.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,76.84,87.60,446.03,46.00"><head>Table 2 :</head><label>2</label><figDesc>Evaluation score of Submitted manual runs</figDesc><table coords="3,337.22,87.60,185.65,9.46"><row><cell>0.3712</cell><cell>0.3631</cell><cell>0.5025</cell><cell>0.1759</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,87.01,765.19,168.50,7.77"><p>https://huggingface.co/castorini/t5-base-canard</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,322.28,754.34,129.82,7.77"><p>https://github.com/castorini/pyserini</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="3,322.28,765.19,129.82,7.77"><p>https://github.com/castorini/pyserini</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,70.87,583.81,220.01,8.64;4,81.78,594.77,207.36,8.64;4,81.78,605.73,207.36,8.64;4,81.78,616.68,209.02,8.64;4,81.78,627.64,163.90,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,81.78,594.77,38.46,8.64">HBKU at</title>
		<author>
			<persName coords=""><forename type="first">Haya</forename><surname>Al-Thani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><forename type="middle">J</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
		<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
	</analytic>
	<monogr>
		<title level="m" coord="4,123.29,594.77,165.85,8.64;4,81.78,605.73,207.36,8.64;4,81.78,616.68,209.02,8.64;4,81.78,627.64,159.39,8.64">TREC 2020: Conversational Multi-Stage Retrieval with Pseudo-Relevance Feedback; HBKU at TREC 2020: Conversational Multi-Stage Retrieval with Pseudo-Relevance Feedback</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,70.87,651.36,220.01,8.64;4,81.78,662.32,207.36,8.64;4,81.47,673.28,137.69,8.64" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,110.29,662.32,178.85,8.64;4,81.47,673.28,62.15,8.64">CAsT 2019: The Conversational Assistance Track Overview</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="4,70.87,696.99,220.01,8.64;4,81.78,707.95,207.36,8.64;4,81.47,718.91,137.69,8.64" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,110.29,707.95,178.85,8.64;4,81.47,718.91,62.15,8.64">CAsT 2020: The Conversational Assistance Track Overview</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="4,70.87,742.62,218.52,8.64;4,81.78,753.58,207.36,8.64;4,81.78,764.37,79.59,8.81" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,160.14,753.58,129.00,8.64;4,81.78,764.54,34.10,8.64">Trec complex answer retrieval overview</title>
		<author>
			<persName coords=""><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manisha</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,189.64,742.62,99.75,8.64;4,81.78,753.58,33.70,8.64">Filip Radlinski, and Nick Craswell</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="4,306.14,75.34,219.92,8.64;4,317.05,86.30,207.36,8.64;4,317.05,97.09,207.36,8.81;4,317.05,108.05,132.04,8.58" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,381.40,86.30,143.01,8.64;4,317.05,97.26,110.51,8.64">Can you unpack that? learning to rewrite questions-in-context</title>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Denis</forename><surname>Peskov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,447.41,97.09,77.00,8.58;4,317.05,108.05,127.83,8.58">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,306.14,128.14,218.27,8.64;4,317.05,139.10,207.36,8.64;4,317.05,150.06,207.36,8.64;4,317.05,160.85,208.60,8.81;4,317.05,171.98,65.86,8.64" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,384.78,150.06,139.64,8.64;4,317.05,161.02,166.39,8.64">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>CoRR, abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,306.14,191.90,218.52,8.64;4,317.05,202.86,207.36,8.64;4,316.74,213.82,207.67,8.64;4,317.05,224.78,207.36,8.64;4,317.05,235.74,207.53,8.64;4,317.05,246.53,207.36,8.81;4,317.05,257.49,209.01,8.58;4,317.05,268.45,209.02,8.58;4,316.69,279.40,208.96,8.81;4,317.05,290.53,204.23,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,425.85,235.74,98.73,8.64;4,317.05,246.70,140.16,8.64">KILT: a benchmark for knowledge intensive language tasks</title>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Majid</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><forename type="middle">De</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.200</idno>
	</analytic>
	<monogr>
		<title level="m" coord="4,475.06,246.53,49.35,8.58;4,317.05,257.49,209.01,8.58;4,317.05,268.45,209.02,8.58;4,316.69,279.40,126.84,8.58">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2523" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,306.14,310.46,218.27,8.64;4,317.05,321.42,207.36,8.64;4,317.05,332.38,207.36,8.64;4,316.80,343.17,136.97,8.81" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="4,463.85,332.38,60.56,8.64;4,316.80,343.33,34.47,8.64">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>CoRR, abs/1706.03762</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,306.14,363.26,219.52,8.64;4,316.86,374.22,207.55,8.64;4,317.05,385.18,207.36,8.64;4,316.49,395.97,26.85,8.58" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="4,482.11,374.22,42.30,8.64;4,317.05,385.18,183.88,8.64">Query and answer expansion from conversation history</title>
		<author>
			<persName coords=""><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,316.49,395.97,21.48,8.58">TREC</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
