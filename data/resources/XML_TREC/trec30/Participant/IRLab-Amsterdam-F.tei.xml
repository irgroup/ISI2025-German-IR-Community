<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,121.82,84.23,368.29,15.44;1,231.07,104.15,150.36,15.44">The University of Amsterdam at the TREC 2021 Fair Ranking Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,156.72,134.31,57.54,10.59"><forename type="first">Ali</forename><surname>Vardasbi</surname></persName>
							<email>a.vardasbi@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.23,134.31,78.81,10.59"><forename type="first">Gabriel</forename><surname>Bénédict</surname></persName>
							<email>g.benedict@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.04,134.31,77.02,10.59"><forename type="first">Shashank</forename><surname>Gupta</surname></persName>
							<email>s.gupta2@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,394.48,134.31,61.38,10.59"><forename type="first">Maria</forename><surname>Heuss</surname></persName>
							<email>m.c.heuss@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.08,148.25,70.90,10.59"><forename type="first">Pooya</forename><surname>Khandel</surname></persName>
							<email>p.khandel@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.37,148.25,36.84,10.59"><forename type="first">Ming</forename><surname>Li</surname></persName>
							<email>m.li@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.25,148.25,69.66,10.59"><forename type="first">Fatemeh</forename><surname>Sarvi</surname></persName>
							<email>f.sarvi@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,121.82,84.23,368.29,15.44;1,231.07,104.15,150.36,15.44">The University of Amsterdam at the TREC 2021 Fair Ranking Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4DCD8C2CBE2D937B649240514BA00EAA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TREC 2021 fair ranking track is composed of two tasks, intended to help WikiProject coordinators, with a static ranking of 1000 pages (Task1), as well as WikiPedia editors, with a stochastic ranking of 50 pages (Task2). The rankings should be fair with respect to geographical locations as well as an undisclosed demographic attribute. We have used a lexical matching method to detect two demographic attributes, namely gender and sexuality. For the static ranker of Task1, we tried a method based on swapping the items that result in largest marginal gain for the relevance-fairness compound objective. We have seen that the greedy pairwise swapping method leads to better results compared to other variants. For the probabilistic ranker of Task2, we used two sampling approaches. The first one is based on an existing control-theory inspired algorithm, and it leads to the best overall performance among our submissions. The second approach uses a two-stage Plackett-Luce and achieves very good disparity performance (in terms of EE-D), but overall, its performance is dominated by the first approach due to its low ranking performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The TREC 2021 Fair Ranking Track aims at helping Wikipedia editors involved in the WikiProject to find articles that need editing via fair recommendations: provide exposure to Wikipedia articles related to protected groups, otherwise underrepresented in the Wikipedia corpus.</p><p>The corpus consists of a subset of Wikipedia pages and a set of queries, and there are two main tasks defined for this year. The goal of each task is to rank documents for a given query (a WikiProject) so that the ranking is: (1) relevant to the query, and (2) fair to articles that represent a protected demographics or attributes.</p><p>Our methods for the TREC 2021 Fair Ranking Track are:</p><p>• Enriching fairness features by adding some demographic attributes representing gender and sexuality of each Wikipedia page. • A pairwise and a listwise approach for maximizing the objective function for Task1, based on swapping items that result in largest marginal gain for the objective.</p><p>Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). TREC 2021, November 17-19, 2021, Gaithersburg, Md. USA © 2021 Copyright held by the owner/author(s).</p><p>• Developing a probabilistic ranker that samples rankings from a probability distribution for Task2 based on (1) control-theory inspired from <ref type="bibr" coords="1,413.54,227.97,9.63,7.94" target="#b3">[4]</ref>; and (2) a two-stage Plackett-Luce approach.</p><p>Among all our submissions, for the Task1, we achieve our best results using the greedy pairwise swapping approach. For Task2 we achieve the best disparity score (measured by EE-D) with one of the two stage Plackett-Luce approaches, but the best relevance score (measured by EE-R) and overall score (EE-L) with one of the control-theory inspired rankers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BUILDING BLOCKS 2.1 Ranking Features</head><p>We extract two types of features from the dataset: Term-based features and BERT-based features.</p><p>We consider Corpus and Topics that contain document and query information to extract term-based features. Specifically, we found that using key_words column from topics as representative of query information along with text column from corpus as representative of document information for extracting term-based features would be effective for our tasks. To this end, we extract all features based on term and document frequency in addition to BM25 score similar to feature extraction of MSLR <ref type="bibr" coords="1,428.52,459.64,10.55,7.94" target="#b6">[7]</ref> dataset.</p><p>For the BERT-based features, we use the pre-trained BERT model<ref type="foot" coords="1,555.24,468.45,3.38,6.44" target="#foot_0">1</ref> to generate embeddings for query and document separately. After that, we compute the semantic relevance feature between the query and document via simple dot product between the query embedding vector and the document embedding vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relevance Estimation</head><p>Our submissions are based on either post-processing an unfair ranker, or using the relevance probability of each page. For both cases, we need a calibrated ranker which does not consider the sensitive features. We have tested the following learning to rank (LTR) algorithms:</p><p>(1) LambdaMART <ref type="bibr" coords="1,396.87,609.86,9.38,7.94" target="#b0">[1]</ref>: A well-known pair-wise approach that is usually among the top performing LTR methods. It directly optimizes the ranking evaluation metric, i.e., normalized discounted cumulative gain (NDCG), by including the difference of NDCG caused by swapping each pair of items in a list, while leaving other items fixed at their position. We used the LightGBM implementation <ref type="bibr" coords="1,476.17,675.61,9.39,7.94" target="#b2">[3]</ref>.</p><p>(2) ListNet <ref type="bibr" coords="2,106.95,87.79,9.47,7.94" target="#b1">[2]</ref>: A high performing list-wise approach that uses softmax to compute the distribution of a permutation. (3) Pointwise RMSE: A 5-layer neural network (NN) with root mean-square error (RMSE) loss. (4) Logistic regression: we use Scikit-Learn's <ref type="bibr" coords="2,229.41,131.63,10.46,7.94" target="#b5">[6]</ref> logistic regression module with default settings and a sag solver.</p><p>Using 5-fold validation on the training data, we select the Lamb-daMART model and calibrate its output scores using sigmoid calibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Demographic Attributes</head><p>Wikipedia is used as a reference to discover demographic attributes that are observable in the population. Each demographic attribute (e.g. gender) has its corresponding groups (male, female, non-binary).</p><p>We considered the following demographic attributes: gender, sexuality, ethnicity, religion. Ethnicity and religion were sparse in the data and ethnicity can take a lot of forms in Wikipedia and revolve around an American point of view. We thus only kept gender and sexuality.</p><p>The textual content of the articles in the given Wikipedia corpus is used to determine allocation to these groups. The first step is to determine whether that person is or has been a living human (as opposed to fictional characters). The former are characterized by having a reported birth and eventually death year. We thus filtered out any data not containing a sentence of the sort : "1954 births", "1999 deaths". Any article that is referred to bellow, thus refers to an article about a real person.</p><p>Next, gender is determined by searching for women ["female", "woman", "women"], men ["male", "man", "men", "pharaoh", "military", "duke", "king", "prince "] and non-binaries [" trans ", "queer", "non-binary", "transgender"]. The Wikipedia page on non-binary genders is used as a reference <ref type="foot" coords="2,164.48,432.03,3.38,6.44" target="#foot_1">2</ref> . If terms of different groups were present, we attributed a unique group using the following order of precedence: non-binary, female, male. If none of the terms above could be found, it is considered an unknown gender.</p><p>Regarding sexuality, the reductive binary classification heterosexual VS LGBTQ+ is used. The reference to LGBTQ+ terms are rare in Wikipedia (only 13437 in our corpus of 4𝑀+), it seemed reasonable to aggregate them: ["LGBT", "homosexual", "bisexual", "queer", "lesbian", "gay "]. By opposition, any article that does not contain these words is assigned the heterosexual category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TASK1: WIKIPROJECT COORDINATORS</head><p>In the first task, the ranker should produce a static ranked list of 1000 pages. The ranked list should be fair in terms of attention-weighted rank fairness (AWRF) <ref type="bibr" coords="2,133.75,591.00,10.44,7.94" target="#b7">[8]</ref> and the submissions are ranked based on their nDCG × AWRF. Since we do not have access to the relevance scores, nor to all the fairness attributes, we have to estimate both nDCG and AWRF for the test set. As a proxy for nDCG, we compute the DCG of the list using the calibrated outputs of our (unfair) ranker (Sec. 2.2). For the AWRF computation, we use the geographic tags together with the extracted demographic attributes (Sec. 2.3). We set the objective of our re-ranker to maximize the multiplication of these two proxy values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pairwise Swaps</head><p>Starting from the unfair ranking which maximizes the DCG but does not consider AWRF, we iteratively swap items which result in the largest marginal gain for the objective. We continue until the largest marginal gain falls below a threshold. This approach is inspired by the greedy maximization of submodular functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Listwise Updates</head><p>We also tried listwise score updates for maximizing the DCG × AWRF. In this approach, at each iteration, the score of each item is updated with respect to the aggregated gain in the objective caused by swapping that item with other items in the list. In other words, for each item 𝑖, we measure the objective gain caused by swapping 𝑖 with items 𝑗 ≠ 𝑖 and use the average of these values as the aggregated gain of item 𝑖. Then, we update the score of item 𝑖 with a constant fraction of this aggregated gain (similar to updates in gradient descent using a constant learning rate). The scores are initialized by the calibrated output of our (unfair) ranker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TASK2: WIKIPEDIA EDITORS</head><p>In the second task, a stochastic ranker should produce a sequence of lists of 50 pages. The ranker should consider both relevance and work-needed for each page, while being fair with respect to geographic tags and an undisclosed demographic attribute. We tried two different approaches for this task: (1) Control-theory inspired probabilistic ranker; and (2) Two-stage Plackett-Luce ranker. In this section we explain these two approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Control-Theory Inspired Probabilistic Ranker</head><p>For this ranker we took inspiration from <ref type="bibr" coords="2,473.97,470.51,9.52,7.94" target="#b3">[4]</ref>, where the authors use a control-theory inspired ranker. In each sampling step, the over/under representation of item groups is measured based on a weighted sum of the predicted relevance score. This orders the items into the next ranking. We use a Plackett-Luce model <ref type="bibr" coords="2,547.52,514.34,10.68,7.94" target="#b4">[5]</ref> which draws from a probability distribution given by this linear combination of score and advantage.</p><p>Let 𝐷 be the collection of items, that we want to rank for a given query q. We use a position based user model that assumes that the expected exposure of a document 𝑑 in a ranking 𝜋 is purely dependent on it's rank</p><formula xml:id="formula_0" coords="2,383.87,577.83,106.13,14.24">E (𝑑 | 𝜋) = 1 𝑙𝑜𝑔 2 (1+𝑟𝑎𝑛𝑘 (𝑑 |𝜋 ))</formula><p>. In this approach we use only the geographical attribute to define groups, using the Plackett-Luce sampling to achieve some level of individual fairness as well. The expected exposure of the items of each geographic group 𝐺 can be determined by the sum of the expected exposure of all it's items:</p><formula xml:id="formula_1" coords="2,393.31,652.36,164.89,18.64">E (𝐺 | 𝜋) = 𝑑 ∈𝐺 E (𝑑 | 𝜋)<label>(1)</label></formula><p>Given a sequence Π = {𝜋 𝑖 } of sampled rankings that we show to the users, the total expected exposure of 𝐺 can be calculated by aggregating the expected exposure of this group in each individual ranking:</p><formula xml:id="formula_2" coords="3,125.48,102.46,168.56,18.68">E (𝐺 | Π) = 𝜋 𝑖 ∈Π E (𝐺 | 𝜋 𝑖 )<label>(2)</label></formula><p>To determine the target exposure we work with a mix of disparate treatment and demographic parity. The total exposure that will be (in expectation) available for one top-𝑘 ranking is given by (𝑖) . We first calculate the merit 𝑀 (𝐺) of group 𝐺 as the sum of the relevance scores 𝑟 𝑑 of the items in the group and get:</p><formula xml:id="formula_3" coords="3,53.53,157.27,49.43,14.24">𝐴 = 𝑘 𝑖=1 1 𝑙𝑜𝑔 2</formula><formula xml:id="formula_4" coords="3,129.69,195.27,164.35,19.34">E * disp (𝐺) = 𝑑 ∈𝐺 𝑟 𝑑 𝑑 ∈𝐷 𝑟 𝑑 • 𝐴<label>(3)</label></formula><p>As relevance scores 𝑟 𝑑 we use the product of the work-needed feature and the relevance score predicted with LambdaMART 2.2.</p><p>To get the final target exposure, we average this with share of the total exposure that the group should get based on the proportion of group 𝐺 in the total population, pop 𝐺 , to get as final target exposure for group 𝐺:</p><formula xml:id="formula_5" coords="3,120.46,280.37,173.59,26.25">E * (𝐺) = E * disp (𝐺) + pop 𝐺 •𝐴 2<label>(4)</label></formula><p>The target exposure for a sequence of 𝑡 rankings is given by E * 𝑡 (𝐺) = 𝑡 • E * (𝐺). Note that the target exposure is calculated based on relevance labels that have previously been estimated, which means that what we call target exposure here is merely an estimation of the actual target exposure that is unknown to us. Now for sampling a ranking, we start with calculating the aggregated expected exposure that each item group has collected over the course of all previously sampled rankings. Based on the estimated target exposure E * 𝑡 -1 (𝐺) and the aggregated exposure E 𝑡 -1 (𝐺) of each group 𝐺 we now calculate the advantage as</p><formula xml:id="formula_6" coords="3,60.67,421.45,108.15,12.73">𝐴 𝑡 (𝐺) = E 𝑡 -1 (𝐺) -E * 𝑡 -1 (𝐺)</formula><p>2 sign E 𝑡 -1 (𝐺) -E * 𝑡 -1 (𝐺) . (5) Combining the Advantage 𝐴 𝑡 (𝐺) with the originally estimated relevance score 𝑟 𝑑 , an adjusted score is calculated as</p><formula xml:id="formula_7" coords="3,110.40,466.18,183.64,8.43">ℎ 𝑑,𝑡 = min(0, 𝜃𝑟 𝑑 -(1 -𝜃 )𝐴 𝑡 (𝐺)).<label>(6)</label></formula><p>for some 𝜃 ∈ [0, 1]. These adjusted scores are now used to define a Plackett-Luce model from which we iteratively sample items to put in our ranked list. The goal of this method is that, by adding some randomization, our method will provide a more fair representation for groups that we do not consider explicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Two-stage Plackett-Luce Ranker</head><p>Inspired by the Plackett-Luce used in individual fairness, we use a simple two-stage Plackett-Luce based ranker to take both group fairness and work-needed into consideration.</p><p>For relevance evaluation, we trained a logistic regression model to get the relevance probability of available documents. Given a query 𝑞, we calculate the relevance probability 𝑝 of every document in the collection via the model. We only focus on the documents with relatively high relevance probability, since the number of candidate documents is large and the non-relevant documents would not contribute the relevance evaluation. We consider the document with a probability higher than a threshold 𝑣 as relevant, 𝑣 is a hyper-parameter.</p><p>The first ranking stage ensures group fairness. Given the number of possible relevant items 𝐶 𝑔 of each geographical group and the </p><formula xml:id="formula_8" coords="3,360.99,261.10,197.21,51.85">𝐷 (𝑔) 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 = 𝐶 𝑔 𝑔 ∈𝐺 𝐶 𝑔 (7) D * (𝑔) = 𝐷 (𝑔) 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 + 𝐷 (𝑔) 𝑝𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛 2 (8)</formula><p>where 𝐷 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 is the relevant documents distribution over different groups; 𝐷 𝑝𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛 is the population distribution over different groups.</p><p>We aim to add a constraint at this stage to help with group fairness. Specifically, we generate a candidate pool which is associated with the target group distribution. Given the target distribution, we can derive the desired number of documents for each group:</p><formula xml:id="formula_9" coords="3,411.26,394.96,52.78,10.43">𝑐 𝑔 = 𝐿 • D * (𝑔)</formula><p>where 𝐿 is the required list length.</p><p>Within each group, we use PL sampling to select 𝑐 𝑔 candidate documents according to the relevance probability. Since 100 ranking are desired, we repeat this generation process to get 100 candidate pools to avoid that the 100 rankings only consist of the same group of documents. Note that this repeated process naturally helps with the individual fairness. The candidate pools will be used in the second stage.</p><p>The second stage accounts for the work needed factor. For each candidate pool, we multiply the work-needed factor 𝑤 and the relevance probability of documents in this candidate pool and get the score:</p><formula xml:id="formula_10" coords="3,416.81,547.06,41.31,7.93">𝑠 𝑤𝑝 = 𝑝 • 𝑤</formula><p>These scores 𝑠 𝑤𝑝 will be used to define the second level PL model and generate a rank list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS AND DISCUSSION 5.1 Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1 contains the average performance of our submissions for</head><p>Task1. There are four submissions for Task1 as follows:</p><p>(1) 1step_pair_list: For each test query, we re-ranked by both pairwise (Sec. 3.1) and (Sec. 3.2) approaches and selected the output with the highest objective. (2) 1step_pair: Only the pairwise approach.</p><p>(3) 2step_pair_list: Similar to 1step_pair_list, but on the output of 1step_pair_list, instead of the unfair initial ranker. Among the above four submissions, the 1step_pair reaches the highest nDCG and AWRF score, though the difference between different submissions seems to be insignificant. Table <ref type="table" coords="4,86.36,315.72,4.25,7.94" target="#tab_1">2</ref> shows the results for Task2. For the control theory inspired probabilistic ranker we experiment with different values for the hyperparameter 𝜃 . The results of the experiments with values 𝜃 = 0.6, 0.8, 0.92 can be found in the rows with name PL_control_𝜃 . Among these submissions PL_control_0.92 reaches the best (lowest) EE-D score, and PL_control_0.6 reaches the highest and hence best value for EE-R, and the total score, EE-L. For two-stage Plackett-Luce Ranker, we experiment with different values of relevance threshold 𝑣 = 0.5, 0.7, the corresponding results can be found in rows with name PL_IRLab_𝑣.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discussion</head><p>Looking at the Task1 results in Table <ref type="table" coords="4,189.49,451.89,3.04,7.94" target="#tab_0">1</ref>, we observe that the nDCG of all the four submissions is below the average median nDCG × AWRF. Since AWRF is always between [0, 1], this means the main weak point of our submissions for Task1 is its initial ranker. We hypothesize the problem with our initial ranker could be on the non-calibrated scores of the tree-based methods. To elaborate, we choose the ranker based on its ranking performance, but for Task1 we relied on our proxy estimations of DCG from the output scores of the ranker. An accurate estimation of DCG is only possible if the output of the ranker is calibrated. But as the output of our initial ranker is not calibrated, our DCG estimations are far from being accurate. For example, we observe the range of scores for each query lies in a small range, causing our re-rank approaches to treat liberally in swapping relevant and non-relevant items.</p><p>The results of the second task show that for the control theory inspired approach the lowest value of 𝜃 gives the best results in terms of EE-R, while the highest value of 𝜃 gives the best results for EE-D. This seems counter intuitive to us since we expected to see a trade off between EE-D and EE-R in the opposite direction. According to our assumptions, lower values for 𝜃 should favor groups with little exposure so far, leading to lower EE-R and higher fairness measured by EE-D. On the other hand all these scores lie fairly close together, when comparing them to the range of scores in the other submissions and might not be significant.</p><p>Compared with the controlled PL method, the two-stage Plackett-Luce method is able to generate several rankings in parallel. However, we identify two limitations of this method. (1) The logistic regression might be too weak to find the most relevant items, when comparing to modern LTR methods. (2) Because of the randomness of PL sampling, this method might perform better with a large number of ranking settings, however only 100 rankings are needed in Task2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this TREC track we have submitted nine runs, four for Task1 and five for Task2. We used LambdaMART as the initial (unfair) ranker and built our fair rankers on top of that. Though LambdaMART was chosen by cross-validation on the training queries, detailed results on the test queries show that for some queries a simple lexical matching method (such as BM25) would have performed better. It seems in the extremely low data regime of this track, one should use an ensemble of rankers and assign each query to one ranker based on the confidence or other similar measures.</p><p>Among our four runs for Task1, 1step_pair reaches the highest nDCG and AWRF score. The difference between different runs is not noticeable. The main weak point of our runs is its low ranking performance, as the average nDCG scores of all four runs falls below the average median nDCG × AWRF scores.</p><p>For Task2, our control-theory inspired method achieves the best overall result (𝐸𝐸 𝐿 = 15.50), very close to the average minimum score of 13.07. It has to be noted that the average minimum score is a lower bound for the best performance and may differ from it, as the minimum score may come from different runs for different queries. At the time of writing this report we do not have access to the results of other teams. Our two-stage Plackett-Luce method achieves very good disparity scores (EE-D), but due to its bad relevance score, the overall performance is worse than the average median. One reason for this could be the use of logistic regression-based ranker instead of LambdaMART.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,317.62,88.14,240.58,164.48"><head>Table 1 :</head><label>1</label><figDesc>Performance of our submissions for Task1.</figDesc><table coords="3,317.62,114.08,240.58,138.55"><row><cell></cell><cell cols="3">nDCG AWRF Score</cell></row><row><cell>1step_pair_list</cell><cell>0.082</cell><cell>0.691</cell><cell>0.062</cell></row><row><cell>1step_pair</cell><cell cols="3">0.084 0.694 0.065</cell></row><row><cell>2step_pair_list</cell><cell>0.079</cell><cell>0.691</cell><cell>0.061</cell></row><row><cell>2step_pair</cell><cell>0.082</cell><cell>0.694</cell><cell>0.064</cell></row><row><cell>average median</cell><cell></cell><cell></cell><cell>0.111</cell></row><row><cell>average min</cell><cell></cell><cell></cell><cell>0.002</cell></row><row><cell>average max</cell><cell></cell><cell></cell><cell>0.199</cell></row><row><cell cols="4">world geographical population information, we then generate the</cell></row><row><cell>target distribution D</cell><cell></cell><cell></cell><cell></cell></row></table><note coords="3,396.49,242.14,2.28,6.25;3,401.51,244.68,91.01,7.94"><p>* across groups as follows:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,64.71,88.18,213.16,187.18"><head>Table 2 :</head><label>2</label><figDesc>Performance of our submissions for Task2.</figDesc><table coords="4,64.71,114.11,209.22,161.24"><row><cell></cell><cell>EE-D EE-R</cell><cell>EE-L</cell></row><row><cell>PL_control_0.6</cell><cell cols="2">3.273 8.809 15.501</cell></row><row><cell>PL_control_0.8</cell><cell>3.254 8.665</cell><cell>15.77</cell></row><row><cell cols="2">PL_control_0.92 3.148 8.48</cell><cell>16.034</cell></row><row><cell>PL_IRlab_0.5</cell><cell>1.402 4.933</cell><cell>21.383</cell></row><row><cell>PL_IRlab_0.7</cell><cell>1.532 5.278</cell><cell>20.821</cell></row><row><cell>average median</cell><cell></cell><cell>20.635</cell></row><row><cell>average min</cell><cell></cell><cell>13.072</cell></row><row><cell>average max</cell><cell></cell><cell>30.086</cell></row><row><cell cols="3">(4) 2step_pair: Similar to 1step_pair, but on the output of</cell></row><row><cell cols="3">1step_pair_list, instead of the unfair initial ranker.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,320.88,702.79,117.57,6.18"><p>https://huggingface.co/bert-base-uncased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,56.84,702.79,141.90,6.18;2,327.92,87.79,230.28,7.94;2,317.96,98.75,45.38,7.94"><p>https://en.wikipedia.org/wiki/Non-binary_gender To maximize the objective, we tried two approaches: pairwise and listwise.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,330.15,497.96,228.52,6.25;4,330.15,505.93,170.21,6.25" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,419.56,497.96,139.11,6.25;4,330.15,505.93,34.24,6.25">From RankNet to LambdaRank to LambdaMART: An Overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2010-82</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Microsoft</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="4,330.15,513.96,228.05,6.18;4,330.15,521.87,228.05,6.25;4,330.15,529.84,153.25,6.25" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,532.17,513.96,26.03,6.18;4,330.15,521.93,151.35,6.18">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName coords=""><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,494.07,521.87,64.13,6.25;4,330.15,529.84,123.97,6.25">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,537.87,228.82,6.18;4,330.15,545.84,228.05,6.18;4,330.15,553.75,226.22,6.25" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,422.25,545.84,135.95,6.18;4,330.15,553.81,37.80,6.18">LightGBM: A Highly Efficient Gradient Boosting Decision Tree</title>
		<author>
			<persName coords=""><forename type="first">Guolin</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qi</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Taifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weidong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiwei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,380.10,553.75,140.48,6.25">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,561.78,228.18,6.18;4,330.15,569.75,68.13,6.18" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Till</forename><surname>Kletti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Michel</forename><surname>Renders</surname></persName>
		</author>
		<title level="m" coord="4,451.93,561.78,106.41,6.18;4,330.15,569.75,40.44,6.18">Naver Labs Europe at TREC 2020 Fair Ranking Track</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,577.72,229.23,6.18;4,330.15,585.63,228.06,6.25;4,329.94,593.66,18.66,6.18" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Harrie</forename><surname>Oosterhuis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.00855</idno>
		<title level="m" coord="4,406.74,577.72,152.64,6.18;4,330.15,585.69,136.31,6.18">Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,330.15,601.63,229.23,6.18;4,330.15,609.60,228.82,6.18;4,330.15,617.57,228.05,6.18;4,330.15,625.49,192.18,6.25" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,464.22,617.57,93.98,6.18;4,330.15,625.54,18.98,6.18">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,354.81,625.49,105.78,6.25">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,633.46,229.13,6.25;4,330.15,641.48,84.60,6.18" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno>LETOR 4.0 Datasets. CoRR</idno>
		<ptr target="http://arxiv.org/abs/1306.2597" />
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,649.45,228.05,6.18;4,329.81,657.42,229.57,6.18;4,330.15,665.34,228.05,6.25;4,330.15,673.31,58.45,6.25" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,370.59,657.42,188.80,6.18;4,330.15,665.39,63.30,6.18">Quantifying the Impact of User Attentionon Fair Group Representation in Ranked Lists</title>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Sapiezynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wesley</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronald</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christo</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,405.99,665.34,152.21,6.25;4,330.15,673.31,29.00,6.25">Companion Proceedings of The 2019 World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
