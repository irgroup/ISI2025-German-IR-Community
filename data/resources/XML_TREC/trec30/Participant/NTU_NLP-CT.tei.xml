<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.70,96.74,434.59,15.12;1,191.90,118.66,228.20,15.12">Hybrid Re-ranking for Biomedical Information Retrieval at the TREC 2021 Clinical Trials Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,108.85,151.14,78.03,10.48"><forename type="first">Ming-Xuan</forename><surname>Shi</surname></persName>
							<email>mxshi@nlg.csie.ntu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,198.76,151.14,91.98,10.48"><forename type="first">Tsung-Hsuan</forename><surname>Pan</surname></persName>
							<email>tspan@nlg.csie.ntu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.63,151.14,86.88,10.48"><forename type="first">Hen-Hsen</forename><surname>Huang</surname></persName>
							<email>hhhuang@iis.sinica.edu.tw</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Science</orgName>
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,424.16,151.14,74.26,10.48"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
							<email>hhchen@ntu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.70,96.74,434.59,15.12;1,191.90,118.66,228.20,15.12">Hybrid Re-ranking for Biomedical Information Retrieval at the TREC 2021 Clinical Trials Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4D9B097B5B64896A05CED3750312BF66</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our methodology for the task of TREC 2021 Clinical Trials Track, which requires a system to retrieve and return the most relevant biomedical articles after giving queries. We propose a novel approach to biomedical information retrieval by leveraging the term-based and the embeddingbased retrieval models with a re-ranking strategy. In our hybrid framework, all the documents will be indexed by using a term-based, efficient search engine. For the given query, a smaller set of candidate results are retrieved from the search engine. The ranking is determined not only by the term-based ranking score but also by the term relationships labeled by the Amazon Comprehend service 1 for refinement. Then, the candidate results are further scored by using the embedding-based model. We represent the document and the query with bioBERT and compute the cosine similarity between a pair of the document embedding and the query embedding as their relevance score. The final score is a linear combination of the term-based and the embedding-based scores. Experimental results show that our hybrid re-ranking method improves both Precision@k and R-precision scores on the 2016 Clinical Decision Support Track and 2021 Clinical Trials Track dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In handling challenging cases, clinicians often seek out relevant biomedical articles to assist in making a better decision. To better enable access to the scientific literature in the clinical scenario, it is necessary to explore information retrieval methods that connect clinical notes with the published literature. TREC Clinical Trials Track (CT) <ref type="bibr" coords="1,278.83,540.99,10.52,8.74" target="#b0">[1]</ref> provides an opportunity for the development of related information retrieval technology. For the purpose of this track, TREC Clinical Traits Track provided retrieved clinical trials from ClinicalTrials.gov. Clinical trial descriptions can be a long document, in which the core aspect of the trial description are the inclusion/exclusion criteria. Each of the topics, also a long free text description consisting of five to ten sentences, presents a patient's admission statement in an EHR (electronic health record). <ref type="foot" coords="1,294.67,599.19,3.97,6.12" target="#foot_1">2</ref>For the aim of this task, we develop a hybrid model that leverages the advantages of the term-based and the embedding-based ranking models. The term-based model, which determines the relevance between a document and the query by lexical matching, has advantages in retrieval efficiency thanks to inverted indexing. However, the lexical matching fails to retrieve the semantically relevant documents that do not contain any query terms explicitly. On the other hand, the embedding-based model, which determines the relevance between a document and the query by computing the similarity between their distributed representations, is capable of finding semantically relevant results. The downside of the embedding-based model is the lack of efficient indexing mechanisms for querying a large collection of documents.</p><p>In this work, we propose an approach to biomedical information retrieval by integrating the termbased and the embedding-based retrieval models with a re-ranking strategy. In our hybrid framework, all the documents will be indexed by a search engine based on ElasticSearch, <ref type="foot" coords="2,437.63,106.10,3.97,6.12" target="#foot_2">3</ref> which is a toolkit for building efficient term-based search engines. For the given query, a set of candidate results are retrieved from the search engine. The ranking is initially determined by the term-based ranking score, and further refined by considering the term relationships labeled by the Amazon Comprehend service <ref type="foot" coords="2,519.72,141.96,3.97,6.12" target="#foot_3">4</ref> . From the smaller set of candidate results, we further apply the embedding-based model for re-ranking. We represent the document and the query with bioBERT <ref type="bibr" coords="2,332.12,167.45,10.52,8.74" target="#b1">[2]</ref> and compute the cosine similarity between a pair of the document embedding and the query embedding as their relevance score. The final score is a linear combination of the term-based and the embedding-based scores. We conduct the evaluation on the dataset used for the 2016 Clinical Decision Support Track. Experimental results show that our hybrid re-ranking method improves both Precision@k and R-precision scores on two test sizes. The performances of our model in the formal run will be presented when the evaluation of the 2021 Clinical Trials Track releases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>We choose the dataset previously used for the 2016 Clinical Decision Support Track<ref type="foot" coords="2,445.26,292.37,3.97,6.12" target="#foot_4">5</ref> as our dataset for building our hybrid information retrieval framework. The topics provided between 2017 and 2020 only have three specific attributes, but the topics provided in 2016 and 2021 are both free contexts. There are three tags in 2016's topics, which are note, description, and summary. We choose the contexts in the description tag as our queries because the text length, narrative style, and readability of the such contexts are similar to the topics in the 2021 task. Furthermore, there are 1.25 million documents in the 2016 CDS Task, providing sufficient data to fine-tune and evaluate our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Our idea is to leverage the efficiency of the term-based model and the semantic, fuzzy matching supported by the embedding-based model. The process of retrieval in our framework is two-staged. In the first stage, an efficient term-based model retrieves the candidate results from the full document collection. Query expansion is applied to include the potentially relevant documents that do not contain query terms. The candidate results are then further re-ranking by using an embedding-based model that is fine-tuned to represent the biomedical documents in contextual embeddings. We detail the term-based model and the embedding-based model in Section 3.1 and Section 3.2, respectively, and describe our final model in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Term-based Model</head><p>The term-based model is constructed by using the ElasticSearch toolkit. We adopt the Okapi BM25<ref type="foot" coords="2,522.49,548.83,3.97,6.12" target="#foot_5">6</ref> similarity module for relevant scoring. For every document, we build the indexes for the title, the abstract, and the PMID tags. In the beginning, we index the title and the abstract in different indexing attributes. Due to inconsistent document format (e.g. some contents are empty), we finally decide to concatenate the title and the abstract as a single document. Furthermore, we use the contents in brief title, officl title, and text block tag as our document content and nct id as our document identifier for creating the index of the documents. The other settings remain identical to those in 2016. To improve the performance, we also consider the additional information automatically labeled by using Amazon Comprehend Medical service. Amazon Comprehend Medical service has the ability to label the biomedical terms in the text and give their confidence scores. We extract the terms labeled by Amazon Comprehend Medical service as our queries and use the confidence score of each term multiply the correspond retrieval score as our final scores. A part of relevant documents may be ignored by the term-based model if they do not contain any query terms. To extend the search range, one important step in our framework is query expansion. We extend the query terms by consulting biomedical online dictionaries, such as WordNet,<ref type="foot" coords="3,474.63,244.57,3.97,6.12" target="#foot_6">7</ref> RongYang Dictionary,<ref type="foot" coords="3,133.08,256.53,3.97,6.12" target="#foot_7">8</ref> and mesh.<ref type="foot" coords="3,187.83,256.53,3.97,6.12" target="#foot_8">9</ref> These biomedical online dictionaries provide the synonyms of biomedical terms. In order to include the words in the document into the scope of synonym expansion, we also use word embedding to find the synonyms. The last hidden layer of the pretrained bioBERT model is subject to be the representation of the word. When searching for synonyms, we will calculate the cosine similarity between words to assess similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Embedding-based Model</head><p>We use document embedding to consider the relationship between clinical trials and topics. We consider the last hidden layer of the [CLS] token in the bioBERT model as the document embedding. The length of a document may exceed the maximum input length of the bioBERT model. Thus, we split the whole document into several paragraphs and represent them separately. We keep a small overlap of text between each adjacent paragraphs. For two paragraphs with similar meanings, the cosine similarity between the two paragraph embedding would be close to 1. When we judge whether document A is semantically similar to paragraph B, we will calculate the cosine similarity between each paragraph in document A and paragraph B, then sum and calculate the average. If the average value is close to 1, the semantics of document A and paragraph B are similar, otherwise the semantics are not similar. Thus, if we want to find the top-k related documents for a paragraph, then we can sort the calculated cosine similarity average and take the top k document as the search results.</p><p>We use bioBERT as our pretrained model <ref type="bibr" coords="3,281.29,483.71,9.96,8.74" target="#b2">[3]</ref>. There are 30 topics in 2016 Clinical Decision Support Track(CDS). For each topic, we use the relevant documents released by the 2016 CDS and the most irrelevant documents retrieved from our term-based model as the fine-tune dataset. We generate tight negative samples by extracting the documents that are ranked the highest by our term-based model but not listed in the ground-truth. As shown in Figure <ref type="figure" coords="3,324.35,531.53,3.87,8.74" target="#fig_0">1</ref>, the fine-tuning will strengthen the similarity between relevant document/query pairs and weaken the similarity between irrelevant document/query pairs even though they are lexically similar.</p><p>In our fine-tune phase, we used Triplet Loss as our loss function <ref type="bibr" coords="3,390.87,567.39,9.96,8.74" target="#b3">[4]</ref>. Formally speaking, we use the following formula as the loss function. The variable a, p, n appearing in the following formula respectively represent anchor (topic), relevant document, and irrelevant document. The margin variable represents the upper bound of distance, which means that when the difference between cosine similarity(a, n) and cosine similarity(p, n) is greater than or equal to the margin, the loss value is 0. The reason we need this is because we only need to focus on those samples that are not very different. When the differences between the two are identified, we will deal with other samples with small differences. As for the reason why we use cosine similarity(a, n)cosine similarity(a, p) as the loss function, we hope that the model can learn the cosine similarity between topic and relevant document should move as close as possible to 1 and the cosine similarity between topic and irrelevant document should stay as far away as possible to -1.</p><p>L(a, p, n) = max{cosine similarity(a, n)cosine similarity(a, p) + margin, 0}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Final Model</head><p>After we fine-tune our embedding-based model, we compute the average of the cosine similarity between each paragraph in the document and the topic. For this purpose, we normalize the paragraph embedding obtained from the bioBERT encoder and make them into unit vectors. So far, we can compute the average of the cosine similarity between each paragraph in a document and a topic easily, which equal to the cosine similarity between the topic embedding vector and the mean vector of paragraph embedding in the document. In order to give the score for each document, we use the averaged cosine similarity between each paragraph and topic as the score. If the embedding-based model is used alone, however, the performance is only slightly better than the term-based model. Thus, we combine these the two scores obtained by both the term-based and the embedding-based models by calculating their linear combination as follows.</p><formula xml:id="formula_0" coords="4,256.31,255.49,270.65,9.65">s = (1 -α) • s e + α • s t (1)</formula><p>where s e is the relevant score obtained by our embedding-based model, and s t is the relevant score obtained by our term-based model. The value of α can be explored by grid search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>This section shows the performance of our model evaluated on the 2016 Clinical Decision Support Track and 2021 TREC Clinical Trials Track dataset. In the 2016 CDS dataset, there are two version relevant file sets. The average number of their relevant document is about 1,000 and 3,600, respectively.</p><p>In Table <ref type="table" coords="4,125.42,373.34,3.87,8.74" target="#tab_0">1</ref>, Table <ref type="table" coords="4,164.49,373.34,4.98,8.74" target="#tab_1">2</ref> and Table <ref type="table" coords="4,220.35,373.34,3.87,8.74">3</ref>, we show the performances of our hybrid model, compared with the term-based model as the baseline. In the 2016 dataset experiments, we set the value of α as 0.6. As for the 2021 evaluation results, the model with 0.5 alpha value achieved the best performance. Experimental results show that our hybrid model outperforms the term-based model, confirming that the information implied by the embeddings can be used to distinguish the semantic difference and refine the ranking. In this work, the negative samples for fine-tuning our embedding model are collected by using the term-based model. That is, they are the documents with a high s t but labeled as irrelevant in the ground-truth. A potential direction to improve our hybrid model could be made by introducing another kind of negative samples, which can be obtained from the documents with a high initial embedding score but labeled as irrelevant in the ground-truth. Regarding this point, we hope this direction can be explored in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metric</head><p>Term-based Model Hybrid Model P@10 0.2507 0.2760 NDCG@5 0.4679 0.4899 NDCG@10 0.4341 0.4665 R-prec 0.1573 0.1624 Table <ref type="table" coords="5,179.90,138.64,3.87,8.74">3</ref>: Final results on the 1,000 relevant document in 2021 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper shows our attempt to biomedical information retrieval at the TREC 2021 Clinical Traits Track. We propose a hybrid information retrieval framework that enhances the efficiency term-based model with the semantic awareness benefited by the embedding-based model. The embedding-based model has the ability to capture the relationship between document/query pairs in a different perspective, helping to distinguish the subtle semantic difference. Our hybrid approach has been shown effective on the 2016 datasets and can be easily applied to other information retrieval tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,85.04,178.42,441.92,8.77;3,85.04,190.41,399.20,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Triplet Loss has the ability to make the distance between Negative Sample and Anchor Sample farther, and make the distance between Positive Sample and Anchor Sample closer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.50,457.57,342.99,173.39"><head>Table 1 :</head><label>1</label><figDesc>Experimental results on the 1,000 relevant document in 2016 dataset.</figDesc><table coords="4,205.78,457.57,200.44,173.39"><row><cell>Metric</cell><cell cols="2">Term-based Model Hybrid Model</cell></row><row><cell>P@10</cell><cell>0.909</cell><cell>0.940</cell></row><row><cell>P@20</cell><cell>0.871</cell><cell>0.890</cell></row><row><cell>P@1000</cell><cell>0.285</cell><cell>0.302</cell></row><row><cell>R-prec</cell><cell>0.259</cell><cell>0.2731</cell></row><row><cell>Metric</cell><cell cols="2">Term-based Model Hybrid Model</cell></row><row><cell>P@10</cell><cell>0.990</cell><cell>0.996</cell></row><row><cell>P@20</cell><cell>0.983</cell><cell>0.993</cell></row><row><cell>P@1000</cell><cell>0.582</cell><cell>0.614</cell></row><row><cell>R-prec</cell><cell>0.339</cell><cell>0.350</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.50,646.20,342.99,8.74"><head>Table 2 :</head><label>2</label><figDesc>Experimental results on the 3,600 relevant document in 2016 dataset.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,100.28,703.38,144.54,6.99"><p>https://aws.amazon.com/comprehend/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,100.28,712.89,130.85,6.99"><p>http://www.trec-cds.org/2021.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,100.28,700.84,138.51,6.99"><p>https://www.elastic.co/elasticsearch/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,100.28,710.35,144.54,6.99"><p>https://aws.amazon.com/comprehend/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,100.28,719.85,130.85,6.99"><p>http://www.trec-cds.org/2016.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="2,100.28,729.36,352.70,6.99"><p>https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="3,100.28,693.92,116.74,6.99"><p>https://wordnet.princeton.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="3,100.28,703.42,261.84,6.99"><p>http://libs2.vghtpe.gov.tw/digital new/portal d1.php?button num=d1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="3,100.28,712.93,139.12,6.99"><p>https://www.ncbi.nlm.nih.gov/mesh/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,100.54,306.83,426.43,8.74;5,100.54,318.79,250.41,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,458.15,306.83,68.82,8.74;5,100.54,318.79,172.32,8.74">Overview of the trec 2016 clinical decision support track</title>
		<author>
			<persName coords=""><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,293.88,318.79,24.84,8.74">TREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,100.54,338.71,426.42,8.74;5,100.54,350.67,426.43,8.74;5,100.54,362.62,169.85,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,170.06,350.67,356.90,8.74;5,100.54,362.62,48.74,8.74">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">So</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,158.37,362.62,62.71,8.74">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,100.54,382.55,426.42,8.74;5,100.54,394.50,351.77,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,307.04,382.55,219.92,8.74;5,100.54,394.50,321.49,8.74">Transfer learning in biomedical natural language processing: An evaluation of bert and elmo on ten benchmarking datasets</title>
		<author>
			<persName coords=""><forename type="first">Yifan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shankai</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,100.54,414.43,426.42,8.74;5,100.54,426.38,248.86,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,359.75,414.43,167.21,8.74;5,100.54,426.38,111.70,8.74">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName coords=""><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<idno>CoRR, abs/1503.03832</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
