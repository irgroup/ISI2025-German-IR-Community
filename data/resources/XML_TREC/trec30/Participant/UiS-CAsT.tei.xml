<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.98,116.75,339.39,12.62;1,174.69,134.69,265.97,12.62">The University of Stavanger (IAI) at the TREC 2021 Conversational Assistance Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,134.77,174.43,54.12,8.74"><forename type="first">Ivica</forename><surname>Kostric</surname></persName>
							<email>ivica.kostric@uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.18,174.43,65.87,8.74"><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
							<email>krisztian.balog@uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.64,174.43,57.06,8.74"><forename type="first">Magnus</forename><surname>Book</surname></persName>
							<email>magnus.s.book@uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.76,174.43,68.07,8.74"><forename type="first">Trond</forename><surname>Linjordet</surname></persName>
							<email>trond.linjordet@uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,429.17,174.43,51.43,8.74"><forename type="first">Vinay</forename><surname>Setty</surname></persName>
							<email>vinay.j.setty@uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.98,116.75,339.39,12.62;1,174.69,134.69,265.97,12.62">The University of Stavanger (IAI) at the TREC 2021 Conversational Assistance Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CD1E4F4B7CE2DD823B1C40C1A8FF52BC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Conversational AI</term>
					<term>conversational search</term>
					<term>TREC CAsT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the IAI group at the University of Stavanger in the TREC 2021 Conversational Assistance track. The focus of our submission was to produce a strong baseline on top of which future research can be conducted. We followed the already established two-step passage ranking architecture, i.e., first-pass passage retrieval followed by re-ranking. In the first step, standard BM25 ranking is used. For the second step, we used a T5 model pre-trained on the MS MARCO QA dataset. Initial results suggest that our submission constitutes a reasonable and competitive baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC Conversational Assistance Track (CAsT) aims to advance research in conversational search systems by creating a reusable offline test collection for open-domain information centric conversational dialogues <ref type="bibr" coords="1,401.35,486.67,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,414.71,486.67,7.01,8.74" target="#b1">2]</ref>. In this third year of running TREC CAsT, the focus of the track is on utilizing conversational context. Specifically, (1) tracking how information needs evolve during the course of the conversation and identifying salient information needed for a given turn in the conversation, and (2) retrieving relevant passages from a large collection of paragraphs.</p><p>The focus of our submission is to produce a strong baseline on top of which future research can be conducted. We follow the already established two-step passage ranking architecture, i.e., first-pass passage retrieval followed by re-ranking. In the first step, standard BM25 ranking is used. For the second step, we use neural re-rankers pre-trained on the MS MARCO QA dataset. Our experiments on the TREC CAsT 2020 dataset suggest that a T5-based re-ranker is more effective than a BERT-based one, therefore we use the former in our submission. Preliminary results on the 2021 evaluation topics suggest that our submission constitutes a reasonable and competitive baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In this section, we describe in detail our approach and implementation. We follow the canonical pipeline that has emerged for this task <ref type="bibr" coords="2,362.81,154.33,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,376.09,154.33,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="2,386.62,154.33,7.01,8.74" target="#b5">6]</ref>, consisting of query rewriting, first-pass passage retrieval, and passage re-ranking components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Query Rewriting</head><p>We used the manual query rewrites provided by the organizers, both for firstpass retrieval and re-ranking. No additional processing is applied to the manually rewritten queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">First-pass Passage Retrieval</head><p>Each utterance is passed to the first-pass passage retrieval module. For this stage, we employ Elasticsearch. <ref type="foot" coords="2,243.01,298.09,3.97,6.12" target="#foot_0">1</ref> Each passage consists of three fields: title, body, and a catch-all field, which is a concatenation of the two. During indexing, the passages are analyzed using the Elasticsearch built-in analyzer which is responsible for tokenization, stopword removal, and stemming. The tokenizer removes most punctuation symbols and divides passages into terms on word boundaries, as defined by the Unicode Text Segmentation algorithm. Stopword removal is done using English corpus from the NLTK toolkit. <ref type="foot" coords="2,339.79,369.82,3.97,6.12" target="#foot_1">2</ref> Stemming is performed using KStem, which combines algorithmic stemming with a built-in dictionary.</p><p>We rank passages using BM25 with default parameters (k1 = 1.2, b = 0.75) on the catch-all field and gather the top 1000 candidates for each turn for downstream re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Passage Re-ranking</head><p>After retrieving relevant passages from the first-pass retrieval, they are re-ranked using a neural re-ranker, specifically BERT or T5. Given a query utterance and a set of candidate passages from first-pass retrieval, we construct query-passage pairs as input to the re-ranker.</p><p>To ensure fair comparison, we base our passage re-ranking on models that are fine-tuned on the same dataset, i.e., the MS-MARCO passage collection. We do not perform any further fine-tuning for TREC CAsT.</p><p>BERT We use a BERT base uncased model by NBoost<ref type="foot" coords="2,388.50,567.49,3.97,6.12" target="#foot_2">3</ref> shared on Hugging Face. <ref type="foot" coords="2,157.04,579.45,3.97,6.12" target="#foot_3">4</ref> This model has a binary classification head with binary cross-entropy loss function (point-wise re-ranking). We use the BERT tokenizer to prepare each query-passage pair as input to the BERT re-ranker.</p><p>Table <ref type="table" coords="3,163.95,115.91,4.12,7.89">1</ref>. Results on TREC CAsT 2020, using manual query rewrites. Highest scores for each evaluation measure are in boldface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Recall MAP MRR NDCG NDCG@3 T5 As an alternative technique for passage re-ranking, we use T5, a powerful sequence-to-sequence language modeling architecture <ref type="bibr" coords="3,384.73,356.27,9.96,8.74" target="#b4">[5]</ref>. The particular T5 model we use is by Nogueira et al. <ref type="bibr" coords="3,294.54,368.23,9.96,8.74" target="#b3">[4]</ref>, published on Hugging Face. <ref type="foot" coords="3,435.01,366.65,3.97,6.12" target="#foot_4">5</ref> For constructing the input to the T5 model, we use the associated T5 tokenizer and encode the query-passage pairs. Since T5 is a generative model, we employ a variant fine-tuned to generate "true" and "false" labels for the relevant and non-relevant passages.</p><formula xml:id="formula_0" coords="3,140.74,165.07,24.19,7.86">BM25</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section reports first on results we obtained for the 2020 evaluation topics.</p><p>Based on these results, we selected our strong baseline that we submitted as a single run to TREC 2021.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results on TREC CAsT 2020</head><p>Table <ref type="table" coords="3,162.59,552.20,4.98,8.74">1</ref> reports the performance of the first-pass BM25 ranker and two neural re-rankers applied on top of that, on the 2020 dataset. All methods use manual query rewrites that are provided by the track organizers. For comparison, we also include the BERT baseline supplied by the track organizers <ref type="bibr" coords="3,423.64,588.06,10.52,8.74" target="#b1">[2]</ref> as well as the best performing team at TREC 2020 <ref type="bibr" coords="3,316.42,600.02,9.96,8.74" target="#b2">[3]</ref>. We find that the T5 re-ranker outperforms the BERT-based one. Further, it even outperforms the best performing system at TREC last year. Therefore, we use this as our strong baseline to be submitted to TREC 2021.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results on TREC CAsT 2021</head><p>We submitted a single run, with run ID UiS raft, <ref type="foot" coords="4,360.53,137.34,3.97,6.12" target="#foot_5">6</ref> that uses a T5 re-ranker. This corresponds to the T5 re-ranker reported in Table <ref type="table" coords="4,385.68,150.87,3.87,8.74">1</ref>, i.e., trained on the MS-MARCO passage dataset, without any further fine-tuning on conversational data. Based on the results that are available at the time of writing, our approach seems to be competitive.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,165.07,345.83,159.64"><head>Table 2 .</head><label>2</label><figDesc>Results on TREC CAsT 2021, using manual query rewrites. TREC median and best refer to topic-level averages of all submissions (13) in this category.</figDesc><table coords="3,140.74,165.07,336.16,159.64"><row><cell>baseline</cell><cell></cell><cell>0.694</cell><cell>0.139</cell><cell>0.389</cell><cell>0.419</cell><cell>0.259</cell></row><row><cell>BERT re-ranker</cell><cell></cell><cell>0.694</cell><cell>0.302</cell><cell>0.633</cell><cell>0.558</cell><cell>0.482</cell></row><row><cell>T5 re-ranker</cell><cell></cell><cell>0.694</cell><cell cols="2">0.338 0.716</cell><cell>0.584</cell><cell>0.537</cell></row><row><cell cols="2">Organizers' baseline (BERT) [2]</cell><cell>0.498</cell><cell>0.252</cell><cell>0.651</cell><cell>0.451</cell><cell>0.479</cell></row><row><cell>Best@TREC'20 [3]</cell><cell></cell><cell>0.747</cell><cell>0.302</cell><cell>0.684</cell><cell>0.571</cell><cell>0.530</cell></row><row><cell>Method</cell><cell cols="5">Recall MAP MRR NDCG NDCG@3</cell></row><row><cell>UiS raft</cell><cell>0.749</cell><cell>0.408</cell><cell>0.859</cell><cell>0.637</cell><cell>0.579</cell></row><row><cell>TREC median</cell><cell></cell><cell>0.371</cell><cell></cell><cell></cell><cell>0.555</cell></row><row><cell>TREC best</cell><cell></cell><cell>0.535</cell><cell></cell><cell></cell><cell>0.800</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,623.92,150.75,7.86"><p>https://www.elastic.co/elasticsearch/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,634.88,91.20,7.86"><p>https://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,645.84,162.27,7.86"><p>https://github.com/koursaros-ai/nboost</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,144.73,656.80,249.89,7.86"><p>https://huggingface.co/nboost/pt-bert-base-uncased-msmarco</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,144.73,656.80,225.23,7.86"><p>https://huggingface.co/castorini/monot5-base-msmarco</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,144.73,656.80,242.57,7.86"><p>Our ambition was to build a ship, but we only got to a raft.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,148.23,240.59,332.37,6.12;4,148.23,248.56,290.77,6.12" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,279.35,240.59,201.24,6.12;4,148.23,248.56,28.72,6.12">TREC CAsT 2019: The Conversational Assistance Track overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,194.06,248.56,221.01,6.12">Proceedings of the 28th Text REtrieval Conference, TREC &apos;19</title>
		<meeting>the 28th Text REtrieval Conference, TREC &apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,148.23,256.53,332.37,6.12;4,148.23,264.50,254.90,6.12" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,273.55,256.53,203.45,6.12">CAsT 2020: The Conversational Assistance Track overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,158.19,264.50,221.00,6.12">Proceedings of the 29th Text REtrieval Conference, TREC &apos;20</title>
		<meeting>the 29th Text REtrieval Conference, TREC &apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,148.23,272.47,332.37,6.12;4,148.23,280.44,332.36,6.12;4,148.23,288.41,58.48,6.12" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,245.77,272.47,234.82,6.12;4,148.23,280.44,138.42,6.12">Glasgow Representation and Information Learning Lab (GRILL) at the Conversational Assistance track 2020</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gemmell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,301.59,280.47,179.00,6.08;4,148.23,288.41,34.54,6.12">Proceedings of the 29th Text REtrieval Conference, TREC &apos;20</title>
		<meeting>the 29th Text REtrieval Conference, TREC &apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,148.23,296.38,332.37,6.12;4,148.23,304.35,332.36,6.12;4,148.23,312.32,73.54,6.12" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,316.19,296.38,164.40,6.12;4,148.23,304.35,62.76,6.12">Document ranking with a pretrained sequenceto-sequence model</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,231.09,304.38,249.50,6.08;4,148.23,312.35,15.27,6.08">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,148.23,320.29,332.36,6.12;4,148.23,328.26,299.51,6.12" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,148.23,328.26,275.12,6.12">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,148.23,336.23,332.37,6.12;4,148.23,344.20,332.36,6.12;4,148.23,352.17,332.37,6.12;4,148.23,360.14,38.97,6.12" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,396.96,336.23,83.63,6.12;4,148.23,344.20,126.22,6.12">Chatty goose: A python framework for conversational search</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,294.64,344.23,185.95,6.08;4,148.23,352.17,284.28,6.12">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2521" to="2525" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
