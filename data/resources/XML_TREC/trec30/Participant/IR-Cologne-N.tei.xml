<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,73.44,95.42,198.99,10.71;1,73.44,112.85,272.30,10.71">IRCologne at TREC 2021 News Track Relation-based re-ranking for background linking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,73.44,138.94,96.24,9.75"><forename type="first">Björn</forename><surname>Engelmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln (University of Applied Sciences)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">PHILIPP SCHAER</orgName>
								<orgName type="institution" key="instit2">TH Köln (University of Applied Sciences)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,73.44,95.42,198.99,10.71;1,73.44,112.85,272.30,10.71">IRCologne at TREC 2021 News Track Relation-based re-ranking for background linking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8B96159CF2FA54547D39A50487C2366F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our approach to the background linking task of the TREC 2021 News Track. The background linking task is to find a set of relevant articles in the Washington Post dataset containing helpful background information for a given news article. Our approach involved a two-stage retrieval process. In the first stage, the 200 most relevant documents were extracted from the entire corpus using BM25. The second stage involved re-ranking using similarity scores based on entities and relations extracted from the query document and the associated 200 relevant documents. For this task, we submitted five runs, each giving different weights to the entities and relations. Our best run received a nDCG@5 of 0.4423, and we were thus able to show that re-ranking with the use of relations leads to a slight improvement over the baseline without re-ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The number of online news offerings and their use has been increasing rapidly in the recent past. News has been a big topic in IR for a long time, but the news consumer has not been addressed sufficiently. From the user's point of view, it is still challenging to find one's way through the flood of information. Since the level of knowledge of users varies greatly, it is often essential to get relevant background information to understand and correctly contextualize news articles. However, this background information is difficult to find without assistance. Therefore, the background linking Task exists to develop methods that use approaches from information retrieval to support the user with the massive amount of data.</p><p>For a given news article (query document), a ranked set of documents should be returned containing as much relevant background information as possible. Human assessors perform the actual relevance assessments. The relevance score for an article ranges from 0 (The linked document provides little or no useful background information) to 4 (The document must appear in an explanation box or a list of context links, otherwise important context is missing).</p><p>In the last iteration of the News Track, several ideas were presented to evaluate the similarity of articles <ref type="bibr" coords="1,450.23,503.74,9.27,7.94" target="#b3">[4]</ref>. Document similarity was then used as a measure of relevance. Approaches were presented that used named entities, relation graphs, and embeddings as features of the documents <ref type="bibr" coords="1,272.51,531.14,9.36,7.94" target="#b1">[2,</ref><ref type="bibr" coords="1,284.12,531.14,6.15,7.94" target="#b2">3,</ref><ref type="bibr" coords="1,292.52,531.14,6.15,7.94" target="#b5">6,</ref><ref type="bibr" coords="1,300.92,531.14,6.24,7.94" target="#b6">7]</ref>. Surprisingly, it turns out that embeddings seem not well suited for this task. Instead, standard approaches like BM25, achieved the best results <ref type="bibr" coords="1,404.21,544.84,9.39,7.94" target="#b5">[6]</ref>.</p><p>The goal of this submission was to evaluate how re-ranking with named entities and relations affects retrieval performance. We manually examined the relevance scores of News Track 2020 and hypothesized that similar relations across multiple articles are an indicator of relevant documents. A concise example is the relation "goes to" between the entities Nixon and China. Many documents marked as highly relevant contained a variation of this relation. However, many non-relevant articles included the entities China and Nixon but in a different context. Since the meaning of the relation "goes to" can present itself in many variations (e.g., Nixon "visits" China), this work has tried not to exclude other relation variations.</p><p>2 DATA</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TREC Washington Post Corpus</head><p>The Washington Post dataset (version 4) contains 728,626 documents of news articles or blog posts from 2012 to 2020.</p><p>The articles are stored in JSON format, and include <ref type="bibr" coords="2,298.75,147.09,9.50,7.94" target="#b0">[1]</ref>:</p><formula xml:id="formula_0" coords="2,126.13,168.70,76.91,35.83">• title • byline • date of publication</formula><p>• kicker (a section header)</p><p>• article text broken into paragraphs</p><p>• links to embedded images and multimedia (for 2012-2017 documents)</p><p>In 2021, the background linking task contained 51 annotated query documents (topics), including a set of subtopics for the subtopic run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocessing</head><p>As an interface to the indexing pipeline, we used the python package "ir-datasets" to efficiently iterate over the documents, examine individual documents, and avoid encoding problems <ref type="bibr" coords="2,330.58,333.26,9.27,7.94" target="#b7">[8]</ref>. To index the articles we used the framework PyTerrier <ref type="bibr" coords="2,110.16,346.96,9.39,7.94" target="#b8">[9]</ref>, which is a python API for Terrier <ref type="bibr" coords="2,249.12,346.96,13.36,7.94" target="#b9">[10]</ref>.</p><p>All articles that were labeled "Opinion", "Opinions", "Letters to the Editor", or "The Post's View" in the kicker section were filtered out in advance. Furthermore, we filtered out duplicates by identifying identical documents via the URL of the article during retrieval. The fields "title", "author", "kicker", "body" and "body_paras_html" were used as document representation for the query and all candidate articles. Then only the terms of the resulting indexed text were used for comparison during retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>In this section, we describe the methods we used for the submitted runs. All the experiments we did to evaluate the methods were based on the Washington Post dataset version 3 from 2020.</p><p>The flow of the individual modules is shown in Figure <ref type="figure" coords="2,317.68,488.93,3.02,7.94" target="#fig_0">1</ref>, whereby only the TF-IDF scores were used for the baseline model. The estimation of the relation scores is described in subsection 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>Since our approach aims to evaluate the effect of incorporating named entities and relations to estimate relevance, a baseline is needed for the retrieval process, pre-selecting documents for the re-ranking step. To evaluate the methods from subsection 3.2 and subsection 3.3, the retrieval performance of the baseline is used as a reference. We used Okapi BM25 <ref type="bibr" coords="2,134.03,589.81,14.85,7.94" target="#b11">[12]</ref> as the scoring function for retrieval. Our system used the default parameters and the implementation of PyTerrier. Each query article was transformed into a set of query terms (as described in subsection 2.2) to obtain a similarity score of all documents in the corpus using the scoring function. Only the top 200 retrieved documents were then used for further processing with the re-ranking since the methods for re-ranking are much more computationally intensive, and it is infeasible to re-rank across all the documents from the corpus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Entity Recognition</head><p>For each query, we extracted the entities from the query document 𝑞 and every document 𝑑 ∈ 𝐷, where 𝐷 are the top 200 retrieved documents. For named entity recognition, we used the python library spaCy <ref type="bibr" coords="3,383.69,475.43,9.27,7.94" target="#b4">[5]</ref>. Only terms corresponding to one of the following entity types were used: 'EVENT', 'FAC', 'GPE', 'LAW', 'LOC', 'NORP', 'ORG', 'PERSON', 'PRODUCT', 'WORK-OF-ART'. These types were selected because they seemed relevant to us through a manual examination of the articles, especially in the news context. We applied the following formula for all pairs of query documents and the 200 corresponding candidate documents to build a similarity score based on the extracted entities:</p><formula xml:id="formula_1" coords="3,198.30,557.14,300.37,18.43">𝑆 𝑒𝑛 (𝑞, 𝑑) = 𝑡 ∈𝐸 𝑞_𝑑 log(𝑁 /𝑖𝑑 𝑓 (𝑡)) • log(𝑡 𝑓 (𝑡) + 1). (<label>1</label></formula><formula xml:id="formula_2" coords="3,498.67,557.63,3.17,7.94">)</formula><p>𝐸 𝑞_𝑑 represents the set of all entities that occur in the query document q and the candidate document d. 𝑁 is the number of documents in the corpus. The function 𝑖𝑑 𝑓 (𝑡) corresponds to inverse document frequency of the term 𝑡 in the corpus and the function 𝑡 𝑓 (𝑡) to the number of occurrences of 𝑡 in 𝑞. The similarity score was then combined with the score of the baseline model (BM25):</p><formula xml:id="formula_3" coords="3,213.89,642.29,147.07,8.38">𝑆 𝑏𝑒𝑛 (𝑞, 𝑑) = 𝑏𝑚25(𝑞, 𝑑) + 𝜆 𝑒𝑛 • 𝑆 𝑒𝑛 (𝑞, 𝑑).</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Relation Extraction</head><p>A framework was used to extract relations between entities to apply simple heuristics that link entities when they match a specific predefined pattern. The Snorkel framework <ref type="bibr" coords="4,329.10,133.31,14.62,7.94" target="#b10">[11]</ref> applies several so-called labeling functions to pairs of entities to decide whether they are related. These functions serve as a rule of thumb and provide a weak signal for each pair as to whether they are related. The combination of the individual signals then leads to a noisy label. We have defined the following rules for relation identification:</p><p>• Both entities appear in the same sentence</p><p>• One entity appears as the subject and the other as the object in the sentence</p><p>• There is a verb that connects both entities For this purpose, the previously extracted entities (subsection 3.2) and their grammatical properties were used, with which spaCy annotates the entities. The shared relations of two documents were then used for the similarity score. To integrate also weak relations, we have examined the following cases of relations:</p><p>• The entities of the shared relation must be connected by the same verb</p><p>• The entities of the shared relation must be connected by any verb</p><p>• The entities of the shared relation must appear only in the same sentence</p><p>The relation similarity score for documents d and q were then determined (analogous to subsection 3.2) in the following way: </p><formula xml:id="formula_4" coords="4,194.82,368.65,340.56,19.92">𝑆 𝑟 (𝑞, 𝑑) = (𝑡 1 ,𝑡 2 ) ∈𝑅 𝑞_𝑑 (log(𝑁 /𝑖𝑑 𝑓 (𝑡 1 )) + log(𝑁 /𝑖𝑑 𝑓 (𝑡 2 ))) • log(𝑘 𝑡 12 + 1). (<label>3</label></formula><p>The combination of scoring functions was estimated as follows:</p><formula xml:id="formula_6" coords="4,223.30,466.33,315.26,8.43">𝑆 𝑏𝑒𝑛𝑟 (𝑞, 𝑑) = 𝑏𝑚25(𝑞, 𝑑) + 𝜆 𝑒𝑛 • 𝑆 𝑒𝑛 (𝑞, 𝑑) + 𝜆 𝑟 • 𝑆 𝑟 (𝑞, 𝑑).<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Background Linking</head><p>All experiments were conducted on the 2020 Washington Post dataset (version 3) using the supplied topics and relevancescored qrels. We performed all the following experiments on the runs with relation extraction only for the entities' scenario in the same sentence. We did not consider the other scenarios in detail because too few common relations were found in the documents. Since we wanted to compare the effect of the entity similarity score, relation similarity score, and a combination with both to the baseline, we evaluated three grid search instances. To avoid overfitting, we used an 80/20 split. The following parameters were evaluated in the respective grid searches:</p><p>• Entity run: 𝜆 𝑒𝑛 ∈ {0.1, 0.2, . . . , 1.0}</p><p>• Relation run: 𝜆 𝑟 ∈ {0.1, 0.2, . . . , 1.0}</p><p>• Combined run: (𝜆 𝑒𝑛 , 𝜆 𝑟 ) ∈ {0.1, 0.2, . . . , 1.0} × {0.1, 0.2, . . . , 1.0}  Figure <ref type="figure" coords="5,109.61,426.07,4.25,7.94" target="#fig_2">2</ref> shows a comparison of the baseline run with the best system (𝜆 𝑒𝑛 =0.2, 𝜆 𝑟 = 0.5). It can be seen that the results for most topics do not differ. Only in some cases is there an improvement compared to the baseline (e.g., topic 954 or topic 961).</p><p>Table <ref type="table" coords="5,105.13,467.16,4.10,7.94" target="#tab_0">1</ref> shows the results for the Washington Post dataset from 2020 and 2021. The retrieval model, which considers both entities and relations, provides the best results for the background linking task of 2021. Compared to the previous year, the results are significantly worse. The Mean nDCG@5 score of the baseline decreased by 0.1068 points. Both for the task of 2020 and 2021, it can be seen that the consideration of relations leads to a better retrieval result.</p><p>In the following, an example is shown in which the incorporation of the relations resulted in an advantage over the baseline. For topic 984 with the title Lidl, an improvement of the nDCG@5 of 0.1513 could be achieved. One relevant document was not ranked among the top 5 by the baseline system. The best system, on the other hand, placed this document with the title What is Lidl? "5 things the German grocer is bringing to America" to rank 1.</p><p>The five most relevant extracted entity pairs coming from both documents are:</p><p>• ('Lidl', 'U.S. ')</p><p>• ('Brendan Proctor', 'U.S. ')</p><p>• ('Brendan Proctor', 'Lidl')</p><p>• ('German', 'Lidl')</p><p>• ('U.S. ', 'Arlington')  <ref type="table" coords="6,129.73,158.15,2.78,7.13">2</ref>. Results for the subtopic task. The first column shows the average nDCG@10 score of all participant runs. The following columns show the results of our approach.</p><p>To find relevant documents for the subtopics, we used our baseline approach and added the text of the associated subtopic to the query. The score for the subtopic text was then weighted and included in the final score for the ranking:</p><formula xml:id="formula_7" coords="6,229.94,241.00,308.62,8.43">𝑆 𝑠𝑢𝑏 (𝑞, 𝑞 𝑠𝑢𝑏 , 𝑑) = 𝑏𝑚25(𝑞, 𝑑) + 𝜆 𝑠𝑢𝑏 • 𝑏𝑚25(𝑞 𝑠𝑢𝑏 , 𝑑).<label>(6)</label></formula><p>Here 𝑞 𝑠𝑢𝑏 is the text from the subtopic. Since this task was called for the first time this year, there was no training data yet. We, therefore, chose the following weights for the five runs: 𝜆 𝑠𝑢𝑏 ∈ {0.25, 0.5, 1, 2, 4}.</p><p>In Table <ref type="table" coords="6,151.35,288.57,4.09,7.94">2</ref> it can be seen that with increasing 𝜆 𝑠𝑢𝑏 a better retrieval result occurs. Of course, an evaluation with even larger 𝜆 𝑠𝑢𝑏 was not possible without training data, but a weighted subtopic retrieval approach seems reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>This paper presents an approach that combines classical retrieval approaches, namely BM25, with a similarity ranking based on entities and relations. It turned out that a re-ranking that takes relations into account leads to better results than re-ranking with entities alone. Thus, even if the results do not differ much from the baseline, it is reasonable to assume that relations provide an additional benefit to identify relevant background information. We suspect that this is because the context in which entities are related to each other is better taken into account by relations than by simple matching in the whole document. Future work could consider more complex types of relations or exclude relation types that are not essential for extracting background information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,231.22,382.75,112.84,7.13;3,73.44,95.04,428.41,274.02"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Retrieval pipeline overview.</figDesc><graphic coords="3,73.44,95.04,428.41,274.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,535.39,369.13,3.17,7.94;4,109.98,395.98,16.17,5.96;4,129.47,394.04,211.84,9.57;4,344.54,393.56,194.02,9.38;4,109.76,407.74,351.14,7.94;4,257.01,429.37,10.84,5.96;4,269.63,426.95,84.28,7.93;4,357.34,426.95,11.01,7.76;4,370.14,426.95,21.15,7.70"><head>)</head><label></label><figDesc>𝑅 𝑞_𝑑 represents the set of shared entity tuples from 𝑞 and 𝑑. 𝑘 𝑡 12 is the number of occurrences of the relation (𝑡 1 , 𝑡 2 ) in 𝑞. The relation similarity score was then combined with the score of the baseline model (BM25): 𝑆 𝑏𝑟 (𝑞, 𝑑) = 𝑏𝑚25(𝑞, 𝑑) + 𝜆 𝑟 • 𝑆 𝑟 (𝑞, 𝑑).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,189.57,283.88,196.14,7.13;5,94.86,190.07,385.56,62.52"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results of all topics for baseline and the best system.</figDesc><graphic coords="5,94.86,190.07,385.56,62.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,93.45,380.26,388.16,7.13"><head>Table 1 .</head><label>1</label><figDesc>Background linking evaluation results für Washington Post dataset from 2020 (version 3) and 2021 (version 4).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,109.95,102.41,384.67,62.87"><head></head><label></label><figDesc>RunAvg. participant runs 𝜆 𝑠𝑢𝑏 =0.25 𝜆 𝑠𝑢𝑏 =0.5 𝜆 𝑠𝑢𝑏 =1 𝜆 𝑠𝑢𝑏 =2 𝜆 𝑠𝑢𝑏 =4</figDesc><table coords="6,109.95,102.41,382.27,62.87"><row><cell>4.2 Subtopics</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Avg. nDCG@10 0.2177</cell><cell>0.2553</cell><cell>0.2698</cell><cell>0.2931 0.3157 0.3343</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,125.59,464.22,247.35,6.18" xml:id="b0">
	<monogr>
		<ptr target="https://trec.nist.gov/data/wapost/" />
		<title level="m" coord="6,125.59,464.22,81.29,6.18">Trec washington post corpus</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.59,474.19,212.98,6.18" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">E</forename><surname>Ak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ç</forename><surname>Köksal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Fayoumi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yeniterzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.59,484.10,285.70,6.23" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,223.51,484.15,152.87,6.18">Osc at trec 2020-news track&apos;s background linking task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Worley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Allison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,381.54,484.10,15.63,6.23">TREC</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.60,494.06,412.96,6.23;6,125.60,504.02,412.96,6.23;6,125.60,513.99,384.03,6.23" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,225.61,494.11,141.72,6.18">TREC 2020 NEWS track background linking task</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec29/papers/IRLABISI.N.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="6,487.66,494.06,50.90,6.23;6,125.60,504.02,181.44,6.23">Proceedings of the Twenty-Ninth Text REtrieval Conference, TREC 2020, Virtual Event</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>the Twenty-Ninth Text REtrieval Conference, TREC 2020, Virtual Event<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">November 16-20, 2020. 2020</date>
			<biblScope unit="volume">1266</biblScope>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.60,524.00,413.79,6.18;6,125.44,533.96,69.40,6.18" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,304.50,524.00,195.77,6.18">spaCy: Industrial-strength Natural Language Processing in Python</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Van Landeghem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Boyd</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.1212303</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.59,543.87,254.37,6.23" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,211.42,543.92,122.34,6.18">The clac system at the trec 2020 news track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Khloponin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kosseim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,346.55,543.87,13.73,6.23">TREC</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.59,553.89,211.95,6.18" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,180.93,553.89,153.36,6.18">Aspect based background document retrieval for news</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.59,563.80,384.46,6.23" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,345.23,563.85,118.76,6.18">Simplified data wrangling with ir-datasets</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,476.70,563.80,14.26,6.23">SIGIR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.59,573.76,387.15,6.23" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,220.15,573.81,191.06,6.18">Declarative experimentation ininformation retrieval using pyterrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,423.96,573.76,69.76,6.23">Proceedings of ICTIR 2020</title>
		<meeting>ICTIR 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.60,583.73,412.96,6.23;6,125.60,593.74,34.58,6.18" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,285.88,583.77,167.22,6.18">From puppy to maturity: Experiences in developing terrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,458.04,583.73,59.59,6.23">Proc. of OSIR at SIGIR</title>
		<meeting>of OSIR at SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="60" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.60,603.65,413.73,6.23;6,125.60,613.66,120.52,6.18" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="6,309.51,603.70,164.39,6.18">Snorkel: Rapid training data creation with weak supervision</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">R</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<idno>CoRR, abs/1711.10160</idno>
		<ptr target="http://arxiv.org/abs/1711.10160" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,125.60,623.58,412.96,6.23;6,125.60,633.59,68.39,6.18" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,212.32,623.62,271.16,6.18">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,496.02,623.58,22.10,6.23">SIGIR&apos;94</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
