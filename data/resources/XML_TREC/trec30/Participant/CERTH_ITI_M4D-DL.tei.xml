<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.11,120.56,280.50,15.12;1,171.94,142.48,250.84,15.12">M4D-MKLab/ITI-CERTH Participation in TREC Deep Learning Track 2021</title>
				<funder ref="#_5RcF9cx">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder>
					<orgName type="full">CONNEXIONs</orgName>
				</funder>
				<funder>
					<orgName type="full">INFINITY</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.94,174.97,145.64,10.48"><forename type="first">Alexandros-Michail</forename><surname>Koufakis</surname></persName>
							<email>akoufakis@iti.gr</email>
							<affiliation key="aff0">
								<orgName type="department">Ioannis Kompatsiaris Information Technologies Institute</orgName>
								<orgName type="institution" key="instit1">Stefanos Vrochidis</orgName>
								<orgName type="institution" key="instit2">Centre for Research and Technology Hellas</orgName>
								<address>
									<addrLine>6th Km. Charilaou -Thermi Road</addrLine>
									<postCode>57001</postCode>
									<settlement>Thermi-Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.83,174.97,92.95,10.48"><forename type="first">Theodora</forename><surname>Tsikrika</surname></persName>
							<email>theodora.tsikrika@iti.gr</email>
							<affiliation key="aff0">
								<orgName type="department">Ioannis Kompatsiaris Information Technologies Institute</orgName>
								<orgName type="institution" key="instit1">Stefanos Vrochidis</orgName>
								<orgName type="institution" key="instit2">Centre for Research and Technology Hellas</orgName>
								<address>
									<addrLine>6th Km. Charilaou -Thermi Road</addrLine>
									<postCode>57001</postCode>
									<settlement>Thermi-Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.11,120.56,280.50,15.12;1,171.94,142.48,250.84,15.12">M4D-MKLab/ITI-CERTH Participation in TREC Deep Learning Track 2021</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D7365483B2F849364DD2AD75D553966C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our team's (CERTH ITI M4D) goal in the TREC Deep Learning Track was to study how the Contextualized Embedding Query Expansion (CEQE) <ref type="bibr" coords="1,301.52,327.10,10.52,8.74" target="#b0">[1]</ref> method performs in such setting and how our proposed modifications affect the performance. In particular, we examine how CEQE performs with the addition of bigrams as potential expansion terms, and how an IDF weight component affects the performance. The first run we submitted is produced by a query expansion pipeline that uses BM25 for retrieval and CEQE with the IDF modification for query expansion. The second submitted run used a modification of CEQE with the addition of bigrams as candidate expansion terms and a re-ranking step using CEDR. Our runs showed promising results, especially for Average Precision.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC Deep Learning (DL) track 1 is actively developing and improving a large dataset based on MS MARCO for document and passage retrieval. It offers ample data for the development of novel methodologies while it has the challenge of partially labeled training data that incentivizes semi-supervised and transfer learning.</p><p>Recently, transformers <ref type="bibr" coords="1,192.72,503.95,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,206.01,503.95,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="1,216.54,503.95,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="1,227.08,503.95,7.75,8.74" target="#b4">5,</ref><ref type="bibr" coords="1,237.61,503.95,7.75,8.74" target="#b5">6,</ref><ref type="bibr" coords="1,248.15,503.95,7.75,8.74" target="#b6">7]</ref> and other DL architectures <ref type="bibr" coords="1,378.16,503.95,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="1,391.45,503.95,7.75,8.74" target="#b8">9]</ref> were used to produce word embeddings that allow operations in the vector space instead of using word-based statistics. Moreover, in some cases contextualized word embeddings were produced (which means that the embeddings depend on the neighboring words). Such contextualized embeddings are better equipped to tackle polysemy and other issues that require understanding of the context. Word embeddings have been already studied <ref type="bibr" coords="1,147.17,563.72,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="1,165.70,563.72,12.73,8.74" target="#b10">11,</ref><ref type="bibr" coords="1,181.45,563.72,12.73,8.74" target="#b11">12,</ref><ref type="bibr" coords="1,197.21,563.72,12.73,8.74" target="#b12">13,</ref><ref type="bibr" coords="1,212.97,563.72,12.73,8.74" target="#b13">14,</ref><ref type="bibr" coords="1,228.72,563.72,12.73,8.74" target="#b14">15]</ref> in numerous Information Retrieval (IR) tasks showcasing great results.</p><p>Query Expansion (QE) is a well established technique <ref type="bibr" coords="1,333.08,587.63,15.50,8.74" target="#b15">[16,</ref><ref type="bibr" coords="1,352.11,587.63,12.73,8.74" target="#b16">17,</ref><ref type="bibr" coords="1,368.37,587.63,12.73,8.74" target="#b17">18,</ref><ref type="bibr" coords="1,384.63,587.63,12.73,8.74" target="#b18">19,</ref><ref type="bibr" coords="1,400.88,587.63,12.73,8.74" target="#b19">20]</ref> and entails the process of adding new terms in the original query to better represent the information need. Pseudo-Relevance Feedback (PRF) is a particular family of QE techniques that works on the assumption that the top-K retrieved documents are likely to be relevant and expands the query based on the contents of those documents. Recently, some studies <ref type="bibr" coords="1,233.70,635.45,15.50,8.74" target="#b20">[21,</ref><ref type="bibr" coords="1,252.67,635.45,12.73,8.74" target="#b21">22,</ref><ref type="bibr" coords="1,268.88,635.45,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="1,280.11,635.45,12.73,8.74" target="#b22">23,</ref><ref type="bibr" coords="1,296.31,635.45,12.73,8.74" target="#b23">24]</ref> examined the potential of using contextualized embeddings to perform QE. These studies reported great results, but there are more directions open for exploration. In particular, we performed some preliminary studies on variations of Contextualized Embedding Query Expansion (CEQE) <ref type="bibr" coords="1,248.78,671.32,9.96,8.74" target="#b0">[1]</ref>:</p><p>• How does IDF affect the performance?</p><p>• How does the addition of bigrams affect the performance?</p><p>1 https://microsoft.github.io/msmarco/TREC-Deep-Learning.html</p><p>• How does the addition of term weight affects the performance?</p><p>The rest of the document is structured as follows; Section 2 presents the contextualized embedding methodology and the variations we examined, Section 3 analyzes the experiments and evaluates our performance in TREC DL 2021, and finally Section 4 concludes with an overview of the paper and some future directions for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In this section we present briefly the original CEQE <ref type="bibr" coords="2,303.06,196.80,10.52,8.74" target="#b0">[1]</ref> formulation and its derivation from probabilistic language modeling approaches, especially the Relevance Model <ref type="bibr" coords="2,374.63,208.75,14.61,8.74" target="#b17">[18]</ref>. Subsequently, the two new modifications of CEQE are presented. The two modifications correspond to the runs submitted by our team to TREC DL 2021.</p><p>Probabilistic language modeling approaches quantify the relevance of terms to a query in terms of the probability that the word be generated based on a language model. In the case of PRF the language model is calculated via the set of pseudo-relevant documents and the whole corpus. Equations 1 and 2 show that the probability of a word to be relevant based on the feedback relevance model (θ R ) is proportional to summation of some simpler probabilities that can be estimated through statistical metrics.</p><formula xml:id="formula_0" coords="2,241.04,328.30,276.00,20.06">p(w|θ R ) ∝ D∈R p(w, Q, D)<label>(1)</label></formula><formula xml:id="formula_1" coords="2,157.64,359.99,359.40,20.06">D∈R p(w, Q, D) = D∈R p(w|Q, D)p(D) = D∈R p(w|D)p(Q|D)p(D)<label>(2)</label></formula><p>In order to make the simplifications of equation 2 in original RM formulation is assumed that query Q and term w are independent. In CEQE they note that this assumption is not valid in case of contextualized vector representations as each word is dependent to its context. The CEQE parametrization is presented in eq 3: </p><p>Moreover, in CEQE they propose three methods to calculate p(w|Q, D) according to the updated formulation. First, in eq 4 they define p(w|Q, D) as the normalized distances between the mentions of a word in a document ( ⃗ m D w ) and the centroid of the query ( ⃗ Q). A word mention within a document is the embedding of the word given its context within the document. M D w is the complete set of mentions of a word in a document D. The centroid of a query is defined as the mean of the individual token embeddings, i.e. ⃗ Q ≜ 1 |Q| qi∈Q ⃗ q, where q i is a query token and ⃗ q its embedding. The function δ is a similarity function, e.g. cosine similarity.</p><p>The BERT tokenizer sometimes splits words into multiple tokens (especially complex and long words), for example, "surfboarding" is split into three tokens "['surf', '##board', '##ing']". Such tokens are called wordpieces <ref type="bibr" coords="2,204.86,584.35,14.61,8.74" target="#b24">[25]</ref>. As CEQE works on word-level embeddings it aggregates the individual wordpieces to compose the corresponding word embedding. In particular, it uses the centroid of the token embeddings as the aggregation method, ⃗ w ≜ pi∈w ⃗ p i , where p i are the wordpieces of word w.</p><formula xml:id="formula_3" coords="2,224.29,640.28,292.75,34.35">p(w|Q, D) ≜ m D w ∈M D w δ( ⃗ Q, ⃗ m D w ) m D ∈M D * δ( ⃗ Q, ⃗ m D )<label>(4)</label></formula><p>The other two proposed methods of the new formulation are based on individual query term representations, instead of the centroid. Equation <ref type="formula" coords="2,308.52,692.03,4.98,8.74" target="#formula_4">5</ref>shows the alternative form of the p(w|q, D). This equation differs to eq 4 in that the mentions of a word are compared with all individual query terms. Thus, in order to have an overall similarity between the query and the word, a pooling step is performed. In particular, eq 6 (called "MaxPool") shows the first pooling technique, which defines that similarity to the most similar query term is selected. Eq 7 shows the alternative pooling technique that multiplies the similarities between a word and all the individual query terms. Finally, eq 8 normalizes the results of eq 6 and 7 in order for the final p(w|Q, D) to be a relevance distribution of terms derived from contextual representations in top retrieved documents. Z ′ is a normalization factor that is the sum over the terms in document D.</p><formula xml:id="formula_4" coords="3,227.37,139.61,289.67,34.35">p(w|q, D) ≜ m D w ∈M D w δ(⃗ q, ⃗ m D w ) m D ∈M D * δ(⃗ q, ⃗ m D )<label>(5)</label></formula><formula xml:id="formula_5" coords="3,221.65,185.12,295.39,9.65">f max (w, Q, D) = max q∈Q p(w|q, D)<label>(6)</label></formula><formula xml:id="formula_6" coords="3,230.83,215.00,286.21,20.06">f prod (w, Q, D) = q∈Q p(w|q, D)<label>(7)</label></formula><formula xml:id="formula_7" coords="3,226.70,244.70,290.34,23.00">p(w|Q, D) ≜ f max/prod (w, Q, D) Z ′<label>(8)</label></formula><p>In this work we only used the MaxPool method as it produced the best results as the authors of CEQE showed, and we confirmed it through our own experimentation. The MaxPool formulation seems to be effective in a broader context within the contextualized embeddings as in ColBERT used a similar function for similarity. In particular Khattab and Zaharia <ref type="bibr" coords="3,386.81,308.72,15.50,8.74" target="#b25">[26]</ref> named it MaxSim but is essentially the max similarity between a word and the individual terms of a query/document (query in CEQE, document in ColBERT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">CEQE with IDF and term weights</head><p>Clinchant and Gaussier in their analysis on PRF models <ref type="bibr" coords="3,328.83,378.91,15.50,8.74" target="#b26">[27]</ref> observed that well-known PRF models of that period (published in 2013) tend to select common terms with low IDF, violating the heuristics constraints Fang et al. <ref type="bibr" coords="3,179.51,402.82,15.50,8.74" target="#b27">[28]</ref> formulated, indicating sub-optimal performance.</p><p>In proposed CEQE implementations, the IDF effect is not explicitly satisfied via the equations, as the probability p(w|Q, D) considers solely the similarity within the feedback set. No term distribution metrics are used.</p><formula xml:id="formula_8" coords="3,199.80,460.52,195.11,12.69">f ′ max (w, Q, D) = max q∈Q (IDF w * p(w|q, D))</formula><p>The updated equation (modifies the equation 6) by injecting the IDF of a word w as weight to the probability p(w|q, D). For our preliminary tests we do not modify the normalization step (eq 8) which means that the final scores are not probabilities. However, we performed QE by adding the proposed terms with their corresponding weights to the original query, and the fact that their score is not a probability does not affect this method.</p><p>Moreover, we tried to use the scores as weights in the final retrieval step. The motive for this is to encourage terms that are highly similar to the query (thus having increased score) while discouraging less similar terms. In particular, the parameter λ (0 &lt; λ &lt; 1) applies a weight to the original query terms and λ -1 weight is applied on the expansion terms. For example, without using weights the query "types of dysarthria from cerebral palsy" with λ = 0.2 would be expanded: typeˆ0.2 cerebralˆ0.2 dysarthriaˆ0.2 ofˆ0.2 palsyˆ0.2 fromˆ0.2 speechˆ0.8 motorˆ0.8 musclesˆ0.8 ... Where the first terms are terms from the original query with the weight λ = 0.2 and the following terms are the expansion terms with weight λ = 1 -0.2 = 0.8. While when applying the scores as weights it would be similar to: typeˆ0.2 cerebralˆ0.2 dysarthriaˆ0.2 ofˆ0.2 palsyˆ0.2 fromˆ0.2 speechˆ0.059 motorˆ0.018 mus-clesˆ0.018 ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">CEQE with bigrams</head><p>Another direction that modern QE works on contextualized embeddings seem to leave space for improvement is the utilization of n-grams. Particularly so, because BERT and contextualized embeddings inherently consider context, we hypothesized that groups of neighboring words would represent better the particular meaning of a query. For example, if a word in a particular context is found to match better the meaning of the query, then the neighboring words are likely to be important as well for the particular meaning. Thus, the expansion with bigrams could prove more beneficial than single words in the representation of the information need.</p><p>We generated both unigrams and bigrams from the feedback documents as candidate expansion terms that undergo a similar selection process. The bigram embeddings were generated as the centroid of the two individual terms, in similar fashion to the transition from wordpieces to words. We devised a procedure for selecting the best expansion terms from the pool of unigrams and bigrams. This procedure includes some filtering through the potential bigram expansion terms to remove near duplicates and noisy terms. In detail, the following list presents the filtering conditions:</p><p>1. No bigrams with stopwords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">No bigrams with numbers.</head><p>3. No bigrams with terms from the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>No bigrams with terms that are already selected as unigram expansion term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">No bigrams with terms with document frequency less than 25.</head><p>We observed that stopwords and numbers (conditions 1 &amp; 2) tended to dilute the bigrams and result in bigrams that are not significantly different than their unigram counterparts. Bigrams that include terms from the original query (condition 3) tended to be already sufficiently represented. Likewise, terms that were already selected as unigrams (condition 4) tended to be sufficiently represented already. Finally, similar to AlQatan et al. <ref type="bibr" coords="4,263.68,416.88,15.50,8.74" target="#b28">[29]</ref> we used words above a minimum document frequency (condition 5). Too infrequent terms often were result of imperfect data collection, for example the mangled words "unmuteif" and "palsydysarthria" have low document frequency and indeed they are not good expansion terms. While BERT can make sense of such words, traditional word based methods are hindered by them. Moreover, words that are so under-represented in the collection offer limited potential for improvement as they influence just a handful of document. For example, the query "types of dysarthria from cerebral palsy" is expanded </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section we describe our two submitted runs and offer some analysis on the results. Our modifications on the original CEQE methods were implemented based on the official code <ref type="foot" coords="4,475.45,614.88,3.97,6.12" target="#foot_1">3</ref> . CEQE and the new modifications were integrated to the pyterrier platform <ref type="foot" coords="4,375.24,626.83,3.97,6.12" target="#foot_2">4</ref> . We had a machine with GTX 2080Ti 11GB, 128GB RAM, and an HDD for all stages of our experiments. In both of our runs, the best parameters for the models were selected after grid search using the qrels of TREC DL 2019 and 2020 on the new dataset (this year's MS MARCO v2). In particular, the parameters that were tuned are shown in the table 1. The parameters f b docs and f b terms represent the number of feedback documents and the number of feedback terms and they follow the naming convention of the pyterrier platform that we used. The last parameter lambda (λ) defines the term weight coefficient as described </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Run 1: CEQE with IDF and term weights</head><p>Our first submitted run (ID: bigrams cont qe 5 ) was the result of a query expansion pipeline without reranking. The query expansion was performed via the CEQE algorithm with the addition of IDF component optimized for Normalized Discounted Cumulative Gain with cutoff at 10 (NDCG@10) and the addition of the CEQE scores as term weights (cf. section 2.1). The parameters that yielded the best results in the validation set were f b docs = 5, f b terms = 45, lambda = 0.2. The pipeline follows the three steps:</p><p>1. BM25 for initial retrieval.</p><p>2. Query expansion with CEQE IDF with the score as weights.</p><p>3. BM25 on expanded queries.</p><p>Initially the default BM25 retrieves a set of documents (the number is dictated by the f b docs parameter) for the original query, then the CEQE algorithm expands the query with f b terms expansion terms, and the final documents are retrieved according to the expanded query using the default BM25 again. Inference took 30 seconds per query, but the delay is mostly due to the large size of the index and the absence of an SSD drive.</p><p>Figure <ref type="figure" coords="5,125.05,434.15,4.98,8.74" target="#fig_2">1</ref> shows the percentage of queries that were above, below or at the median in our first run. Each piechart shows the performance for a different metric. In Average Precision ("map") 74% queries achieved better performance than the median. In Precision at 10 ("P 10") 21% of queries were above median and 26% below. In the case of Reciprocal Rank ("recip rank") is not easy to evaluate our performance because the median in all but one query was 1, indicating that most runs retrieved a relevant document in the first position. As the organizers pointed out, due to the large size of the dataset, the number of positive labels is very large. This caused a large number of perfect scores in Precision at 10 and Reciprocal Rank. In Normalized Discounted Cumulative Gain with cutoff at 10 ("ndcg cut 10") we scored above median in slightly less than half (46%) of the queries.</p><p>Figures <ref type="figure" coords="5,128.45,541.75,7.75,8.74" target="#fig_3">3,</ref><ref type="figure" coords="5,140.10,541.75,3.87,8.74" target="#fig_4">4</ref>, 5 and 6 show the performance of our runs per query for the four different metrics. The black horizontal lines cover the whole range between the best and worst performance across all the submitted runs. Figures <ref type="figure" coords="5,222.68,565.66,4.98,8.74" target="#fig_5">5</ref> and<ref type="figure" coords="5,251.91,565.66,4.98,8.74" target="#fig_6">6</ref> confirm that that many runs reached the perfect score at precision@10 and reciprocal due to the numerous positive results in the dataset. Otherwise, there does not seem to be a clear tendency in our run 1.</p><p>Overall, our run performs very well in Average Precision, which is the only metric that evaluates all the top 100 documents. This indicates that our run performs comparatively better outside the top 10 documents. NDCG@10 is the only metric that considers the different similarity labels (0: irrelevant, 1-4: gradually more relevant). The other metrics transform the labels to binary (0: irrelevant, 1-4: relevant). NDCG@10 seems to follow a similar pattern with Precision at 10 in that it performs slightly bellow median, indicating no meaningful difference with the two scoring approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Run 2: CEQE with Bigrams and CEDR reranking</head><p>The second run (ID: bigram qe cedr) improves on the previous pipeline with the addition of a reranking step at the end. This run uses the bigram variation of CEQE algorithm (cf. section 2.2) and was In detail the steps:</p><p>1. BM25 for initial retrieval.</p><p>2. Query expansion with CEQE Bigrams.</p><p>3. BM25 on expanded queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Reranking with CEDR.</head><p>BM25 performed the initial retrieval stage, followed by QE with Bigram variation of CEQE, then BM25 retrieved documents based on the expanded queries, finally, a CEDR model re-ranked the top 100 documents. CEDR was trained with batch size 512, for 126 iterations with early stopping. We used CEDR as a re-ranking step after the query expansion step, to examine the effect of the improved recall along with a final document re-ranking stage. We chose to use CEDR for re-ranking as it produces good results in a reasonable time frame without the necessity of the resource intensive BERT re-training/fine-tuning. We used the PyTerrier port of the CEDR algorithm<ref type="foot" coords="6,445.24,609.64,3.97,6.12" target="#foot_3">6</ref> and the "bertbase-uncased"<ref type="foot" coords="6,139.22,621.59,3.97,6.12" target="#foot_4">7</ref> BERT model. Inference took approximately 35 seconds per query which is 5 seconds slower than the first run that did not include a re-ranking step. This indicates that the re-ranking step did not add a great overhead, and as previously the main cause of delay was the slow disk access (HDD).</p><p>Figure <ref type="figure" coords="6,123.78,670.99,4.98,8.74" target="#fig_1">2</ref> shows the percentage of queries that performed better/worse than median for our second run. The second run seems to follow the tendencies of the first, meaning that it performs very well on Average Precision but less so in the other metrics. This indicates once more that our methodology under-performs in the top 10 documents while performing better than the median in the top 100, in Figure <ref type="figure" coords="7,159.27,368.52,3.87,8.74" target="#fig_1">2</ref>: Percentage of queries that performed better/worse than the median most cases. This result is counter-intuitive given that run 2 has an re-ranking step contrary to run 1. The re-ranking step is expected to rearrange the top 100 documents and boost the score of the most similar, thus, increasing the top 10 metrics (P 10, ndcg cut 10). In practice, it appears that the re-ranking step harmed the performance uniformly in all metrics. This is possibly due to the use of the default BERT model (not fine-tuned) for CEDR, incompatibility issues with the training data (previous years' qrels were used), or some other inaccuracy in CEDR's training.</p><p>Figures <ref type="figure" coords="7,128.59,483.69,7.75,8.74" target="#fig_3">3,</ref><ref type="figure" coords="7,140.43,483.69,3.87,8.74" target="#fig_4">4</ref>, 5 and 6 seem to reinforce the notion that run 2 performed better than median on Average Precision and less so in the other metrics, but we did not identify any other pattern in relation to run 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we presented our participation in TREC DL 2021. We submitted two runs for the document ranking task with some variations of PRF based on BERT embeddings. In our first run we examined the direct addition of IDF as a score component and used the scores as term weights. In our second run we performed QE on both unigrams and bigrams and finally added a CEDR re-ranking stage. The resuls show that our runs performed very well on Average Precision on top 100 documents while they were not as effective in the metrics that examined the top 10 documents. Interestingly, the second run that included a re-ranking step did not perform as well as the first run, likely due to ineffective re-ranking. Overall, our runs' performance was promising and indicates that it can benefit greatly from an effective re-ranking stage.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,200.55,460.36,18.10,6.12;2,220.35,446.41,55.94,8.74;2,279.05,460.36,18.10,6.12;2,298.84,446.41,96.97,8.74"><head></head><label></label><figDesc>D∈R p(w, Q, D) = D∈R p(w|Q, D)p(Q|D)p(D)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,339.30,487.04,3.97,6.12;4,343.77,488.61,2.77,8.74;4,77.67,500.57,437.91,8.74;4,77.67,512.52,439.37,8.74;4,77.67,524.48,19.35,8.74;4,77.67,536.43,439.37,8.74;4,77.67,548.39,182.54,8.74"><head>2 :</head><label>2</label><figDesc>#combine:0=0.95:1=0.95:2=0.95:3=0.95:4=0.95:5=0.95:6=0.05:7=0.05: [...] 41=0.05:42=0.05 [...] ( types of dysarthria from cerebral palsy speech symptoms [...] #1(lobe cranially) #1(also symptom) [...]) Where the first terms are from the original query with weight 0.95 and the following are unigram and bigram expansion terms with weight 0.05.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,127.84,368.52,339.04,8.74;6,113.03,80.52,368.64,276.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Percentage of queries that performed better/worse than the median</figDesc><graphic coords="6,113.03,80.52,368.64,276.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,213.96,630.03,166.79,8.74;8,110.52,176.79,373.68,441.72"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Average Precision per query</figDesc><graphic coords="8,110.52,176.79,373.68,441.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,212.69,630.03,169.32,8.74;9,110.52,176.79,373.68,441.72"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: NDCG at 10 score per query</figDesc><graphic coords="9,110.52,176.79,373.68,441.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,220.48,630.03,153.76,8.74;10,110.52,176.79,373.68,441.72"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Precision at 10 per query</figDesc><graphic coords="10,110.52,176.79,373.68,441.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="11,216.84,630.03,161.03,8.74;11,110.52,176.79,373.68,441.72"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Reciprocal Rank per query</figDesc><graphic coords="11,110.52,176.79,373.68,441.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,113.03,80.52,368.64,276.48"><head></head><label></label><figDesc></figDesc><graphic coords="7,113.03,80.52,368.64,276.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,77.67,82.45,439.37,113.57"><head>Table 1 :</head><label>1</label><figDesc>The parameters that were tuned via grid search in section 2.1. Documents were preprocessed with Porter Stemmer and punctuation and stopword removal.</figDesc><table coords="5,202.37,82.45,189.98,45.83"><row><cell cols="2">Parameter Name Range/Values</cell></row><row><cell>f b docs</cell><cell>5, 10, 15</cell></row><row><cell>f b terms</cell><cell>10, 15, ... 60</cell></row><row><cell>lambda</cell><cell>0.05, 0.1, ... 0.9, 0.95</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="4,92.91,719.62,362.49,6.99"><p>The query formatting is different than in subsection 2.1 in order to enable pair of words to match</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,92.91,729.70,182.57,6.64"><p>https://github.com/sherinaseri/ceqe-release</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,92.91,739.20,182.07,6.64"><p>https://pyterrier.readthedocs.io/en/latest/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="6,92.91,726.36,186.30,6.64"><p>https://github.com/cmacdonald/pyterrier_bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="6,92.91,735.86,170.36,6.64"><p>https://huggingface.co/bert-base-uncased</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>5 Acknowledgements This work has received funding from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme under projects CREST</rs> (Grant Agreement No <rs type="grantNumber">833464</rs>), <rs type="funder">CONNEXIONs</rs> (Grant Agreement No 786731) and <rs type="funder">INFINITY</rs> (Grant Agreement No 883293).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5RcF9cx">
					<idno type="grant-number">833464</idno>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme under projects CREST</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,98.15,189.99,418.89,8.74;12,98.15,201.95,418.89,8.74;12,98.15,213.90,418.89,8.74;12,98.15,225.86,274.86,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,388.74,189.99,128.29,8.74;12,98.15,201.95,110.42,8.74">Ceqe: Contextualized embeddings for query expansion</title>
		<author>
			<persName coords=""><forename type="first">Shahrzad</forename><surname>Naseri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,361.60,213.90,151.29,8.74">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Raffaele</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="467" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.15,245.79,418.89,8.74;12,98.15,257.74,412.78,8.74" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="12,430.56,245.79,86.49,8.74;12,98.15,257.74,232.59,8.74">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,98.15,277.67,418.89,8.74;12,98.15,289.62,418.89,8.74;12,98.15,301.58,105.05,8.74" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m" coord="12,253.09,289.62,185.57,8.74">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,98.15,321.50,418.89,8.74;12,98.15,333.46,337.55,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,496.97,321.50,20.06,8.74;12,98.15,333.46,215.21,8.74">Language models are unsupervised multitask learners</title>
		<author>
			<persName coords=""><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,321.85,333.46,52.47,8.74">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.15,353.38,418.89,8.74;12,98.15,365.34,418.90,8.74;12,98.15,377.29,217.93,8.74" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="12,352.38,365.34,164.67,8.74;12,98.15,377.29,37.66,8.74">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,98.15,397.22,418.89,8.74;12,98.15,409.17,418.89,8.74;12,98.15,421.13,418.89,8.74;12,98.15,433.08,22.69,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,312.35,409.17,204.69,8.74;12,98.15,421.13,263.72,8.74">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>Bart</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,98.15,453.01,418.89,8.74;12,98.15,464.96,418.89,8.74;12,98.15,476.92,105.05,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="12,134.79,464.96,313.47,8.74">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName coords=""><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,98.15,496.84,418.89,8.74;12,98.15,508.80,418.89,8.74;12,98.15,520.75,186.95,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,437.81,496.84,79.23,8.74;12,98.15,508.80,257.29,8.74">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,378.35,508.80,138.69,8.74;12,98.15,520.75,78.35,8.74">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.15,540.68,418.89,8.74;12,98.15,552.63,418.89,8.74;12,98.15,564.59,198.10,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,384.61,540.68,132.43,8.74;12,98.15,552.63,60.28,8.74">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,180.67,552.63,336.36,8.74;12,98.15,564.59,88.11,8.74">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.15,584.51,418.89,8.74;12,98.15,596.47,418.89,8.74;12,98.15,608.43,347.78,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,404.38,584.51,112.66,8.74;12,98.15,596.47,131.87,8.74">Cedr: Contextualized embeddings for document ranking</title>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,249.23,596.47,267.80,8.74;12,98.15,608.43,239.53,8.74">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1101" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.15,628.35,418.89,8.74;12,98.15,640.31,229.30,8.74" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,328.53,628.35,188.51,8.74;12,98.15,640.31,48.86,8.74">Query expansion with locally-trained word embeddings</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07891</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,98.15,660.23,418.89,8.74;12,98.15,672.19,418.89,8.74;12,98.15,684.14,100.79,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,287.85,660.23,173.31,8.74">Query expansion using word embeddings</title>
		<author>
			<persName coords=""><forename type="first">Saar</forename><surname>Kuzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,481.13,660.23,35.91,8.74;12,98.15,672.19,413.66,8.74">Proceedings of the 25th ACM international on conference on information and knowledge management</title>
		<meeting>the 25th ACM international on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1929" to="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,98.15,704.07,418.89,8.74;12,98.15,716.02,296.02,8.74" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="12,396.83,704.07,120.21,8.74;12,98.15,716.02,115.90,8.74">Using word embeddings for automatic query expansion</title>
		<author>
			<persName coords=""><forename type="first">Dwaipayan</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Debjyoti</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Utpal</forename><surname>Garain</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07608</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,98.15,83.67,418.89,8.74;13,98.15,95.63,418.89,8.74;13,98.15,107.58,65.36,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,374.13,83.67,142.90,8.74;13,98.15,95.63,129.58,8.74">Local and global query expansion for hierarchical complex topics</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shahrzad</forename><surname>Naseri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,246.54,95.63,199.66,8.74">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="290" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,127.51,418.90,8.74;13,98.15,139.46,418.89,8.74;13,98.15,151.42,209.39,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,359.63,127.51,157.41,8.74;13,98.15,139.46,182.85,8.74">Exploiting various word embedding models for query expansion in microblog</title>
		<author>
			<persName coords=""><forename type="first">Shafayet</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Abu</forename><surname>Nowshed Chy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Md</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ullah</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,308.45,139.46,208.59,8.74;13,98.15,151.42,99.79,8.74">2020 IEEE 8th R10 Humanitarian Technology Conference (R10-HTC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,171.34,418.89,8.74;13,98.15,183.30,298.85,8.74" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="13,180.39,171.34,336.65,8.74;13,98.15,183.30,200.50,8.74">Relevance feedback in information retrieval. The Smart retrieval systemexperiments in automatic document processing</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,203.23,418.89,8.74;13,98.15,215.18,319.38,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,227.49,203.23,250.35,8.74">Quary expansion using local and global document analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,497.41,203.23,19.63,8.74;13,98.15,215.18,46.37,8.74">Acm sigir forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="168" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,235.11,418.89,8.74;13,98.15,247.06,264.92,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,262.84,235.11,143.52,8.74">Relevance-based language models</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,427.47,235.11,84.35,8.74">ACM SIGIR Forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="260" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,266.99,418.89,8.74;13,98.15,278.94,418.89,8.74;13,98.15,290.90,212.32,8.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,267.14,266.99,245.05,8.74">Revisiting the divergence minimization feedback model</title>
		<author>
			<persName coords=""><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,111.69,278.94,405.35,8.74;13,98.15,290.90,102.92,8.74">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1863" to="1866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,310.82,418.89,8.74;13,98.15,322.78,266.72,8.74" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,389.53,310.82,127.51,8.74;13,98.15,322.78,78.59,8.74">Score distributions for pseudo relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alvaro</forename><surname>Manuel A Presedo-Quindimil</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Barreiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,185.62,322.78,90.25,8.74">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="171" to="181" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,342.70,418.89,8.74;13,98.15,354.66,277.29,8.74" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="13,161.14,342.70,355.90,8.74;13,98.15,354.66,97.48,8.74">Neuralqa: A usable library for question answering (contextual query expansion+ bert) on large datasets</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Dibia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.15211</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,98.15,374.58,78.87,8.74;13,194.63,374.58,238.19,8.74;13,450.44,374.58,66.60,8.74;13,98.15,386.54,105.05,8.74" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="13,194.63,374.58,234.17,8.74">Query expansion with artificially generated texts</title>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Claveau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.08787</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,98.15,406.46,418.89,8.74;13,98.15,418.42,358.10,8.74" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="13,414.83,406.46,102.21,8.74;13,98.15,418.42,178.23,8.74">Bert-qe: contextualized query expansion for document re-ranking</title>
		<author>
			<persName coords=""><forename type="first">Zhi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07258</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,98.15,438.34,418.89,8.74;13,98.15,450.30,345.42,8.74" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="13,387.57,438.34,129.47,8.74;13,98.15,450.30,166.01,8.74">Pseudo-relevance feedback for multiple representation dense retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Tonellotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.11251</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,98.15,470.22,418.89,8.74;13,98.15,482.18,418.89,8.74;13,98.15,494.13,22.69,8.74" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="13,267.01,470.22,142.89,8.74">Japanese and korean voice search</title>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kaisuke</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,430.20,470.22,86.84,8.74;13,98.15,482.18,307.67,8.74">2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,514.06,418.89,8.74;13,98.15,526.01,418.89,8.74;13,98.15,537.97,322.36,8.74" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="13,255.35,514.06,261.69,8.74;13,98.15,526.01,133.89,8.74">Colbert: Efficient and effective passage search via contextualized late interaction over bert</title>
		<author>
			<persName coords=""><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,251.89,526.01,265.15,8.74;13,98.15,537.97,234.03,8.74">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,557.90,418.89,8.74;13,98.15,569.85,418.89,8.74;13,98.15,581.81,22.69,8.74" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="13,270.35,557.90,246.69,8.74;13,98.15,569.85,10.42,8.74">A theoretical analysis of pseudo-relevance feedback models</title>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,130.03,569.85,329.04,8.74">Proceedings of the 2013 Conference on the Theory of Information Retrieval</title>
		<meeting>the 2013 Conference on the Theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,601.73,418.89,8.74;13,98.15,613.69,418.89,8.74;13,98.15,625.64,214.89,8.74" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="13,287.49,601.73,212.40,8.74">A formal study of information retrieval heuristics</title>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,98.15,613.69,418.89,8.74;13,98.15,625.64,126.86,8.74">Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 27th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,98.15,645.57,418.89,8.74;13,98.15,657.52,418.89,8.74;13,98.15,669.48,302.79,8.74" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="13,364.74,645.57,152.30,8.74;13,98.15,657.52,149.64,8.74">Analyzing the influence of bigrams on retrieval bias and effectiveness</title>
		<author>
			<persName coords=""><forename type="first">Abdulaziz</forename><surname>Alqatan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashar</forename><surname>Moshfeghi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,273.68,657.52,243.35,8.74;13,98.15,669.48,204.50,8.74">Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval</title>
		<meeting>the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="157" to="160" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
