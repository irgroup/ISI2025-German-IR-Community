<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.41,99.67,269.18,14.93;1,197.51,119.60,216.98,14.93">NAVER LABS EUROPE (SPLADE) @ TREC DEEP LEARNING 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,162.45,184.61,69.46,8.96"><forename type="first">Carlos</forename><surname>Lassance</surname></persName>
							<email>carlos.lassance@naverlabs.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Naver Labs Europe</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.43,184.61,70.88,8.96"><forename type="first">Thibault</forename><surname>Formal</surname></persName>
							<email>thibault.formal@naverlabs.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Naver Labs Europe and Sorbonne Université</orgName>
								<address>
									<country>ISIR France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.19,245.52,93.62,8.96"><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
							<email>benjamin@piwowarski.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Sorbonne Université</orgName>
								<orgName type="institution" key="instit2">ISIR</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,234.39,306.42,52.60,8.96"><forename type="first">Arnaud</forename><surname>Sors</surname></persName>
							<email>arnaud.sors@naverlabs.com</email>
							<affiliation key="aff3">
								<orgName type="department">Naver Labs Europe</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,293.75,306.42,83.87,8.96"><forename type="first">Stéphane</forename><surname>Clinchant</surname></persName>
							<email>stephane.clinchant@naverlabs.com</email>
							<affiliation key="aff3">
								<orgName type="department">Naver Labs Europe</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.41,99.67,269.18,14.93;1,197.51,119.60,216.98,14.93">NAVER LABS EUROPE (SPLADE) @ TREC DEEP LEARNING 2021</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2A8E86C2F46CF595E7B4EFCF8B015A5A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation to the 2021 TREC Deep Learning challenge. We submitted runs to both passage and document full ranking tasks, with a focus on the passage task, where the goal is to retrieve and rank a set of 100 passages directly from the new MS MARCO v2 collection, containing around 138M entries. We rely on SPLADE for first-stage retrieval. For the second stage, we use an ensemble of BERT re-rankers, trained using hard negatives selected by SPLADE. Three runs were submitted, coming from a diverse set of experiments: i) a fast retriever without re-ranking nor query encoding (SPLADE-doc model), ii) a SPLADE model fully trained on MS MARCO v1, and re-ranked by an ensemble of models, and iii) an ensemble of SPLADE models trained on both new and old MS MARCO, re-ranked by an ensemble of models also trained on both datasets. Much to our surprise, out of the 3 runs, the one trained only on MS MARCO v1 obtained the best results on the TREC competition and is very competitive when compared to the median and best results. More surprising to us is that the results on the dev set of MS MARCO v2 did not correlate with TREC results, contrary to previous years.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we detail our TREC 2021 Deep Learning track submission, based on the SPLADE model <ref type="bibr" coords="1,136.64,635.10,85.12,8.64" target="#b1">[Formal et al., 2021b]</ref>. We introduce several improvements for SPLADE, that are further detailed in the updated version of the model <ref type="bibr" coords="1,284.99,646.01,84.64,8.64">[Formal et al., 2021a]</ref>. We submitted three runs to both passage and document full-ranking tasks, with a focus on the first one. For the document task, we simply score a document by taking the maximum score over its passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MS MARCO v2</head><p>The TREC organizers introduced a new dataset for the Deep Learning track (TREC DL), that we refer to as MS MARCO v2 (and thus MS MARCO v1 for the previous one). The main differences between the two datasets are: i) the size of their respective collection, with v2 containing around fifteen times more passages than v1, and ii) how documents are cut into passages: we now have a mapping from all passages to documents, allowing our participation to the document task, where we do everything in the passage domain and then map ids to the document ones.</p><p>Note that the increased collection size introduces some issues. First, indexing and searching in the collection is more expensive than before. Second, the relevance assignment (qrels) changed a lot due to the way the passages are extracted from documents, causing issues for training and evaluation (Section 3.3). Finally, the amount of documents from the collection that are not seen during training increased a lot, as the amount of queries (and positives/negatives per query) did not change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In the following, we introduce the models we consider for both candidate generation as well as re-ranking. We also describe our training procedure, and detail the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">First Stage -Candidate mining with SPLADE</head><p>SPLADE <ref type="bibr" coords="2,149.06,263.65,82.31,8.64" target="#b1">[Formal et al., 2021b</ref>] is a transformer-based retrieval model, that relies on the Masked Language Modeling (MLM) head and max pooling over the tokens to represent documents and queries. Thus, document/query representations have the same number of dimensions as the amount of tokens in the transformer vocabulary (in this case <ref type="bibr" coords="2,314.54,296.37,105.50,8.64">BERT [Devlin et al., 2018]</ref>, with |V | ≈ 30000). The model is trained by jointly optimizing ranking and regularization losses; consequently, retrieval can be done in a sparse fashion, as only a few dimensions are activated by SPLADE for a given document (or query).</p><p>A variant of such model consists in having only a document encoder: the ranking score is then a simple sum over query <ref type="bibr" coords="2,184.95,356.40,25.27,8.64">(sub-)</ref>words. This model is referred to as SPLADE-doc in <ref type="bibr" coords="2,414.50,356.40,85.12,8.64" target="#b1">[Formal et al., 2021b]</ref>. In this case, the only cost associated with retrieval is the index search, as there is no inference on query side.</p><p>The training of SPLADE is done via optimization of a contrastive loss (InfoNCE) using hardnegatives (from BM25) and in-batch negatives, constrained by a regularization that aims at reducing the amount of expected floating-point operations during retrieval. For our models trained on MS MARCO v1, we build upon recent distillation work <ref type="bibr" coords="2,326.43,427.33,91.44,8.64" target="#b2">[Hofstätter et al., 2020]</ref>, and train SPLADE with the MarginMSE loss 1 (thus replacing the InfoNCE loss). Unfortunately we could not generate the data (i.e. the teacher scores) in time for MS MARCO v2, and thus all SPLADE models trained on v2 do not rely on distillation. Also, note that while it has been shown that hard-negative mining <ref type="bibr" coords="2,138.46,470.97,78.31,8.64" target="#b6">[Xiong et al., 2021]</ref> and intelligent query sampling <ref type="bibr" coords="2,341.86,470.97,93.24,8.64" target="#b2">[Hofstätter et al., 2021]</ref> may improve the results of retrieval, we were not able to integrate it in time for TREC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Second Stage -Re-ranking with cross-attention models</head><p>In recent years it has been shown that re-ranking based on cross-attention models <ref type="bibr" coords="2,124.37,537.05,99.94,8.64" target="#b3">[Nogueira and Cho, 2019</ref>] is paramount for the TREC competitions <ref type="bibr" coords="2,416.01,537.05,83.51,8.64" target="#b1">[Craswell et al., 2020</ref><ref type="bibr" coords="2,499.52,537.05,4.48,8.64;2,108.00,547.95,83.70,8.64" target="#b1">, Craswell et al., 2021]</ref>. In our case, we build upon a recent work 2 [Gao et al., 2021] in order to train our re-rankers.</p><p>The procedure can be summarized shortly: for each annotated query of the training set (either MS MARCO v1 or v2), we draw negatives from the first-stage SPLADE model used for the run, either from the top-100 or top-1000. This training procedure differs from most prior works where rerankers are systematically trained with BM25 negatives, even though being applied on top of other models like dense bi-encoders, introducing a shift between train and test distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ensembling</head><p>We also have applied ensembling in order to improve our results. We proceeded in a very standard way: the score for a document is the mean score over all the individual model scores. -Second stage: An ensemble of seven re-rankers, where: i) 1 is taken "off-the-shelf"<ref type="foot" coords="3,497.52,178.89,3.49,6.05" target="#foot_0">3</ref> , based on MINILM <ref type="bibr" coords="3,241.43,191.46,74.60,8.64" target="#b5">[Wang et al., 2020]</ref>, ii) 2 models are trained on the top-100 results from SPLADE, on the training queries of MS MARCO v1. These models use ELEC-TRA-large <ref type="bibr" coords="3,210.18,213.28,75.54,8.64" target="#b1">[Clark et al., 2020]</ref> and ROBERTA-large <ref type="bibr" coords="3,377.95,213.28,67.24,8.64" target="#b3">[Liu et al., 2019]</ref> as pre-trained checkpoints, and iii) 4 models are trained on the top-1000 results from SPLADE, on the training queries of MS MARCO v1. Three of these models use the ROBER-TA-large <ref type="bibr" coords="3,202.78,246.01,67.24,8.64" target="#b3">[Liu et al., 2019]</ref> as their backbone with different hyperparameters during fine-tuning; the last one relies on ELECTRA-large <ref type="bibr" coords="3,367.55,256.92,69.45,8.64" target="#b1">[Clark et al., 2020</ref>]. • V1 + V2:</p><p>-First stage: An ensemble of 5 SPLADE models. These models are i) the same as the Quick model, ii) the first-stage of V1, iii) a sparser model using the same training as V1, iv) a SPLADE model trained with InfoNCE on the MS MARCO v1 dataset, and v) a SPLADE model trained with InfoNCE on the MS MARCO v2 dataset. We get the top-1000 documents of each model and then perform ensembling via the mean score over all models, in order to choose which documents to consider for re-ranking; -Second stage: An ensemble of ten re-rankers, where: i) 7 are the same as the ones used in V1, and ii) 3 models are trained on the top-1000 results of BM25 on the training queries of MS MARCO v2. The pre-trained checkpoints used are ROBERTA-large <ref type="bibr" coords="3,254.68,386.46,65.44,8.64" target="#b3">[Liu et al., 2019]</ref>, MINILM <ref type="bibr" coords="3,373.90,386.46,76.39,8.64" target="#b5">[Wang et al., 2020]</ref> and ELEC-TRA-large <ref type="bibr" coords="3,209.26,397.37,73.74,8.64" target="#b1">[Clark et al., 2020]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analysis on MS MARCO v1 and v2</head><p>In the following we discuss our experimental process and we analyze the performance of different models on the dev sets of MS MARCO v1 and v2. Note that these analyses are for the passage track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">V1 on MS MARCO v1</head><p>First we inspect the results of our V1 model on MS MARCO v1. This will serve as a baseline for our runs, as we analyze results in numbers that we can compare with prior works and TREC competitions.</p><p>Our first-stage model achieves an impressive (at the time of TREC submission) result of 0.355 MRR@10 and 97.6 R@1k, which compared to other models available at that time was pretty substantial. As far as we are aware, the state of the art for a single non-cross-attention model in June 2021 were i) ColBERT [Khattab and Zaharia, 2020], with 0.36 MRR@10 and 97% R@1k, which would be difficult to scale for TREC before the inclusion of binarization<ref type="foot" coords="3,426.74,594.92,3.49,6.05" target="#foot_1">4</ref> , and ii) TCT-Col-BERT <ref type="bibr" coords="3,135.94,607.50,67.24,8.64" target="#b2">[Lin et al., 2021]</ref> with 0.359 MRR@10 and 97% R@1k. We also evaluate on TREC-2019, where our model was also very competitive with the state of the art at the time.</p><p>By applying our re-ranking ensemble, we are able to jump from 0.355 to 0.425 MRR@10, which is quite an impressive jump, at the expense of a large inference cost.</p><p>Note that in between the beginning of TREC and the writing of this contribution, the state of the art for both single models and two-stage ones has been evolving quickly, with models such as Co-Condenser [Gao and Callan, 2021] (0.382 MRR@10 for single-stage) and AR2 <ref type="bibr" coords="3,425.15,683.91,78.85,8.64" target="#b6">[Zhang et al., 2021]</ref> (0.395 MRR@10 for single-stage). Even our SPLADE model has been able to achieve an MRR@10 of 0.393 by using a combination of pre-training techniques from [Gao and Callan, 2021] and better hard-negatives<ref type="foot" coords="4,169.70,95.63,3.49,6.05" target="#foot_2">5</ref> . For two-stage models, the state of the art has evolved significantly with models such as RocketQAv2 <ref type="bibr" coords="4,206.61,108.20,69.45,8.64" target="#b3">[Ren et al., 2021]</ref> claiming 0.419 MRR@10 with only a dense model and a top-50 re-ranker, as well as other models on the official leaderboard<ref type="foot" coords="4,376.14,117.44,3.49,6.05" target="#foot_3">6</ref> reaching up to 0.44 MRR@10, but without much specification on how exactly the re-rankers are trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments on MS MARCO v2 dev1</head><p>Result analysis We then started experimenting with training on the MS MARCO v2 dev1. The final result table for our three runs (split between single-stage and two-stage retrieval) is available in Table <ref type="table" coords="4,132.09,197.07,3.74,8.64" target="#tab_1">1</ref>, alongside comparison with TCT-ColBERT<ref type="foot" coords="4,311.28,195.40,3.49,6.05" target="#foot_4">7</ref> . Note that while in full ranking mode, (V1+V2) achieves a better result than TCT-ColBERT, it does so with a lot more complexity. On the first-stage front, TCT-ColBERT trained on v2 clearly outperforms (V1+V2), while the one trained on v1 is pretty comparable to our V1. In the next paragraphs we explain our reasoning and how we ended with our final V1+V2 run. Experimental process This year, there was no triplets file that was provided, so we first extracted the top-100 negatives from BM25 (given by the organizers) and generated triplets with them. In doing so, we noticed that training SPLADE was very dependent on the negatives, and that top-100 negatives does not seem to be sufficient; we expect the same to be true for dense models, but were not able to test it due to time constraints.</p><p>We then extracted the top-1000 negatives from BM25 and re-trained our SPLADE models. This time, results were a little bit better, but not enough to justify a run trained solely on MS MARCO v2. The next step would be to generate new hard-negative triplets and re-ranker scores of those triplets (for distillation training), but due to time constraints and dataset size, we were not able to do so. Thus, we took an ensemble of SPLADE models trained on MS MARCO v1 alongside our v2 trained model for our first-stage ranker (V1+V2), which improved slightly the results over the V1 run.</p><p>Finally as a re-ranker, we would like to use the same reasoning as for the V1 run. However due to timing constraints, we had to use BM25 to train re-rankers on the MS MARCO v2. Individually, the re-rankers did not achieve very strong results, but their ensemble was able to improve effectiveness by a large margin. Finally, we decided to consider an ensemble of re-rankers trained solely on v2 and the ones trained solely on v1, in order to reduce the train/test discrepancy, which allowed us to get some final points on MS MARCO v2 dev1.</p><p>Conclusion Overall, our experiments with the v2 dev dataset were quite unsuccessful, with our v2trained model achieving almost the same performance as the V1 one. We could achieve significant improvements in the dev dataset only by ensembling first-stage models and v2-trained re-rankers.</p><p>In the next paragraphs, we perform an analysis to better understand what are the reasons for this difference, and why training with the v2 dataset was so complex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of MS MARCO v2 labels</head><p>In order to get an idea of how noisy the MS MARCO v2 labels are, we randomly drew 52 training queries and manually re-evaluated the relevance of positive and negative passages. For the positive passage we evaluated whether it was relevant or not for answering the query. For the negative passages, we only looked up to the top-20 'hardest' (from BM25), and evaluated whether at least one false negative was present in this top-20. For 7 of the 52 queries, we were not confident in our manual evaluation, usually because the query was unclear, too general, or passages too short. We excluded these 7 queries. Figure <ref type="figure" coords="5,241.80,160.91,4.98,8.64" target="#fig_0">1</ref> shows the result of our annotation on the 45 remaining queries. About a quarter of positives passages are actually negatives. Moreover, about two third of the queries have at least one false negative in the top-20 of BM25. Out of these, we also observed that many had more than one, although we cannot provide an average number because we did not look at all 20 passages for all queries. Overall, only about a quarter of all queries have correct annotation for the top-20. In the next section, we posit that these labelling issues could be the cause of the difference in performance from dev1 to TREC 2021. Also, note that while we expect a lot of false negatives in the MS MARCO collection, the presence of false positives is something new that could possibly change a lot how we perform training on this dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TREC DL 2021 -initial analysis 4.1 Overall analysis</head><p>Passage track Considering the results on MS MARCO v2 dev1, we were expecting models to have similar performance on TREC 2021, i.e. V2+V1 &gt; V1 &gt; Quick, with lower performance in absolute terms when compared to what we were used to in the previous TREC competitions (around 0.7 nDCG@10) would be a very large downgrade. However, results turned out to be different, as we can see in Table <ref type="table" coords="5,192.01,620.76,3.74,8.64" target="#tab_3">2</ref>. Compared to the mean of best results per query and the mean of median, the results seem good enough and we are eager to know how it compares to other solutions. Also, our best model (V1) is inline with what we saw in previous years (absolute nDCG@10 around 0.7), but it was not the one we expected to perform best. Because our best model is the one trained on MS MARCO v1, it might indicate that the new dataset has some issues that need to be fixed before training.</p><p>We note that <ref type="bibr" coords="5,162.06,691.70,96.55,8.64" target="#b0">[Arabzadeh et al., 2021]</ref> recently argued that the noisy MS MARCO labels are problematic, possibly leading to wrong conclusions about the model ranking and true performance. It could be the case here again: before the assessment, we thought that the V1+V2 model was the best according to its dev performance. However, we see that after manual assessment, it is quite the opposite conclusion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Track</head><p>For this track we submitted runs from the same models as the passage ones, using max pooling over passages: the document score is the maximum score over its passages. Therefore we get results that are very inline with what we saw on the passage track (see Table <ref type="table" coords="6,493.21,253.45,3.60,8.64" target="#tab_4">3</ref>).</p><p>As expected, when compared to the mean of best and mean of medians the document results are inferior to the passage ones. In-depth analysis In Tables 4 (passage) and Table <ref type="table" coords="6,329.56,404.32,4.98,8.64" target="#tab_9">5</ref> (document) of the appendix section, we present the results of our best run (V1) in all queries and compare it to the mean and median nDCG@10 results. For the passage track, we have 12 queries out of 53 (23%) for which we have the best nDCG@10. On the other hand, we also have 8 queries for which we have a result that is at most 1 nDCG point (0.01) better than the median, with 4 of those 8 where we are worse than the median. This is better than what we expected during the competition / after seeing some results on the dev1 dataset. To better understand the positives and negatives results of our passage submission, we have selected 5 queries: the 2 "worst" performing queries and the 3 "best" performing queries, that we analyze in detail in the following. For more information on the queries and the retrieved documents please see Section A in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Worst performing queries</head><p>Query 838273 -what is the methylmalon a. c test: This is the worst performing query of our V1 method, with a 0.13 nDCG@10 loss compared to the median (and 0.31 points loss compared to the best). When analyzing the top-5 results, what we see is that while we always retrieve a relevant passage, it is not necessarily neither considered very relevant nor perfect. This mostly happens because we are retrieving passages that explain what the test is, but not always for what it is used. This might be linked to the training strategy, that only considers binary relevance (and not a graded one), making it difficult for models with this type of query.</p><p>Query 190623 -for what is david w. taylor known: The other worst performing query fails for a completely different reason. While the loss of performance is not as dramatic as in the previous case, we are still 0.03 points worse than the median (and a whooping 0.52 points worse than the best). When analyzing our top-5 results, what we actually see is that the model did not understand that the entity "David W. Taylor" was, and actually retrieved results for e.g. "David Taylor" and "Taylor", or it failed in the same was as before and found things that are related to the entity, but that are not the person itself (e.g. a research center dedicated to the person). This entity problem has actually being studied recently in <ref type="bibr" coords="6,242.75,713.51,93.82,8.64" target="#b4">[Sciavolino et al., 2021]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Best performing queries</head><p>Query 629937 -what does a popped blood vessel in hand feel like: This is a rather hard query as there are some important -but not obvious -words ("in hand"); the V1 model is able to find perfectly relevant passages for the entire top-5. We do not gain much knowledge from analysing this result other that being able to consider "in finger" as something that is "in hand" to be very helpful. We are able to achieve an nDCG@10 of 0.88, which is 0.3 points better than the median.</p><p>Query 1104447 -which kind of continental boundary is formed where two plates move horizontally past one another: This is a very long query with a lot of specific sequences ("continental boundary", "two plates", "move horizontally") for which retrieving correct results without proper context could be very hard; this type of query clearly benefits from contextualization. We are able to get a perfect score nDCG@10 of 1.0, while the median is almost 0.4 points lower.</p><p>Query 661905 -what foods should you stay away from if you have asthma: This query has rather weird results. None of the top-10 passages is considered more than relevant (R@10 = 0) but we get a reasonably good nDCG@5 and nDCG@10 (0.5). All of the top-5 are scored only as relevant, but to us should be considered as highly relevant, especially when compared to the answers that were considered highly relevant. Nonetheless our model gets the best result at 0.5 nDCG@10, while the median is of only 0.28 which is on the top-5 of worst median scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>For the TREC DL 21 competition, we submitted runs based on several variants of SPLADE for firststage ranking, followed by an ensemble of BERT re-rankers trained with hard negatives selected by SPLADE. Much to our surprise, the run trained on MS MARCO v1 obtained the best results on the track, even though evaluation was done on the new dataset. More surprising to us is that the results on the dev set of MS MARCO v2 do not seem to correlate with the TREC results, contrary to previous years. We qualitatively inspect the best and worse performing queries and find some advantages and issues with our models, that we aim to improve. Finally, the results seem to indicate that our document approach (i.e. performing everything with passages and mapping the ids to documents) was not as successful as our passage runs.</p><p>A Analysed Queries Top-5 passages retrieved by V1:</p><p>1. Relevance score: 1-Relevant. The methylmalonic acid test is performed on blood plasma or blood serum taken from a standard blood draw. Typically, a doctor or nurse will take a blood sample from your arm in a clinical setting. The blood will be collected in a tube and sent to a lab for analysis. Once the lab reports the results, your doctor will be able to provide you with more information about the results and what they mean. 2. Relevance score: 1-Relevant. The methylmalonic acid test is performed on blood plasma or blood serum taken from a standard blood draw. Typically, a doctor or nurse will take a blood sample from your arm in a clinical setting. The blood will be collected in a tube and sent to a lab for analysis. Once the lab reports the results, your doctor will be able to provide you with more information about the results and what they mean. 3. Relevance score: 3-Perfect. Methylmalonic acid test. The methylmalonic acid blood test measures the amount of methylmalonic acid in the blood. The methylmalonic acid test may be used to help diagnose an early or mild vitamin B12 deficiency. It may be ordered by itself or along with a homocysteine test as a follow-up to a vitamin B12 test result that is in the lower end of the normal range.</p><p>4. Relevance score: 3-Perfect. Methylmalonic acid test. The methylmalonic acid blood test measures the amount of methylmalonic acid in the blood. The methylmalonic acid test may be used to help diagnose an early or mild vitamin B12 deficiency. It may be ordered by itself or along with a homocysteine test as a follow-up to a vitamin B12 test result that is in the lower end of the normal range. Text: what does a popped blood vessel in hand feel like nDCG@10 comparison: V1: 88.2; Median: 59.2; Best: 88.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Relevance</head><p>Top-5 passages retrieved by V1:</p><p>1. Relevance score: 3-Perfect. Popped Blood Vessel In Hand Symptoms. The condition will show under the layer of transparent skin and is characterized by: Bright red or dark appearance in the outermost layer of the skin. A feeling of minor pain upon contact.</p><p>2. Relevance score: 3-Perfect. Popped Blood Vessel In Hand Symptoms. The condition will show under the layer of transparent skin and is characterized by: Bright red or dark appearance in the outermost layer of the skin. A feeling of minor pain upon contact.</p><p>3. Relevance score: 3-Perfect. Symptoms of popped blood vessel in hand: Bursting of blood vessels or popped blood vessel in hand and subsequent bleeding under the skin of your hands has the following symptoms: Swelling in the affected area of the skin. In some cases, an associated fracture in the bone may take place. Some pain (minor) may be felt upon touching the affected area. 4. Relevance score: 3-Perfect. Symptoms of a Popped Blood Vessel in the Finger. Onset of this condition is sudden or may follow after a minor injury. Sudden onset of intense burning pain felt in the hand or finger. Sudden localized swelling. 5. Relevance score: 3-Perfect. Symptoms of a Popped Blood Vessel in the Finger. Onset of this condition is sudden or follow after a minor injury. Sudden onset of intense burning pain felt in the hand or finger. Sudden localized swelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Query 1104447</head><p>Text: which kind of continental boundary is formed where two plates move horizontally past one another nDCG@10 comparison: V1: 100.0; Median: 62.2; Top: 100.0</p><p>Top-5 passages retrieved by V1:</p><p>1. Relevance score: 3-Perfect. 3. Relevance score: 1-Relevant. Cut out foods that aggravate your asthma. People with asthma may have certain food triggers that are typically unique to each person. In general, individuals with asthma should avoid the common triggers such as eggs, fish, peanuts, soy, yeast, cheese, wheat and rice. 4. Relevance score: 1-Relevant. Cut out foods that aggravate your asthma. People with asthma have certain food triggers that are typically unique to each person. In general, individuals with asthma should avoid the common triggers such as eggs, fish, peanuts, soy, yeast, cheese, wheat and rice. 5. Relevance score: 1-Relevant. Citrus fruits and tomatoes. People with asthma should avoid citrus fruits and tomatoes. Both contain a lot of nutrients and fiber, which benefit your health, but they also have some components that can worsen asthma symptoms. You don't have to stop eating them overnight, but at least make an effort to lower your consumption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Query by query result tables</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,108.00,489.51,396.00,8.64;5,108.00,500.42,284.36,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Manual Assessment of 45 queries MS MARCO v2 and their labels: out of the 45 analysed queries, more than a quarter of the positives are actually false positives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,108.00,691.46,396.00,30.53"><head></head><label></label><figDesc>Based only on the SPLADE-doc model, trained with InfoNCE on the MS MARCO v1 triplets; • V1: -First stage: Based on the distilled SPLADE model, trained with MarginMSE on the MS MARCO v1 model. The top-1000 documents are kept for the next stage.</figDesc><table coords="2,108.00,691.46,396.00,19.65"><row><cell>1 using</cell><cell>the</cell><cell>provided</cell><cell>cross-encoder</cell><cell>teacher</cell><cell>scores</cell><cell>from</cell><cell>https://github.com/</cell></row><row><cell cols="4">sebastian-hofstaetter/neural-ranking-kd</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="2,120.65,712.30,2.99,5.18;2,124.14,714.16,217.43,7.83;3,108.00,75.09,130.63,8.96;3,108.00,95.45,239.47,8.64;3,135.40,116.29,35.00,8.82"><p><p><p><p>2 code available at https://github.com/luyug/Reranker</p>2.4 Runs submitted to TREC</p>For our TREC submission, we considered three approaches:</p>• Quick:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,108.00,260.14,396.00,110.79"><head>Table 1 :</head><label>1</label><figDesc>Experiments on the MS MARCO v2 dev1 dataset. MRR numbers are multiplied by 100 for ease of presentation.</figDesc><table coords="4,113.30,291.86,385.39,79.06"><row><cell>Run</cell><cell></cell><cell>First Stage</cell><cell></cell><cell></cell><cell cols="2">Full Ranking</cell><cell cols="2">TCT-ColBERT v2</cell></row><row><cell>Metric</cell><cell>Quick</cell><cell>V1</cell><cell cols="2">V1+V2 Quick</cell><cell>V1</cell><cell cols="3">V1+V2 MS MARCO v1 MS MARCO v2</cell></row><row><cell>MRR@10</cell><cell>12.2</cell><cell>13.0</cell><cell>14.1</cell><cell>12.2</cell><cell>17.7</cell><cell>21.6</cell><cell>-</cell><cell>-</cell></row><row><cell>MRR@100</cell><cell>13.2</cell><cell>14.1</cell><cell>15.5</cell><cell>13.2</cell><cell>18.8</cell><cell>22.7</cell><cell>14.7</cell><cell>20.0</cell></row><row><cell>R@10</cell><cell cols="6">26.7% 28.3% 30.2% 26.7% 35.4% 39.7%</cell><cell>27.5%</cell><cell>-</cell></row><row><cell>R@100</cell><cell cols="6">54.0% 57.2% 57.9% 54.0% 64.3% 67.4%</cell><cell>58.8%</cell><cell>64.0%</cell></row><row><cell>R@1000</cell><cell cols="6">75.7% 80.7% 81.8% 75.7% 80.7% 81.8%</cell><cell>83.2%</cell><cell>84.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,108.00,107.90,396.00,97.93"><head>Table 2 :</head><label>2</label><figDesc>TREC DL 21 Results on the passage track. nDCG@10 values have been multiplied by 100 for ease of presentation.</figDesc><table coords="6,113.84,140.06,381.88,65.78"><row><cell>Run</cell><cell></cell><cell>First Stage</cell><cell></cell><cell></cell><cell cols="2">Full Ranking</cell><cell></cell><cell>Baselines</cell><cell></cell></row><row><cell>Metric</cell><cell>Quick</cell><cell>V1</cell><cell cols="2">V1+V2 Quick</cell><cell>V1</cell><cell cols="4">V1+V2 BM25 Median Best</cell></row><row><cell>nDCG@10</cell><cell>60.9</cell><cell>65.3</cell><cell>60.2</cell><cell>60.9</cell><cell>73.5</cell><cell>67.2</cell><cell>44.6</cell><cell>60.0</cell><cell>83.7</cell></row><row><cell>R@10</cell><cell cols="7">13.4% 16.8% 16.6% 13.4% 18.9% 17.4% 9.60%</cell><cell>-</cell><cell>-</cell></row><row><cell>R@100</cell><cell cols="7">46.8% 52.7% 49.2% 46.8% 60.4% 57.0% 32.6%</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,108.00,296.78,396.00,81.78"><head>Table 3 :</head><label>3</label><figDesc>TREC DL 21 Results on the document track. nDCG@10 values have been multiplied by 100 for ease of presentation.</figDesc><table coords="6,113.78,328.71,382.04,49.85"><row><cell cols="2">Metric Quick</cell><cell>V1</cell><cell cols="2">V1+V2 Quick</cell><cell>V1</cell><cell cols="4">V1+V2 BM25 Median Best</cell></row><row><cell>nDCG@10</cell><cell>60.2</cell><cell>63.2</cell><cell>60.6</cell><cell>60.2</cell><cell>72.2</cell><cell>68.7</cell><cell>51.2</cell><cell>66.0</cell><cell>85.7</cell></row><row><cell cols="2">Recall@10 8.5%</cell><cell>9.2%</cell><cell>8.4%</cell><cell cols="3">8.50% 10.7% 10.4%</cell><cell>7.8%</cell><cell>-</cell><cell>-</cell></row><row><cell cols="8">Recall@100 31.3% 35.6% 32.5% 31.3% 41.3% 39.6% 31.9%</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,108.00,134.90,396.00,438.94"><head></head><label></label><figDesc>score: 1-Relevant. Methylmalonate Test -More Information. The methylmalonic acid test, also known as a methylmalonic acid blood test, methylmalonate lab test and an MMA level test, measures the methylmalonic acid blood level. Relevance score: 3-Perfect. Rear Adm. David W. Taylor. Rear Admiral David Watson Taylor, USN (March 4, 1864 -July 28, 1940) was a naval architect and engineer of the United States Navy. He served during World War I as Chief Constructor of the Navy, and Chief of the Bureau of Construction and Repair. Taylor is best known as the man who constructed the first experimental towing tank ever built in the United States. 2. Relevance score: 0-Irrelevant. World Champ David taylor the magic man. World Champ. David taylor the magic man. David Taylor, widely known as The Magic Man, is a 4x NCAA All-American, 4x BIG 10 Champion, and a 2x NCAA Champion -and he's just getting started. Having wrapped up his NCAA career in March of 2014, David is just getting started on his international career and ultimately, his quest for Gold in Tokyo, 2020. Taylor is best known for being the former lead singer of the music group Kool &amp; the Gang. Taylor worked as an amateur night club singer and joined his first band at 13. He joined Kool &amp; The Gang in 1979 and became their lead singer in 1979. 5. Relevance score: 0-Irrelevant. Taylor is predominately known for his roles as Romeo in Student Bodies, and Kwest in Instant Star. He played the role of Lewis 'Lou' Young in the Canadian police drama television series Flashpoint until his character was killed in the 23rd episode (part of the second season).</figDesc><table coords="9,108.00,180.82,252.10,393.02"><row><cell>A.1.2 Query 190623</cell></row><row><cell>Text: for what is david w. taylor known</cell></row><row><cell>nDCG@10 comparison: V1: 40.5; Median: 44.4; Best: 92.6</cell></row><row><cell>Top-5 documents from V1:</cell></row><row><cell>1. A.2 Best performing queries</cell></row><row><cell>A.2.1 Query 629937</cell></row></table><note coords="9,131.41,388.87,372.59,8.82;9,143.87,399.96,360.14,8.64;9,143.87,410.87,360.14,8.64;9,143.87,421.78,135.66,8.64;9,131.41,437.56,133.33,8.82"><p>3. Relevance score: 1-Relevant. History. The facility was previously known as the David W. Taylor Naval Ship Research and Development Center; it was renamed "David Taylor Research Center (DTRC)" in 1987 and later became the " Carderock Division of the Naval Surface Warfare Center " in 1992. 4. Relevance score: 0-Irrelevant.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,108.00,312.08,396.00,410.07"><head></head><label></label><figDesc>Transform boundaries. Most boundaries are either convergent or divergent, but transform boundaries occur in a few places to accommodate lateral motion, where plates move horizontally past one another. This type of boundary is very rare on continents, but they are dramatic where they do occur. 2. Relevance score: 3-Perfect. Transform boundaries. Most boundaries are either convergent or divergent, but transform boundaries occur in a few places to accommodate lateral motion, where plates move horizontally past one another. This type of boundary is very rare on continents, but they are dramatic where they do occur. 3. Relevance score: 3-Perfect. In some places, two plates move apart from each other; this is called a diverging plate boundary. Elsewhere two plate move together; this is a converging plate boundary. Finally plates can also slide past each other horizontally. This is called a transform plate boundary. 4. Relevance score: 3-Perfect. The way one plate moves relative to another determines the type of boundary: spreading, where the two plates move away from each other; subduction, where the two plates move toward each other, with one sliding beneath the other; and transform, where the two plates slide horizontally past each other. 5. Relevance score: 3-Perfect. The way one plate moves relative to another determines the type of boundary: spreading, where the two plates move away from each other; subduction, where the two plates move toward each other, with one sliding beneath the other; and transform, where the two plates slide horizontally past each other. Relevance score: 1-Relevant. Beans, cabbage, fried foods, carbonated drinks, onion and garlic are foods to avoid if you have asthma. World Asthma Day 2018: Asthmatic patients should avoid processed foods. 2. People who have asthma should avoid processed foods since they come with added preservatives and flavours. 2. Relevance score: 1-Relevant. Foods to Avoid if You Have Asthma. 1. Cheese. Cheese is a troublesome dairy product that has been linked to the development of asthma in several studies, and has also been shown to exacerbate symptoms ( 2 ).</figDesc><table coords="10,108.00,558.26,263.56,94.41"><row><cell>A.2.3 Query 661905</cell></row><row><cell>Text: what foods should you stay away from if you have asthma</cell></row><row><cell>nDCG@10 comparison: V1: 50.0; Median: 28.2; Top: 50.0.</cell></row><row><cell>Top-5 passages retrieved by V1:</cell></row><row><cell>1.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,108.00,76.67,396.00,635.17"><head>Table 4 :</head><label>4</label><figDesc>Query level results for V1 on the passage full ranking task. nDCG@10 results are given and have been multiplied by 100 for ease of presentation. Numbers are underscored if V1 is not able to outperform the median by at least 1 point and are bolded if it gets the best nDCG@10 for a query.</figDesc><table coords="12,176.50,119.83,259.01,592.00"><row><cell cols="2">Query Id V1</cell><cell cols="4">Best V1 vs Best Median V1 vs Median</cell></row><row><cell>2082</cell><cell cols="2">88.7 100</cell><cell>-11.3</cell><cell>82.9</cell><cell>5.8</cell></row><row><cell>23287</cell><cell cols="2">54.3 65.3</cell><cell>-11.0</cell><cell>26.5</cell><cell>27.8</cell></row><row><cell>30611</cell><cell cols="2">31.3 75.7</cell><cell>-44.4</cell><cell>31.0</cell><cell>0.2</cell></row><row><cell>112700</cell><cell cols="2">47.8 68.9</cell><cell>-21.1</cell><cell>47.8</cell><cell>0.0</cell></row><row><cell>168329</cell><cell cols="2">69.4 74.0</cell><cell>-4.6</cell><cell>68.5</cell><cell>0.9</cell></row><row><cell>190623</cell><cell cols="2">40.5 92.6</cell><cell>-52.1</cell><cell>44.4</cell><cell>-3.9</cell></row><row><cell>226975</cell><cell cols="2">44.6 66.8</cell><cell>-22.2</cell><cell>28.9</cell><cell>15.7</cell></row><row><cell>237669</cell><cell cols="2">75.7 91.9</cell><cell>-16.3</cell><cell>54.0</cell><cell>21.7</cell></row><row><cell>253263</cell><cell cols="2">69.6 89.1</cell><cell>-19.5</cell><cell>62.1</cell><cell>7.5</cell></row><row><cell>300025</cell><cell cols="2">78.3 83.9</cell><cell>-5.6</cell><cell>53.9</cell><cell>24.4</cell></row><row><cell>300986</cell><cell cols="2">69.9 79.4</cell><cell>-9.5</cell><cell>62.3</cell><cell>7.6</cell></row><row><cell>337656</cell><cell cols="2">65.2 71.9</cell><cell>-6.7</cell><cell>26.9</cell><cell>38.2</cell></row><row><cell>364210</cell><cell cols="2">84.8 84.8</cell><cell>0.0</cell><cell>78.7</cell><cell>6.1</cell></row><row><cell>395948</cell><cell cols="2">68.4 72.7</cell><cell>-4.3</cell><cell>60.9</cell><cell>7.5</cell></row><row><cell>421946</cell><cell cols="2">77.2 92.6</cell><cell>-15.4</cell><cell>65.7</cell><cell>11.5</cell></row><row><cell>493490</cell><cell cols="2">94.3 100</cell><cell>-5.7</cell><cell>85.5</cell><cell>8.8</cell></row><row><cell>505390</cell><cell cols="2">70.9 86.8</cell><cell>-15.9</cell><cell>66.1</cell><cell>4.9</cell></row><row><cell>508292</cell><cell cols="2">50.0 53.9</cell><cell>-3.9</cell><cell>46.8</cell><cell>3.2</cell></row><row><cell>540006</cell><cell cols="2">86.5 88.0</cell><cell>-1.6</cell><cell>63.0</cell><cell>23.4</cell></row><row><cell>596569</cell><cell cols="2">92.6 100</cell><cell>-7.4</cell><cell>56.5</cell><cell>36.1</cell></row><row><cell>629937</cell><cell cols="2">88.2 88.2</cell><cell>0.0</cell><cell>57.2</cell><cell>31.0</cell></row><row><cell>646091</cell><cell cols="2">74.4 84.0</cell><cell>-9.7</cell><cell>65.4</cell><cell>8.9</cell></row><row><cell>647362</cell><cell cols="2">95.3 95.3</cell><cell>0.0</cell><cell>62.7</cell><cell>32.6</cell></row><row><cell>661905</cell><cell>50</cell><cell>50</cell><cell>0.0</cell><cell>28.2</cell><cell>21.8</cell></row><row><cell>681645</cell><cell cols="2">71.8 71.8</cell><cell>0.0</cell><cell>52.1</cell><cell>19.7</cell></row><row><cell>688007</cell><cell cols="2">51.1 74.6</cell><cell>-23.4</cell><cell>53.2</cell><cell>-2.1</cell></row><row><cell>707882</cell><cell cols="2">100 100</cell><cell>0.0</cell><cell>95.2</cell><cell>4.9</cell></row><row><cell>764738</cell><cell cols="2">62.2 86.6</cell><cell>-24.3</cell><cell>60.4</cell><cell>1.9</cell></row><row><cell>806694</cell><cell cols="2">95.4 96.6</cell><cell>-1.3</cell><cell>81.2</cell><cell>14.2</cell></row><row><cell>818583</cell><cell cols="2">61.1 76.2</cell><cell>-15.1</cell><cell>47.3</cell><cell>13.8</cell></row><row><cell>832573</cell><cell cols="2">46.3 77.2</cell><cell>-30.9</cell><cell>59.2</cell><cell>-12.9</cell></row><row><cell>835760</cell><cell cols="2">77.7 86.0</cell><cell>-8.4</cell><cell>71.9</cell><cell>5.7</cell></row><row><cell>845121</cell><cell cols="2">57.9 61.2</cell><cell>-3.2</cell><cell>35.1</cell><cell>22.8</cell></row><row><cell>935353</cell><cell cols="2">91.8 94.2</cell><cell>-2.4</cell><cell>44.4</cell><cell>47.4</cell></row><row><cell>935964</cell><cell cols="2">97.8 97.8</cell><cell>0.0</cell><cell>75.8</cell><cell>22.0</cell></row><row><cell>952262</cell><cell cols="2">100 100</cell><cell>0.0</cell><cell>93.6</cell><cell>6.4</cell></row><row><cell>952284</cell><cell cols="2">60.9 77.8</cell><cell>-16.9</cell><cell>43.3</cell><cell>17.6</cell></row><row><cell>975079</cell><cell cols="2">67.9 76.1</cell><cell>-8.2</cell><cell>58.1</cell><cell>9.8</cell></row><row><cell cols="3">1006728 51.7 64.4</cell><cell>-12.7</cell><cell>34.9</cell><cell>16.7</cell></row><row><cell cols="3">1040198 68.1 88.7</cell><cell>-20.7</cell><cell>59.3</cell><cell>8.7</cell></row><row><cell cols="3">1104300 100 100</cell><cell>0.0</cell><cell>92.2</cell><cell>7.8</cell></row><row><cell cols="3">1104447 100 100</cell><cell>0.0</cell><cell>62.2</cell><cell>37.8</cell></row><row><cell cols="3">1107704 59.5 64.9</cell><cell>-5.3</cell><cell>24.5</cell><cell>35.1</cell></row><row><cell cols="3">1107821 71.7 91.0</cell><cell>-19.4</cell><cell>71.6</cell><cell>0.1</cell></row><row><cell cols="3">1109840 80.3 82.9</cell><cell>-2.6</cell><cell>67.4</cell><cell>12.9</cell></row><row><cell cols="3">1110996 77.9 94.6</cell><cell>-16.7</cell><cell>73.5</cell><cell>4.4</cell></row><row><cell cols="3">1111577 71.5 75.8</cell><cell>-4.2</cell><cell>51.5</cell><cell>20.1</cell></row><row><cell cols="3">1113361 100 100</cell><cell>0.0</cell><cell>95.5</cell><cell>4.5</cell></row><row><cell cols="3">1117243 84.8 84.8</cell><cell>0.0</cell><cell>75.4</cell><cell>9.4</cell></row><row><cell cols="3">1118716 80.9 84.5</cell><cell>-3.6</cell><cell>63.2</cell><cell>17.6</cell></row><row><cell cols="3">1121909 85.2 95.8</cell><cell>-10.6</cell><cell>66.0</cell><cell>19.2</cell></row><row><cell cols="3">1128632 80.9 90.1</cell><cell>-9.2</cell><cell>82.2</cell><cell>-1.2</cell></row><row><cell cols="3">1129560 80.7 86.1</cell><cell>-5.4</cell><cell>62.5</cell><cell>18.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="13,108.00,72.13,396.00,656.98"><head>Table 5 :</head><label>5</label><figDesc>Query level results for V1 on the document full ranking task. nDCG@10 results are given and have been multiplied by 100 for ease of presentation. Numbers are underscored if V1 is not able to outperform the median by at least 1 point and are bolded if it gets the best nDCG@10 for a query.</figDesc><table coords="13,175.95,115.30,260.10,613.82"><row><cell cols="2">Query Id V1</cell><cell cols="4">Max V1 vs Max Median V1 vs Median</cell></row><row><cell>2082</cell><cell cols="2">76.0 100</cell><cell>-23.9</cell><cell>92.3</cell><cell>-16.3</cell></row><row><cell>23287</cell><cell cols="2">67.6 71.5</cell><cell>-3.9</cell><cell>37.9</cell><cell>29.6</cell></row><row><cell>30611</cell><cell cols="2">78.3 88.4</cell><cell>-10.0</cell><cell>67.6</cell><cell>10.7</cell></row><row><cell>112700</cell><cell cols="2">53.5 72.4</cell><cell>-18.7</cell><cell>48.1</cell><cell>5.5</cell></row><row><cell>168329</cell><cell cols="2">84.2 93.7</cell><cell>-9.4</cell><cell>80.8</cell><cell>3.5</cell></row><row><cell>190623</cell><cell cols="2">38.7 77.1</cell><cell>-38.4</cell><cell>58.9</cell><cell>-20.2</cell></row><row><cell>226975</cell><cell cols="2">48.1 57.0</cell><cell>-8.9</cell><cell>30.2</cell><cell>17.9</cell></row><row><cell>237669</cell><cell cols="2">78.8 89.8</cell><cell>-10.9</cell><cell>74.9</cell><cell>3.9</cell></row><row><cell>253263</cell><cell cols="2">65.3 83.9</cell><cell>-18.6</cell><cell>46.2</cell><cell>19.1</cell></row><row><cell>300025</cell><cell cols="2">90.9 90.9</cell><cell>0</cell><cell>60.2</cell><cell>30.6</cell></row><row><cell>300986</cell><cell cols="2">64.7 81.8</cell><cell>-17.1</cell><cell>66.5</cell><cell>-1.8</cell></row><row><cell>337656</cell><cell cols="2">49.5 90.1</cell><cell>-40.6</cell><cell>45.2</cell><cell>4.3</cell></row><row><cell>364210</cell><cell cols="2">89.9 97.8</cell><cell>-7.9</cell><cell>91.7</cell><cell>-1.8</cell></row><row><cell>395948</cell><cell cols="2">73.7 95.5</cell><cell>-21.8</cell><cell>80.9</cell><cell>-7.2</cell></row><row><cell>421946</cell><cell cols="2">53.8 78.4</cell><cell>-24.6</cell><cell>66.2</cell><cell>-12.3</cell></row><row><cell>493490</cell><cell cols="2">87.8 100</cell><cell>-12.2</cell><cell>95.1</cell><cell>-7.3</cell></row><row><cell>505390</cell><cell cols="2">85.8 93.3</cell><cell>-7.5</cell><cell>81.7</cell><cell>4.1</cell></row><row><cell>508292</cell><cell cols="2">54.7 71.4</cell><cell>-16.7</cell><cell>56.3</cell><cell>-1.6</cell></row><row><cell>540006</cell><cell cols="2">87.3 89.7</cell><cell>-2.4</cell><cell>79.3</cell><cell>8.0</cell></row><row><cell>596569</cell><cell cols="2">76.9 97.7</cell><cell>-20.8</cell><cell>63.5</cell><cell>13.4</cell></row><row><cell>615176</cell><cell cols="2">54.1 78.2</cell><cell>-24.1</cell><cell>49.6</cell><cell>4.5</cell></row><row><cell>629937</cell><cell cols="2">75.3 80.9</cell><cell>-5.7</cell><cell>57.8</cell><cell>17.4</cell></row><row><cell>632075</cell><cell cols="2">28.3 53.8</cell><cell>-25.5</cell><cell>22.1</cell><cell>6.3</cell></row><row><cell>646091</cell><cell cols="2">68.6 88.3</cell><cell>-19.7</cell><cell>73.4</cell><cell>-4.8</cell></row><row><cell>647362</cell><cell cols="2">100 100</cell><cell>0</cell><cell>72.7</cell><cell>27.3</cell></row><row><cell>661905</cell><cell cols="2">56.4 80.3</cell><cell>-23.9</cell><cell>39.1</cell><cell>17.3</cell></row><row><cell>681645</cell><cell cols="2">70.7 81.6</cell><cell>-10.9</cell><cell>61.5</cell><cell>9.1</cell></row><row><cell>688007</cell><cell cols="2">88.4 90.9</cell><cell>-2.6</cell><cell>79.7</cell><cell>8.7</cell></row><row><cell>707882</cell><cell cols="2">80.4 93.4</cell><cell>-12.9</cell><cell>78.3</cell><cell>2.2</cell></row><row><cell>764738</cell><cell cols="2">72.9 84.8</cell><cell>-11.9</cell><cell>73.1</cell><cell>-0.2</cell></row><row><cell>806694</cell><cell cols="2">85.0 95.7</cell><cell>-10.6</cell><cell>74.9</cell><cell>10.1</cell></row><row><cell>818583</cell><cell cols="2">31.1 73.3</cell><cell>-42.2</cell><cell>49.4</cell><cell>-18.3</cell></row><row><cell>832573</cell><cell cols="2">79.8 93.9</cell><cell>-14.1</cell><cell>75.7</cell><cell>4.1</cell></row><row><cell>835760</cell><cell cols="2">86.6 95.7</cell><cell>-9.1</cell><cell>86.6</cell><cell>0.0</cell></row><row><cell>845121</cell><cell cols="2">72.3 94.6</cell><cell>-22.2</cell><cell>63.3</cell><cell>9.1</cell></row><row><cell>935353</cell><cell cols="2">68.2 79.9</cell><cell>-11.8</cell><cell>49.4</cell><cell>18.8</cell></row><row><cell>935964</cell><cell cols="2">97.8 97.9</cell><cell>-0.1</cell><cell>82.6</cell><cell>15.2</cell></row><row><cell>952262</cell><cell cols="2">100 100</cell><cell>0</cell><cell>100</cell><cell>0.0</cell></row><row><cell>952284</cell><cell cols="2">52.5 64.5</cell><cell>-12.0</cell><cell>44.9</cell><cell>7.6</cell></row><row><cell>975079</cell><cell cols="2">57.1 82.6</cell><cell>-25.4</cell><cell>53.3</cell><cell>3.9</cell></row><row><cell cols="3">1006728 34.1 56.9</cell><cell>-22.8</cell><cell>40.2</cell><cell>-6.1</cell></row><row><cell cols="3">1040198 61.2 76.4</cell><cell>-15.2</cell><cell>47.4</cell><cell>13.8</cell></row><row><cell cols="3">1103547 89.0 100</cell><cell>-11.0</cell><cell>100</cell><cell>-11.0</cell></row><row><cell cols="3">1104300 92.8 100</cell><cell>-7.2</cell><cell>92.0</cell><cell>0.8</cell></row><row><cell cols="3">1104447 97.9 100</cell><cell>-2.1</cell><cell>75.8</cell><cell>22.1</cell></row><row><cell cols="3">1107704 82.4 88.2</cell><cell>-5.7</cell><cell>61.4</cell><cell>21.0</cell></row><row><cell cols="3">1107821 75.2 76.7</cell><cell>-1.6</cell><cell>57.8</cell><cell>17.4</cell></row><row><cell cols="3">1109840 53.5 67.8</cell><cell>-14.3</cell><cell>49.3</cell><cell>4.2</cell></row><row><cell cols="3">1110996 93.7 100</cell><cell>-6.3</cell><cell>93.2</cell><cell>0.5</cell></row><row><cell cols="3">1111577 78.7 86.9</cell><cell>-8.3</cell><cell>71.3</cell><cell>7.4</cell></row><row><cell cols="3">1113361 96.8 100</cell><cell>-3.2</cell><cell>96.8</cell><cell>0.0</cell></row><row><cell cols="3">1117243 75.5 91.5</cell><cell>-15.9</cell><cell>56.2</cell><cell>19.3</cell></row><row><cell cols="3">1117298 70.9 82.9</cell><cell>-12.1</cell><cell>66.9</cell><cell>4.0</cell></row><row><cell cols="3">1118716 65.5 87.1</cell><cell>-21.6</cell><cell>39.7</cell><cell>25.8</cell></row><row><cell cols="3">1128632 86.8 100</cell><cell>-13.2</cell><cell>92.9</cell><cell>-6.2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,124.14,703.65,285.43,7.47"><p>https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-12-v2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,124.14,714.52,301.76,7.47"><p>https://github.com/stanford-futuredata/ColBERT/tree/binarization</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="4,124.14,682.53,378.92,7.83"><p>from https://huggingface.co/datasets/sentence-transformers/msmarco-hard-negatives</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,124.14,693.41,131.16,7.77"><p>https://microsoft.github.io/msmarco/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,124.14,704.20,437.25,7.83;4,108.00,714.52,213.82,7.47"><p>available at https://github.com/castorini/pyserini/blob/3e4c2837a72ef72b1bee08e4132765db51aa7714/ docs/experiments-msmarco-v2-tct_colbert-v2.md</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.65,474.04,391.36,8.64;7,119.62,484.95,100.16,8.64" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><surname>Arabzadeh</surname></persName>
		</author>
		<title level="m" coord="7,471.60,474.04,32.41,8.64;7,119.62,484.95,96.49,8.64">Shallow pooling for sparse labels</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,108.00,499.88,396.00,8.64;7,119.62,510.61,384.38,8.82;7,108.00,525.73,396.00,8.64;7,119.62,536.63,133.35,8.64;7,108.00,551.57,396.00,8.64;7,119.62,562.30,356.41,8.82;7,108.00,577.41,396.00,8.64;7,119.62,588.14,347.51,8.82;7,108.00,603.26,396.00,8.64;7,119.62,614.17,259.61,8.64;7,108.00,629.10,396.00,8.64;7,119.62,639.83,384.39,8.82;7,119.62,650.74,384.38,8.82;7,119.62,661.83,244.37,8.64;7,108.00,676.76,396.00,8.64;7,119.62,687.49,295.73,8.82;7,108.00,702.61,396.00,8.64;7,119.62,713.51,117.10,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,453.68,525.73,50.32,8.64;7,119.62,536.63,129.61,8.64;7,152.25,562.48,181.78,8.64;7,427.28,577.41,76.72,8.64;7,119.62,588.32,245.07,8.64;7,476.89,603.26,27.12,8.64;7,119.62,614.17,256.10,8.64;7,416.38,629.10,87.62,8.64;7,119.62,640.01,168.85,8.64;7,328.37,676.76,175.63,8.64;7,119.62,687.67,153.95,8.64">Unsupervised corpus aware language model pre-training for dense passage retrieval</title>
		<author>
			<persName coords=""><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<idno>arXiv:2108.05540</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,452.30,499.88,51.71,8.64;7,119.62,510.79,242.94,8.64;7,443.66,603.26,25.11,8.64;7,305.89,639.83,198.12,8.59;7,119.62,650.74,310.11,8.82;7,354.40,702.61,149.61,8.64;7,119.62,713.51,113.26,8.64">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Piwowarski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Clinchant</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename></persName>
		</editor>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Gao and Callan</publisher>
			<date type="published" when="2018">2020. 2020. 2021. 2021. 2020. 2020. 2018. 2018. 2021. 2021b. 2021. 2021. 2021</date>
			<biblScope unit="page" from="2288" to="2292" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Rethink training of bert rerankers in multi-stage retrieval pipeline</note>
</biblStruct>

<biblStruct coords="8,108.00,75.48,396.00,8.64;8,119.62,86.39,384.39,8.64;8,119.62,97.12,61.53,8.59;8,108.00,111.41,396.00,8.64;8,119.62,122.32,384.39,8.64;8,108.00,136.43,396.00,8.64;8,119.62,147.16,384.38,8.82;8,119.62,158.07,384.38,8.82;8,119.62,169.16,313.82,8.64;8,108.00,183.27,396.00,8.64;8,119.62,194.00,384.38,8.82;8,119.62,204.91,290.48,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,119.62,86.39,363.35,8.64;8,151.47,122.32,349.07,8.64;8,378.33,136.43,125.68,8.64;8,119.62,147.34,234.29,8.64;8,367.15,183.27,136.86,8.64;8,119.62,194.18,234.89,8.64">In-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval</title>
		<author>
			<persName coords=""><surname>Hofstätter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,119.62,97.12,56.96,8.59;8,372.79,147.16,131.21,8.59;8,119.62,158.07,384.38,8.82;8,119.62,169.16,11.83,8.64;8,372.47,194.00,131.53,8.59;8,119.62,204.91,146.31,8.59">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;20</title>
		<editor>
			<persName><forename type="first">Lin</forename></persName>
		</editor>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2021. 2021. 2020. 2020. 2021</date>
			<biblScope unit="page" from="163" to="173" />
		</imprint>
	</monogr>
	<note>Proceedings of the 6th Workshop on Representation Learning for NLP. RepL4NLP-2021</note>
</biblStruct>

<biblStruct coords="8,108.00,219.20,396.00,8.64;8,119.62,230.11,384.39,8.64;8,119.62,240.84,167.86,8.82;8,108.00,255.13,362.58,8.64;8,108.00,269.24,396.00,8.64;8,119.62,280.15,384.38,8.64" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="8,296.47,230.11,207.53,8.64;8,119.62,241.02,25.37,8.64;8,354.52,255.13,112.46,8.64">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019. 2019. 2019. 2019. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Passage re-ranking with bert. Ren et al., 2021. Rocketqav2: A joint training method for dense passage retrieval and passage re-ranking</note>
</biblStruct>

<biblStruct coords="8,108.00,294.26,396.00,8.64;8,119.62,305.17,175.28,8.64" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,446.34,294.26,57.66,8.64;8,119.62,305.17,171.67,8.64">Simple entitycentric questions challenge dense retrievers</title>
		<author>
			<persName coords=""><surname>Sciavolino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,108.00,319.28,396.00,8.64;8,119.62,330.01,384.38,8.82;8,119.62,340.92,110.05,8.59" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,471.34,319.28,32.67,8.64;8,119.62,330.19,353.70,8.64">Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers</title>
		<author>
			<persName coords=""><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10957</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.70,355.21,391.30,8.64;8,119.62,366.12,384.39,8.64;8,119.62,376.85,270.48,8.82;8,108.00,391.14,396.00,8.64;8,119.62,402.05,180.12,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,208.01,366.12,295.99,8.64;8,119.62,377.03,31.67,8.64">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName coords=""><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,169.18,376.85,216.77,8.59;8,476.14,391.14,27.87,8.64;8,119.62,402.05,176.60,8.64">Adversarial retriever-ranker for dense text retrieval</title>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2021. 2021</date>
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
