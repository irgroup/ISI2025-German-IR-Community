<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.58,75.47,290.64,12.60">CincyMedIR at TREC 2021 Clinical Trial Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.58,93.58,52.40,10.80"><forename type="first">Hoang</forename><surname>Vu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Informatics</orgName>
								<orgName type="institution">University of Cincinnati College of Medicine</orgName>
								<address>
									<settlement>Cincinnati</settlement>
									<region>OH</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep2">College of Engineering and Applied Science</orgName>
								<orgName type="institution">University of Cincinnati</orgName>
								<address>
									<settlement>Cincinnati</settlement>
									<region>OH</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.10,93.58,138.61,10.80"><roleName>PhD, MSI</roleName><forename type="first">Danny</forename><forename type="middle">T Y</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Informatics</orgName>
								<orgName type="institution">University of Cincinnati College of Medicine</orgName>
								<address>
									<settlement>Cincinnati</settlement>
									<region>OH</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep2">College of Engineering and Applied Science</orgName>
								<orgName type="institution">University of Cincinnati</orgName>
								<address>
									<settlement>Cincinnati</settlement>
									<region>OH</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.58,75.47,290.64,12.60">CincyMedIR at TREC 2021 Clinical Trial Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">83DC333EAA1B0CB3F875B850C4907B24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The CincyMedIR team led by Dr. Danny T.Y. Wu at the University of Cincinnati College of Medicine participated in the Text Retrieval Conference 2021 Clinical Trials Track (TREC-CT). This year, we applied our existing text-retrieval methods from our previous TREC tracks on the new Clinical Trials track while also experimenting with new techniques to process the trial exclusion criteria.</p><p>Method Similar to our past TREC tracks, we continued to use Elasticsearch as the information retrieval platform. However, for the nature of clinical trials, this time we focused more on filtering based on the extracted information, including age, gender, and exclusion criteria, prior to performing the text search. We applied three filters to the clinical trials. First of all, we extracted the patient's age and gender from the topic file by applying a list of regular expression rules and filtering only trials whose age and gender requirements match the patient's. Secondly, we filtered only trials with the "recruiting" status. Thirdly, we extracted negating concepts from both the topic description and the trial exclusion criteria and crossed out trials with matching negating concepts with the topic description. We used the python pipeline negspaCy paired with the python model scispaCy "en_ner_bc5cdr_md" to extract negating chemical and disease concepts from the texts. In the end, the top 1000 trials are retrieved for each topic by performing text search with Elasticsearch that queried the topic description against the trial title, brief summary, and detailed description. Our different runs are just different orderings of filters and search, i.e., which filters come before the search (pre-filters) and which filters come after the search (reranking). For our past TREC tracks, we also used Learning to Rank algorithms to sort the search results based on relevance feedback provided by TREC, but we did not do it this time as we did not find supervised data relevant to the Clinical Trials corpus.  <ref type="table" coords="2,265.84,426.45,4.50,10.80">1</ref>. Performance of runs * These runs were not submitted to TREC-CT but generated after the conferenceusing trec_eval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Table <ref type="table" coords="2,102.01,473.95,6.00,10.80">1</ref> shows that the performance of our submitted runs (1, 2, 3, 4, and 5) did not differ much. For ndcg_cut_10 and P_10, the results were exactly the same. For recip_rank, the results were slightly different. It can be inferred that the top 10 relevant trials retrieved by all runs were the same, which makes sense because the ordering of filters and search does not matter for the top few relevant trials. All our scores were below the median. The scores listed in table 1 are the means of the individual score for each topic. For some topics, the performance of our runs surpassed the median. The ID of these topics are: 1, <ref type="bibr" coords="2,323.35,569.22,213.00,10.80;2,72.03,585.00,125.24,10.80">3, 4, 7, 11, 14, 15, 16, 20, 25, 26, 27, 31, 42, 44, 45, 51, 61, 65, and 73.</ref> After the conference, we learned that our filters were counterproductive as they hard-filtered out many relevant trials. We generated four more runs where some filters are completely removed. Most of these additional runs showed better performance. Age and gender are the only pre-filters of the best run, CincyMedIR_7, which suggested that they were the only good hard filters. Recruiting status was a bad filter since it significantly lowered the scores as seen in CincyMedIR_8. Exclusion criteria did not lower the scores as much; it provided some useful information, yet should not be used as a hard filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We did not achieve high performance for the Clinical Trials track this year. The hard-filtering method dragged the performance. The additional runs that have all the filters removed except age and gender achieved better. While the recruiting status did not seem to be relevant, we have gathered useful information by extracting negation terms from the exclusion criteria. We plan to refine our method by turning the exclusion criteria matching from a hard filter into a score and combining it with the text matching score. We expect to utilize Learning to Rank algorithms using relevance feedback as the training data and continue to learn from other teams' techniques at the conference. Lastly, we thank the organizers of TREC-CT for their effort and look forward to participating in the track next year.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
