<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.66,115.96,328.04,12.62">DOSSIER at TREC 2021 Clinical Trials Track</title>
				<funder ref="#_KfsMxdF">
					<orgName type="full">EU Horizon 2020 ITN/ETN on Domain Specific Systems for Information Extraction and Retrieval -DoSSIER</orgName>
				</funder>
				<funder ref="#_VvT4WD4">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,217.91,153.63,64.81,8.74"><forename type="first">Wojciech</forename><surname>Kusa</surname></persName>
							<email>wojciech.kusa@tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">TU Wien</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.88,153.63,76.26,8.74"><forename type="first">Yasin</forename><surname>Ghafourian</surname></persName>
							<email>yasin.ghafourian@researchstudio.at</email>
							<affiliation key="aff0">
								<orgName type="institution">TU Wien</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Research Studios Austria</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.66,115.96,328.04,12.62">DOSSIER at TREC 2021 Clinical Trials Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E0022928A0CA82EBD7B3906111956AF7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our experimental setup and results for the Clinical Trials Track at TREC 2021. In particular, we study (i) the effectiveness of post-processing with patients' metadata and (ii) the novel re-ranking formula using eligibility criteria. We find that the postprocessing improves the model over the baseline run. However, the custom re-ranking negatively impacts average results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents an overview of the DoSSIER team's submissions to the TREC 2021 Clinical Trials Track<ref type="foot" coords="1,278.67,367.03,3.97,6.12" target="#foot_0">1</ref> . The main objective of the system was to retrieve all relevant clinical trials to the given 75 topics, which represent patients' descriptions. The clinical trials dataset consisted of a snapshot of a Clinical-Trials.gov website, with around 370 thousand different trials. Clinical trials are research studies designed to assess medical, surgical, or behavioural interventions. They contain lengthy descriptions and inclusion/exclusion criteria which are utilized to evaluate the trial-patient eligibility <ref type="bibr" coords="1,359.29,440.33,9.96,8.74" target="#b0">[1]</ref>. On the other hand, patients' descriptions contain a free text case description of a patient, a simulation of an admission statement in an Electronic Health Record (EHR) format.</p><p>We submit three runs coming from subsequent stages of the same architecture. We study the effectiveness of post-processing with patients' metadata compared to using baseline BM25 model. We try to model the rule that the most relevant trials should be that for which the patient's history overlaps with all inclusion criteria and, at the same time, with none of the exclusion criteria. We use a custom re-ranking formula that utilises inclusion and exclusion criteria to score the trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Figure <ref type="figure" coords="1,166.42,602.09,4.98,8.74">1</ref> describes the overall architecture and workflow of the system we used for all three submission runs.</p><p>Clinical trials are semi-structured documents containing multiple sections, e.g., title, summary, detailed description, or eligibility criteria. Both trials and Fig. <ref type="figure" coords="2,170.89,292.57,4.13,7.89">1</ref>. General workflow of the system we used for all three submission runs.</p><p>topics are written in complex language and contain medical jargon. We preprocess documents and topics using the ScispaCy en core sci sm<ref type="foot" coords="2,425.15,338.16,3.97,6.12" target="#foot_1">2</ref> biomedical language model <ref type="bibr" coords="2,207.89,351.69,9.96,8.74" target="#b1">[2]</ref>. We concatenate title, brief summary and eligibility criteria fields into a single text that represents every clinical trial. We index that data using the BM25Okapi model from the rank bm25 Python package<ref type="foot" coords="2,447.13,374.03,3.97,6.12" target="#foot_2">3</ref> . After indexing, 2,000 best clinical trials for each patient that best match them are retrieved.</p><p>We manually annotate topics to extract age, gender and health status information from each patient description. This information is available in the description of the clinical trials in separate fields, which requires only parsing the XML file. We normalise these three concepts: age is a floating-point variable, and both gender and health status are binary categories.</p><p>Inclusion and exclusion criteria are mentioned in a semi-structured or unstructured format inside the trial's eligibility section. We extract this information using a rule-based approach. We successfully extracted both inclusion and exclusion criteria for 91% of documents. We split the inclusion/exclusion texts into a list of concepts. When the extraction of inclusion criteria is not possible, we utilise the full text of the trial as inclusion information. If we cannot extract exclusion criteria, we assume an empty text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">baseline</head><p>The first submission consists of 1,000 top-ranked clinical trials returned by the BM25 model for each topic. We use the default parameters for the BM25 algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">postproc</head><p>The top 2,000 trials retrieved by the BM25 model are post-processed using age, gender and health status data extracted from patients descriptions. Retrieved trials are filtered based on the stored metadata to remove the mismatches. Using the filtering, we remove on average 34% of potentially ineligible trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">rerank</head><p>Our third submission uses as an initial pool the output from the postproc run. It utilises a custom formula for re-ranking using SPECTER language model <ref type="bibr" coords="3,467.30,238.93,9.96,8.74" target="#b2">[3]</ref>. An overview of the re-ranking formula is presented in Figure <ref type="figure" coords="3,399.95,250.88,3.87,8.74" target="#fig_0">2</ref>. In the first step, we take the lists with inclusion and exclusion criteria and encode them one by one using SPECTER. We do the same for the patient description. We calculate the cosine similarity between inclusion criteria and the patient encoding and also exclusion criteria and patient. We sort both of them and take the three highest inclusion and exclusion similarity scores. We calculate the final score using the following formula:</p><formula xml:id="formula_0" coords="3,223.40,343.79,158.98,25.41">score = 3 i=1 IN i 3 â€¢ 1 - 3 i=1 EX i 3</formula><p>where IN i means i-th most similar inclusion criterion score and EX i means i-th most similar exclusion criterion. This is based on the reasoning that the patient's description should overlap with inclusion criteria and be as much distinct as possible to the exclusion criteria. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Results are presented in Table <ref type="table" coords="4,266.31,139.99,3.87,8.74" target="#tab_0">1</ref>. Even though the extraction was conducted only with heuristics, post-processing with patient metadata improves all scores when compared to the baseline submission. Our custom re-ranking not only does not improve on the previous run but even further lowers the scores for all metrics when compared to the baseline. We assume that the choice of the formula to calculate the final re-ranking score had the most significant negative impact on the last submission. Due to the time and resource constraints, we could not test other formula variations. To check to what extent each step improves on the previous ones, we tested the pairwise difference between NDCG@10 scores for each topic (Table <ref type="table" coords="4,448.42,384.73,3.87,8.74" target="#tab_1">2</ref>). The second run (postproc) achieves higher NDCG@10 scores for 44 and 52 topics than runs 1 and 3. Surprisingly, baseline obtained higher NDCG@10 over postproc for 13 topics. We believe that these might be caused by inaccurate extraction of the metadata from topics and clinical trials. Even though rerank achieved the worse mean scores, it still improved on 21 topics compared to postproc. Further analysis would be needed to check if this improvement is a meaningful gain from the re-ranking retrieving new relevant documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We submitted three runs to the Clinical Trials track of TREC 2021 and studied the effectiveness of post-processing with patient's metadata and a novel neural re-ranking formula. We found that the post-processing improves the model performance over the baseline run, but the custom re-ranking negatively impacts average results. In a future iteration of this system, we plan to evaluate other re-ranking formulas using the eligibility criteria.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,202.40,632.19,210.55,7.89;3,136.49,448.22,342.37,169.21"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Description of the neural re-ranking process.</figDesc><graphic coords="3,136.49,448.22,342.37,169.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,136.49,115.83,342.37,161.97"><head></head><label></label><figDesc></figDesc><graphic coords="2,136.49,115.83,342.37,161.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,251.78,345.83,93.07"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison for submitted runs with across query averaged median values.</figDesc><table coords="4,169.40,281.79,269.79,63.06"><row><cell>Metric</cell><cell>TREC's Median</cell><cell cols="3">baseline (1) postproc (2) rerank (3)</cell></row><row><cell>NDCG@5</cell><cell>-</cell><cell>0.401</cell><cell>0.455</cell><cell>0.322</cell></row><row><cell>NDCG@10</cell><cell>0.304</cell><cell>0.380</cell><cell>0.413</cell><cell>0.293</cell></row><row><cell>PREC@10</cell><cell>0.161</cell><cell>0.208</cell><cell>0.252</cell><cell>0.187</cell></row><row><cell cols="2">Reciprocal Rank 0.294</cell><cell>0.406</cell><cell>0.478</cell><cell>0.368</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,498.45,345.83,81.71"><head>Table 2 .</head><label>2</label><figDesc>Aggregation of pairwise inter-run comparisons for single topics for ND-CGG@10 metric.</figDesc><table coords="4,199.37,528.07,213.53,52.10"><row><cell>Run A : Run B</cell><cell>Run A higher</cell><cell>Equal scores</cell><cell>Run B higher</cell></row><row><cell>baseline (1) : postproc (2)</cell><cell>13</cell><cell>18</cell><cell>44</cell></row><row><cell>baseline (1) : rerank (3)</cell><cell>45</cell><cell>3</cell><cell>27</cell></row><row><cell>postproc (2) : rerank (3)</cell><cell>52</cell><cell>2</cell><cell>21</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,656.80,146.05,7.86"><p>https://www.trec-cds.org/2021.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,645.84,134.04,7.86"><p>https://allenai.github.io/scispacy</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,656.80,150.89,7.86"><p>https://pypi.org/project/rank-bm25/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by the <rs type="funder">EU Horizon 2020 ITN/ETN on Domain Specific Systems for Information Extraction and Retrieval -DoSSIER</rs> (<rs type="grantNumber">H2020-EU.1.3.1</rs>., ID: <rs type="grantNumber">860721</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KfsMxdF">
					<idno type="grant-number">H2020-EU.1.3.1</idno>
				</org>
				<org type="funding" xml:id="_VvT4WD4">
					<idno type="grant-number">860721</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,258.15,342.24,7.86;5,146.91,269.11,333.68,7.86;5,146.91,280.07,261.95,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,342.34,258.15,138.25,7.86;5,146.91,269.11,333.68,7.86;5,146.91,280.07,23.76,7.86">Physicians&apos; perceptions of an electronic health record-based clinical trial alert approach to subject recruitment: a survey</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Embi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,177.70,280.07,186.65,7.86">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,291.03,342.24,7.86;5,146.91,301.99,333.68,7.86;5,146.91,312.95,242.95,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,421.99,291.03,58.60,7.86;5,146.91,301.99,257.45,7.86">ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,422.36,301.99,58.23,7.86;5,146.91,312.95,183.56,7.86">Proceedings of the 18th BioNLP Workshop and Shared Task</title>
		<meeting>the 18th BioNLP Workshop and Shared Task</meeting>
		<imprint>
			<date type="published" when="2019-08">2019. August</date>
			<biblScope unit="page" from="319" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,323.91,342.25,7.86;5,146.91,334.87,333.68,7.86;5,146.91,345.83,333.68,7.86;5,146.91,356.78,175.32,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,172.42,334.87,308.18,7.86;5,146.91,345.83,51.19,7.86">SPECTER: Document-level Representation Learning using Citation-informed Transformers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,218.90,345.83,261.70,7.86;5,146.91,356.78,106.72,7.86">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020-07">2020, July</date>
			<biblScope unit="page" from="2270" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
