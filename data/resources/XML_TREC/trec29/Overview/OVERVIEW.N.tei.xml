<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,186.61,164.85,238.03,15.12">TREC 2020 News Track Overview</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-11">November 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,187.03,197.33,60.94,10.48"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
						</author>
						<author>
							<persName coords="1,256.94,197.33,78.42,10.48"><forename type="first">Shudong</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName coords="1,345.37,197.33,78.84,10.48;1,291.65,211.28,27.96,10.48"><forename type="first">Donna</forename><forename type="middle">Harman</forename><surname>Nist</surname></persName>
						</author>
						<title level="a" type="main" coord="1,186.61,164.85,238.03,15.12">TREC 2020 News Track Overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11">November 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">26B92339AB8C27088AA77F379569AFC7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The News track focuses on information retrieval in the service of helping people read the news. In 2018, in cooperation with the Washington Post 1 , we released a new collection of nearly 600,000 news articles, and crafted two tasks related to how news is presented on the web: background linking and entity ranking. For 2020, we added more documents to the collection and retired the entity ranking task in favor of a new wikification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>While news content has been a common genre in IR experimentation for a very long time, the evaluation tasks in IR have rarely if ever supported the "news user" -a consumer of news that is not an analyst. According to Pew Research studies, in 2018, 34% of U.S. adults said they preferred to get news online 2 In 2019, they found that about 20% of U.S. adults say they get political news primarily through social media 3 . They also found that readers getting their information on major news stories such as the coronavirus outbreak from social media tended to be less knowledgeable about those topics than those who received their news from other sources.</p><p>Moreover, since online delivery of news has shifted the focus away from the provider or publisher towards the story, news production has been dramatically democratized. If everyone can produce professional looking news, then understanding the context and background of information becomes a harder task for the consumer. In conjunction with The Washington Post, we are developing tasks around how news is presented on the web and thinking about how to support the reader in understanding the news.</p><p>1 Certain companies and/or products are identified in this paper in order to specify the experimental procedure adequately. Such identification is not intended to imply recommendation or endorsement by NIST, nor is it intended to imply that the company or product identified are necessarily the best available for the purpose.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The initial run of the track in TREC 2018 introduced two tasks: recommending articles to read as background in the context of the article a user is presently reading (background linking) and ranking the entities mentioned in the article in order of how important it is to link to a Wikipedia page for that entity in order to provide background context (entity ranking). <ref type="bibr" coords="2,420.21,175.78,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,432.63,175.78,7.75,8.74" target="#b1">2]</ref> For the 2020 track, the entity ranking task was replaced with a new wikification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The data for the News track is the TREC Washington Post Collection. <ref type="foot" coords="2,448.08,240.93,3.97,6.12" target="#foot_0">4</ref> This collection contains seven years of articles, from 2012 though 2019. The 671,947 documents in the collection comprise all Washington Post content published in that interval: articles, columns, and blogs.</p><p>The documents are stored in "JSON-lines" format, that is, each document is a single long line of JSON. The articles are broken into content paragraphs, with interspersed media such as images and videos referenced by URL. Those URLs point back to the Washington Post website and according to the Post should persist at those URLs for the foreseeable future. This unique multimedia article format is novel for TREC but this track is not yet exploring it.</p><p>Based on findings in last year's track, the collection has been cleaned of exact-and near-duplicate articles. Near-duplicate documents were detected using locality-sensitive hashing with minhash fingerprints. <ref type="bibr" coords="2,389.86,385.96,10.52,8.74" target="#b1">[2]</ref> With thanks due to Laura Dietz, we provided a CAR-track formatted dump of Wikipedia articles as of the beginning of 2020, the end of the collection epoch. The Wikipedia dump was primarily intended for the wikification task but participants were free to use it however they liked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background Linking task</head><p>The goal of the background linking task is to develop evaluation data to support researchers in developing systems that can help users contextualize news articles as they are reading them. News websites nearly always link to related articles in a sidebar, at the end of an article, from within the text of the article, or all three. We want to look at a particular case for linking: given that the user is reading a specific article (the query article), algorithms should recommend articles that this person should read next that are the most useful for providing context and background for the query article. The background article can be dated before or after the query article, because we are considering the use case where the user is reading the query article now, irrespective of when it was published, and the system is recommending background reading live at the time when the user is reading the query article.</p><p>Sometimes the Post will develop a link block in the context of a large story, for example the block shown in Figure <ref type="figure" coords="2,317.65,643.97,4.98,8.74" target="#fig_0">1</ref> for a story appearing during the COVID-19 pandemic, a significant news event with many details and sub-events. This task imagines automatically providing links like these, for any article the user might be reading.</p><p>It's important to note that links present in the Washington Post article collection are not training data for this task. In our conversations with the Post, their current practice is largely driven by the author of the article and does not follow any fixed guidelines or goal. Hence, we are designing this task as a specific kind of news recommendation task that would be useful in any news reading context, including the Post's website.</p><p>From our conversations with Post journalists about linking for background and context, every author has their own guidelines in their head, but three common rules emerged:</p><p>1. No wire service articles. (That is, from Associated Press (AP), AFP, etc) 2. No opinion or editorials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The list of links should be diverse.</head><p>The corpus should not contain any wire service articles, so (1) is taken care of for free.<ref type="foot" coords="3,178.19,594.30,3.97,6.12" target="#foot_1">5</ref> For (2), we decree that articles from the "Opinion", "Letters to the Editor", or "The Post's View" sections, as labeled in the "kicker" field, are not relevant. (3) is complicated as we are not sure we yet have a good understanding of diversity in the news recommendation context.</p><p>The assessors following NIST's standard adhoc topic development process, which involves scouting the collection for a topic, loosely estimating the number of relevant articles that might exist, and crafting a title, description, and narrative statement. As a final step, the assessor selected a relevant article that they had found during the development process as the query article for the topic. A total of fifty topics were selected by NIST and released for the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;top&gt;</head><p>&lt;num&gt; Number: 890 &lt;/num&gt; &lt;docid&gt;QD7AORAY6AI6TCH67H3XUO6LNQ&lt;/docid&gt; &lt;url&gt;https://www.washingtonpost.com/entertainment/music/as-aclassical-music-critic-i-used-to-think-the-star-wars-score-wasbeneath-me-i-was-wrong/2019/01/17/80fe0744-18f0-11e9-88fe-f9f77a3bcb6c_story.html&lt;/url&gt; &lt;/top&gt; The topic field "Docid" references the "id" field in the Washington Post corpus documents. "Url" references the "article url" field in the documents. Both indicate the query article. In the first running of the track last year, the topics were shared with the Common Core track and some of those were re-used from previous TRECs, but this year all topics are new.</p><p>The relevance scale used by the NIST assessors was: 0. The linked document provides little or no useful background information.</p><p>1. The linked document provides some useful background or contextual information that would help the user understand the broader story context of the query article.</p><p>2. The document provides significantly useful background . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>The document provides essential useful background . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>The document MUST appear in the sidebar otherwise critical context is missing.</p><p>Systems retrieved up to 100 documents per topic and returned results in the standard trec eval format; this constitutes a run. The top 50 documents from each run were pooled for assessment. No relevant documents were found for topic 917, and thus it was dropped from the topic set.</p><p>The primary metric for the background linking task is nDCG@5, with the gain value as 2 r where r is the relevance level from the scale above, and the zero relevance level contributing no gain. This is implemented for trec eval by having the relevance levels in the qrels file be the gain values for nDCG. The evaluation reported all the standard trec eval measures to a depth of 100. Figure <ref type="figure" coords="4,447.78,638.05,4.98,8.74" target="#fig_1">2</ref> plots the nDCG@5 scores.</p><p>Nine teams participated in the background linking task: Runs with overlapping boxes may not be statistically significantly different from one another.</p><p>• BJTAG (SAS Research and Development (Beijing) Co., Ltd.)</p><p>• CLAC NEWS 2020 (CLaC Lab (Computational Linguistics at Concordia))</p><p>• IRLABISI (Indian Statistical Institute)</p><p>• OSC (OpenSource Connections)</p><p>• QU (Qatar University)</p><p>• RUIR (Radboud University IR Research Group)</p><p>• SUNLP (Sabanci University)</p><p>• anserini (Anserini Gaggle)</p><p>• udel fang (InfoLab at University of Delaware) 33 runs were submitted for the background linking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Wikification Task</head><p>In addition to providing links to articles that give the reader background or contextual information, journalists sometimes link mentions of concepts, artifacts, and entities to internal or external pages with in depth information that will help the reader better understand the article. In the first two years of the track, we worked on ranking entities within the document as to their priority for linking. For this year, the task was grown into a full wikification task. Wikification is providing Wikipedia-like markup in a document by linking related content to contextually-relevant anchors. The goal of wikification depends on the application; in Wikipedia, the goal is to link articles to other articles as cross-references. For news reading, we imagine that wikification could be used to recommend interstitial links to the author or editor of the article, where those links serve a similar function to results in the background linking task: provide essential background and context to the reader of the article.</p><p>This definition of wikification differs in some important ways from the natural language processing field's version, where it essentially means linking entities in the article (which may be a Wikipedia article) to other Wikipedia articles. First, we do not restrict the anchor to entity mentions but rather they can be any contiguous span of text within a block. Second, the target of the link can be the knowledge base (Wikipedia) or another article in the Post. Lastly, the task is formulated as ranked recommendation, so high performance is modeled by selecting useful anchors and linking them in a way that provides context to the user, instead of complete and correct entity linking.</p><p>The task is operationalized as follows: Given the same starting article as in the background linking task, systems were to provide a ranked list of link anchors and suggestions. A link anchor was a triple of content block number, starting character, and anchor length, defining an extent of characters in the document. The suggested target for the anchor could be either another Washington Post article, or a Wikipedia article in the provided Wikipedia dump. Individual (anchor, target) pairs are ranked by the system-provided score as in a traditional TREC run.</p><p>At the time that the task was released to participants, the rubric for relevance judgments was not yet set, although the coordinators had expected the scheme to mirror that of background linking. However, as the assessment plan was developed, it was clear that a wikification result could be poor for multiple reasons. Thus, the following two-level, four-part scheme was used:</p><p>1. is the anchor sensible, that is, does it break on word boundaries and seem reasonable in a "lexical" sense? Anchors that break in the middle of words or awkwardly in the middle of phrases are not sensible.</p><p>2. is the anchor useful, that is, would a link at that place in the document possible help the reader better understand the article? Converting a noun phrase that has no bearing on the main topic of the article would be sensible, but not useful.</p><p>3. does the target match the anchor? Is the target document what the reader would reasonably expect to be linked from that anchor? Linking the text "Justin Bieber" to the Wikipedia page for Barack Obama would not match, although the anchor seems sensible and is conceivably useful.</p><p>4. is the target helpful? Does the content in the linked article provide background information or context for understanding the topic document? This is essentially the relevance criterion in the background linking task.</p><p>Three groups submitted eight runs to the wikification task which, given that at submission time the relevance and evaluation criteria were not well-defined, signifies true bravery and sacrifice in the name of research, and we salute them here (with appropriate disclaimers):</p><p>• BJTAG (SAS Research and Development (Beijing) Co., Ltd.)</p><p>• SUNLP (Sabanci University)</p><p>• TUW-IFS (Vienna University of Technology)</p><p>The top-ranked 50 (anchor, target) pairs were pooled for assessment. Figure <ref type="figure" coords="7,179.48,582.26,4.98,8.74" target="#fig_2">3</ref> shows scores for the runs ordered by average nDCG@5. Gain values were derived from the assessments as follows:</p><p>1. if the anchor is sensible and the target matches, the pair received a gain of 1.</p><p>2. if additionally the anchor is useful, the pair received a gain of 5.</p><p>3. if additionally the target is helpful, the pair received a gain of 10. The plot illiustrates the median and interquartile distance across topics. Runs with overlapping boxes may not be statistically significantly different from one another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The third year of the News track continued the background linking task and introduced a new wikification task to expand the track notion of recommendation to interstitial links. Currently, the track is slated to continue in TREC 2021.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,133.77,324.39,343.71,8.74;3,133.77,336.35,221.12,8.74;3,176.73,124.80,257.79,184.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A set of manually-curated background links from the Washington Post website (image taken on November 14, 2020).</figDesc><graphic coords="3,176.73,124.80,257.79,184.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,133.77,556.85,343.71,8.74;5,133.77,568.81,343.71,8.74;5,133.77,580.76,343.71,8.74;5,133.77,592.72,54.27,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Boxplots for nDCG@5 score for each run in the background linking task. The plot illiustrates the median and interquartile distance across topics. Runs with overlapping boxes may not be statistically significantly different from one another.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,133.77,556.85,343.71,8.74;8,133.77,568.81,343.71,8.74;8,133.77,580.76,343.71,8.74;8,133.77,592.72,36.00,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Boxplots for nDCG@5 score for each run in the wikification task. The plot illiustrates the median and interquartile distance across topics. Runs with overlapping boxes may not be statistically significantly different from one another.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,149.01,663.47,143.97,6.64"><p>https://trec.nist.gov/data/wapost/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,149.01,650.67,328.46,6.99;3,133.77,660.13,88.74,6.99"><p>There are actually some wire service articles, and we plan to cull them out in a future release of the collection.</p></note>
		</body>
		<back>

			<div type="funding">
<div> <ref type="bibr" coords="1,144.86,637.42,3.65,5.24" target="#b1">2</ref> <p>https://www.pewresearch.org/fact-tank/2019/09/11/key-findings-about-theonline-news-landscape-in-america/ 3 https://www.journalism.org/2020/07/30/americans-who-mainly-get-their-newson-social-media-are-less-engaged-less-knowledgeable/</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,149.27,228.46,328.22,8.74;9,149.27,240.41,328.21,8.74;9,149.27,252.37,328.21,9.02;9,149.27,265.04,165.41,8.30" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,376.40,228.46,101.08,8.74;9,149.27,240.41,35.94,8.74">TREC 2018 news track overview</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec27/papers/Overview-News.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="9,212.67,240.41,264.81,8.74;9,149.27,252.37,22.67,8.74">Proceedings of the 27th Text REtrieval Conference (TREC 2018)</title>
		<meeting>the 27th Text REtrieval Conference (TREC 2018)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11">November 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,149.27,284.25,328.22,8.74;9,149.27,296.20,328.21,8.74;9,149.27,308.16,328.21,9.02;9,149.27,320.83,149.22,8.30" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,376.40,284.25,101.08,8.74;9,149.27,296.20,35.94,8.74">TREC 2019 news track overview</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shudong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec28/papers/OVERVIEW.N.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="9,212.67,296.20,264.81,8.74;9,149.27,308.16,22.67,8.74">Proceedings of the 28th Text REtrieval Conference (TREC 2019)</title>
		<meeting>the 28th Text REtrieval Conference (TREC 2019)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11">November 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
