<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.96,115.96,343.44,12.62;1,230.31,133.89,154.73,12.62">NLM at TREC 2020 Health Misinformation and Deep Learning Tracks</title>
				<funder>
					<orgName type="full">U.S. National Library of Medicine, National Institutes of Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.86,171.56,65.45,8.74"><forename type="first">Yassine</forename><surname>Mrabet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.61,171.56,71.38,8.74"><forename type="first">Mourad</forename><surname>Sarrouti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.56,171.56,78.71,8.74"><forename type="first">Asma</forename><forename type="middle">Ben</forename><surname>Abacha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,378.66,171.56,62.55,8.74"><forename type="first">Soumya</forename><surname>Gayen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,449.57,171.56,26.93,8.74;1,165.48,183.51,36.86,8.74"><forename type="first">Travis</forename><surname>Goodwin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.94,183.51,52.63,8.74"><forename type="first">Alastair</forename><surname>Rae</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.76,183.51,49.57,8.74"><forename type="first">Will</forename><surname>Rogers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.64,183.51,101.23,8.74"><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Library of Medicine</orgName>
								<address>
									<postCode>8600, 20894</postCode>
									<settlement>Rockville Pike, Bethesda</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.96,115.96,343.44,12.62;1,230.31,133.89,154.73,12.62">NLM at TREC 2020 Health Misinformation and Deep Learning Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">020DA381B640F51A5F938F5A27408152</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the National Library of Medicine to TREC 2020. Our main focus was the health misinformation track. We also participated to the Deep Learning track to both evaluate and enhance our deep re-ranking baselines for information retrieval. Our methods include a wide variety of approaches, ranging from conventional Information Retrieval (IR) models, neural re-ranking models, Natural Language Inference (NLI) models, Claim-Truth models, hyperlinks-based scores such as Page Rank and HITS, and ensemble methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Health Misinformation Track</head><p>With the fast pace of online content publication, misinformation about COVID-19 and the new coronavirus proved difficult to track and debunk at scale. The health misinformation track at TREC 2020 tackles this issue through an international challenge on the automatic recognition of misinformation from the web using a crawl of new articles published between January and April 2020 <ref type="foot" coords="1,454.49,445.88,3.97,6.12" target="#foot_0">1</ref> as a reference dataset.</p><p>The challenge relies on a set of 46 questions about COVID-19 and their reference yes/no answer. Two tasks are considered. The first Total Recall task focuses on misinformation and requires participating systems to rank documents promulgating misinformation first. The second Ad-hoc task tackles the retrieval of relevant, correct, and credible information first.</p><p>For our participation, we first parsed the target Common Crawl News collection and used a combination of the Optimaize language detector<ref type="foot" coords="1,412.94,541.52,3.97,6.12" target="#foot_1">2</ref> and an ASCII character ratio threshold to keep only documents written in English.</p><p>We indexed the filtered documents at two different levels of granularity: (1) document-level indexing and (2) sentence level indexing. We applied different conventional information retrieval models to retrieve either the top 10000 or top 1000 documents, as well as relevance-based T5 and BERT re-ranking models, and rank-based ensembles with the different approaches. Figure <ref type="figure" coords="1,421.71,614.82,4.98,8.74" target="#fig_0">1</ref> presents an overview of our data pipeline, approaches and workflow. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Retrieval Performance</head><p>We analyzed retrieval performance as it is critical for both the ad-hoc and total recall tasks. Table <ref type="table" coords="2,217.58,397.26,4.98,8.74" target="#tab_0">1</ref> presents a summary of our both our backend retrieval approaches and some of our first runs. All submitted runs are described in more details in section 1. <ref type="bibr" coords="2,219.74,421.17,4.24,8.74" target="#b1">2</ref> We used the derived qrels for the useful (relevant) aspect to evaluate each of our approaches. We computed the values for ndcg @1000, ndcg @10, reciprocal rank (rr), and recall @1000 (cf. table <ref type="table" coords="2,298.71,458.59,3.87,8.74" target="#tab_1">2</ref>.</p><p>The sentence-level indexing approaches (BNU, and TME) under-performed substantially document-level indexing approaches. Which is likely due in part to the very low overlap between the lists of documents retrieved by the documentbased and sentence-based methods (cf. figure <ref type="figure" coords="2,330.79,507.97,4.43,8.74" target="#fig_2">2</ref>) and the high correlation between the ratio of retrieved documents annotated by NIST assessors and the NDCG values (cf. table 2.</p><p>To investigate this hypothesis, we performed a manual evaluation of one of the sentence-based approaches to analyze further the error cases.</p><p>We pooled the top 20 documents for each query from the BM25 (BNU) -T5 sentence-based method on all 46 topics and used the specific set of sentences returned by the method for each document as our textual evidence to assess its relevance for the topic. Table <ref type="table" coords="2,265.25,606.74,4.98,8.74" target="#tab_2">3</ref> shows the number of annotated documents, the number of documents in common between our annotations and the official useful qrels from NIST, and the agreement between our annotations and the official qrels on the common documents.</p><p>We present a summary of all annotation disgreement cases in table <ref type="table" coords="2,445.63,656.12,3.87,8.74">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Search Engine</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BM25</head><p>Terrier <ref type="bibr" coords="3,103.65,458.67,7.86,9.73" target="#b8">[9]</ref> BM25 baseline BM25 -T5 Terrier BM25 baseline followed by a re-ranking using relevance scores from a T5 model <ref type="bibr" coords="3,131.44,351.05,7.86,14.34" target="#b9">[10]</ref>   Relevant document annotated as not relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13.1%</head><p>Borderline and clear cases where we reverted back to the official annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>85%</head><p>Divided between:</p><p>-The sentences answer the question but the document is not specific to the topic, e.g.: "He said, while social distancing and staying at home are effective prevention methods for Covid-19, it is very difficult for detainees to be granted such precautions." -The answer can be inferred from the sentences but is not directly stated, e.g.: "Vaccinologist X told Y, a health website in the Asian country: "Quitting or staying away from passive smoking can indirectly prevent covid-19 infection." -The answer is a part of a larger statement, e.g.: "Some of the tree species, including Khaya senegalensis, turmeric, ginger, garlic, iyere, onion, and so on contain good phyto-medicinal ingredients capable of curing COVID-19." or "The drugs chloroquine, hydroxychloroquine and a combination of lopinavir and ritonavir can be used to treat other ailments and for treating Covid-19." -The sentences are relevant for the question but do not fit the narrative or provide a definitive answer, e.g.: "Though some studies have shown ARBs increase ACE 2 activity in animal models, it must be emphasized that the results have been inconsistent, the researchers said." -The sentences answer both the question and the narrative, e.g.: "Don't take the findings to mean those with type O blood are immune or are less likely to get COVID-19."</p><p>Table <ref type="table" coords="5,194.82,550.35,4.13,7.89">4</ref>. Analysis and summary of all annotation disagreement cases. To evaluate the impact of low intersection between the retrieval methods and the relatively low number of assessed documents for the sentence-based retrieval approaches, we merged our additional annotations with the official challenge annotations for the useful label (following the disagreement resolution described on table 4), and evaluated the relevance scores of the same methods on the expanded annotations (cf. table 5).</p><p>Our findings show that a substantial part of the lower performance of the sentence-based retrieval methods were not due to retrieval errors but rather to the incompleteness of the collection, with an NDCG@10 value improving from 48.18% to 81.41% for BM25 (BNU) -T5, and a relative improvement of 35% for NDCG.</p><p>All other sentence-based methods also benefited substantially from the added annotations. Approaches that relied on document-level retrieval with T5-based re-ranking also had substantial improvements in NDCG@10 and RR despite the low overlap in retrieved documents (cf. figure <ref type="figure" coords="6,339.38,644.16,3.87,8.74" target="#fig_2">2</ref>). Improvements reached up to 20% for BM25 -T5 in NDCG@10 and 15% in RR. The correlation between the performance measures of all approaches and their ratio of assessed documents decreased, with a 4 points drop in correlation for NDCG, despite the ratio of assessed documents increasing by only 1.12% for the pooled BM25 (BNU) -T5 approach.</p><p>This suggests that the distribution of false negatives in the collection was biased towards a restricted ranking perspective favoring document-level indexing and retrieval.</p><p>Considering that documents that were assessed as "not useful" were not annotated for correctness and credibility, this distribution bias has likely impacted the evaluation of our more inference, re-ranking, and ensemble approaches that relied on the sentence-level retrieval methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Ad-hoc Runs</head><p>We submitted 10 runs to the Ad-hoc task. BNU ENS NLI. Based on a sentence-level index of the CCN Covid collection, we first retrieved the top-30000 sentences with BM25 (BNU). The parent documents were then scored incrementally with each relevant sentence, then re-ranked with an ensemble of models (T5, BERT-base, BERT-large). Each question from the topics description was then transformed to an affirmative sentence automatically using syntactic rules and the Roberta <ref type="bibr" coords="8,344.15,357.24,10.52,8.74" target="#b6">[7]</ref> model for Natural Language Inference model trained on MultiNLI <ref type="bibr" coords="8,303.37,369.19,15.50,8.74" target="#b11">[12]</ref> was used to infer whether the most relevant sentence from the documents had an entailment/neutral/contradiction relation with the affirmative form of the topic. The final ranking was performed by putting the documents validating the reference answer first (in order of relevance) then the remaining documents (still ranked by relevance). TME NLIR. Ensemble retrieval method combining 4 conventional IR models, and 4 deep-learning based re-ranking models. The results were filtered to keep only documents with sentences mentioning both the subject and object entities in the questions. The most relevant sentence of each document was used to detect entailment, neutrality, or contradiction with the affirmative form of the topic. The results were then re-ranked according to their contradiction/entailment scores. BNU T5 CTM. Based on a sentence-level index of the CCN Covid collection, we first retrieved the top-30000 sentences with BM25 (BNU). The parent documents were then scored incrementally with each relevant sentence, then re-ranked with a T5 relevance-based ranking model. Only the most relevant sentence from the IR-based search was then classified as containing "false" or "true" claims using a Claim-Truth Model (CTM). The CTM model was built using T5 and a manually created training dataset derived from fact-checking websites. We used the dataset from <ref type="bibr" coords="8,214.40,596.34,15.50,8.74" target="#b10">[11]</ref> for validation. The model is fine-tuned to produce the tokens "true" or "false" depending on whether the claim is misinformation or not. CTM R1. Top-1000 documents retrieved with (BM25), re-ranked with a T5 relevance-based re-ranking model applied to the first 250 words in each document. Each sentence in the re-ranked documents was then classified as containing "false" or "true" claims using the CTM model. A voting method was applied to derive a document-level classification from the sentences classification into a document-level classification. CTM R2. Top-1000 documents retrieved with the CombSum IR method. Each document was then automatically summarized using a pointer-generator model and the summaries were re-ranked with a T5 model. Each summary was then classified as containing "false" or "true" claims using a voting approach similar to NLM CTM R1. TME GH. We used the Hypertext Induced Topic Selection (HITS) algorithm <ref type="bibr" coords="9,134.77,226.72,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="9,146.95,226.72,7.75,8.74" target="#b5">6]</ref> to rank all domain names according to their authority and hub scores. Following several manual evaluations of different combinations of both scores, we selected a dependency based combination where the authority score is more significant at lower hub scores: i.e., when the source is a good authority without being a large hub. We wrap up the score in a Gaussian function to better distinguish between otherwise close scores, with:</p><formula xml:id="formula_0" coords="9,254.88,306.38,225.71,13.14">GH = exp -( auths 1+10hubs -1) 2 (1)</formula><p>Figure <ref type="figure" coords="9,180.58,332.89,4.98,8.74" target="#fig_4">3</ref> shows the top 30 domains ranked with GH. For the NLM TME GH run, we first retrieved the relevant document with the TME retrieval approach (cf. table 2), then re-ranked the documents by using the GH value of their domain name as a score boost. BNU E GH. Re-ranking with Gaussian HITS (hub/authority scores) and page rank scores based on the BNU E retrieval ensemble. CTM R1 was our best performing run for the binary measures and MAP using the official qrels. An important part of the performance is likely due to both a good NDCG value for its underlying retrieval approach (BM25-T5) and the high ratio of assessed documents among its top-1000 results. This aspect is better shown when comparing it with BNU T5 CTM that used the same CTM model but a different sentence-based retrieval approach.</p><p>Our second best run for the binary measures was TME GH, using an ensemble of retrieval methods including the better performing CombSUM and BM25-T5 approaches, and re-ranking with our Gaussian HITS approach GH.</p><p>The run with highest compatibility with helpful content was CTM R1, and the run with the less compatibility with harmful content was TME NLIR, which also had the best ratio of helpful vs. harmful compatibility.</p><p>On a more general note, the compatibility scores with harmful content for the submitted runs were correlated with their ratio of assessed documents (%A), with a Pearson correlation value of 0.49. This might be due to a lower presence in the collection for useful, correct (and credible) labels when compared with the combinations of useful, not correct, and (not) credible, which were used for the compatibility scores with harmful content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NDCG cam map</head><p>Compatibility <ref type="bibr" coords="10,421.89,493.82,0.49,65.53">[</ref>  As could be expected from our initial retrieval experiments, the relevance scores were highly correlated with the ratio of assessed documents in the top-1000 results of each approach, with Pearson correlation values ranging from .47 to .54 for MAP, and from .84 to .91 for NDCG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Total Recall Runs</head><p>Following the challenge instructions, we submitted only three runs for the total recall task. CTM R1 C. We retrieved the top-10000 documents with (BM25-T5). Each sentence in the documents was then classified as containing "false" or "true" claims using the CTM model. A voting method was applied to generate a document-level class from turn the sentences classification. Only documents classified as "false" were selected for the Total Recall task. BNU E NLI C. Based on a sentence-level index of the CCN Covid collection, we first retrieved the top-30000 sentences with BM25 (BNU). The parent documents were then scored incrementally with each relevant sentence, then re-ranked with an ensemble of models (T5, BERT-base, BERT-large). Each question from the topics description was then transformed to an affirmative sentence automatically using syntactic rules and the Roberta <ref type="bibr" coords="11,344.15,656.12,10.52,8.74" target="#b6">[7]</ref> model for Natural Language Inference model trained on MultiNLI <ref type="bibr" coords="12,303.37,118.99,15.50,8.74" target="#b11">[12]</ref> was used to infer whether the most relevant sentence from the documents had an entailment/neutral/contradiction relation with the affirmative form of the topic. The final ranking was performed by putting the documents contradicting the reference answer first (in order of relevance) then the remaining documents (still ranked by relevance). TME NLIR C. Ensemble retrieval method combining 4 conventional IR models, and 4 deep-learning based re-ranking models. The results were filtered to keep only documents with sentences mentioning both the subject and object entities in the questions. The most relevant sentence of each document was used to detect entailment, neutrality, or contradiction with the affirmative form of the topic. The results were then re-ranked according to their contradiction/entailment scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Deep Learning Track</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Passage Ranking</head><p>We submitted 4 runs for the passage ranking task. nlm-bert-rr. a re-ranking run based on the official top 1000 passages provided by the challenge. We trained a BERT-base classifier on the MS-MARCO training data and re-ranked the documents using their relevance score from prediction. nlm-prfun-bert. a full-ranking run where We indexed the sentences (UNits) of each passage then retrieved the top 1000 passages using a BM25 model with Pseudo-Relevance Feedback (PRF). We first retrieved the top 3000 sentences then scored the parent passages incrementally with each retrieved sentence and ranked the passages based on their final score. Pseudo-relevance feedback was applied at the sentence-level retrieval. We tested different negative sampling strategies to train a BERT-base model. We picked the best strategy from our tests on the dev set with 2:1 negative to positive ratio with examples randomly selected from the top 1000 passages. nlm-ens-bst-2. Following the observation that a passage-level index provided substantially different results that the sentence-based index, we combined the results of the same BERT-base model when trained separately on each retrieval method using a downstream rank-based boost, where the score of each passage is boosted by (1 + 1/r 2 ), and r 2 is the rank of the passage in the other method if it exists. When a passage was common to both methods, we selected the average of the boosted scores as the final passage score. The goal of this method was to keep the boosted scores comparable with the original scores of a given method and limit the range of re-ranking for any given passage. nlm-ens-bst-3. In this run we followed a similar strategy to nlm-ens-bst-2 and added nlm-bert-rr as a third component of the ensemble. Our best reciprocal rank value was obtained by the nlm-prfun-bert run relying on sentence-level indexing and retrieval, whole the best ndcg@10 value was obtained by our ensemble method combining different sources for the top 1000 passages and a BERT model for re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Retrieval</head><p>We submitted 2 baselines for the document ranking task. nlm-bm25-prf-1. This is a full ranking run produced by a BM25 model based on a document-level index with a word limit set to 10 for query expansion with pseudo-relevance feedback. nlm-bm25-prf-2. This is a full ranking run produced by a BM25 model based on a document-level index with a word limit set to 20 for query expansion with pseudo-relevance feedback.</p><p>Run NDCG @ 10 NDCG @100 RR MAP nlm-bm25-prf- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusion</head><p>We have described our submissions to the Health Misinformation and Deep Learning tracks of TREC 2020. Our methods have shown that point-wise reranking with neural language models fine-tuned for query-document relevance and claim-truth T5 models can outperform substantially conventional retrieval methods and NLI-based re-ranking. In the misinformation track, our approaches and runs followed an exploratory strategy where we used multiple top-K retrieval methods with low pairwise overlap in result sets. This exploration along with the error analysis that we presented in this paper highlighted a potential bias in the distribution of false negatives in the collection, favoring document-level indexing to retrieve the initial top-K texts for re-ranking in the ad-hoc an total recall tasks. Moving forward, a more relevant use of the test collection could be to rely on top-K retrieval methods that have high result set overlap with the list of assessed documents, and to focus on improvements of the downstream misinformation-based re-ranking task. It could also be relevant to study novel evaluation metrics that would take into account the amount of evidence that was used to evaluate the results of each approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,254.40,320.72,106.55,7.89;2,152.06,115.83,311.25,190.12"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Methods Overview</figDesc><graphic coords="2,152.06,115.83,311.25,190.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,131.44,319.29,7.86,28.70;3,131.44,306.48,7.86,9.73;3,131.44,251.07,7.86,52.35;3,131.44,238.27,7.86,9.73;3,148.28,573.11,7.86,24.19;3,148.28,556.60,7.86,13.44;3,148.28,465.07,7.86,27.46;3,148.28,412.39,7.86,24.19;3,148.28,377.51,7.86,31.80;3,148.28,356.52,7.86,17.92;3,148.28,330.90,7.86,22.55;3,148.28,288.10,7.86,39.73;3,165.12,577.10,7.86,20.20;3,165.12,567.24,7.86,6.78;3,165.12,554.45,7.86,9.73;3,165.12,468.70,7.86,20.20;3,165.12,392.75,7.86,43.83;3,165.12,347.48,7.86,43.01;3,165.12,320.31,7.86,24.90;3,165.12,292.45,7.86,25.61;3,165.12,250.51,7.86,39.69;3,165.12,240.06,7.86,8.19;3,165.12,225.00,7.86,12.80;3,165.12,201.63,7.86,21.12;3,165.12,181.46,7.86,17.91;3,176.07,414.02,7.86,22.55;3,176.07,370.73,7.86,40.21;3,192.91,577.10,7.86,20.20;3,192.91,568.27,7.86,5.76;3,192.91,555.47,7.86,9.73;3,192.91,468.70,7.86,20.20;3,192.91,392.75,7.86,43.83;3,192.91,347.48,7.86,43.01;3,192.91,320.31,7.86,24.90;3,192.91,292.45,7.86,25.61;3,192.91,250.51,7.86,39.69;3,192.91,240.06,7.86,8.19;3,192.91,225.00,7.86,12.80;3,192.91,201.63,7.86,21.12;3,192.91,181.46,7.86,17.91;3,203.87,400.47,7.86,36.11;3,203.87,374.84,7.86,22.55;3,203.87,331.56,7.86,40.21;3,220.71,565.18,7.86,32.12;3,220.71,465.07,7.86,27.46;3,220.71,404.45,7.86,32.12;3,220.71,369.58,7.86,31.80;3,237.54,561.47,7.86,35.84;3,237.54,465.07,7.86,27.46;3,237.54,408.34,7.86,28.24;3,237.54,366.18,7.86,37.50;3,237.54,320.18,7.86,41.35;3,237.54,274.41,7.86,41.12;3,237.54,245.44,7.86,24.32;3,237.54,222.87,7.86,17.92;3,237.54,181.45,7.86,36.76;3,248.50,393.54,7.86,43.04;3,248.50,375.61,7.86,14.85;3,248.50,317.23,7.86,55.31;3,265.34,553.02,7.86,44.28;3,265.34,540.22,7.86,9.73;3,265.34,465.07,7.86,27.46;3,265.34,398.25,7.86,38.32;3,265.34,387.75,7.86,7.42;3,265.34,352.55,7.86,32.12;3,265.34,334.64,7.86,14.85;3,265.34,295.73,7.86,35.84;3,282.18,553.02,7.86,44.28;3,282.18,545.34,7.86,4.61;3,282.18,539.20,7.86,3.07;3,282.18,524.86,7.86,11.26;3,282.18,465.07,7.86,27.46;3,282.18,420.70,7.86,15.88;3,282.18,373.95,7.86,44.28;3,282.18,341.02,7.86,30.47;3,282.18,309.37,7.86,29.19;3,282.18,298.71,7.86,8.19;3,282.18,251.70,7.86,44.55;3,282.18,206.61,7.86,42.62;3,282.18,196.72,7.86,7.42;3,282.18,181.45,7.86,12.80;3,293.14,393.51,7.86,43.06;3,293.14,375.60,7.86,14.85;3,293.14,331.26,7.86,41.26;3,293.14,310.27,7.86,17.92;3,293.14,295.94,7.86,11.26;3,309.97,573.11,7.86,24.19;3,309.97,550.02,7.86,20.01;3,309.97,529.80,7.86,17.15;3,309.97,469.26,7.86,19.07;3,309.97,412.39,7.86,24.19;3,309.97,376.25,7.86,33.06;3,309.97,352.13,7.86,21.04;3,309.97,331.90,7.86,17.15;3,309.97,316.03,7.86,12.80;3,309.97,296.57,7.86,16.39;3,309.97,276.61,7.86,16.90;3,326.81,573.11,7.86,24.19;3,326.81,542.52,7.86,27.52;3,326.81,469.26,7.86,19.07;3,326.81,380.49,7.86,56.08;3,326.81,354.17,7.86,21.76;3,326.81,331.68,7.86,17.92;3,326.81,298.43,7.86,28.69;3,326.81,262.58,7.86,31.28;3,326.81,222.38,7.86,35.63;3,326.81,201.95,7.86,15.88;3,326.81,181.46,7.86,15.93;3,337.77,411.94,7.86,24.63;3,337.77,394.93,7.86,12.31;3,337.77,357.70,7.86,32.53;3,337.77,343.28,7.86,9.72;3,337.77,319.61,7.86,18.97;3,337.77,275.49,7.86,39.43;3,337.77,260.43,7.86,10.37;3,337.77,240.88,7.86,14.85;3,337.77,223.38,7.86,12.80;3,337.77,181.45,7.86,37.24;3,348.73,412.90,7.86,23.68;3,348.73,403.63,7.86,6.19;3,348.73,382.59,7.86,17.97;3,348.73,371.32,7.86,8.19;3,348.73,336.22,7.86,32.03;3,348.73,328.55,7.86,4.61;3,348.73,313.14,7.86,12.34;3,348.73,302.65,7.86,7.42;3,348.73,272.42,7.86,27.15;3,348.73,223.72,7.86,45.62;3,365.56,573.11,7.86,24.19;3,365.56,542.52,7.86,27.52;3,365.56,536.38,7.86,3.07;3,365.56,522.05,7.86,11.26;3,365.56,469.26,7.86,19.07;3,365.56,412.39,7.86,24.19;3,365.56,380.63,7.86,27.52;3,365.56,343.87,7.86,32.51;3,365.56,329.90,7.86,9.72;3,365.56,321.04,7.86,4.61;3,365.56,275.54,7.86,41.26;3,365.56,250.26,7.86,21.04;3,365.56,209.38,7.86,36.64;3,365.56,181.45,7.86,23.68;3,376.52,417.87,7.86,18.71;3,376.52,410.18,7.86,4.61;3,376.52,395.85,7.86,11.26;3,376.52,368.46,7.86,24.32;3,376.52,336.69,7.86,28.70;3,376.52,323.90,7.86,9.73;3,376.52,268.48,7.86,52.34;3,393.36,573.11,7.86,24.19;3,393.36,542.52,7.86,27.52;3,393.36,536.38,7.86,3.07;3,393.36,521.02,7.86,12.29;3,393.36,469.26,7.86,19.07;3,393.36,412.39,7.86,24.19;3,393.36,380.63,7.86,27.52;3,393.36,343.87,7.86,32.51;3,393.36,329.90,7.86,9.72;3,393.36,321.04,7.86,4.61;3,393.36,275.54,7.86,41.26;3,393.36,250.26,7.86,21.04;3,393.36,209.38,7.86,36.64;3,393.36,181.45,7.86,23.68;3,404.32,417.87,7.86,18.71;3,404.32,410.18,7.86,4.61;3,404.32,355.90,7.86,51.22;3,404.32,328.51,7.86,24.32;3,404.32,315.70,7.86,9.73;3,404.32,283.93,7.86,28.70;3,404.32,271.14,7.86,9.73;3,404.32,215.72,7.86,52.34;3,421.16,586.42,7.86,10.88;3,421.16,476.50,7.86,4.61;3,421.16,402.91,7.86,33.66;3,421.16,377.26,7.86,22.58;3,421.16,338.04,7.86,36.15;3,437.99,586.42,7.86,10.88;3,437.99,476.50,7.86,4.61;3,437.99,377.26,7.86,59.32;3,437.99,338.03,7.86,36.16;3,454.83,575.93,7.86,21.37;3,454.83,476.50,7.86,4.61;3,454.83,357.12,7.86,79.45;3,454.83,318.65,7.86,36.15;3,454.83,279.49,7.86,36.85;3,454.83,250.43,7.86,26.75;3,454.83,207.04,7.86,41.08;3,454.83,181.45,7.86,23.27;3,465.79,428.26,7.86,8.32;3,465.79,378.34,7.86,46.84;3,465.79,351.08,7.86,24.19;3,465.79,317.93,7.86,30.08;3,465.79,300.01,7.86,14.85;3,465.79,272.76,7.86,24.19;3,465.79,242.17,7.86,27.52;3,465.79,236.03,7.86,3.07;3,465.79,202.23,7.86,30.72;3,482.62,575.93,7.86,21.37;3,482.62,558.47,7.86,14.14;3,482.62,476.50,7.86,4.61;3,482.62,415.20,7.86,21.37;3,482.62,385.90,7.86,26.23;3,482.62,344.89,7.86,37.93;3,482.62,323.90,7.86,17.92;3,482.62,308.02,7.86,12.80;3,482.62,268.43,7.86,36.52;3,482.62,243.35,7.86,22.01;3,482.62,216.60,7.86,23.68;3,499.46,575.93,7.86,21.37;3,499.46,549.83,7.86,22.78;3,499.46,476.50,7.86,4.61;3,499.46,415.20,7.86,21.37;3,499.46,385.90,7.86,26.23;3,499.46,344.89,7.86,37.93;3,499.46,323.90,7.86,17.92;3,499.46,316.21,7.86,4.61;3,499.46,297.15,7.86,16.00;3,499.46,269.76,7.86,24.32"><head></head><label></label><figDesc>applied to automatice summaries of the documents and re-ranking with T5 BM25 titles only SolR BM25 retrieval using only the title field BM25 (BNU) SolR Sentence-level index with n-gram boosted retrieval. The sentences are grouped by their document ID and the sentences scores is used to produce a list of ranked documents. BM25 (BNU) -T5 SolR BM25 (BNU) followed by a re-ranking using relevance scores from a T5 model trained on MS-MARCO BM25 (BNU) -BL SolR BM25 (BNU) followed by a re-ranking using relevance scores from a BERT-Large model [3] trained on MS--based ensemble including BM25, BM25-T5, Essie-L, CombSUM, BM25 (BNU), and BM25 (BNU) -T5/BL. TME GH -TME results re-ranked with the Gaussian HITS scores TME NLIR -TME results re-ranked with a NLI model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,134.77,424.92,345.82,7.89;6,134.77,435.90,189.65,7.86;6,152.06,115.84,311.26,294.31"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Correlation between sentence-vs. document-level indexing approaches. Computed as number of common results at rank N.</figDesc><graphic coords="6,152.06,115.84,311.26,294.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,149.71,332.89,330.88,8.74;9,134.77,344.84,345.82,8.74;9,134.77,356.80,345.83,8.74;9,134.77,368.75,134.13,8.74;9,134.77,380.74,345.83,8.77;9,134.77,392.73,227.24,8.74;9,134.77,404.71,345.82,8.77;9,134.77,416.70,242.91,8.74;9,134.77,428.69,345.82,8.77;9,134.77,440.67,288.42,8.74;9,149.71,452.69,330.88,8.74;9,134.77,464.65,345.83,8.74;9,134.77,476.60,345.82,8.74;9,134.77,488.56,345.83,8.74;9,134.77,500.51,345.83,8.74;9,134.77,512.47,244.31,8.74;9,149.71,524.48,330.88,8.74;9,134.77,536.44,345.83,8.74;9,134.77,548.40,339.28,8.74;9,149.71,560.41,330.88,8.74;9,134.77,572.37,345.83,8.74;9,134.77,584.32,258.14,8.74;9,149.71,596.34,330.88,8.74;9,134.77,608.30,345.82,8.74;9,134.77,620.25,345.83,8.74;9,134.77,632.21,345.82,8.74;9,134.77,644.16,345.83,8.74;9,134.77,656.12,184.75,8.74"><head></head><label></label><figDesc>Figure3shows the top 30 domains ranked with GH. For the NLM TME GH run, we first retrieved the relevant document with the TME retrieval approach (cf. table 2), then re-ranked the documents by using the GH value of their domain name as a score boost. BNU E GH. Re-ranking with Gaussian HITS (hub/authority scores) and page rank scores based on the BNU E retrieval ensemble. E3. Average rank-based ensemble of 4 Ad-hoc runs based on different methods: BNU T5 CTM, CTM R2, BNU ENS NLI, TME NLIR. E4. Average rank-based ensemble of 5 Ad-hoc runs based on different methods: BNU T5 CTM, CTM R2, BNU ENS NLI, TME NLIR, CTM R1.CTM R1 was our best performing run for the binary measures and MAP using the official qrels. An important part of the performance is likely due to both a good NDCG value for its underlying retrieval approach (BM25-T5) and the high ratio of assessed documents among its top-1000 results. This aspect is better shown when comparing it with BNU T5 CTM that used the same CTM model but a different sentence-based retrieval approach.Our second best run for the binary measures was TME GH, using an ensemble of retrieval methods including the better performing CombSUM and BM25-T5 approaches, and re-ranking with our Gaussian HITS approach GH.The run with highest compatibility with helpful content was CTM R1, and the run with the less compatibility with harmful content was TME NLIR, which also had the best ratio of helpful vs. harmful compatibility.On a more general note, the compatibility scores with harmful content for the submitted runs were correlated with their ratio of assessed documents (%A), with a Pearson correlation value of 0.49. This might be due to a lower presence in the collection for useful, correct (and credible) labels when compared with the combinations of useful, not correct, and (not) credible, which were used for the compatibility scores with harmful content.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,162.36,396.98,290.63,7.89;11,152.06,115.84,311.27,266.37"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Top 30 domains as ranked by the Gaussian HITS method (GH).</figDesc><graphic coords="11,152.06,115.84,311.27,266.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,521.95,248.37,7.89,282.02"><head>Table 1 .</head><label>1</label><figDesc>Summary of Information Retrieval and Re-ranking methods</figDesc><table coords="4,139.37,149.50,353.33,342.38"><row><cell>method</cell><cell cols="3">NDCG NDCG@10 Recall</cell><cell>RR</cell><cell>% assessed (p+n)</cell></row><row><cell>BM25</cell><cell>51.74</cell><cell>35.27</cell><cell>52.11</cell><cell>48.28</cell><cell>22.62</cell></row><row><cell>BM25 QE</cell><cell>46.17</cell><cell>21.17</cell><cell>48.73</cell><cell>31.96</cell><cell>21.85</cell></row><row><cell>BM25 -T5</cell><cell>54.89</cell><cell>53.24</cell><cell>54.24</cell><cell>69.92</cell><cell>21.83</cell></row><row><cell>ESSIE R</cell><cell>26.74</cell><cell>33.72</cell><cell>25.44</cell><cell>55.98</cell><cell>7.41</cell></row><row><cell>ESSIE L</cell><cell>34.00</cell><cell>32.29</cell><cell>26.99</cell><cell>55.33</cell><cell>14.39</cell></row><row><cell>InExpB2</cell><cell>54.43</cell><cell>47.14</cell><cell>57.02</cell><cell>59.15</cell><cell>22.57</cell></row><row><cell>TF-IDF</cell><cell>56.12</cell><cell>50.41</cell><cell>57.98</cell><cell>65.75</cell><cell>22.38</cell></row><row><cell>CombSUM</cell><cell>55.38</cell><cell>48.94</cell><cell>57.73</cell><cell>65.07</cell><cell>22.54</cell></row><row><cell>CombSUM 2</cell><cell>44.91</cell><cell>37.26</cell><cell>34.05</cell><cell>53.90</cell><cell>22.54</cell></row><row><cell>BM25 -titles</cell><cell>11.83</cell><cell>20.4</cell><cell>7.9</cell><cell>36.96</cell><cell>5.33</cell></row><row><cell>BM25 (BNU)</cell><cell>27.10</cell><cell>31.14</cell><cell>22.79</cell><cell>48.73</cell><cell>12.34</cell></row><row><cell>BM25 (BNU) -T5</cell><cell>32.96</cell><cell>48.18</cell><cell>27.50</cell><cell>65.60</cell><cell>12.34</cell></row><row><cell>BM25 (BNU) -BL</cell><cell>32.13</cell><cell>41.60</cell><cell>28.55</cell><cell>58.92</cell><cell>12.34</cell></row><row><cell>E3</cell><cell>27.55</cell><cell>32.84</cell><cell>34.36</cell><cell>50.7</cell><cell>10.06</cell></row><row><cell>E4</cell><cell>31.59</cell><cell>32.65</cell><cell>41.25</cell><cell>50.41</cell><cell>11.12</cell></row><row><cell>TME</cell><cell>33.07</cell><cell>27.92</cell><cell>49.36</cell><cell>47.94</cell><cell>11.8</cell></row><row><cell>TME GH</cell><cell>36.53</cell><cell>28.56</cell><cell>49.38</cell><cell>48.69</cell><cell>11.81</cell></row><row><cell>TME NLIR</cell><cell>19.23</cell><cell>25.46</cell><cell>24.54</cell><cell>40.32</cell><cell>7.53</cell></row><row><cell>Pearson correlation w/ % assessed</cell><cell>0.96</cell><cell>0.56</cell><cell>0.77</cell><cell>0.38</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,151.33,500.38,312.70,112.12"><head>Table 2 .</head><label>2</label><figDesc>Evaluation of our retrieval and re-ranking approaches for relevance.</figDesc><table coords="4,171.44,587.80,272.48,24.70"><row><cell cols="3">Assessed docs % in common with official qrels Agreement (p+n)</cell></row><row><cell>881</cell><cell>30.6%</cell><cell>70.2%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,160.94,617.16,293.48,7.89"><head>Table 3 .</head><label>3</label><figDesc>Statistics on manually annotated documents for error analysis.</figDesc><table coords="5,146.46,216.33,177.08,24.70"><row><cell>Case % Disagreement Type and Examples</cell></row><row><cell>1.6%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,117.97,115.84,380.19,547.09"><head>Table 5 .</head><label>5</label><figDesc>Evaluation of retrieval relevance with the additional annotations (deltas of more than 10% from original are indicated between parentheses).</figDesc><table coords="7,117.97,185.11,342.38,408.55"><row><cell>% assessed</cell><cell>22.98</cell><cell>22.24</cell><cell>22.22</cell><cell>7.65</cell><cell>14.74</cell><cell>22.95</cell><cell>22.77</cell><cell>22.93</cell><cell>22.93</cell><cell>5.45</cell><cell>12.92</cell><cell>12.92</cell><cell>12.92</cell><cell>10.54</cell><cell>11.59</cell><cell>12.19</cell><cell>12.2</cell><cell>7.65</cell><cell cols="2">1</cell></row><row><cell>NDCG NDCG@10 Recall RR</cell><cell>52.72 37.42 51.96 51.91</cell><cell>47.05 22.69 49.34 33.32</cell><cell>58.62 63.93 (+20%) 55.91 80.48 (+15%)</cell><cell>27.35 35.73 26.08 58.75</cell><cell>34.43 33.22 27.26 55.48</cell><cell>55.48 50.12 56.76 64.95</cell><cell>57.12 53.42 57.57 69.41</cell><cell>56.37 52.21 57.18 70.41</cell><cell>47.73 47.51 (+28%) 35.99 67.75 (+25%)</cell><cell>12.23 21.4 40.4 7.86</cell><cell>31.78 (+17%) 37.53 (+20%) 27.9 (+22%) 55.98 (+15%)</cell><cell>44.39 (+35%) 81.41 (+69%) 34.64 (+25%) 91.68 (+40%)</cell><cell>41.05 (+27%) 58.49 (+40%) 35.12 (+23%) 74.47 (+26%)</cell><cell>32.99 (+20%) 43.5 (+32%) 40.24 (+17%) 56.75 (+12%)</cell><cell>36.49 (+15%) 41.62 (+27%) 46.22 (+12%) 56.53 (+12%)</cell><cell>39.72 (+20%) 34.9 (+25%) 51.66 57.21 (+19%)</cell><cell>39.81 35.74 (+25%) 51.67 57.99 (+19%)</cell><cell>20.16 26.94 25.07 44.25</cell><cell cols="2">0.91 (-0.04) 0.32 (-0.23) 0.63 (-0.13) 0.37</cell></row><row><cell>method</cell><cell>BM25</cell><cell>BM25 QE</cell><cell>BM25 -T5</cell><cell>Essie R</cell><cell>Essie L</cell><cell>InexpB2</cell><cell>TF-IDF</cell><cell>CombSUM</cell><cell>CombSUM 2 -T5</cell><cell>BM25 titles</cell><cell>BM25 (BNU)</cell><cell>BM25 (BNU) -T5</cell><cell>BM25 (BNU) -BL</cell><cell>E3</cell><cell>E4</cell><cell>TME</cell><cell>TME GH</cell><cell>TME NLIR</cell><cell>Pearson correlation</cell><cell>w/ %assessed</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,188.95,150.63,234.41,452.22"><head>Table 6 .</head><label>6</label><figDesc>Ad-hoc runs results</figDesc><table coords="10,211.47,150.63,211.90,452.22"><row><cell>Correl. w/ Ret. %A 0.91 0.91 0.84 0.90 0.47 0.54 0.54 -0.16 0.48 -0.40 1</cell><cell>BNU T5 CTM 25.22 20.84 26.39 19.60 6.28 9.79 8.33 26.56 6.09 4.36 6.83</cell><cell>BNU ENS NLI 14.07 14.58 13.12 13.31 4.11 3.73 3.66 19.20 1.89 10.15 4.02</cell><cell>BNU ENS GH 29.25 23.58 27.91 22.81 7.43 10.27 8.94 24.59 8.04 3.03 8.61</cell><cell>T M E N LIR 19.23 17.52 17.15 16.48 3.15 3.62 3.30 16.70 1.30 12.84 7.53</cell><cell>TME GH 36.53 29.84 33.29 28.50 6.84 10.01 8.61 15.32 6.80 2.25 11.81</cell><cell>TME 36.51 29.79 33.21 28.31 6.78 10.05 8.63 15.03 6.86 2.19 11.8</cell><cell>E4 31.59 28.71 29.94 26.50 5.21 6.76 6.06 20.50 3.30 6.21 11.12</cell><cell>E3 27.55 24.63 25.78 22.38 4.13 5.18 5.07 19.69 3.00 6.56 10.06</cell><cell>CTM R2 23.77 20.20 23.32 19.03 4.38 5.87 5.11 22.28 3.64 6.12 7.16</cell><cell>CTM R1 38.56 33.80 38.62 31.55 10.03 13.40 11.85 31.53 6.58 4.79 10.46</cell><cell>U. U.C. U.B. U.C.B. C.B. U.B. U.C.B. Help. Harm. Ratio %A</cell><cell>2] Ret</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,236.54,285.76,142.29,70.93"><head>Table 7 .</head><label>7</label><figDesc>Total Recall Runs results</figDesc><table coords="12,250.83,285.76,113.69,58.37"><row><cell></cell><cell>R-precision</cell></row><row><cell>TME NLIR C</cell><cell>3.06</cell></row><row><cell>BNU E NLI C</cell><cell>6.30</cell></row><row><cell>CTM R1 C</cell><cell>9.76</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="13,185.17,494.23,245.01,87.76"><head>Table 8 .</head><label>8</label><figDesc>Passage Ranking Runs results</figDesc><table coords="13,185.17,494.23,245.01,75.21"><row><cell>Run</cell><cell cols="4">NDCG @ 10 NDCG @1000 RR MAP</cell></row><row><cell>nlm-bert-rr</cell><cell>.672</cell><cell>.647</cell><cell>.778</cell><cell>.434</cell></row><row><cell>nlm-prfun-bert</cell><cell>.664</cell><cell>.643</cell><cell cols="2">.860 .426</cell></row><row><cell>nlm-ens-bst-2</cell><cell>.693</cell><cell>.667</cell><cell cols="2">.820 .459</cell></row><row><cell>nlm-ens-bst-3</cell><cell>.680</cell><cell>.685</cell><cell>.849</cell><cell>.452</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="14,186.08,272.91,241.81,37.25"><head>Table 9 .</head><label>9</label><figDesc>Document Ranking Runs results</figDesc><table coords="14,186.08,272.91,241.81,24.70"><row><cell>1</cell><cell>.467</cell><cell>.467</cell><cell>.808</cell><cell>.272</cell></row><row><cell>nlm-bm25-prf-2</cell><cell>.470</cell><cell>.482</cell><cell cols="2">.809 .291</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,645.84,278.73,7.86"><p>Common Crawl News: https://github.com/commoncrawl/news-crawl</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,656.80,196.68,7.86"><p>https://github.com/optimaize/language-detector</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the intramural research program at the <rs type="funder">U.S. National Library of Medicine, National Institutes of Health</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="15,142.96,142.59,337.63,7.86;15,151.52,153.55,232.28,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,254.25,142.59,226.34,7.86;15,151.52,153.55,156.32,7.86">List at trec 2015 clinical decision support track: Question analysis and unsupervised result fusion</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khelifi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,328.77,153.55,26.37,7.86">TREC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,164.51,337.64,7.86;15,151.52,175.46,329.07,7.86;15,151.52,186.42,254.73,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="15,323.91,164.51,156.69,7.86;15,151.52,175.46,87.48,7.86">Offline evaluation by maximum similarity to an ideal ranking</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vtyurina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,259.62,175.46,220.97,7.86;15,151.52,186.42,169.94,7.86">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="225" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,197.38,337.63,7.86;15,151.52,208.34,329.07,7.86;15,151.52,219.30,25.60,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="15,346.99,197.38,133.60,7.86;15,151.52,208.34,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.96,230.26,337.63,7.86;15,151.52,241.22,329.07,7.86;15,151.52,252.18,329.07,7.86;15,151.52,263.14,283.46,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,311.37,230.26,169.22,7.86;15,151.52,241.22,11.90,7.86">Inferring web communities from link topology</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,184.61,241.22,295.99,7.86;15,151.52,252.18,329.07,7.86;15,151.52,263.14,199.37,7.86">Proceedings of the ninth ACM conference on Hypertext and hypermedia: links, objects, time and space-structure in hypermedia systems: links, objects, time and space-structure in hypermedia systems</title>
		<meeting>the ninth ACM conference on Hypertext and hypermedia: links, objects, time and space-structure in hypermedia systems: links, objects, time and space-structure in hypermedia systems</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="225" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,274.09,337.64,7.86;15,151.52,285.05,329.07,7.86;15,151.52,295.99,138.19,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,344.22,274.09,136.38,7.86;15,151.52,285.05,139.75,7.86">Essie: a concept-based search engine for structured biomedical text</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">C</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F</forename><surname>Loane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,298.21,285.05,182.38,7.86;15,151.52,296.01,46.17,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="263" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,306.97,337.64,7.86;15,151.52,317.90,166.37,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,221.41,306.97,209.49,7.86">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,439.04,306.97,41.55,7.86;15,151.52,317.93,74.36,7.86">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,328.89,337.64,7.86;15,151.52,339.85,329.07,7.86;15,151.52,350.81,201.31,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="15,282.11,339.85,198.48,7.86;15,151.52,350.81,34.83,7.86">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.96,361.77,337.63,7.86;15,151.52,372.72,329.07,7.86" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<title level="m" coord="15,165.24,372.72,286.91,7.86">Ms marco: A human-generated machine reading comprehension dataset</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,383.68,337.64,7.86;15,151.52,394.64,329.07,7.86;15,151.52,405.60,116.26,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="15,453.13,383.68,27.47,7.86;15,151.52,394.64,118.37,7.86">Terrier information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,290.45,394.64,186.26,7.86">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,416.56,337.97,7.86;15,151.52,427.52,329.07,7.86;15,151.52,438.45,295.12,7.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="15,209.74,427.52,270.85,7.86;15,151.52,438.48,45.40,7.86">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,204.12,438.48,155.11,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,449.44,337.97,7.86;15,151.52,460.40,329.07,7.86;15,151.52,471.35,54.85,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Petrak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<title level="m" coord="15,427.24,449.44,53.35,7.86;15,151.52,460.40,329.07,7.86;15,151.52,471.35,26.18,7.86">Classification aware neural topic model and its application on a new covid-19 disinformation corpus</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,482.31,337.97,7.86;15,151.52,493.27,329.07,7.86" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05426</idno>
		<title level="m" coord="15,324.53,482.31,156.06,7.86;15,151.52,493.27,164.97,7.86">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
