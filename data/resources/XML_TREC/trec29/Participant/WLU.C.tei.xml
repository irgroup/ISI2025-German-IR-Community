<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,110.83,81.76,390.34,15.38;1,183.02,101.92,245.88,15.38">Wilfrid Laurier University at the NIST TREC 2020: Conversational Assistance Track</title>
				<funder>
					<orgName type="full">Wilfrid Laurier University Faculty of Science</orgName>
				</funder>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council of Canada</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,131.18,131.26,75.64,10.54;1,206.82,129.88,1.98,6.95"><forename type="first">Max</forename><surname>Niebergall</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,408.17,131.26,57.66,10.54;1,465.83,129.88,1.99,6.95"><forename type="first">Jiashu</forename><surname>Zhao</surname></persName>
							<email>jzhao@wlu.ca</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics and Computer Science</orgName>
								<orgName type="institution">Wilfrid Laurier University</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Computer Science</orgName>
								<orgName type="institution">Wilfrid Laurier University</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,110.83,81.76,390.34,15.38;1,183.02,101.92,245.88,15.38">Wilfrid Laurier University at the NIST TREC 2020: Conversational Assistance Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3F29CFA6EB57FD0D75DAFA169CF0CBBD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>For TREC 2020, we submitted two runs to the Conversational Assistance Track (CAsT):</p><p>WLU_ManUttOnly, for this run we used indri search to retrieve 1000 candidate results for each query, followed by reranking with a hierarchical session-based learning model with BERT encoding, and evaluated on the manually rewritten conversational query set.</p><p>WLU_RawUttOnly, this run is the same as above except we evaluated on the raw conversational query set without any rewriting. This report details the system we designed to generate these runs, as well as an evaluation of each run. Overall, this system consists of four broad steps:</p><p>1. The newest utterance is used to retrieve 1000 sample answer paragraphs from the dataset using the Indri document search engine.</p><p>2. The sequences of utterances and their respective sample answer paragraphs the are then both encoded using a pretrained BERT-768 model <ref type="bibr" coords="1,130.50,380.60,9.58,8.01" target="#b0">[1]</ref>.</p><p>3. The sequences of encoded utterances and encoded sample answer paragraphs are used as input to the main deep neural network, which determines a score in the range [0,1].</p><p>4. Finally, the results are reranked according their scores.</p><p>We designed the approach in this paper based on one of our previous work, the hierarchical deep learning model DPHA <ref type="bibr" coords="1,493.33,444.20,9.58,8.01" target="#b1">[2]</ref>. We improved the model to incorporate the background information provided by the pretrained BERT model, in order to make up for the size of the dataset. Additionally, we leveraged a part of the MS MARCO <ref type="bibr" coords="1,248.73,467.00,10.54,8.01" target="#b2">[3]</ref> search dataset in training our model, though a larger portion of MS MARCO could have been used. Our work is also inspired by several work from CAsT 2019 <ref type="bibr" coords="1,330.19,478.28,9.58,8.01" target="#b4">[5]</ref>, <ref type="bibr" coords="1,345.19,478.28,9.58,8.01" target="#b5">[6]</ref>, <ref type="bibr" coords="1,360.18,478.28,9.58,8.01" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head><p>In this section we describe the details of our hierarchical session-based learning model, including an overview of the dataset, required data preprocessing, our document retrieval model, our choice of document encoding system, and our document reranking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Set and Data Preprocessing</head><p>The first step is to transform the dataset such that each query contains all the information required to predict a score for a potential answer document. For CAsT 2020, two sets of data were provided. Firstly, there is the dataset used for CAsT 2019, which contains 30 example sequences (called topics) each in the form of a sequence of utterances (i.e. questions) with some meta datía. Each of these utterances is associated with a number of (document ID, score) pairs which represent the training labels. For CAsT 2020, the evaluation utterances are associated with a canonical result document ID, as well as some rewritten versions of each utterance. Our model requires that each query contain the current utterance, and a sequence of previous utterances. For training, each query also needs to be associated with a potential † Max Niebergall worked on this project as part of the Undergraduate Student Research Award at WLU and is now attending the MDSAI program at the University of Waterloo. † † Jiashu Zhao supervised this project and is an Assistant Professor at WLU.</p><p>Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).</p><p>answer document and its score. In the data preprocessing stage, a script reads the datasets, searches for potentially relevant documents (for evaluation only), performs document embedding, and outputs a series of files each containing: the topic number, turn number, canonical score (for training only), and encoded versions of the new utterance, past utterances, potential answer document, and the canonical response document (for evaluation only).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Retrieval</head><p>Because the set of available documents is so large, a conventional search engine such as Indri <ref type="bibr" coords="2,402.41,150.20,10.54,8.01" target="#b7">[8]</ref> is more convenient to produce a list of potential documents, since doing so with our deep learning model would be prohibitively expensive. Thus, we propose a document retrieval step which is separate from document encoding and document processing, and which can retrieve documents from a big set with sufficient speed. During preprocessing, we use a simple and naïve document retrieval process which uses the text of the newest utterance in Indri's #combine tag as the query for a default configuration of version 5.17 of the Indri document search engine with Krovetz stemming from which 1000 thousand seemingly relevant documents are retrieved. These documents are the encoded as described in the next section, before being reranked by our document scoring model as described in section 2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Encoding</head><p>Since the dataset of labeled documents is relatively small, we chose to incorporate background information on the English language by using a pretrained language model, to decrease the amount of data needed to train our model to extract useful information from the text. To that end, we used a pretrained BERT-768 model to encode each utterance. In practice, we used BERT-as-a-service <ref type="bibr" coords="2,469.04,278.36,10.53,8.01" target="#b3">[4]</ref> to easily encode our utterances and documents. Using BERT-as-a-service allowed us to encode all utterances and documents as part of the preprocessing step, instead of during model prediction or training. However, using this technique we were unable to finetune the BERT model on our training set, which limits the effectiveness of the BERT model at this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Document Scoring Model</head><p>Figure <ref type="figure" coords="2,80.57,620.60,4.56,8.01" target="#fig_0">1</ref> shows the general architecture of our proposed predictive model. The past utterances, current utterance, and a potential answer document are encoded as explained in Section 2.3. Information from multiple past turns is learned in the Session Module, in which we adopt our previous work, DPHA model, proposed in <ref type="bibr" coords="2,228.00,643.40,9.58,8.01" target="#b1">[2]</ref>. The model structure is shown in Figure <ref type="figure" coords="2,392.77,643.40,3.39,8.01" target="#fig_1">2</ref>. It models dynamic session intent from the preceding queries by applying multi-head self-attention with dropout to the sequence of inputs before applying GRUs to encode the session by learning sequential information in the session forwardly. Then, a soft attention layer is applied to generate the session's annotation by aggregating the hidden states of the GRUs.  From: A Dynamic Product aware Learning Model for E-commerce Query Intent Understanding <ref type="bibr" coords="3,473.07,345.80,9.58,8.01" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EVALUATION OF RESULTS</head><p>TREC lists four measures as the most important for this track. They are: NDCG@3, NDCG@5, NDCG@1000, and AP@1000 where NDCG is the Normalized Discounted Cumulative Gain over the top number of results, and AP@1000 is the Average Precision over the entire result set returned for each turn. For this project, NDCG can be thought of as a measure of the effectiveness of our scoring model given our document retrieval model, while AP@1000 is a measure of the effectiveness of our document retrieval model. In the table below, we present the average value of these measures. Note: out of 208 questions and the 208'000 results our model returned only around 10'000 were judged so these scores should be taken as an estimate only.  <ref type="table" coords="3,77.45,597.56,4.56,8.01" target="#tab_0">1</ref> shows that the Manually rewritten queries return results that are about 3 times as relevant as the Raw utterances alone, by these measures. This indicates that our model is not as effective at interpreting raw utterances as the human rewriters. Therefore, raw utterance interpretation is an area of potential for improvement in future iterations of this system. When comparing the RawUttOnly results to the mean across all turns of the median performing raw runs submitted in this track, we see that the median runs outperform our model in these measures. The difference indicates that our document retrieval system is ripe for improvement.</p><p>Firstly, our document retrieval process is simple, and our AP@1000 scores show that it limits the effectiveness of the rest of our system. Potential improvements to the document retrieval process include: • Including information from past turns in the query to the document search engine • Performing query rewriting before sending the query to the document search engine • Performing keyword and named entity identification and extraction prior to searching • Evaluating alternative document search engine algorithms for this problem Secondly, our document encoding process can be further improved. Currently, it uses only the general BERT-768 model, without finetuning which leaves great room for improvement. This year alone, several alternative language models have shown to be even more powerful than BERT and exploring those could improve the effectiveness of our embeddings. Using a language model which is finetuned would likely improve effectiveness of our document scoring model and could greatly improve our NDCG scores. At the same time, it is unlikely that the CAsT dataset alone would be of sufficient size to fine tune BERT on, and we would need to bring in external datasets like MS MARCO for this task to be effective. Finetuning BERT and augmenting out dataset with more MS MARCO datapoints (as well as any other text retrieval datasets that may be developed in the future) are both areas with great potential in future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,209.54,572.60,193.68,8.01;2,124.80,349.69,321.65,199.15"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The architecture of our predictive model</figDesc><graphic coords="2,124.80,349.69,321.65,199.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,195.01,323.48,222.03,8.01;3,193.35,136.69,225.30,150.95"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The Session module from the DPHA framework</figDesc><graphic coords="3,193.35,136.69,225.30,150.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,54.00,479.00,372.12,126.57"><head>Table 1 : Main measures of results by run</head><label>1</label><figDesc></figDesc><table coords="3,54.00,503.96,372.12,101.61"><row><cell>Average</cell><cell cols="3">ManUttOnly RawUttOnly Mean Median</cell></row><row><cell>Score</cell><cell></cell><cell></cell><cell>Raw Run</cell></row><row><cell>NDCG@3</cell><cell>0.0665</cell><cell>0.0222</cell><cell>0.2796</cell></row><row><cell>NDCG@5</cell><cell>0.0695</cell><cell>0.0215</cell><cell>0.2735</cell></row><row><cell cols="2">NDCG@1000 0.2872</cell><cell>0.1106</cell><cell>0.3749</cell></row><row><cell>AP@1000</cell><cell>0.0456</cell><cell>0.0147</cell><cell>0.1801</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,68.00,674.05,84.07,9.69;3,54.00,689.96,503.99,8.01;3,54.00,701.48,116.00,8.01"><p>FUTURE WORKAfter analyzing the performance results, we believe there are several areas of our project in which future improvements could lead to big improvements in overall results.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We acknowledge the support of the <rs type="funder">Natural Sciences and Engineering Research Council of Canada (NSERC)</rs>. We also thank <rs type="funder">Wilfrid Laurier University Faculty of Science</rs> for funding this project as a part of the Faculty start-up fund and <rs type="institution">Undergraduate Student Research Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,89.25,325.39,468.86,6.11;4,89.25,334.03,98.31,6.11" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,306.18,325.39,248.86,6.11">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1810.04805v2" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.25,342.91,468.78,6.11;4,89.25,351.79,468.67,6.11;4,89.25,360.67,116.80,6.11" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,238.99,342.91,250.95,6.11">A Dynamic Product aware Learning Model for E-commerce Query Intent Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jiashu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3357384.3358055</idno>
		<ptr target="https://doi.org/10.1145/3357384.3358055" />
	</analytic>
	<monogr>
		<title level="m" coord="4,502.98,342.91,55.05,6.11;4,89.25,351.79,317.43,6.11">Proceedings of The 28th ACM International Conference on Information and Knowledge Management (CIKM &apos;19)</title>
		<meeting>The 28th ACM International Conference on Information and Knowledge Management (CIKM &apos;19)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.25,369.55,468.75,6.11;4,89.25,378.43,468.82,6.11;4,89.25,387.31,91.31,6.11" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="4,298.91,378.43,256.32,6.11">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName coords=""><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alina</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1611.09268" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.40,396.19,212.84,6.11" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,119.92,396.19,40.25,6.11">bert-as-service</title>
		<author>
			<persName coords=""><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<ptr target="https://github.com/hanxiao/bert-as-service" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.40,405.07,433.46,6.11" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,220.62,405.07,188.40,6.11">TREC CAsT 2019: The Conversational Assistance Track Overview</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2003.13624" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.40,413.95,442.45,6.11" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,151.02,413.95,185.54,6.11">WaterlooClarke at the TREC 2019 Conversational Assistant Track</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Clarke</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec28/papers/WaterlooClarke.C.pdf" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.25,422.59,468.76,6.11;4,89.25,431.47,165.54,6.11" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="4,356.65,422.59,178.04,6.11">Query and Answer Expansion from Conversation History</title>
		<author>
			<persName coords=""><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://trec.nist.gov/pubs/trec28/papers/CFDA_CLIP.C.pdf" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,89.40,440.35,311.14,6.11" xml:id="b7">
	<analytic>
		<title/>
		<ptr target="https://www.lemurproject.org/indri.php" />
	</analytic>
	<monogr>
		<title level="j" coord="4,89.40,440.35,165.53,6.11">The Lemur Project. Indri Document Search Engine version</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
