<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.91,112.05,466.18,15.12">The University of Maryland at the TREC 2020 Fair Ranking Track</title>
				<funder ref="#_UQMfrfe">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.69,154.49,99.98,10.48"><forename type="first">Mahmoud</forename><forename type="middle">F</forename><surname>Sayed</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,324.34,154.49,89.96,10.48"><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
							<email>oard@umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.91,112.05,466.18,15.12">The University of Maryland at the TREC 2020 Fair Ranking Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">094991E19DD1E79D4A83AB4AA336DF10</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our submission to the second Fair Ranking Track at TREC 2020. We leverage the flexibility of listwise Learning to Rank (LtR) techniques which directly optimize towards a custom evaluation measure. To do this, we developed an objective function that balances between relevance and fairness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this second year of the track, the Fair Ranking Track<ref type="foot" coords="1,314.93,335.55,3.97,6.12" target="#foot_0">1</ref> had two tasks: 1) re-ranking, and 2) retrieval. We submitted one run for the re-ranking task. The training data consists of 200 queries and 8,879 academic papers from the Semantic Scholar open research corpus <ref type="bibr" coords="1,317.95,361.03,9.96,8.74" target="#b0">[1]</ref>. Each query is associated with a pool of papers that were judged for relevance. The evaluation data consists of another 200 queries where each query is associated with an evaluation set of documents, without relevance judgments. For the re-ranking task the task is to re-rank that evaluation set in a way that minimizes the squared error of the difference between the group expected exposure of the system and desired group expected exposure specified by the organizers <ref type="bibr" coords="1,526.71,408.85,9.96,8.74" target="#b4">[5]</ref>.</p><p>Our approach relies on using listwise learning to rank algorithms because they can directly optimize an objective function. We developed an objective function that is a weighted average of relevance and fairness measures. Then a listwise LtR model is used to optimize that evaluation function, thus jointly optimizing both relevance and fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Processing Pipeline</head><p>We created one submission based on a listwise Learning to Rank (LtR) model with a custom objective function. Our pipeline starts by indexing the training data using an Elasticsearch instance with an LtR plugin. Then we generate the features for documents and for query-documents pairs that are shown in Table <ref type="table" coords="1,99.40,547.30,3.87,8.74" target="#tab_0">1</ref>.</p><p>Our evaluation measure is computed as the weighted average between a relevance measure and a fairness measure. The relevance measure is the same as in TREC 2019 <ref type="bibr" coords="1,356.57,571.21,10.52,8.74" target="#b1">[2]</ref> which is a generalized version of ERR with a patience parameter. It is defined as follows.</p><formula xml:id="formula_0" coords="1,238.27,603.77,301.73,30.32">R = n i=1 [p(s|d i )γ i-1 i-1 j=1 p(s|d j )]<label>(1)</label></formula><p>where p(s|d i ) is the stopping probability at a document at rank i, γ is the patience parameter, and n is the number of documents. For the fairness measure, we compute entropy from probability of seeing an author with class L. It can be defined as follows.  </p><formula xml:id="formula_1" coords="2,208.26,404.41,331.74,9.96">F = -p n/2 log p n/2 -(1 -p n/2 ) log(1 -p n/2 ) (2)</formula><p>where p k is the percentage of authors with class L that appear by position k. So the fairness is maximized if the probability is equal to 1/2. Our final objective function to be maximized, Z, is then a weighted average of the previous two measures, defined as follows:</p><formula xml:id="formula_2" coords="2,263.18,469.33,276.82,8.74">Z = βR + (1 -β)F<label>(3)</label></formula><p>We used the training data to evaluate three ranking algorithms: 1) AdaRank <ref type="bibr" coords="2,416.85,486.43,9.96,8.74" target="#b7">[8]</ref>, 2) Coordinate Ascent <ref type="bibr" coords="2,526.72,486.43,9.96,8.74" target="#b6">[7]</ref>, and 3) ListNet <ref type="bibr" coords="2,139.31,498.38,9.96,8.74" target="#b3">[4]</ref>. For our official submission, we selected the Coordinate Ascent model because it had the best 5-fold cross-validation results on the training data, as shown in Table <ref type="table" coords="2,399.30,510.34,3.87,8.74" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LtR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Figure <ref type="figure" coords="2,103.83,659.40,4.98,8.74">1</ref> shows the difference between the score per query (difference in expected exposure) of our system and the median over all submitted runs to the track, with topics sorted in increasing order of that difference.</p><p>As can be seen, our system achieves below-median expected exposure on 79 of the 200 queries. Figure <ref type="figure" coords="3,104.48,315.04,3.87,8.74">1</ref>: Sorted per-topic difference between our system's expected exposure score and median over all submitted runs (lower is better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we describe our submission to the second Fair Ranking Track at TREC 2020. That was our first hands-on experience with the problem of balancing relevance and fairness. There are two apparent limitations in our work. First, we based our objective function solely on the percentage of authors with class L, which is not the same as the group definition chosen by the track organizers (since the organizer's group definition is not known a priori ). To overcome these limitations, we suggest producing multiple ranked lists for a given query based on different group definitions (e.g., number of citations, gender, or country of origin). Each ranked list could then be optimized to balance between relevance and fairness according to a specific group definition. Some form of system combination (e.g., CombMNZ <ref type="bibr" coords="3,375.21,465.98,10.79,8.74" target="#b5">[6]</ref>) might then be used in an effort to produce a ranked list for each query that is robust to the user's preferred definition of fairness. Second, we submitted a static ranking per query without randomizing those results. No such ranked list can achieve the target expected exposure because two equally relevant documents will not receive the same exposure. One way to address this would be to use a stochastic version of learning to rank <ref type="bibr" coords="3,475.02,513.80,9.96,8.74" target="#b2">[3]</ref>, and that is something we are interested in trying.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,164.02,73.93,62.95,8.77;2,402.05,73.93,45.77,8.77;2,172.17,86.32,174.65,8.74;2,415.68,86.32,18.68,8.74;2,172.17,98.27,192.44,8.74;2,415.68,98.27,18.68,8.74;2,172.17,110.23,181.56,8.74;2,415.68,110.23,18.68,8.74;2,172.17,122.18,188.07,8.74;2,415.68,122.18,18.68,8.74;2,172.17,134.14,203.51,8.74;2,415.68,134.14,18.68,8.74;2,172.17,146.09,217.94,8.74;2,415.68,146.09,18.68,8.74"><head></head><label></label><figDesc>between title and query Q-D 2 BM25 score between abstract and query Q-D 3 BM25 score between venue and query Q-D 4 BM25 score between sources and query Q-D 5 BM25 score between all authors and query Q-D 6 BM25 score between fields of study and query Q-D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,167.18,158.45,274.63,210.38"><head>Table 1 :</head><label>1</label><figDesc>Learning to Rank features. Q=Query, D=Document.</figDesc><table coords="2,167.18,158.45,261.64,188.07"><row><cell>7 Min h-index of paper's authors</cell><cell>D</cell></row><row><cell>8 Avg h-index of paper's authors</cell><cell>D</cell></row><row><cell>9 Max h-index of paper's authors</cell><cell>D</cell></row><row><cell>10 Min number of papers of paper's authors</cell><cell>D</cell></row><row><cell>11 Avg number of papers of paper's authors</cell><cell>D</cell></row><row><cell>12 Max number of papers of paper's authors</cell><cell>D</cell></row><row><cell>13 Min i10-index of paper's authors</cell><cell>D</cell></row><row><cell>14 Avg i10-index of paper's authors</cell><cell>D</cell></row><row><cell>15 Max i10-index of paper's authors</cell><cell>D</cell></row><row><cell>16 Min number of citations of paper's authors</cell><cell>D</cell></row><row><cell>17 Avg number of citations of paper's authors</cell><cell>D</cell></row><row><cell>18 Max number of citations of paper's authors</cell><cell>D</cell></row><row><cell>19 Number of in citations to the paper</cell><cell>D</cell></row><row><cell>20 Number of out citations from the paper</cell><cell>D</cell></row><row><cell>21 Number of authors with class L</cell><cell>D</cell></row><row><cell>22 Number of authors with class H</cell><cell>D</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,138.81,532.41,334.38,68.14"><head>Table 2 :</head><label>2</label><figDesc>Objective function Z on the training data (higher is better).</figDesc><table coords="2,138.81,532.41,334.38,45.83"><row><cell>Algorithm</cell><cell cols="6">Fold 1 Fold 2 Fold 3 Fold 4 Fold 5 Avg.</cell></row><row><cell>AdaRank</cell><cell>0.536</cell><cell>0.556</cell><cell>0.560</cell><cell>0.596</cell><cell>0.517</cell><cell>0.553</cell></row><row><cell cols="2">Coordinate Ascent 0.558</cell><cell>0.572</cell><cell>0.570</cell><cell>0.577</cell><cell cols="2">0.527 0.561</cell></row><row><cell>ListNet</cell><cell>0.400</cell><cell>0.424</cell><cell>0.517</cell><cell>0.519</cell><cell>0.371</cell><cell>0.446</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,87.24,683.64,98.62,6.99"><p>https://fair-trec.github.io/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported in part by <rs type="funder">NSF</rs> grant <rs type="grantNumber">IIS-1618695</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_UQMfrfe">
					<idno type="grant-number">IIS-1618695</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,87.50,635.29,452.50,8.74;3,87.50,647.24,452.50,8.74;3,87.50,659.20,289.74,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,408.06,647.24,131.94,8.74;3,87.50,659.20,110.05,8.74">Construction of the literature graph in semantic scholar</title>
		<author>
			<persName coords=""><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Dunkelberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vu</forename><surname>Ha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02262</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,87.50,75.16,452.50,8.74;4,87.50,87.11,278.04,8.74" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Ekstrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Kohlmeier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11650</idno>
		<title level="m" coord="4,437.12,75.16,102.88,8.74;4,87.50,87.11,98.32,8.74">Overview of the TREC 2019 fair ranking track</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,87.50,107.04,452.50,8.74;4,87.50,118.99,452.50,8.74;4,87.50,130.95,117.78,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,394.94,107.04,145.06,8.74;4,87.50,118.99,107.08,8.74">A stochastic treatment of learning to rank scoring functions</title>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Bruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuguang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,215.61,118.99,324.39,8.74;4,87.50,130.95,28.80,8.74">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,87.50,150.87,452.50,8.74;4,87.50,162.83,452.51,8.74;4,87.50,174.78,63.65,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,360.20,150.87,179.80,8.74;4,87.50,162.83,85.65,8.74">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName coords=""><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,196.92,162.83,310.69,8.74">Proceedings of the 24th International Conference on Machine Learning</title>
		<meeting>the 24th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,87.50,194.71,452.50,8.74;4,87.50,206.67,367.06,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,493.09,194.71,46.90,8.74;4,87.50,206.67,186.94,8.74">Evaluating stochastic rankings with expected exposure</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Michael D Ekstrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Carterette</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13157</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,87.50,226.59,452.51,8.74;4,87.50,238.55,22.69,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,244.81,226.59,142.68,8.74">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,395.59,226.59,118.67,8.74">NIST special publication SP</title>
		<imprint>
			<biblScope unit="volume">243</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,87.50,258.47,452.50,8.74;4,87.50,270.43,133.91,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,251.43,258.47,228.61,8.74">Linear feature-based models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,487.91,258.47,52.09,8.74;4,87.50,270.43,37.33,8.74">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="274" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,87.50,290.35,452.50,8.74;4,87.50,302.31,452.50,8.74;4,87.50,314.26,90.83,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,182.14,290.35,239.97,8.74">Adarank: a boosting algorithm for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,441.42,290.35,98.58,8.74;4,87.50,302.31,448.36,8.74">Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="391" to="398" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
