<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.36,71.79,416.83,12.90;1,180.56,87.73,236.42,12.90">Multi-task transfer learning for finding actionable information from crisis-related messages on social media</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.72,122.46,83.91,10.75"><forename type="first">Congcong</forename><surname>Wang</surname></persName>
							<email>congcong.wang@ucdconnect.ie</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University College Dublin</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,368.78,122.46,59.17,10.75"><forename type="first">David</forename><surname>Lillis</surname></persName>
							<email>david.lillis@ucd.ie</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University College Dublin</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.36,71.79,416.83,12.90;1,180.56,87.73,236.42,12.90">Multi-task transfer learning for finding actionable information from crisis-related messages on social media</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2350E331304C52DB619BBD4F41FB5D61</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Incident streams (IS) track is a research challenge aimed at finding important information from social media during crises for emergency response purposes. More specifically, given a stream of crisis-related tweets, the IS challenge asks a participating system to 1) classify what the types of users' concerns or needs are expressed in each tweet, known as the information type (IT) classification task and 2) estimate how critical each tweet is with regard to emergency response, known as the priority level prediction task. In this paper, we describe our multi-task transfer learning approach for this challenge. Our approach leverages state-of-the-art transformer models including both encoder-based models such as BERT and a sequence-to-sequence based T5 for joint transfer learning on the two tasks. Based on this approach, we submitted several runs to the track. The returned evaluation results show that our runs substantially outperform other participating runs in both IT classification and priority level prediction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media platforms such as Twitter have made it possible for users to report on an ongoing event in their vicinity in a timely manner <ref type="bibr" coords="1,245.42,579.72,44.85,9.46;1,72.00,593.27,53.38,9.46" target="#b4">(Fraustino et al., 2012)</ref>. This has motivated researchers to explore the potential of social media platforms for finding actionable information from this usergenerated content during a crisis event <ref type="bibr" coords="1,250.90,633.92,39.37,9.46;1,72.00,647.47,52.82,9.46" target="#b1">(Caragea et al., 2011;</ref><ref type="bibr" coords="1,128.20,647.47,82.24,9.46" target="#b5">Imran et al., 2015;</ref><ref type="bibr" coords="1,213.83,647.47,76.44,9.46;1,72.00,661.02,23.48,9.46" target="#b8">McCreadie et al., 2019)</ref>. Finding this type of information is especially important for emergency response agencies to enable them to take immediate actions to help those who are posting for help, which is known as situational awareness <ref type="bibr" coords="1,184.47,715.22,68.50,9.46" target="#b15">(Vieweg, 2012;</ref><ref type="bibr" coords="1,257.43,715.22,32.84,9.46;1,72.00,728.77,52.98,9.46" target="#b14">Vieweg et al., 2010)</ref>. This naturally raises the question: how can the process of finding the actionable information effectively be automated, given the fact that the messages posted during a crisis on social media are usually noisy and numerous?</p><p>The Incident streams (IS) track <ref type="bibr" coords="1,473.44,254.29,52.10,9.46;1,307.28,267.84,54.62,9.46" target="#b8">(McCreadie et al., 2019</ref><ref type="bibr" coords="1,373.69,267.84,25.45,9.46" target="#b9">(McCreadie et al., , 2020) )</ref> is proposed by the Text REtrieval Conference (TREC) as a research challenge for this purpose. Since it was introduced in 2018, the IS track has conducted two major tasks regarding crisis short message processing. Given a stream of tweets from crisis events, the foremost task is that it asks a participating system to classify the information types (ITs) for each tweet. The ITs are simply a pre-defined set of classes in relation to something that a user is likely to post during a crisis. The ITs can be something important such as requesting research and rescue, call for moving people, reporting goods available, etc., as well as something less important such as reporting weather or location, expressing sentiment, etc. <ref type="foot" coords="1,322.72,469.03,3.99,6.91" target="#foot_0">1</ref> In addition to the ITs classification task, the IS track also asks the participating systems to estimate the priority level for each tweet, indicating how important the tweet is in taking immediate emergency response actions. The IS track predefines four priority levels: critical, high, medium and low, which are ordered from the highest to lowest priority.</p><p>The IS track was run once in 2018 and twice in each subsequent year, so it has accumulated five editions as of 2020. For each edition, an annotated collection of tweets from previous editions is used as the training data for the community, and unseen tweets (non-annotated) are released as the test tweets for official evaluation. The two most recent editions, conducted in 2020, are named 2020A and 2020B respectively. Slightly different from previous editions, the two editions introduce a reduced set of ITs as well as a set of test tweets related to the COVID-19 pandemic, resulting in three tasks described as follows.</p><p>• Task 1: This task remains the same as the editions before 2020, it uses all 25 ITs for classification and four priority levels for estimation.</p><p>• Task 2: Different from Task 1, this task only asks the participating systems to classify one or more of 12 IT classes. The 12 ITs include 11 that are closely related to emergency response and the remaining as "Other-Any" 2 .</p><p>• Task 3: Unlike Task 1 and 2 that relate to general crises such as earthquakes, explosions or hurricanes, this task focuses on the COVID-19 domain. It provides a stream of COVID-related tweets from different locations for IT classification using only a subset of 9 ITs suitable for COVID-19 and priority estimation using the same four priority levels as used in Task 1 and 2.</p><p>In this paper, we describe our system's approach in the three tasks of the IS track from our participation in both 2020A and 2020B. For different tasks, we submitted different runs but all were based on the multi-task transfer learning approach that we utilised in our system. Given the recent success of transformers <ref type="bibr" coords="2,165.92,462.12,83.35,9.46" target="#b19">(Wolf et al., 2020)</ref> in transfer learning for various language tasks such as sentence classification, question answering, etc., we leverage them in the IS challenge. We explored transformer encoder based models such as BERT <ref type="bibr" coords="2,104.23,529.86,94.71,9.46" target="#b3">(Devlin et al., 2019)</ref> and a sequence-tosequence model -T5 <ref type="bibr" coords="2,166.23,543.41,85.70,9.46" target="#b12">(Raffel et al., 2020)</ref> for their potential in this challenge. By doing so, we finetune them in a multi-task learning fashion (i.e, joint fine-tuning of the IT classification and priority estimation). With this approach, we submitted five runs to the IS track. The evaluation results show that our runs substantially outperform other participating runs in both IT classification and priority level prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To improve emergency response, the community has seen many works on exploring computational techniques for knowledge acquisition from crisis 2 For full details, refer to http://dcs.gla.ac.uk/ ˜richardm/TREC_IS/2020/participate.html messages on social media. <ref type="bibr" coords="2,431.30,66.67,94.24,9.46" target="#b1">Caragea et al. (2011)</ref> applied traditional machine learning algorithms including LDA and SVM to find important information such as people trapped or food shortage from the 2010 Haiti Earthquake. As neural network (NN) approaches have gained popularity in recent years, many deep learning approaches have been applied to this domain. For example, Nguyen et al. ( <ref type="formula" coords="2,373.91,175.06,19.39,9.46">2017</ref>) applied a convolution neural network (CNN) for classifying informative tweets from general disasters such as the 2015 Nepal Earthquake, Typhoon Hagupit, etc., whereas <ref type="bibr" coords="2,501.31,215.71,24.24,9.46;2,307.28,229.26,57.22,9.46" target="#b0">Alam et al. (2018)</ref> leveraged a CNN with adversarial training for identifying whether a tweet is relevant to a certain crisis event.</p><p>In recent years, since the attention-based transformer model was introduced <ref type="bibr" coords="2,449.40,289.32,72.75,9.46">(Vaswani et al.)</ref>, several variations have been proposed such as BERT <ref type="bibr" coords="2,339.68,316.42,93.26,9.46" target="#b3">(Devlin et al., 2019)</ref>, ELECTRA <ref type="bibr" coords="2,497.67,316.42,27.87,9.46;2,307.28,329.97,56.91,9.46" target="#b2">(Clark et al., 2020)</ref> and T5 <ref type="bibr" coords="2,407.45,329.97,90.70,9.46" target="#b12">(Raffel et al., 2020)</ref>, collectively known as the transformers <ref type="bibr" coords="2,471.22,343.52,54.33,9.46;2,307.28,357.07,23.48,9.46" target="#b19">(Wolf et al., 2020)</ref>, achieving state-of-the-art performance in many language tasks with transfer learning. It is common that the transformers are first pre-trained on a large general text corpus and then are finetuned on specific downstream language tasks such as text classification. Given the strong transfer capability of transformers, they have been widely studied for crisis messages processing also. <ref type="bibr" coords="2,510.39,451.91,15.15,9.46;2,307.28,465.46,55.83,9.46" target="#b7">Liu et al. (2020)</ref> fine-tuned BERT for crisis identification and detection tasks and Wang and Lillis (2020b) applied T5 for extracting useful information such as who tested positive/negative or cannot get test from COVID-related tweets by treating it as a question-answering task. Our approach in the IS track is similar to this line of work, which applies the transformers with transfer learning for finding actionable information in the tasks as proposed by the IS track. However, our approach is different in the way it fine-tunes the transformers by multi-task learning, aiming to make use of shared model weights between different tasks.</p><p>Since the IS track has been run for several years, the participating systems have proposed various techniques specifically for this track. Such approaches can broadly be summarised in three categories. First, traditional machine learning algorithms have been used with careful pre-processing steps and handcrafted input features. For example, Wang et al. applied models including Naïve Bayes, SVM, Random Forest, and the ensemble of these models. To train these models, they used hand-crafted features such as the length, sentiment polarity of a tweet, number of followers of the user, combining with context-free GloVe and FastText embeddings as well as context-aware BERT embeddings as the input features. The second category uses deep learning approaches that pre-date the widespread adoption of transformers. For instance, <ref type="bibr" coords="3,132.04,175.06,98.44,9.46" target="#b10">Miyazaki et al. (2019)</ref> proposed the method using label embedding with a BiLSTM model in this track while <ref type="bibr" coords="3,183.82,202.16,106.45,9.46">Wang and Lillis (2020a)</ref> applied a BiLSTM network along with pre-trained ELMo embeddings and trainable embeddings as the input features for crisis tweet categorisation. The last category encompasses transformer-based fine-tuning approaches. One example is that Zahera et al. ( <ref type="formula" coords="3,124.51,283.45,19.39,9.46">2019</ref>) fine-tuned BERT for the multilabel ITs classification task using the training tweets after preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our approach is based on multi-task transfer learning through fine-tuning both transformer encoderbased models such as BERT and sequence-tosequence transformers such as T5. The following details the process of the two types of models used, which we name the encoders scenario and sequence-to-sequence scenario respectively. Each type of model was used for both the IT classification task and priority prediction task.</p><p>Encoders scenario: This scenario simply adds two linear projection layers on top of transformer encoders such as BERT. Our architecture is agnostic as to the specific transfer encoder used. One projection layer transforms the encoder's pooled output (namely, the [CLS] output vector of BERT) to a vector representing the IT classes. The IT representation is then passed to the sigmoid function that calculates the probability distribution for every IT class. The other projection layer is used to transform the encoder's output to a vector representing the four priority levels. Similarly, it is then passed to the sigmoid function, which calculates a score indicating the priority levels as follows. In order to achieve the joint learning of both tasks, the encoder model is fine-tuned with the loss function linearly combining the binary cross entropy loss between the IT probability distribution and ground truths (a multi-label classification problem) as well as the mean squared error between the importance scores and priority ground truths (a regression problem).</p><p>Sequence-to-sequence scenario (seq2seq): This scenario is mostly motivated by the work that applies T5 for COVID-related event extraction by treating it as a multi-choice question answering task <ref type="bibr" coords="3,329.81,229.26,113.55,9.46">(Wang and Lillis, 2020a)</ref>. We adapt it to the IS track for multi-task transfer learning using seq2seq transformers such as T5. Basically, the seq2seq model takes a sequence of text as the input, known as the source sequence, and outputs the target sequence conditional on the source sequence. Under this mechanism, the template used to construct the source and target sequences in both tasks of the IS track is presented as follows.</p><p>Source: context: T question: IQ/PQ choices: IC/PC Target: I/P</p><p>• T refers to the raw tweet text without any reprocessing except for being lower-cased.</p><p>• IQ/PQ refers to the IT classification and priority estimation task-specific ad-hoc question texts, which are "what type of information does the tweet convey relating to a crisis?" and "what level of urgency is likely expressed in this tweet relating to a crisis?" respectively.</p><p>• IC/PC implies the flatted texts concatenating all IT and priority levels respectively. For example, IC is something like "call for donations, call to move people, ..." which varies in different IT classification tasks. The PC is simply "critical, high, medium, low".</p><p>• I/P indicates the generated predictions for ITs and priority level, which are direct textual predictions from IC/PC respectively.</p><p>Using this template, each tweet in the training set is converted to an IT-specific source-target pair and a priority-specific source-target pair. In order to achieve the joint learning of both tasks, the sequence-to-sequence model is fine-tuned on batches of training sequences that contain both the IT pairs and priority pairs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>This section describes the details of our system's runs submitted to the latest 2020B edition of the IS track. Since our system was developed based on our previous experience in this track, the method we described in Section 3 also covers our approach to the 2020A edition (actually the encoders scenario). Our baseline run (run1) for 2020B, which is an ensemble run under the encoders scenario from 2020A that we consider as a strong baseline.</p><p>In 2020B, we submitted a total of five runs to Task 1, 2 and 3 as mentioned in Section 1 and they are summarised in Table <ref type="table" coords="4,165.36,383.56,5.45,9.46" target="#tab_0">1</ref> and described as follows.</p><p>• run1: This is a baseline with techniques initially developed in 2019A. In 2020A, we proposed the encoders scenario, achieving strong performance as compared to other participating techniques. To further make it a strong baseline, we used a simple ensemble approach combining the predictions made by the fine-tuned individual models 3 under the encoders scenario. The ensemble run simply predicts the final IT predictions for each tweet to be the union of individual IT predictions and the final priority level to the highest of the individual priority predictions. Per the guideline of 2020B, both the IT and priority levels are expected to be numeric instead of being categorical as required prior to 2020B. Hence, we transform the final IT predictions to one-hot encodings and map the priority level prediction to its importance score by: Critical: 1.0, High: 0.75, Medium: 0.5, Low: 0.25.</p><p>• run2: Similar to run1, the difference is that 3 The individual models that were used in this run included fine-tuned bert-base-uncased, electra-base-discriminator, albert-base-v2 and distilbert-base-uncased, which are all available in the transformers library <ref type="bibr" coords="4,202.33,757.13,64.15,7.77" target="#b19">(Wolf et al., 2020)</ref>. for run2, the final ITs predictions are the highest probability values among the predictions by individual models. The final priority predictions are simply the highest of the individual models' outputs without applying the conversion as defined in Equation <ref type="formula" coords="4,479.08,281.66,4.09,9.46">1</ref>.</p><p>• run3: For this run, the seq2seq scenario is conducted for multi-task transfer learning. We follow the T5 base architecture initialised with t5-base weights and fine-tune it on the training tweets prior to 2020B (excluding the COVID-related tweets from the 2020A edition). Since the seq2seq model outputs the generated texts as the predictions for both priority and ITs, we convert the IT predictions to one-hot encodings and priority level to the importance score before they are submitted.</p><p>• run4: With a similar setup to run3, run4 is submitted for Task 3 and thus it includes the training tweets prior to 2020B including the COVID-related tweets from 2020A.</p><p>• run5: With a similar setup to run3, run5 is submitted for Task 1 &amp; 2 and it uses all previous training tweets including the COVID tweets for fine-tuning the T5 model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training Details</head><p>As described, our runs mainly focus on finetuning several transformer encoder models and a t5-base sequence-to-sequence model in a multitask learning way. For the fine-tuning of t5-base, we follow the same hyper-parameter configuration as used in <ref type="bibr" coords="4,359.63,688.12,111.36,9.46">Wang and Lillis (2020b)</ref>. For finetuning each of the transformer encoder models, we use the same set of the hyper-parameters that are configured with reference to a similar work in this domain <ref type="bibr" coords="4,378.13,742.32,77.35,9.46" target="#b7">(Liu et al., 2020)</ref>  <ref type="table" coords="5,96.50,517.78,3.88,8.64">3</ref>: Evaluation results of participating runs at TREC-IS 2020-B Task 2. The Task-1 systems refer to the runs from Task 1 re-evaluated under Task 2 while Task-2 systems are the submitted runs specific to Task 2.</p><p>the validation set first. Then, we fine-tune each model with a batch size of 32, learning rate of 5e-5, linear warm-up ratio of 0.1 with Adam optimizer <ref type="bibr" coords="5,107.78,604.24,107.48,9.46" target="#b6">(Kingma and Ba, 2015)</ref>. For the input length, we set the maximum input length to be 256 since we found few examples has length beyond this number. All training examples in our experiments are not pre-processed but used in raw texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Having submitted the five runs as described in Table <ref type="table" coords="5,100.52,715.22,5.45,9.46" target="#tab_0">1</ref> to the track, they were officially evaluated and the results are reported in Tables 2, 3 and 4. The tables show the performance of participating runs in Task 1, 2 and 3 respectively. The columns are the official metrics used to evaluate different aspects of a run's performance, which are described briefly as follows.</p><p>• Information type classification: There are two types of information type (IT) F1. The "Actionable IT" F1 reflects a run's performance in classifying actionable ITs<ref type="foot" coords="5,493.62,651.13,3.99,6.91" target="#foot_2">4</ref> . The "All IT" F1 measures a run's performance across all information types (25 in Task 1, 12 in Task 2 and 9 in Task 3). The IT accuracy is the overall accuracy in IT classification. • Prioritisation: Similarly, the Actionable priority F1 measures a run's performance in priority level prediction for only the tweets that are labeled as actionable ITs while the All F1 measures the performance for all test tweets. Moreover, the nDCG@100 is used to measure a run's average performance in ranking top 100 test tweets per event by priority.</p><p>As seen from Table <ref type="table" coords="6,172.82,517.09,4.09,9.46" target="#tab_1">2</ref>, in Task 1, our runs substantially outperform other participating runs in both IT classification and prioritisation 5 . In particular, our runs are effective in classifying actionable ITs. For example, our run1 and run3 achieve the top actionable IT F1 score of 0.3215 and the best actionable priority F1 of 0.2803 respectively. This is further evidenced by the runs' performance in Task 2, as in Table <ref type="table" coords="6,170.45,625.48,4.09,9.46">3</ref>. All the runs overall perform well in IT classification and prioritisation in Task 2 (the condensed more emergency response related 12 ITs).</p><p>In Task 1 and 2, run1 and run2 perform similarly across the metrics since both are based on the encoder scenario and only differ in the final sub- 5 The exception if accuracy, where only a small difference is observed accuracy across the participating runs: our results are substantially higher than other participating runs in the remaining metrics. mission type. It is interesting that run5 performs similarly to run3 across the metrics except for being better in nDCG@100: 0.5252 versus 0.5038. The two runs are both based on the seq2seq scenario and only difference is in their training data. This indicates that adding the COVID data (similar domain) to the general crisis data for training can be helpful in the priority-centric ranking performance. To compare between the four runs, it is found that no one run dominates the other runs across all the metrics. This indicates that the multi-task transfer learning approach using either the transformer encoder or the seq2seq as the base model is likely to bring similar performance.</p><p>To further examine our runs' performance at every IT level, we report the IT F1s and priority F1s per IT of the run1 in Task 1, as presented in Figure <ref type="figure" coords="6,388.49,633.92,4.09,9.46">1</ref>. Figure <ref type="figure" coords="6,442.18,633.92,10.30,9.46">1a</ref> shows that the run performs well in categorising some actionable ITs, such as "CallToAction-MovePeople" and "Report-EmergingThreats" while not the best in actionable ITs such as "Request-GoodsService", as compared to the non-actionable ITs. However, taking a look at the priority F1s per IT in Figure <ref type="figure" coords="6,373.45,728.77,9.09,9.46">1b</ref>, we found that the run performs relatively better in priority level prediction for actionable ITs than non-actionable ITs, where "CallToAction-MovePeople", "Request-GoodsService" and "Report-ServiceAvailable" are the top 3 the runs achieves in priority F1.</p><p>Apart from the four runs to Task 1 and Task 2, we submitted run4 to Task 3 and the results are reported in Table <ref type="table" coords="7,148.31,135.56,4.09,9.46" target="#tab_2">4</ref>. We see that the run is competitive with other participating runs, particularly in prioritisation. Unlike our other four runs in Task 1 and 2, this run achieves 0.1425 in actionable IT F1, next to the best 0.1629. Since Task 3 is COVIDrelated and newly introduced, we expect our run to be improved in future iterations of this track as more data accumulates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper introduces University College Dublin's (UCD) participation in the 2020 TREC-IS track. The IS track was run twice in 2020: namely 2020A and 2020B. Based on our experience from previous editions, we describe our multitask transfer learning approach using pre-trained encoder-based and sequence-to-sequence transformers. With these approaches, we submitted five runs to the track's 2020-B edition -four for Task 1 and Task 2, and one for Task 3. The results show that our runs to Task 1 and Task 2 substantially outperform other participating runs in both information type classification and priority level prediction. In addition, our runs are effective in finding some actionable information types in Task 1 and Task 2 and the run to Task 3 performs competitively with other participating runs. Regarding future work, we expect to explore the incorporation of knowledge graphs to enhance the model's identification of the crisis-related tweets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,130.21,694.24,101.84,9.60;3,277.55,694.62,12.72,9.46;3,133.32,714.65,95.64,9.60;3,123.82,735.07,114.63,9.60;3,135.84,755.48,90.41,9.60"><head></head><label></label><figDesc>(0.75, 1] -→ Critical (1) (0.5, 0.75] -→ High (0.25, 0.5] -→ Medium [0.0, 0.25] -→ Low</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,72.00,69.12,453.55,119.58"><head>Table 1 :</head><label>1</label><figDesc>The summary of our submitted runs for TREC-IS 2020-B. Run1, 2, 3, 5 submitted to task 1 are also submitted to task 2 for evaluation.</figDesc><table coords="4,108.09,69.12,381.36,82.68"><row><cell cols="4">runtag scenario task target submission type</cell><cell>training data</cell></row><row><cell cols="3">run1 Encoders Task 1 &amp; 2</cell><cell>one-hot</cell><cell>prior to 2020B excluding COVID</cell></row><row><cell cols="3">run2 Encoders Task 1 &amp; 2</cell><cell>probability</cell><cell>prior to 2020B excluding COVID</cell></row><row><cell>run3</cell><cell cols="2">seq2seq Task 1 &amp; 2</cell><cell>one-hot</cell><cell>prior to 2020B excluding COVID</cell></row><row><cell>run4</cell><cell>seq2seq</cell><cell>Task 3</cell><cell>one-hot</cell><cell>prior to 2020B including COVID</cell></row><row><cell>run5</cell><cell cols="2">seq2seq Task 1 &amp; 2</cell><cell>one-hot</cell><cell>prior to 2020B including COVID</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,307.28,742.32,218.27,23.01"><head>Table 2 :</head><label>2</label><figDesc>Evaluation results of participating runs at TREC-IS 2020-B Task 1. Highest in columns are bold.</figDesc><table coords="4,455.48,742.32,70.06,9.46"><row><cell>. For training,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,94.97,63.40,406.47,310.14"><head>Table 4 :</head><label>4</label><figDesc>Evaluation results of participating runs at TREC-IS 2020-B Task 3.</figDesc><table coords="6,94.97,63.40,406.47,285.86"><row><cell>F1 Scores</cell><cell>0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</cell><cell cols="3">CallToAction-Donations CallToAction-MovePeople CallToAction-Volunteer Other-Advice Other-ContextualInformation Other-Discussion Other-Irrelevant Other-Sentiment Report-CleanUp Report-EmergingThreats Report-Factoid Report-FirstPartyObservation Report-Hashtags Report-Location Report-MultimediaShare Report-News Report-NewSubEvent Report-Official Report-OriginalEvent Report-ServiceAvailable Report-ThirdPartyObservation Report-Weather Request-GoodsServices Request-InformationWanted Request-SearchAndRescue F1 Scores by Information Type</cell><cell>Priorty Label Prediction F1</cell><cell>0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</cell><cell>CallToAction-Donations CallToAction-MovePeople CallToAction-Volunteer Other-Advice Other-ContextualInformation Other-Discussion Other-Irrelevant Other-Sentiment Report-CleanUp Report-EmergingThreats Report-Factoid Report-FirstPartyObservation Report-Hashtags Report-Location Report-MultimediaShare Report-News Report-NewSubEvent Report-Official Report-OriginalEvent Report-ServiceAvailable Report-ThirdPartyObservation Report-Weather Request-GoodsServices Request-InformationWanted Request-SearchAndRescue Priorty Label Prediction F1 Per Information Type</cell></row><row><cell></cell><cell></cell><cell cols="3">(a) F1 Scores by Information Type</cell><cell cols="3">(b) Priority level prediction F1 per information type</cell></row><row><cell></cell><cell></cell><cell cols="6">Figure 1: Performance visualisation by information types of ucd-run1 in Task 1.</cell></row><row><cell cols="2">Run</cell><cell></cell><cell cols="2">nDCG@100 Info-Type F1</cell><cell cols="2">Info-Type</cell><cell>Info-Type</cell><cell>Priority F1</cell><cell>Priority F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[Actionable]</cell><cell cols="2">F1 [All]</cell><cell>Accuracy</cell><cell>[Actionable]</cell><cell>[All]</cell></row><row><cell cols="3">njit.s1.aug.t3</cell><cell>0.4322</cell><cell>0.1629</cell><cell cols="2">0.1450</cell><cell>0.8593</cell><cell>0.2551</cell><cell>0.1499</cell></row><row><cell cols="4">njit.s2.cmmd.t3 0.4329</cell><cell>0.1590</cell><cell cols="2">0.1184</cell><cell>0.8586</cell><cell>0.2551</cell><cell>0.1499</cell></row><row><cell cols="3">njit.s3.img.t3</cell><cell>0.3986</cell><cell>0.1590</cell><cell cols="2">0.1184</cell><cell>0.8586</cell><cell>0.2544</cell><cell>0.1562</cell></row><row><cell cols="3">njit.s4.cml.t3</cell><cell>0.4249</cell><cell>0.0210</cell><cell cols="2">0.0650</cell><cell>0.8626</cell><cell>0.1375</cell><cell>0.1502</cell></row><row><cell cols="3">ucd-run4</cell><cell>0.4497</cell><cell>0.1425</cell><cell cols="2">0.1817</cell><cell>0.8541</cell><cell>0.3443</cell><cell>0.2867</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,323.42,737.20,202.13,7.77;1,307.28,747.17,218.27,7.77;1,307.28,757.13,153.54,7.77"><p>There are 6 important ITs known as "actionable" ITs predefined by the IS track and 19 are considered to be "nonactionable". For details, see(McCreadie et  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="1,463.06,757.13,36.36,7.77"><p>al., 2019).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="5,323.42,727.24,18.29,7.77;5,359.29,727.24,10.95,7.77;5,387.83,727.24,84.42,7.77;5,493.67,727.24,31.88,7.77;5,307.28,737.20,67.97,7.77;5,396.16,737.20,81.07,7.77;5,498.15,737.20,27.39,7.77;5,307.28,747.17,218.27,7.77;5,307.28,757.13,64.33,7.77"><p>They are Request-GoodsService, Request-SearchAndRescue, Report-NewSubEvent, Report-ServiceAvailable, CallToAction-MovePeople, and Report-EmergingThreats.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,72.00,600.47,218.27,8.64;7,82.91,611.43,207.36,8.64;7,82.91,622.22,207.36,8.81;7,82.91,633.18,207.36,8.58;7,82.91,644.14,207.36,8.81;7,82.91,655.27,22.42,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,82.91,611.43,207.36,8.64;7,82.91,622.39,71.85,8.64">Domain adaptation with adversarial training and graph embeddings</title>
		<author>
			<persName coords=""><forename type="first">Firoj</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Muhammad</forename><surname>Imran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,176.39,622.22,113.87,8.58;7,82.91,633.18,207.36,8.58;7,82.91,644.14,43.74,8.58;7,178.93,644.14,52.79,8.58">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1077" to="1087" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct coords="7,72.00,679.77,218.27,8.64;7,82.91,690.73,207.36,8.64;7,82.91,701.69,207.36,8.64;7,82.91,712.64,207.36,8.64;7,82.91,723.43,207.36,8.81;7,82.91,734.39,207.36,8.58;7,82.91,745.35,207.36,8.58;7,82.91,756.31,92.42,8.81" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,225.02,712.64,65.26,8.64;7,82.91,723.60,135.12,8.64">Classifying text messages for the haiti earthquake</title>
		<author>
			<persName coords=""><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nathan</forename><forename type="middle">J</forename><surname>Mcneese</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anuj</forename><forename type="middle">R</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Traylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hyun-Woo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dinghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrea</forename><forename type="middle">H</forename><surname>Tapia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C Lee</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><forename type="middle">J</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,240.91,723.43,49.35,8.58;7,82.91,734.39,207.36,8.58;7,82.91,745.35,188.91,8.58">Proceedings of the 8th International Conference on Information Systems for Crisis Response and Management</title>
		<meeting>the 8th International Conference on Information Systems for Crisis Response and Management</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,67.28,218.27,8.64;7,318.19,78.24,207.36,8.64;7,318.19,89.20,207.36,8.64;7,318.19,99.99,207.36,8.81;7,318.19,110.95,81.54,8.58" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,468.04,78.24,57.50,8.64;7,318.19,89.20,207.36,8.64;7,318.19,100.16,39.99,8.64">Electra: Pretraining text encoders as discriminators rather than generators</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,380.22,99.99,145.32,8.58;7,318.19,110.95,77.40,8.58">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,131.68,218.27,8.64;7,318.19,142.64,207.36,8.64;7,318.19,153.60,207.36,8.64;7,318.19,164.39,207.36,8.81;7,318.19,175.35,207.36,8.58;7,318.19,186.31,207.36,8.58;7,318.19,197.27,207.36,8.58;7,318.19,208.40,207.36,8.64;7,318.19,219.35,145.02,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,433.74,142.64,91.80,8.64;7,318.19,153.60,207.36,8.64;7,318.19,164.56,32.23,8.64">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,374.96,164.39,150.58,8.58;7,318.19,175.35,207.36,8.58;7,318.19,186.31,207.36,8.58;7,318.19,197.27,50.27,8.58">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s" coord="7,424.47,197.27,92.79,8.58">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="7,307.28,239.92,218.27,8.64;7,318.19,250.88,207.36,8.64;7,318.19,261.67,207.36,8.81;7,318.19,272.63,204.27,8.58" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,318.19,250.88,207.36,8.64;7,318.19,261.67,207.36,8.81;7,318.19,272.63,200.12,8.58">Social media use during disasters: a review of the knowledge base and gaps. National Consortium for the Study of Terrorism and Responses to Terrorism</title>
		<author>
			<persName coords=""><forename type="first">Julia</forename><surname>Daisy Fraustino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brooke</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yan</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,293.36,218.27,8.64;7,318.19,304.32,207.36,8.64;7,318.19,315.11,207.36,8.81;7,318.19,326.07,134.45,8.81" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,427.70,304.32,97.84,8.64;7,318.19,315.28,154.61,8.64">Processing social media messages in mass emergency: A survey</title>
		<author>
			<persName coords=""><forename type="first">Muhammad</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sarah</forename><surname>Vieweg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,480.44,315.11,45.10,8.58;7,318.19,326.07,90.30,8.58">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,346.80,218.27,8.64;7,318.19,357.59,207.36,8.81;7,318.19,368.55,207.36,8.58;7,318.19,379.51,66.32,8.58" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,486.18,346.80,39.36,8.64;7,318.19,357.76,138.10,8.64">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,476.19,357.59,49.35,8.58;7,318.19,368.55,207.36,8.58;7,318.19,379.51,62.18,8.58">Proceedings of the 3rd International Conference for Learning Representations</title>
		<meeting>the 3rd International Conference for Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,400.25,218.27,8.64;7,318.19,411.20,207.36,8.64;7,318.19,422.16,207.36,8.64;7,318.19,432.95,207.36,8.81;7,318.19,443.91,75.27,8.58" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Junhua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trisha</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucienne</forename><surname>Blessing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristin</forename><forename type="middle">L</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kwan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lim</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2005.06627</idno>
		<title level="m" coord="7,498.98,411.20,26.57,8.64;7,318.19,422.16,207.36,8.64;7,318.19,433.12,136.33,8.64">Crisis-BERT: Robust Transformer for Crisis Classification and Contextual Crisis Embedding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,307.28,464.65,218.27,8.64;7,318.19,475.61,207.36,8.64;7,318.19,486.40,207.36,8.81;7,318.19,497.35,207.36,8.81;7,318.19,508.48,83.29,8.64" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cody</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<title level="m" coord="7,371.70,475.61,153.84,8.64;7,318.19,486.40,207.36,8.81;7,318.19,497.35,177.73,8.58">TREC incident streams: Finding actionable information on social media. Proceedings of the International ISCRAM Conference</title>
		<imprint>
			<date type="published" when="2019-05">2019. 2019-May(May</date>
			<biblScope unit="page" from="691" to="705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,529.05,218.27,8.64;7,318.19,540.01,207.36,8.64;7,318.19,550.80,207.36,8.81;7,318.19,561.76,207.36,8.58;7,318.19,572.71,207.36,8.58;7,318.19,583.67,55.34,8.58" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,367.67,540.01,157.88,8.64;7,318.19,550.97,121.91,8.64">Incident Streams 2019: Actionable Insights and How to Find Them</title>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cody</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,464.73,550.80,60.81,8.58;7,318.19,561.76,207.36,8.58;7,318.19,572.71,188.91,8.58">Proceedings of the 17th International Conference on Information Systems for Crisis Response and Management</title>
		<meeting>the 17th International Conference on Information Systems for Crisis Response and Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>IS-CRAM 2020</note>
</biblStruct>

<biblStruct coords="7,307.28,604.41,218.27,8.64;7,318.19,615.37,207.36,8.64;7,318.19,626.33,207.36,8.64;7,318.19,637.12,207.36,8.81;7,318.19,648.07,207.36,8.58;7,318.19,659.03,207.36,8.58;7,318.19,669.99,207.36,8.81;7,318.19,681.12,47.32,8.64" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,454.70,615.37,70.84,8.64;7,318.19,626.33,207.36,8.64;7,318.19,637.28,35.48,8.64">Label embedding using hierarchical structure of labels for twitter classification</title>
		<author>
			<persName coords=""><forename type="first">Taro</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kiminobu</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuka</forename><surname>Takei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hiroki</forename><surname>Okamoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,371.12,637.12,154.42,8.58;7,318.19,648.07,207.36,8.58;7,318.19,659.03,207.36,8.58;7,318.19,669.99,176.50,8.58">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6318" to="6323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,307.28,701.69,218.27,8.64;7,318.19,712.64,207.36,8.64;7,318.19,723.60,207.36,8.64;7,318.19,734.56,207.36,8.64;7,318.19,745.35,207.35,8.81;7,318.19,756.31,104.51,8.58" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,359.59,723.60,165.96,8.64;7,318.19,734.56,207.36,8.64;7,318.19,745.52,22.28,8.64">Robust classification of crisis-related data on social networks using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Kamela</forename><surname>Dat Tien Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Al</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shafiq</forename><surname>Mannai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hassan</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Muhammad</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prasenjit</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,361.83,745.35,163.70,8.58;7,318.19,756.31,99.85,8.58">Eleventh International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,67.28,218.27,8.64;8,82.91,78.24,207.36,8.64;8,82.91,89.20,207.36,8.64;8,82.91,100.16,207.36,8.64;8,82.91,110.95,207.36,8.81;8,82.91,122.08,56.73,8.64" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,209.77,89.20,80.50,8.64;8,82.91,100.16,207.36,8.64;8,82.91,111.12,24.90,8.64">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,122.65,110.95,163.28,8.58">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,142.00,218.27,8.64;8,82.91,152.96,207.36,8.64;8,82.91,163.92,207.36,8.64;8,82.91,174.71,207.36,8.81;8,82.91,185.67,49.25,8.58" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,209.23,163.92,81.04,8.64;8,82.91,174.88,17.04,8.64">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,121.79,174.71,168.48,8.58;8,82.91,185.67,45.00,8.58">Advances in Neural Information Processing Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,205.76,218.27,8.64;8,82.91,216.72,207.36,8.64;8,82.91,227.68,207.36,8.64;8,82.91,238.47,207.35,8.81;8,82.91,249.43,207.36,8.58;8,82.91,260.39,135.19,8.81" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,165.98,216.72,124.29,8.64;8,82.91,227.68,207.36,8.64;8,82.91,238.64,98.30,8.64">Microblogging during two natural hazards events: what twitter may contribute to situational awareness</title>
		<author>
			<persName coords=""><forename type="first">Sarah</forename><surname>Vieweg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amanda</forename><forename type="middle">L</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kate</forename><surname>Starbird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leysia</forename><surname>Palen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,210.81,238.47,79.45,8.58;8,82.91,249.43,207.36,8.58;8,82.91,260.39,28.81,8.58">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1079" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,280.31,218.27,8.81;8,82.91,291.27,207.36,8.58;8,82.91,302.23,207.36,8.81;8,82.91,313.36,165.92,8.64" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="8,201.78,280.31,88.49,8.58;8,82.91,291.27,207.36,8.58;8,82.91,302.23,170.98,8.58">Situational awareness in mass emergency: A behavioral and linguistic analysis of microblogged communications</title>
		<author>
			<persName coords=""><forename type="first">Elizabeth</forename><surname>Sarah</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vieweg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>University of Colorado at Boulder</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="8,72.00,333.28,218.27,8.64;8,82.91,344.24,207.36,8.64;8,82.91,355.03,207.36,8.81;8,82.91,365.99,207.36,8.58;8,82.91,376.95,133.55,8.81" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,257.06,333.28,33.22,8.64;8,82.91,344.24,207.36,8.64;8,82.91,355.20,148.29,8.64">Classification for Crisis-Related Tweets Leveraging Word Embeddings and Data Augmentation</title>
		<author>
			<persName coords=""><forename type="first">Congcong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lillis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,254.20,355.03,36.06,8.58;8,82.91,365.99,207.36,8.58;8,82.91,376.95,51.61,8.58">Proceedings of the Twenty-Eighth Text REtrieval Conference (TREC 2019)</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference (TREC 2019)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,397.05,218.27,8.64;8,318.19,67.28,207.36,8.64;8,318.19,78.24,207.36,8.64;8,318.19,89.03,207.36,8.81;8,318.19,99.99,207.36,8.81;8,318.19,111.12,207.36,8.64;8,318.19,122.08,16.33,8.64" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,243.77,397.05,46.50,8.64;8,318.19,67.28,207.36,8.64;8,318.19,78.24,207.36,8.64;8,318.19,89.20,23.29,8.64">UCD-CS at W-NUT 2020 Shared Task-3: A Text to Text Approach for COVID-19 Event Extraction on Social Media</title>
		<author>
			<persName coords=""><forename type="first">Congcong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lillis</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.wnut-1.78</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,366.87,89.03,158.67,8.58;8,318.19,99.99,175.79,8.58">Proceedings of the Sixth Workshop on Noisy User-Generated Text (W-NUT 2020)</title>
		<meeting>the Sixth Workshop on Noisy User-Generated Text (W-NUT 2020)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="514" to="521" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="8,307.28,144.33,218.27,8.64;8,318.19,155.29,207.36,8.64;8,318.19,166.08,207.36,8.81;8,318.19,177.03,207.36,8.58;8,318.19,187.99,103.38,8.81" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,391.36,155.29,134.19,8.64;8,318.19,166.24,96.63,8.64">CMU-Informedia at TREC 2019 Incident Streams Track</title>
		<author>
			<persName coords=""><forename type="first">Junpei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,445.52,166.08,80.02,8.58;8,318.19,177.03,207.36,8.58;8,318.19,187.99,21.44,8.58">Proceedings of the Twenty-Eighth Text REtrieval Conference (TREC 2019)</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference (TREC 2019)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,307.28,210.41,218.27,8.64;8,318.19,221.37,207.36,8.64;8,318.19,232.33,207.36,8.64;8,318.19,243.29,207.36,8.64;8,318.19,254.25,207.36,8.64;8,318.19,265.21,207.36,8.64;8,318.19,276.17,207.36,8.64;8,318.19,287.12,207.36,8.64;8,318.19,297.91,207.36,8.81;8,318.19,308.87,207.36,8.58;8,318.19,319.83,207.36,8.81;8,318.19,330.96,161.06,8.64" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,499.89,276.17,25.65,8.64;8,318.19,287.12,207.36,8.64;8,318.19,298.08,11.42,8.64">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,348.40,297.91,177.14,8.58;8,318.19,308.87,207.36,8.58;8,318.19,319.83,93.05,8.58">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="8,307.28,353.21,218.27,8.64;8,318.19,364.17,207.36,8.64;8,318.19,375.13,207.36,8.64;8,318.19,385.92,207.35,8.81;8,318.19,396.88,181.60,8.81" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,482.38,364.17,43.17,8.64;8,318.19,375.13,203.58,8.64">Fine-tuned BERT Model for Multi-Label Tweets Classification</title>
		<author>
			<persName coords=""><forename type="first">Ibrahim</forename><forename type="middle">A</forename><surname>Hamada M Zahera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rricha</forename><surname>Elgendy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohamed</forename><forename type="middle">Ahmed</forename><surname>Jalota</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sherif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,329.45,385.92,196.09,8.58;8,318.19,396.88,99.66,8.58">Proceedings of the Twenty-Eighth Text REtrieval Conference (TREC 2019)</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference (TREC 2019)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
