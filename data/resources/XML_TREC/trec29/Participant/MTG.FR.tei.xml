<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.40,84.23,431.19,15.44">Balancing Exposure and Relevance in Academic Search</title>
				<funder ref="#_MpeHqkJ">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder>
					<orgName type="full">Kakao Corp</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,105.11,114.38,74.06,10.59"><forename type="first">Andres</forename><surname>Ferraro</surname></persName>
							<email>andres.ferraro@upf.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Pompeu Fabra</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.30,114.38,80.40,10.59"><forename type="first">Lorenzo</forename><surname>Porcaro</surname></persName>
							<email>lorenzo.porcaro@upf.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Universitat Pompeu Fabra</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,440.13,114.38,60.64,10.59"><forename type="first">Xavier</forename><surname>Serra</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universitat Pompeu Fabra</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.40,84.23,431.19,15.44">Balancing Exposure and Relevance in Academic Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4A66E5D9837C1CB09C7F8D4F7D5C7004</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information retrieval</term>
					<term>TREC 2020 fair ranking track</term>
					<term>exposure</term>
					<term>fairness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TREC 2020 Fair Ranking Track focuses on the evaluation of retrieval systems according to how well they fairly rank academic papers. The evaluation metric considered estimates how much the ranked papers are relevant and fairly represent different groups of authors, groups unknown to the track's participants. In this paper, we present the three different solutions proposed by our team to the given problem. The first solution is built on a learning-to-rank model to predict how much the documents are relevant for a given query and modify the ranking based on this relevance and a randomization strategy. The second approach is also based on the relevance predicted by a learning-to-rank model, but it additionally selects the authors using categories defined by analyzing collaborations between authors. The third approach uses the DELTR framework, and it considers different categories of authors based on the corresponding H-class. The results show that the first approach gives the best performance, with the additional advantage that it does not require extra information about the authors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In the field of information retrieval, the area of fair ranking focuses on minimizing the disparity in items' exposure while at the same time giving relevant results. However, fairness is not a concept generalizable and universally accepted in a univocal way. In the context of the Text Retrieval Conference (TREC) 2020, the specific goal of the Fair Ranking Track was to provide fair exposure to different groups of authors in an academic search task. For accomplishing it, we explored different ways to consider the trade-off between the relevance of the results and group exposure leading to diverse outcomes. First, we used a learning-to-rank model combined with randomization ( Â§2.1), to ensure that results with the same relevance are likely to be ranked similarly. Second, on top of the previous logic, we build a group classification of authors based on their collaborations, making use of the authors' network. We eventually used such classification for re-ranking the results obtained through the relevance-based model ( Â§2.2). Third, we consider the DELTR framework proposed in <ref type="bibr" coords="1,140.91,639.92,9.32,7.94" target="#b4">[5]</ref>, using the authors' H-class as the main feature for training the learning-to-rank model ( Â§2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROPOSED MODELS</head><p>We proposed three different alternatives for the reranking problem in TREC 2020 Fair Ranking Track. In this Section, we describe the proposed solutions. The evaluation metric has been provided by the organizers of the track<ref type="foot" coords="1,413.74,180.99,3.38,6.44" target="#foot_0">1</ref> , and it is expressed by the formula <ref type="bibr" coords="1,546.60,183.14,9.44,7.94" target="#b3">[4]</ref>:</p><formula xml:id="formula_0" coords="1,357.67,209.37,200.53,33.45">ğ‘’ ğœ‹ ğ‘ = ğ‘› ğ‘–=1 ï£® ï£¯ ï£¯ ï£¯ ï£¯ ï£° ğ›¾ ğ‘–-1 ğ‘–-1 ğ‘—=1 (1 -ğ‘ (ğ‘  |ğœ‹ ğ‘— )) ï£¹ ï£º ï£º ï£º ï£º ï£» ğ¼ (ğœ‹ ğ‘– âˆˆ D ğ‘ )<label>(1)</label></formula><p>where The final expected exposure for a is the sum over all the impressions for a query, Î  ğ‘ :</p><formula xml:id="formula_1" coords="1,333.92,259.10,4.46,7.70">â€¢</formula><formula xml:id="formula_2" coords="1,414.02,365.28,144.18,18.83">ğ‘’ ğ‘ = ğœ‹ âˆˆÎ  ğ‘ ğ‘’ ğœ‹ ğ‘ (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relevance</head><p>Our first approach is based on the solution proposed by Bonant<ref type="foot" coords="1,542.04,411.05,3.38,6.44" target="#foot_1">2</ref>  <ref type="bibr" coords="1,547.78,413.20,10.43,7.94" target="#b1">[2]</ref> to the 2019 Fair TREC. We first train a ranking model <ref type="bibr" coords="1,524.34,424.16,10.68,7.94" target="#b2">[3]</ref> using features extracted from the provided data, including the length of the query and the following information for each publication: title, abstract, entities, venue, journal, authors' names, out-citations and in-citations.</p><p>Once the ranking model is trained, for a given query of length ğ¾, we compute the relevance score predicted by the model for each item ( rğ‘– ). Then, we sort the items according to the predicted relevance and compute the mean difference (ğ‘‘) following the Equation 3.</p><formula xml:id="formula_3" coords="1,400.80,547.21,157.40,24.75">ğ‘‘ = 1 ğ¾ â€¢ ğ¾ ğ‘–=2 rğ‘– -rğ‘–-1<label>(3)</label></formula><p>Since the goal of this approach is that items with the same relevance will have the same probability to be in a position, we apply a randomization to the results based on the predicted relevance. The new relevance ( r ) is computed following the Equation <ref type="formula" coords="1,517.26,613.02,3.07,7.94">4</ref>. rğ‘– = ğ‘Ÿğ‘ğ‘›ğ‘‘ğ‘œğ‘š(0, ğ‘‘) + rğ‘– (4)</p><p>We then obtain the final ranking by sorting the items using the new relevance rğ‘– .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Groups exposure</head><p>The main goal of the second solution was to give equal exposure to authors of different groups. In order to define the groups, we make use of a graph of authors connected by the collaborations between them in the papers. Afterwards, we use the method proposed by Blondel et al. <ref type="bibr" coords="2,106.40,145.33,10.68,7.94" target="#b0">[1]</ref> to create groups of authors, depending on the distance that they presented in the graph. Using this method, each author in the dataset was assigned to a single group. Therefore, authors in the same group should be co-authors in a paper, or should have some co-author in common.</p><p>In order to generate the reranking, for a given query we first obtain a relevance value following the procedure explain the Section 2.1, and then we assign the corresponding group to each candidate paper. Finally, we select the paper of each group with higher relevance and we repeat this process until all the papers are ranked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Protected groups</head><p>The third solution proposed is based on the framework created by Zehlike and Castillo <ref type="bibr" coords="2,130.62,291.90,9.49,7.94" target="#b4">[5]</ref>. DELTR is a learning-to-rank framework that allows to take into account the different categories of authors to addresses potential issues of discrimination and unequal opportunity. One of the parameters that needs to be defined in DELTR is the 'gamma', which indicates the importance of the provided class. Gamma equals zero gives more importance to relevance over fairness, and gamma value of one gives more importance to fairness over relevance. In our case, we used the H-class provided by the organizers to train DELTR. In order to obtain a trade-off between relevance and fairness we train two models of DELTR, one with gamma=1 and another with gamma=0, then for each query we used a weighted average of the score obtain by each model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DISCUSSION AND FUTURE WORK</head><p>In Figure <ref type="figure" coords="2,89.02,449.44,3.06,7.94" target="#fig_0">1</ref>, we provide details about the performance of the three approaches from the information published by the organizers, showing the distributions of the difference in exposure compared with the expected exposure on each query. These results are also summarized in Table <ref type="table" coords="2,116.84,493.27,3.06,7.94" target="#tab_1">1</ref>, where the average expected exposure for each model is reported.</p><p>We can see that the performance of the randomized ranking based on relevance gives a lower difference with the expected exposure. Therefore, the proposed alternative for the first solution based on authors' groups, in this case, does not improve the results. However, including the groups' information seems to mitigate the wrong behaviors of the first model, especially in the cases where it shows worst performances (see the outliers in Figure <ref type="figure" coords="2,265.83,580.94,3.00,7.94" target="#fig_0">1</ref>). This mitigation is also proven by the smaller variance of the results of the second model, in comparison to the first one, indicating that this solution could be effective for joining group constraints and relevance. Randomizing the order of the groups when selected in the reranking step could also be helpful in reducing the variance of the results. Nonetheless, the groups created with our model are not symmetrically distributed, having few groups with a lot of authors, and a series of small groups with only two authors. Because of how academic networks are built, where few big communities collaborate while many small research labs are not connected, our grouping represents a real-world scenario, which however implies  a structural unfairness which partly has been embedded in our model. Using a group definition which does not take into account only collaboration, but also other socio-political differentials should lead to improved results. We also see that the proposed solution based balancing fairness and relevance using DELTR gives a higher difference with the expected exposure compared to the other approaches.</p><p>In summary, we proposed three different alternatives to balance exposure and relevance of the documents. Basing on the results, we see that the more simple solution is the one that performed better. Nevertheless, is important to mention that the proposed alternatives followed an exploratory approach and is possible that further studies could lead to improvements in the results of each solution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,317.96,312.36,241.85,7.70;2,317.96,323.32,22.29,7.70;2,317.96,172.43,240.27,125.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Difference in exposure summary statistics -boxplots.</figDesc><graphic coords="2,317.96,172.43,240.27,125.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,352.85,85.73,170.01,71.27"><head>Table 1 :</head><label>1</label><figDesc>Results of the proposed solutionsModelDifference in exposure -ğ‘ğ‘£ğ‘”(ğ‘’ ğ‘ )</figDesc><table coords="2,352.85,127.14,121.85,29.86"><row><cell>LM-rel</cell><cell>0.6733</cell></row><row><cell>LM-groups</cell><cell>0.6755</cell></row><row><cell>Deltr</cell><cell>0.9097</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,320.88,694.38,156.64,6.18"><p>https://fair-trec.github.io/2020/doc/guidelines-2020.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,321.00,702.79,152.45,6.18"><p>Code available at https://github.com/irgroup/fair-trec</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work is partially supported by the <rs type="funder">European Commission</rs> under the <rs type="projectName">TROMPA</rs> project (<rs type="grantNumber">H2020 770376</rs>). This work is also partially supported by <rs type="funder">Kakao Corp</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_MpeHqkJ">
					<idno type="grant-number">H2020 770376</idno>
					<orgName type="project" subtype="full">TROMPA</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="2,330.15,583.72,229.13,6.18;2,330.15,591.63,228.05,6.25;2,330.15,599.60,163.02,6.25" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="2,349.37,591.69,142.78,6.18">Fast unfolding of communities in large networks</title>
		<author>
			<persName coords=""><forename type="first">Jean-Loup</forename><surname>Vincent D Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Guillaume</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Etienne</forename><surname>Lambiotte</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="2,499.77,591.63,58.43,6.25;2,330.15,599.60,94.47,6.25">Journal of statistical mechanics: theory and experiment</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">10008</biblScope>
			<date type="published" when="2008">2008. 2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,330.15,607.63,176.90,6.18" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Malte</forename><surname>Bonart</surname></persName>
		</author>
		<title level="m" coord="2,390.13,607.63,89.37,6.18">Fair ranking in academic search</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="2,330.15,615.60,228.05,6.18;2,330.15,623.52,131.22,6.25" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="2,418.44,615.60,139.76,6.18;2,330.15,623.57,24.40,6.18">From ranknet to lambdarank to lambdamart: An overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2010-82</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="2,330.15,631.54,228.05,6.18;2,330.15,639.46,228.05,6.25;2,330.15,647.43,91.44,6.25" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Michael D Ekstrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Carterette</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13157</idno>
		<title level="m" coord="2,379.01,639.51,158.14,6.18">Evaluating Stochastic Rankings with Expected Exposure</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="2,330.15,655.45,228.30,6.18;2,330.15,663.37,226.33,6.25" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="2,441.53,655.45,116.92,6.18;2,330.15,663.42,71.18,6.18">Reducing disparate exposure in ranking: A learning to rank approach</title>
		<author>
			<persName coords=""><forename type="first">Meike</forename><surname>Zehlike</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,413.55,663.37,95.16,6.25">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="2849" to="2855" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
