<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.57,107.03,416.10,12.90">LRG at TREC 2020: Document Ranking with XLNet-Based Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,173.39,146.54,91.33,10.75"><forename type="first">Abheesht</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">BITS Pilani</orgName>
								<orgName type="institution" key="instit2">KK Birla Goa Campus</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,361.86,146.54,79.92,10.75"><forename type="first">Harshit</forename><surname>Pandey</surname></persName>
							<email>hp2pandey1@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">BITS Pilani</orgName>
								<orgName type="institution" key="instit2">KK Birla Goa Campus</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.57,107.03,416.10,12.90">LRG at TREC 2020: Document Ranking with XLNet-Based Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">639891DEF5A8947DC526712C4027BF68</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Establishing a good information retrieval system in popular mediums of entertainment is a quickly growing area of investigation for companies and researchers alike. We delve into the domain of information retrieval for podcasts. In Spotify's Podcast Challenge, we are given a user's query with a description to find the most relevant short segment from the given dataset having all the podcasts. Previous techniques that include solely classical Information Retrieval (IR) techniques, perform poorly when descriptive queries are presented. On the other hand, models which exclusively rely on large neural networks tend to perform better. The downside to this technique is that a considerable amount of time and computing power are required to infer the result. We experiment with two hybrid models which first filter out the best podcasts based on user's query with a classical IR technique, and then perform re-ranking on the shortlisted documents based on the detailed description using a transformer-based model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Podcasts are exploding in popularity. With the addition of the DIY podcasting platform Anchor, everyone today has access to tools to create their own podcasts and publish it to Spotify, and hence, the landscape is growing ever richer and more diverse. As the medium grows, a very interesting problem arises: how can one connect one's users to podcasts which align with one's interest? How can a user find the needle in the haystack and how can the user be presented with a list of potential podcasts customized to their interests? The Spotify podcasts track of TREC 2020 attempts to enhance the discoverability of podcasts with a task that attempts to retrieve the jump-in point for relevant segments of podcast episodes given a query and a description.</p><p>The dataset consists of 100,000 episodes from a large variety of different shows on Spotify. The sampled episodes range from amateur to professional podcasts including a wide variety of formats, topics and audio quality. Each episode consists of a raw audio file, an RSS header contain-ing the metadata (such as title, description and publisher) and an automatically-generated transcript in English that boasts a word error rate of just 18.1% as well as a named entity recognition rate of 81.8%.</p><p>Traditional information retrieval techniques use statistical methods such as TF-IDF to score and retrieve relevant segments. While these methods work well on straightforward queries which consist of only a few terms, and which can be easily matched with the keywords of the document to be retrieved, the more complicated queries with abstract questions will end up failing in traditional IR techniques. The Spotify dataset <ref type="bibr" coords="1,339.05,351.77,11.63,8.64" target="#b0">[1]</ref> for the information retrieval task consists of two components for a user's search: the query and a description along with the query, which is a more verbose query highlighting the specific requirements of the user. A traditional IR system ends up performing poorly if we consider the descriptive query. On the other hand, transformer-based models like BERT have been used for information retrieval tasks and have achieved satisfactory results considering both the parameters of the user's search. However, the amount of time required to process one search request is considerable more than the traditional IR methods.</p><p>Our approaches use both: a traditional information retrieval system as well as a transformers-based model. For the traditional information retrieval model, we use a combination of BM25 <ref type="bibr" coords="1,346.67,522.17,15.12,8.64" target="#b10">[11]</ref>, a traditional relevance ranking model, as well as, RM3 <ref type="bibr" coords="1,346.79,534.12,10.72,8.64" target="#b5">[6]</ref>, a relevance-based language model for query expansion. We filter the top thousand podcasts from this IR model and pass it to our transformer-based model. For the transformer-based model, we use XLNet <ref type="bibr" coords="1,469.53,569.99,15.12,8.64" target="#b14">[15]</ref>, a Permutation Language Model (PLM) with two different modifications. For the first type of XLNet model, we add a simple linear layer to XLNet that performs a regression task to generate a score reflecting how relevant the query-document pair is.</p><p>The second approach is contextualised re-ranking with XLNet. We use XLNet to compute the query and document embeddings separately, and we use these embeddings to compute the similarity matrix between the query and the document, followed by kernel pooling techniques to arrive at a relevance score. The advantage of this method is that we can create, store and index the embeddings of documents for future use. Storing contextualised representation makes the query-inference time much lesser than the above mentioned regression model, according to Sebastian Hofstätter et al. <ref type="bibr" coords="2,274.64,99.39,10.06,8.64" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In the earlier days, before the advent of neural networks, people relied on statistical or probabilistic algorithms such as TF-IDF, BM25 <ref type="bibr" coords="2,122.54,166.30,16.46,8.64" target="#b10">[11]</ref> and RM3 <ref type="bibr" coords="2,180.50,166.30,10.44,8.64" target="#b5">[6]</ref>. BM25 is based loosely on the TF-IDF <ref type="bibr" coords="2,109.69,178.25,16.46,8.64" target="#b9">[10]</ref> model but improves on it by introducing a document length normalization term and by satisfying the concavity constraint of the term frequency (taking logarithm of the term frequency, etc.). RM3 is an association-based and relevance-based language model, useful for query expansion. BM25 and RM3 together form a lethal combination (namely, BM25+RM3), and is reliable and efficient.</p><p>However, with the meteoric rise of neural networks (and the fact that BM25+RM3 is essentially a statistical method), researchers started looking for models which can learn unique representations for words based on their context, usage in text, etc. A few CNN/RNN-based methods are DRMM <ref type="bibr" coords="2,84.15,321.75,10.58,8.64" target="#b2">[3]</ref>, DSSM <ref type="bibr" coords="2,130.37,321.75,10.58,8.64" target="#b4">[5]</ref>, CDSSM <ref type="bibr" coords="2,183.23,321.75,16.60,8.64" target="#b11">[12]</ref> and K-NRM <ref type="bibr" coords="2,254.89,321.75,15.27,8.64" target="#b12">[13]</ref>.</p><p>One of the earliest attempts in neural research for document retrieval was with DSSM <ref type="bibr" coords="2,188.94,345.70,10.72,8.64" target="#b4">[5]</ref>. The DSSM model ranked the query and document simply by their representation similarities. Later on, a version of DSSM with CNNs was introduced, also known as CDSSM. <ref type="bibr" coords="2,204.11,381.57,20.13,8.64" target="#b11">[12]</ref>.</p><p>DRMM, a CNN-based model, introduced a histogram pooling technique to summarize the translation matrix and hence showed that counting the word level translation scores at different soft match levels is more effective than weightsumming them.</p><p>K-NRM <ref type="bibr" coords="2,98.29,453.38,16.70,8.64" target="#b12">[13]</ref> uses the similarities between the words of the query and the document to build a translation matrix and then uses kernel-pooling to obtain summarised word embeddings and at the same time, provides soft-match signals in order to learn how to rank. The Conv-KNRM <ref type="bibr" coords="2,274.61,501.20,11.75,8.64" target="#b1">[2]</ref> model uses a CNN for soft-matching of n-grams. CNNs are used to represent n-grams of various lengths which are then soft-matched in a unified embedding space. It ranks using n-grams soft matches with Kernel Pooling and learning to rank layer.</p><p>Then came the era of transformer-based information retrieval approaches. One of the first transformer based methods was using BERT for ad hoc-retrieval <ref type="bibr" coords="2,225.09,596.88,15.42,8.64" target="#b13">[14]</ref>. BERT is used to get a combined representation of the query and the document with a linear layer on top which is then used for obtaining a score. XLNet <ref type="bibr" coords="2,143.02,632.74,16.53,8.64" target="#b14">[15]</ref> follows a permutation language modelling approach that outperforms BERT on various NLP tasks, which is why we we chose XLNet as the encoder.</p><p>Hofstätter, et. al. <ref type="bibr" coords="2,133.16,668.65,11.73,8.64" target="#b3">[4]</ref> combine the transformers with the KNRM method. The difference from the KNRM approach is that they use an n-layered transformer to obtain embeddings for the query and the document. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Approach</head><p>Here, We elucidate the algorithms and models that are required to implement our approach. We start off with the traditional IR method, i.e., BM25 and RM3, and then, move on to XLNet Regression and XLNet with Similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">BM25</head><p>BM25 <ref type="bibr" coords="2,350.16,357.76,16.73,8.64" target="#b10">[11]</ref> is a bag-of-words retrieval function which ranks documents based on the appearance of query terms in every document, not taking into consideration the proximity of the query words within the document. The general instantiation method is as follows:</p><p>Given a query Q, containing keywords q 1 , ..., q n the BM25 score of a document D is:</p><formula xml:id="formula_0" coords="2,310.52,445.93,254.33,32.37">score(D, Q) = n i=1 IDF (q i )• f (q i , D) • (k 1 + 1) f (q i , D) + k 1 • 1 -b + b • |D| avgdl</formula><p>(1) where f (q i , D) is q i 's term frequency in the document D, |D| is the length of the document D in words, and avgdl is the average document length amongst other documents from the text collection. k 1 and b are free parameters, usually chosen, in absence of an advanced optimization, as k 1 ∈ [1.2, 2.0] and b = 0.75. IDF (q i ) is the IDF (inverse document frequency) weight of the query term, q i . It is usually computed as:</p><formula xml:id="formula_1" coords="2,346.98,597.04,194.26,23.22">IDF (q i ) = ln N -n (q i ) + 0.5 n (q i ) + 0.5 + 1 (<label>2</label></formula><formula xml:id="formula_2" coords="2,541.24,604.10,3.87,8.64">)</formula><p>where N is the total number of documents in the collection, and n(q i ) is the number of documents containing q i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">RM3</head><p>In the first estimation method of relevance model (often called RM1), the query likelihood p(Q | D) is used as the weight for document D. For every word w, we average over the probabilities given by each document language model. The formula of RM1 is:</p><formula xml:id="formula_3" coords="3,59.50,336.00,226.87,31.17">p 1 (w | Q) ∝ θ D ∈Θ p (w | θ D ) p (θ D ) m i=1 p (q i | θ D ) (3)</formula><p>where Θ denotes the set of smoothed document models in the pseudo feedback collection F , and</p><formula xml:id="formula_4" coords="3,190.70,387.57,91.69,9.65">Q = {q 1 , q 2 , • • • , q m }.</formula><p>In RM2, the term p(w|Q) is computed using document containing both query terms and word.</p><formula xml:id="formula_5" coords="3,53.20,428.09,229.29,41.14">p 2 (w | Q) ∝ p(w) m i=1 θ D ∈Θ p (q i | θ D ) p (w | θ D ) p (θ D ) p(w)<label>(4</label></formula><p>) RM3 is based on RM1 and RM2, and it uses the Dirichlet Smoothing Method to smooth the language model of each pseudo-relevant document. To enhance the performance, a linear combination of P (w | Q) and θ Q can be taken <ref type="bibr" coords="3,262.98,508.41,10.58,8.64" target="#b7">[8]</ref>.</p><formula xml:id="formula_6" coords="3,55.09,527.46,231.27,10.62">RM3 : p w | θ Q = (1 -α)p (w | θ Q ) + αp 1 (w | Q) (5)</formula><p>We chose to use RM3 <ref type="bibr" coords="3,144.20,547.15,11.75,8.64" target="#b5">[6]</ref> over RM4 and other query language models because of the conclusions derived from <ref type="bibr" coords="3,270.50,559.11,10.58,8.64" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">BM25 + RM3</head><p>We score each episode using BM25+RM3 model and hence select the top 1000 episodes to be processed further. Compared to QL, QL+RM3 and other combinations, performed the best <ref type="bibr" coords="3,114.58,631.81,10.58,8.64" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">XLNet Regression</head><p>The XLNet paper consolidates the latest advances in NLP research with inventive decisions in how the language modelling problem is approached. XLNet achieves state-of-theart for a multitude of NLP tasks. XLNet is a Permutation Language Model. It calculates the probability of a word token given all permutations of word tokens in a sentence, instead of just those before or just after the target token, i.e., it takes bidirectional context into account.</p><p>Previous works have used BERT. However, since the online implementations of BERT have a limit on the sequence length (up to 512 tokens), and XLNet can handle large documents (it has no token limit), we proceed with XLNet. The formal definition of the XLNet modeling objective is as follows:</p><formula xml:id="formula_7" coords="3,351.30,436.11,193.81,30.20">max θ E z∼Z T T t=1 log p θ (x zt | x z&lt;t )<label>(6)</label></formula><p>where Z T is the set of all possible permutations of the length-T index sequence [1, 2, . . . , T ]. The use of z t and z &lt;t is to denote the t -th element and the first t -1 elements of a permutation z ∈ Z T . <ref type="bibr" coords="3,398.02,513.19,15.42,8.64" target="#b14">[15]</ref>. We use the pre-trained XLNet model (base-cased) from the HuggingFace repository. We add a linear layer on top (with dropout probability of 0.1).</p><p>For training our model, We fine-tune it on a subset of the MS-Marco Passage Ranking Dataset <ref type="bibr" coords="3,465.24,561.01,11.74,8.64" target="#b8">[9]</ref> after freezing 5 encoder layers out of the 12 encoder layers. The subset has 100,000 samples. This linear layer is followed by a sigmoid function. This way, we are able to get a score between zero and one. The MS-Marco dataset has query-document pairs (the queries are descriptive, which works in our favour). Each query-document is labelled either 0 (irrelevant) or 1 (relevant). We pass the query, descriptive query and the two-minute segment through the XLNet model, with separator tokens [SEP] between each of them. XLNet Regression returns a score between 0 and 1. To evaluate our model during training, we calculate metrics such as Accuracy, Precision, Recall and F1 score.</p><p>During the inference phase, we obtain the top 1000 episodes from the BM25+RM3 algorithm. From these shortlisted episodes, we create two-minute segments for each episode and index them for future use (if not indexed already). We then re-rank the top 1000 two-minute segments using our trained model and return them as our output.</p><p>We also try out a variant of XLNet Regression, namely, XLNet Regression+Concat. It is a well-known fact that the last layer's hidden state given by the transformer encoder might not be the best representation of the text. In order to improve our results, we take the last two hidden states and pass the concatenated vector to the linear layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">XLNet with Similarity</head><p>In this approach, we compute the contextualised embeddings of the query and the document as follows:</p><formula xml:id="formula_8" coords="4,65.03,569.55,221.33,23.68">query embeddings = XLN et(query) document embeddings = XLN et(document)<label>(7)</label></formula><p>After computing these embeddings for both query and document, we find the cosine similarity matrix between the two.</p><formula xml:id="formula_9" coords="4,131.69,636.21,154.68,9.65">M ij = cos(q i , d j )<label>(8)</label></formula><p>where q i is the i th query token and d j is the j th document token. The shape of the matrix is (length(query), length(document)). The entry M ij corresponds to the similarity score between the i th query token and the j th document token.</p><p>After this, we obtain k matrices using the k RBF kernels. We choose k values of µ, or the mean term, and one value of σ, i.e., the standard deviation term. The purpose of doing is that each kernel focuses on a particular similarity range centred around µ. σ decides the range. This is how the computation proceeds:</p><formula xml:id="formula_10" coords="4,364.04,433.91,181.08,25.28">K k i,j = exp - (M ij -µ k ) 2 2σ 2<label>(9)</label></formula><p>We sum up the matrix above along the document dimension and get a representation for each query and each kernel.</p><formula xml:id="formula_11" coords="4,396.36,499.38,148.75,21.98">K k i = j K k i,j<label>(10)</label></formula><p>Here, we fork the process into two paths: Log Normalisation and Length Normalisation. In Log Normalisation, we apply logarithm with base b to each query term computed above and sum them up.</p><formula xml:id="formula_12" coords="4,383.71,582.78,157.25,21.98">s k log = i log b K k i (<label>11</label></formula><formula xml:id="formula_13" coords="4,540.96,585.17,4.15,8.64">)</formula><p>Length Normalisation is performed as follows:</p><formula xml:id="formula_14" coords="4,395.50,627.45,149.61,28.23">s k len = i K k i d len<label>(12)</label></formula><p>Each kernel has a scalar to represent it. We use a linear layer (without the bias term) to get one common scalar for each of the log terms and the length normalisation terms. The final score is computed as a weighted sum of the above two terms:</p><formula xml:id="formula_15" coords="4,363.94,702.12,181.17,12.85">s log = s k log W 1 s len = s k len W 2<label>(13)</label></formula><formula xml:id="formula_16" coords="5,122.06,176.04,164.30,9.65">s = s log * α + s len * β<label>(14)</label></formula><p>Finally, we restricted the range to [0, 1] using sigmoid activation function.</p><formula xml:id="formula_17" coords="5,126.07,224.30,160.29,8.96">score = sigmoid(s)<label>(15)</label></formula><p>Again, we train the model on the MS-Marco dataset. During training, we freeze a few XLNet encoder layers. We perform inference exactly the same way as we did for XLNet Regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Final Score Computation</head><p>After obtaining the BM25+RM3 score, and the score returned by either XLNet Regression or XLNet with Similarity, we compute the final relevance score as follows:</p><p>Final Score = X + 2 α (σ(BM 25 + RM 3) -0.5) 1 + α (16) where σ represents the sigmoid function, α is a tunable scalar and X is the computed XLNet Score.</p><p>This formula takes the best of both worlds: the short query, which BM25 &amp; RM3 are able to model well, along with the more confusing and verbose query which gets taken care of by XLNet. The purpose of applying sigmoid is that the BM25+RM3 score is not restricted to a range, which will not have both XLNet Score and BM25+RM3 score on an even keel. Since Bm25+RM3 scores are positive, σ(BM 25 + RM 3) will lie in the range [0.5, 1]. To expand it to the range [0, 1], we subtract it by 0.5 and multiply it by 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Hyperparameters</head><p>We use Adam Optimiser for training our model, with a weight decay of 0.01. We experiment with our set of hyperparameters, i.e., the learning rate, the weight decay and the number of layers frozen. To find the optimal set of hyperparameters, we perform a Grid Search on the hyperparameter space. We then zero down on a learning rate of 1e -5 . We try out two losses-Cross Entropy (CE) and Hinge Loss (HL). Cross Entropy Loss gives better results than Hinge Loss. We attempt to leverage information from not just the last layer of XLNet, but the previous two layers, by concatenating their embeddings.</p><p>Due to computational constraints, we went ahead with XLNet Base. We evaluate the results using two approaches: 1) we freeze all the layers of XLNet (Frozen XLNet), 2) We keep seven layers of XLNet unfrozen (Unfrozen XLNet). Unfrozen XLNet Base gives us better results. We train our models for 5 epochs with early stopping with a patience of 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>The results of our methods are summarized in Table <ref type="table" coords="5,539.24,264.95,3.81,8.64" target="#tab_0">1</ref>. Note that even though the performance of XLNet with Similarity is slightly lesser than XLNet Regression, it more than makes up for it with an increase in the speed of computation. Additionally, the XLNet Regression+Concat brings about an increase in the precision values and nDCG@20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we demonstrate the ability of XLNet to perform the document retrieval task using two different approaches. XLNet outperforms BERT on most tasks, which is one of the reasons we went ahead with XLNet. In the future, we would like to evaluate the large variant of XLNet (which has 24 layers instead of 12) and a Longformers-based approach. We look forward to the next iteration of this competition, which might have variablelength segments to be retrieved instead of just 2-minute segments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,330.84,234.39,192.29,7.77;2,308.86,72.00,297.01,156.28"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Shortlisting podcasts using BM25 and RM3</figDesc><graphic coords="2,308.86,72.00,297.01,156.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,141.32,278.62,312.60,7.77;3,50.11,72.00,495.00,200.51"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Splitting podcasts into two minute segments and reranking them with XLNet.</figDesc><graphic coords="3,50.11,72.00,495.00,200.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,100.14,326.38,394.94,7.77;4,50.11,72.00,494.99,248.27"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Creating contextualised Query-Document pairs and using them for scoring podcasts with regression.</figDesc><graphic coords="4,50.11,72.00,494.99,248.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,121.44,74.28,352.35,56.58"><head>Table 1 .</head><label>1</label><figDesc>Results for the three models that were tested.</figDesc><table coords="5,121.44,74.28,352.35,45.70"><row><cell>Model</cell><cell>P@10</cell><cell>P@20</cell><cell cols="2">nDCG@20 nDCG@100 nDCG</cell></row><row><cell>XLNet Regression</cell><cell cols="3">0.4708 0.4438 0.3827</cell><cell>0.4501</cell><cell>0.5414</cell></row><row><cell cols="4">XLNet Regression + Concat 0.4771 0.4542 0.3838</cell><cell>0.4477</cell><cell>0.5386</cell></row><row><cell>XLNet With Similarity</cell><cell cols="3">0.4083 0.3667 0.3083</cell><cell>0.3828</cell><cell>0.5006</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,330.44,523.81,215.92,8.64;5,330.44,535.77,215.92,8.64;5,330.44,547.72,216.32,8.64;5,330.44,559.51,214.67,8.81;5,330.19,571.47,216.58,8.58;5,330.44,583.42,112.07,8.81" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,461.32,547.72,85.45,8.64;5,330.44,559.68,121.11,8.64">000 Podcasts: A Spoken English Document Corpus</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rezapour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bonab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eskevich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,470.49,559.51,74.62,8.58;5,330.19,571.47,216.58,8.58;5,330.44,583.42,73.52,8.58">Proceedings of the 28th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 28th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">100</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.44,599.99,214.67,8.64;5,330.44,611.94,214.67,8.64;5,330.44,623.90,139.98,8.64" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,489.09,599.99,56.02,8.64;5,330.44,611.94,214.67,8.64;5,330.44,623.90,23.94,8.64">Convolutional neural networks for soft-matching n-grams in ad-hoc search</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">02 2018. 2</date>
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.44,640.30,216.32,8.64;5,330.44,652.08,215.92,8.81;5,330.44,664.21,99.34,8.64" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,499.80,640.30,46.97,8.64;5,330.44,652.25,179.30,8.64">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno>CoRR, abs/1711.08611</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,330.44,680.60,214.67,8.64;5,329.52,692.56,215.59,8.64;5,330.44,704.35,189.80,8.81" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,510.27,680.60,34.84,8.64;5,329.52,692.56,215.59,8.64;5,330.44,704.51,54.09,8.64">TU wien @ TREC deep learning &apos;19 -simple contextualization for re-ranking</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zlabinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<idno>CoRR, abs/1912.01385</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.69,75.48,214.67,8.64;6,71.69,87.43,214.67,8.64;6,71.69,99.22,214.67,8.81;6,71.69,111.17,214.67,8.58;6,71.36,123.13,135.00,8.81" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,112.50,87.43,173.86,8.64;6,71.69,99.39,149.52,8.64">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,228.12,99.22,58.25,8.58;6,71.69,111.17,214.67,8.58;6,71.36,123.13,96.59,8.58">Proceedings of the 22nd ACM international conference on Information Knowledge Management</title>
		<meeting>the 22nd ACM international conference on Information Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.69,138.24,216.32,8.64;6,71.69,150.03,214.67,8.81;6,71.52,161.98,214.84,8.58;6,71.33,173.94,215.03,8.81;6,70.94,186.06,215.58,8.64;6,71.69,198.02,120.83,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,200.68,138.24,87.34,8.64;6,71.69,150.20,55.56,8.64">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,152.47,150.03,133.89,8.58;6,71.52,161.98,214.84,8.58;6,71.33,173.94,190.67,8.81">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;01</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.69,212.96,214.92,8.64;6,71.69,224.75,204.52,8.81" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,100.16,212.96,186.46,8.64;6,71.69,224.92,35.11,8.64">The neural hype and comparisons against weak baselines</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,114.29,224.75,51.19,8.58">SIGIR Forum</title>
		<imprint>
			<date type="published" when="2003">Jan. 2019. 3</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.69,239.86,214.84,8.64;6,71.69,251.82,216.33,8.64;6,71.69,263.60,214.67,8.81;6,71.52,275.56,216.33,8.81;6,70.94,287.68,55.89,8.64" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,146.42,239.86,140.11,8.64;6,71.69,251.82,216.33,8.64;6,71.69,263.77,17.31,8.64">A comparative study of methods for estimating query language models with pseudo feedback</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,107.83,263.60,178.53,8.58;6,71.52,275.56,159.41,8.58">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1895" to="1898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.69,302.63,215.92,8.64;6,71.69,314.58,214.67,8.64;6,71.69,326.54,214.67,8.64;6,71.36,338.32,91.90,8.81" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,188.51,314.58,97.85,8.64;6,71.69,326.54,199.03,8.64">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,71.36,338.32,53.73,8.58">CoCo@ NIPS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.44,75.48,214.67,8.64;6,330.44,87.43,130.31,8.64" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,372.89,75.48,172.22,8.64;6,330.44,87.43,79.38,8.64">Using TF-IDF to determine word relevance in document queries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ramos</surname></persName>
		</author>
		<idno>. 01 2003. 2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.44,104.17,216.33,8.64;6,330.44,116.12,214.67,8.64;6,330.44,128.08,68.34,8.64" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="6,442.61,116.12,102.50,8.64;6,330.44,128.08,24.91,8.64">Okapi at TREC-3. pages 0-, 01</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.44,144.82,215.02,8.64;6,330.44,156.77,216.33,8.64;6,330.44,168.56,216.32,8.81;6,330.44,180.51,214.67,8.58;6,330.27,192.47,216.33,8.81;6,329.69,204.59,63.36,8.64" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,538.13,144.82,7.34,8.64;6,330.44,156.77,216.33,8.64;6,330.44,168.73,115.53,8.64">A latent semantic model with convolutional-pooling structure for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,453.27,168.56,93.49,8.58;6,330.44,180.51,214.67,8.58;6,330.27,192.47,163.86,8.58">CIKM 2014 -Proceedings of the 2014 ACM International Conference on Information and Knowledge Management</title>
		<imprint>
			<date type="published" when="2002">11 2014. 2</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.44,221.33,216.42,8.64;6,330.44,233.29,216.42,8.64;6,330.11,245.07,128.12,8.81" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="6,330.44,233.29,212.32,8.64">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
		<idno>CoRR, abs/1706.06613</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.44,261.98,216.33,8.64;6,330.44,273.76,215.92,8.81;6,330.44,285.89,99.34,8.64" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="6,480.61,261.98,66.15,8.64;6,330.44,273.93,181.17,8.64">Simple applications of BERT for ad hoc document retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno>CoRR, abs/1903.10972</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,330.44,302.63,216.32,8.64;6,330.44,314.58,216.32,8.64;6,330.44,326.37,215.92,8.81;6,330.44,338.49,119.26,8.64" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="6,415.43,314.58,131.33,8.64;6,330.44,326.54,178.41,8.64">XLNet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906">1906.08237, 2019. 1, 2, 3</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
