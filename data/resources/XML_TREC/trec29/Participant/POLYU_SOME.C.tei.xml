<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.92,80.31,416.37,19.63;1,66.85,100.24,478.76,19.63">POLYU at TREC 2020 Conversational Assistant Track: Query Reformulation with Heuristic Topic Phrases Discovery</title>
				<funder ref="#_pF7jzhm">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_yrsAfsn">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_5saGAVP">
					<orgName type="full">Research Grants Council of Hong Kong</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,112.59,131.50,59.51,13.63"><forename type="first">Kaishuai</forename><surname>Xu</surname></persName>
							<email>xu.kaishuai@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong Polytechnic University Hong Kong</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.91,131.50,46.60,13.63"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Hong Kong Polytechnic University Hong Kong</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,448.75,131.50,43.43,13.63"><forename type="first">Yongli</forename><surname>Li</surname></persName>
							<email>liyongqi0@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University Hong Kong</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.92,80.31,416.37,19.63;1,66.85,100.24,478.76,19.63">POLYU at TREC 2020 Conversational Assistant Track: Query Reformulation with Heuristic Topic Phrases Discovery</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">18AF7DE87379CB36B98B12C1C7C48866</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>conversational search</term>
					<term>query reformulation</term>
					<term>information retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper demonstrates a 2-stage conversational search architecture for the Conversational Assistant Track in TREC 2020, including the initial rule-based retrieval and BERT-based re-ranking. We propose a straightforward query reformulation method with topic phrases discovery and inheritance. The method can efficiently extract the key phrase as a topic and inherit phrases based on specific rules. Experimental results show that our method performs as well as top-2 teams in CAsT 2019 evaluation datasets (NDCG@3: 0.433) with a simpler query expansion and smaller BERT model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Conversational Information Seeking (CIS) or Conversational Search (CS) has received burgeoning attention in information retrieval and natural language processing researches. To create a reusable benchmark for open-domain CIS systems, TREC organizes the Conversational Assistance Track (CAsT) based on several decades of multiple turns of dialogues and definitive collection. The primary aim of this year is to find relevant passages using contextual information.</p><p>Our work concentrates on solving correlation and omission problems in a straightforward and low-computing method without training on deep learning models. We construct a pipeline architecture, including the initial retrieval and the BERT-based re-ranking. In the first step, we develop a heuristic query expansion algorithm to reformulate the queries with topic phrases discovery and inheritance based on BM25 scores. The ranking model in this step is also BM25. In the second step, a simple BERT-based classifier is trained Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. TREC '20, November 18-20, 2020, Gaithersburg, Maryland USA © 2020 Association for Computing Machinery. ACM ISBN XXX-X-XXXX-XXXX-X/XX/XX…$15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn on another dataset for transfer learning. The detailed methodology is described in Section 2, followed by the experiments (Section 3) and results (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head><p>Following previous reports and recent advances <ref type="bibr" coords="1,496.03,261.53,9.40,10.22" target="#b1">[2]</ref>, we construct the 2-stage retrieval pipeline. In the initial retrieval, we use BM25 to retrieve top-1000 relevant passages for each query and record the corresponding scores. In the re-ranking, a BERT-based classifier is built on pairs of the query and passage to obtain the classification value as a relevance score. Finally, we sum up scores from two stages with equal weight and get the passages' new ranking list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Initial retrieval</head><p>The initial retrieval is based on a probabilistic retrieval model BM25. For the application of such models, the preprocessing procedures such as stop word removal and query reformulation are crucial to increasing the recall rate. The relevance is calculated through the word occurrence probability in documents and word frequency, so it is required to eliminate the irrelevant words and make the query self-contained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Stop word removal.</head><p>The stop words in our work are selected in two ways: 1. Most words are summarized by <ref type="bibr" coords="1,498.59,471.75,10.55,10.22" target="#b0">[1]</ref> according to its experiment; 2. The others are chosen with relatively low BM25 scores. We supplement another 17 words into the stop words list and get a total of 95 stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Query expansion.</head><p>Inspired by the history query expansion in <ref type="bibr" coords="1,326.99,534.77,9.40,10.22" target="#b3">[4]</ref>, we develop a heuristic algorithm for topic phrases discovery and inheritance, simpler and easier to use. The proposed method's core idea is similar to <ref type="bibr" coords="1,395.52,556.69,9.40,10.22" target="#b3">[4]</ref>. However, instead of distinguishing query keywords from session ones, we exclusively obtain or inherit one key phrase as a topic phrase from the current query or last key phrase. The two reasons for this revision are that BM25 scores alone cannot tell from different types of keywords, and topic words generally appear in phrases. Our method focuses on finding phrases and selecting the key phrase in a heuristic way. Based on observations on the datasets, we assume that the current query is only related to the previous query. Accordingly, if there are coreference, omission, or no key phrase in the current query, the method will inherit the last key phrase and supplement the current query with the preceding query phrases. The exact method is as follows.</p><p>The method input is a set of passages d i ∈ D, and a topic T with N conversational queries,T = {Q i } N i=1 . Algorithm 1 describes the details of topic phrases discovery and inheritance. The function FindPhrase is a constituency parsing algorithm that extracts phrases from a query. F (•) calculates the BM25 scores between phrases and passages. Ind(•) is a rule-based query independence judge. We judge the existence of the coreference or omission in queries based on three rules: 1. Phrases like "what about", "how about" are in a query; 2. Determiners are in a query, although the coreference resolution has been carried out; 3. The superlative words appear in the form of "the best". len(•) computes the number of tokens in a phrase. λ is the threshold controlling whether the phrase is specific enough to be considered the topic. W K P is the key phrase list.</p><p>Algorithm 1: Topic Phrases Discovery and Inheritance</p><formula xml:id="formula_0" coords="2,63.76,246.74,208.32,196.86">Data: T = {Q i } N i=1 , D Result: T begin W K P ←-∅ for i = 1 to N do is_KP = 0 P i = FindPhrase(Q i ) = {p i k } n(i) k =1 for j = 1 to n(i) do S i j = max d t ∈D F (d t , p i j ) if S i j l en(p i j ) &gt; λ then is_KP = 1 W K P ←-W K P + {p i j } if is_KP = 0 or Ind(Q i ) = 0 and i &gt; 1 then Q i ←-Q i + p i k for all p i-1 k ∈ P i-1 ∧ S i-1 k &gt; λ return T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Re-ranking</head><p>We construct a BERT-based classifier with the same architecture in <ref type="bibr" coords="2,63.11,498.15,9.40,10.22" target="#b2">[3]</ref>. The [CLS] vector is extracted and put into a fully connected layer to classify the relevance. The classifier is trained on other open-domain question answering datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL SETUP</head><p>The proposed pipeline is carried out in two stages. The first stage is the initial retrieval using the BM25 algorithm. According to previous reports, we choose the parameter range and obtain the best parameters (k = 1.2, β = 0.25) through further experiments. In preprocessing, coreference resolution and constituency parsing are both implemented using the AllenNLP toolkit 1 . All phrases and queries are tokenized through the spaCy toolkit 2 . We retrieve 1000 passages at the first stage.</p><p>In the second stage, we build a classifier based on the BERTbase model using the Keras-bert package. The model is trained on MS MARCO Question Answering datasets. Most parameters are initial default values, but the maximum token number of BERT is 1 https://allennlp.org/ 2 https://spacy.io/ set 192 according to all samples' length. The queries without the expansion and initial-retrieved passages are put into the model to get the relevance scores. The final ranking is concluded from the weighted sum of initial retrieval scores and classifier scores. We set equal weight for two stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND DISCUSSION</head><p>The result is represented in Table <ref type="table" coords="2,441.56,299.57,3.07,10.22" target="#tab_0">1</ref>. Since some bugs are not modified before submission, the CAsT 2020 evaluation results are not the proposed method's best performance. The main issue is that we mistakenly set the number of tokens in the BERT input to 15. After correction to 192, our method has proved effective compared to the last year's best results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,328.56,83.34,219.03,120.71"><head>Table 1 : Results on the CAsT evaluation</head><label>1</label><figDesc></figDesc><table coords="2,328.56,109.49,219.03,81.54"><row><cell>Models</cell><cell cols="2">Datasets Type</cell><cell>NDCG@3</cell></row><row><cell cols="2">Our method (defective) * 2019</cell><cell cols="2">automatic 0.324</cell></row><row><cell>Our method</cell><cell></cell><cell></cell><cell>0.433</cell></row><row><cell>h2oloo_RUN2</cell><cell></cell><cell></cell><cell>0.434</cell></row><row><cell>CFDA_CLIP_RUN7</cell><cell></cell><cell></cell><cell>0.436</cell></row><row><cell cols="2">Our method (defective) 2020</cell><cell cols="2">automatic 0.265</cell></row><row><cell></cell><cell></cell><cell>manual</cell><cell>0.398</cell></row></table><note coords="2,330.75,194.80,174.69,9.25"><p>* the input number of tokens in BERT is mistakenly set to 15</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The work described in this paper is supported by <rs type="funder">Research Grants Council of Hong Kong</rs> (<rs type="grantNumber">5210919</rs>), <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">62076212</rs>) and <rs type="grantName">PolyU Internal Grant</rs> (ZVRH, <rs type="grantNumber">ZG7H</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5saGAVP">
					<idno type="grant-number">5210919</idno>
				</org>
				<org type="funding" xml:id="_pF7jzhm">
					<idno type="grant-number">62076212</idno>
					<orgName type="grant-name">PolyU Internal Grant</orgName>
				</org>
				<org type="funding" xml:id="_yrsAfsn">
					<idno type="grant-number">ZG7H</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="2,330.15,444.81,229.23,7.95;2,330.15,452.78,64.84,7.95" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="2,404.90,444.81,154.48,7.95;2,330.15,452.78,35.37,7.95">WaterlooClarke at the TREC 2019 Conversational Assistant Track</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct coords="2,330.15,460.75,229.23,7.95;2,330.04,468.72,229.34,7.95;2,330.15,476.69,225.19,7.95" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02230</idno>
		<title level="m" coord="2,416.80,468.72,142.58,7.95;2,330.15,476.69,111.43,7.95">Query Reformulation using Query History for Passage Retrieval in Conversational Search</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="2,330.15,484.66,229.13,7.95;2,330.15,492.63,108.32,7.95" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="2,467.67,484.66,88.14,7.95">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="2,330.15,500.60,228.05,7.95;2,329.94,508.57,224.28,7.95" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="2,361.85,508.57,163.02,7.95">Query and Answer Expansion from Conversation History</title>
		<author>
			<persName coords=""><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,537.06,508.57,13.73,7.95">TREC</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
