<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,131.57,84.23,348.87,15.44;1,53.80,447.48,241.37,8.91;1,53.55,458.60,241.99,8.74;1,53.80,469.39,98.39,8.77">CSIROmed at TREC Precision Medicine 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,215.83,110.08,84.51,11.50"><forename type="first">Maciej</forename><surname>Rybinski</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>CSIRO Data61 Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.94,110.08,83.23,11.50"><forename type="first">Sarvnaz</forename><surname>Karimi</surname></persName>
							<affiliation key="aff0">
								<address>
									<settlement>CSIRO Data61 Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,131.57,84.23,348.87,15.44;1,53.80,447.48,241.37,8.91;1,53.55,458.60,241.99,8.74;1,53.80,469.39,98.39,8.77">CSIROmed at TREC Precision Medicine 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C8B1A599AE589FBE8625553A316F3B51</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Precision medicine</term>
					<term>Search</term>
					<term>Medical information retrieval</term>
					<term>Learning-to-rank</term>
					<term>Evidence-based medicine</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>TREC Precision Medicine (PM) focuses on providing highquality evidence from the biomedical literature for clinicians treating cancer patients. Our experiments focus on incorporating treatment into search. We established a promising baseline using PM 2017-2018 datasets for training and 2019 for validation. Our baseline consisted of a base-ranking step using Divergence From Randomness (DFR) scoring that used disease and gene as queries and an aggregated text field to represent documents, followed by a BERT-based neural reranker. We examined two mechanisms for incorporating the treatment within the query formulation strategy for DFR: (1) a concatenation of disease, gene and treatment fields; and (2) a concatenation of disease and gene fields, but filtering out the documents where treatment terms were absent. We experimented with both strategies in combination with re-rankers trained either directly on TREC PM 2017-2019 retrieval task, or trained on a treatment-augmented version of these tasks.</p><p>We obtained the best results using boolean retrieval for treatment terms with a re-ranker trained on non-augmented TREC PM datasets. Our top-ranking run achieved 0.530, 0.565, 0.436 for infNDCG, P@10, RPrec, respectively. TREC median for these metrics were 0.432, 0.465, and 0.326.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>TREC Precision Medicine (PM) focuses on providing highquality evidence from the biomedical literature for clinicians treating cancer patients. In 2020, TREC PM aimed at search that provides evidence on pros and cons of a given treatment for a cancer patient from the published literature <ref type="bibr" coords="1,546.91,223.36,9.65,8.63" target="#b3">[4]</ref>. That is, it simulated a scenario where an oncologist seeks for information on a treatment, given a type of cancer and genetic mutation <ref type="bibr" coords="1,383.88,256.24,12.34,8.63">(s)</ref>. We participated in the TREC PM as CSIROmed team, experimenting with neural ranking for precision medicine. We experimented with a two-step information retrieval framework, consisting of initial ranking step and a re-ranking step. For the initial ranking we use an established, strong, word-matching baseline-Divergence from Randomness (DFR) <ref type="bibr" coords="1,397.79,321.99,13.75,8.63" target="#b0">[1]</ref>-using information content modeled with inverse document frequency. The initial ranking step is followed by a re-scoring of top 100 results using a neural re-ranker, obtained through fine-tuning a BioBERT model on historical TREC PM datasets (2017-2018) <ref type="bibr" coords="1,481.91,365.83,9.71,8.63" target="#b2">[3,</ref><ref type="bibr" coords="1,494.23,365.83,6.47,8.63" target="#b4">5]</ref>.</p><p>We analyse several approaches for incorporating the treatment aspect-new in TREC Precision Medicine 2020 shared task-in the search system pipeline. We evaluate two simple ways of incorporating the treatment aspect within the initial ranking step (adding the treatment term to a disjunctive query versus boolean filtering of the results based on presence of the treatment term) in combination with two different flavours of the re-ranker. We consider re-ranking using:</p><p>(1) direct fine tuning on historical TREC PM data; and, (2) using a treatment-augmented dataset obtained from the original TREC PM data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DATASETS</head><p>Search systems were evaluated with a collection of 31 topics, each with disease, gene and treatment fields e.g., (Disease: colorectal cancer, Gene: ABL1, Treatment: Regorafenib). Each topic represents a patient profile. The corpus used for search is a 2019 PubMed snapshot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>Overview of the search pipeline. As already mentioned, we present the experiments within a 2-step search framework (ranking/re-ranking), consisting of: (1) an initial retrieval step using DFR, and (2) neural re-ranking with BioBERT for the top 100 documents of the initial ranking.</p><p>Queries are formulated from the topics independently at each of the two steps.</p><p>Indexing and initial retrieval step with DFR. We index the Medline 2019 snapshot using the following fields: PMID (Pub-MedID), title, abstract, author-given keywords, MeSH descriptors, MeSH qualifiers. An inverted index representation is also created for an aggregated text field.</p><p>For the initial retrieval step we use a DFR model with information content modeled with inverse document frequency with Laplacian after-effect and H2 normalisation.</p><p>We evaluate two query formulation strategies: (DIS) a simple disjoint query, formulated with disease, gene and treatment topic fields; and (FIL) a disjoint query over disease and gene terms with a Boolean filter for presence of the treatment term(s).</p><p>Neural re-ranking with BioBERT. We produce a the (neural) re-ranking relevance score using an output of a fine-tuned BioBERT with binary linear layer connected to the encoder's pooled layer with dropout. BioBERT is a domain-adapted BERT variant with additional pre-training on an earlier snapshot of the PM abstract corpus <ref type="bibr" coords="2,180.73,290.29,9.63,8.63" target="#b1">[2]</ref>. The re-ranking model is fine-tuned using cross-entropy loss and pointwise re-ranking approach, so we essentially train a binary classifier on binarised human judgments from 2017-2019 TREC PM datasets. For inference (for search) we use a softmax over the classifier output as BERT-based relevance score.</p><p>Training on human judgment means that a training instance is a topic (query) and document pair. We use a queries formulated as concatenations of specific topic fields, (e.g., disease and gene) as BERT's 'Sentence A' input and document representation (title and abstract) as 'Sentence B' input.</p><p>Treatment Augmentation. We experiment with 'treatmentaugmentation' of the 2017-2018 TREC PM training data to increase the value of the historical data in fine-tuning the BioBERT re-ranker for the TREC 2020 task (so, covering the 'new' treatment aspect).</p><p>For this purpose we use a list of drug names from Drug-Bank and cross-reference it with MeSH terms and keywords of articles from the human judgment data from the past tracks.</p><p>To create treatment-augmented judgment dataset we iterate through the (PMID, topic number, relevance score) triples. For each triple we check, if any of the keyword/MeSH terms of the document corresponding to a given PMID appears in the DrugBank name list. For each keyword (i.e., treatment) that does, we add a 'treatment-augmented' quad to the augmented dataset. Each quad of this augmented dataset has PMID, topic number, relevance score and treatment (all but the treatment 'inherited' from the original triple).</p><p>After the initial augmented dataset is compiled, for each positive quad added, we add a negative quad with randomly sampled treatment expression. This is to ensure that the model can learn the difference between a hit and a miss on the treatment aspect.</p><p>We use the augmented dataset as if the treatment expressions of each of the quads pertained to the respective topics. The specifics of query formulation for re-ranking are presented below.</p><p>Query formulation for re-ranking. We evaluate two variants of fine-tuning, each of them used differently at re-ranking stage as well. The first variant is fine-tuned directly on the nonaugmented human judgments of the 2017-2019 PM datasets. In this variant (hereafter referred to as 'non-augmented') the query (so, the 'Sentence A' input) is formulated as a spaceseparated concatenation of disease and gene topic fields, both for tuning and actual re-ranking.</p><p>In the variant using treatment-augmented data (referred to as 'augmented'). The 'Sentence A' inputs are formulated as: 'disease: D, gene: G, treatment: T', where D and G are disease and gene topic fields respectively. T denotes the treatment added to training quads in the augmentation process (in training), or the treatment topic field (for re-ranking).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In our runs submitted for evaluation in TREC we experiment with different combinations of DIS/FIL (initial retrieval) and augmented/non-augmented re-ranking. We submitted DIS-augmented, DIS-non-augmented, FIL-augmented and FIL-non-augmented runs, as well as a FIL-baseline (with no reranking). Here, we also include results of a DIS-baseline (no reranking).</p><p>FIL runs in our TREC submission had tail documents appended from corresponding DIS runs to avoid returning less than 1000 documents per topic. It means that for each topic we appended documents non-present in the original FILbaseline ranking in the order they appeared in DIS-baseline, until the 1000 document limit was reached. The same procedure was performed for FIL-augmented/DIS-augmented and FIL-non-augmented/DIS-non-augmented respectively. Our post TREC experiments revealed that the merging procedure had minimal impact on the effectiveness of the FIL runs.</p><p>We report search effectiveness metrics as reported by TREC organisers: P@10, infNDCG and RPrec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS AND DISCUSSION</head><p>We obtained the best results using boolean retrieval for treatment terms with a re-ranker trained on non-augmented TREC PM datasets (FIL-non-augmented). Our best run achieved 0.530, 0.565, 0.436 for infNDCG, P@10, RPrec, respectively. TREC median for these metrics were 0.432, 0.465, and 0.326.</p><p>In the official evaluation of TREC Precision Medicine 2020 FIL-non-augmented was the best performing run in R-prec and P@10, and second best in infNDCG. The results for all runs are presented in Table <ref type="table" coords="2,429.28,602.62,3.36,8.63" target="#tab_0">1</ref>.</p><p>Although the augmented runs have not led to improvements over the baseline, the comparison between DIS-augmented and DIS-non-augmented suggests that supervised training on augmented data results in a re-ranking model adapted to the new search aspect. FIL-augmented outperforms FILnon-augmented, because the treatment aspect is incorporated restrictively in the initial retrieval step and FIL-augmented does better in covering the remaining two aspects (disease and gene).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>TREC run infNDCG R-prec P@10 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>The main theme of our submission to the TREC PM 2020 track was to experiment with neural re-ranking focusing on task adaptation for this year's problem, which includes a new search aspect (treatment) as compared to previous years. We obtain the best results including the treatment aspect through Boolean filtering and following the initial retrieval step with a neural re-ranker trained directly on the past TREC PM relevance judgments. This led our team achieve the top ranking run among all teams for R-Prec and P@10. We also propose a treatment-augmentation approach, in which we reformulate the training data to resemble the new task (using external resources). Although we achieve best results with a non-augmented model, the augmentation procedure shows enough promise in aspect-adaptation to make it a suitable avenue for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,53.42,103.98,504.95,119.42"><head>Table 1 : Results of our runs and comparison with TREC median (over 66 runs, 16 teams). DIS: disjoint query formulated with disease, gene and treatment topic fields. FIL: disjoint query over disease and gene terms with a Boolean filter for presence of the treatment term(s).</head><label>1</label><figDesc></figDesc><table coords="3,171.14,103.98,269.23,83.41"><row><cell>DIS-baseline</cell><cell>-</cell><cell>0.502</cell><cell>0.380</cell><cell>0.523</cell></row><row><cell>DIS-augmented</cell><cell>rRRa</cell><cell>0.493</cell><cell>0.373</cell><cell>0.532</cell></row><row><cell>DIS-non-augmented</cell><cell>rlxRR</cell><cell>0.475</cell><cell>0.378</cell><cell>0.484</cell></row><row><cell>FIL-baseline</cell><cell>strDFR</cell><cell>0.513</cell><cell>0.412</cell><cell>0.526</cell></row><row><cell>FIL-augmented</cell><cell>sRRa</cell><cell>0.527</cell><cell>0.412</cell><cell>0.529</cell></row><row><cell>FIL-non-augmented</cell><cell>strRR</cell><cell>0.530</cell><cell>0.436</cell><cell>0.565</cell></row><row><cell>TREC Median</cell><cell></cell><cell>0.432</cell><cell>0.465</cell><cell>0.326</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,330.07,310.22,228.13,6.71;3,330.07,318.14,229.00,6.80;3,330.07,326.25,60.72,6.71" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,445.07,310.22,113.13,6.71;3,330.07,318.23,202.24,6.71">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,541.22,318.14,14.29,6.65">TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.07,334.22,228.40,6.71;3,329.86,342.24,228.33,6.71;3,330.07,350.16,148.42,6.80" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,522.68,334.22,35.79,6.71;3,329.86,342.24,228.33,6.71;3,330.07,350.25,20.53,6.71">BioBERT: A pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,356.82,350.16,40.08,6.65">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2019-09">09 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.07,358.27,229.00,6.71;3,329.80,366.24,229.62,6.71;3,330.07,374.12,106.10,6.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,397.17,366.24,159.43,6.71">Overview of the TREC 2017 Precision Medicine track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,338.51,374.12,15.65,6.65">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.07,382.22,229.35,6.71;3,330.07,390.10,229.00,6.80;3,330.07,398.16,15.69,6.71" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,354.36,390.19,169.56,6.71">Overview of the TREC 2020 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,539.11,390.10,15.97,6.65">TREC</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.07,406.13,229.00,6.71;3,330.07,414.10,228.13,6.71;3,329.65,421.98,97.66,6.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,380.61,414.10,165.21,6.71">Overview of the TREC 2018 Precision Medicine Track</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Lazar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,329.65,421.98,15.65,6.65">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
