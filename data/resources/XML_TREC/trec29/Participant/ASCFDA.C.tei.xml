<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,67.53,84.23,477.30,15.44;1,235.44,104.15,141.11,15.44">Query Expansion with Semantic-Based Ellipsis Reduction for Conversational IR</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,87.75,141.83,86.08,10.60"><forename type="first">Chia-Yuan</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.61,141.83,81.68,10.60"><forename type="first">Hsien-Hao</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.08,141.83,53.02,10.60"><forename type="first">Ning</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.89,141.83,83.59,10.60"><forename type="first">Wei-Ting</forename><surname>Chiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,447.27,141.83,68.49,10.60"><forename type="first">Chih-Hen</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.00,156.16,80.48,10.60"><forename type="first">Yu-Hsuan</forename><surname>Tseng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.95,170.11,76.27,10.60"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.42,170.11,78.25,10.60"><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Information Technology Innovation</orgName>
								<address>
									<country>Academia Sinica</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,67.53,84.23,477.30,15.44;1,235.44,104.15,141.11,15.44">Query Expansion with Semantic-Based Ellipsis Reduction for Conversational IR</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FF62BED72B240878B9F4AAC8194F3A82</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Word choice mismatch between query and documents is a common problem in QA/dialogue subjects such as the TREC Conversational Assistance Track (CAsT) 2020. We account for this kind of mismatch by expanding queries using semantic-based ellipsis reduction (SER), which involves gathering supplemental information from historical queries and potentially relevant documents.</p><p>We formulate information retrieval as (1) retrieving potential information and (2) reranking its priority. To explain the importance of query expansion and verify our method's effectiveness, we conduct experiments with diverse settings in the retrieval part, followed by a Transformer model for reranking. We also resolve coreferences by replacing pronouns with their coreferential antecedents using a Transformer-based model.</p><p>This work shows the importance of accounting for differences in wording and the potential of semantic-based approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Vocabulary mismatch is a common and inevitable phenomenon in conversational IR, given that many concepts can be expressed using more than one kind of word or description. Also, conversations contain many pronouns; although such coreferences make for more succinct language, they complicate comprehension with their resultant ambiguities, as demonstrated in Table <ref type="table" coords="1,228.34,548.78,3.06,7.95" target="#tab_0">1</ref>. Moreover, omitting repeated subjects-that is, ellipsis-can result in profoundly wrong misinterpretations. Note that the TREC CAsT 2020 query turns also include elliptical queries. For instance, in the 83-3 query (see Table <ref type="table" coords="1,92.16,592.61,2.96,7.95" target="#tab_0">1</ref>), the subject bees is omitted in the utterance, as is the corresponding pronoun.</p><p>We attempt to account for such mismatch by using techniques for relevance feedback; specifically, we reconcile word differences between queries and passages by expanding each query with keywords from retrieved passages. However, since Transformer-based models provide a better way to consider each word's co-occurrences, and since they use attention <ref type="bibr" coords="1,157.77,669.33,10.48,7.95" target="#b0">[1]</ref>   <ref type="bibr" coords="1,406.69,368.28,10.43,7.95" target="#b1">[2]</ref> to determine the correct pronoun reference given the current context and historical conversations. We also borrow from another Transformer-based model to add auxiliary information from historical queries and topic sentences in passages to resolve ellipses. Figure <ref type="figure" coords="1,354.07,423.07,4.25,7.95" target="#fig_0">1</ref> shows the proposed pipeline: we first use a T5-based coreference query reformation (T5-CQR) model to resolve coreferences in queries. Using the resultant queries in which the pronouns have been replaced, we expand the query via RM3, the proposed semantic-based ellipsis reduction (SER) method, and a T5-based QA method. Last, in the reranking part, we train a T5 reranker based on the BERT reranker <ref type="bibr" coords="1,420.75,488.83,10.43,7.95" target="#b2">[3]</ref> to rerank the retrieved passages by relevance.</p><p>In summary, our contributions are as follows.</p><p>• We use a semantic-aware Transformer-based model to expand queries to account for word mismatches between queries and documents. • To efficiently resolve coreferences, we propose the T5-CQR model, a Transformer-based sequence-to-sequence model fine-tuned on the CANARD dataset <ref type="bibr" coords="1,468.41,578.34,10.43,7.95" target="#b3">[4]</ref> for question-in-context rewriting. • We propose semantic-based ellipsis reduction, a novel way to resolve ellipses by considering historical queries and related topic sentences at the semantic level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY 2.1 Coreference Query Reformation (CQR)</head><p>A simple way to approach the coreference problem is to rewrite sentences with their coreferential antecedent, as a type of sequenceto-sequence problem. Therefore, we adopt a Transformer-based </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic-Based Ellipsis Reduction (SER)</head><p>To tackle the ellipsis problem at the semantic level, we propose semantic-based ellipsis reduction (SER), which supplements the original query with the historical queries and the related topic sentences in documents that are semantically associated with the original query.</p><p>In the first part, as shown in Figure <ref type="figure" coords="2,196.49,442.39,3.11,7.95" target="#fig_1">2</ref>, we calculate the similarity between the original query and the other queries in the same conversation, and extend the original query using the historical query with the highest similarity; this is referred to as the expanded query.</p><p>Second, to acquire more query-related semantic information from the passages, we extract a topic sentence from potentially related passages. We separate each retrieved passage into sentences and apply the doc2query model <ref type="bibr" coords="2,173.22,530.06,10.65,7.95" target="#b4">[5]</ref> to each sentence to obtain its underlying "latent query". We then calculate the similarity between </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Retrieval</head><p>Okapi BM25, a modified version of TF-IDF, has been used for decades. Given its efficiency and competitiveness with most language models, we use it as the primary retrieval method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Reranking</head><p>We follow the BERT reranker <ref type="bibr" coords="2,433.15,464.46,10.68,7.95" target="#b2">[3]</ref> settings by concatenating the query and each document with a [SEP] tag as the model input, ranking all the pairs with the corresponding score. However, to make full use of the encoder-decoder structure, we adopt T5 instead of the BERT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS 3.1 Evaluation and Settings</head><p>To compare our models with different query expansion methods and hyperparameters, we evaluated model performance on the TREC CAsT 2019 evaluation topics in terms of recall (𝑅@1000 and 𝑅@2000) and mean average precision (mAP). We used BM25 as the retrieval method, and the T5-3B model <ref type="bibr" coords="2,460.64,602.85,10.50,7.95" target="#b5">[6]</ref> as the reranking model, which we fine-tuned only on the MS MARCO dataset but not TREC CAR, since the MS MARCO queries are more similar to the queries in TREC CAsT than TREC CAR.</p><p>The proposed baseline model includes coreference resolution via T5-CQR, retrieval via BM25, and reranking via the T5-reranker model. Also, as shown in Table <ref type="table" coords="2,432.44,668.61,3.04,7.95" target="#tab_2">2</ref>, to improve recall in the retrieval stage, we used three different methods to expand queries of TREC CAsT raw utterance topics and validated these methods on the 2019 TREC CAsT evaluation topics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CQR Model Settings</head><p>We fine-tuned our CQR model on the CANARD dataset <ref type="bibr" coords="3,273.70,343.18,9.52,7.95" target="#b3">[4]</ref>, a conversational reading comprehension dataset containing dialogic question-answer pairs. This dataset can be used to evaluate query rewriting models that account for linguistic phenomena such as coreference and ellipsis resolution. When fine-tuning the T5-CQR model, for the input we used the previous dialogs followed by the current query, and for the target answer we used the rewritten, coreference-reformated query. For the ground truth, we used the reference rewrites. Note that questions and answers in the input dialog utterances were separated by the "|||" symbol, as recommended by the authors of CANARD. After fine-tuning, we assembled each query in each turn under each TREC CAsT topic with its previous queries. Using the assembled sentences as the input to the proposed CQR model, the outputs were the coreference-free queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SER Settings</head><p>As Figure <ref type="figure" coords="3,91.10,521.22,4.19,7.95" target="#fig_2">3</ref> shows, to exploit semantic relations, we first encoded each coreference-solved query by a pre-trained sentence Transformer model, a Roberta-large based model <ref type="bibr" coords="3,213.77,543.14,10.54,7.95" target="#b6">[7]</ref> trained on the NLI and STSb datasets and optimized for semantic textual similarity. For each query, we calculated the cosine similarity between the current query and the previous query, and appended the previous query as historical information if the cosine similarity was between 0.8 and 0.9, as determined empirically. Also, we used BM25 with the Anserini toolkit <ref type="bibr" coords="3,376.29,351.40,10.42,7.95" target="#b7">[8]</ref> to filter the corpus into a smaller corpus for efficiency. We parsed the passages of this smaller corpus into sentences and extracted one latent query per sentence with the doc2query model trained on the MS MARCO and TREC CAR datasets. The Roberta-large-based model was adopted to encode the original query and the latent queries to calculate the similarity. The most similar latent query with a cosine similarity greater than 0.9 was extracted as the most related topic sentence. Thus we concatenated the original query, the historical information, and the topic sentence to form an expanded query.</p><p>We also leveraged the manual responses provided in the 2020 TREC CAsT topics using the following T5-based method to expand each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">T5</head><p>-SQuAD Query Expansion. We used the manual results as the SQuAD-format content, which was one of the pre-trained tasks of the T5 model, and the raw utterance of each turn as the SQuAD-format question. We inputted this into the T5-3B model to yield the answers. In this query expansion method, we leveraged the answers as the words for query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TREC 2019 TREC 2020 Stage</head><p>Retrieval Reranking Retrieval + Reranking Raw utterances only mAP@1000 R@1000 R@2000 mAP@1000 R@1000 mAP@1000 R@1000 NDCG@3 NDCG@5 NDCG@1000 Raw queries 0.1077 0.4182 0.4681 4934 Manually rewritten utterances mAP@1000 R@1000 R@2000 mAP@1000 R@1000 mAP@1000 R@1000 NDCG@3 NDCG@5 NDCG@1000 QE (T5-SQuAD) N/A N/A N/A N/A N/A 0.3102 0.6498 0.4663 0.4514 0.5131   <ref type="table" coords="4,87.28,112.44,4.25,7.95" target="#tab_2">2</ref> are from using the raw utterances of the 2019 TREC CAsT evaluation set with various query expansion methods. In the retrieval stage, after rewriting raw queries with T5-CQR, the baseline model yields improvements in mAP and recall. T5-CQR improves the mAP, 𝑅@1000, and 𝑅@2000 at the retrieval stage by 132%, 82%, and 76%. With query expansion, SER slightly improves on the baseline model by 0.6% and 0.3% in 𝑅@1000 and 𝑅@2000 but decreases the mAP by 2.5%. RM3 query expansion, in turn, improves on the baseline model's 𝑅@1000 and 𝑅@2000 by 5.2% and 3.7%, and even increases the mAP by 14%. As the primary purpose of the retrieval stage is to increase recall, we believe that the above query expansion methods both yield marginal gains over the baseline. Since higher recall likely benefits reranking, we retrieved the top 2000 passages at the retrieval stage. After re-ranking, we kept only the top 1000 passages as the final results. The baseline model without query expansion shows the best mAP after reranking, although the 𝑅@1000 is not as high as that of QE (RM3) or QE (SER). This may be due to the difference in distributions between the training and test datasets. When fine-tuning the T5-reranker, we used only MS MARCO, a question-answering dataset featuring real humangenerated questions and answers similar to the TREC CAsT queries. However, since the answer passage set of TREC CAsT contains both MS MARCO and TREC CAR, the proposed T5-reranker may assign higher ranks to MS MARCO passages than to TREC CAR passages.</p><formula xml:id="formula_0" coords="3,288.65,625.14,227.09,6.37">N/A N/A N/A N/A N/A N/A N/</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">2020 TREC CAsT submission.</head><p>We submitted four runs to TREC CAsT this year with the query expansion methods mentioned in the previous section, three of which use only the raw questions, and the last of which uses the manual questions. The results of the evaluation are shown in Table <ref type="table" coords="4,166.17,425.15,3.07,7.95" target="#tab_2">2</ref>.</p><p>For the three runs using only raw utterances, the results are similar to the 2019 TREC CAsT evaluation set. That is, the baseline model without query expansion shows the best mAP although its 𝑅@1000 is lower than that of the other two results. For NDCG, the baseline model still outperforms at NDCG@3 and NDCG@5, which suggests that the top-3 and top-5 passages of the baseline model are more related than the other query-expanded passages. However, query expansion with RM3 boosts NDCG@1000 by 1.21%, perhaps because even though the pool with RM3 query expansion contains more related passages, the related passages rank lower at the retrieval stage.</p><p>For the run using manually rewritten utterances, we submitted only one result with T5-based QA-style query expansion. We still used the raw utterances and used the same model pipeline as that used for the raw-utterances-only run; the only difference is that we used the manually rewritten utterances for T5-squad query expansion. Compared to the baseline model, this query expansion slightly improves NDCG@3, NDCG@5, NDCG@1000, and mAP. These meager improvements suggest that such query expansion yields little new information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>This work demonstrates the importance of accounting for querydocument mismatch in conversational systems. We propose CQR and SER, resolving three critical challenges-vocabulary mismatch, coreference, and subject ellipsis-and we conduct empirical studies to evaluate the performance of the proposed methods. CQR and SER improve retrieval results, and the T5 reranker further enhances the final performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,250.61,311.64,110.78,7.70;2,81.85,86.52,448.30,208.30"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Proposed pipeline</figDesc><graphic coords="2,81.85,86.52,448.30,208.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,126.37,698.43,95.10,7.70"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: SER workflow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,259.48,301.52,93.04,7.70"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: SER structure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,53.80,86.80,132.29,9.37;4,53.80,101.43,240.25,8.04;4,53.80,112.44,30.57,7.95"><head>3. 4</head><label>4</label><figDesc>Quantitative Analysis 3.4.1 Results on 2019 TREC CAsT evaluation set. The results shown in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,170.50,227.86,389.22,449.42"><head>Table 1 :</head><label>1</label><figDesc>to eliminate the window size limit</figDesc><table coords="1,337.38,227.86,201.40,97.95"><row><cell cols="2">Number Raw utterance</cell></row><row><cell>83-1</cell><cell>What are some interesting facts about bees?</cell></row><row><cell>83-2</cell><cell>Why doesn't it spoil?</cell></row><row><cell>83-3</cell><cell>Why are so many dying?</cell></row><row><cell>83-4</cell><cell>What can be done to stop it?</cell></row><row><cell>83-5</cell><cell>What has happened to their habitat?</cell></row><row><cell>83-6</cell><cell>What can I do to help with the problem?</cell></row><row><cell>83-7</cell><cell>What is the cause of CCD?</cell></row><row><cell>83-8</cell><cell>What would happen if they died out?</cell></row></table><note coords="1,370.31,334.28,168.73,7.70;1,317.96,357.32,241.76,7.95;1,317.96,368.28,86.80,7.95"><p>TREC CAsT 2020 conversation utterances inherent to n-gram-based models, we use the T5, a Transformerbased text-to-text model</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,274.13,686.47,63.44,7.70"><head>Table 2 :</head><label>2</label><figDesc>Results</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank <rs type="person">Jheng-Hong Yang</rs> for valuable comments on the experience pipeline and experiment sharing.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="4,330.15,199.67,229.13,6.19;4,330.15,207.64,214.51,6.19" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct coords="4,330.15,215.61,228.05,6.19;4,330.15,223.58,228.19,6.19;4,330.15,231.55,152.17,6.19" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,467.00,223.58,91.33,6.19;4,330.15,231.55,133.00,6.19">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,239.52,228.05,6.19;4,330.15,247.49,88.14,6.19" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="4,448.90,239.52,86.95,6.19">Passage re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="4,330.15,255.46,228.36,6.19;4,330.15,263.43,228.75,6.19;4,330.15,271.40,64.38,6.19" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,495.81,255.46,62.69,6.19;4,330.15,263.43,116.68,6.19">Can you unpack that? Learning to rewrite questions-in-context</title>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Denis</forename><surname>Peskov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,460.03,263.45,98.87,6.16;4,330.15,271.42,45.41,6.16">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,279.37,229.23,6.19;4,330.15,287.34,153.71,6.19" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,508.96,279.37,50.42,6.19;4,330.15,287.34,68.65,6.19">Document expansion by query prediction</title>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno>ArXiv, abs/1904.08375</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,295.31,228.51,6.19;4,330.15,303.29,161.12,6.19" xml:id="b5">
	<analytic>
		<title/>
		<ptr target="https://github.com/google-research/text-to-text-transfer-transformer" />
	</analytic>
	<monogr>
		<title level="j" coord="4,330.15,295.31,60.14,6.19">Google Research. T</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Text-To-Text Transfer Transformer</note>
</biblStruct>

<biblStruct coords="4,330.15,311.26,228.05,6.19;4,330.15,319.23,228.05,6.19;4,330.15,327.20,228.82,6.19;4,329.99,335.17,22.73,6.19" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,430.40,311.26,127.80,6.19;4,330.15,319.23,70.27,6.19">Sentence-BERT: Sentence embeddings using Siamese BERT-networks</title>
		<author>
			<persName coords=""><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,417.91,319.24,140.29,6.16;4,330.15,327.21,107.17,6.16">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,330.15,343.14,228.18,6.19;4,330.15,351.11,228.06,6.19;4,330.15,359.08,228.05,6.19;4,329.99,367.05,219.70,6.19" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,470.53,343.14,87.80,6.19;4,330.15,351.11,82.79,6.19">Enabling the use of Lucene for information retrieval research</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Anserini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,425.75,351.12,132.45,6.16;4,330.15,359.08,208.03,6.19">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
