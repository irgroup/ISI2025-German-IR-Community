<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.05,115.96,307.25,12.62">BIT.UA@TREC 2020 Deep Learning Track</title>
				<funder ref="#_eruYvuv">
					<orgName type="full">EU/EFPIA Innovative Medicines Initiative 2 Joint Undertaking</orgName>
				</funder>
				<funder>
					<orgName type="full">National Funds</orgName>
				</funder>
				<funder ref="#_FKw6HJN">
					<orgName type="full">FCT -Foundation for Science and Technology</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,148.46,154.45,64.48,8.74"><forename type="first">Tiago</forename><surname>Almeida</surname></persName>
							<email>tiagomeloalmeida@ua.pt</email>
							<affiliation key="aff0">
								<orgName type="department">DETI/IEETA</orgName>
								<orgName type="institution">University of Aveiro</orgName>
								<address>
									<postCode>3810-193</postCode>
									<settlement>Aveiro</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.85,154.45,56.82,8.74"><forename type="first">SÃ©rgio</forename><surname>Matos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DETI/IEETA</orgName>
								<orgName type="institution">University of Aveiro</orgName>
								<address>
									<postCode>3810-193</postCode>
									<settlement>Aveiro</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.05,115.96,307.25,12.62">BIT.UA@TREC 2020 Deep Learning Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">28D10B4080E03A5BE33B533D0ACDA118</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Neural Networks</term>
					<term>Information Retrieval</term>
					<term>Lightweight Neural Model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a two-stage retrieval pipeline for the TREC Deep Learning 2020 track, where we used a lightweight neural model to rerank a baseline produced by an efficient traditional technique. In terms of overall performance, our results are slightly below the median, with a best score of 0.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This work describes the participation, for the first time, of the Biomedical Informatics and Technologies (BIT) group from the University of Aveiro, Portugal, in the TREC Deep Learning track. More precisely, we submitted results to the document ranking task, that aimed to retrieve documents from the MSMarco [5] dataset for the given test topics.</p><p>Our approach was focused on an in-house lightweight shallow interactionbased neural network, with only 620 trainable parameters in its current configuration, that was used as a reranker in a two-stage pipeline. Our main objective was to gain intuition on the track and evaluate the model behavior on a large scale dataset, as well as comparing it against state-of-the-art models such as transform-based ones.</p><p>In the remainder of the paper we describe our methodology for the construction of the submitted runs, present the results that were obtained, and finish with a conclusion section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>As already hinted, we explored a classic two-stage retrieval pipeline, where the first stage corresponds to a baseline originated from a traditional retrieval model, namely BM25 <ref type="bibr" coords="1,198.39,632.21,9.96,8.74">[7]</ref>. In the second stage we adopted our shallow interaction-based model to further score the previously retrieved documents. Through this section, we describe the most important steps that comprise our submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data preparation</head><p>In terms of data preparation, we kept a simple approach and built a regex based tokenizer and 200 dimension word embeddings for the produced vocabulary. The tokenizer consisted of filtering off non-alphanumeric characters with the exception of the hyphen character since this usually appears as part of compound words, that empirically seems to be important to keep together. We run this tokenizer over the MSMARCO documents and the development and test questions, resulting in a vocabulary with approximately 2 million tokens. Note this is a large number which hints that more attention should be given to this step.</p><p>We used the word2vec skip-gram algorithm from the Gensim [6] library to obtain the word embeddings. Specifically, we adopted the default configuration present on the Gensim library for training with word2vec skip-gram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Neural reranking model</head><p>The adopted neural model was originally proposed in <ref type="bibr" coords="2,364.95,312.75,10.52,8.74" target="#b1">[2]</ref> and further improved in <ref type="bibr" coords="2,134.77,324.70,9.96,8.74" target="#b0">[1]</ref>. Figure <ref type="figure" coords="2,181.35,324.70,4.98,8.74" target="#fig_0">1</ref> describes the overall architecture, where we employed an interaction network to learn and pool relevant signals and an aggregation network to weigh all the evidence found on different document passages. In a more detailed way, each document is split into sentences that are further combined with the query to build interaction matrices. Then, taking these matrices in the interaction network, 3-by-3 convolutions are adopted to learn n-gram patterns that are then extracted by pooling operations, lastly, the resulting feature vector is linearly combined with a trainable vector to compute a sentence relevant signal, with 0 for irrelevant and 1 for relevant. Next, the job of the aggregation network is to weigh the importance of each sentence in order to produce the final document score. For that, we follow the heuristic to first weigh each sentence by the importance of each query term, as suggested in <ref type="bibr" coords="3,467.31,130.95,9.96,8.74">[4]</ref>, where this importance is learned by taking into consideration the embedding representation of the query term.</p><p>More importantly, this model inner-working follows some of the best-reported ideas from shallow interaction-based models resulting in a completely transformfree architecture. As intuition, it was designed to weigh the importance of the document sentences by taking into consideration the context where the exact match with the query terms occurs. In other words, this model produces a more refined judgment of the previously exact match signal considered in the first stage of the pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training and hardware</head><p>Regarding the neural model, it was trained using a pairwise cross-entropy loss over the entire training collection. After each training epoch we also store the current model weights and measure the performance in the validation and 2019 test data. The model architecture parameters were the same as used in <ref type="bibr" coords="3,454.54,321.52,9.96,8.74" target="#b0">[1]</ref>, so we redirect the reader for further information or details.</p><p>Additionally, our experiments ran on a machine with 2x Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz and 128GB of RAM, highlighting that the neural model only ran on the CPU not requiring a GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Runs identification</head><p>The TREC Deep Learning track allowed three submissions that we utilized in the following way:</p><p>-BIT-run1: We adopted as the first stage the baseline provided by the organizers and applied our neural ranking model to score these documents producing a final ranking order. -BIT-run2: Consisted of an ensemble submission, using the reciprocal rank fusion [3], over four runs similar to the BIT-run1 using different training checkpoints for the neural ranking model. Furthermore, we chose the checkpoints that maximized some evaluation metrics on the validation or 2019 test data. -BIT-run3: This run also used the previous ensemble strategy. However, it corresponds to a full rank submission because we utilized the BM25 for the first stage retrieval instead of the TREC baseline. Furthermore, we indexed the full MSMARCO dataset using the ElasticSearch and finetuned the BM25 hyperparameters on the TREC 2019 test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and discussion</head><p>In this section, we present the results of our runs and compare to the median measures per topic, as summarized in Table <ref type="table" coords="3,329.34,656.12,3.87,8.74" target="#tab_0">1</ref>. In general, our system under-performed comparatively to the median scores. Moreover, the BIT-run2 achieved our best scores confirming the improvement, although only slight in this case, that is usually achieved when a combination of multiple runs is adopted. Our full ranking approach, BIT-run3, was our weakest submission, which indicates that our BM25 baseline does not offer a better starting point compared to the TREC baseline. We speculate that this behavior may be related to overfitting of BM25 to the TREC 2019 data, which is further aggravated by the fact that we retrieved 250 documents per query instead of 100, which means that the reranker has more unrelated documents to score.</p><p>As mentioned, our architecture was the same as used in <ref type="bibr" coords="4,398.78,329.52,9.96,8.74" target="#b0">[1]</ref>, which may not be the best suitable for this challenge, given the high availability of training data and a broader question domain. It would be interesting to test with a larger architecture and see its behavior. Another detail is the low percentage of relevant documents per query in the training data, which may require a different training setup from what we currently follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Per topic analysis</head><p>We now present two visualizations to look with more detail at the individual query performance of our submitted runs. In both visualizations, we use a sequential identifier for the topics and show the conversion to the original TREC topic identifier in the Appendix.</p><p>In Figure <ref type="figure" coords="4,191.95,508.70,4.98,8.74" target="#fig_1">2</ref> we show the performance in terms of nDCG@10 per each topic for all the submitted runs comparatively to the official TREC median. It is observable that for a great majority of topics our submissions were able to match the official median, which is a bit counter-intuitive when comparing with the results presented in Table <ref type="table" coords="4,219.68,556.52,3.87,8.74" target="#tab_0">1</ref>. Moreover, our submissions only severely underperformed for topics 32 (1116380), 40 (1131069), and 22 (1030303), especially in the last case due to the first stage baseline failing to retrieve any relevant document, which explains the missing values in the figure . 
We also compare, in Figure <ref type="figure" coords="4,271.09,606.32,3.87,8.74" target="#fig_2">3</ref>, our best run with the official median and best values, in terms of nDCG@10, reinforcing the idea that our system was able to achieve close to median results and in some cases being close to top results.</p><p>In Appendix B we also present the same visualization for the other available evaluation metrics, namely nDCG@100 and reciprocal rank. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Despite the relatively weaker results, we gained fundamental insights on the model behavior, given this large training regime, making it an useful effort and an important stepping stone for future enhancements. We believe that more attention can be given to improve the quality of the first stage retrieval while also correcting and finetuning the neural model for this larger training regime.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Topic identifiers</head><p>Table <ref type="table" coords="6,162.00,644.16,12.45,8.74" target="#tab_1">A1</ref> shows the mapping between our sequential identifiers and the original TREC topic identifiers to facilitate analysing the per topic visualization.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,207.31,550.78,200.75,6.12;2,134.77,380.59,345.80,159.41"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Lightweight neural model data and operation flow.</figDesc><graphic coords="2,134.77,380.59,345.80,159.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,167.72,336.84,279.93,6.12;5,134.77,115.84,345.83,210.22"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: nDCG@10 of all the submitted runs in comparison to the official median.</figDesc><graphic coords="5,134.77,115.84,345.83,210.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,148.48,339.79,318.40,6.12;6,134.77,115.83,345.83,213.18"><head>Fig. 3 :</head><label>3</label><figDesc>Fig.3: nDCG@10 of our best run against the official median and best values for each topic.</figDesc><graphic coords="6,134.77,115.83,345.83,213.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,146.91,374.33,333.68,7.86;6,146.91,385.29,333.55,7.86;6,134.77,396.68,345.83,7.86;6,146.91,407.64,333.68,7.86;6,146.91,418.60,333.68,7.86;6,146.91,429.56,333.68,7.86;6,146.91,440.51,333.68,8.12;6,146.91,452.12,155.34,7.47;6,134.77,462.87,345.83,7.86;6,146.91,473.83,333.68,7.86;6,146.91,484.78,333.68,7.86;6,134.77,496.18,345.83,7.86;6,146.91,507.14,317.17,7.86;6,134.77,516.26,345.83,10.13;6,146.91,529.49,333.68,7.86;6,146.91,540.45,333.68,8.12;6,146.91,552.05,98.85,7.47;6,134.77,562.80,345.83,7.86;6,146.91,573.73,333.68,7.89;6,146.91,584.72,145.73,7.86"><head></head><label></label><figDesc>M.J., Martins, F. (eds.) Advances in Information Retrieval. pp. 69-77. Springer International Publishing, Cham (2020). https://doi.org/10.1007/978-3-030-45442-5 9 3. Cormack, G.V., Clarke, C.L.A., Buettcher, S.: Reciprocal rank fusion outperforms condorcet and individual rank learning methods. In: Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval. p. 758-759. SIGIR '09, Association for Computing Machinery, New York, NY, USA (2009). https://doi.org/10.1145/1571941.1572114, https: //doi.org/10.1145/1571941.1572114 4. Guo, J., Fan, Y., Ai, Q., Croft, W.B.: A deep relevance matching model for ad-hoc retrieval. Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (Oct 2016). https://doi.org/10.1145/2983323.2983769 5. Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R., Deng, L.: Ms marco: A human-generated machine reading comprehension dataset (2016) 6. ÅehÅ¯Åek, R., Sojka, P.: Software Framework for Topic Modelling with Large Corpora. In: Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. pp. 45-50. ELRA, Valletta, Malta (May 2010), http://is.muni.cz/ publication/884893/en 7. Robertson, S., Zaragoza, H.: The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr. 3(4), 333-389 (Apr 2009). https://doi.org/10.1561/1500000019</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,167.42,357.12,280.51,6.12;8,134.77,135.68,345.83,210.66"><head>Fig. B1 :</head><label>B1</label><figDesc>Fig.B1: nDCG@100 of all the submitted runs comparable to the official median.</figDesc><graphic coords="8,134.77,135.68,345.83,210.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="8,160.09,635.92,295.17,6.12;8,134.77,411.95,345.82,213.19"><head>Fig. B2 :</head><label>B2</label><figDesc>Fig. B2: Reciprocal rank of all the submitted runs comparable to the official median.</figDesc><graphic coords="8,134.77,411.95,345.82,213.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="9,143.71,357.48,327.94,6.12;9,134.77,135.85,345.83,210.85"><head>Fig. B3 :</head><label>B3</label><figDesc>Fig.B3: nDCG@100 of our best run against the official median and best values for each topic.</figDesc><graphic coords="9,134.77,135.85,345.83,210.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="9,136.37,635.75,342.61,6.12;9,134.77,412.64,345.82,212.34"><head>Fig. B4 :</head><label>B4</label><figDesc>Fig. B4: Reciprocal rank of our best run against the official median and best values for each topic.</figDesc><graphic coords="9,134.77,412.64,345.82,212.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,151.61,126.61,312.14,61.60"><head>Table 1 :</head><label>1</label><figDesc>Summary of our runs results comparatively to the TREC average of the median.</figDesc><table coords="4,171.02,135.69,273.32,52.52"><row><cell cols="5">Submissions nDCG@10 nDCG@100 Reciprocal Rank AP</cell></row><row><cell>BIT-run1</cell><cell>0.5239</cell><cell>0.5430</cell><cell>0.8389</cell><cell>0.3466</cell></row><row><cell>BIT-run2</cell><cell>0.5283</cell><cell>0.5447</cell><cell>0.8611</cell><cell>0.3466</cell></row><row><cell>BIT-run3</cell><cell>0.5063</cell><cell>0.5365</cell><cell>0.8296</cell><cell>0.3267</cell></row><row><cell>Median</cell><cell>0.5733</cell><cell>0.5859</cell><cell>0.9444</cell><cell>0.3902</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,126.61,367.05,306.32"><head>Table A1 :</head><label>A1</label><figDesc>Translation table between sequential indetifiers and the TREC topic identifiers.</figDesc><table coords="7,134.77,135.69,367.05,297.25"><row><cell cols="4">TREC topic identifier pseudo-identifier TREC topic identifier pseudo-identifier</cell></row><row><cell>42255</cell><cell>1</cell><cell>1043135</cell><cell>24</cell></row><row><cell>47210</cell><cell>2</cell><cell>1049519</cell><cell>25</cell></row><row><cell>67316</cell><cell>3</cell><cell>1051399</cell><cell>26</cell></row><row><cell>135802</cell><cell>4</cell><cell>1056416</cell><cell>27</cell></row><row><cell>156498</cell><cell>5</cell><cell>1064670</cell><cell>28</cell></row><row><cell>169208</cell><cell>6</cell><cell>1071750</cell><cell>29</cell></row><row><cell>174463</cell><cell>7</cell><cell>1103153</cell><cell>30</cell></row><row><cell>258062</cell><cell>8</cell><cell>1105792</cell><cell>31</cell></row><row><cell>324585</cell><cell>9</cell><cell>1108729</cell><cell>32</cell></row><row><cell>330975</cell><cell>10</cell><cell>1109707</cell><cell>33</cell></row><row><cell>332593</cell><cell>11</cell><cell>1113256</cell><cell>34</cell></row><row><cell>336901</cell><cell>12</cell><cell>1115210</cell><cell>35</cell></row><row><cell>673670</cell><cell>13</cell><cell>1116380</cell><cell>36</cell></row><row><cell>701453</cell><cell>14</cell><cell>1119543</cell><cell>37</cell></row><row><cell>730539</cell><cell>15</cell><cell>1122767</cell><cell>38</cell></row><row><cell>768208</cell><cell>16</cell><cell>1127540</cell><cell>39</cell></row><row><cell>877809</cell><cell>17</cell><cell>1131069</cell><cell>40</cell></row><row><cell>911232</cell><cell>18</cell><cell>1132532</cell><cell>41</cell></row><row><cell>938400</cell><cell>19</cell><cell>1136043</cell><cell>42</cell></row><row><cell>940547</cell><cell>20</cell><cell>1136047</cell><cell>43</cell></row><row><cell>997622</cell><cell>21</cell><cell>1136769</cell><cell>44</cell></row><row><cell>1030303</cell><cell>22</cell><cell>1136962</cell><cell>45</cell></row><row><cell>1037496</cell><cell>23</cell><cell></cell><cell></cell></row><row><cell cols="2">B Remaining visualisation</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has received support from the <rs type="funder">EU/EFPIA Innovative Medicines Initiative 2 Joint Undertaking</rs> under grant agreement No <rs type="grantNumber">806968</rs> and from <rs type="funder">National Funds</rs> through the <rs type="funder">FCT -Foundation for Science and Technology</rs>, in the context of the project <rs type="grantNumber">UIDB/00127/2020</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_eruYvuv">
					<idno type="grant-number">806968</idno>
				</org>
				<org type="funding" xml:id="_FKw6HJN">
					<idno type="grant-number">UIDB/00127/2020</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,590.96,342.25,7.86;5,146.91,601.92,333.68,7.86;5,146.91,612.88,333.68,7.86;5,146.91,623.84,333.68,7.86;5,146.91,634.80,329.43,8.12" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,244.19,590.96,236.40,7.86;5,146.91,601.92,125.06,7.86">UA at bioasq 8: Lightweight neural document ranking with zero-shot snippet retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matos</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_161.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="5,186.53,612.88,294.06,7.86;5,146.91,623.84,24.01,7.86;5,358.73,623.84,117.65,7.86">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>NÃ©vÃ©ol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2020</date>
			<biblScope unit="volume">2696</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="5,138.35,645.84,342.24,7.86;5,146.91,656.80,333.68,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,247.11,645.84,233.48,7.86;5,146.91,656.80,28.51,7.86">Calling attention to passages for biomedical question answering</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>MagalhÃ£es</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Silva</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
