<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,73.76,112.05,447.77,15.12">IELAB for TREC Conversational Assistance Track (CAsT) 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-11-11">November 11, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.01,144.53,41.46,10.48"><forename type="first">Hang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.35,144.53,71.21,10.48"><forename type="first">Arvin</forename><surname>Zhuang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,402.21,144.53,88.28,10.48"><forename type="first">Koopman</forename><surname>Bevan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">CSIRO</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,73.76,112.05,447.77,15.12">IELAB for TREC Conversational Assistance Track (CAsT) 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-11">November 11, 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">145678112C23675FF3D7268353621812</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the work done by the IELAB for the TREC Conversational Assistance Track (CAsT) 2020. IELAB investigated two methods to improve both the retrieval and re-ranking stages of a conversational IR system. The first method used an Adapted Query (AQ), which extracted context from the first utterance only to expand all subsequent queries for a conversational session. The second method utilized a query likelihood model (QLM) which used a pre-trained deep language model to estimate the likelihood that a query could be generated by a document. Specifically, we used the text-to-text transfer transformer (T5) as a scoring functions for re-ranking passages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The aim of TREC Conversational Assistance Track (CAsT) is to advance research on conversational search systems. For TREC CAsT of 2020, the aim is to focus on candidate information ranking in the context of the conversation. This introduces two challenges: the first is extracting relevant context or information from the conversation. This is done to improve the effectiveness of the current query; the second is a traditional information retrieval task, which is retrieving and ranking documents that are relevant to the given query.</p><p>The IELAB team participated in TREC CAsT 2020 by submitting two systems that addressed these two challenges. The first system used an Adapted Query (AQ) approach to expand the query based on the contextual history of the conversation. Previous submissions in TREC CAst 2019 <ref type="bibr" coords="1,472.28,497.22,10.52,8.74" target="#b0">[1]</ref> included the entire contextual history of a conversation. However, our approach assumes that the main context of a conversation is stated during the first utterance. Table <ref type="table" coords="1,337.12,521.13,4.98,8.74">1</ref> shows an example conversation from the TREC CAst 2020 dataset. The focus of this conversation is the "garage door opener" which is stated within the first utterance. This term is never explicitly mentioned through the rest of the conversation although being explicitly referred to in each subsequent utterance. This leaves many questions open with no context or focus.</p><p>The second system used a query likelihood model for re-ranking the results. Previous success with the T5 model within the context of natural language processing was the leading motivation for using T5 in one of our systems. What's important for me to know about their safety? What's important for me to know about the safety of smart garage door openers? 8 How could they be hacked? How could smart garage door openers be hacked? Table <ref type="table" coords="1,113.99,718.32,3.87,8.74">1</ref>: Conversation example of raw and manually rewritten utterances from the 2020 data set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In TREC CAst 2019, most of the submissions considered the entire context of a conversation and deployed off-the-shelf coreference models <ref type="bibr" coords="2,208.21,108.93,9.96,8.74" target="#b0">[1]</ref>. However, the large gap in performance between the raw utterance and manually resolved utterance systems demonstrated the struggle of the coreference models with TREC CAst topics. Our AQ approach, therefore, aims to partially resolve this issue by considering the first utterance in the conversation. Considering re-ranking, we build atop of TREC CAst 2019 submissions by using neural models to improve the re-ranking. However, we employed T5 instead of BERT. While other methods were investigated, the IELAB team submitted two systems based on the AQ and T5-QLM methods to the CAsT task for 2020.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Collections</head><p>TREC provided a set of 25 conversational scenarios. Each of these contained a set of conversational search utterances, which were provided in three forms: raw utterances, automatically rewritten utterances and manually rewritten utterances. The AQ system used the raw utterances, while the T5-QLM system used the manually rewritten utterances. Indexing. We considered the two data collections provided by TREC CAsT, namely, MS-MARCO [3] and TREC CAR. They were both converted to JSON documents with the following format "id": "", "contents": "". Id represented the id of the document, and which collection it originated from. The contents represented the main text from each of the documents. Then we created two indexes: MS-MARCO and TREC CAR, which is used by AQ; and MS-MARCO only, which is used by T5-QLM. The file size of the MS-MARCO &amp; TREC CAR index is 25GB, while the file size of MS-MARCO index is 5GB. The data collections were indexed using Apache Lucene<ref type="foot" coords="2,344.52,344.79,3.97,6.12" target="#foot_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Conversational Search Systems</head><p>The IELAB team submitted two systems. All submissions employed Pyserini<ref type="foot" coords="2,415.94,390.93,3.97,6.12" target="#foot_1">2</ref> (a python wrapper for Anserini <ref type="bibr" coords="2,111.93,404.46,10.30,8.74" target="#b4">[5]</ref>), with BM25 and RM3, as a first stage retrieval model. It is also considered as a baseline. Pyserini was independently fine tuned to suit the task.</p><p>AQ System. AQ seeks to improve the BM25+RM3 baseline by using query expansion. It involves selecting the first query (Q1) from the conversation, and using this query to extend every subsequent query (Qn). The adaptation is achieved by appending Q1 to Qn. The new extended query is then run through the fine tuned BM25+RM3 index to retrieve the candidate responses.</p><p>T5-QLM System The QLM-T5, uses the text-to-text transfer transformer language model (T5) <ref type="bibr" coords="2,510.23,476.19,13.05,8.74" target="#b3">[4]</ref> instead of the maximum likelihood estimation in a query likelihood model (QLM). A QLM is used to calculate the probability P (Q|D) of generating a query Q based on a document D. The T5 model uses an encoder-decoder architecture. The encoder's input is tokens from the document d 0 , d 1 ...d n ∈ D. The decoder's input is tokens from the target query q 0 , q 1 ...q |Q| ∈ Q along with a pad token &lt;PAD&gt;. This pad token is used to signify the start sequence for the decoder. For each time step t, the decoder generates the probability of using the next token from the target query P T 5 (q t+1 ). We exploit this QLM-T5 to re-rank documents, by estimating the likelihood that a query could be generated by a document. Specifically, we compute the query (log) likelihood for Q given the document D as</p><formula xml:id="formula_0" coords="2,155.75,592.76,367.53,31.18">log(P QLM -T 5 (Q, D)) = log(P T 5 (&lt; P AD &gt;)) + |Q|-1 i=0 log(P T 5 (q i ))<label>(1)</label></formula><p>Other Explorations We developed two other systems that utilized BERT translation models. One system to reproduce previous models that used BERT <ref type="bibr" coords="2,298.20,645.83,16.31,8.74" target="#b1">[2]</ref> for re-ranking. The other system utilized BERT for query expansion in a pseudo relevance feedback manner. Results for both systems were not reported because of a number of errors within the development process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Analysis</head><p>Each system was developed using the 2019 CAsT dataset, and evaluated using the 2019 CAsT Qrels. The 2019 CAsT task used three evaluation metrics, nDCG@3, MRR and MAP. Results shown in The results of our submitted runs closely resemble the expectations of our test runs. As seen in table 3 the AQ method results were nDCG@1000 = 0.2463 and the MAP@1000 = 0.1024. While our system under performed compared to the median raw utterance score, it should be noted that this system was not judge. The T5 QLM method will not be compared with the AQ method as this was performed over the manual utterance. The results for this method were nDCG@1000 = 0.4103 and the MAP@1000 = 0.2712.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The IELAB submission for TREC Conversational Assistance (CAsT) Track 2020 focused on two submissions the AQ and QLM T5. These two submission were chosen as they attempt to solve the two main challenges outlined in the TREC CAsT task. Future work will be focused on improving the retrieval results by extending the current submitted runs. For instance, investigation into improving the method of context extraction has begun, specifically extracting context from the syntactical structure of the conversation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,491.42,736.33,31.85,8.74"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="3,195.68,73.96,203.92,35.44"><row><cell>Run Methods</cell><cell cols="2">NDCG@3 MRR MAP</cell></row><row><cell>BM25+RM3</cell><cell>.1716</cell><cell>.3495 .1469</cell></row><row><cell cols="2">BM25+RM3+AQ .2614</cell><cell>.4935 .1925</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,148.72,122.53,297.84,58.10"><head>Table 2 :</head><label>2</label><figDesc>Experimental Run Results from 2019 Topics Dataset</figDesc><table coords="3,148.72,145.18,297.84,35.44"><row><cell cols="5">Run Methods NDCG@3 nDCG@5 nDCG@1000 MAP@1000</cell></row><row><cell>Raw Median</cell><cell>0.2795</cell><cell>0.2735</cell><cell>0.3749</cell><cell>0.1801</cell></row><row><cell>BM25 AQ</cell><cell>.0.1330</cell><cell>0.1282</cell><cell>0.2463</cell><cell>0.1024</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,144.25,193.75,306.78,58.10"><head>Table 3 :</head><label>3</label><figDesc>Raw Utterance Median result and AQ results</figDesc><table coords="3,144.25,216.41,306.78,35.44"><row><cell>Run Methods</cell><cell cols="4">NDCG@3 nDCG@5 nDCG@1000 MAP@1000</cell></row><row><cell cols="2">Manual Median 0.4137</cell><cell>0.3977</cell><cell>0.4886</cell><cell>0.2633</cell></row><row><cell>BM25T5 QLM</cell><cell>.0.4103</cell><cell>0.4113</cell><cell>0.4472</cell><cell>0.2712</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,72.00,264.97,417.74,40.56"><head>Table 4 :</head><label>4</label><figDesc>Manual Utterance Median result and T5 QLM results demonstrated that AQ substantially outperformed the baseline of BM25+RM3 over all metrics.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,87.24,755.52,110.09,6.64"><p>https://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,87.24,765.02,156.66,6.64"><p>https://github.com/castorini/pyserini</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,87.50,537.83,435.78,8.74;3,87.50,549.79,435.78,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,316.42,537.83,206.86,8.74;3,87.50,549.79,35.94,8.74">Cast 2019: The conversational assistance track overview</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,143.15,549.79,258.91,8.74">Proceedings of the Twenty-Eighth Text REtrieval Conference</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="13" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,87.50,569.71,435.78,8.74;3,87.50,581.67,412.78,8.74" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="3,434.41,569.71,88.87,8.74;3,87.50,581.67,232.59,8.74">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="3,87.50,601.60,435.77,8.74;3,87.50,613.55,384.92,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="3,129.55,613.55,311.46,8.74">Ms marco: A human-generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,87.50,633.48,435.78,8.74;3,87.50,645.43,435.78,8.74;3,87.50,657.39,229.11,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="3,229.45,645.43,293.82,8.74;3,87.50,657.39,49.09,8.74">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="3,87.50,677.31,435.77,8.74;3,87.50,689.27,295.99,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,276.95,677.31,242.05,8.74">Anserini: Reproducible ranking baselines using lucene</title>
		<author>
			<persName coords=""><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,87.50,689.27,213.48,8.74">Journal of Data and Information Quality (JDIQ)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
