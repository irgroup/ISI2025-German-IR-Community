<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.14,115.96,237.09,12.62;1,209.00,133.89,197.37,12.62;1,190.74,151.82,233.87,12.62">Leveraging Query Resolution and Reading Comprehension for Conversational Passage Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,137.91,189.61,84.13,8.74"><forename type="first">Svitlana</forename><surname>Vakulenko</surname></persName>
							<email>s.vakulenko@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.60,189.61,73.26,8.74"><forename type="first">Nikos</forename><surname>Voskarides</surname></persName>
							<email>n.voskarides@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.41,189.61,56.74,8.74"><forename type="first">Zhucheng</forename><surname>Tu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Apple Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.07,189.61,69.90,8.74"><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Apple Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.14,115.96,237.09,12.62;1,209.00,133.89,197.37,12.62;1,190.74,151.82,233.87,12.62">Leveraging Query Resolution and Reading Comprehension for Conversational Passage Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">50FC8EAE02690A9418CF188A116AB160</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of UvA.ILPS group at the TREC CAsT 2020 track. Our passage retrieval pipeline consists of (i) an initial retrieval module that uses BM25, and (ii) a re-ranking module that combines the score of a BERT ranking model with the score of a machine comprehension model adjusted for passage retrieval. An important challenge in conversational passage retrieval is that queries are often under-specified. Thus, we perform query resolution, that is, add missing context from the conversation history to the current turn query using QuReTeC, a term classification query resolution model. We show that our best automatic and manual runs outperform the corresponding median runs by a large margin.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Passage Retrieval Pipeline</head><p>Our passage retrieval pipeline is shown schematically in Figure <ref type="figure" coords="1,414.92,442.52,4.98,8.74" target="#fig_0">1</ref> and works as follows. Given the original current turn query Q and the conversation history H, we first perform query resolution, that is, add missing context from the H to Q to arrive to the resolved query Q <ref type="bibr" coords="1,294.68,478.39,9.96,8.74" target="#b7">[8]</ref>. Next, we perform initial retrieval using Q to get a list of top-k passages P . Finally, for each passage in P , we combine the scores of a reranking module and a reading comprehension module to obtain the final ranked list R. We describe each module of the pipeline below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Query Resolution</head><p>One important challenge in conversational passage retrieval is that the current turn query is often under-specified. In order to address this challenge, we perform query resolution, that is, add missing context from the conversation history to the current turn query <ref type="bibr" coords="1,236.44,601.10,9.96,8.74" target="#b7">[8]</ref>.</p><p>We use QuReTeC, a binary term classification query resolution model. QuReTeC uses BERT to classify each term in the conversation history as relevant or not, and adds the relevant terms to the original current turn query. <ref type="foot" coords="1,406.19,635.50,3.97,6.12" target="#foot_0">3</ref> Due to BERT's</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reading Comprehension</head><p>Resolved query</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q'</head><p>Original query</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q</head><p>Conversation history restrictions on the number of tokens, we cannot include the responses to all the previous turn queries in the conversation history. Thus, we include (i) all the previous turn queries and (ii) the automatic canonical response to the previous turn query only (provided by the track organizers). We use the QuReTeC model described in <ref type="bibr" coords="2,189.04,339.97,10.52,8.74" target="#b7">[8]</ref> that was trained on gold standard query resolutions derived from the CANARD dataset <ref type="bibr" coords="2,234.72,351.92,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Initial Retrieval</head><p>We perform initial retrieval using BM25. We tuned the parameters on the MS MARCO passage retrieval dataset (k 1 = 0.82, b = 0.68).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Re-ranking</head><p>Here, we re-rank the original ranking list obtained in the initial retrieval step. The final ranking score is a weighted average of the Re-ranking (BERT) and Reading Comprehension scores, which we describe below. The interpolation weight w is optimized on the TREC CAsT 2019 dataset <ref type="bibr" coords="2,383.10,516.20,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-ranking (BERT).</head><p>We use a BERT model to get a ranking score for each passage as described in <ref type="bibr" coords="2,237.11,556.27,9.96,8.74" target="#b3">[4]</ref>. We initialize BERT with bert-large and fine-tuned it on the MS MARCO passage retrieval dataset as described in <ref type="bibr" coords="2,413.66,568.22,9.96,8.74" target="#b5">[6]</ref>.</p><p>Reading Comprehension. As an additional signal to rank passages we use a reading comprehension model. The model is a RoBERTa-Large model trained to predict an answer as a text span in a given passage or "No Answer" if the passage does not contain the answer. It is fine-tuned on the MRQA dataset <ref type="bibr" coords="2,467.31,632.21,9.96,8.74" target="#b2">[3]</ref>. We compute the reading comprehension score as the sum of the predicted start and end span logits: (l start + l end ).</p><p>Table <ref type="table" coords="3,164.99,115.91,4.12,7.89">1</ref>. Experimental results on the TREC CAsT 2020 dataset. Note that apart from our submitted runs, we also report performance of the Median runs for reference (Median-auto and Median-manual). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Runs</head><p>We submitted 3 automatic runs and 1 manual run. Automatic runs use the raw current turn query, while the manual run uses the manually rewritten current turn query. For all runs, we keep the top-100 ranked passages per query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Automatic runs</head><p>-quretecNoRerank: Uses QuReTeC for query resolution (Section 1.1) and the initial retrieval module (Section 1.2), but does not use re-ranking (Section 1.3). -quretecQR: Uses the whole retrieval pipeline described in Section 1.</p><p>-baselineQR: Uses the whole retrieval pipeline but uses the automatically rewritten version of the current turn query provided by the track organizers, instead of QuReTeC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Manual run</head><p>-HumanQR: Uses the whole retrieval pipeline but uses the manually rewritten version of the current turn query provided by the track organizers, instead of QuReTeC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Table <ref type="table" coords="3,161.42,560.48,4.98,8.74">1</ref> shows our experimental results. First, we observe that quretecNoRerank underperforms Median-auto, thus highlighting the importance of the re-ranking module. Also, we observe that quretecQR, the run that uses the whole pipeline, outperforms Median-auto by a large margin and also outperforms baselineQR, on all reported metrics. This shows the effectiveness of QuReTeC for query resolution <ref type="bibr" coords="3,180.56,620.25,9.96,8.74" target="#b7">[8]</ref>. Moreover, we see that quretecQR is outperformed by humanQR by a large margin, which highlights the need for future work on the task of query resolution <ref type="bibr" coords="3,181.54,644.16,9.96,8.74" target="#b6">[7]</ref>. Lastly, we observe that our manual run (humanQR) outperforms Median-manual, likely because of better (tuned) retrieval modules.</p><p>Table <ref type="table" coords="4,164.46,115.91,4.13,7.89">2</ref>. Error analysis when using Original, QuReTeC-resolved or Human queries. For a given query group, if NDCG@3&gt;0 for the query used then we mark it with , otherwise we mark it with × (NDCG@3=0). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error type</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head><p>In this section, we analyze our results using the approach introduced in [5].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quantitative analysis</head><p>In our pipeline, passage retrieval performance is dependent on the performance of the query resolution module. Thus, we try to estimate the proportion of ranking and query resolution errors separately. Specifically, we compare passage retrieval performance when using the Original queries, the QuReTeC-resolved queries or Human rewritten queries, and group queries into different types: (i) ranking error, (ii) query resolution error and (iii) no error. In order to simplify our analysis, we first choose a ranking metric m (e.g., NDCG@3) and a threshold t. We define ranking errors as follows: we assume that Human rewritten queries are always well specified (i.e., they do not need query resolution), and thus poor ranking performance (m &lt;= t) when using the Human rewritten queries can be attributed to the ranking modules. A query resolution error is one for which the Human rewritten query has performance m &gt; t, but for which the QuReTeCresolved query has performance m &lt;= t.</p><p>Table <ref type="table" coords="4,176.25,548.52,4.98,8.74">2</ref> shows the results of this analysis when using NDCG@3 as the ranking metric m and setting the threshold to t = 0. Since we assume that human rewrites are always well specified, all queries with NDCG@3=0 (× in column Human) are due to errors in retrieval (13.5%). Among the queries for which at least one relevant passage was retrieved in the top-3 ( in column Human), we see that 61.0% were correctly resolved by QuReTeC, and 25.5% were not. This shows that query resolution for conversational passage retrieval has more room for improvement. In addition, we observe that (0 + 1 + 2 + 39)/208 ≈20% of the queries in the dataset do not need resolution, since when using those we can retrieve at least one relevant passage in the top-3 ( in column Original).</p><p>Table <ref type="table" coords="5,163.30,115.91,4.12,7.89">3</ref>. Error analysis when using Original, QuReTeC-resolved or Human queries. indicates that the retrieval performance (NDCG@3 or NDCG@5) reached the threshold indicated in the right columns, and × indicates that it did not reach the threshold. The numbers correspond to the number of queries in each group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head><p>NDCG@3 NDCG@5 Original QuReTeC-resolved Human &gt;0 &gt;= 0.5 = 1 &gt;0 &gt;= 0. Table <ref type="table" coords="5,177.51,318.81,4.98,8.74">3</ref> shows the same error analysis performed for different thresholds of NDCG@3 and NDCG@5. We observe that, as the performance threshold increases, the number of ranking errors increases, which indicates that the passage ranking modules have a lot of room for improvement. Figure <ref type="figure" coords="5,404.37,354.67,4.98,8.74">2</ref> shows the same analysis for NDCG@3, for more thresholds. <ref type="foot" coords="5,323.77,365.05,3.97,6.12" target="#foot_1">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Qualitative analysis</head><p>In order to gain further insights, we sample cases where using the QuReTeCresolved queries result in a better or worse retrieval performance than when using the Human rewrites.</p><p>In Table <ref type="table" coords="5,189.76,451.59,4.98,8.74">4</ref> we show examples where QuReTeC performs worse than Human rewrites. In these cases, QuReTeC either misses relevant tokens or introduces redundant tokens.</p><p>Interestingly, there are also cases in which QuReTeC performs better than Human rewrites (see Table <ref type="table" coords="5,254.41,499.41,4.98,8.74">5</ref> for examples). In these examples, QuReTeC introduced tokens from the conversation history that were absent from the manually rewritten queries but which helped to retrieve relevant passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented our participation in the TREC CAsT 2020 track. We found that our best automatic run that uses QuReTeC for query resolution (quretecQR) outperforms both the automatic median run and the run that uses the rewritten queries provided by the organizers (baselineQR). In addition, we found that our manual run that uses the human rewrites (humanQR) outperforms our best Fig. <ref type="figure" coords="6,154.40,321.69,4.13,7.89">2</ref>. Error analysis results using Original, QuReTeC-resolved and Human queries for all thresholds of NDCG@3 for (0; 1] with intervals of 0.02. Passage ranking errors increase as the NDCG threshold increases (blue). The proportion of correct query resolutions (turquoise) is higher than the number of errors produced by QuReTeC (orange). Best seen in color.</p><p>automatic run (quretecQR), which, alongside with our analysis, highlight the need for further work on the task of query resolution for conversational passage retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,230.93,256.73,153.50,7.89;2,302.55,140.49,57.17,77.98"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Our passage retrieval pipeline.</figDesc><graphic coords="2,302.55,140.49,57.17,77.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,134.77,115.84,345.82,191.08"><head></head><label></label><figDesc></figDesc><graphic coords="6,134.77,115.84,345.82,191.08" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="1,144.73,656.80,288.57,7.86"><p>We refer the interested reader to the original paper for more details<ref type="bibr" coords="1,421.01,656.80,9.22,7.86" target="#b7">[8]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,144.73,645.84,335.86,7.86;5,144.73,656.80,289.65,7.86"><p>The source code for this analysis that allows to produce the visualisation in Figure2from the run files is available at https://github.com/svakulenk0/QRQA</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,475.16,342.24,7.86;6,146.91,486.12,153.09,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,330.71,475.16,149.88,7.86;6,146.91,486.12,77.53,7.86">Cast-19: A dataset for conversational information seeking</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,245.55,486.12,25.78,7.86">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,496.77,342.25,7.86;6,146.91,507.73,162.78,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,317.71,496.77,162.88,7.86;6,146.91,507.73,79.33,7.86">Can you unpack that? learning to rewrite questions-in-context</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Peskov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,247.36,507.73,33.66,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,518.39,342.24,7.86;6,146.91,529.35,308.12,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,398.95,518.39,81.64,7.86;6,146.91,529.35,228.82,7.86">MRQA 2019 shared task: Evaluating generalization in reading comprehension</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,397.31,529.35,29.06,7.86">MRQA</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,540.00,342.24,7.86;6,146.91,550.96,97.80,7.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="6,267.46,540.00,134.82,7.86">Passage re-ranking with bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,138.35,561.61,342.24,7.86;6,146.91,572.57,333.67,7.86;6,146.91,583.53,217.78,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,345.13,561.61,135.46,7.86;6,146.91,572.57,333.67,7.86;6,146.91,583.53,145.72,7.86">A wrong answer or a wrong question? an intricate relationship between question reformulation and answer selection in conversational question answering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vakulenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Anantha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>SCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,594.18,342.24,7.86;6,146.91,605.14,180.98,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,349.36,594.18,131.23,7.86;6,146.91,605.14,100.85,7.86">Question rewriting for conversational question answering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vakulenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Anantha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>WSDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,615.79,342.24,7.86;6,146.91,626.75,264.73,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,349.38,615.79,131.21,7.86;6,146.91,626.75,192.31,7.86">A comparison of question rewriting methods for conversational passage retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vakulenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Voskarides</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>ECIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,637.41,342.24,7.86;6,146.91,648.36,259.78,7.86;7,155.68,158.43,303.99,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,397.28,637.41,83.31,7.86;6,146.91,648.36,184.20,7.86">Query resolution for conversational search with limited supervision</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Voskarides</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,352.24,648.36,54.45,7.86;7,155.68,158.43,300.17,7.89">SIGIR (2020) Table 4. Examples where QuReTeC performs worse than Human rewrites</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,153.30,241.73,4.61,7.86;7,165.11,236.25,29.44,7.86;7,212.12,236.25,144.84,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,153.30,241.73,4.61,7.86;7,165.11,236.25,29.44,7.86;7,212.12,236.25,144.84,7.86">8 Human Does the public pay Ivanka Trump?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,153.30,295.57,4.61,7.86;7,165.11,290.09,29.44,7.86;7,212.12,290.09,115.33,7.86;7,458.21,290.09,20.99,7.86;7,165.11,301.05,225.49,7.86;7,474.59,301.05,4.61,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,165.11,290.09,29.44,7.86;7,212.12,290.09,115.33,7.86;7,458.21,290.09,20.99,7.86;7,165.11,301.05,225.49,7.86;7,474.59,301.05,4.61,7.86">Human Can social security be fixed? 0.413 QuReTeC Can it be fixed? checks social check security 0</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,153.30,322.49,4.61,7.86;7,165.11,317.01,29.44,7.86;7,212.12,317.01,218.31,7.86;7,212.12,327.97,32.31,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="7,165.11,317.01,29.44,7.86;7,212.12,317.01,218.31,7.86;7,212.12,327.97,32.31,7.86">Human How much of a tax increase will keep social security solvent?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,165.11,494.84,175.51,7.86;7,458.21,494.84,20.99,7.86" xml:id="b11">
	<monogr>
		<title level="m" coord="7,165.11,494.84,175.51,7.86;7,458.21,494.84,4.20,7.86">QuReTeC And Jared? ivana donald trump 0</title>
		<imprint>
			<biblScope unit="page">296</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,153.30,516.28,4.61,7.86;7,165.11,510.80,29.44,7.86;7,212.12,510.80,165.02,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="7,165.11,510.80,29.44,7.86;7,212.12,510.80,165.02,7.86">Human Why was George Zimmerman acquitted?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,165.11,521.76,265.32,7.86;7,212.12,532.72,17.41,7.86;7,458.21,521.76,20.99,7.86" xml:id="b13">
	<monogr>
		<title level="m" coord="7,165.11,521.76,265.32,7.86;7,212.12,532.72,17.41,7.86;7,458.21,521.76,4.20,7.86">QuReTeC Why was he acquitted? george trayvon martin zimmerman 0</title>
		<imprint>
			<biblScope unit="page">202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,148.69,554.16,4.61,7.86;7,165.11,548.68,29.44,7.86;7,212.12,548.68,169.18,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="7,165.11,548.68,29.44,7.86;7,212.12,548.68,169.18,7.86">Human What support does the franchise provide?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,165.11,559.64,265.32,7.86;7,212.12,570.60,48.85,7.86" xml:id="b15">
	<monogr>
		<title level="m" coord="7,165.11,559.64,265.32,7.86;7,212.12,570.60,48.85,7.86">QuReTeC What support does it provide? king franchise agreement burger</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,148.69,592.04,4.61,7.86;7,165.11,586.56,29.44,7.86;7,212.12,586.56,208.36,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="7,165.11,586.56,29.44,7.86;7,212.12,586.56,208.36,7.86">Human Can you show me vegetarian recipes with almonds?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,165.11,597.52,265.32,7.86;7,212.12,608.48,25.88,7.86;7,458.21,597.52,20.99,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="7,165.11,597.52,250.58,7.86">QuReTeC Oh almonds? Can you show me recipes with it?</title>
		<idno>al- monds 0.296</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
