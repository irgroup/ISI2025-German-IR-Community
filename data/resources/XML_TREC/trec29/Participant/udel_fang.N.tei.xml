<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.00,118.16,467.99,18.14;1,274.25,143.07,63.49,18.14">Aspect Based Background Document Retrieval for News Articles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,226.88,182.87,61.83,12.58"><forename type="first">Kuang</forename><surname>Lu</surname></persName>
							<email>lukuang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.53,182.87,56.77,12.58"><forename type="first">Hui</forename><surname>Fang</surname></persName>
							<email>hfang@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.00,118.16,467.99,18.14;1,274.25,143.07,63.49,18.14">Aspect Based Background Document Retrieval for News Articles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FB3E30F0C626015064F9313F1758C620</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background information is essential for readers to understand news articles. Moreover, background information is often multi-faceted <ref type="bibr" coords="1,354.42,328.09,10.91,9.57" target="#b3">[4]</ref>, which introduces extra complexity to the problem of background retrieval. In this year's News Track, we explored how to build entity graphs on news articles to identify aspects, and leverage the aspects to retrieve background information. More specifically, given a query news article, the entities in it and their relations are used to build the entity graph, and aspects are extracted using community analysis. Subsequently, the discovered aspects are individually used to retrieve background news articles, and the per-aspect results are merged to form the final background article list for the query article.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>News Track organizers and journalists designed the News Track in collaboration with the purpose of identifying news readers' search needs as well as providing the test bed to investigate techniques for the needs. In this year's News Track, we focused on the background linking task of the track, which is designed for the information need of background information.</p><p>According to Fox, a professional journalist and editor, background information can be basic information of the news story, or connections between the story and other related ones <ref type="bibr" coords="1,508.76,581.82,11.71,10.48" target="#b3">[4]</ref>. In other words, there can be multiple aspects for the background information. Based on this, our effort this year centered around how to identify the aspects, and how to leverage the aspects to perform background information retrieval. For aspect identification, we hypothesized that entities are strong indicators of aspects in that different aspects involve different sets of entities. Moreover, the set of entities of an aspect tend to co-occur more often than entities from different aspects. Based on these hypotheses, we built an entity graph for each query article where nodes are entities and edges represent co-occurrences of the entities. We then employed community analysis <ref type="bibr" coords="1,228.76,697.39,12.36,10.48" target="#b1">[2]</ref> to segment the graph into aspects (or communities in the context of community analysis). For background retrieval of a single aspect, two methods were tested which are different in terms of the text representations of aspects used for retrieval. One method used only entities. However, in addition to entities, the other method used non-entity words surrounding them as well. Finally, we merged results of aspects by assigning weights to aspects based on how related they are to the main story of the article. The score of a background article is computed as the weighted sum of its scores of all aspects. This score is subsequently used to rank the background articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Processing</head><p>Our data pre-processing steps are the same as our participating runs of the last two years. We first adopted the de-duplication method from Bimantara et al. <ref type="bibr" coords="2,415.23,228.68,11.71,10.48" target="#b0">[1]</ref>, which processed files in the lexical order of the file names. Documents were de-duplicated based on the document title, author name, and published date. In addition, articles belonging to "Opinion", "Letters to the Editor", and "The Post View" section were discarded in accordance with the guideline. An article that was not removed by the above steps was stored by its id, title, timestamp, and the aggregated text of all of its paragraphs.</p><p>For entity recognition, following the previous two years, DBpedia Spotlight <ref type="bibr" coords="2,472.92,322.58,12.36,10.48" target="#b2">[3]</ref> was used. DBpedia<ref type="foot" coords="2,116.87,335.41,4.23,6.99" target="#foot_0">1</ref> is a knowledge base that contains structured information about Wikipedia pages. There is a unique DBpedia entity corresponding to a Wikipedia page and therefore we use the term Wiki entity and DBpedia entity interchangeably in the rest of the paper. DBpedia Spotlight can automatically annotate DBpedia entities from the text of the articles in the collection, which accomplishes our entity annotation goal. The identified entities were subsequently replaced by their canonical forms (e.g. the form appears in DBpedia), which are also provided by the toolkit. For example, "the Red Planet" and "Mars" are all mapped to the canonical form "Mars". We hope that this would help us to more accurately match the entities in the query articles and background articles. The parameter "Confidence" of the tool is set to 0.5. We treat the identified entities, either single-term or multi-term, as single words and use the Indri <ref type="bibr" coords="2,230.22,481.48,12.36,10.48" target="#b4">[5]</ref> toolkit to index the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>As mentioned before, our aspect based method consists of three steps: aspect identification, individual aspect result retrieval, and aspect result merging. In order to identify aspects, entity graphs were built using the Wiki entities. Edges were added between entities cooccurring in paragraphs. The weights of the edges were determined by the word distances between them in paragraphs. More specifically, the word distance between two entities e 1 and e 2 in a paragraph p was computed as:</p><formula xml:id="formula_0" coords="2,180.06,650.90,359.95,26.77">W (e 1 , e 2 , p) = 1 - 1 + # of words between e 1 , e 2 |p| ,<label>(1)</label></formula><p>where |p| is the length (i.e. the number of words) of the paragraph. The paragraph word distances of two entities in paragraphs that they co-occur were averaged to obtain the aggregated word distance, which was then used as the edge weight between e 1 and e 2 . The Louvain method proposed by Blondel et al. <ref type="bibr" coords="3,296.19,119.13,12.36,10.48" target="#b1">[2]</ref> was applied to the entity graph of the article to segment the graph into aspects. This method is designed for community analysis, which attempts to separate a weighted network into densely connected communities/sub-graphs. It accomplishes this by approximately optimizing modularity, which measures how edges are concentrated within communities instead of between them. It is clear that the method can segment entities following our intuition of grouping the entities co-occur often into the same aspects.</p><p>For individual aspect result retrieval, as mentioned earlier, we applied two methods which either used only entities of the aspects, or both entities and non-entity words surround them. The surrounding words were obtained by setting a word window of size ten, applying the window to each occurrence of the entities of an aspect to obtain spans of text, and extracting all non-entity words from the union of the spans. The union of the spans was used so that an occurrence of a non-entity word could only be counted once. It is important to note that, in the individual aspect result retrieval step, not all documents in the collection were scored. Instead, we first obtained a result list for each query article by using a baseline method, and only scored the articles in the result of the baseline method for different aspects. The baseline method used all words in the article as the retrieval query. The query then was searched against the collection. A time filter was applied to remove results published after the query article. The top 100 articles from the remaining result were then scored by the aspects with the two methods mentioned above. Using a baseline and performing re-ranking on its results is not only more efficient but also can be more effective if the baseline method is reasonably effective and can filter out irrelevant results. In fact, the baseline was indeed shown to be effective in previous years' News Tracks as one of the top performing runs. The baseline method will be referred to as "all words" in the remainder of the report, whereas the two aspect result retrieval methods are named as "aspect entities" and "aspect all words", respectively.</p><p>The final step of our method, which is aspect result merging, requires assigning weights to aspects. In order to do that, we first obtained the language model of an aspect by using the text spans of the aspect that were produced by the "aspect all words" method to extract all words, both entity and non-entity. Maximum likelihood estimation of the aspect language model was computed on the extracted words. The language model of the whole article was obtained similarly by applying maximum likelihood estimation on all words of the article.</p><p>We then computed the query likelihood of the aspect language model with respect to the article language model as the weight of the aspect. The rationale of it is that if it is very likely to observe the aspect from the whole article, it means that the aspect is important in discussing the mains story of the article, and therefore the aspect is more important and needs to be assigned with a higher weight. It is important to note that, after merging results of different aspects using such weights to obtain a score for each candidate document, we further combined this score with that from the "all word" baseline. The intuition behind this is that it could ensure the retrieved articles discuss the aspects in the sense that is related to the query article. Linear interpolation was used to combine these two scores and the weights for the scores from the baseline method and proposed methods were tuned on the last two years' data and were set as 0.7 and 0.3, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Run Description and Results</head><p>We submitted three runs, all of which employed language modeling with Dirichlet smoothing as the retrieval method. The first run is a baseline run called udel fang AW, which was implemented using the "all word" baseline. We also submitted two runs with the same aspect identification method and aspect result merging method, but different aspect background retrieval methods to test our idea of using aspects for background retrieval. The one using the "aspect entities" method is called udel fang CE, and the other one using "aspect all words" is called udel fang CW. The effectiveness of the submitted runs are reported in Table <ref type="table" coords="4,519.36,350.59,5.85,10.48" target="#tab_0">1</ref> as NDCG@5.</p><p>As can be seen, no improvements can be observed of runs with the proposed methods compared to the baseline method. Moreover, the effectiveness decreases slightly when both entity and non-entity words are used, though the difference is not statistically significant at the level of 0.05 using paired student t-test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year's News Track, we investigated identifying and using aspects in the query article to find background news articles. Although no benefits can be observed for the proposed methods, we believe this direction is still promising and plan to explore further in the future since there are potential improvements that can be applied to these methods. For instance, using all entities in an article to build the entity graph of the article for mining aspects might not be optimal since there are entities belonging to the main story other than the background aspects. Moreover, the weighting of aspects can be improved as well. Using the query likelihood of the aspect language model to the article language model might prioritize the aspects explained well in the article, which might not require additional information. However, readers might want to know more about the aspects that are mentioned but not discussed in detail in the original article.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,207.94,82.10,196.12,75.03"><head>Table 1 :</head><label>1</label><figDesc>NDCG@5 for submitted runs</figDesc><table coords="4,230.81,102.07,150.38,55.05"><row><cell>Method</cell><cell>NDCG@5</cell></row><row><cell>udel f ang AW</cell><cell>0.5437</cell></row><row><cell>udel f ang CE</cell><cell>0.5454</cell></row><row><cell>udel f ang CW</cell><cell>0.5292</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,89.93,690.67,112.17,8.74"><p>https://wiki.dbpedia.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,90.21,102.07,449.79,10.48;5,90.21,116.52,449.79,10.48;5,90.21,130.97,59.83,10.48" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,246.76,116.52,154.16,10.48">htw saar trec 2018 news track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bimantara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gerwert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gottschalk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lukosz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Piri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Shaft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,428.60,116.52,111.40,10.48;5,90.21,130.97,23.41,10.48">Proceedings of TREC 2018</title>
		<meeting>TREC 2018</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,90.21,152.63,449.79,10.48;5,90.21,167.08,449.79,10.48;5,90.21,181.53,73.65,10.48" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,400.44,152.63,139.57,10.48;5,90.21,167.08,105.88,10.48">Fast unfolding of communities in large networks</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">D</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Guillaume</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lambiotte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,205.03,167.08,283.95,10.48">Journal of statistical mechanics: theory and experiment</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">10008</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,90.21,203.20,449.78,10.48;5,90.21,217.64,449.78,10.48;5,90.21,232.09,200.49,10.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,352.20,203.20,187.80,10.48;5,90.21,217.64,150.80,10.48">Improving efficiency and accuracy in multilingual entity extraction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daiber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,272.07,217.64,267.93,10.48;5,90.21,232.09,158.82,10.48">Proceedings of the 9th International Conference on Semantic Systems (I-Semantics</title>
		<meeting>the 9th International Conference on Semantic Systems (I-Semantics</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,90.21,253.76,362.79,10.48" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,139.46,253.76,87.32,10.48">Writing the News</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Iowa State University Press</publisher>
		</imprint>
	</monogr>
	<note>3 edn.</note>
</biblStruct>

<biblStruct coords="5,90.21,275.42,449.79,10.48;5,90.21,289.87,449.79,10.48;5,90.21,304.32,263.24,10.48" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,375.41,275.42,164.60,10.48;5,90.21,289.87,173.28,10.48">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,294.20,289.87,245.81,10.48;5,90.21,304.32,96.76,10.48">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
