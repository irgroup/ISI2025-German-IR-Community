<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,73.98,115.13,464.04,16.15;1,228.54,137.04,154.92,16.15">PASH at TREC 2020 Deep Learning Track: Dense Matching for Nested Ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,104.17,184.57,65.48,11.50"><forename type="first">Yixuan</forename><surname>Qiao</surname></persName>
							<email>qiaoyixuan528@pingan.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,195.19,184.57,53.56,11.50"><forename type="first">Hao</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.35,184.57,48.61,11.50"><forename type="first">Liyu</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.55,184.57,66.16,11.50"><forename type="first">Liping</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,426.03,184.57,67.10,11.50"><forename type="first">Pengyong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,170.00,199.32,51.57,11.50"><forename type="first">Jun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.53,199.32,51.17,11.50"><forename type="first">Peng</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.66,199.32,43.45,11.50"><forename type="first">Yuan</forename><surname>Ni</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,349.06,199.32,67.06,11.50"><forename type="first">Guotong</forename><surname>Xie</surname></persName>
							<email>xieguotong@pingan.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Ping An Health Cloud Company Limited</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Ping An International Smart City Technology Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,73.98,115.13,464.04,16.15;1,228.54,137.04,154.92,16.15">PASH at TREC 2020 Deep Learning Track: Dense Matching for Nested Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">987E144E03FF8C22B70AF6D4A751EB9E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>dense retrieval</term>
					<term>transfer learning</term>
					<term>pre-trained language model</term>
					<term>multi-stage ranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the passage ranking task of TREC 2020 Deep Learning Track. We propose a Dense retriever by a BERT-based dual-encoder framework utilizing in-batch negatives corresponding to a list-wise ranking loss. To add an extra degree of difficulty, we redesign the pre-training tasks of BERT to absorb additional information rendered by Dense Retriever. After pre-trained with general knowledge and document-level data, we firstly fine-tune it with a strictly balanced binary data using a point-wise ranking strategy. Then we re-rank the top k passages using a fine-grained data by gradual unfreezing skill which form a Nested Ranking framework. In addition, further combined with traditional retrieval methods and ensemble learning, we obtain the competitive ranking results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In real-world scenarios, queries issued by users and passages compiled by editors are likely to use different styles of expressions for presenting the same meaning . It is the difference of thinking patterns that contribute to the well known query-passage mismatch problem. Traditional term-based methods, for instance different variants of TF-IDF and BM25 which can be viewed as representing the queries and passages as high-dimensional, sparse vectors (with weighting) are fundamentally powerless in cases where terms from the query and the passages don't match at all. Many studies have explored enriching query representations <ref type="bibr" coords="1,297.97,569.38,14.47,10.49" target="#b0">[1]</ref> or passage representations <ref type="bibr" coords="1,441.72,569.38,14.14,10.49" target="#b1">[2]</ref>, latent representation learning <ref type="bibr" coords="1,140.50,582.93,13.89,10.49" target="#b2">[3]</ref>, matching function learning <ref type="bibr" coords="1,292.37,582.93,13.88,10.49" target="#b3">[4]</ref>, and so forth which inspire us to learn a dense representation of query and passage using a dual-encoder framework for matching. One natural idea is to endow transformer-based structure especially BERT <ref type="bibr" coords="2,371.10,75.54,16.98,10.49" target="#b4">[5]</ref> as encoders due to their effectiveness across a range of domains like Natural Language Processing, Computer Vision <ref type="bibr" coords="2,503.25,89.09,14.43,10.49" target="#b5">[6]</ref> and Reinforcement Learning.</p><p>As such, it is quite natural that a wealth of research has been dedicated to making remarkable improvements to the BERT model over the past few years. Many of them redesign the Next Sequence Prediction (NSP) task deemed ineffective since its lack of difficulty compared to Masked Language Model (MLM) task. Some of them significantly improving performance on downstream tasks that require reasoning about the relationship between sentence pairs <ref type="bibr" coords="2,424.37,177.16,13.48,10.49" target="#b6">[7,</ref><ref type="bibr" coords="2,440.32,177.16,7.88,10.49" target="#b7">8]</ref>. But the fact easily ignored is, the available information to MLM has also changed accordingly which rarely analysised. To capture knowledge tailored for ranking task, we propose the Retrieval-Augmented Pre-training strategy, which augments NSP with a Dense Retriever. Our goals are clear, they include: (a) relieve the pressure of storing a surprising amount of world knowledge implicitly in the parameters of a ever-larger network; (b) allow the model to retrieve and attend over information really need; (c) explicitly contain the retrieved segment as a new category greatly bridge the gap between pre-training and fine-tuning.</p><p>Our approach turn ranking into a relevance classification problem where we sort candidate passages p i by P(relevant = 1|q, p i ) for a given query q in a retrieve-and-rank paradigm. An obvious extension of this design is to employ a multi-stage cascade architecture. A common practice often consists of multi-way matching <ref type="bibr" coords="2,240.75,332.98,15.86,10.49" target="#b8">[9]</ref> and multi-stage ranking <ref type="bibr" coords="2,375.56,332.98,20.34,10.49" target="#b9">[10]</ref> which exists widely in many industrial systems such as Search Engines and Recommender Systems. In addition to term-based BM25 and semantic-based Dense Retriever, we also implemente string-based method operates on word composition after stemming that measures similarity between query and passage for approximate string matching or comparison. In the course of second stage ranking, we transfer the knowledge of retrieval augmented ranker to a fine-grained re-ranker using annotated query passage pairs from Test set 2019. The re-ranker is applied in top K passages of ranked list generated by the ranker to get the final ranking result. For passage re-ranking task, we submit runs by integrating thirteen basic re-rankers and seven other attempts. For passage full ranking task, we further adopt the multi-way matching technique.</p><p>The rest of the paper is organized as follows: section 2 will introduce the details of our approach, including Dense Retriever, Retrieval Augmented Ranker and Fine-grained Re-ranker, section 3 and 4 will give experiment results and conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In this section, we sequentially describe the component in the nested ranking pipeline. The passage ranking task contains 1,010,916 queries on a collection of 8,841,823 passages, totally 532,761 query passage pairs annotated as positive for relevance. Few queries are matched with multiple relevant passages. NDCG metric with 3-level or 4-level judgements is the main official evaluation index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dense Retriever</head><p>Traditional information retrieval methods such as BM25 tend to focus on term-based matching which difficult in retrieving semantically correct answers. Inspired by DPR <ref type="bibr" coords="2,422.08,683.04,21.61,10.49" target="#b10">[11]</ref>, we learn the dense representation of query and passage by a dual-encoder framework capturing the semantic similarity in latent space which makes up the deficiency of the traditional sparse representation.</p><p>Encoders We use two independent BERT <ref type="bibr" coords="3,276.88,75.54,16.98,10.49" target="#b4">[5]</ref> models from Google pre-trained checkpoint(base, uncased) as initialization and use the output of [CLS] token to represent query or passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training data &amp; strategy</head><p>We apply an sample-efficient list-wise loss function in the case of only possess positive pairs.</p><formula xml:id="formula_0" coords="3,177.52,148.31,227.24,20.99">L (q i , p 1 , p 2 , • • • , p i , • • • , p n ) = -log e sim(q i ,p i )</formula><p>∑ n j=1 e sim(q i ,p j ) sim(q i , p j ) = BERT Q (q i ) BERT P (p j ) <ref type="bibr" coords="3,527.28,169.23,12.72,10.49" target="#b0">(1)</ref> This loss expects as input a batch consisting of query and passage pairs (q i , p 1 ), (q i , p 2 ), . . . , (q i , p n ) where we assume that (q i , p i ) are a positive pair and (q i , p j ) for i = j a negative pair. Moreover, for each given query, we add a negative passage retrieved by BM25 with highest score to improve performance. We choose simple inner product similarity function for fast indexing provided by FAISS <ref type="bibr" coords="3,96.89,269.16,19.91,10.49" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval Augmented Ranker</head><p>In this subsection, we describe the data and basic setup during the pre-training stage and finetuning stage of Ranker in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training Stage</head><p>We modify the pre-training tasks of BERT to absorb additional information rendered by Dense Retriever. Many previous studies argue that Next Sentence Predict (NSP) task is rather simplistic even useless so we switch it to a relatively difficult three-class classification task. Specifically, given a pair of segments (S 1 , S 2 ) as input, we predict whether S 2 is the retrieved segment closest to S 1 using Dense Retriever, or the next sentence that follow S 1 , or a random segment from a different document, under equal chance. Combined with original Masked Language Model (MLM) task, we firstly use BooksCorpus and English Wikipedia (19G) and then Document ranking dataset (22G) provided by TREC official as pre-training data to sequentially train the 24-layer BERT large architecture (L = 24, H = 1024, A = 16) optimized through mixed precision and distributed training. The latter uses the checkpoint of the former as initialization. We further use the LAMB optimizer that helps accelerate training using large minibatches. For each pre-training corpus, the model is pre-trained for approximately 8k updates with minibatches containing 65536 examples of maximum length 384 tokens. The whole pre-training process is performed on a distributed computing cluster consisting of 32 Telsa V100 GPU cards which takes about 15 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-tuning Stage</head><p>We use a trivial method constructing the training data for fine-tuning stage. In particular for each query that already has a positive (relevant) passage, we randomly sample a negative (not relevant) passage from passage pool composing a strictly balanced data set containing about 500k query-passage pairs. We represent the input sentence pairs as described in BERT, and use the final hidden vector C ∈ R H corresponding to the first input token ([CLS]) as the aggregate representation. The only new parameters introduced during fine-tuning are classification layer weights W ∈ R K×H , where K is set to 2. We compute a point-wise loss with C and W, i.e., log softmax CW T , fine-tune for 5 epochs with a learning rate of 2e-5 and a batch size of 32 performed on 4 Telsa V100 GPU cards which takes about 30 hours.</p><p>After fine-tuning the model, we run it on unseen queries and compute a relevance score for each candidate Top 1000 passage, and afterwards simply sort them in order to obtain the first phase of ranking results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Passage Re-ranking &amp; Ensemble</head><p>During Fine-tuning, we just have ground-truth label {0,1} namely {relevant, not relevant} and there is no discrimination among relevant passages. However, NIST refines it into three levels, namely perfect related, highly relevant and related leading to our Ranker suffers from a finetune-inference discrepancy. Therefore, we propose a fine-grained re-ranker acted on top K passages after Ranker to alleviate the mismatch status.</p><p>Fine-grained Re-ranker We employ the annotated query passage pairs from Test 2019 as training data. With the fine-tuned checkpoint of Ranker as a staring point, we replace the last layer with a random initialized 4-class classification layer while keeping other layers unchanged. Inspired by Gradual unfreezing <ref type="bibr" coords="4,180.07,208.15,19.49,10.49" target="#b12">[13]</ref>, we first unfreeze the last layer and fine-tune all unfrozen layers for one epoch. We then unfreeze the next lower frozen layer and repeat, until we fine-tune all layers until convergence at the last iteration. After full training, we apply it to top K passages ranked by Ranker to get the refined ranking result where K is selected based on the development set ranking accuracy. The score of the Re-ranker is added to the score of the previous Ranker.</p><p>Ensemble Diversity, that is, the difference among the individual learners is a fundamental issue in ensemble methods. Our ensemble strategy is based on average of probability scores from twenty Re-rankers with equally-weighted which acquires the best accuracy on the TEST 2019. Thirteen of them are initialized with different random seeds, others take different model structures or training data.</p><p>• On the aspect of the model structure, we also fine-tune ALBER-xxlarge, ELECTRA-Large and XLNet-Large model using the same training data as Ranker.</p><p>• We also use some novel but not powerful training data selected from a variety of attempts in the course of experiment, they include: a) Change the order of query and passage in the input representation.</p><p>b) Inspired by <ref type="bibr" coords="4,182.61,441.47,11.59,10.49" target="#b1">[2]</ref>, use T5 <ref type="bibr" coords="4,231.63,441.47,20.21,10.49" target="#b13">[14]</ref> as the expansion model to generate 5 pseudo queries then append to the original passage. c) Expand query by appending 3 queries generated by GNMT <ref type="bibr" coords="4,407.17,475.34,26.29,10.49" target="#b14">[15]</ref> which was trained to rephrase an input query into semantically similar queries.</p><p>d) Delete the words in passage that appear in query except stop words.</p><p>Although the performance of the above seven models are not as well performance as the Reranker, they do play an important role in final ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Passage Full Ranking &amp; Ensemble</head><p>To effectively address the query-passage mismatch challenge, we absorb the quintessence of the complementary characteristics in traditional and deep semantic matching methods before ranking and re-ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-way Matching</head><p>In our experiments, we use BM25+PRF <ref type="bibr" coords="4,373.27,638.53,24.21,10.49" target="#b15">[16]</ref> with tuned parameters k 1 = 0.82, b = 0.68. Compared to unigram features (i.e., on individual terms) such as BM25 scores, many n-gram features are better signals of relevance, but also more computationally expensive to compute, in both time and space. Therefore, we use string-based method compare the n-grams g n with n being 2, 3, and 4 between query and passage. Specifically, for (p i , q i ), we divide q i into several n-grams (consecutive word) with length n, and to determine whether g n is included in p i , a match scoring function can be written as:</p><formula xml:id="formula_1" coords="5,212.87,99.22,327.13,64.47">sim(p i , q i ) = exp( 4 ∑ n=2 w n log p n ) p n = ∑ g n ∈q i g n ∈p i count dist (g n ) ∑ g n ∈q i count(g n )<label>(2)</label></formula><p>Where count dist means that the same n-gram is calculated only once, and w n is the weight of ngram set to 1/3. A linear combination of multi-way matching scores or completely ignore scores further boosts retrieval effectiveness.</p><p>Ensemble Benefited from multi-way matching, we just sequentially train Rankers and Re-rankers with ten different random seeds for ensemble learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We submitted six official runs in both passage re-ranking and full ranking subtasks. Table <ref type="table" coords="5,505.23,300.37,5.45,10.49" target="#tab_0">1</ref> and<ref type="table" coords="5,534.55,300.37,5.45,10.49" target="#tab_1">2</ref> present the results of our all runs in which the former judges the passage on a four-point scale of Not Relevant (0), Related (1), Highly Relevant (2), and Perfect (3). Since "related" means that the passage is on-topic, but don't actually answer the question, it is treated as NOT relevant by Table <ref type="table" coords="5,531.82,341.02,4.09,10.49" target="#tab_1">2</ref>.</p><p>We use pash_r * to denote the runs for passage re-ranking, pash_f * for passage full ranking.  From the results, we can clearly see the remarkable performance of pash_r1 owing to retrieval augmented pre-training and nested ranking strategy. Under same circumstances, equipped with Dense Retriever (pash_f1) is even comparable to the best ensemble re-ranking results (pash_r3), which demonstrates the effectiveness of our dual-encoder framework by leveraging in-batch negatives. With the help of more different model strucures and training data forms, the experiments show that ensemble method can effectively improve performance of the ranking.</p><p>Table <ref type="table" coords="6,100.15,136.51,5.45,10.49" target="#tab_2">3</ref> and 4 shows the detailed performace distribution of pash_r3 and pash_f3 according to AP, NDCG@10, NDCG@1000 and RR. Other runs are provided in Appendix. The per-topic minimum, maximum, and median scores are achieved across 59 submitted runs from contestants. From the results, we observe that a large proportion of ranking predictions fall into the median to best region. Specifically, 87.0%, 90.7%, 79.6%, 88.9% for re-ranking subtask and 90.7%, 88.9%, 85.2%, 88.9% for full ranking subtask in terms of the four metrics respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose the dense retriever and retrieval augmented ranker for ad-hoc passage matching. We demonstrate that semantically-rich dense representation can outperform traditional term-based and string-based retrieval method. Multi-way matching is put into effect benefited from complementarity among them for best accuracy. We modify the pre-training task by giving model the ability to learn from additional retrieval augmented information especially to tackle ranking task. Fine-tuned with coarse and fine grained data make up our nested ranking framework. The experimental results show the effectiveness and high performance of our method. We believe that design highly transferable pre-training strategy will be a focus point of future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.53,378.61,342.95,148.68"><head>Table 1 :</head><label>1</label><figDesc>Ranking performance with 4-level judgements.</figDesc><table coords="5,134.53,404.93,342.95,122.37"><row><cell>RUN</cell><cell cols="4">RUN Description RNDCG NDCG@10 NDCG@1000</cell></row><row><cell cols="2">pash_r1 Single Model</cell><cell>0.6556</cell><cell>0.7463</cell><cell>0.6797</cell></row><row><cell cols="2">pash_r2 Ensemble Model</cell><cell>0.6919</cell><cell>0.8011</cell><cell>0.7020</cell></row><row><cell cols="2">pash_r3 Ensemble Model</cell><cell>0.6956</cell><cell>0.8031</cell><cell>0.7034</cell></row><row><cell>pash_f1</cell><cell>Single Model</cell><cell>0.6912</cell><cell>0.7956</cell><cell>0.7074</cell></row><row><cell cols="2">pash_f2  *  Single Model</cell><cell>0.6866</cell><cell>0.7941</cell><cell>0.7019</cell></row><row><cell>pash_f3</cell><cell>Single Model</cell><cell>0.6977</cell><cell>0.8005</cell><cell>0.7120</cell></row><row><cell cols="5">*  Due to our carelessness, pash_f2 is the same as pash_f1 just using a different random</cell></row><row><cell>seed.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,115.44,543.69,375.24,137.72"><head>Table 2 :</head><label>2</label><figDesc>Ranking performance with 3-level judgements.</figDesc><table coords="5,115.44,570.00,375.24,107.03"><row><cell>RUN</cell><cell>RUN Description</cell><cell>AP</cell><cell cols="3">R@1000 NDCG@10 NDCG@1000</cell></row><row><cell cols="2">pash_r1 Single Model</cell><cell cols="2">0.4969 0.7526</cell><cell>0.6896</cell><cell>0.6835</cell></row><row><cell cols="4">pash_r2 Ensemble Model 0.5420 0.7526</cell><cell>0.7589</cell><cell>0.7153</cell></row><row><cell cols="4">pash_r3 Ensemble Model 0.5445 0.7526</cell><cell>0.7628</cell><cell>0.7189</cell></row><row><cell>pash_f1</cell><cell>Single Model</cell><cell cols="2">0.5455 0.7667</cell><cell>0.7504</cell><cell>0.7186</cell></row><row><cell cols="2">pash_f2  *  Single Model</cell><cell cols="2">0.5389 0.7595</cell><cell>0.7513</cell><cell>0.7146</cell></row><row><cell>pash_f3</cell><cell>Single Model</cell><cell cols="2">0.5504 0.7708</cell><cell>0.7561</cell><cell>0.7252</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="5,116.65,670.67,2.42,6.37;5,121.90,672.79,357.64,8.63"><p>* Due to our carelessness, pash_f2 is the same as pash_f1 just using a different random seed.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,168.93,228.30,274.13,106.55"><head>Table 3 :</head><label>3</label><figDesc>Performace distribution of pash_r3.</figDesc><table coords="6,168.93,254.62,274.13,80.23"><row><cell>Evaluation</cell><cell cols="4">AP NDCG@10 NDCG@1000 RR</cell></row><row><cell>Best</cell><cell>7</cell><cell>11</cell><cell>4</cell><cell>48</cell></row><row><cell>Best to Median</cell><cell>40</cell><cell>38</cell><cell>39</cell><cell>0</cell></row><row><cell>Median</cell><cell>4</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>Median to Worst</cell><cell>3</cell><cell>2</cell><cell>7</cell><cell>1</cell></row><row><cell>Worst</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,168.93,357.32,274.13,106.55"><head>Table 4 :</head><label>4</label><figDesc>Performace distribution of pash_f3.</figDesc><table coords="6,168.93,383.64,274.13,80.23"><row><cell>Evaluation</cell><cell cols="4">AP NDCG@10 NDCG@1000 RR</cell></row><row><cell>Best</cell><cell>4</cell><cell>14</cell><cell>5</cell><cell>46</cell></row><row><cell>Best to Median</cell><cell>45</cell><cell>34</cell><cell>41</cell><cell>2</cell></row><row><cell>Median</cell><cell>2</cell><cell>4</cell><cell>2</cell><cell>4</cell></row><row><cell>Median to Worst</cell><cell>3</cell><cell>2</cell><cell>6</cell><cell>2</cell></row><row><cell>Worst</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,94.06,650.14,445.94,9.71;7,94.05,662.09,274.17,9.71" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,296.51,650.27,189.61,9.58">Brown university at trec deep learning 2019</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,505.69,650.14,34.31,9.50;7,94.05,662.09,210.42,9.50">Proceedings of the Twenty-Eighth Text REtrieval Conference</title>
		<meeting>the Twenty-Eighth Text REtrieval Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,94.06,680.82,445.94,9.71;7,94.05,692.78,104.60,9.71" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,284.58,680.95,185.04,9.58">Document expansion by query prediction</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08375</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,94.06,711.51,445.94,9.71;8,94.05,76.05,445.95,9.71;8,94.05,88.14,391.36,9.58" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,174.16,711.64,361.48,9.58">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,107.34,76.05,432.66,9.50;8,94.05,88.14,40.99,9.58">Proceedings of the 22nd ACM International Conference on Information amp; Knowledge Management, CIKM &apos;13</title>
		<meeting>the 22nd ACM International Conference on Information amp; Knowledge Management, CIKM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.06,106.74,403.50,9.71" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="8,199.35,106.87,124.77,9.58">Passage re-ranking with bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,94.06,125.60,445.95,9.58;8,94.05,137.42,445.94,9.71;8,94.05,149.38,445.95,9.50;8,94.05,161.46,76.37,9.58" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,335.27,125.60,204.73,9.58;8,94.05,137.55,122.31,9.58">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,239.13,137.42,275.24,9.50">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s" coord="8,444.30,149.38,87.47,9.50">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.06,180.06,445.94,9.71" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,165.19,180.19,200.99,9.58">End-to-end object detection with transformers</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12872</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,94.06,198.79,445.95,9.71;8,94.05,210.75,332.36,9.71" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,170.53,198.92,369.47,9.58;8,94.05,210.88,62.83,9.58">Structbert: Incorporating language structures into pre-training for deep language understanding</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,176.95,210.75,217.92,9.50">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.06,229.48,445.94,9.71;8,94.05,241.43,193.84,9.71" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,148.30,229.61,320.35,9.58">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,486.87,229.48,53.13,9.50;8,94.05,241.43,162.30,9.50">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.06,260.16,445.94,9.71;8,94.05,272.12,104.60,9.71" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,181.23,260.29,277.17,9.58">Cold: Towards the next generation of pre-ranking system</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.16122</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,94.05,290.85,445.95,9.71;8,94.05,302.80,104.60,9.71" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14424</idno>
		<title level="m" coord="8,288.28,290.98,180.48,9.58">Multi-stage document ranking with bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,94.05,321.53,445.95,9.71;8,94.05,333.49,104.60,9.71" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,190.37,321.66,276.33,9.58">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,94.05,352.22,445.95,9.71;8,94.05,364.17,51.46,9.71" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,251.40,352.35,174.52,9.58">Billion-scale similarity search with gpus</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,435.23,352.22,104.77,9.50;8,94.05,364.17,19.92,9.50">IEEE Transactions on Big Data</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.05,382.90,445.95,9.71;8,94.05,394.86,445.95,9.71;8,94.05,406.94,29.05,9.58" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,199.84,383.03,261.54,9.58">Universal language model fine-tuning for text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,481.85,382.90,58.15,9.50;8,94.05,394.86,301.81,9.50">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.05,425.54,445.95,9.71;8,94.05,437.50,190.58,9.71" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,160.00,425.67,341.91,9.58">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,510.11,425.54,29.89,9.50;8,94.05,437.50,121.68,9.50">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,94.05,456.23,445.95,9.71;8,94.05,468.18,245.57,9.71" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,150.46,456.36,389.54,9.58;8,94.05,468.31,71.96,9.58">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,94.05,486.91,445.95,9.71;8,94.05,498.87,87.44,9.71" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,180.61,487.04,297.66,9.58">Bm25 pseudo relevance feedback using anserini at waseda university</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,496.02,486.91,43.98,9.50;8,94.05,498.87,23.75,9.50">OSIRRC@ SIGIR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
