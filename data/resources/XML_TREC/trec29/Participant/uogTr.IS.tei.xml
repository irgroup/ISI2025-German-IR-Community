<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,111.17,84.23,389.65,15.44;1,171.46,104.15,269.06,15.44">Exploratory Undersampling for Class-Imbalance Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
				<availability status="unknown"><p>Copyright Institute of Electrical and Electronics Engineers (IEEE)</p>
				</availability>
				<date type="published" when="2009-04">2009-04</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><surname>Xu-Ying Liu</surname></persName>
						</author>
						<author>
							<persName><surname>Jianxin Wu</surname></persName>
						</author>
						<author>
							<persName><surname>Zhi-Hua Zhou</surname></persName>
						</author>
						<title level="a" type="main" coord="1,111.17,84.23,389.65,15.44;1,171.46,104.15,269.06,15.44">Exploratory Undersampling for Class-Imbalance Learning</title>
					</analytic>
					<monogr>
						<title level="j" type="main">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</title>
						<title level="j" type="abbrev">IEEE Trans. Syst., Man, Cybern. B</title>
						<idno type="ISSN">1083-4419</idno>
						<imprint>
							<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
							<biblScope unit="volume">39</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="539" to="550"/>
							<date type="published" when="2009-04" />
						</imprint>
					</monogr>
					<idno type="MD5">6EFBAC5F881D16036AE453DE26AEFD6B</idno>
					<idno type="DOI">10.1109/tsmcb.2008.2007853</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe runs submitted on behalf of the University of Glasgow Terrier Team (uogTr) for the TREC 2020 Incident Streams track. We detail our approach to addressing the challenges present in the classification of crisis and disaster management data in unstructured text. In particular, we explore the usage of pretrained ELMo embeddings alongside descriptive metadata-level and event-level features for classification. We also utilise algorithms incorporating undersampling techniques in order to mitigate the significant class imbalance in the dataset. We submitted a total of three official runs to the 2020A track: ELMO_ALL_BRF, ELMO_ALL_EEC, and ELMO_ALL_TFIDF_BRF with varying features and classifiers used. Our results show that our run, ELMO_ALL_BRF shows competitive performance, performing above the median across a number of track-specific metrics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The Terrier team (uogTr) at the University of Glasgow participated in the TREC 2020 Incident Streams track. We experimented with a variety of approaches and features that resulted in three official submitted runs to the 2020A edition of the track, and an unsubmitted run for the 2020B edition of the track. In particular, we explore the complexities of classification for crisis and disaster datasets as part of ongoing work into event-centric information extraction. We approached the problem by leveraging advances made in deep, contextual word representations and utilised ELMo <ref type="bibr" coords="1,234.92,462.18,13.64,4.09" target="#b4">[5]</ref> embeddings to generate word embeddings for tweets. We use these per-word embeddings via average pooling to produce a single embedding for each tweet. Following an analysis of the characteristics of actionable tweets in the dataset, we also incorporated the use of a pretrained entity recognition pipeline to identify location information within the tweet. Furthermore, we leveraged associated tweet and event metadata to produce a number of numerical and eventlevel features, the latter of which proved to be especially valuable in disambiguating actionable information from general discussion. For learning methods, we experimented with both Balanced Random Forest <ref type="bibr" coords="1,76.20,582.73,11.20,4.09" target="#b0">[1]</ref> and EasyEnsemble <ref type="bibr" coords="1,157.79,582.73,12.83,4.09" target="#b2">[3]</ref> models, which both use random undersampling during training, to address the significant class imbalance present in the dataset.</p><p>The remainder of this paper is structured as follows: Section 2 will discuss the features created from the tweet text and the preprocessing steps therein; Section 3 will discuss the numeric features present in our work, generated from tweet metadata and the transformation steps we carried out to achieve this; Section 5 outlined our submitted runs for the 2020A edition of the track; Section 6 details our results compared with the median and best-performing results; Section 7 includes a brief discussion of those results; and Section 8 includes our concluding remarks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TEXT-BASED FEATURES</head><p>Our approach is inspired by an analysis of the Critical tweets present in the 2019B dataset by McCreadie et al. <ref type="bibr" coords="1,497.30,403.23,9.41,4.09" target="#b3">[4]</ref>. As shown in the Table <ref type="table" coords="1,354.35,414.19,4.23,4.09" target="#tab_0">1</ref> below that summarizes the outcome of that work, we observe that the majority (97%) of tweets contained terms and/or phrases that indicate actionable information was embedded in the text content. Users on Twitter are constrained to a maximum of 280 characters per tweet and as such, tweets often contain contractions, abbreviations, and colloquial language in order for users to express themselves within these restrictions. Hence, we normalise our text and utilise external dictionaries to reduce our embedding space as much as possible, specifically, a slang dictionary and a contraction dictionary. We use pretrained, high-dimensional ELMo word embeddings to more accurately capture the complex syntax and semantics often found in short text representations. These embeddings then go through an average pooling process to produce a single, document vector for each tweet. Prior to this, mentions, URLs, and text containing over two identical consecutive characters were removed during preprocessing. Hashtags were left as they appeared in the original text, as they are often used in conjunction with other hashtags or relevant tokens to identify latent topics.</p><p>In order to further enrich our training feature vector, we must examine what is present within the text that distinguishes these tweets from those that are less critical to emergency response.</p><p>Location is explicitly mentioned in 88% of Critical priority tweets, so we incorporated a named entity recognition module to create a binary representation of the presence of a location mentioned within the tweet text; to achieve this, we use a pre-trained named entity recognition pipeline provided by the SparkNLP 1 package. We found that the addition of this binary feature provided a significant boost in the performance of each run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NUMERICAL FEATURES</head><p>We generate a number of numeric features from additional metadata provided by the JSON structure of each tweet as follows:</p><p>‚Ä¢ The number of hashtags present ‚Ä¢ The presence of URLs (binary)</p><p>‚Ä¢ The presence of additional media elements such as pictures and videos (binary)</p><p>We also incorporate an event-level feature found in the per-topic metadata files supplied by the track. The training data provided by the Incident Streams track is split by events, and each event corresponds to a type within a provided in the topics file, which provides extended metadata on each event. The types present across both training and test sets are: earthqake, flood, typhoon, wildfire, shooting, bombing. We leveraged this information to include a one-hot encoded feature representing each event subtype.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head><p>Our models were trained on the 2019A, and 2019B datasets from previous editions of the track. This collection consists of 15,673 tweets after cleaning and filtering stages. We approach the Information Type classification task as a multi-label classification problem.</p><p>As such, we transform our multi-label classification problem with ùëõ labels into ùëõ separate, binary classification problems using each of the aforementioned models as our base classifier. Throughout experimentation, we maintain the following hyperparameters: In this case of Balanced Random Forest, we set the number of estimators (n_estimators) to 100, no limit on the max depth of the tree (max_depth); in the case of our EasyEnsemble classifier, we set our number of estimators n_estimators) to 10 and set warm_start to False, which results in fitting an entirely new ensemble at each step of the algorithm. The implementations of these models are provided by the imbalanced-learn 2 Python package.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SUBMITTED AND UNSUBMITTED RUNS</head><p>Considering the aforementioned features, we structure our experimentation in order to address the following research questions:</p><p>(1) Is there significant difference in performance between employing the use of Balanced Random Forest and EasyEnsemble classifiers? (2) Does the inclusion of average pooled TF-IDF vectors to represent each document benefit overall classification performance?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Submitted Runs</head><p>The maximum number of submissions a participant can make to the track is four and as such, a total of three separate runs were submitted to the first two tasks of 2020A edition of the track:</p><p>(1) ELMO_ALL_BRF: Our first submitted run uses the Balanced Random Forest algorithm developed by Chen et al. <ref type="bibr" coords="2,265.94,671.82,9.06,4.09" target="#b0">[1]</ref>. It is an adaption of the Random Forest algorithm and attempts 2 https://imbalanced-learn.org to balance the tree at each step of the algorithm by undersampling from the majority class, we utilise this to mitigate the influence and effect of lower criticality, irrelevant tweets that are disproportionately common in our data. (2) ELMO_ALL_EEC: Our second run is very similar to our first in that it includes the same set of features. However, it uses the boosting algorithm EasyEnsemble developed by Liu et al. <ref type="bibr" coords="2,351.71,166.29,9.35,4.09" target="#b2">[3]</ref> which uses a combination of AdaBoost <ref type="bibr" coords="2,499.72,166.29,12.32,4.09" target="#b1">[2]</ref> learners and undersampling to generate synthetic samples characteristic of those belonging to our minority classes and to randomly undersample those from majority classes. (3) ELMO_ALL_TFIDF_BRF: Noticing a performance increase with Balanced Random Forest, we decided to submit a third run using the same algorithm. We decided to include an additional average pooled TF-IDF vector in the hopes of mitigating the drop in accuracy of our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>Table <ref type="table" coords="2,339.79,292.32,4.18,4.09" target="#tab_1">2</ref> reports the performance of our submitted runs in comparison to the TREC Best and Median systems. We abbreviate each track metric as follows: "HAAW" means High Priority Accumulated Alert Worth, "AAAW" means Accumulated Alert Worth (All), "ITAct" means Information Type Positive F1-score (Actionable), "ITAll" means Information Type Positive F1-score (All), "ITAcc" means Information Type Accuracy, "PAct" means Priority F1-score (Actionable), and "PAll" means Priority F1-score (All). An analysis of the results table (Table <ref type="table" coords="2,471.42,379.99,3.49,4.09" target="#tab_1">2</ref>) shows that the introduction of a TF-IDF feature in elmo_all_tfidf_brf seemed to be more effective in alerting the user of relevant posts. It also outperformed other runs in overall Information Type Accuracy, suggesting that this approach creates a better, general representation of the underlying data. However, this run fell short in terms of classifying the criticality of tweets, both actionable and overall. Our Balanced Random Forest approach seems to generally outperform our EasyEnsemble classifier across the board, however EasyEnsemble seems to be slightly more performant in overall alerting. We notice both algorithms struggle from a particularly low type categorisation accuracy, and upon further inspection, it seems our system is overly generous when assigning relevant labels to any single tweet. As expected, overall accuracy from each submission increases with the reduced set of information type labels. However, we notice that this brings a significant decrease in both information type and priority F1-score across the board. Despite the increase in performance across ranking and alerting metrics, the inclusion of a TF-IDF-based document vector negatively impacts our type categorisation and priority estimation scores in the first task. Interestingly, this is not reflected in the second task, suggesting that the benefit of this additional feature is lost as the number of labels increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>Comparison with other methods. Our proposed method is amongst the top scoring methods submitted to the 2020A edition of the track. Our TF-IDF run with Balanced Random Forest is the second highest scoring method for the first task with regard to alerting metrics (for both high and low priority tweets), as is our baseline Balanced Reflections on proposed method. Given the significant boost in performance with the addition of event types as a feature during training, we would like to experiment with the inclusion of more general event-level information for each tweet. We would also like to investigate the use of entity linkage with external sources to enrich the knowledge of the model during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS</head><p>In this paper, we proposed a method of classifying crisis and disaster tweets to assist emergency response. We confirmed its effectiveness via evaluation in the 2020A edition of the TREC Incident Streams track. Building on and further developing the quality of our runs by leveraging external datasets on crises, and experimenting with various complementary tasks is something we have left for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,317.66,175.42,242.15,172.04"><head>Table 1 :</head><label>1</label><figDesc>Statistics for what makes a tweet critical from analysis of the 2019-B critical tweets. Reconstructed from<ref type="bibr" coords="1,535.91,339.77,10.44,7.70" target="#b3">[4]</ref>.</figDesc><table coords="1,330.30,175.42,215.40,138.42"><row><cell>Source</cell><cell>Information</cell><cell>#Tweets</cell><cell>%</cell></row><row><cell>Tweet Text</cell><cell>Terms/Phrases</cell><cell>164</cell><cell>97%</cell></row><row><cell></cell><cell>Location</cell><cell>150</cell><cell>88%</cell></row><row><cell></cell><cell>Event Mention</cell><cell>34</cell><cell>20%</cell></row><row><cell></cell><cell>Time Mention</cell><cell>10</cell><cell>6%</cell></row><row><cell></cell><cell>Person Mention</cell><cell>10</cell><cell>6%</cell></row><row><cell>Linked Content</cell><cell>Article/Web Page</cell><cell>83</cell><cell>49%</cell></row><row><cell></cell><cell>Tweet</cell><cell>21</cell><cell>12%</cell></row><row><cell></cell><cell>Image</cell><cell>8</cell><cell>5%</cell></row><row><cell></cell><cell>Video</cell><cell>5</cell><cell>3%</cell></row><row><cell>Author</cell><cell>Name/Username</cell><cell>7</cell><cell>4%</cell></row><row><cell>Regional Context Needed</cell><cell></cell><cell>42</cell><cell>25%</cell></row><row><cell>Tweet is Out of Date</cell><cell></cell><cell>41</cell><cell>24%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,53.48,85.73,482.59,280.72"><head>Table 2 :</head><label>2</label><figDesc>TREC-IS Performance on the 2020-A eventsRandom Forest run for the Priority F1-score over actionable classes. As mentioned previously, our accuracy is among the lowest in the table. This is something we hope to rectify in future editions of the track by experimenting with different feature generation methods and algorithm decisions.</figDesc><table coords="3,75.93,109.04,460.14,186.52"><row><cell></cell><cell></cell><cell cols="3">Task 1: 25 Information Types</cell></row><row><cell>Run</cell><cell></cell><cell></cell><cell>Ranking</cell><cell>Alerting</cell><cell>Type Categorization</cell><cell>Priority</cell></row><row><cell>ID</cell><cell cols="2">Learner Text Encoding</cell><cell cols="3">NDCG HAAW AAAW ITAct ITAll ITAcc</cell><cell>PAct</cell><cell>PAll</cell></row><row><cell>TREC Best</cell><cell>-</cell><cell>-</cell><cell>0.4866</cell><cell cols="2">0.2121 -0.0847 0.1674 0.2089 0.9403 0.2642 0.2800</cell></row><row><cell>TREC Median</cell><cell>-</cell><cell>-</cell><cell>0.4235</cell><cell cols="2">-0.4488 -0.2451 0.0792 0.1380 0.8978 0.1524 0.2076</cell></row><row><cell cols="2">elmo_all_2020_brf BRF</cell><cell>ELMO</cell><cell>0.4212</cell><cell cols="2">-0.2628 -0.2028 0.0933 0.1438 0.7502 0.2630 0.2575</cell></row><row><cell cols="2">elmo_all_2020_eec EE</cell><cell>ELMO</cell><cell>0.4235</cell><cell cols="2">-0.2674 -0.1863 0.0769 0.1371 0.7284 0.2076 0.2351</cell></row><row><cell>elmo_all_tfidf</cell><cell>BRF</cell><cell>TF-IDF+ELMO</cell><cell>0.4301</cell><cell cols="2">-0.2090 -0.1705 0.0884 0.1380 0.7529 0.1651 0.1929</cell></row><row><cell></cell><cell></cell><cell cols="3">Task 2: 12 Information Types</cell></row><row><cell>Run</cell><cell></cell><cell></cell><cell>Ranking</cell><cell>Alerting</cell><cell>Type Categorization</cell><cell>Priority</cell></row><row><cell></cell><cell cols="2">Learner Text Encoding</cell><cell cols="3">NDCG HAAW AAAW ITAct ITAll ITAcc</cell><cell>PAct</cell><cell>PAll</cell></row><row><cell>TREC Best</cell><cell>-</cell><cell>-</cell><cell>0.4864</cell><cell cols="2">0.2121 -0.0847 0.1695 0.2079 0.9535 0.2077 0.2612</cell></row><row><cell>TREC Median</cell><cell>-</cell><cell>-</cell><cell>0.3919</cell><cell cols="2">-0.5101 -0.2598 0.0563 0.0886 0.8773 0.1187 0.1417</cell></row><row><cell cols="2">elmo_all_2020_brf BRF</cell><cell>ELMO</cell><cell>0.4222</cell><cell cols="2">-0.2628 -0.2028 0.0933 0.1113 0.8035 0.1821 0.1672</cell></row><row><cell cols="2">elmo_all_2020_eec EE</cell><cell>ELMO</cell><cell>0.4235</cell><cell cols="2">-0.2674 -0.1863 0.0770 0.993 0.7835 0.1370 0.1612</cell></row><row><cell>elmo_all_tfidf</cell><cell>BRF</cell><cell>TF-IDF+ELMO</cell><cell>0.4297</cell><cell cols="2">-0.2090 -0.1705 0.0881 0.1036 0.8072 0.1737 0.1913</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,324.49,704.18,86.45,3.18"><p>https://nlp.johnsnowlabs.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>We would like to thank the organisers of the <rs type="affiliation">TREC Incident Streams track</rs> for providing datasets, evaluating our work, and facilitating a community around the role of information retrieval in crisis and emergency management.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="3,330.15,430.01,228.05,3.18;3,330.15,436.54,138.71,6.23" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,434.68,430.01,123.51,3.18;3,330.15,437.98,12.00,3.18">Using Random Forest to Learn Imbalanced Data</title>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-01">2004. 01 2004</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.15,445.95,217.63,3.18" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<title level="m" coord="3,452.24,445.95,92.56,3.18">A Short Introduction to Boosting</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.15,453.92,228.05,3.18;3,330.15,460.45,228.49,6.23;3,330.15,469.86,191.17,3.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,423.17,453.92,135.03,3.18;3,330.15,461.89,23.56,3.18">Exploratory Undersampling for Class-Imbalance Learning</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMCB.2008.2007853</idno>
		<ptr target="https://doi.org/10.1109/TSMCB.2008.2007853" />
	</analytic>
	<monogr>
		<title level="j" coord="3,359.06,460.45,199.58,6.23">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="539" to="550" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.15,477.83,228.87,3.18;3,329.90,484.36,228.30,6.23;3,330.15,490.67,228.88,6.23;3,329.93,500.08,74.95,3.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,495.77,477.83,63.25,3.18;3,329.90,485.80,123.09,3.18">Incident Streams 2019: Actionable Insights and How to Find Them</title>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cody</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<ptr target="http://eprints.gla.ac.uk/210955/" />
	</analytic>
	<monogr>
		<title level="m" coord="3,466.16,484.36,92.05,6.23;3,330.15,490.67,207.49,6.23">17th International Conference on Information Systems for Crisis Response and Management (ISCRAM 2020)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,330.15,508.05,228.82,3.18;3,330.15,516.02,229.23,3.18;3,330.15,522.55,229.13,6.23;3,330.15,531.96,16.21,3.18" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="3,449.76,516.02,109.62,3.18;3,330.15,523.99,13.30,3.18">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<ptr target="http://arxiv.org/abs/1802.05365" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
