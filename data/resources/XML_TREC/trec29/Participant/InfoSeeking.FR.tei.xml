<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,97.33,99.67,417.34,14.93;1,242.16,119.60,127.69,14.93">UNIVERSITY OF WASHINGTON AT TREC 2020 FAIRNESS RANKING TRACK</title>
				<funder>
					<orgName type="full">US National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,164.34,185.61,50.59,8.96"><forename type="first">Yunhe</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,224.38,185.61,56.19,8.96"><forename type="first">Daniel</forename><surname>Saelid</surname></persName>
							<email>saeliddp@uw.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,290.02,185.61,23.83,8.96"><forename type="first">Ke</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName coords="1,323.30,185.61,58.96,8.96"><forename type="first">Ruoyuan</forename><surname>Gao</surname></persName>
							<email>ruoyuan.gao@rutgers.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.71,185.61,53.98,8.96"><forename type="first">Chirag</forename><surname>Shah</surname></persName>
							<email>chirags@uw.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,97.33,99.67,417.34,14.93;1,242.16,119.60,127.69,14.93">UNIVERSITY OF WASHINGTON AT TREC 2020 FAIRNESS RANKING TRACK</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F282D64C9B9C35D9EA144D1ECBD94AD9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fair Ranking</term>
					<term>Text Retrieval</term>
					<term>Fair Exposure</term>
					<term>Information Retrieval</term>
					<term>Fairness</term>
					<term>Ranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>InfoSeeking Lab's FATE (Fairness Accountability Transparency Ethics) group at University of Washington participated in 2020 TREC Fairness Ranking Track. This report describes that track, assigned data and tasks, our group definitions, and our results. Our approach to bringing fairness in retrieval and re-ranking tasks with Semantic Scholar data was to extract various dimensions of author identity. These dimensions included gender and location. We developed modules for these extractions in a way that allowed us to plug them in for either of the tasks as needed. After trying different combinations of relative weights assigned to relevance, gender, and location information, we chose five runs for retrieval and five runs for re-ranking tasks. The results showed that our runs performed below par for re-ranking task, but above average for retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As one of the emerging topics in fairness-aware information systems, presenting relevant results to the users while ensuring fair exposure of the content suppliers have raised more and more attention. Fairer information retrieval and search systems not only provide relevant search results with higher diversity and transparency, but also offer reasonable discoverability for underrepresented groups. For example, a high-quality academic paper from small institutions and universities, which have very limited media outlets and resources, should also be treated equally to get its deserved exposures in search systems, especially at the early stage of publication when such papers are more likely to suffer from cold-start problems.</p><p>The TREC 2020 Fairness Track <ref type="bibr" coords="1,204.36,546.70,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="1,218.26,546.70,8.30,8.64" target="#b1">2]</ref> initiated the task of fairness ranking within an academic search task context, where the goal was to provide fair exposure of different groups of authors while maintaining good relevance of the ranked papers regarding given queries. However, it is difficult to achieve such a goal due to the following challenges.</p><p>• Openness and complexity of defining the author group. Defining the author group is not a trivial task. This requires an in-depth understanding of what should be considered as important group attributes that not only separate different authors but also aggregate similar authors. The challenges in this task include and are not limited to, how many groups should be identified, how to identify and extract the features from authors and their publications for the group classification task, and what algorithm to use for effective and efficient classification. • Algorithm Robustness on different applications. The definition of author groups may change from application to application. A good fairness ranking algorithm should be robust to a broad range of group definitions in various scenarios. In other words, fairness-aware ranking algorithms should demonstrate a high generalization capability when processing application-wise group definitions. • Dynamics of information retrieval given varying group definitions. The task of retrieving relevant documents requires a good representation of each group. It is still an open question of how to effectively select a pool of relevant candidates that also covers a broad range of author groups with varying group definitions.</p><p>• Trade-off between relevance and fairness. The re-ranking algorithm based on a list of candidate items needs to optimize for both the relevance of the re-ranked results and the fairness of the exposed author groups, while carefully balancing between the two.</p><p>At TREC 2020 fairness ranking track, we aimed to design and implement fairly ranking and retrieval algorithms to enhance the fairness for scholarly search. On the subset of the Semantic Scholar (S2) Open Corpus<ref type="foot" coords="2,470.92,128.47,3.49,6.05" target="#foot_0">1</ref>  <ref type="bibr" coords="2,477.65,130.14,11.62,8.64" target="#b2">[3]</ref> provided by the Allen Institute for Artificial Intelligence, we defined multiple author groups, inferred demographic characteristics of authors, and developed fairness-aware algorithms to achieve a flexible trade-off between relevance and fairness by tuning principal component weights. Specifically, we participated in two tasks: (1) retrieval task where the goal was to return a ranked list of papers to serve as the candidate papers for re-ranking; (2) re-ranking task where the goal was to rank the candidate papers based on the relevance to a given query, while accounting for the fair author group exposure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Description and Storage</head><p>The Semantic Scholar (S2) Open Corpus used in TREC 2020 fairness ranking track consists of extracted fields of academic papers. For most papers, the available fields include the S2 paper ID, title, abstract, authors, inbound and outbound citations. The S2 corpus subset available to participants for training and testing consisted of 8,879 academic papers in total. A given paper was associated with a unique S2 identifier, which we used as a key for querying purposes. Beyond the identifier, a given paper could have non-empty data for any subset of the set of fields found at http://api.semanticscholar.org/corpus/ <ref type="bibr" coords="2,283.00,292.10,10.58,8.64" target="#b2">[3]</ref>. For re-ranking purposes, the following fields are likely most pertinent: title, abstract, author list, in-citations, out-citations, fields of study, journal name, journal volume, year of publication, and venue of publication. Authors in the author list are identified by name and one or more unique author IDs. The lists of in-citations and out-citations are simply collections of S2 identifiers referring to other papers in the sub-corpus.</p><p>We chose to upload the full sub-corpus to an AWS DynamoDB database for querying and processing. This NoSQL approach was appropriate because we only needed to query the documents by S2 identifiers. Figure <ref type="figure" coords="2,469.45,363.03,4.98,8.64" target="#fig_0">1</ref> shows the snapshots of Authors JSON data, and In-Citations JSON data returned by Amazon DynamoDB during a query operation. The TREC organizers also provided three CSV files. One consisted of paper ids and a list of corresponding author positions with their corpus id. Another one contained paper information such as paper id, title, year of publication, venue, number of citations, and number of key citations. The other one mapped author IDs to a few features: author's name, number of citations, h-index (and a dependent feature, h-class), i10-Index, and number of papers published.</p><p>For the 31,975 authors included in the sub-corpus of papers, we constructed a similar DynamoDB database. Using these two databases in tandem, we could extract the author group characteristics for a given paper.</p><p>We also received a training sample with the same JSON format as the evaluation data for training purposes. Each JSON line contained the query id, query name, frequency, and a list of document ids. For each document in the document list, we had its document id and a binary relevance score (0 or 1). As described by TREC, the relevance score was extracted from real-time traffic. That means if a person queries the corpus and clicks on one of the results, that selected document's relevance score will be set to 1. And the other documents that are not being chosen will be considered irrelevant to the query. The evaluation data has the same format except that we do not have the relevance score for each document in the evaluation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>We first defined author groups based on general demographic characteristics including genders and countries (see below for details). Then, we utilized Okapi BM25 <ref type="bibr" coords="3,283.37,295.42,11.62,8.64" target="#b3">[4]</ref> to estimate the relevance of papers to given search queries.</p><p>Based on the group definition and BM25 relevance score, we proposed our fairness-aware re-ranking algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Group Definition</head><p>When defining author groups, we considered genders and countries of authors because the two demographic features are general enough for different applications. Re-ranking algorithms based on such group definitions are more likely to demonstrate strong robustness in various scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Gender Inference</head><p>To predict the binary gender of a given author, we called the genderize.io API 2 <ref type="bibr" coords="3,383.77,415.92,10.58,8.64" target="#b4">[5]</ref>, which is powered by a large dataset that maps first names to binary genders. Given a name, genderize.io will return 'male' if there are more instances of the name associated with men, and it will return 'female' otherwise. If the dataset contains no instances of the given name, no gender prediction will be returned. For the authors in our sub-corpus, the returned gender predictions are shown in Table <ref type="table" coords="3,134.87,459.56,3.74,8.64" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Country Inference</head><p>In contrast with gender prediction, we could not rely on a single API call for location prediction. To begin the process, we searched for the author by name in Google Scholar using the Scholarly API 3 <ref type="bibr" coords="3,408.65,513.01,10.58,8.64" target="#b5">[6]</ref>. Since there are often many authors with a given full name on Google Scholar, we picked a single author by comparing our author citation data with Google Scholar's data. After choosing the closest match, we then retrieved email extension and 'affiliation' data from Google Scholar. If we successfully retrieved this author data, we followed the below procedure, moving to each consecutive step if the prior was unsuccessful. As listed as the last step, if no author data was retrieved from Google Scholar, we tried finding the author's homepage and parsing its URL for country code.</p><p>1. Parse the email extension for a country code (e.g. .uk -→ the United Kingdom).</p><p>2. Parse the affiliation for a university name, then return the country in which that university is located. 4   3. Parse the affiliation for a city name, then return that city's country. 5   4. Search author name, author affiliation on Google, scrape the first URL, then parse for country code.</p><p>5. Call Google Places API with author affiliation, then return associated country.  Once all authors had been run through this process, we mapped each author's affiliated country to 'advanced economy' or 'developing economy' based on the IMF's October 2019 World Economic Outlook report <ref type="bibr" coords="4,437.23,220.79,10.58,8.64" target="#b6">[7]</ref>. The results are shown in Table <ref type="table" coords="4,106.62,231.70,3.74,8.64" target="#tab_2">2</ref>. Here, 'unidentified' means that no country was predicted for that author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pure Relevance with BM25</head><p>As one of the most popular ranking algorithms, Okapi BM25 is adopted by many search engines to calculate and predict the relevance of a document based on a given query. For both TREC tasks, retrieval and ranking, we used Gensim's BM25 module to predict the relevancy for each document in the provided document list.</p><p>Before running BM25, we preprocessed the sub-corpus to extract useful information. Since the complete paper for each document in the sub-corpus was not provided by TREC organizers, we instead chose the paper's abstract and title to represent the corresponding document. The papers were written in 28 different languages (detected by the langdetect API<ref type="foot" coords="4,131.55,345.90,3.49,6.05" target="#foot_1">6</ref>  <ref type="bibr" coords="4,138.09,347.57,10.79,8.64" target="#b7">[8,</ref><ref type="bibr" coords="4,151.44,347.57,7.74,8.64" target="#b8">9]</ref>) including English, Arabian, German, Chinese, etc., while all the queries were in English only. However, BM25 functions are incompatible with certain languages that cannot be tokenized by whitespace. Therefore, we decided to translate all needed documents into English first and stored the tokenized text in the database for further usage.</p><p>Then we started the BM25 process, which was similar for both retrieval and ranking tasks. We first translated and tokenized the queries since some of them contained Unicode. After that, for each query, we calculated the BM25 score as the base relevance score for each document in the baseline document list provided by TREC organizers, and then arranged the documents based on their scores in descending order. This sorted list was used as the pure ranking list for the given query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fairness-aware Re-ranking Algorithm</head><p>We proposed a fairness-aware re-ranking algorithm incorporating both relevance and diversity of documents. The mainly idea to estimate the cost of adding a document to the rank list R from the perspective of relevance and fairness. For a document of d, we used F (d, D, q), the reversed normalized BM25 score of d in a corpus D given a query q, to represent its relevance cost, where 0 corresponds to most relevant, and 1 corresponds to least relevant.</p><p>For a given query q, we first retrieved the top relevant documents to build a candidate corpus D . To ensure ranking fairness, it is intuitive to make the probability of defined groups over the rank list R and the candidate corpus D very similar. Specifically, let p(v, D) is the probability distributions of a discrete group variable v over the the document corpus D. Based on our group definitions, v could be either the group of gender g or country c, i.e., v ∈ {g, c}.</p><p>Note that it is flexible to be extended to other group definitions. Then we use the Kullback-Leibler (KL) divergence of the group distribution probability between the updated current rank list R and the whole candidate corpus D to measure their similarities. We also assigned weights w for relevance cost and fairness cost for each defined group. The cost function is expressed as:</p><formula xml:id="formula_0" coords="4,136.48,638.16,403.52,20.56">C(d, w, R, D , q) = w r * F (d, D , q) + v∈{g,c} w v * KL(p(v, R + {d}) p(v, D ))<label>(1)</label></formula><p>where w = {w r , w g , w c } and w r + w g + w c = 1; F (d, D , q) is the reversed normalized BM25 score of a document d such that 0 corresponds to most relevant, and 1 corresponds to least relevant; and KL(p(v, R + {d}) p(v, D )) is the Kullback-Leibler divergence regarding group v between the updated R by appending document d and the overall candidate corpus D . Then, we built our re-ranked list by repeatedly appending the document with the minimal cost C(d, w, R, D , q). The proposed fairness-aware re-ranking algorithm as illustrated in Algorithm 1.</p><p>Since many documents were missing group definitions for at least one author, we adopted a systematic way to address this missing data. For every author missing a group definition, we assigned a group value based on the overall group distribution in the corpus. For instance, if 75% of the authors in the corpus were identified as male, we choose 'male' for an unidentified author with a probability of 75%.</p><p>Algorithm 1: Fairness-aware Re-ranking Algorithm Input: D: document corpus; q: query of interest; l: length of expected ranked list ; w: component weight vector Output: R: re-ranked list of relevant documents R ← Ø ; // initialize the ranked list as empty D , D ← Retrieve relevant document candidates from D for query q ; // document candidate corpus for q for i = 1 → l do c min ← A Large Integer; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>We evaluated the utility and unfairness with different combinations of w r , w g , w c in Equation 1 from the perspective of relevance, the group of gender, and the group of country, as shown in Figure <ref type="figure" coords="5,389.27,448.23,3.74,8.64" target="#fig_2">2</ref>. In both gender and country groups, BM25 demonstrates a relatively high utility score but a low fairness score, implying that BM25 fails to take fairness into account when calculating the ranking. Another interesting finding is that the random ranking achieves lower fairness than most of our proposed methods on the country group but the highest fairness on the gender group. So, the fairness performance of random ranking methods is sensitive to the definition of groups. In other words, the definition of groups is not a trivial task as we claimed in Section 1. As we expected, our methods' utility drops greatly when BM25 scores are excluded (w r = 0). When w r is assigned a positive value, the performance of our methods with different combinations of w r , w g , w c are comparable on both country and gender groups (see the cluster on left top in Figure <ref type="figure" coords="5,100.50,535.51,3.71,8.64" target="#fig_2">2</ref>(a), and the cluster on the middle top in Figure <ref type="figure" coords="5,293.37,535.51,14.94,8.64" target="#fig_2">2(b)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future Work</head><p>In the future, we will further explore more features of both authors and papers (see Figure <ref type="figure" coords="5,428.88,588.03,4.15,8.64" target="#fig_3">3</ref>) to improve the fairness in retrieval and re-ranking tasks with scholar data. For a single author, we can consider both traditional demographic features including genders, ages, locations and languages, and the research related features such as affiliations, H-index, research interests, seniority levels (e.g., professors, postdocs, and PhD students), and backgrounds (e.g., academia, industry, and government). When taking multiple authors into account, the citation and co-authorship historical data can be used to build up networking graphs, from which many measurements, such as centrality, will be calculated. Adding the papers from authors who are far away from the influencers on the graphs may benefit diversity and fairness.</p><p>For the single paper, metadata such as keywords can be used to label the document. Besides, we can extract the topics from the paper abstract using topic models if possible. Other features, e.g., the number of coauthors, publication date, and total citations, can also be included. It is common that multiple papers are supported by the same funding sources or derived from the same projects. For example, given the keyword of "proactive searching", most of the paper in search results probably come from the InfoSeeking Lab. But it hurts diversity as the voices from small  labs/universities and those who are not among the first to explore this research direction have less opportunity to be heard. In addition, the citation graph enables the measurement of the closeness of multiple papers.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>At TREC 2020 Fairness Ranking Track, InfoSeeking Lab's FATE (Fairness Accountability Transparency Ethics) group at University of Washington proposed a fairness-aware retrieval and re-ranking algorithm incorporating both relevance and fairness for Semantic Scholar data. Evaluation results with different weights of relevance, gender, and location information demonstrated that our algorithm was flexible and explainable. In this report, we also highlighted various challenges and possible directions for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,204.98,574.42,202.05,8.64;2,288.14,412.41,230.26,136.25"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Snapshots of data stored on DynamoDB.</figDesc><graphic coords="2,288.14,412.41,230.26,136.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,234.96,271.57,138.99,8.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Utility versus unfairness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,221.88,604.55,165.76,8.64"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Fairness features to be explored</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,185.43,72.31,241.14,83.63"><head>Table 1 :</head><label>1</label><figDesc>The distribution of inferred genders by genderize.io</figDesc><table coords="3,234.83,93.66,142.34,62.28"><row><cell>Gender</cell><cell cols="2">Count Percentage</cell></row><row><cell>Male</cell><cell cols="2">18810 58.8%</cell></row><row><cell>Female</cell><cell>6235</cell><cell>19.5%</cell></row><row><cell cols="2">Unidentified 6930</cell><cell>21.7%</cell></row><row><cell>Total</cell><cell cols="2">31975 100%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,73.72,72.31,396.00,124.60"><head>Table 2 :</head><label>2</label><figDesc>The economy distribution of inferred locations</figDesc><table coords="4,73.72,93.66,396.00,103.25"><row><cell>Locations</cell><cell cols="2">Count Percentage</cell></row><row><cell>Advanced</cell><cell cols="2">15106 47.2%</cell></row><row><cell>Developing</cell><cell>3926</cell><cell>12.3%</cell></row><row><cell cols="3">Unidentified 12933 40.5%</cell></row><row><cell>Total</cell><cell cols="2">31975 100%</cell></row><row><cell cols="3">6. Search author name + 'homepage' on Google, scrape the first URL, then parse for country code.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,72.00,231.57,436.19,150.99"><head></head><label></label><figDesc>// initialize the minimal cost d min ← N one ; // initialize the document with the minimal cost for d ∈ D do Calculate the cost C(d, w, R, D , q) according to Equation 1 ; // calculate the cost if adding d into R if C(d, w, R, D , q) &lt; c min then d min ← d ; // update the document with the minimal cost c min ← C(d, w, R, D , q) ; // update the minimal cost end end append d min to R ; // add the document with the minimal cost into the re-ranked list R D ← D -{d min } ; // remove the added document dmin from D end return R</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,88.14,714.52,178.88,7.47"><p>http://api.semanticscholar.org/corpus/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="4,88.14,714.52,169.46,7.47"><p>https://pypi.org/project/langdetect/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>A part of this work is supported by the <rs type="funder">US National Science Foundation (NSF)</rs> award number IIS-1910154.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,88.60,149.92,451.40,8.82;7,88.60,161.01,22.42,8.64" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Ekstrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Kohlmeier</surname></persName>
		</author>
		<title level="m" coord="7,409.92,149.92,125.94,8.59">The TREC 2020 Fairness Track</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,175.90,451.40,8.64;7,88.60,186.63,387.32,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,415.27,175.90,124.73,8.64;7,88.60,186.81,51.60,8.64">Overview of the trec 2019 fair ranking track</title>
		<author>
			<persName coords=""><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Ekstrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Kohlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,158.31,186.63,288.39,8.59">The Twenty-Eighth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>TREC 2019) Proceedings</note>
</biblStruct>

<biblStruct coords="7,88.60,201.70,451.41,8.64;7,88.60,212.61,451.41,8.64;7,88.60,223.52,451.41,8.64;7,88.60,234.43,451.40,8.64;7,88.60,245.16,57.83,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,294.09,234.43,226.39,8.64">Construction of the literature graph in semantic scholar</title>
		<author>
			<persName coords=""><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Dunkelberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vu</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodney</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Kohlmeier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tyler</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hsu-Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joanna</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Skjonsberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zheng</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Madeleine</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,88.60,245.16,27.44,8.59">NAACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,260.06,451.40,8.82;7,88.60,270.96,60.05,8.82" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,285.86,150.00,8.82" xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="7,88.60,285.86,121.15,8.82">Demografix ApS. genderize.io</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,300.75,451.40,8.82;7,88.60,311.66,111.99,8.82" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,180.70,300.75,359.30,8.82;7,88.60,311.66,83.40,8.59">Panos Ipeirotis, and Victor Silva Revision. scholarly: Simple access to Google Scholar authors and citations</title>
		<author>
			<persName coords=""><forename type="first">Steven</forename><forename type="middle">A</forename><surname>Cholewiak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,326.73,451.41,8.64;7,88.60,337.64,151.09,8.64" xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="7,210.17,326.73,329.83,8.64;7,88.60,337.64,120.26,8.64">Research Dept. World economic outlook. World Economic Outlook. INTERNA-TIONAL MONETARY FUND</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>International Monetary Fund</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,352.36,408.59,8.82" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,191.53,352.36,272.58,8.59">Language detection library ported from Google&apos;s language-detection</title>
		<author>
			<persName coords=""><forename type="first">Michal</forename><surname>Mimino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danilak</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.60,367.43,237.49,8.64" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,158.59,367.43,138.86,8.64">Language detection library for java</title>
		<author>
			<persName coords=""><forename type="first">Shuyo</forename><surname>Nakatani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
