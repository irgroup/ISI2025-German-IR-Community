<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,91.99,118.16,428.02,18.14">TUW-IFS at TREC NEWS 2020 Wikification Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.45,159.56,149.77,10.52"><forename type="first">Annisa</forename><forename type="middle">Maulida</forename><surname>Ningtyas</surname></persName>
							<email>annisa.ningtyas@student.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien, Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,376.73,159.56,95.51,10.52"><forename type="first">Alaa</forename><surname>El-Ebshihy</surname></persName>
							<email>alaa.el-ebshihy@tuwien.ac.at</email>
							<affiliation key="aff1">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien, Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,127.34,238.32,75.52,10.52"><forename type="first">Florina</forename><surname>Piroi</surname></persName>
							<email>florina.piroi@tuwien.ac.at</email>
							<affiliation key="aff2">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien, Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.87,238.32,99.32,10.52"><forename type="first">Linda</forename><surname>Andersson</surname></persName>
							<email>linda.andersson@artificialresearcher.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Artificial Researcher IT GmbH</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.00,317.07,87.81,10.52"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
							<email>allan.hanbury@tuwien.ac.at</email>
							<affiliation key="aff4">
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Wien, Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,91.99,118.16,428.02,18.14">TUW-IFS at TREC NEWS 2020 Wikification Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BB2C71319099F5F435B5BB8081C3B144</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our work and submission to the TREC 2020 News Track on Wikification. This task aims to link word and phrases to entities in external knowledge bases, such as external news articles or Wikipedia. The idea behind this task is to increase user reading comprehension by linking entities in the text they are reading to external knowledge bases that contain information on those entities. In order to perform the Wikification task, we have built a processing pipeline consisting of three main parts: identification, candidate generation and disambiguation, and candidate pruning or nil detection. Our model is fully unsupervised, and it does not require data training. We use commonness, topic modeling distance, and embedding similarity as a disambiguation method.</p><p>The evaluation of the task submissions was done using newly introduced metrics: correctness of the link, the usefulness of the target link, the usefulness of the anchor span and the sensibility of the anchor text. Our method was designed to focus on coverage to also support the readers with limited knowledge in English, and thereby requiring more explanations and the possibility to have the explanation in another language. Based on the result, we conducted a failure analysis. We infer that our low scores on both evaluation are due to the use of Wikipedia as the only knowledge base to linked to, and lack of entity ordering during our final processing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TREC 2020 News Track is proposed to encourage the use of the IR system to enhance the reading comprehension of the users. The TREC 2020 News Track had two tasks -Background Linking and Wikification. The Background Linking task focused on linking a news article with a list of other news articles that provide useful context and background information to the reader. The second task, Wikification aimed to find hyperlinks from concept words or phrases in news articles to an external knowledge base. Wikipedia is one of the popular examples of such a knowledge base, though other external resources, such as news articles, can give meaningful insight to the reader.</p><p>This paper focuses on the Wikification task. The task of wikifying an input document can be divided into several interrelated sub-tasks or processing phases: <ref type="bibr" coords="2,436.95,176.91,14.96,10.48" target="#b0">(1)</ref> word and phrase identification (called mentions), in the input document, that are to be candidates to be linked to into a knowledge base; (2) detect the knowledge base entries (called entities) that semantically match the identified words and phrases selected in the 1st sub-task, and retain their links; (3) from all pairs of &lt;mention, entity&gt; detected in the previous two subtasks, perform word sense disambiguation to determine which ones are the correct and useful entities to be linked to from the mention.</p><p>The general pipeline we developed has two main modules that address these sub-tasks. The first module handles mention identification and aims to spot entities from the given documents, that are candidates to be linked into a knowledge base. The second module first syntactically matches the mentions (word or phrases) extracted in the first phase with entries in the knowledge base (in this work, Wikipedia). Then it will apply a disambiguation mechanism to eliminate the matched knowledge base entries that do not, semantically, refer to the mentions they syntactically matched. The disambiguation step is an important one, since it must remove the Wikipedia entities that only syntactically match a mention, but not semantically. In the disambiguation step we use features like "commonness", "topic distance" and "embedding similarity" to decide if an entity is semantically matching a mention. Once this is done we apply a probability filter on the remaining &lt;mention, entity&gt; pairs that estimates which of them is most probably of use to a reader.</p><p>Our method is designed to focus on coverage (more entities linked) to support the readers with limited English knowledge, thereby requiring more explanations possibly having access to explanation in another language.</p><p>The structure of this paper as follows: Section 2 gives a brief description of the related work. Section 3 gives a very brief account on the dataset used in this Wikification task. Section 4 describes the methodology chosen for this work. Section 5 presents the experiments and the results given by our method. Lastly, in Section 6 we draw some conclusions about our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The research on Wikification (or entity linking), can be divided into using two types of models: end-to-end and disambiguation-only. The end-to-end entity linking models process the input text to extract mentions (i.e Named Entity Recognition) and then disambiguate this mention to point to the correct entity in the knowledge base. The disambiguation-only methods focus mainly on the later part.</p><p>Wikification is a task for extracting important words or phrases from a document and link them to the appropriate entities in a knowledge base, such as Wikipedia. In one of the early works on this task, Mihalcea and Csomai <ref type="bibr" coords="3,293.82,75.79,12.36,10.48" target="#b7">[8]</ref> divided the Wikification task into two task: keyword extraction and words sense disambiguation. To extract keywords that are to be linked to a knowledge base, the authors implemented a dictionary matching algorithm and for each match a rank of dictionary entries are given, to select the most salient mentions. In their word sense disambiguation step, the authors computed the contextual overlap between the contexts of the entities and those of the mentions. They also use machine learning approach, which is a Naive Bayes Classifier. The train data is a combination of feature vectors such as part-of-speech and surrounding words as a local context, and five most frequent word in the document as a global context. The target data is the correct entity among the ambiguous candidate.</p><p>With the advancement of deep neural network applied to language processing tasks, entity linking has also been one of the application areas <ref type="bibr" coords="3,326.45,234.69,12.36,10.48" target="#b2">[3,</ref><ref type="bibr" coords="3,340.16,234.69,9.11,10.48" target="#b3">4,</ref><ref type="bibr" coords="3,350.63,234.69,9.11,10.48" target="#b6">7,</ref><ref type="bibr" coords="3,361.08,234.69,9.11,10.48" target="#b8">9,</ref><ref type="bibr" coords="3,371.55,234.69,14.96,10.48" target="#b10">11,</ref><ref type="bibr" coords="3,387.86,234.69,13.66,10.48" target="#b14">15]</ref>. In entity disambiguation, neural networks act to represent mentions as continuous vectors with the context awareness. These representation can be achieved with with Convolutional Neural Networks (CNN) <ref type="bibr" coords="3,524.39,263.59,11.71,10.48" target="#b8">[9]</ref>, Long Short-Term Memory Networks (LSTM) <ref type="bibr" coords="3,307.79,278.03,11.71,10.48" target="#b2">[3]</ref>, and Attention mechanisms <ref type="bibr" coords="3,467.90,278.03,11.71,10.48" target="#b6">[7]</ref>.</p><p>In end-to-end models, mention detection and entity disambiguation can be treated as inference step in the trained model of neural network <ref type="bibr" coords="3,344.64,306.92,13.59,10.48" target="#b3">[4,</ref><ref type="bibr" coords="3,358.22,306.92,13.59,10.48" target="#b10">11]</ref>. However, these approaches rely on big training datasets to build their model.</p><p>In contrast, a light-weight linguistic approach <ref type="bibr" coords="3,314.53,335.81,19.23,10.48" target="#b14">[15,</ref><ref type="bibr" coords="3,333.75,335.81,14.42,10.48" target="#b15">16]</ref> that uses classical text processing and exploits the graph structure of the knowledge base can still reach high performance levels. The approach describes by Sakor et.al <ref type="bibr" coords="3,273.38,364.71,18.20,10.48" target="#b14">[15]</ref> fuse the knowledge graph of several datasets to increase the size of the available knowledge base for linking. The recent classical approach also described by Shnayderman et.al <ref type="bibr" coords="3,268.09,393.60,18.21,10.48" target="#b15">[16]</ref> that mainly uses Wikipedia redirects as a basis for entity linking. The classical approaches prove to be fast with respect to training time when compared to the use of Neural Network based models <ref type="bibr" coords="3,393.03,422.49,17.17,10.48" target="#b15">[16]</ref>, and can cover multiple domains <ref type="bibr" coords="3,118.10,436.94,17.17,10.48" target="#b14">[15]</ref>. In this paper, we propose a simple linguistic processing for mention detection and local disambiguation with topic modeling and simple semantic similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>The TREC News track organizers provided the participants with two collections of data. The first one, in collaboration with The Washington Post, contains 671,947 news articles and blog posts starting January 2012 through December 2019 <ref type="foot" coords="3,406.63,544.87,4.23,6.99" target="#foot_0">1</ref> . The second dataset is an English Wikipedia Dump generated on January 1st, 2020. There were no topics and relevance assessments to train on from the previous years. This year the track organizers have created 50 topics<ref type="foot" coords="3,187.54,588.21,4.23,6.99" target="#foot_1">2</ref> selected from the set of news articles which the track participants should wikify. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>In this section, we describe the pipeline we used to approach the wikification task. As we mentioned in the introduction, our solution is divided into three phases: mention identification, matching Wikipedia entities to the mentions (with an additional disambiguation step), and a ranking of &lt;mention, entity&gt; pairs to select those that are of most use to a reader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mention Identification</head><p>In the first phase of our approach we aim to identify words and sequences of words (phrases) in a given text that are candidates to be linked to a knowledge base. The knowledge base we use in this work is Wikipedia. We start, here, by building a dictionary of Wikipedia article titles, words or phrases, which we use as a look-up index to identify good candidates to be linked from the input news article. We do lower casing on the Wikipedia titles before adding them to the dictionary. The dictionary is constructed with the Aho-Corasick algorithm which uses a tree-like structure to store it. The aim of this method is to find words or phrases in the Washington Post articles that match the pre-built dictionary. If the matched word is a subset of another matched words or phrases, we will select the longest string in the news article that matches as a mention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Candidate Generation and Disambiguation -to change</head><p>For this phase we have created a Solr index containing the Wikipedia articles in the TREC News Wikification corpus. In a first step we take the mentions obtained in Section 4.1 and send them as queries to the Solr index, where we apply the Jelinek-Mercer smoothing language model to the queries. We retrieve, thus, those Wikipedia articles for which we have an exact match between the mention and the Wikipedia article's title. For each mention we retain the top 10 results returned by the Solr index.</p><p>The next step in this phase aims to disambiguate between (matched) Wikipedia articles by adding a semantic component to the process. That is, we want to avoid proposing the user a link to a Wikipedia article about 'Pat Nixon' when the news article mentions 'Nixon' and it is clear from the context that the article writes about 'President Nixon' or 'Richard Nixon'.</p><p>Previous work on disambiguation classifies disambiguation features into local and global features <ref type="bibr" coords="5,115.52,119.13,18.77,10.48" target="#b11">[12,</ref><ref type="bibr" coords="5,134.28,119.13,14.07,10.48" target="#b13">14]</ref>. Local features are, for example, 'commonness' and 'topic distance', and use only the surrounding context of a mention in a sentence or paragraph. Global features take into account the semantic context of a mention in the whole document. In the system proposed by us, we only use local features to disambiguate each mention, namely 'commonness', 'topic distance' and 'embedding similarity.' We combine these metrics to calculate a final disambiguation score using a weighted sum of these features in order to select an appropriate Wikipedia entity in the knowledge base for each selected mention in the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Commonness</head><p>A mention can be used as an anchor text for entities, such as Wikipedia pages. A mention, m, can refer to different entities, e, depending on the context of the mention. Commonness is defined to be a prior probability for a mention, m, to a specific entity, e, <ref type="bibr" coords="5,461.44,288.03,17.17,10.48" target="#b12">[13]</ref>:</p><formula xml:id="formula_0" coords="5,225.71,312.94,314.29,29.49">P (e|m) = f req(m → e) e ∈W f req(m → t )<label>(1)</label></formula><p>where f req(m → e) is the number of mentions, m, that are a hyperlink for the entity, e, and f req(m → e ) is the number of mentions, m, that are also a title in Wikipedia. Commonness is not a robust metric across domains and results may be misleading when we disambiguate a mention as it does not take into consideration the context of the document <ref type="bibr" coords="5,471.34,398.47,17.17,10.48" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Topic Modeling</head><p>We use topic modeling a local feature in our disambiguation step. As commonness is contextindependent, we use topic modeling to estimate the topic similarity between the input document and documents in the knowledge base. We build a topic modelling using Latent Dirichlet Allocation (LDA) on The Washington Post news articles, and use it to capture the topic distribution over the Washington post news articles. This model will be used for inference process in the disambiguation step. We transform the articles from Washington Post as well as Wikipedia to become a vector of topic distribution using the topic model. The topic distribution of Wikipedia and Washington Post articles, will be used to measure the topic similarity between the Washington Post and the Wikipedia articles. The basic intuition of the LDA is that every document consists of a mixture of topics, that can be seen as a topic distribution per document. Blei <ref type="bibr" coords="5,374.28,596.27,12.36,10.48" target="#b1">[2]</ref> defines topics as a probability distribution over of a set of words. For example, the 'politics' topic has words about politics with high probability and words about sports with low probability, while a 'sports' topic is related to words about sports with high probability, but words referring to music have a low probability in a document about sports. We assume that document topics have been specified before corpus documents were released.</p><p>To implement our topic modeling method we use gensim and run it on the 50 topics of the Washington Post track. We use these topics to disambiguate between a mention, m, and an entity, e. We compare the paragraph where the mention occurs (pm) with the first paragraph of each entity, e, initially associated with m. We, then, calculate the distance between the two probability distribution using the Hellinger Distance (HD) <ref type="bibr" coords="6,450.97,90.24,11.71,10.48" target="#b0">[1]</ref>. By definition, the Hellinger Distance between two probability distributions, p and q, that represent two topics, is defined as (3):</p><formula xml:id="formula_1" coords="6,222.75,136.28,317.25,35.77">H(p, q) = 1 √ 2 nv i=1 ( √ p i - √ q i ) 2<label>(2)</label></formula><p>p is the topic distribution detected on the Washington Post article' paragrpahs, and q is the topic distribution detected on the first paragraph of the Wikipedia target article. The minimum H(p, q) distance is 0 when p is equal to q. The maximum Hellinger Distance between two probabilities is 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Doc2Vec</head><p>An additional feature that we use in the disambiguation step is a score derived from applying Doc2Vec. This step aims to calculate the semantic similarity between the Washington Post paragraph which contain the mention, with the first section of Wikipedia articles. Doc2vec is an unsupervised algorithm that learns feature representations from texts, such as sentences, paragraphs, and documents. Doc2Vec represents each document as a dense vector of real numbers.</p><p>There are two main algorithms to learn paragraph vectors, namely Paragraph Vector -Distributed Memory(PV-DM) and distributed Bag-of-Words (dBOW) <ref type="bibr" coords="6,434.89,380.20,11.71,10.48" target="#b5">[6]</ref>.</p><p>We use the pre-trained model created by Lau and Baldwin <ref type="bibr" coords="6,398.79,394.65,12.36,10.48" target="#b4">[5]</ref> which is built using the gensim's doc2vec library. This model is trained on the English Wikipedia corpus using a dump dated December 1st, 2015. We use this model to infer the paragraph context of the mention, m, as well as each of the paragraph of candidate entity, e. Then, we calculate the similarity between them using a cosine measure and select the most similar pairs of paragraph context and candidate entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Scoring</head><p>Each of the three processing steps described above gives back a score between 0 and 1. We combine all these scores with a weighted sum to obtain a final ranking of the pairs &lt;mention, entity&gt; :</p><formula xml:id="formula_2" coords="6,165.14,563.56,374.86,11.50">score = w cm * P (e|m) + w td * (1 -H(p, q)) + w es * sim<label>(3)</label></formula><p>where w cm is the commonness weight, P (e|m) is a prior probability of a specific entity, e, given a mention, m, wtd is the topic model weight, H(p, q) is the distance between two topic distributions (p for the the paragraph topic distribution in the topic document, and q for the topic distribution of the first entity paragraph), w es the doc2vec weight, and sim is the cosine similarity between the mention's context and the Wikipedia page (i.e. the entity).</p><p>We experimented with different values for w cm , w td , and w es , which we report on in the next subsection. Using this score we order the pairs &lt; mention, wiki link &gt; and take the top 10 and pass them on to the next phase. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Candidate Pruning</head><p>From the &lt;mention, entity&gt; pairs that were retained in the previous processing steps, the last phase of our method will select those that are estimated indeed relevant to a user. In our interpretation, the Wikification task aims to provide useful information to a reader, contributing to the reader's comprehension skills.</p><p>For each of the &lt;mention, entity&gt; pairs we compute the link probability of a mention to be attached a Wikipedia link. With this probability we prune the irrelevant semantic annotations from the &lt;mention, entity&gt; pairs. The formula by which we compute this is as follows <ref type="bibr" coords="7,110.43,339.95,17.17,10.48" target="#b9">[10]</ref>:</p><formula xml:id="formula_3" coords="7,260.93,352.90,279.07,26.77">lp(m) = link(m) f req(m)<label>(4)</label></formula><p>where link(m) represents how many times the mention, m has been selected as an anchor text in a Wikipedia page, while f req(m) is the number of times the mention, m appears in the Wikipedia page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this section we present the outcome of the Wikification submission. The statistics on retrieved entities in our submissions are shown in Table <ref type="table" coords="7,369.57,498.17,4.55,10.48" target="#tab_0">1</ref>. We ran the experiments with various weights and turning candidate pruning on or off for each run. The weights are commonness (w cm ) explained in Eq. 3, topic distance (w td ) explained in Eq. 3 and embedding similarity (w es ). This score is calculated based on the Eq. 3. The NDCG@5 can be seen in Table <ref type="table" coords="7,104.92,555.96,4.55,10.48" target="#tab_1">2</ref>. NDCG is the main measure indicated by the the TREC Wikification guidelines. Thus, the ranking for a relevant entity will be taken into measure. However, the NDCG@5 results were not satisfying. This is because we did not re-rank the entities in the final list of extracted entities. Since our method does not directly produce a ranking, we listed the mentions and their attached Wikipedia entities in the order of the character position in the document. The overall NDCG results are shown in Fig. <ref type="figure" coords="7,361.69,628.18,4.85,10.48" target="#fig_1">2</ref>. On this graph, we observe that the performance is better for higher NDCG cuts. In Table <ref type="table" coords="7,378.37,642.63,4.55,10.48" target="#tab_1">2</ref>, we can see that our best run is tuw-ifs-4. As stated in the previous section, commonness plays a big role in determining the correct entity to be associated to a mention.  The organizers of the track also provided four new metric to asses the correctness of the Wikification task. These measures are: (1) The correctness of the link, (2) the usefulness of the target link, (3) the usefulness of the anchor span, and (4) the sensibility of the anchor text. The result is in line with the earlier assessment, which shows a low performance. From 47 topics (three were left out by the track organizers for lack of to be linked to Wikipedia), there are 20 topics which have a zero median, with 0.078 on the average of median. This means that that half of our results that were checked by the track assessors didn't meet the target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Failure Analysis</head><p>The main findings of our failure analysis is that the low scores we obtained are due to our omission to order the results according to their relevance. We also only use Wikipedia as the candidate's knowledge base, while the entity-linking task may be linked to another sources. In the new measure we found the usefulness of the target link is including the background information, which sometimes is not captured in Wikipedia.</p><p>By looking at the worst-performing topic (topic id 899), we noticed ambiguities in handling entities representing person's proper names. For example, 'Ben Penrod' was linked to 'Guy Penrod.' This is due to the high commonness of the entity. This happened for other topics, too, which reduced our system's efficiency. Thus, we conclude that candidate pruning can be counter-productive if it only uses commonness as a parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper presents our work and our submission for the TREC 2020 News Track on Wikification. For this task we constructed a pipeline that consisted of 3 main phases: mention identification, candidate generation and disambiguation, and candidate pruning. Our experiments show that our system setting has a high recall, but lower precision. This is seen in the results of the evaluation on the terms of the NDCG and the new measures used by the track organisers.</p><p>The main findings of our failure analysis are using Wikipedia only as a knowledge base, not ordering the entity according to the relevance ranking in submission file, and only using commonness as a parameter for candidate pruning. In a future iteration of this system we plan to use use the relevance assessments of this year and improve our model. We also consider using supervised model for the disambiguation task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,97.45,228.63,417.10,10.48;4,72.00,72.00,468.00,144.72"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: General Workflow of the system we used to solve the Wikification task.</figDesc><graphic coords="4,72.00,72.00,468.00,144.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,237.29,449.40,137.43,10.48;8,125.67,220.84,360.65,216.65"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: NDCG Statistics</figDesc><graphic coords="8,125.67,220.84,360.65,216.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,105.27,73.95,401.46,116.59"><head>Table 1 :</head><label>1</label><figDesc>Run Statistics</figDesc><table coords="7,105.27,91.78,401.46,98.75"><row><cell>Runs</cell><cell>Weight w cm w td</cell><cell>w es</cell><cell>Nil</cell><cell cols="3">Number of Entities Retrieved per Topic Standard Mean Median Min Max Deviation</cell></row><row><cell cols="5">tuw-ifs-1 0.5 0.25 0.25 No 43.26 40</cell><cell>18</cell><cell>89</cell><cell>17.83</cell></row><row><cell cols="2">tuw-ifs-2 0.4 0.3</cell><cell>0.3</cell><cell cols="2">No 42.96 38</cell><cell>18</cell><cell>89</cell><cell>17.92</cell></row><row><cell cols="5">tuw-ifs-3 0.5 0.25 0.25 Yes 26.28 23</cell><cell>7</cell><cell>61</cell><cell>12.05</cell></row><row><cell cols="2">tuw-ifs-4 0.7 0.2</cell><cell>0.1</cell><cell></cell><cell>26.06 23</cell><cell>7</cell><cell>59</cell><cell>11.96</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,156.40,73.95,299.20,116.59"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table coords="8,156.40,73.95,299.20,116.59"><row><cell></cell><cell cols="2">NDCG@5 Statistics</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>NDCG@5</cell><cell></cell><cell></cell></row><row><cell>Runs</cell><cell>Mean Median</cell><cell>Standard Deviation</cell><cell>Min</cell><cell>Max</cell></row><row><cell>tuw-ifs-1</cell><cell cols="2">0.0990 0.0000 0.1480</cell><cell>0</cell><cell>0.4704</cell></row><row><cell>tuw-ifs-2</cell><cell cols="2">0.0477 0.0000 0.1118</cell><cell>0</cell><cell>0.5087</cell></row><row><cell>tuw-ifs-3</cell><cell cols="2">0.1121 0.0131 0.1633</cell><cell>0</cell><cell>0.4913</cell></row><row><cell cols="3">tuw-ifs-4 0.1191 0.0140 0.1659</cell><cell>0</cell><cell>0.4913</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,89.93,627.09,153.23,8.74"><p>https://trec.nist.gov/data/wapost/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,89.93,639.04,177.00,8.74"><p>http://trec-news.org/guidelines-2020.pdf</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,96.06,410.47,443.94,11.15;9,96.06,424.91,443.94,10.48;9,96.06,439.36,222.92,10.48" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,519.29,410.47,20.71,10.48;9,96.06,424.91,352.09,10.48">Discovering topic structures of a temporally evolving document corpus</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beykikhoshk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Arandjelović</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,461.85,424.91,78.15,10.48;9,96.06,439.36,105.98,10.48">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="599" to="632" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.06,465.79,443.93,9.13;9,96.06,478.21,443.94,11.15;9,96.06,492.66,50.08,10.48" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,133.43,478.21,138.67,10.48">Latent Dirichlet Allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">B</forename><surname>Edu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Edu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B</forename><surname>Edu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,285.35,478.21,201.28,10.48">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.06,517.07,443.93,11.15;9,96.06,531.51,443.93,10.48;9,96.06,545.96,271.33,10.48" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,320.23,517.07,219.76,10.48;9,96.06,531.51,125.53,10.48">Entity linking via joint encoding of types, descriptions, and context</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,231.14,531.51,308.86,10.48;9,96.06,545.96,103.23,10.48">EMNLP 2017 -Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2681" to="2690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.06,570.37,443.94,11.15;9,96.06,584.81,156.53,10.48" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,374.26,570.37,165.74,10.48;9,96.06,584.81,14.15,10.48">End-to-End Neural Entity Linking</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O.-E</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<idno>CoRR abs/1808.0</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.06,609.22,443.93,11.15;9,96.06,623.67,283.40,10.48" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,274.55,609.22,265.44,10.48;9,96.06,623.67,240.25,10.48">An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.06,648.08,443.94,11.15;9,96.06,662.52,443.01,10.48" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,249.32,648.08,284.89,10.48">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,96.06,662.52,263.40,10.48">31st International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="2931" to="2939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,96.06,688.95,443.93,9.13;9,96.06,701.38,443.94,11.15;10,96.06,75.79,443.94,10.48;10,96.06,90.24,156.73,10.48" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,151.13,701.38,283.61,10.48">Zero-shot entity linking by reading entity descriptions</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,449.30,701.38,90.70,10.48;10,96.06,75.79,443.94,10.48;10,96.06,90.24,56.34,10.48">ACL 2019 -57th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3449" to="3460" />
		</imprint>
	</monogr>
	<note>Proceedings of the Conference</note>
</biblStruct>

<biblStruct coords="10,96.06,114.64,443.94,11.15;10,96.06,129.09,58.86,10.48" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Csomai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">!</forename><surname>Wikify</surname></persName>
		</author>
		<title level="m" coord="10,349.09,114.64,190.91,10.48;10,96.06,129.09,52.97,10.48">Linking Documents to Encyclopedic Knowledge</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.06,153.50,443.94,11.15;10,96.06,167.94,443.93,10.48;10,96.06,182.39,443.94,10.48;10,96.06,196.84,246.48,10.48" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,514.32,153.50,25.68,10.48;10,96.06,167.94,381.28,10.48">Hierarchical losses and new resources for fine-grained entity typing and linking</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Radovanovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,487.69,167.94,52.31,10.48;10,96.06,182.39,443.94,10.48;10,96.06,196.84,75.77,10.48">ACL 2018 -56th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
		</imprint>
	</monogr>
	<note>Proceedings of the Conference</note>
</biblStruct>

<biblStruct coords="10,96.06,221.24,443.94,11.15;10,96.06,235.69,443.94,10.48;10,96.06,250.14,330.72,10.48" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,296.34,221.24,238.33,10.48">From Tagme to WAT: A new entity annotator</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ferragina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,96.06,235.69,443.94,10.48;10,96.06,250.14,253.00,10.48">ERD 2014 -Proceedings of the 1st ACM International Workshop on Entity Recognition and Disambiguation, Co-located with SIGIR 2014</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="55" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.06,274.54,443.94,11.15;10,96.06,288.99,443.94,10.48;10,96.06,303.44,55.93,10.48" xml:id="b10">
	<analytic>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Deeptype</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,326.55,274.54,213.45,10.48;10,96.06,288.99,336.69,10.48">Multilingual entity linking by neural type system evolution. 32nd AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="5406" to="5413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.06,327.84,443.93,11.15;10,96.06,342.29,293.90,10.48" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,448.67,327.84,91.33,10.48;10,96.06,342.29,227.22,10.48">Local and Global Algorithms for Disambiguation to Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1375" to="1384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.06,366.70,443.93,11.15;10,96.06,381.14,346.97,10.48" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,377.12,366.70,162.88,10.48;10,96.06,381.14,229.28,10.48">Wikification and Beyond : The Challenges of Entity and Concept Grounding</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cassidy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,336.33,381.14,65.79,10.48">ACL tutorial</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.06,405.55,431.31,11.15" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,161.26,405.55,266.03,10.48">Semantic Analysis Using Wikipedia Graph Structure</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sajadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,96.06,431.98,443.94,9.13;10,96.06,444.41,443.94,11.15;10,96.06,458.85,443.94,10.48;10,96.06,473.30,443.93,10.48;10,96.06,487.74,339.50,10.48" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,273.07,444.41,266.93,10.48;10,96.06,458.85,168.72,10.48">Old is gold: Linguistic driven approach for entity and relation linking of short text</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sakor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">O</forename><surname>Mulang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,275.94,458.85,264.06,10.48;10,96.06,473.30,443.93,10.48;10,96.06,487.74,228.20,10.48">NAACL HLT 2019 -2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies -Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2336" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,96.06,514.17,443.94,9.13;10,96.06,526.60,443.94,11.15;10,96.06,541.04,104.86,10.48" xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Shnayderman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ein-Dor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Mass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Halfon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sznajder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Spector</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sheinwald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Fast Endto-End Wikification</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
