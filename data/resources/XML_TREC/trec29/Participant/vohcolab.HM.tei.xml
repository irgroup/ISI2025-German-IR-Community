<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,205.04,120.17,205.72,10.21;1,201.52,138.10,206.10,10.21;1,407.61,132.69,5.73,8.77">VOH.CoLAB at TREC 2020 Health Misinformation Track ⋆</title>
				<funder ref="#_ZBHXxyQ">
					<orgName type="full">DSAIPA project FrailCare.AI</orgName>
				</funder>
				<funder ref="#_842KFwy">
					<orgName type="full">NOVA LINCS</orgName>
				</funder>
				<funder>
					<orgName type="full">FCT -Fundação para a Ciência e a Tecnologia</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,206.49,172.50,87.29,8.80"><forename type="first">Simão</forename><forename type="middle">N</forename><surname>Gonçalves</surname></persName>
							<email>simao.goncalves@vohcolab.org</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">VOH.CoLAB</orgName>
								<orgName type="institution" key="instit2">Universidade NOVA de Lisboa</orgName>
								<address>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">NOVA LINCS</orgName>
								<orgName type="institution" key="instit2">Universidade NOVA de Lisboa</orgName>
								<address>
									<settlement>Caparica</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.28,172.50,64.44,8.80"><forename type="first">Flávio</forename><surname>Martins</surname></persName>
							<email>flavio.martins@vohcolab.org</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">VOH.CoLAB</orgName>
								<orgName type="institution" key="instit2">Universidade NOVA de Lisboa</orgName>
								<address>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">NOVA LINCS</orgName>
								<orgName type="institution" key="instit2">Universidade NOVA de Lisboa</orgName>
								<address>
									<settlement>Caparica</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Comprehensive Health Research Centre (CHRC)</orgName>
								<address>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,205.04,120.17,205.72,10.21;1,201.52,138.10,206.10,10.21;1,407.61,132.69,5.73,8.77">VOH.CoLAB at TREC 2020 Health Misinformation Track ⋆</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5375D2A7EC92539B3AD6036A3F28B96E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Consumer Health Search</term>
					<term>COVID-19</term>
					<term>Misinformation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the participation of VOH.CoLAB in the TREC 2020 Health Misinformation Track (HMT). This year's edition of the track focused on two main Consumer Health Search tasks regarding COVID-19 questions: 1) to find misinformation; 2) to find relevant, credible, and correct information. In our participation in the HMT track, we submitted runs to both tasks, performing experiments to explore two main research hypothesis: 1) Does misinformation avoid mentioning the evidence text? 2) Does correct and credible information look similar to the evidence text? To explore these two complementary ideas we represent both the documents and the evidence as vectors and compute scores using a formula based on Kullback-Leibler divergence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The outbreak of a novel coronavirus in 2019 (SARS-CoV-2), has led to an increase of misinformation online and pushed the World Health Organization (WHO) to declare "We're fighting an infodemic". In Consumer Health Search, people often cannot separate the useful, correct, and credible information from misinformation. Therefore, because Consumer Health Search is used to make decisions about Health, fighting misinformation is critical. Previous research <ref type="bibr" coords="1,411.20,498.60,11.10,8.80" target="#b1">[2]</ref> showed that users make incorrect decisions when presented increasing amounts of incorrect information in Search Engine Result Pages (SERPs), which is potentially harmful.</p><p>The TREC Health Misinformation Track focuses on methods that promote correct and credible information over non-credible, incorrect information. Access to correct information about COVID-19 is of critical importance to public health, therefore this track aims to create a suitable dataset to foster research on misinformation, credibility, correctness, and relevance regarding COVID-19 questions. A dataset labeled along these dimensions can be used to build information retrieval systems that retrieve correct information and demote misinformation. This can lead people to make better decisions about their health.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Health Misinformation Track Setup</head><p>This section describes the setup of the track, which aims to obtain a labeled dataset with annotations for document usefulness, correctness, and credibility suitable for future research in health misinformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collection</head><p>The collection contains 65 million news articles from CommonCrawl News<ref type="foot" coords="2,476.38,237.76,3.99,6.18" target="#foot_0">4</ref> corresponding to the period from January to April of 2020. CommonCrawl News contains archives of Web pages (snapshots) crawled from news sites from all over the world in multiple languages and published by the CommonCrawl Foundation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Topics</head><p>The track focuses on Consumer Health Search, where the users are regular people seeking health advice online in regards to the COVID-19 epidemic. This represents the dangers of the proliferation of misinformation and the weaknesses of search engines, which can have negative consequences on consumer health. A total of 50 topics were developed for evaluation on this track with the following fields: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Tasks</head><p>The Health Misinformation Track consist of two tasks:</p><p>Total Recall Task: find misinformation articles contradicting the answer.</p><p>Ad hoc Task: find useful, correct, and credible articles supporting the answer.</p><p>While in the Total Recall task the goal is to find harmful misinformation, the Ad Hoc task aims to find relevant, credible, and correct information that can help consumer health searchers make better health-related decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Evaluation</head><p>Relevance judgments were evaluated according to three criteria: usefulness, correctness, and credibility. A useful document talks about the topic's subject, but doesn't depend on correctness (effectively it's the "topic relevance"). A correct document must give the right answer to the topic (therefore it is also useful). Finally, a credible document doesn't depend on correctness, but must be useful. Credibility judgments also depend on other factors such as: amount of expertise of the author, references contained to support claims, whether the article contains advertising, and more. Further information on how the annotators classified the relevance judgments can be found in the track's Assessing Guidelines <ref type="foot" coords="3,439.67,375.46,4.23,6.18" target="#foot_1">5</ref> .</p><p>Derived qrels are special qrel files, derived from the 2020 qrels, that were used to evaluate adhoc and total recall runs on multiple levels. The derived qrels are essentially combinations of all the three criteria considered in the relevance judgments. In the Results section we discuss more in depth these derived qrels.</p><p>Total Recall is evaluated according to the metric Rprec of the incorrect documents retrieved. Incorrect documents are useful, but don't give the right answer to the topic. AdHoc Retrieval is evaluated for 9 different criteria such as: finding only useful documents, or finding useful, correct, and credible documents, among other combinations of these three aspects. The metrics used for this task were: Normalized Discounted Cumulative Gain (NDCG), Convex Aggregating Measure (CAM) <ref type="bibr" coords="3,168.47,574.23,10.69,8.80" target="#b3">[4]</ref> using Mean Average Precision (MAP), and compatibility <ref type="bibr" coords="3,431.14,574.23,9.25,8.80" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental methodology</head><p>In this section we describe the experimental methodology including indexing and data preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>The first step filters out non-English documents since these are considered nonrelevant according to the assessors' instructions. To create a whitelist of English pages we adapted the code from CC-News Tools <ref type="foot" coords="4,348.96,217.94,4.35,6.18" target="#foot_2">6</ref> . The final indexing contains 28.3M documents mostly in English, compared to the original 65M documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Indexing and Retrieval</head><p>We used Anserini <ref type="bibr" coords="4,220.43,274.50,11.20,8.80" target="#b5">[6]</ref> to create the index, using its whitelist flag to index only English documents. Pyserini<ref type="foot" coords="4,260.63,284.95,3.88,6.18" target="#foot_3">7</ref> was used to query the index of the collection using queries composed by the concatenation of the topic's fields title and description, because some of the topics' title field contained extra information not present in the description field. For our re-ranking runs we use nltk<ref type="foot" coords="4,395.91,320.82,4.35,6.18" target="#foot_4">8</ref> to preprocess and tokenize the documents' text and the Python package scikit-learn <ref type="bibr" coords="4,428.62,334.28,10.92,8.80" target="#b4">[5]</ref> to create a tf-idf representation of the candidate documents retrieved initially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submitted runs</head><p>This section describes our approach at answering both tasks described above. In summary, we have submitted a total of 5 runs, they are:</p><formula xml:id="formula_0" coords="4,139.75,424.10,132.10,41.44">Total Recall -vohbm25rm3 (baseline) -vohEvDivTfidf -vohEvDiv_colm</formula><p>Ad hoc Retrieval -vohbm25 (baseline) -vohcolabEvSim</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baselines</head><p>Total Recall Task. Our baseline uses BM25 and RM3 to retrieve 10k documents. This task is recall-oriented and therefore we employ pseudo-relevance feedback:</p><p>1. First, we use BM25 to retrieve the most likely relevant documents; 2. Then, we assume blindly that the top documents retrieved are relevant to the topic and use RM3 to expand the query to find more relevant documents.</p><p>Ad hoc Task. Our baseline uses BM25 alone to retrieve 1000 documents. We do not employ query expansion as this task is precision-oriented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Commons similarity and divergence</head><p>This section contains three submissions that arise from the following hypothesis: "Misinformation tries to avoid the actual evidence, therefore vocabulary distribution will be different". We further make an analogous argument for the Ad hoc Retrieval task: "Correct information paraphrases the actual evidence, therefore vocabulary distribution will be similar". To test this hypothesis we built the following pipeline for each topic:</p><p>1. Retrieve the evidence text of the topic by crawling the evidence URL field; 2. Retrieve an initial set of documents with BM25; 3. Represent documents as probability distributions; 4. Rerank on the similarity between documents and the evidence text. The settings for each run can be found in Table <ref type="table" coords="5,289.53,409.13,3.40,8.80" target="#tab_1">1</ref>.</p><p>In order to represent documents as probability distributions in vector space we create tf-idf vectors of the initial retrieval and normalize the document vectors, so that they add up to 1. To compute the distance between each document and the evidence we propose Equation (1). This is a symmetrized version of the Kullback-Leibler divergence and was adapted from the work of Kulkarni and Callan <ref type="bibr" coords="5,166.26,492.81,11.15,8.80" target="#b2">[3]</ref> where it was originally used to cluster topics in a collection based on the distance between each document and their centroid.</p><formula xml:id="formula_1" coords="5,190.89,530.50,289.70,26.86">D N KL θ E θ D = w∈D∩Q p(w | θ E ) log p(w | θ D ) λ • p(w | θ B )<label>(1)</label></formula><formula xml:id="formula_2" coords="5,268.94,562.96,153.72,26.86">+ w∈D∩Q p(w | θ D ) log p(w | θ E ) λ • p(w | θ B )</formula><p>We adapt their formula to our scenario by computing the distance between the evidence text document θ E and each document present in the initial retrieval θ Di . We also replace the global collection model θ C by a topic-based background model θ B , which is estimated using an average pooling of the documents retrieved by a query Q for each given topic T .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document length bias</head><p>We suspected that documents with a length similar to the evidence text's have an advantage due to the use of the KL-divergence. Documents larger than the evidence text probably contain a larger vocabulary, thus increasing the divergence, while smaller documents probably contain a smaller vocabulary than the evidence text, thus also contributing to an increase in the divergence. We confirmed this bias by comparing the distribution of document lengths in BM25 retrieval in Fig. <ref type="figure" coords="6,331.15,425.99,10.62,8.80" target="#fig_1">2a</ref> with vohEvDivTfidf in Fig. <ref type="figure" coords="6,468.53,425.99,9.34,8.80" target="#fig_1">2b</ref>. As expected, in vohEvDivTfidf the top documents are concentrated closer to the evidence text's size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this section we look at the results obtained in both the submitted runs and not-submitted runs. We discuss the experiments evaluated on each task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Total Recall Results</head><p>The goal in the Total Recall task is to find incorrect documents. Table <ref type="table" coords="7,431.59,137.31,5.34,8.80" target="#tab_2">2</ref> shows the results obtained for this task. We include the Track leaderboard's median score, our submitted runs, and also non-submitted runs (identifiable by an asterisk). The baseline vohbm25rm3 was slightly better than the median at finding incorrect documents. We also ran the baseline on the index containing the original, unfiltered collection of multi-language articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">AdHoc Results</head><p>The AdHoc task has relevance judgments for 3 criteria: usefulness, credibility, and correctness. Based on these criteria, several derived relevance judgments were used for evaluation. We grouped the measured relevance judgments in two: the binary assessed judgments in Table <ref type="table" coords="7,286.66,277.67,4.11,8.80" target="#tab_3">3</ref>, and the multi-aspect assessed judgments in Table <ref type="table" coords="7,161.50,289.63,3.91,8.80" target="#tab_4">4</ref>. The multi-aspect measures are computed using CAM and compatibility.</p><p>Similarly to the Total Recall task we also ran the baseline over the original, unfiltered, multi-language collection. The submitted run vohcolabEvSim had the document rank inverted by accident, so we also evaluated the not-submitted run vohcolabEvSimInv* with the scores corrected. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Conclusions</head><p>The baselines outperformed the median by a significant margin and were the best performing runs for both tasks. We also showed that using an English filtered index helped find more relevant documents for both tasks. RM3 improved the compatibility compatibility measures by a significant margin on the adhoc task. While the officially submitted run vohcolabEvSim based on the commons similarity/divergence hypothesis under-performed due to the being inverted, the post-mortem run vohcolabEvSimInv*, which inverts the scores back, achieved much better results in the AdHoc task. It significantly increased the compatibility with helpful-only results and keeps a low compatibility with harmful-only results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,248.19,364.73,118.97,8.97;5,175.98,280.33,263.40,70.20"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. KL reranking pipeline</figDesc><graphic coords="5,175.98,280.33,263.40,70.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,134.77,318.78,347.50,8.97;6,301.21,189.09,179.28,107.57"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Distribution of the difference of doc-length's between top/bottom vs. evidence.</figDesc><graphic coords="6,301.21,189.09,179.28,107.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,157.19,116.43,300.98,8.97"><head>Table 1 .</head><label>1</label><figDesc>Pipeline description for commons similarity and divergence runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,237.13,553.28,141.10,107.08"><head>Table 2 .</head><label>2</label><figDesc>Total Recall Task results</figDesc><table coords="6,257.20,575.64,101.90,84.72"><row><cell>Run</cell><cell>Rprec</cell></row><row><cell>median</cell><cell>0.0976</cell></row><row><cell>vohbm25rm3</cell><cell>0.1026</cell></row><row><cell cols="2">vohTR_bm25* 0.1020</cell></row><row><cell cols="2">vohbm25rm3-ml* 0.0482</cell></row><row><cell cols="2">vohEvDiv_colm 0.0430</cell></row><row><cell>vohEvDivTfidf</cell><cell>0.0325</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,177.77,364.44,259.81,146.40"><head>Table 3 .</head><label>3</label><figDesc>Ad hoc Task results using binary relevance judgments.</figDesc><table coords="7,188.03,388.44,233.37,122.40"><row><cell></cell><cell></cell><cell cols="2">NDCG</cell></row><row><cell></cell><cell>useful</cell><cell>useful correct</cell><cell>useful credible</cell><cell>useful correct</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>credible</cell></row><row><cell>median</cell><cell cols="3">0.4699 0.3380 0.4471</cell><cell>0.3308</cell></row><row><cell>vohbm25</cell><cell cols="2">0.6077 0.4771</cell><cell cols="2">0.5768 0.4592</cell></row><row><cell cols="5">vohAH_bm25rm3* 0.5950 0.4564 0.5684 0.4545</cell></row><row><cell cols="5">vohcolabEvSimInv* 0.5528 0.4547 0.5504 0.4483</cell></row><row><cell>vohbm25-ml*</cell><cell cols="4">0.4800 0.3408 0.4608 0.3317</cell></row><row><cell>vohcolabEvSim</cell><cell cols="2">0.4287 0.3271</cell><cell cols="2">0.3950 0.3061</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,144.81,524.92,318.98,135.44"><head>Table 4 .</head><label>4</label><figDesc>Ad hoc Task results using multiple aspect judgments.</figDesc><table coords="7,144.81,548.92,318.98,111.44"><row><cell></cell><cell></cell><cell>cam_map</cell><cell></cell><cell></cell><cell cols="2">compatibility</cell></row><row><cell></cell><cell>useful</cell><cell>correct</cell><cell cols="2">3aspects helpful-</cell><cell>harmful-</cell><cell>helpful-</cell></row><row><cell></cell><cell>credible</cell><cell>credible</cell><cell></cell><cell>only</cell><cell>only</cell><cell>harmful</cell></row><row><cell>median</cell><cell>0.1717</cell><cell>0.1003</cell><cell>0.1389</cell><cell cols="2">0.3337 0.0747</cell><cell>0.2590</cell></row><row><cell>vohbm25</cell><cell>0.2824</cell><cell>0.1740</cell><cell>0.2367</cell><cell>0.3402</cell><cell>0.1124</cell><cell>0.2278</cell></row><row><cell cols="3">vohAH_bm25rm3* 0.2929 0.1891</cell><cell cols="3">0.2468 0.3589 0.1218</cell><cell>0.2371</cell></row><row><cell cols="3">vohcolabEvSimInv* 0.2023 0.1486</cell><cell>0.1742</cell><cell>0.2454</cell><cell>0.0457</cell><cell>0.1997</cell></row><row><cell>vohbm25-ml*</cell><cell>0.1869</cell><cell cols="2">0.0952 0.1514</cell><cell cols="3">0.2293 0.0503 0.1790</cell></row><row><cell>vohcolabEvSim</cell><cell>0.0717</cell><cell cols="2">0.0330 0.0574</cell><cell cols="3">0.0862 0.0245 0.0608</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,144.73,658.36,259.90,7.62"><p>https://commoncrawl.org/2016/10/news-dataset-available/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,658.36,335.72,7.62"><p>https://trec-health-misinfo.github.io/docs/AssessingGuidelines-2020.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="4,144.73,636.29,212.83,7.62"><p>https://github.com/jmmackenzie/cc-news-tools/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="4,144.73,647.32,174.17,7.62"><p>https://github.com/castorini/pyserini</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="4,144.73,658.36,94.15,7.62"><p>https://www.nltk.org</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work is supported by <rs type="funder">DSAIPA project FrailCare.AI</rs> (<rs type="grantNumber">DSAIPA/0106/2019/02</rs>) and by <rs type="funder">NOVA LINCS</rs> (<rs type="grantNumber">UIDB/04516/2020</rs>) with the financial support of <rs type="funder">FCT -Fundação para a Ciência e a Tecnologia</rs>, through national funds.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZBHXxyQ">
					<idno type="grant-number">DSAIPA/0106/2019/02</idno>
				</org>
				<org type="funding" xml:id="_842KFwy">
					<idno type="grant-number">UIDB/04516/2020</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,139.75,291.29,342.78,8.80;8,148.13,303.24,332.46,8.80;8,147.77,315.20,333.02,8.80;8,148.13,327.15,332.47,9.16;8,148.13,339.86,104.61,8.41" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,342.53,291.29,135.73,8.80">Offline evaluation without gain</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vtyurina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<idno type="DOI">10.1145/3409256.3409816</idno>
		<ptr target="https://doi.org/10.1145/3409256.3409816" />
	</analytic>
	<monogr>
		<title level="m" coord="8,164.47,303.24,316.12,8.80;8,147.77,315.20,144.80,8.80">Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval</title>
		<meeting>the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="185" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,139.03,351.06,342.94,8.80;8,148.13,363.02,333.85,8.80;8,148.13,374.97,332.47,8.80;8,148.13,386.93,332.46,8.80;8,148.13,398.88,332.47,9.16;8,148.13,411.59,110.33,8.41" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,260.21,374.97,220.38,8.80;8,148.13,386.93,168.55,8.80">Covid-19-related infodemic and its impact on public health: A global social media analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kabir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yeasmin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">I</forename><surname>Amin Chowdhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Chughtai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Seale</surname></persName>
		</author>
		<idno type="DOI">10.4269/ajtmh.20-0812</idno>
		<ptr target="http://www.ajtmh.org/content/journals/10.4269/ajtmh.20-0812" />
	</analytic>
	<monogr>
		<title level="j" coord="8,326.87,386.93,153.72,8.80;8,148.13,398.88,95.95,8.80">The American Journal of Tropical Medicine and Hygiene</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.95,422.79,341.64,8.80;8,148.13,434.75,332.47,9.16;8,148.13,447.45,130.76,8.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,262.60,422.79,217.99,8.80;8,148.13,434.75,104.36,8.80">Selective search: Efficient and effective search of large textual collections</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2738035</idno>
		<ptr target="https://doi.org/10.1145/2738035" />
	</analytic>
	<monogr>
		<title level="j" coord="8,261.46,434.75,99.57,8.80">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015-04">Apr 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,139.18,458.66,341.41,8.80;8,148.13,470.62,334.13,8.80;8,148.13,482.57,333.85,8.80;8,147.75,494.53,304.83,9.16" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,327.74,458.66,152.86,8.80;8,148.13,470.62,130.12,8.80">Evaluation measures for relevance and credibility in ranked lists</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,301.87,470.62,180.38,8.80;8,148.13,482.57,234.81,8.80">Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval</title>
		<meeting>the ACM SIGIR International Conference on Theory of Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,139.03,506.48,342.94,8.80;8,148.13,518.44,333.85,8.80;8,148.13,530.39,334.13,8.80;8,148.13,542.35,333.85,8.80;8,147.86,554.30,79.51,8.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,454.10,530.39,28.15,8.80;8,148.13,542.35,144.55,8.80">Scikitlearn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,302.00,542.35,164.65,8.80">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.95,566.26,343.30,8.80;8,148.13,578.21,332.46,8.80;8,148.13,590.17,334.40,8.80;8,147.73,602.12,252.86,8.80" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,272.06,566.26,210.20,8.80;8,148.13,578.21,114.71,8.80">Anserini: Enabling the Use of Lucene for Information Retrieval Research</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,287.31,578.21,193.28,8.80;8,148.13,590.17,313.68,8.80;8,199.86,602.12,42.13,8.80">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;17</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
