<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.44,84.23,343.62,15.44">MPII at the TREC 2020 Deep Learning Track</title>
				<funder>
					<orgName type="full">TensorFlow Research Cloud</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.31,114.38,44.16,10.59"><forename type="first">Canjia</forename><surname>Li</surname></persName>
							<email>licanjia17@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,395.51,114.38,67.77,10.59"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
							<email>ayates@mpi-inf.mpg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.44,84.23,343.62,15.44">MPII at the TREC 2020 Deep Learning Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7F3E320C8B50779F2335208F18977762</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-08-05T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>MPII participated in the TREC 2020 Deep Learning track's document ranking task with several variants of our recent PARADE model. PARADE is based on the idea that aggregating passage-level relevance representations is preferable to aggregating relevance scores. We submitted runs using three different PARADE variants that performed well in previous evaluations. The results differ from both those in the PARADE paper and those from the NTCIR-15 WWW-3 track: on this document ranking task, the least complex representation aggregation technique performs best.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>We participated in the TREC 2020 Deep Learning track's document ranking task in order to supplement previous evaluations of our PARADE ranking model <ref type="bibr" coords="1,144.40,333.80,9.35,7.94" target="#b5">[6]</ref>. While pre-trained Transformer architectures like BERT can be directly applied as relevance classifiers to passage ranking tasks <ref type="bibr" coords="1,136.42,355.72,9.42,7.94" target="#b7">[8]</ref>, their maximum input length limitation must be overcome when applying them to longer documents <ref type="bibr" coords="1,282.73,366.67,9.52,7.94" target="#b6">[7]</ref>. Dai and Callan <ref type="bibr" coords="1,111.20,377.63,10.66,7.94" target="#b2">[3]</ref> overcame this limitation by applying BERT to each passage independently and then aggregating the passages' scores into a document score. PARADE attempts to improve effectiveness by aggregating passage representations rather than scores. In this paper we briefly summarize PARADE's aggregation strategies and describe how the model was trained for TREC DL before comparing results for three PARADE variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head><p>PARADE uses a pre-trained Transformer-based model, such as BERT <ref type="bibr" coords="1,77.34,493.36,10.69,7.94" target="#b3">[4]</ref> or ELECTRA <ref type="bibr" coords="1,140.88,493.36,9.52,7.94" target="#b1">[2]</ref>, to produce a vector representation of each passage within a document. These vector representations are then aggregated to arrive at a document relevance score using one of several approaches. The model is trained end-to-end, which avoids the need to extend a document's relevance score to apply to all passages within the document (during training). A more detailed description can be found in the original work <ref type="bibr" coords="1,227.08,559.11,9.52,7.94" target="#b5">[6]</ref>. We submitted runs corresponding to the aggregation approaches that previous performed well in the original work and in NTCIR WWW-3 <ref type="bibr" coords="1,282.27,581.03,9.63,7.94" target="#b4">[5]</ref>: PARADE Max , PARADE Attn , and the full Transformer-based model (denoted "PARADE").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL SETUP 3.1 Data</head><p>Using a sliding window of 150 tokens with a stride of 100, we split each document into 32 passages. This resulted in 3250 (100 * 31+150) tokens being preserved in each document (excluding overlapping tokens). The maximum sequence length was set to 256 tokens, which includes both query and document terms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training</head><p>PARADE was initialized with an ELECTRA-Base model that was first fine-tuned on the MS MARCO passage ranking dataset <ref type="bibr" coords="1,546.89,278.24,9.52,7.94" target="#b0">[1]</ref>. PARADE was then trained on the judgments from the TREC 2019 Deep Learning track's document ranking task <ref type="bibr" coords="1,485.36,300.15,10.44,7.94" target="#b8">[9]</ref> by reranking the top 100 results from the organizers' baseline run. The model was trained for 3 epochs with a batch size of 32 and a learning rate of 3e-6 with warm-up over the first 10 proportions of training steps.</p><p>After training, the model was used to rerank the top 100 results from the 2020 Deep Learning track's baseline run. All experiments were conducted on a Google Cloud TPU v3-8.</p><p>Our code <ref type="foot" coords="1,363.30,374.72,3.38,6.44" target="#foot_0">1</ref> and the ELECTRA-Base model fine-tuned on MS MARCO<ref type="foot" coords="1,349.68,385.68,3.38,6.44" target="#foot_1">2</ref> are available online. Additionally, Capreolus <ref type="bibr" coords="1,526.28,387.83,14.85,7.94" target="#b9">[10]</ref> provides independent implementations of PARADE in both TensorFlow and PyTorch as well as the fine-tuned ELECTRA-base model under the name electra-base-msmarco. <ref type="foot" coords="1,445.79,418.55,3.38,6.44" target="#foot_2">3</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We submitted three runs using the PARADE, PARADE Max , and PARADE Attn variants. The results are shown in Table <ref type="table" coords="1,524.54,467.56,3.13,7.94" target="#tab_0">1</ref>. Unlike the results from WWW-3 and in the original paper's evaluations, PARADE Max (i.e., max pooling across each dimension of the passages' representations) outperforms the full PARADE model (i.e., Transformer-based aggregation of passage representations). Similarly, PARADE Max outperforms PARADE Attn , though the latter's low scores suggests that training was not successful. The reason for these approaches' differences in effectiveness on the DL20 document ranking task is not clear and requires further investigation.</p><p>Differently from the queries used in the other evaluations (i.e., keyword queries with WWW-3 and topic and description queries with Robust04 and GOV2), the DL20 queries are questions. However, the documents and other aspects of the evaluation also differ; further analysis is needed to determine if the query type or differences in document characteristics have any impact.</p><p>We additionally include comparisons of each variant's metrics against the median run scores in Figures <ref type="figure" coords="1,467.38,642.90,3.31,7.94" target="#fig_0">1</ref><ref type="figure" coords="1,470.69,642.90,3.31,7.94">2</ref><ref type="figure" coords="1,474.00,642.90,3.31,7.94">3</ref>. The best-performing and worst-performing queries for each variant are shown in Table <ref type="table" coords="1,553.17,653.86,3.01,7.94" target="#tab_2">2</ref>, Table <ref type="table" coords="1,339.73,664.82,3.07,7.94" target="#tab_3">3</ref>, and Table <ref type="table" coords="1,385.90,664.82,3.07,7.94" target="#tab_4">4</ref>.      </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,172.84,214.50,266.32,7.70;2,79.02,235.38,151.32,100.88"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Per-topic difference from median nDCG@10 for all runs</figDesc><graphic coords="2,79.02,235.38,151.32,100.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,184.25,366.19,243.50,7.70;2,79.02,387.07,151.32,100.88"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Per-topic difference from median mAP for all runs</figDesc><graphic coords="2,79.02,387.07,151.32,100.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,329.38,161.25,219.68,56.00"><head>Table 1 :</head><label>1</label><figDesc>Deep Learning document task results.</figDesc><table coords="1,329.38,161.25,219.68,42.96"><row><cell>Run Name Variant</cell><cell>mAP</cell><cell>nDCG@10</cell><cell>MRR</cell></row><row><cell>mpii_run1 PARADE</cell><cell>0.4030</cell><cell>0.6017</cell><cell>0.9000</cell></row><row><cell cols="2">mpii_run2 PARADE Max 0.4205</cell><cell>0.6135</cell><cell>0.8833</cell></row><row><cell cols="2">mpii_run3 PARADE Attn 0.2587</cell><cell>0.3286</cell><cell>0.6388</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,111.37,249.38,391.26,187.91"><head>Table 2 :</head><label>2</label><figDesc>Queries solved best/worst by PARADE according to nDCG@10.</figDesc><table coords="3,111.37,283.46,391.26,153.83"><row><cell>Type</cell><cell>QID</cell><cell cols="2">Score -洧노 Query</cell></row><row><cell></cell><cell>67316</cell><cell>0.3460</cell><cell>can fever cause miscarriage early pregnancy</cell></row><row><cell></cell><cell>1105792</cell><cell>0.3380</cell><cell>define: geon</cell></row><row><cell>洧노 = median</cell><cell>42255</cell><cell>0.2345</cell><cell>average salary for dental hygienist in nebraska</cell></row><row><cell></cell><cell cols="3">1136769 -0.2797 why does lacquered brass tarnish</cell></row><row><cell></cell><cell cols="3">1119543 -0.2030 what does a psychological screening consist of for egg donors</cell></row><row><cell></cell><cell>911232</cell><cell cols="2">-0.1554 what type of conflict does della face in o, henry the gift of the magi</cell></row><row><cell></cell><cell>1116380</cell><cell>0.9266</cell><cell>what is a nonconformity? earth science</cell></row><row><cell></cell><cell>1131069</cell><cell>0.9149</cell><cell>how many sons robert kraft has</cell></row><row><cell>洧노 = 0</cell><cell>1136962</cell><cell>0.9071</cell><cell>why did the ancient egyptians call their land kemet, or black land?</cell></row><row><cell></cell><cell>673670</cell><cell>0.0000</cell><cell>what is a alm</cell></row><row><cell></cell><cell>1056416</cell><cell>0.2698</cell><cell>who was the highest career passer rating in the nfl</cell></row><row><cell></cell><cell>258062</cell><cell>0.2914</cell><cell>how long does it take to remove wisdom tooth</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,111.37,443.92,391.26,187.91"><head>Table 3 :</head><label>3</label><figDesc>Queries solved best/worst by PARADE Max according to nDCG@10.</figDesc><table coords="3,111.37,478.00,391.26,153.83"><row><cell>Type</cell><cell>QID</cell><cell cols="2">Score -洧노 Query</cell></row><row><cell></cell><cell>997622</cell><cell>0.2985</cell><cell>where is the show shameless filmed</cell></row><row><cell></cell><cell>1116380</cell><cell>0.1413</cell><cell>what is a nonconformity? earth science</cell></row><row><cell>洧노 = median</cell><cell>1136769</cell><cell>0.1369</cell><cell>why does lacquered brass tarnish</cell></row><row><cell></cell><cell>701453</cell><cell cols="2">-0.7443 what is a statutory deed</cell></row><row><cell></cell><cell>324585</cell><cell cols="2">-0.6847 how much money do motivational speakers make</cell></row><row><cell></cell><cell>911232</cell><cell cols="2">-0.6641 what type of conflict does della face in o, henry the gift of the magi</cell></row><row><cell></cell><cell>1113256</cell><cell>0.9881</cell><cell>what is reba mcentire's net worth</cell></row><row><cell></cell><cell>997622</cell><cell>0.9048</cell><cell>where is the show shameless filmed</cell></row><row><cell>洧노 = 0</cell><cell>169208</cell><cell>0.8746</cell><cell>does mississippi have an income tax</cell></row><row><cell></cell><cell>1136043</cell><cell>0.0000</cell><cell>difference between a hotel and motel</cell></row><row><cell></cell><cell>324585</cell><cell>0.0000</cell><cell>how much money do motivational speakers make</cell></row><row><cell></cell><cell>336901</cell><cell>0.0000</cell><cell>how old is vanessa redgrave</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,153.62,638.46,304.46,8.99"><head>Table 4 :</head><label>4</label><figDesc>Queries solved best/worst by PARADE Attn according to nDCG@10.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,320.88,685.97,103.61,6.18"><p>https://github.com/canjiali/PARADE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,321.00,694.38,97.65,6.18"><p>https://zenodo.org/record/3974431</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,321.00,702.79,118.92,6.18"><p>https://github.com/capreolus-ir/capreolus</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by <rs type="person">Google Cloud</rs> and by the <rs type="funder">TensorFlow Research Cloud</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="2,69.23,615.12,224.81,6.18;2,69.23,623.09,224.94,6.18;2,69.23,631.06,224.81,6.18;2,69.23,638.98,224.81,6.23;2,69.23,646.95,97.33,6.23" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="2,284.73,631.06,9.32,6.18;2,69.23,639.03,204.62,6.18">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName coords=""><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alina</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268v3</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="2,69.23,654.97,225.88,6.18;2,69.23,662.94,225.88,6.18;2,69.23,670.86,201.50,6.23" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="2,69.23,662.94,222.93,6.18">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,76.83,670.86,158.44,6.23">8th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>ICLR 2020</note>
</biblStruct>

<biblStruct coords="2,69.23,678.88,224.81,6.18;2,69.23,686.80,224.81,6.23;2,69.23,694.77,224.81,6.23;2,68.81,702.74,62.11,6.23" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="2,178.87,678.88,115.17,6.18;2,69.23,686.85,109.51,6.18">Deeper Text Understanding for IR with Contextual Neural Language Modeling</title>
		<author>
			<persName coords=""><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,191.29,686.80,102.75,6.23;2,69.23,694.77,224.81,6.23">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="985" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,333.39,547.15,225.63,6.18;2,333.39,555.12,224.81,6.18;2,333.39,563.05,203.39,6.23" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="2,541.50,547.15,17.53,6.18;2,333.39,555.12,214.32,6.18">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,333.39,563.05,44.51,6.23">NAACL-HLT (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,333.39,571.06,224.81,6.18;2,333.39,578.99,224.81,6.23;2,333.39,586.96,36.28,6.23" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="2,439.32,571.06,107.61,6.18">MPII at the NTCIR-15 WWW-3 Task</title>
		<author>
			<persName coords=""><forename type="first">Canjia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,333.39,578.99,224.81,6.23;2,333.39,586.96,33.49,6.23">Proceedings of the 15th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<meeting>the 15th NTCIR Conference on Evaluation of Information Access Technologies</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,333.39,594.98,225.99,6.18;2,333.39,602.90,224.81,6.23;2,333.39,610.92,207.39,6.18" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="2,548.93,594.98,10.46,6.18;2,333.39,602.95,202.29,6.18">PA-RADE: Passage Representation Aggregation for Document Reranking</title>
		<author>
			<persName coords=""><forename type="first">Canjia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yingfei</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09093</idno>
		<ptr target="https://arxiv.org/abs/2008.09093" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,333.39,618.89,224.81,6.18;2,333.39,626.81,215.81,6.23" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06467</idno>
		<title level="m" coord="2,489.56,618.89,68.64,6.18;2,333.39,626.86,101.34,6.18">Pretrained Transformers for Text Ranking: BERT and Beyond</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="2,333.39,634.83,225.89,6.18;2,333.39,642.75,108.33,6.23" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="2,467.59,634.83,88.07,6.18">Passage Re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="2,333.39,650.77,225.88,6.18;2,333.39,658.74,224.81,6.18;2,333.39,666.71,224.81,6.18;2,333.39,674.63,17.16,6.23" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="2,351.69,658.74,206.51,6.18;2,333.39,666.71,214.13,6.18">IDST at TREC 2019 Deep Learning Track: Deep Cascade Ranking with Generation-based Document Expansion and Pre-trained Language Modeling</title>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiangnan</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,333.39,674.63,13.73,6.23">TREC</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="2,333.39,682.65,224.81,6.18;2,333.39,690.57,224.81,6.23;2,333.39,698.54,152.49,6.23" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="2,528.89,682.65,29.31,6.18;2,333.39,690.62,67.89,6.18">Flexible IR Pipelines with Capreolus</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><forename type="middle">Martin</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,413.05,690.57,145.15,6.23;2,333.39,698.54,116.02,6.23">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3181" to="3188" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
